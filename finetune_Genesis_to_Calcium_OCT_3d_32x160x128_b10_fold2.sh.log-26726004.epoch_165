/home/gridsan/nchutisilp/.conda/envs/nnunet/bin/python
Begin training and evaluating FOLD 2 CONFIG 3d_32x160x128_b10 TRAINER nnUNetTrainer from scratch
wandb: Tracking run with wandb version 0.16.6
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2024-08-03 03:52:21.862379: Using torch.compile...
/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
################### Loading pretrained weights from file  /home/gridsan/nchutisilp/datasets/ModelGenesisOutputs/ModelGenesisNNUNetPretrainingV2_noNorm_correct_orientation/Converted_nnUNet_Genesis_OCT_Best.pt ###################
Below is the list of overlapping blocks in pretrained model and nnUNet architecture:
encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])
encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])
encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])
encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])
encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])
encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])
encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])
encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])
encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])
encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])
encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])
encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])
encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])
encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])
encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])
encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])
encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])
encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])
encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])
encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])
encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])
encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])
encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])
encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])
encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])
encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])
encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])
decoder.encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])
decoder.encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])
decoder.encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])
decoder.encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])
decoder.encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])
decoder.encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])
decoder.encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])
decoder.encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])
decoder.encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])
decoder.encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])
decoder.encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])
decoder.encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])
decoder.encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])
decoder.encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.stages.0.convs.0.conv.weight shape torch.Size([320, 640, 3, 3, 3])
decoder.stages.0.convs.0.conv.bias shape torch.Size([320])
decoder.stages.0.convs.0.norm.weight shape torch.Size([320])
decoder.stages.0.convs.0.norm.bias shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.0.weight shape torch.Size([320, 640, 3, 3, 3])
decoder.stages.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.stages.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.stages.0.convs.1.conv.bias shape torch.Size([320])
decoder.stages.0.convs.1.norm.weight shape torch.Size([320])
decoder.stages.0.convs.1.norm.bias shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.stages.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.stages.1.convs.0.conv.weight shape torch.Size([256, 512, 3, 3, 3])
decoder.stages.1.convs.0.conv.bias shape torch.Size([256])
decoder.stages.1.convs.0.norm.weight shape torch.Size([256])
decoder.stages.1.convs.0.norm.bias shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.0.weight shape torch.Size([256, 512, 3, 3, 3])
decoder.stages.1.convs.0.all_modules.0.bias shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.1.weight shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.1.bias shape torch.Size([256])
decoder.stages.1.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.stages.1.convs.1.conv.bias shape torch.Size([256])
decoder.stages.1.convs.1.norm.weight shape torch.Size([256])
decoder.stages.1.convs.1.norm.bias shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.stages.1.convs.1.all_modules.0.bias shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.1.weight shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.1.bias shape torch.Size([256])
decoder.stages.2.convs.0.conv.weight shape torch.Size([128, 256, 3, 3, 3])
decoder.stages.2.convs.0.conv.bias shape torch.Size([128])
decoder.stages.2.convs.0.norm.weight shape torch.Size([128])
decoder.stages.2.convs.0.norm.bias shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.0.weight shape torch.Size([128, 256, 3, 3, 3])
decoder.stages.2.convs.0.all_modules.0.bias shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.1.weight shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.1.bias shape torch.Size([128])
decoder.stages.2.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.stages.2.convs.1.conv.bias shape torch.Size([128])
decoder.stages.2.convs.1.norm.weight shape torch.Size([128])
decoder.stages.2.convs.1.norm.bias shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.stages.2.convs.1.all_modules.0.bias shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.1.weight shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.1.bias shape torch.Size([128])
decoder.stages.3.convs.0.conv.weight shape torch.Size([64, 128, 3, 3, 3])
decoder.stages.3.convs.0.conv.bias shape torch.Size([64])
decoder.stages.3.convs.0.norm.weight shape torch.Size([64])
decoder.stages.3.convs.0.norm.bias shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.0.weight shape torch.Size([64, 128, 3, 3, 3])
decoder.stages.3.convs.0.all_modules.0.bias shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.1.weight shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.1.bias shape torch.Size([64])
decoder.stages.3.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.stages.3.convs.1.conv.bias shape torch.Size([64])
decoder.stages.3.convs.1.norm.weight shape torch.Size([64])
decoder.stages.3.convs.1.norm.bias shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.stages.3.convs.1.all_modules.0.bias shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.1.weight shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.1.bias shape torch.Size([64])
decoder.stages.4.convs.0.conv.weight shape torch.Size([32, 64, 3, 3, 3])
decoder.stages.4.convs.0.conv.bias shape torch.Size([32])
decoder.stages.4.convs.0.norm.weight shape torch.Size([32])
decoder.stages.4.convs.0.norm.bias shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.0.weight shape torch.Size([32, 64, 3, 3, 3])
decoder.stages.4.convs.0.all_modules.0.bias shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.1.weight shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.1.bias shape torch.Size([32])
decoder.stages.4.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.stages.4.convs.1.conv.bias shape torch.Size([32])
decoder.stages.4.convs.1.norm.weight shape torch.Size([32])
decoder.stages.4.convs.1.norm.bias shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.stages.4.convs.1.all_modules.0.bias shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.1.weight shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.1.bias shape torch.Size([32])
decoder.transpconvs.0.weight shape torch.Size([320, 320, 1, 2, 2])
decoder.transpconvs.0.bias shape torch.Size([320])
decoder.transpconvs.1.weight shape torch.Size([320, 256, 2, 2, 2])
decoder.transpconvs.1.bias shape torch.Size([256])
decoder.transpconvs.2.weight shape torch.Size([256, 128, 2, 2, 2])
decoder.transpconvs.2.bias shape torch.Size([128])
decoder.transpconvs.3.weight shape torch.Size([128, 64, 2, 2, 2])
decoder.transpconvs.3.bias shape torch.Size([64])
decoder.transpconvs.4.weight shape torch.Size([64, 32, 2, 2, 2])
decoder.transpconvs.4.bias shape torch.Size([32])
################### Done ###################
2024-08-03 03:52:23.777758: do_dummy_2d_data_aug: True
2024-08-03 03:52:23.782572: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset302_Calcium_OCTv2/splits_final.json
2024-08-03 03:52:23.786592: The split file contains 3 splits.
2024-08-03 03:52:23.789125: Desired fold for training: 2
2024-08-03 03:52:23.791108: This split has 4 training and 2 validation cases.
using pin_memory on device 0
using pin_memory on device 0

This is the configuration used by this training:
Configuration name: 3d_32x160x128_b10
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 10, 'patch_size': [32, 160, 128], 'median_image_size_in_voxels': [375.0, 498.0, 498.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'inherits_from': '3d_fullres'} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset302_Calcium_OCTv2', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.4977976381778717, 'mean': 0.13332499563694, 'median': 0.08871842920780182, 'min': 0.0, 'percentile_00_5': 0.014754901640117168, 'percentile_99_5': 0.4977976381778717, 'std': 0.12022686749696732}}} 

2024-08-03 03:52:27.311502: unpacking dataset...
2024-08-03 03:52:33.110346: unpacking done...
2024-08-03 03:52:33.135022: Unable to plot network architecture: nnUNet_compile is enabled!
2024-08-03 03:52:33.214189: 
2024-08-03 03:52:33.216370: Epoch 0
2024-08-03 03:52:33.218006: Current learning rate: 0.01
2024-08-03 03:55:14.922519: Validation loss improved from 1000.00000 to -0.19545! Patience: 0/50
2024-08-03 03:55:14.924475: train_loss -0.1524
2024-08-03 03:55:14.926287: val_loss -0.1955
2024-08-03 03:55:14.927649: Pseudo dice [0.545]
2024-08-03 03:55:14.929135: Epoch time: 161.71 s
2024-08-03 03:55:14.930230: Yayy! New best EMA pseudo Dice: 0.545
2024-08-03 03:55:16.476795: 
2024-08-03 03:55:16.478649: Epoch 1
2024-08-03 03:55:16.480224: Current learning rate: 0.00999
2024-08-03 03:57:00.018358: Validation loss improved from -0.19545 to -0.26794! Patience: 0/50
2024-08-03 03:57:00.019784: train_loss -0.3065
2024-08-03 03:57:00.021139: val_loss -0.2679
2024-08-03 03:57:00.022279: Pseudo dice [0.5992]
2024-08-03 03:57:00.023480: Epoch time: 103.54 s
2024-08-03 03:57:00.024562: Yayy! New best EMA pseudo Dice: 0.5504
2024-08-03 03:57:01.789188: 
2024-08-03 03:57:01.790979: Epoch 2
2024-08-03 03:57:01.792378: Current learning rate: 0.00998
2024-08-03 03:59:10.438658: Validation loss improved from -0.26794 to -0.32772! Patience: 0/50
2024-08-03 03:59:10.440085: train_loss -0.3529
2024-08-03 03:59:10.441281: val_loss -0.3277
2024-08-03 03:59:10.442335: Pseudo dice [0.6186]
2024-08-03 03:59:10.443360: Epoch time: 128.65 s
2024-08-03 03:59:10.444411: Yayy! New best EMA pseudo Dice: 0.5573
2024-08-03 03:59:12.319156: 
2024-08-03 03:59:12.320630: Epoch 3
2024-08-03 03:59:12.321946: Current learning rate: 0.00997
2024-08-03 04:01:52.451602: Validation loss improved from -0.32772 to -0.33572! Patience: 0/50
2024-08-03 04:01:52.453085: train_loss -0.3822
2024-08-03 04:01:52.454222: val_loss -0.3357
2024-08-03 04:01:52.455329: Pseudo dice [0.6267]
2024-08-03 04:01:52.456270: Epoch time: 160.14 s
2024-08-03 04:01:52.457194: Yayy! New best EMA pseudo Dice: 0.5642
2024-08-03 04:01:54.318555: 
2024-08-03 04:01:54.321730: Epoch 4
2024-08-03 04:01:54.323222: Current learning rate: 0.00996
2024-08-03 04:04:57.997236: Validation loss improved from -0.33572 to -0.37048! Patience: 0/50
2024-08-03 04:04:57.998930: train_loss -0.4151
2024-08-03 04:04:58.000375: val_loss -0.3705
2024-08-03 04:04:58.001329: Pseudo dice [0.662]
2024-08-03 04:04:58.002846: Epoch time: 183.69 s
2024-08-03 04:04:58.338508: Yayy! New best EMA pseudo Dice: 0.574
2024-08-03 04:05:00.279793: 
2024-08-03 04:05:00.281717: Epoch 5
2024-08-03 04:05:00.283039: Current learning rate: 0.00995
2024-08-03 04:08:28.076144: Validation loss improved from -0.37048 to -0.39650! Patience: 0/50
2024-08-03 04:08:28.079531: train_loss -0.4466
2024-08-03 04:08:28.080583: val_loss -0.3965
2024-08-03 04:08:28.081761: Pseudo dice [0.6655]
2024-08-03 04:08:28.082923: Epoch time: 207.8 s
2024-08-03 04:08:28.083985: Yayy! New best EMA pseudo Dice: 0.5831
2024-08-03 04:08:29.859251: 
2024-08-03 04:08:29.860925: Epoch 6
2024-08-03 04:08:29.862204: Current learning rate: 0.00995
2024-08-03 04:12:18.458616: Validation loss improved from -0.39650 to -0.43175! Patience: 0/50
2024-08-03 04:12:18.459835: train_loss -0.4796
2024-08-03 04:12:18.461269: val_loss -0.4317
2024-08-03 04:12:18.462432: Pseudo dice [0.6844]
2024-08-03 04:12:18.463521: Epoch time: 228.6 s
2024-08-03 04:12:18.464464: Yayy! New best EMA pseudo Dice: 0.5933
2024-08-03 04:12:20.251991: 
2024-08-03 04:12:20.253920: Epoch 7
2024-08-03 04:12:20.255326: Current learning rate: 0.00994
2024-08-03 04:16:23.804905: Validation loss did not improve from -0.43175. Patience: 1/50
2024-08-03 04:16:23.806549: train_loss -0.4764
2024-08-03 04:16:23.807968: val_loss -0.3772
2024-08-03 04:16:23.809405: Pseudo dice [0.6455]
2024-08-03 04:16:23.810737: Epoch time: 243.56 s
2024-08-03 04:16:23.812006: Yayy! New best EMA pseudo Dice: 0.5985
2024-08-03 04:16:25.661794: 
2024-08-03 04:16:25.663307: Epoch 8
2024-08-03 04:16:25.664415: Current learning rate: 0.00993
2024-08-03 04:20:36.252932: Validation loss did not improve from -0.43175. Patience: 2/50
2024-08-03 04:20:36.254413: train_loss -0.5016
2024-08-03 04:20:36.255603: val_loss -0.4096
2024-08-03 04:20:36.256767: Pseudo dice [0.6484]
2024-08-03 04:20:36.257889: Epoch time: 250.59 s
2024-08-03 04:20:36.258979: Yayy! New best EMA pseudo Dice: 0.6035
2024-08-03 04:20:38.540507: 
2024-08-03 04:20:38.542184: Epoch 9
2024-08-03 04:20:38.543398: Current learning rate: 0.00992
2024-08-03 04:25:05.729026: Validation loss did not improve from -0.43175. Patience: 3/50
2024-08-03 04:25:05.730548: train_loss -0.521
2024-08-03 04:25:05.731873: val_loss -0.4054
2024-08-03 04:25:05.732923: Pseudo dice [0.6661]
2024-08-03 04:25:05.734011: Epoch time: 267.19 s
2024-08-03 04:25:06.151223: Yayy! New best EMA pseudo Dice: 0.6097
2024-08-03 04:25:07.951696: 
2024-08-03 04:25:07.953654: Epoch 10
2024-08-03 04:25:07.954983: Current learning rate: 0.00991
2024-08-03 04:29:33.209196: Validation loss improved from -0.43175 to -0.43523! Patience: 3/50
2024-08-03 04:29:33.210619: train_loss -0.5396
2024-08-03 04:29:33.211987: val_loss -0.4352
2024-08-03 04:29:33.213177: Pseudo dice [0.6843]
2024-08-03 04:29:33.214648: Epoch time: 265.26 s
2024-08-03 04:29:33.215957: Yayy! New best EMA pseudo Dice: 0.6172
2024-08-03 04:29:34.975202: 
2024-08-03 04:29:34.977781: Epoch 11
2024-08-03 04:29:34.979569: Current learning rate: 0.0099
2024-08-03 04:34:05.217348: Validation loss did not improve from -0.43523. Patience: 1/50
2024-08-03 04:34:05.218689: train_loss -0.5336
2024-08-03 04:34:05.219726: val_loss -0.3984
2024-08-03 04:34:05.220671: Pseudo dice [0.6741]
2024-08-03 04:34:05.221801: Epoch time: 270.25 s
2024-08-03 04:34:05.222681: Yayy! New best EMA pseudo Dice: 0.6229
2024-08-03 04:34:07.004980: 
2024-08-03 04:34:07.006566: Epoch 12
2024-08-03 04:34:07.007610: Current learning rate: 0.00989
2024-08-03 04:38:45.484465: Validation loss did not improve from -0.43523. Patience: 2/50
2024-08-03 04:38:45.485980: train_loss -0.5387
2024-08-03 04:38:45.487227: val_loss -0.3997
2024-08-03 04:38:45.488340: Pseudo dice [0.6521]
2024-08-03 04:38:45.489401: Epoch time: 278.48 s
2024-08-03 04:38:45.490429: Yayy! New best EMA pseudo Dice: 0.6258
2024-08-03 04:38:47.242659: 
2024-08-03 04:38:47.243987: Epoch 13
2024-08-03 04:38:47.244922: Current learning rate: 0.00988
2024-08-03 04:43:45.233285: Validation loss did not improve from -0.43523. Patience: 3/50
2024-08-03 04:43:45.235439: train_loss -0.5473
2024-08-03 04:43:45.237006: val_loss -0.4297
2024-08-03 04:43:45.238223: Pseudo dice [0.6841]
2024-08-03 04:43:45.239290: Epoch time: 297.99 s
2024-08-03 04:43:45.240375: Yayy! New best EMA pseudo Dice: 0.6316
2024-08-03 04:43:47.007555: 
2024-08-03 04:43:47.009223: Epoch 14
2024-08-03 04:43:47.010437: Current learning rate: 0.00987
2024-08-03 04:48:38.444506: Validation loss did not improve from -0.43523. Patience: 4/50
2024-08-03 04:48:38.446476: train_loss -0.5691
2024-08-03 04:48:38.447768: val_loss -0.409
2024-08-03 04:48:38.448865: Pseudo dice [0.6783]
2024-08-03 04:48:38.449985: Epoch time: 291.44 s
2024-08-03 04:48:38.841363: Yayy! New best EMA pseudo Dice: 0.6363
2024-08-03 04:48:40.591614: 
2024-08-03 04:48:40.593915: Epoch 15
2024-08-03 04:48:40.595600: Current learning rate: 0.00986
2024-08-03 04:53:31.391223: Validation loss improved from -0.43523 to -0.44119! Patience: 4/50
2024-08-03 04:53:31.392712: train_loss -0.5697
2024-08-03 04:53:31.393959: val_loss -0.4412
2024-08-03 04:53:31.395316: Pseudo dice [0.6816]
2024-08-03 04:53:31.396574: Epoch time: 290.8 s
2024-08-03 04:53:31.397603: Yayy! New best EMA pseudo Dice: 0.6408
2024-08-03 04:53:33.160888: 
2024-08-03 04:53:33.162760: Epoch 16
2024-08-03 04:53:33.163811: Current learning rate: 0.00986
2024-08-03 04:58:40.706200: Validation loss did not improve from -0.44119. Patience: 1/50
2024-08-03 04:58:40.707952: train_loss -0.5719
2024-08-03 04:58:40.709825: val_loss -0.4281
2024-08-03 04:58:40.710962: Pseudo dice [0.6755]
2024-08-03 04:58:40.712111: Epoch time: 307.55 s
2024-08-03 04:58:40.713039: Yayy! New best EMA pseudo Dice: 0.6443
2024-08-03 04:58:42.518867: 
2024-08-03 04:58:42.520739: Epoch 17
2024-08-03 04:58:42.521888: Current learning rate: 0.00985
2024-08-03 05:03:43.233242: Validation loss did not improve from -0.44119. Patience: 2/50
2024-08-03 05:03:43.236081: train_loss -0.5922
2024-08-03 05:03:43.238313: val_loss -0.441
2024-08-03 05:03:43.239584: Pseudo dice [0.6722]
2024-08-03 05:03:43.241021: Epoch time: 300.72 s
2024-08-03 05:03:43.242142: Yayy! New best EMA pseudo Dice: 0.6471
2024-08-03 05:03:45.139981: 
2024-08-03 05:03:45.141923: Epoch 18
2024-08-03 05:03:45.143123: Current learning rate: 0.00984
2024-08-03 05:08:52.570496: Validation loss improved from -0.44119 to -0.45964! Patience: 2/50
2024-08-03 05:08:52.571864: train_loss -0.5917
2024-08-03 05:08:52.573045: val_loss -0.4596
2024-08-03 05:08:52.574045: Pseudo dice [0.7016]
2024-08-03 05:08:52.575018: Epoch time: 307.43 s
2024-08-03 05:08:52.575915: Yayy! New best EMA pseudo Dice: 0.6525
2024-08-03 05:08:54.375905: 
2024-08-03 05:08:54.377968: Epoch 19
2024-08-03 05:08:54.379044: Current learning rate: 0.00983
2024-08-03 05:14:02.970485: Validation loss did not improve from -0.45964. Patience: 1/50
2024-08-03 05:14:02.971923: train_loss -0.583
2024-08-03 05:14:02.973151: val_loss -0.448
2024-08-03 05:14:02.974262: Pseudo dice [0.694]
2024-08-03 05:14:02.975286: Epoch time: 308.6 s
2024-08-03 05:14:03.329956: Yayy! New best EMA pseudo Dice: 0.6567
2024-08-03 05:14:05.759593: 
2024-08-03 05:14:05.761437: Epoch 20
2024-08-03 05:14:05.762945: Current learning rate: 0.00982
2024-08-03 05:19:22.348259: Validation loss did not improve from -0.45964. Patience: 2/50
2024-08-03 05:19:22.349911: train_loss -0.6013
2024-08-03 05:19:22.350973: val_loss -0.3752
2024-08-03 05:19:22.351864: Pseudo dice [0.6403]
2024-08-03 05:19:22.352773: Epoch time: 316.59 s
2024-08-03 05:19:23.792480: 
2024-08-03 05:19:23.794851: Epoch 21
2024-08-03 05:19:23.796017: Current learning rate: 0.00981
2024-08-03 05:24:49.487321: Validation loss did not improve from -0.45964. Patience: 3/50
2024-08-03 05:24:49.488808: train_loss -0.6057
2024-08-03 05:24:49.489962: val_loss -0.4021
2024-08-03 05:24:49.491165: Pseudo dice [0.6637]
2024-08-03 05:24:49.492125: Epoch time: 325.7 s
2024-08-03 05:24:50.804808: 
2024-08-03 05:24:50.806472: Epoch 22
2024-08-03 05:24:50.807584: Current learning rate: 0.0098
2024-08-03 05:29:55.667914: Validation loss did not improve from -0.45964. Patience: 4/50
2024-08-03 05:29:55.669306: train_loss -0.6084
2024-08-03 05:29:55.670614: val_loss -0.4223
2024-08-03 05:29:55.671766: Pseudo dice [0.6719]
2024-08-03 05:29:55.672865: Epoch time: 304.87 s
2024-08-03 05:29:55.674227: Yayy! New best EMA pseudo Dice: 0.6575
2024-08-03 05:29:57.369022: 
2024-08-03 05:29:57.372516: Epoch 23
2024-08-03 05:29:57.374275: Current learning rate: 0.00979
2024-08-03 05:35:17.642523: Validation loss did not improve from -0.45964. Patience: 5/50
2024-08-03 05:35:17.643952: train_loss -0.6162
2024-08-03 05:35:17.644986: val_loss -0.4499
2024-08-03 05:35:17.645983: Pseudo dice [0.6833]
2024-08-03 05:35:17.647015: Epoch time: 320.28 s
2024-08-03 05:35:17.647933: Yayy! New best EMA pseudo Dice: 0.6601
2024-08-03 05:35:19.356085: 
2024-08-03 05:35:19.357682: Epoch 24
2024-08-03 05:35:19.358703: Current learning rate: 0.00978
2024-08-03 05:40:39.424686: Validation loss improved from -0.45964 to -0.47397! Patience: 5/50
2024-08-03 05:40:39.425959: train_loss -0.6148
2024-08-03 05:40:39.427063: val_loss -0.474
2024-08-03 05:40:39.428099: Pseudo dice [0.715]
2024-08-03 05:40:39.429160: Epoch time: 320.07 s
2024-08-03 05:40:39.819238: Yayy! New best EMA pseudo Dice: 0.6656
2024-08-03 05:40:41.548120: 
2024-08-03 05:40:41.549726: Epoch 25
2024-08-03 05:40:41.550739: Current learning rate: 0.00977
2024-08-03 05:45:52.325862: Validation loss did not improve from -0.47397. Patience: 1/50
2024-08-03 05:45:52.327127: train_loss -0.6147
2024-08-03 05:45:52.328190: val_loss -0.4262
2024-08-03 05:45:52.329147: Pseudo dice [0.6662]
2024-08-03 05:45:52.330058: Epoch time: 310.78 s
2024-08-03 05:45:52.330992: Yayy! New best EMA pseudo Dice: 0.6656
2024-08-03 05:45:54.025795: 
2024-08-03 05:45:54.027149: Epoch 26
2024-08-03 05:45:54.028136: Current learning rate: 0.00977
2024-08-03 05:51:04.871790: Validation loss did not improve from -0.47397. Patience: 2/50
2024-08-03 05:51:04.873220: train_loss -0.6246
2024-08-03 05:51:04.874375: val_loss -0.4615
2024-08-03 05:51:04.875359: Pseudo dice [0.6971]
2024-08-03 05:51:04.876449: Epoch time: 310.85 s
2024-08-03 05:51:04.877420: Yayy! New best EMA pseudo Dice: 0.6688
2024-08-03 05:51:06.599377: 
2024-08-03 05:51:06.600838: Epoch 27
2024-08-03 05:51:06.601846: Current learning rate: 0.00976
2024-08-03 05:56:38.851738: Validation loss did not improve from -0.47397. Patience: 3/50
2024-08-03 05:56:38.853325: train_loss -0.6261
2024-08-03 05:56:38.854472: val_loss -0.46
2024-08-03 05:56:38.855472: Pseudo dice [0.7091]
2024-08-03 05:56:38.856448: Epoch time: 332.26 s
2024-08-03 05:56:38.857395: Yayy! New best EMA pseudo Dice: 0.6728
2024-08-03 05:56:40.579472: 
2024-08-03 05:56:40.581131: Epoch 28
2024-08-03 05:56:40.582271: Current learning rate: 0.00975
2024-08-03 06:02:21.948072: Validation loss did not improve from -0.47397. Patience: 4/50
2024-08-03 06:02:21.949767: train_loss -0.6399
2024-08-03 06:02:21.951349: val_loss -0.4704
2024-08-03 06:02:21.952585: Pseudo dice [0.6914]
2024-08-03 06:02:21.953655: Epoch time: 341.37 s
2024-08-03 06:02:21.954785: Yayy! New best EMA pseudo Dice: 0.6747
2024-08-03 06:02:23.751049: 
2024-08-03 06:02:23.753758: Epoch 29
2024-08-03 06:02:23.755248: Current learning rate: 0.00974
2024-08-03 06:08:06.400353: Validation loss did not improve from -0.47397. Patience: 5/50
2024-08-03 06:08:06.403733: train_loss -0.6357
2024-08-03 06:08:06.406344: val_loss -0.4725
2024-08-03 06:08:06.407860: Pseudo dice [0.7052]
2024-08-03 06:08:06.409235: Epoch time: 342.65 s
2024-08-03 06:08:06.762341: Yayy! New best EMA pseudo Dice: 0.6777
2024-08-03 06:08:08.745786: 
2024-08-03 06:08:08.747357: Epoch 30
2024-08-03 06:08:08.748453: Current learning rate: 0.00973
2024-08-03 06:13:40.293232: Validation loss improved from -0.47397 to -0.49653! Patience: 5/50
2024-08-03 06:13:40.294677: train_loss -0.6457
2024-08-03 06:13:40.296223: val_loss -0.4965
2024-08-03 06:13:40.297712: Pseudo dice [0.7212]
2024-08-03 06:13:40.299089: Epoch time: 331.55 s
2024-08-03 06:13:40.300321: Yayy! New best EMA pseudo Dice: 0.6821
2024-08-03 06:13:42.073639: 
2024-08-03 06:13:42.075672: Epoch 31
2024-08-03 06:13:42.076957: Current learning rate: 0.00972
2024-08-03 06:19:14.793397: Validation loss did not improve from -0.49653. Patience: 1/50
2024-08-03 06:19:14.794574: train_loss -0.6592
2024-08-03 06:19:14.795732: val_loss -0.4549
2024-08-03 06:19:14.796848: Pseudo dice [0.6963]
2024-08-03 06:19:14.798105: Epoch time: 332.72 s
2024-08-03 06:19:14.799350: Yayy! New best EMA pseudo Dice: 0.6835
2024-08-03 06:19:17.121205: 
2024-08-03 06:19:17.122857: Epoch 32
2024-08-03 06:19:17.124077: Current learning rate: 0.00971
2024-08-03 06:24:51.930608: Validation loss did not improve from -0.49653. Patience: 2/50
2024-08-03 06:24:51.932075: train_loss -0.6525
2024-08-03 06:24:51.933246: val_loss -0.4136
2024-08-03 06:24:51.934279: Pseudo dice [0.6689]
2024-08-03 06:24:51.935315: Epoch time: 334.81 s
2024-08-03 06:24:53.320616: 
2024-08-03 06:24:53.321831: Epoch 33
2024-08-03 06:24:53.322734: Current learning rate: 0.0097
2024-08-03 06:30:25.874028: Validation loss did not improve from -0.49653. Patience: 3/50
2024-08-03 06:30:25.875396: train_loss -0.6476
2024-08-03 06:30:25.876613: val_loss -0.4646
2024-08-03 06:30:25.877764: Pseudo dice [0.6996]
2024-08-03 06:30:25.878952: Epoch time: 332.56 s
2024-08-03 06:30:25.880088: Yayy! New best EMA pseudo Dice: 0.6838
2024-08-03 06:30:27.634238: 
2024-08-03 06:30:27.636563: Epoch 34
2024-08-03 06:30:27.638287: Current learning rate: 0.00969
2024-08-03 06:36:11.188903: Validation loss improved from -0.49653 to -0.51018! Patience: 3/50
2024-08-03 06:36:11.190602: train_loss -0.6523
2024-08-03 06:36:11.191958: val_loss -0.5102
2024-08-03 06:36:11.193093: Pseudo dice [0.7148]
2024-08-03 06:36:11.194210: Epoch time: 343.56 s
2024-08-03 06:36:11.584164: Yayy! New best EMA pseudo Dice: 0.6869
2024-08-03 06:36:13.364290: 
2024-08-03 06:36:13.365992: Epoch 35
2024-08-03 06:36:13.367107: Current learning rate: 0.00968
2024-08-03 06:41:53.280321: Validation loss did not improve from -0.51018. Patience: 1/50
2024-08-03 06:41:53.281711: train_loss -0.6594
2024-08-03 06:41:53.283052: val_loss -0.4845
2024-08-03 06:41:53.284576: Pseudo dice [0.7232]
2024-08-03 06:41:53.285768: Epoch time: 339.92 s
2024-08-03 06:41:53.286912: Yayy! New best EMA pseudo Dice: 0.6905
2024-08-03 06:41:55.067026: 
2024-08-03 06:41:55.068954: Epoch 36
2024-08-03 06:41:55.070311: Current learning rate: 0.00968
2024-08-03 06:47:34.787567: Validation loss did not improve from -0.51018. Patience: 2/50
2024-08-03 06:47:34.788860: train_loss -0.6526
2024-08-03 06:47:34.789918: val_loss -0.4239
2024-08-03 06:47:34.790926: Pseudo dice [0.6801]
2024-08-03 06:47:34.791994: Epoch time: 339.72 s
2024-08-03 06:47:36.197877: 
2024-08-03 06:47:36.199418: Epoch 37
2024-08-03 06:47:36.201113: Current learning rate: 0.00967
2024-08-03 06:53:11.445681: Validation loss did not improve from -0.51018. Patience: 3/50
2024-08-03 06:53:11.447216: train_loss -0.6607
2024-08-03 06:53:11.448366: val_loss -0.4626
2024-08-03 06:53:11.449360: Pseudo dice [0.71]
2024-08-03 06:53:11.450315: Epoch time: 335.25 s
2024-08-03 06:53:11.451302: Yayy! New best EMA pseudo Dice: 0.6915
2024-08-03 06:53:13.241475: 
2024-08-03 06:53:13.243171: Epoch 38
2024-08-03 06:53:13.244134: Current learning rate: 0.00966
2024-08-03 06:56:00.962136: Validation loss did not improve from -0.51018. Patience: 4/50
2024-08-03 06:56:00.963677: train_loss -0.6687
2024-08-03 06:56:00.964989: val_loss -0.4713
2024-08-03 06:56:00.966012: Pseudo dice [0.6934]
2024-08-03 06:56:00.967155: Epoch time: 167.72 s
2024-08-03 06:56:00.968248: Yayy! New best EMA pseudo Dice: 0.6917
2024-08-03 06:56:02.874472: 
2024-08-03 06:56:02.876002: Epoch 39
2024-08-03 06:56:02.877079: Current learning rate: 0.00965
2024-08-03 06:58:47.990156: Validation loss did not improve from -0.51018. Patience: 5/50
2024-08-03 06:58:47.992080: train_loss -0.6646
2024-08-03 06:58:47.993438: val_loss -0.5057
2024-08-03 06:58:47.994513: Pseudo dice [0.7236]
2024-08-03 06:58:47.995524: Epoch time: 165.12 s
2024-08-03 06:58:48.398616: Yayy! New best EMA pseudo Dice: 0.6949
2024-08-03 06:58:50.234035: 
2024-08-03 06:58:50.235348: Epoch 40
2024-08-03 06:58:50.236573: Current learning rate: 0.00964
2024-08-03 07:01:12.248099: Validation loss did not improve from -0.51018. Patience: 6/50
2024-08-03 07:01:12.249567: train_loss -0.6765
2024-08-03 07:01:12.250995: val_loss -0.4844
2024-08-03 07:01:12.252199: Pseudo dice [0.7127]
2024-08-03 07:01:12.253456: Epoch time: 142.02 s
2024-08-03 07:01:12.255865: Yayy! New best EMA pseudo Dice: 0.6967
2024-08-03 07:01:14.098150: 
2024-08-03 07:01:14.099690: Epoch 41
2024-08-03 07:01:14.100871: Current learning rate: 0.00963
2024-08-03 07:03:33.448502: Validation loss did not improve from -0.51018. Patience: 7/50
2024-08-03 07:03:33.450144: train_loss -0.683
2024-08-03 07:03:33.451140: val_loss -0.4368
2024-08-03 07:03:33.452080: Pseudo dice [0.6994]
2024-08-03 07:03:33.453019: Epoch time: 139.35 s
2024-08-03 07:03:33.454049: Yayy! New best EMA pseudo Dice: 0.697
2024-08-03 07:03:35.217372: 
2024-08-03 07:03:35.218817: Epoch 42
2024-08-03 07:03:35.220019: Current learning rate: 0.00962
2024-08-03 07:06:05.610015: Validation loss did not improve from -0.51018. Patience: 8/50
2024-08-03 07:06:05.627227: train_loss -0.6732
2024-08-03 07:06:05.628711: val_loss -0.4122
2024-08-03 07:06:05.629694: Pseudo dice [0.6666]
2024-08-03 07:06:05.630739: Epoch time: 150.41 s
2024-08-03 07:06:07.409336: 
2024-08-03 07:06:07.411237: Epoch 43
2024-08-03 07:06:07.412263: Current learning rate: 0.00961
2024-08-03 07:08:33.449808: Validation loss improved from -0.51018 to -0.51612! Patience: 8/50
2024-08-03 07:08:33.453237: train_loss -0.6792
2024-08-03 07:08:33.454734: val_loss -0.5161
2024-08-03 07:08:33.456066: Pseudo dice [0.7321]
2024-08-03 07:08:33.457231: Epoch time: 146.04 s
2024-08-03 07:08:33.458222: Yayy! New best EMA pseudo Dice: 0.6977
2024-08-03 07:08:35.394043: 
2024-08-03 07:08:35.396158: Epoch 44
2024-08-03 07:08:35.397468: Current learning rate: 0.0096
2024-08-03 07:11:09.222990: Validation loss did not improve from -0.51612. Patience: 1/50
2024-08-03 07:11:09.225540: train_loss -0.6816
2024-08-03 07:11:09.228499: val_loss -0.474
2024-08-03 07:11:09.230304: Pseudo dice [0.7075]
2024-08-03 07:11:09.231794: Epoch time: 153.83 s
2024-08-03 07:11:09.597516: Yayy! New best EMA pseudo Dice: 0.6987
2024-08-03 07:11:11.346314: 
2024-08-03 07:11:11.347946: Epoch 45
2024-08-03 07:11:11.349077: Current learning rate: 0.00959
2024-08-03 07:13:41.690116: Validation loss did not improve from -0.51612. Patience: 2/50
2024-08-03 07:13:41.714142: train_loss -0.6806
2024-08-03 07:13:41.716239: val_loss -0.4195
2024-08-03 07:13:41.717606: Pseudo dice [0.6853]
2024-08-03 07:13:41.718950: Epoch time: 150.35 s
2024-08-03 07:13:43.084403: 
2024-08-03 07:13:43.086274: Epoch 46
2024-08-03 07:13:43.087769: Current learning rate: 0.00959
2024-08-03 07:16:12.248899: Validation loss did not improve from -0.51612. Patience: 3/50
2024-08-03 07:16:12.250242: train_loss -0.6872
2024-08-03 07:16:12.251300: val_loss -0.4457
2024-08-03 07:16:12.252303: Pseudo dice [0.6989]
2024-08-03 07:16:12.253308: Epoch time: 149.17 s
2024-08-03 07:16:13.533945: 
2024-08-03 07:16:13.535825: Epoch 47
2024-08-03 07:16:13.536908: Current learning rate: 0.00958
2024-08-03 07:18:43.276101: Validation loss did not improve from -0.51612. Patience: 4/50
2024-08-03 07:18:43.277670: train_loss -0.6856
2024-08-03 07:18:43.278933: val_loss -0.4435
2024-08-03 07:18:43.279938: Pseudo dice [0.6879]
2024-08-03 07:18:43.280852: Epoch time: 149.75 s
2024-08-03 07:18:44.631261: 
2024-08-03 07:18:44.632839: Epoch 48
2024-08-03 07:18:44.633892: Current learning rate: 0.00957
2024-08-03 07:21:19.088609: Validation loss did not improve from -0.51612. Patience: 5/50
2024-08-03 07:21:19.090125: train_loss -0.6827
2024-08-03 07:21:19.091380: val_loss -0.4636
2024-08-03 07:21:19.092455: Pseudo dice [0.7125]
2024-08-03 07:21:19.093687: Epoch time: 154.46 s
2024-08-03 07:21:20.471958: 
2024-08-03 07:21:20.473522: Epoch 49
2024-08-03 07:21:20.474702: Current learning rate: 0.00956
2024-08-03 07:23:50.884436: Validation loss did not improve from -0.51612. Patience: 6/50
2024-08-03 07:23:50.885743: train_loss -0.6866
2024-08-03 07:23:50.886819: val_loss -0.4464
2024-08-03 07:23:50.887852: Pseudo dice [0.6968]
2024-08-03 07:23:50.888878: Epoch time: 150.42 s
2024-08-03 07:23:52.756625: 
2024-08-03 07:23:52.758773: Epoch 50
2024-08-03 07:23:52.760075: Current learning rate: 0.00955
2024-08-03 07:26:24.025322: Validation loss did not improve from -0.51612. Patience: 7/50
2024-08-03 07:26:24.026820: train_loss -0.6955
2024-08-03 07:26:24.028086: val_loss -0.4269
2024-08-03 07:26:24.029226: Pseudo dice [0.6817]
2024-08-03 07:26:24.030282: Epoch time: 151.27 s
2024-08-03 07:26:25.355111: 
2024-08-03 07:26:25.356983: Epoch 51
2024-08-03 07:26:25.358217: Current learning rate: 0.00954
2024-08-03 07:28:55.236516: Validation loss did not improve from -0.51612. Patience: 8/50
2024-08-03 07:28:55.237996: train_loss -0.6981
2024-08-03 07:28:55.239142: val_loss -0.5029
2024-08-03 07:28:55.240385: Pseudo dice [0.7234]
2024-08-03 07:28:55.241643: Epoch time: 149.88 s
2024-08-03 07:28:55.242822: Yayy! New best EMA pseudo Dice: 0.6991
2024-08-03 07:28:57.045429: 
2024-08-03 07:28:57.047302: Epoch 52
2024-08-03 07:28:57.048613: Current learning rate: 0.00953
2024-08-03 07:31:29.809196: Validation loss did not improve from -0.51612. Patience: 9/50
2024-08-03 07:31:29.810840: train_loss -0.6926
2024-08-03 07:31:29.812143: val_loss -0.3874
2024-08-03 07:31:29.813432: Pseudo dice [0.6625]
2024-08-03 07:31:29.814489: Epoch time: 152.77 s
2024-08-03 07:31:31.209003: 
2024-08-03 07:31:31.210560: Epoch 53
2024-08-03 07:31:31.211714: Current learning rate: 0.00952
2024-08-03 07:34:08.423065: Validation loss did not improve from -0.51612. Patience: 10/50
2024-08-03 07:34:08.424899: train_loss -0.6897
2024-08-03 07:34:08.426324: val_loss -0.463
2024-08-03 07:34:08.427552: Pseudo dice [0.7083]
2024-08-03 07:34:08.428629: Epoch time: 157.22 s
2024-08-03 07:34:11.085546: 
2024-08-03 07:34:11.087962: Epoch 54
2024-08-03 07:34:11.089440: Current learning rate: 0.00951
2024-08-03 07:36:46.990846: Validation loss did not improve from -0.51612. Patience: 11/50
2024-08-03 07:36:46.992378: train_loss -0.6989
2024-08-03 07:36:46.993672: val_loss -0.4848
2024-08-03 07:36:46.994820: Pseudo dice [0.7137]
2024-08-03 07:36:46.995948: Epoch time: 155.91 s
2024-08-03 07:36:48.808747: 
2024-08-03 07:36:48.810248: Epoch 55
2024-08-03 07:36:48.811288: Current learning rate: 0.0095
2024-08-03 07:39:23.604225: Validation loss did not improve from -0.51612. Patience: 12/50
2024-08-03 07:39:23.605730: train_loss -0.6995
2024-08-03 07:39:23.606826: val_loss -0.4183
2024-08-03 07:39:23.607738: Pseudo dice [0.6932]
2024-08-03 07:39:23.608917: Epoch time: 154.8 s
2024-08-03 07:39:24.991544: 
2024-08-03 07:39:24.993612: Epoch 56
2024-08-03 07:39:24.994791: Current learning rate: 0.00949
2024-08-03 07:41:59.244026: Validation loss did not improve from -0.51612. Patience: 13/50
2024-08-03 07:41:59.245548: train_loss -0.7089
2024-08-03 07:41:59.246881: val_loss -0.4671
2024-08-03 07:41:59.247876: Pseudo dice [0.7122]
2024-08-03 07:41:59.248880: Epoch time: 154.26 s
2024-08-03 07:41:59.249842: Yayy! New best EMA pseudo Dice: 0.6993
2024-08-03 07:42:01.051806: 
2024-08-03 07:42:01.053296: Epoch 57
2024-08-03 07:42:01.054305: Current learning rate: 0.00949
2024-08-03 07:44:36.612272: Validation loss did not improve from -0.51612. Patience: 14/50
2024-08-03 07:44:36.613773: train_loss -0.7019
2024-08-03 07:44:36.615071: val_loss -0.4714
2024-08-03 07:44:36.616207: Pseudo dice [0.7103]
2024-08-03 07:44:36.617211: Epoch time: 155.56 s
2024-08-03 07:44:36.618271: Yayy! New best EMA pseudo Dice: 0.7004
2024-08-03 07:44:38.392875: 
2024-08-03 07:44:38.394613: Epoch 58
2024-08-03 07:44:38.395916: Current learning rate: 0.00948
2024-08-03 07:47:12.933785: Validation loss did not improve from -0.51612. Patience: 15/50
2024-08-03 07:47:12.935465: train_loss -0.7108
2024-08-03 07:47:12.937009: val_loss -0.5105
2024-08-03 07:47:12.938351: Pseudo dice [0.7362]
2024-08-03 07:47:12.939694: Epoch time: 154.54 s
2024-08-03 07:47:12.940786: Yayy! New best EMA pseudo Dice: 0.704
2024-08-03 07:47:14.758412: 
2024-08-03 07:47:14.760662: Epoch 59
2024-08-03 07:47:14.762046: Current learning rate: 0.00947
2024-08-03 07:49:49.791139: Validation loss did not improve from -0.51612. Patience: 16/50
2024-08-03 07:49:49.793045: train_loss -0.7074
2024-08-03 07:49:49.794213: val_loss -0.4579
2024-08-03 07:49:49.795188: Pseudo dice [0.7057]
2024-08-03 07:49:49.796071: Epoch time: 155.04 s
2024-08-03 07:49:50.205394: Yayy! New best EMA pseudo Dice: 0.7042
2024-08-03 07:49:51.970991: 
2024-08-03 07:49:51.972627: Epoch 60
2024-08-03 07:49:51.973678: Current learning rate: 0.00946
2024-08-03 07:52:29.894402: Validation loss did not improve from -0.51612. Patience: 17/50
2024-08-03 07:52:29.896969: train_loss -0.7095
2024-08-03 07:52:29.898695: val_loss -0.4686
2024-08-03 07:52:29.899843: Pseudo dice [0.7019]
2024-08-03 07:52:29.901005: Epoch time: 157.93 s
2024-08-03 07:52:31.252289: 
2024-08-03 07:52:31.254463: Epoch 61
2024-08-03 07:52:31.255539: Current learning rate: 0.00945
2024-08-03 07:55:10.713567: Validation loss did not improve from -0.51612. Patience: 18/50
2024-08-03 07:55:10.715061: train_loss -0.718
2024-08-03 07:55:10.716680: val_loss -0.4982
2024-08-03 07:55:10.717867: Pseudo dice [0.724]
2024-08-03 07:55:10.719142: Epoch time: 159.46 s
2024-08-03 07:55:10.720151: Yayy! New best EMA pseudo Dice: 0.7059
2024-08-03 07:55:12.496891: 
2024-08-03 07:55:12.499362: Epoch 62
2024-08-03 07:55:12.500698: Current learning rate: 0.00944
2024-08-03 07:57:46.380694: Validation loss did not improve from -0.51612. Patience: 19/50
2024-08-03 07:57:46.382105: train_loss -0.7133
2024-08-03 07:57:46.383236: val_loss -0.4828
2024-08-03 07:57:46.384291: Pseudo dice [0.715]
2024-08-03 07:57:46.385409: Epoch time: 153.89 s
2024-08-03 07:57:46.386403: Yayy! New best EMA pseudo Dice: 0.7068
2024-08-03 07:57:48.184940: 
2024-08-03 07:57:48.186603: Epoch 63
2024-08-03 07:57:48.194858: Current learning rate: 0.00943
2024-08-03 08:00:21.293866: Validation loss did not improve from -0.51612. Patience: 20/50
2024-08-03 08:00:21.295323: train_loss -0.7165
2024-08-03 08:00:21.296637: val_loss -0.5054
2024-08-03 08:00:21.297719: Pseudo dice [0.7213]
2024-08-03 08:00:21.298718: Epoch time: 153.11 s
2024-08-03 08:00:21.299596: Yayy! New best EMA pseudo Dice: 0.7083
2024-08-03 08:00:23.035670: 
2024-08-03 08:00:23.037445: Epoch 64
2024-08-03 08:00:23.038836: Current learning rate: 0.00942
2024-08-03 08:02:58.098513: Validation loss did not improve from -0.51612. Patience: 21/50
2024-08-03 08:02:58.100003: train_loss -0.7205
2024-08-03 08:02:58.101082: val_loss -0.508
2024-08-03 08:02:58.102055: Pseudo dice [0.7285]
2024-08-03 08:02:58.103011: Epoch time: 155.07 s
2024-08-03 08:02:58.506561: Yayy! New best EMA pseudo Dice: 0.7103
2024-08-03 08:03:00.735590: 
2024-08-03 08:03:00.737226: Epoch 65
2024-08-03 08:03:00.738274: Current learning rate: 0.00941
2024-08-03 08:05:35.467514: Validation loss did not improve from -0.51612. Patience: 22/50
2024-08-03 08:05:35.469202: train_loss -0.7166
2024-08-03 08:05:35.470513: val_loss -0.4597
2024-08-03 08:05:35.471865: Pseudo dice [0.7051]
2024-08-03 08:05:35.472846: Epoch time: 154.74 s
2024-08-03 08:05:36.823931: 
2024-08-03 08:05:36.825616: Epoch 66
2024-08-03 08:05:36.826785: Current learning rate: 0.0094
2024-08-03 08:08:08.741221: Validation loss did not improve from -0.51612. Patience: 23/50
2024-08-03 08:08:08.742763: train_loss -0.723
2024-08-03 08:08:08.744472: val_loss -0.4441
2024-08-03 08:08:08.745942: Pseudo dice [0.6821]
2024-08-03 08:08:08.747330: Epoch time: 151.92 s
2024-08-03 08:08:10.162283: 
2024-08-03 08:08:10.163988: Epoch 67
2024-08-03 08:08:10.165095: Current learning rate: 0.00939
2024-08-03 08:10:46.533345: Validation loss did not improve from -0.51612. Patience: 24/50
2024-08-03 08:10:46.536512: train_loss -0.7286
2024-08-03 08:10:46.537973: val_loss -0.3554
2024-08-03 08:10:46.539083: Pseudo dice [0.6379]
2024-08-03 08:10:46.540280: Epoch time: 156.38 s
2024-08-03 08:10:47.979059: 
2024-08-03 08:10:47.980811: Epoch 68
2024-08-03 08:10:47.982138: Current learning rate: 0.00939
2024-08-03 08:13:22.683013: Validation loss did not improve from -0.51612. Patience: 25/50
2024-08-03 08:13:22.685316: train_loss -0.7148
2024-08-03 08:13:22.686942: val_loss -0.4702
2024-08-03 08:13:22.688302: Pseudo dice [0.7106]
2024-08-03 08:13:22.689383: Epoch time: 154.71 s
2024-08-03 08:13:24.122439: 
2024-08-03 08:13:24.124311: Epoch 69
2024-08-03 08:13:24.125587: Current learning rate: 0.00938
2024-08-03 08:15:56.093701: Validation loss did not improve from -0.51612. Patience: 26/50
2024-08-03 08:15:56.095800: train_loss -0.7195
2024-08-03 08:15:56.097881: val_loss -0.4668
2024-08-03 08:15:56.099078: Pseudo dice [0.707]
2024-08-03 08:15:56.100378: Epoch time: 151.97 s
2024-08-03 08:15:57.969293: 
2024-08-03 08:15:57.970915: Epoch 70
2024-08-03 08:15:57.972104: Current learning rate: 0.00937
2024-08-03 08:18:29.408928: Validation loss did not improve from -0.51612. Patience: 27/50
2024-08-03 08:18:29.410814: train_loss -0.7219
2024-08-03 08:18:29.412241: val_loss -0.5037
2024-08-03 08:18:29.413465: Pseudo dice [0.7323]
2024-08-03 08:18:29.414688: Epoch time: 151.44 s
2024-08-03 08:18:30.812335: 
2024-08-03 08:18:30.814160: Epoch 71
2024-08-03 08:18:30.815265: Current learning rate: 0.00936
2024-08-03 08:21:02.584013: Validation loss did not improve from -0.51612. Patience: 28/50
2024-08-03 08:21:02.585629: train_loss -0.7277
2024-08-03 08:21:02.586748: val_loss -0.4714
2024-08-03 08:21:02.587676: Pseudo dice [0.6999]
2024-08-03 08:21:02.588750: Epoch time: 151.77 s
2024-08-03 08:21:04.006240: 
2024-08-03 08:21:04.007761: Epoch 72
2024-08-03 08:21:04.008708: Current learning rate: 0.00935
2024-08-03 08:23:45.708739: Validation loss did not improve from -0.51612. Patience: 29/50
2024-08-03 08:23:45.710505: train_loss -0.7359
2024-08-03 08:23:45.711816: val_loss -0.4711
2024-08-03 08:23:45.712993: Pseudo dice [0.7183]
2024-08-03 08:23:45.714152: Epoch time: 161.71 s
2024-08-03 08:23:47.053484: 
2024-08-03 08:23:47.055572: Epoch 73
2024-08-03 08:23:47.056737: Current learning rate: 0.00934
2024-08-03 08:26:21.548736: Validation loss did not improve from -0.51612. Patience: 30/50
2024-08-03 08:26:21.550333: train_loss -0.7244
2024-08-03 08:26:21.551623: val_loss -0.4718
2024-08-03 08:26:21.552649: Pseudo dice [0.7047]
2024-08-03 08:26:21.553942: Epoch time: 154.5 s
2024-08-03 08:26:22.992117: 
2024-08-03 08:26:22.993633: Epoch 74
2024-08-03 08:26:22.994653: Current learning rate: 0.00933
2024-08-03 08:28:59.307942: Validation loss did not improve from -0.51612. Patience: 31/50
2024-08-03 08:28:59.309487: train_loss -0.7265
2024-08-03 08:28:59.310562: val_loss -0.4577
2024-08-03 08:28:59.311601: Pseudo dice [0.6935]
2024-08-03 08:28:59.312633: Epoch time: 156.32 s
2024-08-03 08:29:01.146998: 
2024-08-03 08:29:01.148435: Epoch 75
2024-08-03 08:29:01.149479: Current learning rate: 0.00932
2024-08-03 08:31:35.191721: Validation loss did not improve from -0.51612. Patience: 32/50
2024-08-03 08:31:35.193273: train_loss -0.7316
2024-08-03 08:31:35.194461: val_loss -0.4499
2024-08-03 08:31:35.195468: Pseudo dice [0.6838]
2024-08-03 08:31:35.196528: Epoch time: 154.05 s
2024-08-03 08:31:37.079409: 
2024-08-03 08:31:37.080975: Epoch 76
2024-08-03 08:31:37.081976: Current learning rate: 0.00931
2024-08-03 08:34:08.439054: Validation loss did not improve from -0.51612. Patience: 33/50
2024-08-03 08:34:08.440559: train_loss -0.7343
2024-08-03 08:34:08.442199: val_loss -0.4959
2024-08-03 08:34:08.443384: Pseudo dice [0.7236]
2024-08-03 08:34:08.444660: Epoch time: 151.36 s
2024-08-03 08:34:09.894299: 
2024-08-03 08:34:09.895882: Epoch 77
2024-08-03 08:34:09.896983: Current learning rate: 0.0093
2024-08-03 08:36:46.320783: Validation loss did not improve from -0.51612. Patience: 34/50
2024-08-03 08:36:46.322303: train_loss -0.7421
2024-08-03 08:36:46.323696: val_loss -0.4912
2024-08-03 08:36:46.325005: Pseudo dice [0.7132]
2024-08-03 08:36:46.326183: Epoch time: 156.43 s
2024-08-03 08:36:47.789449: 
2024-08-03 08:36:47.791284: Epoch 78
2024-08-03 08:36:47.792785: Current learning rate: 0.0093
2024-08-03 08:39:23.016432: Validation loss did not improve from -0.51612. Patience: 35/50
2024-08-03 08:39:23.017914: train_loss -0.7384
2024-08-03 08:39:23.019132: val_loss -0.44
2024-08-03 08:39:23.020070: Pseudo dice [0.687]
2024-08-03 08:39:23.020975: Epoch time: 155.23 s
2024-08-03 08:39:24.467335: 
2024-08-03 08:39:24.469199: Epoch 79
2024-08-03 08:39:24.470341: Current learning rate: 0.00929
2024-08-03 08:42:01.457939: Validation loss did not improve from -0.51612. Patience: 36/50
2024-08-03 08:42:01.459553: train_loss -0.7407
2024-08-03 08:42:01.460758: val_loss -0.4631
2024-08-03 08:42:01.461694: Pseudo dice [0.7007]
2024-08-03 08:42:01.462764: Epoch time: 156.99 s
2024-08-03 08:42:03.287686: 
2024-08-03 08:42:03.289283: Epoch 80
2024-08-03 08:42:03.290681: Current learning rate: 0.00928
2024-08-03 08:44:35.689670: Validation loss improved from -0.51612 to -0.51845! Patience: 36/50
2024-08-03 08:44:35.691246: train_loss -0.7399
2024-08-03 08:44:35.692459: val_loss -0.5185
2024-08-03 08:44:35.693676: Pseudo dice [0.7319]
2024-08-03 08:44:35.694682: Epoch time: 152.4 s
2024-08-03 08:44:37.175098: 
2024-08-03 08:44:37.176902: Epoch 81
2024-08-03 08:44:37.177928: Current learning rate: 0.00927
2024-08-03 08:47:16.904198: Validation loss did not improve from -0.51845. Patience: 1/50
2024-08-03 08:47:16.905805: train_loss -0.7405
2024-08-03 08:47:16.907078: val_loss -0.4845
2024-08-03 08:47:16.908123: Pseudo dice [0.719]
2024-08-03 08:47:16.909369: Epoch time: 159.73 s
2024-08-03 08:47:18.372253: 
2024-08-03 08:47:18.373921: Epoch 82
2024-08-03 08:47:18.374938: Current learning rate: 0.00926
2024-08-03 08:49:52.267690: Validation loss did not improve from -0.51845. Patience: 2/50
2024-08-03 08:49:52.268948: train_loss -0.744
2024-08-03 08:49:52.270133: val_loss -0.4788
2024-08-03 08:49:52.271114: Pseudo dice [0.7173]
2024-08-03 08:49:52.272337: Epoch time: 153.9 s
2024-08-03 08:49:53.627399: 
2024-08-03 08:49:53.628845: Epoch 83
2024-08-03 08:49:53.629914: Current learning rate: 0.00925
2024-08-03 08:52:26.227249: Validation loss did not improve from -0.51845. Patience: 3/50
2024-08-03 08:52:26.228665: train_loss -0.7471
2024-08-03 08:52:26.229929: val_loss -0.4721
2024-08-03 08:52:26.230850: Pseudo dice [0.7081]
2024-08-03 08:52:26.231775: Epoch time: 152.6 s
2024-08-03 08:52:27.552277: 
2024-08-03 08:52:27.553733: Epoch 84
2024-08-03 08:52:27.554678: Current learning rate: 0.00924
2024-08-03 08:55:02.760309: Validation loss did not improve from -0.51845. Patience: 4/50
2024-08-03 08:55:02.761732: train_loss -0.7473
2024-08-03 08:55:02.763103: val_loss -0.5087
2024-08-03 08:55:02.764173: Pseudo dice [0.7315]
2024-08-03 08:55:02.765246: Epoch time: 155.21 s
2024-08-03 08:55:03.176193: Yayy! New best EMA pseudo Dice: 0.7107
2024-08-03 08:55:04.841192: 
2024-08-03 08:55:04.842967: Epoch 85
2024-08-03 08:55:04.844174: Current learning rate: 0.00923
2024-08-03 08:57:40.305061: Validation loss did not improve from -0.51845. Patience: 5/50
2024-08-03 08:57:40.306466: train_loss -0.7436
2024-08-03 08:57:40.307573: val_loss -0.4269
2024-08-03 08:57:40.308735: Pseudo dice [0.6857]
2024-08-03 08:57:40.309913: Epoch time: 155.47 s
2024-08-03 08:57:41.655363: 
2024-08-03 08:57:41.657187: Epoch 86
2024-08-03 08:57:41.658474: Current learning rate: 0.00922
2024-08-03 09:00:14.760191: Validation loss did not improve from -0.51845. Patience: 6/50
2024-08-03 09:00:14.761370: train_loss -0.7429
2024-08-03 09:00:14.762482: val_loss -0.5099
2024-08-03 09:00:14.763487: Pseudo dice [0.7291]
2024-08-03 09:00:14.764400: Epoch time: 153.11 s
2024-08-03 09:00:16.109543: 
2024-08-03 09:00:16.111134: Epoch 87
2024-08-03 09:00:16.112682: Current learning rate: 0.00921
2024-08-03 09:02:54.242205: Validation loss did not improve from -0.51845. Patience: 7/50
2024-08-03 09:02:54.244257: train_loss -0.7495
2024-08-03 09:02:54.245820: val_loss -0.4566
2024-08-03 09:02:54.246930: Pseudo dice [0.7131]
2024-08-03 09:02:54.247885: Epoch time: 158.14 s
2024-08-03 09:02:55.993244: 
2024-08-03 09:02:55.995061: Epoch 88
2024-08-03 09:02:55.996316: Current learning rate: 0.0092
2024-08-03 09:05:27.077168: Validation loss did not improve from -0.51845. Patience: 8/50
2024-08-03 09:05:27.078654: train_loss -0.7444
2024-08-03 09:05:27.079984: val_loss -0.4747
2024-08-03 09:05:27.080988: Pseudo dice [0.7218]
2024-08-03 09:05:27.081982: Epoch time: 151.09 s
2024-08-03 09:05:27.083014: Yayy! New best EMA pseudo Dice: 0.7117
2024-08-03 09:05:28.814919: 
2024-08-03 09:05:28.816709: Epoch 89
2024-08-03 09:05:28.818010: Current learning rate: 0.0092
2024-08-03 09:08:10.559906: Validation loss did not improve from -0.51845. Patience: 9/50
2024-08-03 09:08:10.561556: train_loss -0.7491
2024-08-03 09:08:10.563074: val_loss -0.4868
2024-08-03 09:08:10.564334: Pseudo dice [0.7211]
2024-08-03 09:08:10.565460: Epoch time: 161.75 s
2024-08-03 09:08:10.975103: Yayy! New best EMA pseudo Dice: 0.7126
2024-08-03 09:08:12.767118: 
2024-08-03 09:08:12.768249: Epoch 90
2024-08-03 09:08:12.769248: Current learning rate: 0.00919
2024-08-03 09:10:45.748853: Validation loss did not improve from -0.51845. Patience: 10/50
2024-08-03 09:10:45.750555: train_loss -0.748
2024-08-03 09:10:45.751977: val_loss -0.4373
2024-08-03 09:10:45.753035: Pseudo dice [0.6941]
2024-08-03 09:10:45.754278: Epoch time: 152.98 s
2024-08-03 09:10:47.115763: 
2024-08-03 09:10:47.117290: Epoch 91
2024-08-03 09:10:47.118368: Current learning rate: 0.00918
2024-08-03 09:13:20.574602: Validation loss did not improve from -0.51845. Patience: 11/50
2024-08-03 09:13:20.576176: train_loss -0.7517
2024-08-03 09:13:20.577568: val_loss -0.4271
2024-08-03 09:13:20.578797: Pseudo dice [0.6895]
2024-08-03 09:13:20.579998: Epoch time: 153.46 s
2024-08-03 09:13:21.952463: 
2024-08-03 09:13:21.954537: Epoch 92
2024-08-03 09:13:21.955945: Current learning rate: 0.00917
2024-08-03 09:15:57.785754: Validation loss did not improve from -0.51845. Patience: 12/50
2024-08-03 09:15:57.787725: train_loss -0.754
2024-08-03 09:15:57.789110: val_loss -0.4886
2024-08-03 09:15:57.790254: Pseudo dice [0.7302]
2024-08-03 09:15:57.791222: Epoch time: 155.84 s
2024-08-03 09:15:59.153321: 
2024-08-03 09:15:59.154946: Epoch 93
2024-08-03 09:15:59.156192: Current learning rate: 0.00916
2024-08-03 09:18:34.116725: Validation loss did not improve from -0.51845. Patience: 13/50
2024-08-03 09:18:34.118376: train_loss -0.7512
2024-08-03 09:18:34.119648: val_loss -0.489
2024-08-03 09:18:34.120718: Pseudo dice [0.7203]
2024-08-03 09:18:34.121659: Epoch time: 154.97 s
2024-08-03 09:18:35.480654: 
2024-08-03 09:18:35.482486: Epoch 94
2024-08-03 09:18:35.483519: Current learning rate: 0.00915
2024-08-03 09:21:14.801213: Validation loss did not improve from -0.51845. Patience: 14/50
2024-08-03 09:21:14.805069: train_loss -0.7489
2024-08-03 09:21:14.807670: val_loss -0.4633
2024-08-03 09:21:14.808978: Pseudo dice [0.7191]
2024-08-03 09:21:14.810513: Epoch time: 159.32 s
2024-08-03 09:21:16.508092: 
2024-08-03 09:21:16.509823: Epoch 95
2024-08-03 09:21:16.510838: Current learning rate: 0.00914
2024-08-03 09:23:53.119159: Validation loss improved from -0.51845 to -0.51978! Patience: 14/50
2024-08-03 09:23:53.120579: train_loss -0.7521
2024-08-03 09:23:53.122081: val_loss -0.5198
2024-08-03 09:23:53.123228: Pseudo dice [0.7371]
2024-08-03 09:23:53.124513: Epoch time: 156.61 s
2024-08-03 09:23:53.125763: Yayy! New best EMA pseudo Dice: 0.7149
2024-08-03 09:23:54.818900: 
2024-08-03 09:23:54.820723: Epoch 96
2024-08-03 09:23:54.822290: Current learning rate: 0.00913
2024-08-03 09:26:32.444691: Validation loss did not improve from -0.51978. Patience: 1/50
2024-08-03 09:26:32.446278: train_loss -0.7529
2024-08-03 09:26:32.449177: val_loss -0.5134
2024-08-03 09:26:32.451211: Pseudo dice [0.7301]
2024-08-03 09:26:32.452589: Epoch time: 157.63 s
2024-08-03 09:26:32.453693: Yayy! New best EMA pseudo Dice: 0.7164
2024-08-03 09:26:34.227795: 
2024-08-03 09:26:34.229727: Epoch 97
2024-08-03 09:26:34.230954: Current learning rate: 0.00912
2024-08-03 09:29:04.749827: Validation loss did not improve from -0.51978. Patience: 2/50
2024-08-03 09:29:04.751450: train_loss -0.7553
2024-08-03 09:29:04.752588: val_loss -0.4766
2024-08-03 09:29:04.753752: Pseudo dice [0.7099]
2024-08-03 09:29:04.754978: Epoch time: 150.52 s
2024-08-03 09:29:06.123972: 
2024-08-03 09:29:06.125481: Epoch 98
2024-08-03 09:29:06.126570: Current learning rate: 0.00911
2024-08-03 09:31:39.494355: Validation loss did not improve from -0.51978. Patience: 3/50
2024-08-03 09:31:39.495769: train_loss -0.7531
2024-08-03 09:31:39.496955: val_loss -0.4721
2024-08-03 09:31:39.498100: Pseudo dice [0.6934]
2024-08-03 09:31:39.499074: Epoch time: 153.37 s
2024-08-03 09:31:41.336267: 
2024-08-03 09:31:41.338356: Epoch 99
2024-08-03 09:31:41.339698: Current learning rate: 0.0091
2024-08-03 09:34:20.466039: Validation loss did not improve from -0.51978. Patience: 4/50
2024-08-03 09:34:20.467496: train_loss -0.7554
2024-08-03 09:34:20.468812: val_loss -0.4532
2024-08-03 09:34:20.470018: Pseudo dice [0.7155]
2024-08-03 09:34:20.471127: Epoch time: 159.13 s
2024-08-03 09:34:22.248163: 
2024-08-03 09:34:22.249894: Epoch 100
2024-08-03 09:34:22.250892: Current learning rate: 0.0091
2024-08-03 09:37:12.382220: Validation loss did not improve from -0.51978. Patience: 5/50
2024-08-03 09:37:12.383659: train_loss -0.758
2024-08-03 09:37:12.384791: val_loss -0.4573
2024-08-03 09:37:12.385911: Pseudo dice [0.6945]
2024-08-03 09:37:12.386830: Epoch time: 170.14 s
2024-08-03 09:37:13.722523: 
2024-08-03 09:37:13.724078: Epoch 101
2024-08-03 09:37:13.725111: Current learning rate: 0.00909
2024-08-03 09:39:54.015806: Validation loss did not improve from -0.51978. Patience: 6/50
2024-08-03 09:39:54.017523: train_loss -0.7598
2024-08-03 09:39:54.018955: val_loss -0.4795
2024-08-03 09:39:54.019976: Pseudo dice [0.7093]
2024-08-03 09:39:54.021116: Epoch time: 160.3 s
2024-08-03 09:39:55.388618: 
2024-08-03 09:39:55.390357: Epoch 102
2024-08-03 09:39:55.391342: Current learning rate: 0.00908
2024-08-03 09:42:34.608433: Validation loss did not improve from -0.51978. Patience: 7/50
2024-08-03 09:42:34.609885: train_loss -0.7632
2024-08-03 09:42:34.611141: val_loss -0.4326
2024-08-03 09:42:34.612304: Pseudo dice [0.6931]
2024-08-03 09:42:34.613496: Epoch time: 159.22 s
2024-08-03 09:42:36.015828: 
2024-08-03 09:42:36.017656: Epoch 103
2024-08-03 09:42:36.018780: Current learning rate: 0.00907
2024-08-03 09:45:14.493173: Validation loss did not improve from -0.51978. Patience: 8/50
2024-08-03 09:45:14.494932: train_loss -0.7646
2024-08-03 09:45:14.496469: val_loss -0.4843
2024-08-03 09:45:14.497672: Pseudo dice [0.7207]
2024-08-03 09:45:14.498969: Epoch time: 158.48 s
2024-08-03 09:45:15.885914: 
2024-08-03 09:45:15.888022: Epoch 104
2024-08-03 09:45:15.889176: Current learning rate: 0.00906
2024-08-03 09:47:53.050534: Validation loss did not improve from -0.51978. Patience: 9/50
2024-08-03 09:47:53.051823: train_loss -0.7595
2024-08-03 09:47:53.053227: val_loss -0.4623
2024-08-03 09:47:53.054519: Pseudo dice [0.6959]
2024-08-03 09:47:53.055844: Epoch time: 157.17 s
2024-08-03 09:47:54.845551: 
2024-08-03 09:47:54.847425: Epoch 105
2024-08-03 09:47:54.848754: Current learning rate: 0.00905
2024-08-03 09:50:29.926178: Validation loss did not improve from -0.51978. Patience: 10/50
2024-08-03 09:50:29.930904: train_loss -0.758
2024-08-03 09:50:29.932319: val_loss -0.4527
2024-08-03 09:50:29.933566: Pseudo dice [0.6995]
2024-08-03 09:50:29.934640: Epoch time: 155.09 s
2024-08-03 09:50:31.308764: 
2024-08-03 09:50:31.310333: Epoch 106
2024-08-03 09:50:31.311357: Current learning rate: 0.00904
2024-08-03 09:53:17.705776: Validation loss did not improve from -0.51978. Patience: 11/50
2024-08-03 09:53:17.707223: train_loss -0.7607
2024-08-03 09:53:17.708339: val_loss -0.5122
2024-08-03 09:53:17.709298: Pseudo dice [0.7299]
2024-08-03 09:53:17.710345: Epoch time: 166.4 s
2024-08-03 09:53:19.094128: 
2024-08-03 09:53:19.095625: Epoch 107
2024-08-03 09:53:19.096565: Current learning rate: 0.00903
2024-08-03 09:55:55.198337: Validation loss did not improve from -0.51978. Patience: 12/50
2024-08-03 09:55:55.199788: train_loss -0.759
2024-08-03 09:55:55.200934: val_loss -0.4699
2024-08-03 09:55:55.201887: Pseudo dice [0.7142]
2024-08-03 09:55:55.202914: Epoch time: 156.11 s
2024-08-03 09:55:56.583861: 
2024-08-03 09:55:56.585641: Epoch 108
2024-08-03 09:55:56.586694: Current learning rate: 0.00902
2024-08-03 09:58:42.047225: Validation loss did not improve from -0.51978. Patience: 13/50
2024-08-03 09:58:42.048795: train_loss -0.765
2024-08-03 09:58:42.050340: val_loss -0.4478
2024-08-03 09:58:42.051324: Pseudo dice [0.6972]
2024-08-03 09:58:42.052556: Epoch time: 165.47 s
2024-08-03 09:58:43.414416: 
2024-08-03 09:58:43.416293: Epoch 109
2024-08-03 09:58:43.417625: Current learning rate: 0.00901
2024-08-03 10:01:26.341343: Validation loss did not improve from -0.51978. Patience: 14/50
2024-08-03 10:01:26.342947: train_loss -0.7676
2024-08-03 10:01:26.344100: val_loss -0.4933
2024-08-03 10:01:26.345115: Pseudo dice [0.7203]
2024-08-03 10:01:26.346238: Epoch time: 162.93 s
2024-08-03 10:01:28.124144: 
2024-08-03 10:01:28.125624: Epoch 110
2024-08-03 10:01:28.126759: Current learning rate: 0.009
2024-08-03 10:04:03.810346: Validation loss did not improve from -0.51978. Patience: 15/50
2024-08-03 10:04:03.811721: train_loss -0.7645
2024-08-03 10:04:03.812863: val_loss -0.4374
2024-08-03 10:04:03.813927: Pseudo dice [0.6792]
2024-08-03 10:04:03.814984: Epoch time: 155.69 s
2024-08-03 10:04:05.969339: 
2024-08-03 10:04:05.971244: Epoch 111
2024-08-03 10:04:05.972382: Current learning rate: 0.009
2024-08-03 10:06:45.261680: Validation loss did not improve from -0.51978. Patience: 16/50
2024-08-03 10:06:45.263424: train_loss -0.7662
2024-08-03 10:06:45.264583: val_loss -0.5076
2024-08-03 10:06:45.265741: Pseudo dice [0.7318]
2024-08-03 10:06:45.266909: Epoch time: 159.3 s
2024-08-03 10:06:46.642744: 
2024-08-03 10:06:46.644284: Epoch 112
2024-08-03 10:06:46.645429: Current learning rate: 0.00899
2024-08-03 10:09:26.575927: Validation loss did not improve from -0.51978. Patience: 17/50
2024-08-03 10:09:26.577392: train_loss -0.7649
2024-08-03 10:09:26.578527: val_loss -0.4976
2024-08-03 10:09:26.579611: Pseudo dice [0.73]
2024-08-03 10:09:26.580776: Epoch time: 159.94 s
2024-08-03 10:09:27.971333: 
2024-08-03 10:09:27.973208: Epoch 113
2024-08-03 10:09:27.974408: Current learning rate: 0.00898
2024-08-03 10:12:13.743146: Validation loss did not improve from -0.51978. Patience: 18/50
2024-08-03 10:12:13.744617: train_loss -0.7651
2024-08-03 10:12:13.745786: val_loss -0.4841
2024-08-03 10:12:13.746783: Pseudo dice [0.706]
2024-08-03 10:12:13.747737: Epoch time: 165.77 s
2024-08-03 10:12:15.130575: 
2024-08-03 10:12:15.132620: Epoch 114
2024-08-03 10:12:15.133762: Current learning rate: 0.00897
2024-08-03 10:14:54.464688: Validation loss did not improve from -0.51978. Patience: 19/50
2024-08-03 10:14:54.466143: train_loss -0.7619
2024-08-03 10:14:54.467247: val_loss -0.4912
2024-08-03 10:14:54.468184: Pseudo dice [0.7248]
2024-08-03 10:14:54.469172: Epoch time: 159.34 s
2024-08-03 10:14:56.373807: 
2024-08-03 10:14:56.375264: Epoch 115
2024-08-03 10:14:56.376346: Current learning rate: 0.00896
2024-08-03 10:17:35.128454: Validation loss improved from -0.51978 to -0.52152! Patience: 19/50
2024-08-03 10:17:35.132196: train_loss -0.7634
2024-08-03 10:17:35.134151: val_loss -0.5215
2024-08-03 10:17:35.135353: Pseudo dice [0.7437]
2024-08-03 10:17:35.136522: Epoch time: 158.76 s
2024-08-03 10:17:36.551915: 
2024-08-03 10:17:36.553762: Epoch 116
2024-08-03 10:17:36.555056: Current learning rate: 0.00895
2024-08-03 10:20:12.320518: Validation loss did not improve from -0.52152. Patience: 1/50
2024-08-03 10:20:12.322349: train_loss -0.7649
2024-08-03 10:20:12.323496: val_loss -0.482
2024-08-03 10:20:12.324750: Pseudo dice [0.6973]
2024-08-03 10:20:12.326008: Epoch time: 155.77 s
2024-08-03 10:20:13.736118: 
2024-08-03 10:20:13.737680: Epoch 117
2024-08-03 10:20:13.738671: Current learning rate: 0.00894
2024-08-03 10:22:56.628329: Validation loss did not improve from -0.52152. Patience: 2/50
2024-08-03 10:22:56.629730: train_loss -0.7576
2024-08-03 10:22:56.630946: val_loss -0.4705
2024-08-03 10:22:56.631978: Pseudo dice [0.7174]
2024-08-03 10:22:56.633078: Epoch time: 162.89 s
2024-08-03 10:22:58.121796: 
2024-08-03 10:22:58.123568: Epoch 118
2024-08-03 10:22:58.124949: Current learning rate: 0.00893
2024-08-03 10:25:42.331038: Validation loss did not improve from -0.52152. Patience: 3/50
2024-08-03 10:25:42.333237: train_loss -0.7623
2024-08-03 10:25:42.335652: val_loss -0.4757
2024-08-03 10:25:42.336873: Pseudo dice [0.7133]
2024-08-03 10:25:42.338277: Epoch time: 164.21 s
2024-08-03 10:25:43.827691: 
2024-08-03 10:25:43.829383: Epoch 119
2024-08-03 10:25:43.830580: Current learning rate: 0.00892
2024-08-03 10:28:20.036385: Validation loss did not improve from -0.52152. Patience: 4/50
2024-08-03 10:28:20.039473: train_loss -0.7675
2024-08-03 10:28:20.041241: val_loss -0.4897
2024-08-03 10:28:20.042983: Pseudo dice [0.7298]
2024-08-03 10:28:20.044531: Epoch time: 156.21 s
2024-08-03 10:28:21.947908: 
2024-08-03 10:28:21.949445: Epoch 120
2024-08-03 10:28:21.950617: Current learning rate: 0.00891
2024-08-03 10:31:02.045709: Validation loss did not improve from -0.52152. Patience: 5/50
2024-08-03 10:31:02.047264: train_loss -0.7731
2024-08-03 10:31:02.048723: val_loss -0.5111
2024-08-03 10:31:02.050048: Pseudo dice [0.7374]
2024-08-03 10:31:02.051232: Epoch time: 160.1 s
2024-08-03 10:31:02.052287: Yayy! New best EMA pseudo Dice: 0.7179
2024-08-03 10:31:03.796308: 
2024-08-03 10:31:03.798413: Epoch 121
2024-08-03 10:31:03.799673: Current learning rate: 0.0089
2024-08-03 10:32:36.585731: Validation loss did not improve from -0.52152. Patience: 6/50
2024-08-03 10:32:36.587690: train_loss -0.7732
2024-08-03 10:32:36.589420: val_loss -0.5001
2024-08-03 10:32:36.591085: Pseudo dice [0.7364]
2024-08-03 10:32:36.592683: Epoch time: 92.79 s
2024-08-03 10:32:36.593661: Yayy! New best EMA pseudo Dice: 0.7198
2024-08-03 10:32:39.389206: 
2024-08-03 10:32:39.392645: Epoch 122
2024-08-03 10:32:39.394360: Current learning rate: 0.00889
2024-08-03 10:34:12.883047: Validation loss did not improve from -0.52152. Patience: 7/50
2024-08-03 10:34:12.884368: train_loss -0.7754
2024-08-03 10:34:12.885643: val_loss -0.4646
2024-08-03 10:34:12.886683: Pseudo dice [0.7079]
2024-08-03 10:34:12.887742: Epoch time: 93.5 s
2024-08-03 10:34:14.263381: 
2024-08-03 10:34:14.264959: Epoch 123
2024-08-03 10:34:14.265960: Current learning rate: 0.00889
2024-08-03 10:35:47.902037: Validation loss improved from -0.52152 to -0.52792! Patience: 7/50
2024-08-03 10:35:47.903727: train_loss -0.7699
2024-08-03 10:35:47.904968: val_loss -0.5279
2024-08-03 10:35:47.906122: Pseudo dice [0.7413]
2024-08-03 10:35:47.907361: Epoch time: 93.64 s
2024-08-03 10:35:47.908246: Yayy! New best EMA pseudo Dice: 0.7208
2024-08-03 10:35:49.645813: 
2024-08-03 10:35:49.647637: Epoch 124
2024-08-03 10:35:49.649041: Current learning rate: 0.00888
2024-08-03 10:37:23.756941: Validation loss did not improve from -0.52792. Patience: 1/50
2024-08-03 10:37:23.759091: train_loss -0.7726
2024-08-03 10:37:23.760476: val_loss -0.488
2024-08-03 10:37:23.761708: Pseudo dice [0.7297]
2024-08-03 10:37:23.762809: Epoch time: 94.11 s
2024-08-03 10:37:24.183643: Yayy! New best EMA pseudo Dice: 0.7217
2024-08-03 10:37:25.866645: 
2024-08-03 10:37:25.868432: Epoch 125
2024-08-03 10:37:25.869437: Current learning rate: 0.00887
2024-08-03 10:39:00.274973: Validation loss did not improve from -0.52792. Patience: 2/50
2024-08-03 10:39:00.276734: train_loss -0.7734
2024-08-03 10:39:00.278312: val_loss -0.4788
2024-08-03 10:39:00.279655: Pseudo dice [0.7145]
2024-08-03 10:39:00.281000: Epoch time: 94.41 s
2024-08-03 10:39:01.652251: 
2024-08-03 10:39:01.654820: Epoch 126
2024-08-03 10:39:01.656227: Current learning rate: 0.00886
2024-08-03 10:40:35.812059: Validation loss did not improve from -0.52792. Patience: 3/50
2024-08-03 10:40:35.813861: train_loss -0.7738
2024-08-03 10:40:35.815198: val_loss -0.4831
2024-08-03 10:40:35.816233: Pseudo dice [0.7273]
2024-08-03 10:40:35.817438: Epoch time: 94.16 s
2024-08-03 10:40:37.132501: 
2024-08-03 10:40:37.134610: Epoch 127
2024-08-03 10:40:37.135815: Current learning rate: 0.00885
2024-08-03 10:42:11.391415: Validation loss did not improve from -0.52792. Patience: 4/50
2024-08-03 10:42:11.393298: train_loss -0.7752
2024-08-03 10:42:11.394659: val_loss -0.4906
2024-08-03 10:42:11.395694: Pseudo dice [0.7129]
2024-08-03 10:42:11.396908: Epoch time: 94.26 s
2024-08-03 10:42:12.730009: 
2024-08-03 10:42:12.731703: Epoch 128
2024-08-03 10:42:12.732769: Current learning rate: 0.00884
2024-08-03 10:43:47.151336: Validation loss did not improve from -0.52792. Patience: 5/50
2024-08-03 10:43:47.153037: train_loss -0.7741
2024-08-03 10:43:47.154642: val_loss -0.5168
2024-08-03 10:43:47.155916: Pseudo dice [0.7361]
2024-08-03 10:43:47.157144: Epoch time: 94.42 s
2024-08-03 10:43:47.158345: Yayy! New best EMA pseudo Dice: 0.7223
2024-08-03 10:43:48.895808: 
2024-08-03 10:43:48.897751: Epoch 129
2024-08-03 10:43:48.899199: Current learning rate: 0.00883
2024-08-03 10:45:23.009499: Validation loss did not improve from -0.52792. Patience: 6/50
2024-08-03 10:45:23.011071: train_loss -0.7731
2024-08-03 10:45:23.012472: val_loss -0.4875
2024-08-03 10:45:23.013582: Pseudo dice [0.7198]
2024-08-03 10:45:23.014627: Epoch time: 94.12 s
2024-08-03 10:45:24.737442: 
2024-08-03 10:45:24.739880: Epoch 130
2024-08-03 10:45:24.741045: Current learning rate: 0.00882
2024-08-03 10:46:58.442661: Validation loss did not improve from -0.52792. Patience: 7/50
2024-08-03 10:46:58.444227: train_loss -0.7693
2024-08-03 10:46:58.445410: val_loss -0.516
2024-08-03 10:46:58.446361: Pseudo dice [0.7382]
2024-08-03 10:46:58.447392: Epoch time: 93.71 s
2024-08-03 10:46:58.448439: Yayy! New best EMA pseudo Dice: 0.7237
2024-08-03 10:47:00.136030: 
2024-08-03 10:47:00.137785: Epoch 131
2024-08-03 10:47:00.138884: Current learning rate: 0.00881
2024-08-03 10:48:34.336798: Validation loss did not improve from -0.52792. Patience: 8/50
2024-08-03 10:48:34.338284: train_loss -0.7763
2024-08-03 10:48:34.339341: val_loss -0.4969
2024-08-03 10:48:34.340349: Pseudo dice [0.731]
2024-08-03 10:48:34.341364: Epoch time: 94.2 s
2024-08-03 10:48:34.342249: Yayy! New best EMA pseudo Dice: 0.7244
2024-08-03 10:48:36.306900: 
2024-08-03 10:48:36.309382: Epoch 132
2024-08-03 10:48:36.311075: Current learning rate: 0.0088
2024-08-03 10:50:10.023526: Validation loss did not improve from -0.52792. Patience: 9/50
2024-08-03 10:50:10.025259: train_loss -0.7718
2024-08-03 10:50:10.026533: val_loss -0.4907
2024-08-03 10:50:10.027698: Pseudo dice [0.7331]
2024-08-03 10:50:10.028983: Epoch time: 93.72 s
2024-08-03 10:50:10.030016: Yayy! New best EMA pseudo Dice: 0.7253
2024-08-03 10:50:12.153214: 
2024-08-03 10:50:12.155205: Epoch 133
2024-08-03 10:50:12.156518: Current learning rate: 0.00879
2024-08-03 10:51:46.047910: Validation loss did not improve from -0.52792. Patience: 10/50
2024-08-03 10:51:46.049772: train_loss -0.7764
2024-08-03 10:51:46.050817: val_loss -0.4744
2024-08-03 10:51:46.051803: Pseudo dice [0.7167]
2024-08-03 10:51:46.055740: Epoch time: 93.9 s
2024-08-03 10:51:47.354259: 
2024-08-03 10:51:47.356666: Epoch 134
2024-08-03 10:51:47.357947: Current learning rate: 0.00879
2024-08-03 10:53:20.862066: Validation loss did not improve from -0.52792. Patience: 11/50
2024-08-03 10:53:20.863520: train_loss -0.7703
2024-08-03 10:53:20.864672: val_loss -0.4941
2024-08-03 10:53:20.865635: Pseudo dice [0.7262]
2024-08-03 10:53:20.866612: Epoch time: 93.51 s
2024-08-03 10:53:22.611794: 
2024-08-03 10:53:22.613701: Epoch 135
2024-08-03 10:53:22.614765: Current learning rate: 0.00878
2024-08-03 10:54:55.801193: Validation loss did not improve from -0.52792. Patience: 12/50
2024-08-03 10:54:55.802807: train_loss -0.7726
2024-08-03 10:54:55.803926: val_loss -0.5182
2024-08-03 10:54:55.804860: Pseudo dice [0.7394]
2024-08-03 10:54:55.805861: Epoch time: 93.19 s
2024-08-03 10:54:55.806793: Yayy! New best EMA pseudo Dice: 0.7261
2024-08-03 10:54:57.561846: 
2024-08-03 10:54:57.563767: Epoch 136
2024-08-03 10:54:57.564999: Current learning rate: 0.00877
2024-08-03 10:56:31.048424: Validation loss did not improve from -0.52792. Patience: 13/50
2024-08-03 10:56:31.050436: train_loss -0.7741
2024-08-03 10:56:31.052071: val_loss -0.4912
2024-08-03 10:56:31.053298: Pseudo dice [0.7206]
2024-08-03 10:56:31.054361: Epoch time: 93.49 s
2024-08-03 10:56:32.450015: 
2024-08-03 10:56:32.451628: Epoch 137
2024-08-03 10:56:32.452720: Current learning rate: 0.00876
2024-08-03 10:58:05.902047: Validation loss did not improve from -0.52792. Patience: 14/50
2024-08-03 10:58:05.903958: train_loss -0.7785
2024-08-03 10:58:05.905415: val_loss -0.4906
2024-08-03 10:58:05.906596: Pseudo dice [0.7212]
2024-08-03 10:58:05.907801: Epoch time: 93.46 s
2024-08-03 10:58:07.267414: 
2024-08-03 10:58:07.269784: Epoch 138
2024-08-03 10:58:07.271223: Current learning rate: 0.00875
2024-08-03 10:59:41.186869: Validation loss did not improve from -0.52792. Patience: 15/50
2024-08-03 10:59:41.188573: train_loss -0.774
2024-08-03 10:59:41.189945: val_loss -0.4824
2024-08-03 10:59:41.191171: Pseudo dice [0.7194]
2024-08-03 10:59:41.192281: Epoch time: 93.92 s
2024-08-03 10:59:42.526871: 
2024-08-03 10:59:42.528584: Epoch 139
2024-08-03 10:59:42.529683: Current learning rate: 0.00874
2024-08-03 11:01:16.528357: Validation loss did not improve from -0.52792. Patience: 16/50
2024-08-03 11:01:16.530179: train_loss -0.7825
2024-08-03 11:01:16.531330: val_loss -0.4849
2024-08-03 11:01:16.532349: Pseudo dice [0.7185]
2024-08-03 11:01:16.533322: Epoch time: 94.0 s
2024-08-03 11:01:18.258885: 
2024-08-03 11:01:18.260902: Epoch 140
2024-08-03 11:01:18.262024: Current learning rate: 0.00873
2024-08-03 11:02:52.029610: Validation loss did not improve from -0.52792. Patience: 17/50
2024-08-03 11:02:52.031077: train_loss -0.7823
2024-08-03 11:02:52.032206: val_loss -0.4663
2024-08-03 11:02:52.033130: Pseudo dice [0.704]
2024-08-03 11:02:52.033989: Epoch time: 93.77 s
2024-08-03 11:02:53.364959: 
2024-08-03 11:02:53.367306: Epoch 141
2024-08-03 11:02:53.368313: Current learning rate: 0.00872
2024-08-03 11:04:27.465437: Validation loss did not improve from -0.52792. Patience: 18/50
2024-08-03 11:04:27.467226: train_loss -0.7816
2024-08-03 11:04:27.468657: val_loss -0.5009
2024-08-03 11:04:27.469825: Pseudo dice [0.7327]
2024-08-03 11:04:27.471015: Epoch time: 94.1 s
2024-08-03 11:04:28.839496: 
2024-08-03 11:04:28.841148: Epoch 142
2024-08-03 11:04:28.842259: Current learning rate: 0.00871
2024-08-03 11:06:02.482964: Validation loss did not improve from -0.52792. Patience: 19/50
2024-08-03 11:06:02.484691: train_loss -0.7804
2024-08-03 11:06:02.486124: val_loss -0.4823
2024-08-03 11:06:02.487324: Pseudo dice [0.7198]
2024-08-03 11:06:02.488492: Epoch time: 93.65 s
2024-08-03 11:06:03.845462: 
2024-08-03 11:06:03.847209: Epoch 143
2024-08-03 11:06:03.848744: Current learning rate: 0.0087
2024-08-03 11:07:37.447952: Validation loss did not improve from -0.52792. Patience: 20/50
2024-08-03 11:07:37.449818: train_loss -0.7736
2024-08-03 11:07:37.451104: val_loss -0.4954
2024-08-03 11:07:37.452400: Pseudo dice [0.7285]
2024-08-03 11:07:37.453716: Epoch time: 93.61 s
2024-08-03 11:07:39.525468: 
2024-08-03 11:07:39.527287: Epoch 144
2024-08-03 11:07:39.528369: Current learning rate: 0.00869
2024-08-03 11:09:13.351895: Validation loss did not improve from -0.52792. Patience: 21/50
2024-08-03 11:09:13.353629: train_loss -0.7791
2024-08-03 11:09:13.355338: val_loss -0.4706
2024-08-03 11:09:13.356611: Pseudo dice [0.7031]
2024-08-03 11:09:13.357923: Epoch time: 93.83 s
2024-08-03 11:09:15.157901: 
2024-08-03 11:09:15.160481: Epoch 145
2024-08-03 11:09:15.162037: Current learning rate: 0.00868
2024-08-03 11:10:48.960703: Validation loss did not improve from -0.52792. Patience: 22/50
2024-08-03 11:10:48.962605: train_loss -0.7827
2024-08-03 11:10:48.964337: val_loss -0.4827
2024-08-03 11:10:48.965495: Pseudo dice [0.7236]
2024-08-03 11:10:48.966515: Epoch time: 93.81 s
2024-08-03 11:10:50.322406: 
2024-08-03 11:10:50.324548: Epoch 146
2024-08-03 11:10:50.325960: Current learning rate: 0.00868
2024-08-03 11:12:23.907295: Validation loss did not improve from -0.52792. Patience: 23/50
2024-08-03 11:12:23.908845: train_loss -0.7843
2024-08-03 11:12:23.909957: val_loss -0.5245
2024-08-03 11:12:23.910943: Pseudo dice [0.7381]
2024-08-03 11:12:23.911859: Epoch time: 93.59 s
2024-08-03 11:12:25.273646: 
2024-08-03 11:12:25.275563: Epoch 147
2024-08-03 11:12:25.276656: Current learning rate: 0.00867
2024-08-03 11:13:58.961021: Validation loss did not improve from -0.52792. Patience: 24/50
2024-08-03 11:13:58.962757: train_loss -0.7879
2024-08-03 11:13:58.964314: val_loss -0.4994
2024-08-03 11:13:58.965488: Pseudo dice [0.7379]
2024-08-03 11:13:58.966656: Epoch time: 93.69 s
2024-08-03 11:14:00.321917: 
2024-08-03 11:14:00.323989: Epoch 148
2024-08-03 11:14:00.325202: Current learning rate: 0.00866
2024-08-03 11:15:33.823915: Validation loss did not improve from -0.52792. Patience: 25/50
2024-08-03 11:15:33.825874: train_loss -0.7877
2024-08-03 11:15:33.827202: val_loss -0.4683
2024-08-03 11:15:33.828273: Pseudo dice [0.7161]
2024-08-03 11:15:33.829346: Epoch time: 93.51 s
2024-08-03 11:15:35.262111: 
2024-08-03 11:15:35.263960: Epoch 149
2024-08-03 11:15:35.265079: Current learning rate: 0.00865
2024-08-03 11:17:08.688367: Validation loss did not improve from -0.52792. Patience: 26/50
2024-08-03 11:17:08.690195: train_loss -0.792
2024-08-03 11:17:08.691784: val_loss -0.472
2024-08-03 11:17:08.692972: Pseudo dice [0.7208]
2024-08-03 11:17:08.694254: Epoch time: 93.43 s
2024-08-03 11:17:10.543211: 
2024-08-03 11:17:10.546141: Epoch 150
2024-08-03 11:17:10.547888: Current learning rate: 0.00864
2024-08-03 11:18:44.686099: Validation loss did not improve from -0.52792. Patience: 27/50
2024-08-03 11:18:44.687824: train_loss -0.7884
2024-08-03 11:18:44.689301: val_loss -0.4092
2024-08-03 11:18:44.690451: Pseudo dice [0.6873]
2024-08-03 11:18:44.691576: Epoch time: 94.15 s
2024-08-03 11:18:46.050984: 
2024-08-03 11:18:46.053179: Epoch 151
2024-08-03 11:18:46.054578: Current learning rate: 0.00863
2024-08-03 11:20:19.250566: Validation loss did not improve from -0.52792. Patience: 28/50
2024-08-03 11:20:19.252475: train_loss -0.7907
2024-08-03 11:20:19.254035: val_loss -0.4955
2024-08-03 11:20:19.255413: Pseudo dice [0.7236]
2024-08-03 11:20:19.256870: Epoch time: 93.2 s
2024-08-03 11:20:20.630671: 
2024-08-03 11:20:20.632334: Epoch 152
2024-08-03 11:20:20.633736: Current learning rate: 0.00862
2024-08-03 11:21:54.184653: Validation loss did not improve from -0.52792. Patience: 29/50
2024-08-03 11:21:54.186663: train_loss -0.786
2024-08-03 11:21:54.188211: val_loss -0.5064
2024-08-03 11:21:54.190835: Pseudo dice [0.7385]
2024-08-03 11:21:54.192958: Epoch time: 93.56 s
2024-08-03 11:21:55.530243: 
2024-08-03 11:21:55.532115: Epoch 153
2024-08-03 11:21:55.533258: Current learning rate: 0.00861
2024-08-03 11:23:29.339250: Validation loss did not improve from -0.52792. Patience: 30/50
2024-08-03 11:23:29.341100: train_loss -0.7883
2024-08-03 11:23:29.343067: val_loss -0.5089
2024-08-03 11:23:29.344293: Pseudo dice [0.7293]
2024-08-03 11:23:29.345437: Epoch time: 93.81 s
2024-08-03 11:23:30.730283: 
2024-08-03 11:23:30.732435: Epoch 154
2024-08-03 11:23:30.733915: Current learning rate: 0.0086
2024-08-03 11:25:04.887701: Validation loss did not improve from -0.52792. Patience: 31/50
2024-08-03 11:25:04.901043: train_loss -0.7863
2024-08-03 11:25:04.903036: val_loss -0.5035
2024-08-03 11:25:04.904378: Pseudo dice [0.7348]
2024-08-03 11:25:04.905694: Epoch time: 94.17 s
2024-08-03 11:25:07.413799: 
2024-08-03 11:25:07.416347: Epoch 155
2024-08-03 11:25:07.417977: Current learning rate: 0.00859
2024-08-03 11:26:41.135860: Validation loss did not improve from -0.52792. Patience: 32/50
2024-08-03 11:26:41.137980: train_loss -0.7786
2024-08-03 11:26:41.139302: val_loss -0.4789
2024-08-03 11:26:41.140511: Pseudo dice [0.7016]
2024-08-03 11:26:41.141585: Epoch time: 93.73 s
2024-08-03 11:26:42.532402: 
2024-08-03 11:26:42.534102: Epoch 156
2024-08-03 11:26:42.535312: Current learning rate: 0.00858
2024-08-03 11:28:17.507040: Validation loss did not improve from -0.52792. Patience: 33/50
2024-08-03 11:28:17.508881: train_loss -0.786
2024-08-03 11:28:17.510371: val_loss -0.5206
2024-08-03 11:28:17.511646: Pseudo dice [0.7421]
2024-08-03 11:28:17.513034: Epoch time: 94.98 s
2024-08-03 11:28:19.007200: 
2024-08-03 11:28:19.009186: Epoch 157
2024-08-03 11:28:19.010407: Current learning rate: 0.00858
2024-08-03 11:29:53.118788: Validation loss did not improve from -0.52792. Patience: 34/50
2024-08-03 11:29:53.120749: train_loss -0.7842
2024-08-03 11:29:53.122288: val_loss -0.4273
2024-08-03 11:29:53.123591: Pseudo dice [0.6992]
2024-08-03 11:29:53.124719: Epoch time: 94.11 s
2024-08-03 11:29:54.621897: 
2024-08-03 11:29:54.624065: Epoch 158
2024-08-03 11:29:54.625387: Current learning rate: 0.00857
2024-08-03 11:31:28.875976: Validation loss did not improve from -0.52792. Patience: 35/50
2024-08-03 11:31:28.878707: train_loss -0.7873
2024-08-03 11:31:28.881820: val_loss -0.433
2024-08-03 11:31:28.883282: Pseudo dice [0.6981]
2024-08-03 11:31:28.884873: Epoch time: 94.26 s
2024-08-03 11:31:30.563276: 
2024-08-03 11:31:30.565178: Epoch 159
2024-08-03 11:31:30.566214: Current learning rate: 0.00856
2024-08-03 11:33:04.949657: Validation loss did not improve from -0.52792. Patience: 36/50
2024-08-03 11:33:04.951264: train_loss -0.7867
2024-08-03 11:33:04.952480: val_loss -0.5075
2024-08-03 11:33:04.953639: Pseudo dice [0.7352]
2024-08-03 11:33:04.954672: Epoch time: 94.39 s
2024-08-03 11:33:06.891633: 
2024-08-03 11:33:06.893897: Epoch 160
2024-08-03 11:33:06.895777: Current learning rate: 0.00855
2024-08-03 11:34:41.236808: Validation loss improved from -0.52792 to -0.53183! Patience: 36/50
2024-08-03 11:34:41.238665: train_loss -0.7898
2024-08-03 11:34:41.240126: val_loss -0.5318
2024-08-03 11:34:41.241609: Pseudo dice [0.739]
2024-08-03 11:34:41.242891: Epoch time: 94.35 s
2024-08-03 11:34:42.676261: 
2024-08-03 11:34:42.678467: Epoch 161
2024-08-03 11:34:42.680011: Current learning rate: 0.00854
2024-08-03 11:36:12.864247: Validation loss did not improve from -0.53183. Patience: 1/50
2024-08-03 11:36:12.866535: train_loss -0.7943
2024-08-03 11:36:12.868119: val_loss -0.516
2024-08-03 11:36:12.869251: Pseudo dice [0.736]
2024-08-03 11:36:12.870559: Epoch time: 90.19 s
2024-08-03 11:36:14.149646: 
2024-08-03 11:36:14.152315: Epoch 162
2024-08-03 11:36:14.154384: Current learning rate: 0.00853
2024-08-03 11:37:44.198154: Validation loss did not improve from -0.53183. Patience: 2/50
2024-08-03 11:37:44.200481: train_loss -0.7886
2024-08-03 11:37:44.202282: val_loss -0.4807
2024-08-03 11:37:44.203616: Pseudo dice [0.7267]
2024-08-03 11:37:44.205107: Epoch time: 90.05 s
2024-08-03 11:37:45.533862: 
2024-08-03 11:37:45.536833: Epoch 163
2024-08-03 11:37:45.538541: Current learning rate: 0.00852
2024-08-03 11:39:15.261285: Validation loss did not improve from -0.53183. Patience: 3/50
2024-08-03 11:39:15.263093: train_loss -0.7968
2024-08-03 11:39:15.264515: val_loss -0.4651
2024-08-03 11:39:15.265633: Pseudo dice [0.7117]
2024-08-03 11:39:15.266628: Epoch time: 89.73 s
2024-08-03 11:39:16.566418: 
2024-08-03 11:39:16.569580: Epoch 164
2024-08-03 11:39:16.571410: Current learning rate: 0.00851
2024-08-03 11:40:46.182503: Validation loss did not improve from -0.53183. Patience: 4/50
2024-08-03 11:40:46.183738: train_loss -0.7938
2024-08-03 11:40:46.184907: val_loss -0.4759
2024-08-03 11:40:46.186072: Pseudo dice [0.7183]
2024-08-03 11:40:46.186978: Epoch time: 89.62 s
2024-08-03 11:40:47.863372: 
2024-08-03 11:40:47.865953: Epoch 165
2024-08-03 11:40:47.867543: Current learning rate: 0.0085
2024-08-03 11:42:17.558824: Validation loss did not improve from -0.53183. Patience: 5/50
2024-08-03 11:42:17.586228: train_loss -0.7946
2024-08-03 11:42:17.588477: val_loss -0.4372
2024-08-03 11:42:17.589765: Pseudo dice [0.7071]
2024-08-03 11:42:17.591088: Epoch time: 89.7 s
2024-08-03 11:42:20.261709: 
2024-08-03 11:42:20.263999: Epoch 166
2024-08-03 11:42:20.265631: Current learning rate: 0.00849
2024-08-03 11:43:50.113350: Validation loss did not improve from -0.53183. Patience: 6/50
2024-08-03 11:43:50.115202: train_loss -0.7922
2024-08-03 11:43:50.116673: val_loss -0.4539
2024-08-03 11:43:50.117601: Pseudo dice [0.7089]
2024-08-03 11:43:50.118711: Epoch time: 89.85 s
2024-08-03 11:43:51.361647: 
2024-08-03 11:43:51.363678: Epoch 167
2024-08-03 11:43:51.364879: Current learning rate: 0.00848
2024-08-03 11:45:21.368187: Validation loss did not improve from -0.53183. Patience: 7/50
2024-08-03 11:45:21.370305: train_loss -0.7925
2024-08-03 11:45:21.372083: val_loss -0.501
2024-08-03 11:45:21.373367: Pseudo dice [0.7372]
2024-08-03 11:45:21.374422: Epoch time: 90.01 s
2024-08-03 11:45:22.656217: 
2024-08-03 11:45:22.658512: Epoch 168
2024-08-03 11:45:22.659570: Current learning rate: 0.00847
2024-08-03 11:46:52.379739: Validation loss did not improve from -0.53183. Patience: 8/50
2024-08-03 11:46:52.381305: train_loss -0.7915
2024-08-03 11:46:52.382969: val_loss -0.462
2024-08-03 11:46:52.384036: Pseudo dice [0.7088]
2024-08-03 11:46:52.385229: Epoch time: 89.73 s
2024-08-03 11:46:53.657341: 
2024-08-03 11:46:53.659897: Epoch 169
2024-08-03 11:46:53.661805: Current learning rate: 0.00847
2024-08-03 11:48:23.356934: Validation loss did not improve from -0.53183. Patience: 9/50
2024-08-03 11:48:23.358576: train_loss -0.7921
2024-08-03 11:48:23.360497: val_loss -0.4789
2024-08-03 11:48:23.361859: Pseudo dice [0.7158]
2024-08-03 11:48:23.363091: Epoch time: 89.7 s
2024-08-03 11:48:24.995426: 
2024-08-03 11:48:24.998267: Epoch 170
2024-08-03 11:48:25.000355: Current learning rate: 0.00846
2024-08-03 11:49:54.663539: Validation loss did not improve from -0.53183. Patience: 10/50
2024-08-03 11:49:54.665434: train_loss -0.7883
2024-08-03 11:49:54.667421: val_loss -0.4849
2024-08-03 11:49:54.668759: Pseudo dice [0.7216]
2024-08-03 11:49:54.670336: Epoch time: 89.67 s
2024-08-03 11:49:55.969534: 
2024-08-03 11:49:55.972007: Epoch 171
2024-08-03 11:49:55.973707: Current learning rate: 0.00845
2024-08-03 11:51:25.570365: Validation loss did not improve from -0.53183. Patience: 11/50
2024-08-03 11:51:25.572149: train_loss -0.7885
2024-08-03 11:51:25.575705: val_loss -0.4622
2024-08-03 11:51:25.577825: Pseudo dice [0.7159]
2024-08-03 11:51:25.579392: Epoch time: 89.6 s
2024-08-03 11:51:26.888299: 
2024-08-03 11:51:26.891295: Epoch 172
2024-08-03 11:51:26.893789: Current learning rate: 0.00844
2024-08-03 11:52:56.529605: Validation loss did not improve from -0.53183. Patience: 12/50
2024-08-03 11:52:56.531238: train_loss -0.7864
2024-08-03 11:52:56.533111: val_loss -0.4632
2024-08-03 11:52:56.534597: Pseudo dice [0.7176]
2024-08-03 11:52:56.535785: Epoch time: 89.64 s
2024-08-03 11:52:57.841346: 
2024-08-03 11:52:57.843873: Epoch 173
2024-08-03 11:52:57.846562: Current learning rate: 0.00843
2024-08-03 11:54:27.815633: Validation loss did not improve from -0.53183. Patience: 13/50
2024-08-03 11:54:27.817369: train_loss -0.7948
2024-08-03 11:54:27.818801: val_loss -0.4022
2024-08-03 11:54:27.819913: Pseudo dice [0.6748]
2024-08-03 11:54:27.820996: Epoch time: 89.98 s
2024-08-03 11:54:29.068500: 
2024-08-03 11:54:29.070837: Epoch 174
2024-08-03 11:54:29.072067: Current learning rate: 0.00842
2024-08-03 11:55:59.077287: Validation loss did not improve from -0.53183. Patience: 14/50
2024-08-03 11:55:59.079290: train_loss -0.7952
2024-08-03 11:55:59.081094: val_loss -0.5237
2024-08-03 11:55:59.082336: Pseudo dice [0.7431]
2024-08-03 11:55:59.083612: Epoch time: 90.01 s
2024-08-03 11:56:00.761623: 
2024-08-03 11:56:00.765244: Epoch 175
2024-08-03 11:56:00.767938: Current learning rate: 0.00841
2024-08-03 11:57:30.799734: Validation loss did not improve from -0.53183. Patience: 15/50
2024-08-03 11:57:30.801720: train_loss -0.7955
2024-08-03 11:57:30.803218: val_loss -0.4159
2024-08-03 11:57:30.804347: Pseudo dice [0.68]
2024-08-03 11:57:30.805543: Epoch time: 90.04 s
2024-08-03 11:57:32.105695: 
2024-08-03 11:57:32.108473: Epoch 176
2024-08-03 11:57:32.109925: Current learning rate: 0.0084
2024-08-03 11:59:02.238930: Validation loss did not improve from -0.53183. Patience: 16/50
2024-08-03 11:59:02.240293: train_loss -0.7945
2024-08-03 11:59:02.241692: val_loss -0.485
2024-08-03 11:59:02.243456: Pseudo dice [0.7194]
2024-08-03 11:59:02.244673: Epoch time: 90.14 s
2024-08-03 11:59:04.065889: 
2024-08-03 11:59:04.068670: Epoch 177
2024-08-03 11:59:04.070972: Current learning rate: 0.00839
2024-08-03 12:00:34.172815: Validation loss did not improve from -0.53183. Patience: 17/50
2024-08-03 12:00:34.174423: train_loss -0.7918
2024-08-03 12:00:34.175625: val_loss -0.4549
2024-08-03 12:00:34.176662: Pseudo dice [0.7161]
2024-08-03 12:00:34.177807: Epoch time: 90.11 s
2024-08-03 12:00:35.454144: 
2024-08-03 12:00:35.456332: Epoch 178
2024-08-03 12:00:35.457680: Current learning rate: 0.00838
2024-08-03 12:02:05.515489: Validation loss did not improve from -0.53183. Patience: 18/50
2024-08-03 12:02:05.517500: train_loss -0.7959
2024-08-03 12:02:05.519495: val_loss -0.4835
2024-08-03 12:02:05.520795: Pseudo dice [0.7284]
2024-08-03 12:02:05.521998: Epoch time: 90.06 s
2024-08-03 12:02:06.809246: 
2024-08-03 12:02:06.811778: Epoch 179
2024-08-03 12:02:06.814050: Current learning rate: 0.00837
2024-08-03 12:03:36.765412: Validation loss did not improve from -0.53183. Patience: 19/50
2024-08-03 12:03:36.767165: train_loss -0.7933
2024-08-03 12:03:36.768308: val_loss -0.4312
2024-08-03 12:03:36.769436: Pseudo dice [0.702]
2024-08-03 12:03:36.770673: Epoch time: 89.96 s
2024-08-03 12:03:38.456846: 
2024-08-03 12:03:38.459526: Epoch 180
2024-08-03 12:03:38.460858: Current learning rate: 0.00836
2024-08-03 12:05:08.445721: Validation loss did not improve from -0.53183. Patience: 20/50
2024-08-03 12:05:08.447145: train_loss -0.7931
2024-08-03 12:05:08.448378: val_loss -0.4848
2024-08-03 12:05:08.449679: Pseudo dice [0.7235]
2024-08-03 12:05:08.451116: Epoch time: 89.99 s
2024-08-03 12:05:09.767039: 
2024-08-03 12:05:09.769514: Epoch 181
2024-08-03 12:05:09.771316: Current learning rate: 0.00836
2024-08-03 12:06:40.096687: Validation loss did not improve from -0.53183. Patience: 21/50
2024-08-03 12:06:40.099157: train_loss -0.7914
2024-08-03 12:06:40.101161: val_loss -0.5064
2024-08-03 12:06:40.102693: Pseudo dice [0.75]
2024-08-03 12:06:40.103991: Epoch time: 90.33 s
2024-08-03 12:06:41.389047: 
2024-08-03 12:06:41.391445: Epoch 182
2024-08-03 12:06:41.393048: Current learning rate: 0.00835
2024-08-03 12:08:11.533853: Validation loss did not improve from -0.53183. Patience: 22/50
2024-08-03 12:08:11.535620: train_loss -0.7947
2024-08-03 12:08:11.537010: val_loss -0.4539
2024-08-03 12:08:11.538364: Pseudo dice [0.7164]
2024-08-03 12:08:11.539981: Epoch time: 90.15 s
2024-08-03 12:08:12.782533: 
2024-08-03 12:08:12.785182: Epoch 183
2024-08-03 12:08:12.786683: Current learning rate: 0.00834
2024-08-03 12:09:42.770509: Validation loss did not improve from -0.53183. Patience: 23/50
2024-08-03 12:09:42.772812: train_loss -0.7979
2024-08-03 12:09:42.774774: val_loss -0.482
2024-08-03 12:09:42.776136: Pseudo dice [0.7357]
2024-08-03 12:09:42.777492: Epoch time: 89.99 s
2024-08-03 12:09:44.078210: 
2024-08-03 12:09:44.080593: Epoch 184
2024-08-03 12:09:44.082821: Current learning rate: 0.00833
2024-08-03 12:11:14.070827: Validation loss did not improve from -0.53183. Patience: 24/50
2024-08-03 12:11:14.072869: train_loss -0.7976
2024-08-03 12:11:14.074504: val_loss -0.4821
2024-08-03 12:11:14.075549: Pseudo dice [0.7099]
2024-08-03 12:11:14.076495: Epoch time: 90.0 s
2024-08-03 12:11:15.661902: 
2024-08-03 12:11:15.664789: Epoch 185
2024-08-03 12:11:15.667386: Current learning rate: 0.00832
2024-08-03 12:12:45.505132: Validation loss did not improve from -0.53183. Patience: 25/50
2024-08-03 12:12:45.506842: train_loss -0.7968
2024-08-03 12:12:45.508506: val_loss -0.2909
2024-08-03 12:12:45.509800: Pseudo dice [0.6195]
2024-08-03 12:12:45.510893: Epoch time: 89.85 s
2024-08-03 12:12:46.789846: 
2024-08-03 12:12:46.792102: Epoch 186
2024-08-03 12:12:46.793973: Current learning rate: 0.00831
2024-08-03 12:14:16.637777: Validation loss did not improve from -0.53183. Patience: 26/50
2024-08-03 12:14:16.639497: train_loss -0.7911
2024-08-03 12:14:16.641348: val_loss -0.4506
2024-08-03 12:14:16.642778: Pseudo dice [0.6998]
2024-08-03 12:14:16.644256: Epoch time: 89.85 s
2024-08-03 12:14:17.938387: 
2024-08-03 12:14:17.940709: Epoch 187
2024-08-03 12:14:17.942469: Current learning rate: 0.0083
2024-08-03 12:15:47.799906: Validation loss did not improve from -0.53183. Patience: 27/50
2024-08-03 12:15:47.801277: train_loss -0.7911
2024-08-03 12:15:47.802518: val_loss -0.4041
2024-08-03 12:15:47.803631: Pseudo dice [0.6807]
2024-08-03 12:15:47.804871: Epoch time: 89.86 s
2024-08-03 12:15:49.437853: 
2024-08-03 12:15:49.439876: Epoch 188
2024-08-03 12:15:49.441386: Current learning rate: 0.00829
2024-08-03 12:17:19.384491: Validation loss did not improve from -0.53183. Patience: 28/50
2024-08-03 12:17:19.386247: train_loss -0.7892
2024-08-03 12:17:19.388110: val_loss -0.4745
2024-08-03 12:17:19.389359: Pseudo dice [0.7193]
2024-08-03 12:17:19.390483: Epoch time: 89.95 s
2024-08-03 12:17:20.658060: 
2024-08-03 12:17:20.660489: Epoch 189
2024-08-03 12:17:20.662071: Current learning rate: 0.00828
2024-08-03 12:18:50.655329: Validation loss did not improve from -0.53183. Patience: 29/50
2024-08-03 12:18:50.657040: train_loss -0.7978
2024-08-03 12:18:50.658417: val_loss -0.4034
2024-08-03 12:18:50.659509: Pseudo dice [0.6816]
2024-08-03 12:18:50.660625: Epoch time: 90.0 s
2024-08-03 12:18:52.306836: 
2024-08-03 12:18:52.309011: Epoch 190
2024-08-03 12:18:52.310365: Current learning rate: 0.00827
2024-08-03 12:20:22.599069: Validation loss did not improve from -0.53183. Patience: 30/50
2024-08-03 12:20:22.600650: train_loss -0.8016
2024-08-03 12:20:22.605564: val_loss -0.4839
2024-08-03 12:20:22.607879: Pseudo dice [0.7281]
2024-08-03 12:20:22.609601: Epoch time: 90.29 s
2024-08-03 12:20:23.869017: 
2024-08-03 12:20:23.871909: Epoch 191
2024-08-03 12:20:23.874064: Current learning rate: 0.00826
2024-08-03 12:21:54.113721: Validation loss did not improve from -0.53183. Patience: 31/50
2024-08-03 12:21:54.115391: train_loss -0.7981
2024-08-03 12:21:54.117164: val_loss -0.4371
2024-08-03 12:21:54.118619: Pseudo dice [0.6938]
2024-08-03 12:21:54.120027: Epoch time: 90.25 s
2024-08-03 12:21:55.418269: 
2024-08-03 12:21:55.420900: Epoch 192
2024-08-03 12:21:55.422601: Current learning rate: 0.00825
2024-08-03 12:23:25.498144: Validation loss did not improve from -0.53183. Patience: 32/50
2024-08-03 12:23:25.499932: train_loss -0.8067
2024-08-03 12:23:25.501311: val_loss -0.4362
2024-08-03 12:23:25.502514: Pseudo dice [0.7053]
2024-08-03 12:23:25.503779: Epoch time: 90.08 s
2024-08-03 12:23:26.764417: 
2024-08-03 12:23:26.766740: Epoch 193
2024-08-03 12:23:26.768418: Current learning rate: 0.00824
2024-08-03 12:24:56.736865: Validation loss did not improve from -0.53183. Patience: 33/50
2024-08-03 12:24:56.738482: train_loss -0.8039
2024-08-03 12:24:56.739749: val_loss -0.4949
2024-08-03 12:24:56.741175: Pseudo dice [0.7297]
2024-08-03 12:24:56.742489: Epoch time: 89.98 s
2024-08-03 12:24:58.027670: 
2024-08-03 12:24:58.030531: Epoch 194
2024-08-03 12:24:58.032531: Current learning rate: 0.00824
2024-08-03 12:26:28.013202: Validation loss did not improve from -0.53183. Patience: 34/50
2024-08-03 12:26:28.015967: train_loss -0.7957
2024-08-03 12:26:28.017641: val_loss -0.4731
2024-08-03 12:26:28.019148: Pseudo dice [0.7076]
2024-08-03 12:26:28.020541: Epoch time: 89.99 s
2024-08-03 12:26:29.664599: 
2024-08-03 12:26:29.667287: Epoch 195
2024-08-03 12:26:29.669017: Current learning rate: 0.00823
2024-08-03 12:27:59.725700: Validation loss did not improve from -0.53183. Patience: 35/50
2024-08-03 12:27:59.727054: train_loss -0.7996
2024-08-03 12:27:59.728362: val_loss -0.523
2024-08-03 12:27:59.729439: Pseudo dice [0.7421]
2024-08-03 12:27:59.730477: Epoch time: 90.06 s
2024-08-03 12:28:01.047254: 
2024-08-03 12:28:01.049700: Epoch 196
2024-08-03 12:28:01.051173: Current learning rate: 0.00822
2024-08-03 12:29:31.134392: Validation loss did not improve from -0.53183. Patience: 36/50
2024-08-03 12:29:31.136464: train_loss -0.8033
2024-08-03 12:29:31.137648: val_loss -0.4776
2024-08-03 12:29:31.138880: Pseudo dice [0.7228]
2024-08-03 12:29:31.140067: Epoch time: 90.09 s
2024-08-03 12:29:32.429423: 
2024-08-03 12:29:32.431568: Epoch 197
2024-08-03 12:29:32.433227: Current learning rate: 0.00821
2024-08-03 12:31:00.582400: Validation loss did not improve from -0.53183. Patience: 37/50
2024-08-03 12:31:00.584951: train_loss -0.7772
2024-08-03 12:31:00.586800: val_loss -0.4262
2024-08-03 12:31:00.588049: Pseudo dice [0.6822]
2024-08-03 12:31:00.589199: Epoch time: 88.16 s
2024-08-03 12:31:01.854302: 
2024-08-03 12:31:01.857110: Epoch 198
2024-08-03 12:31:01.858501: Current learning rate: 0.0082
2024-08-03 12:32:29.923119: Validation loss did not improve from -0.53183. Patience: 38/50
2024-08-03 12:32:29.925060: train_loss -0.775
2024-08-03 12:32:29.926765: val_loss -0.4593
2024-08-03 12:32:29.927917: Pseudo dice [0.7171]
2024-08-03 12:32:29.929016: Epoch time: 88.07 s
2024-08-03 12:32:31.674998: 
2024-08-03 12:32:31.677662: Epoch 199
2024-08-03 12:32:31.679795: Current learning rate: 0.00819
2024-08-03 12:34:01.517650: Validation loss improved from -0.53183 to -0.55079! Patience: 38/50
2024-08-03 12:34:01.524916: train_loss -0.778
2024-08-03 12:34:01.526705: val_loss -0.5508
2024-08-03 12:34:01.527823: Pseudo dice [0.7537]
2024-08-03 12:34:01.528849: Epoch time: 89.85 s
2024-08-03 12:34:03.411694: 
2024-08-03 12:34:03.414116: Epoch 200
2024-08-03 12:34:03.415678: Current learning rate: 0.00818
2024-08-03 12:35:33.424163: Validation loss did not improve from -0.55079. Patience: 1/50
2024-08-03 12:35:33.452473: train_loss -0.7903
2024-08-03 12:35:33.456309: val_loss -0.4164
2024-08-03 12:35:33.457876: Pseudo dice [0.6874]
2024-08-03 12:35:33.459716: Epoch time: 90.04 s
2024-08-03 12:35:35.212613: 
2024-08-03 12:35:35.214989: Epoch 201
2024-08-03 12:35:35.216610: Current learning rate: 0.00817
2024-08-03 12:37:04.821065: Validation loss did not improve from -0.55079. Patience: 2/50
2024-08-03 12:37:04.822883: train_loss -0.7829
2024-08-03 12:37:04.824727: val_loss -0.4353
2024-08-03 12:37:04.825957: Pseudo dice [0.6986]
2024-08-03 12:37:04.827074: Epoch time: 89.61 s
2024-08-03 12:37:06.167348: 
2024-08-03 12:37:06.170151: Epoch 202
2024-08-03 12:37:06.171602: Current learning rate: 0.00816
2024-08-03 12:38:35.865762: Validation loss did not improve from -0.55079. Patience: 3/50
2024-08-03 12:38:35.867541: train_loss -0.7889
2024-08-03 12:38:35.869304: val_loss -0.4747
2024-08-03 12:38:35.870813: Pseudo dice [0.7176]
2024-08-03 12:38:35.872244: Epoch time: 89.7 s
2024-08-03 12:38:37.156151: 
2024-08-03 12:38:37.158307: Epoch 203
2024-08-03 12:38:37.159788: Current learning rate: 0.00815
2024-08-03 12:40:06.870564: Validation loss did not improve from -0.55079. Patience: 4/50
2024-08-03 12:40:06.872260: train_loss -0.7984
2024-08-03 12:40:06.873780: val_loss -0.4195
2024-08-03 12:40:06.875377: Pseudo dice [0.6881]
2024-08-03 12:40:06.876718: Epoch time: 89.72 s
2024-08-03 12:40:08.159122: 
2024-08-03 12:40:08.162044: Epoch 204
2024-08-03 12:40:08.164302: Current learning rate: 0.00814
2024-08-03 12:41:36.306557: Validation loss did not improve from -0.55079. Patience: 5/50
2024-08-03 12:41:36.308535: train_loss -0.7954
2024-08-03 12:41:36.310383: val_loss -0.5293
2024-08-03 12:41:36.311887: Pseudo dice [0.7459]
2024-08-03 12:41:36.313379: Epoch time: 88.15 s
2024-08-03 12:41:38.005960: 
2024-08-03 12:41:38.008260: Epoch 205
2024-08-03 12:41:38.009801: Current learning rate: 0.00813
2024-08-03 12:43:07.882602: Validation loss did not improve from -0.55079. Patience: 6/50
2024-08-03 12:43:07.884043: train_loss -0.7991
2024-08-03 12:43:07.885429: val_loss -0.4407
2024-08-03 12:43:07.886729: Pseudo dice [0.6922]
2024-08-03 12:43:07.887850: Epoch time: 89.88 s
2024-08-03 12:43:09.068964: 
2024-08-03 12:43:09.071694: Epoch 206
2024-08-03 12:43:09.073925: Current learning rate: 0.00813
2024-08-03 12:44:39.030549: Validation loss did not improve from -0.55079. Patience: 7/50
2024-08-03 12:44:39.031862: train_loss -0.8027
2024-08-03 12:44:39.033293: val_loss -0.4715
2024-08-03 12:44:39.034791: Pseudo dice [0.7288]
2024-08-03 12:44:39.036256: Epoch time: 89.96 s
2024-08-03 12:44:40.253816: 
2024-08-03 12:44:40.257727: Epoch 207
2024-08-03 12:44:40.259133: Current learning rate: 0.00812
2024-08-03 12:46:10.028969: Validation loss did not improve from -0.55079. Patience: 8/50
2024-08-03 12:46:10.031110: train_loss -0.8068
2024-08-03 12:46:10.032623: val_loss -0.4558
2024-08-03 12:46:10.033793: Pseudo dice [0.7147]
2024-08-03 12:46:10.035050: Epoch time: 89.78 s
2024-08-03 12:46:11.199053: 
2024-08-03 12:46:11.201827: Epoch 208
2024-08-03 12:46:11.203106: Current learning rate: 0.00811
2024-08-03 12:47:41.017587: Validation loss did not improve from -0.55079. Patience: 9/50
2024-08-03 12:47:41.019467: train_loss -0.8049
2024-08-03 12:47:41.021051: val_loss -0.5112
2024-08-03 12:47:41.022340: Pseudo dice [0.7307]
2024-08-03 12:47:41.023556: Epoch time: 89.82 s
2024-08-03 12:47:42.225737: 
2024-08-03 12:47:42.228920: Epoch 209
2024-08-03 12:47:42.230945: Current learning rate: 0.0081
2024-08-03 12:49:12.142829: Validation loss did not improve from -0.55079. Patience: 10/50
2024-08-03 12:49:12.145386: train_loss -0.8049
2024-08-03 12:49:12.147415: val_loss -0.4904
2024-08-03 12:49:12.148614: Pseudo dice [0.7247]
2024-08-03 12:49:12.149632: Epoch time: 89.92 s
2024-08-03 12:49:14.397774: 
2024-08-03 12:49:14.400429: Epoch 210
2024-08-03 12:49:14.451161: Current learning rate: 0.00809
2024-08-03 12:50:44.465760: Validation loss did not improve from -0.55079. Patience: 11/50
2024-08-03 12:50:44.467371: train_loss -0.8069
2024-08-03 12:50:44.496362: val_loss -0.4834
2024-08-03 12:50:44.497806: Pseudo dice [0.7236]
2024-08-03 12:50:44.498910: Epoch time: 90.07 s
2024-08-03 12:50:45.670173: 
2024-08-03 12:50:45.672882: Epoch 211
2024-08-03 12:50:45.674573: Current learning rate: 0.00808
2024-08-03 12:52:15.654570: Validation loss did not improve from -0.55079. Patience: 12/50
2024-08-03 12:52:15.656339: train_loss -0.8065
2024-08-03 12:52:15.657744: val_loss -0.493
2024-08-03 12:52:15.658864: Pseudo dice [0.7334]
2024-08-03 12:52:15.659846: Epoch time: 89.99 s
2024-08-03 12:52:16.853437: 
2024-08-03 12:52:16.856194: Epoch 212
2024-08-03 12:52:16.857410: Current learning rate: 0.00807
2024-08-03 12:53:46.801758: Validation loss did not improve from -0.55079. Patience: 13/50
2024-08-03 12:53:46.803312: train_loss -0.8041
2024-08-03 12:53:46.804463: val_loss -0.4956
2024-08-03 12:53:46.805473: Pseudo dice [0.7361]
2024-08-03 12:53:46.806471: Epoch time: 89.95 s
2024-08-03 12:53:47.979889: 
2024-08-03 12:53:47.981993: Epoch 213
2024-08-03 12:53:47.983487: Current learning rate: 0.00806
2024-08-03 12:55:17.886693: Validation loss did not improve from -0.55079. Patience: 14/50
2024-08-03 12:55:17.888453: train_loss -0.8077
2024-08-03 12:55:17.889903: val_loss -0.5
2024-08-03 12:55:17.890942: Pseudo dice [0.7323]
2024-08-03 12:55:17.892065: Epoch time: 89.91 s
2024-08-03 12:55:19.069983: 
2024-08-03 12:55:19.073330: Epoch 214
2024-08-03 12:55:19.075566: Current learning rate: 0.00805
2024-08-03 12:56:48.969529: Validation loss did not improve from -0.55079. Patience: 15/50
2024-08-03 12:56:48.971004: train_loss -0.8083
2024-08-03 12:56:48.972643: val_loss -0.4188
2024-08-03 12:56:48.974064: Pseudo dice [0.6955]
2024-08-03 12:56:48.975118: Epoch time: 89.9 s
2024-08-03 12:56:50.512173: 
2024-08-03 12:56:50.514471: Epoch 215
2024-08-03 12:56:50.515941: Current learning rate: 0.00804
2024-08-03 12:58:20.406668: Validation loss did not improve from -0.55079. Patience: 16/50
2024-08-03 12:58:20.408493: train_loss -0.8107
2024-08-03 12:58:20.410224: val_loss -0.4655
2024-08-03 12:58:20.411656: Pseudo dice [0.7214]
2024-08-03 12:58:20.413161: Epoch time: 89.9 s
2024-08-03 12:58:21.678116: 
2024-08-03 12:58:21.681522: Epoch 216
2024-08-03 12:58:21.683589: Current learning rate: 0.00803
2024-08-03 12:59:51.767426: Validation loss did not improve from -0.55079. Patience: 17/50
2024-08-03 12:59:51.769502: train_loss -0.813
2024-08-03 12:59:51.771082: val_loss -0.4639
2024-08-03 12:59:51.772360: Pseudo dice [0.7202]
2024-08-03 12:59:51.773551: Epoch time: 90.09 s
2024-08-03 12:59:52.970258: 
2024-08-03 12:59:52.972981: Epoch 217
2024-08-03 12:59:52.975285: Current learning rate: 0.00802
2024-08-03 13:01:23.063256: Validation loss did not improve from -0.55079. Patience: 18/50
2024-08-03 13:01:23.065815: train_loss -0.8036
2024-08-03 13:01:23.067245: val_loss -0.4857
2024-08-03 13:01:23.068329: Pseudo dice [0.7183]
2024-08-03 13:01:23.069622: Epoch time: 90.1 s
2024-08-03 13:01:24.259860: 
2024-08-03 13:01:24.262806: Epoch 218
2024-08-03 13:01:24.265175: Current learning rate: 0.00801
2024-08-03 13:02:54.439943: Validation loss did not improve from -0.55079. Patience: 19/50
2024-08-03 13:02:54.441226: train_loss -0.7908
2024-08-03 13:02:54.442806: val_loss -0.2831
2024-08-03 13:02:54.444587: Pseudo dice [0.6202]
2024-08-03 13:02:54.446028: Epoch time: 90.18 s
2024-08-03 13:02:55.620314: 
2024-08-03 13:02:55.623309: Epoch 219
2024-08-03 13:02:55.625175: Current learning rate: 0.00801
2024-08-03 13:04:25.807679: Validation loss did not improve from -0.55079. Patience: 20/50
2024-08-03 13:04:25.809090: train_loss -0.7782
2024-08-03 13:04:25.810612: val_loss -0.5212
2024-08-03 13:04:25.811867: Pseudo dice [0.7313]
2024-08-03 13:04:25.812974: Epoch time: 90.19 s
2024-08-03 13:04:27.340811: 
2024-08-03 13:04:27.343297: Epoch 220
2024-08-03 13:04:27.345075: Current learning rate: 0.008
2024-08-03 13:05:57.199944: Validation loss did not improve from -0.55079. Patience: 21/50
2024-08-03 13:05:57.201632: train_loss -0.7916
2024-08-03 13:05:57.203341: val_loss -0.4578
2024-08-03 13:05:57.204707: Pseudo dice [0.7111]
2024-08-03 13:05:57.206172: Epoch time: 89.86 s
2024-08-03 13:05:58.437081: 
2024-08-03 13:05:58.439655: Epoch 221
2024-08-03 13:05:58.441308: Current learning rate: 0.00799
2024-08-03 13:07:27.948169: Validation loss did not improve from -0.55079. Patience: 22/50
2024-08-03 13:07:27.950006: train_loss -0.8017
2024-08-03 13:07:27.951488: val_loss -0.4936
2024-08-03 13:07:27.952913: Pseudo dice [0.7318]
2024-08-03 13:07:27.954255: Epoch time: 89.51 s
2024-08-03 13:07:29.577316: 
2024-08-03 13:07:29.580611: Epoch 222
2024-08-03 13:07:29.582452: Current learning rate: 0.00798
2024-08-03 13:08:59.004757: Validation loss did not improve from -0.55079. Patience: 23/50
2024-08-03 13:08:59.006570: train_loss -0.8032
2024-08-03 13:08:59.008374: val_loss -0.4499
2024-08-03 13:08:59.009506: Pseudo dice [0.7102]
2024-08-03 13:08:59.010810: Epoch time: 89.43 s
2024-08-03 13:09:00.241363: 
2024-08-03 13:09:00.243958: Epoch 223
2024-08-03 13:09:00.245608: Current learning rate: 0.00797
2024-08-03 13:10:29.803876: Validation loss did not improve from -0.55079. Patience: 24/50
2024-08-03 13:10:29.805105: train_loss -0.8079
2024-08-03 13:10:29.806828: val_loss -0.4055
2024-08-03 13:10:29.808228: Pseudo dice [0.6886]
2024-08-03 13:10:29.809590: Epoch time: 89.56 s
2024-08-03 13:10:31.043416: 
2024-08-03 13:10:31.045836: Epoch 224
2024-08-03 13:10:31.047562: Current learning rate: 0.00796
2024-08-03 13:12:00.777233: Validation loss did not improve from -0.55079. Patience: 25/50
2024-08-03 13:12:00.778772: train_loss -0.8065
2024-08-03 13:12:00.780058: val_loss -0.4839
2024-08-03 13:12:00.781090: Pseudo dice [0.7203]
2024-08-03 13:12:00.782289: Epoch time: 89.74 s
2024-08-03 13:12:02.284241: 
2024-08-03 13:12:02.286875: Epoch 225
2024-08-03 13:12:02.288488: Current learning rate: 0.00795
2024-08-03 13:13:31.888861: Validation loss did not improve from -0.55079. Patience: 26/50
2024-08-03 13:13:31.890630: train_loss -0.8111
2024-08-03 13:13:31.892196: val_loss -0.4777
2024-08-03 13:13:31.893760: Pseudo dice [0.7234]
2024-08-03 13:13:31.895297: Epoch time: 89.61 s
2024-08-03 13:13:33.068820: 
2024-08-03 13:13:33.070687: Epoch 226
2024-08-03 13:13:33.072307: Current learning rate: 0.00794
2024-08-03 13:15:02.551167: Validation loss did not improve from -0.55079. Patience: 27/50
2024-08-03 13:15:02.552943: train_loss -0.8107
2024-08-03 13:15:02.554763: val_loss -0.4849
2024-08-03 13:15:02.556161: Pseudo dice [0.7258]
2024-08-03 13:15:02.557574: Epoch time: 89.49 s
2024-08-03 13:15:03.754397: 
2024-08-03 13:15:03.757795: Epoch 227
2024-08-03 13:15:03.760525: Current learning rate: 0.00793
2024-08-03 13:16:33.156682: Validation loss did not improve from -0.55079. Patience: 28/50
2024-08-03 13:16:33.158336: train_loss -0.8125
2024-08-03 13:16:33.159924: val_loss -0.461
2024-08-03 13:16:33.161056: Pseudo dice [0.7175]
2024-08-03 13:16:33.162138: Epoch time: 89.41 s
2024-08-03 13:16:34.339814: 
2024-08-03 13:16:34.341672: Epoch 228
2024-08-03 13:16:34.343226: Current learning rate: 0.00792
2024-08-03 13:18:03.804504: Validation loss did not improve from -0.55079. Patience: 29/50
2024-08-03 13:18:03.806482: train_loss -0.811
2024-08-03 13:18:03.807867: val_loss -0.4839
2024-08-03 13:18:03.809251: Pseudo dice [0.728]
2024-08-03 13:18:03.810429: Epoch time: 89.47 s
2024-08-03 13:18:05.020318: 
2024-08-03 13:18:05.022830: Epoch 229
2024-08-03 13:18:05.024524: Current learning rate: 0.00791
2024-08-03 13:19:34.686655: Validation loss did not improve from -0.55079. Patience: 30/50
2024-08-03 13:19:34.687852: train_loss -0.812
2024-08-03 13:19:34.688998: val_loss -0.4796
2024-08-03 13:19:34.689984: Pseudo dice [0.7229]
2024-08-03 13:19:34.691000: Epoch time: 89.67 s
2024-08-03 13:19:36.223686: 
2024-08-03 13:19:36.225770: Epoch 230
2024-08-03 13:19:36.227419: Current learning rate: 0.0079
2024-08-03 13:21:05.940468: Validation loss did not improve from -0.55079. Patience: 31/50
2024-08-03 13:21:05.941979: train_loss -0.8121
2024-08-03 13:21:05.943101: val_loss -0.507
2024-08-03 13:21:05.944154: Pseudo dice [0.7376]
2024-08-03 13:21:05.945067: Epoch time: 89.72 s
2024-08-03 13:21:07.214707: 
2024-08-03 13:21:07.217369: Epoch 231
2024-08-03 13:21:07.219367: Current learning rate: 0.00789
2024-08-03 13:22:37.211649: Validation loss did not improve from -0.55079. Patience: 32/50
2024-08-03 13:22:37.213925: train_loss -0.8124
2024-08-03 13:22:37.215686: val_loss -0.4613
2024-08-03 13:22:37.216935: Pseudo dice [0.7125]
2024-08-03 13:22:37.218198: Epoch time: 90.0 s
2024-08-03 13:22:38.454086: 
2024-08-03 13:22:38.456484: Epoch 232
2024-08-03 13:22:38.457907: Current learning rate: 0.00789
2024-08-03 13:24:08.445914: Validation loss did not improve from -0.55079. Patience: 33/50
2024-08-03 13:24:08.447388: train_loss -0.8132
2024-08-03 13:24:08.448778: val_loss -0.4961
2024-08-03 13:24:08.450156: Pseudo dice [0.7253]
2024-08-03 13:24:08.451499: Epoch time: 89.99 s
2024-08-03 13:24:09.675285: 
2024-08-03 13:24:09.678140: Epoch 233
2024-08-03 13:24:09.679849: Current learning rate: 0.00788
2024-08-03 13:25:39.572815: Validation loss did not improve from -0.55079. Patience: 34/50
2024-08-03 13:25:39.574280: train_loss -0.8147
2024-08-03 13:25:39.575814: val_loss -0.4635
2024-08-03 13:25:39.577039: Pseudo dice [0.7128]
2024-08-03 13:25:39.578308: Epoch time: 89.9 s
2024-08-03 13:25:41.108348: 
2024-08-03 13:25:41.110954: Epoch 234
2024-08-03 13:25:41.112839: Current learning rate: 0.00787
2024-08-03 13:27:11.151068: Validation loss did not improve from -0.55079. Patience: 35/50
2024-08-03 13:27:11.153387: train_loss -0.813
2024-08-03 13:27:11.155163: val_loss -0.473
2024-08-03 13:27:11.156384: Pseudo dice [0.7263]
2024-08-03 13:27:11.157916: Epoch time: 90.05 s
2024-08-03 13:27:12.774806: 
2024-08-03 13:27:12.777691: Epoch 235
2024-08-03 13:27:12.779440: Current learning rate: 0.00786
2024-08-03 13:28:42.423332: Validation loss did not improve from -0.55079. Patience: 36/50
2024-08-03 13:28:42.425227: train_loss -0.8139
2024-08-03 13:28:42.427226: val_loss -0.3257
2024-08-03 13:28:42.428537: Pseudo dice [0.6487]
2024-08-03 13:28:42.429927: Epoch time: 89.65 s
2024-08-03 13:28:43.644269: 
2024-08-03 13:28:43.646921: Epoch 236
2024-08-03 13:28:43.648645: Current learning rate: 0.00785
2024-08-03 13:30:13.431638: Validation loss did not improve from -0.55079. Patience: 37/50
2024-08-03 13:30:13.433339: train_loss -0.8106
2024-08-03 13:30:13.434862: val_loss -0.4097
2024-08-03 13:30:13.436021: Pseudo dice [0.6873]
2024-08-03 13:30:13.437293: Epoch time: 89.79 s
2024-08-03 13:30:14.656055: 
2024-08-03 13:30:14.658472: Epoch 237
2024-08-03 13:30:14.659854: Current learning rate: 0.00784
2024-08-03 13:31:44.636843: Validation loss did not improve from -0.55079. Patience: 38/50
2024-08-03 13:31:44.638416: train_loss -0.815
2024-08-03 13:31:44.639622: val_loss -0.4577
2024-08-03 13:31:44.640661: Pseudo dice [0.7157]
2024-08-03 13:31:44.641609: Epoch time: 89.98 s
2024-08-03 13:31:45.811953: 
2024-08-03 13:31:45.814459: Epoch 238
2024-08-03 13:31:45.815983: Current learning rate: 0.00783
2024-08-03 13:33:16.022644: Validation loss did not improve from -0.55079. Patience: 39/50
2024-08-03 13:33:16.024848: train_loss -0.8143
2024-08-03 13:33:16.027483: val_loss -0.5183
2024-08-03 13:33:16.029119: Pseudo dice [0.7448]
2024-08-03 13:33:16.030260: Epoch time: 90.21 s
2024-08-03 13:33:17.249044: 
2024-08-03 13:33:17.251876: Epoch 239
2024-08-03 13:33:17.253741: Current learning rate: 0.00782
2024-08-03 13:34:47.498383: Validation loss did not improve from -0.55079. Patience: 40/50
2024-08-03 13:34:47.500320: train_loss -0.8159
2024-08-03 13:34:47.501602: val_loss -0.4687
2024-08-03 13:34:47.502953: Pseudo dice [0.7159]
2024-08-03 13:34:47.504213: Epoch time: 90.25 s
2024-08-03 13:34:49.038549: 
2024-08-03 13:34:49.041552: Epoch 240
2024-08-03 13:34:49.043783: Current learning rate: 0.00781
2024-08-03 13:36:19.341804: Validation loss did not improve from -0.55079. Patience: 41/50
2024-08-03 13:36:19.360180: train_loss -0.8129
2024-08-03 13:36:19.361655: val_loss -0.5169
2024-08-03 13:36:19.362716: Pseudo dice [0.7415]
2024-08-03 13:36:19.363967: Epoch time: 90.32 s
2024-08-03 13:36:20.610748: 
2024-08-03 13:36:20.613131: Epoch 241
2024-08-03 13:36:20.614526: Current learning rate: 0.0078
2024-08-03 13:37:50.752571: Validation loss did not improve from -0.55079. Patience: 42/50
2024-08-03 13:37:50.754472: train_loss -0.8108
2024-08-03 13:37:50.755945: val_loss -0.4581
2024-08-03 13:37:50.757253: Pseudo dice [0.706]
2024-08-03 13:37:50.758537: Epoch time: 90.14 s
2024-08-03 13:37:52.008675: 
2024-08-03 13:37:52.011518: Epoch 242
2024-08-03 13:37:52.013330: Current learning rate: 0.00779
2024-08-03 13:39:22.103306: Validation loss did not improve from -0.55079. Patience: 43/50
2024-08-03 13:39:22.105857: train_loss -0.8129
2024-08-03 13:39:22.108184: val_loss -0.5294
2024-08-03 13:39:22.109880: Pseudo dice [0.7445]
2024-08-03 13:39:22.111253: Epoch time: 90.1 s
2024-08-03 13:39:23.885387: 
2024-08-03 13:39:23.887827: Epoch 243
2024-08-03 13:39:23.889190: Current learning rate: 0.00778
2024-08-03 13:40:54.486999: Validation loss did not improve from -0.55079. Patience: 44/50
2024-08-03 13:40:54.489730: train_loss -0.8047
2024-08-03 13:40:54.494255: val_loss -0.4081
2024-08-03 13:40:54.496796: Pseudo dice [0.6952]
2024-08-03 13:40:54.498743: Epoch time: 90.61 s
2024-08-03 13:40:56.014706: 
2024-08-03 13:40:56.018159: Epoch 244
2024-08-03 13:40:56.020329: Current learning rate: 0.00777
2024-08-03 13:42:25.711826: Validation loss did not improve from -0.55079. Patience: 45/50
2024-08-03 13:42:25.713833: train_loss -0.8051
2024-08-03 13:42:25.715499: val_loss -0.4309
2024-08-03 13:42:25.716852: Pseudo dice [0.6981]
2024-08-03 13:42:25.717863: Epoch time: 89.7 s
2024-08-03 13:42:27.317220: 
2024-08-03 13:42:27.320571: Epoch 245
2024-08-03 13:42:27.322404: Current learning rate: 0.00777
2024-08-03 13:43:57.178372: Validation loss did not improve from -0.55079. Patience: 46/50
2024-08-03 13:43:57.180412: train_loss -0.811
2024-08-03 13:43:57.181873: val_loss -0.4926
2024-08-03 13:43:57.183634: Pseudo dice [0.7264]
2024-08-03 13:43:57.184778: Epoch time: 89.86 s
2024-08-03 13:43:58.759801: 
2024-08-03 13:43:58.762191: Epoch 246
2024-08-03 13:43:58.764256: Current learning rate: 0.00776
2024-08-03 13:45:28.789722: Validation loss did not improve from -0.55079. Patience: 47/50
2024-08-03 13:45:28.791038: train_loss -0.8135
2024-08-03 13:45:28.792235: val_loss -0.4233
2024-08-03 13:45:28.793644: Pseudo dice [0.686]
2024-08-03 13:45:28.794689: Epoch time: 90.03 s
2024-08-03 13:45:29.988621: 
2024-08-03 13:45:29.991235: Epoch 247
2024-08-03 13:45:29.992884: Current learning rate: 0.00775
2024-08-03 13:47:00.084353: Validation loss did not improve from -0.55079. Patience: 48/50
2024-08-03 13:47:00.086342: train_loss -0.8099
2024-08-03 13:47:00.087479: val_loss -0.4583
2024-08-03 13:47:00.088564: Pseudo dice [0.7205]
2024-08-03 13:47:00.089744: Epoch time: 90.1 s
2024-08-03 13:47:01.317853: 
2024-08-03 13:47:01.320604: Epoch 248
2024-08-03 13:47:01.322523: Current learning rate: 0.00774
2024-08-03 13:48:31.218958: Validation loss did not improve from -0.55079. Patience: 49/50
2024-08-03 13:48:31.220301: train_loss -0.8164
2024-08-03 13:48:31.221581: val_loss -0.4894
2024-08-03 13:48:31.222664: Pseudo dice [0.7369]
2024-08-03 13:48:31.223595: Epoch time: 89.9 s
2024-08-03 13:48:32.499507: 
2024-08-03 13:48:32.501412: Epoch 249
2024-08-03 13:48:32.502360: Current learning rate: 0.00773
2024-08-03 13:50:02.341508: Validation loss did not improve from -0.55079. Patience: 50/50
2024-08-03 13:50:02.365838: train_loss -0.8136
2024-08-03 13:50:02.367868: val_loss -0.4596
2024-08-03 13:50:02.369098: Pseudo dice [0.718]
2024-08-03 13:50:02.370709: Epoch time: 89.84 s
2024-08-03 13:50:04.119508: Patience reached. Stopping training.
2024-08-03 13:50:04.503330: Training done.
2024-08-03 13:50:05.789790: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset302_Calcium_OCTv2/splits_final.json
2024-08-03 13:50:05.801660: The split file contains 3 splits.
2024-08-03 13:50:05.803881: Desired fold for training: 2
2024-08-03 13:50:05.805536: This split has 4 training and 2 validation cases.
2024-08-03 13:50:05.807067: predicting 401-004
2024-08-03 13:50:05.867057: 401-004, shape torch.Size([1, 375, 498, 498]), rank 0
2024-08-03 13:52:40.462869: predicting 701-013
2024-08-03 13:52:40.492891: 701-013, shape torch.Size([1, 375, 498, 498]), rank 0
2024-08-03 13:54:33.568069: Validation complete
2024-08-03 13:54:33.569424: Mean Validation Dice:  0.7216945392747467
wandb: 
wandb: Run history:
wandb:            ema_fg_dice ▁▃▄▅▆▆▇▇▇▇▇▇▇▇██▇▇███████████▇▇▇▇██▇█▇██
wandb:   epoch_end_timestamps ▁▁▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████
wandb: epoch_start_timestamps ▁▁▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████
wandb:                    lrs ███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:           mean_fg_dice ▁▃▅▆▄▆▇▅▇▆▇▆▇▆▇█▆▇██▇▇▇█▇█▆▇▆▂▆▅▅▇▇▅▇▃▆▇
wandb:           train_losses █▆▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁
wandb:             val_losses █▅▄▃▄▃▁▄▂▂▁▃▂▂▂▁▂▂▁▂▂▂▂▂▁▁▃▃▃▇▃▄▄▂▂▄▂▆▃▃
wandb: 
wandb: Run summary:
wandb:            ema_fg_dice 0.71591
wandb:   epoch_end_timestamps 1722707402.34265
wandb: epoch_start_timestamps 1722707312.49835
wandb:                    lrs 0.00773
wandb:           mean_fg_dice 0.718
wandb:           train_losses -0.81363
wandb:             val_losses -0.45956
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset302_Calcium_OCTv2/nnUNetTrainer__nnUNetPlans__3d_32x160x128_b10/fold_2/wandb/offline-run-20240803_035219-l4gkbncv
wandb: Find logs at: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset302_Calcium_OCTv2/nnUNetTrainer__nnUNetPlans__3d_32x160x128_b10/fold_2/wandb/offline-run-20240803_035219-l4gkbncv/logs
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f37ce031790>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f37c12c50a0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f37c4925c70>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f37c015c1f0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f37ce1d4910>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f37c098d310>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 2 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 2 cases that I would like to predict

Predicting 101-045:
perform_everything_on_device: True
  0%|          | 0/966 [00:00<?, ?it/s]  0%|          | 1/966 [00:15<4:01:55, 15.04s/it]  0%|          | 3/966 [00:15<1:03:38,  3.97s/it]  1%|          | 5/966 [00:15<31:48,  1.99s/it]    1%|          | 6/966 [00:15<23:44,  1.48s/it]  1%|          | 7/966 [00:15<17:39,  1.10s/it]  1%|          | 8/966 [00:15<13:09,  1.21it/s]  1%|          | 9/966 [00:15<09:52,  1.61it/s]  1%|          | 10/966 [00:16<07:31,  2.12it/s]  1%|          | 11/966 [00:16<05:50,  2.72it/s]  1%|          | 12/966 [00:16<04:39,  3.41it/s]  1%|▏         | 13/966 [00:16<03:49,  4.16it/s]  1%|▏         | 14/966 [00:16<03:13,  4.92it/s]  2%|▏         | 15/966 [00:16<02:48,  5.63it/s]  2%|▏         | 16/966 [00:16<02:31,  6.29it/s]  2%|▏         | 17/966 [00:16<02:18,  6.84it/s]  2%|▏         | 18/966 [00:16<02:10,  7.29it/s]  2%|▏         | 19/966 [00:17<02:03,  7.65it/s]  2%|▏         | 20/966 [00:17<01:59,  7.92it/s]  2%|▏         | 21/966 [00:17<01:56,  8.11it/s]  2%|▏         | 22/966 [00:17<01:54,  8.25it/s]  2%|▏         | 23/966 [00:17<01:53,  8.33it/s]  2%|▏         | 24/966 [00:17<01:52,  8.39it/s]  3%|▎         | 25/966 [00:17<01:51,  8.44it/s]  3%|▎         | 26/966 [00:17<01:51,  8.46it/s]  3%|▎         | 27/966 [00:18<01:50,  8.48it/s]  3%|▎         | 28/966 [00:18<01:50,  8.51it/s]  3%|▎         | 29/966 [00:18<01:49,  8.54it/s]  3%|▎         | 30/966 [00:18<01:49,  8.58it/s]  3%|▎         | 31/966 [00:18<01:48,  8.59it/s]  3%|▎         | 32/966 [00:18<01:48,  8.60it/s]  3%|▎         | 33/966 [00:18<01:48,  8.59it/s]  4%|▎         | 34/966 [00:18<01:48,  8.59it/s]  4%|▎         | 35/966 [00:18<01:48,  8.59it/s]  4%|▎         | 36/966 [00:19<01:48,  8.61it/s]  4%|▍         | 37/966 [00:19<01:47,  8.64it/s]  4%|▍         | 38/966 [00:19<01:47,  8.62it/s]  4%|▍         | 39/966 [00:19<01:47,  8.61it/s]  4%|▍         | 40/966 [00:19<01:47,  8.61it/s]  4%|▍         | 41/966 [00:19<01:47,  8.61it/s]  4%|▍         | 42/966 [00:19<01:47,  8.61it/s]  4%|▍         | 43/966 [00:19<01:47,  8.62it/s]  5%|▍         | 44/966 [00:19<01:46,  8.63it/s]  5%|▍         | 45/966 [00:20<01:46,  8.62it/s]  5%|▍         | 46/966 [00:20<01:46,  8.62it/s]  5%|▍         | 47/966 [00:20<01:46,  8.62it/s]  5%|▍         | 48/966 [00:20<01:46,  8.61it/s]  5%|▌         | 49/966 [00:20<01:46,  8.58it/s]  5%|▌         | 50/966 [00:20<01:46,  8.57it/s]  5%|▌         | 51/966 [00:20<01:46,  8.57it/s]  5%|▌         | 52/966 [00:20<01:46,  8.58it/s]  5%|▌         | 53/966 [00:21<01:46,  8.58it/s]  6%|▌         | 54/966 [00:21<01:46,  8.60it/s]  6%|▌         | 55/966 [00:21<01:45,  8.60it/s]  6%|▌         | 56/966 [00:21<01:45,  8.60it/s]  6%|▌         | 57/966 [00:21<01:45,  8.62it/s]  6%|▌         | 58/966 [00:21<01:45,  8.61it/s]  6%|▌         | 59/966 [00:21<01:45,  8.59it/s]  6%|▌         | 60/966 [00:21<01:45,  8.56it/s]  6%|▋         | 61/966 [00:21<01:45,  8.55it/s]  6%|▋         | 62/966 [00:22<01:45,  8.55it/s]  7%|▋         | 63/966 [00:22<01:45,  8.55it/s]  7%|▋         | 64/966 [00:22<01:45,  8.55it/s]  7%|▋         | 65/966 [00:22<01:45,  8.56it/s]  7%|▋         | 66/966 [00:22<01:45,  8.57it/s]  7%|▋         | 67/966 [00:22<01:44,  8.58it/s]  7%|▋         | 68/966 [00:22<01:44,  8.58it/s]  7%|▋         | 69/966 [00:22<01:44,  8.59it/s]  7%|▋         | 70/966 [00:23<01:44,  8.59it/s]  7%|▋         | 71/966 [00:23<01:43,  8.61it/s]  7%|▋         | 72/966 [00:23<01:43,  8.60it/s]  8%|▊         | 73/966 [00:23<01:43,  8.61it/s]  8%|▊         | 74/966 [00:23<01:43,  8.60it/s]  8%|▊         | 75/966 [00:23<01:43,  8.60it/s]  8%|▊         | 76/966 [00:23<01:43,  8.61it/s]  8%|▊         | 77/966 [00:23<01:43,  8.60it/s]  8%|▊         | 78/966 [00:23<01:43,  8.59it/s]  8%|▊         | 79/966 [00:24<01:43,  8.60it/s]  8%|▊         | 80/966 [00:24<01:42,  8.62it/s]  8%|▊         | 81/966 [00:24<01:42,  8.60it/s]  8%|▊         | 82/966 [00:24<01:42,  8.58it/s]  9%|▊         | 83/966 [00:24<01:43,  8.56it/s]  9%|▊         | 84/966 [00:24<01:42,  8.57it/s]  9%|▉         | 85/966 [00:24<01:42,  8.60it/s]  9%|▉         | 86/966 [00:24<01:42,  8.60it/s]  9%|▉         | 87/966 [00:24<01:42,  8.60it/s]  9%|▉         | 88/966 [00:25<01:42,  8.60it/s]  9%|▉         | 89/966 [00:25<01:41,  8.60it/s]  9%|▉         | 90/966 [00:25<01:41,  8.59it/s]  9%|▉         | 91/966 [00:25<01:41,  8.61it/s] 10%|▉         | 92/966 [00:25<01:41,  8.63it/s] 10%|▉         | 93/966 [00:25<01:41,  8.63it/s] 10%|▉         | 94/966 [00:25<01:41,  8.62it/s] 10%|▉         | 95/966 [00:25<01:41,  8.62it/s] 10%|▉         | 96/966 [00:26<01:40,  8.62it/s] 10%|█         | 97/966 [00:26<01:41,  8.59it/s] 10%|█         | 98/966 [00:26<01:41,  8.57it/s] 10%|█         | 99/966 [00:26<01:41,  8.57it/s] 10%|█         | 100/966 [00:26<01:40,  8.58it/s] 10%|█         | 101/966 [00:26<01:40,  8.58it/s] 11%|█         | 102/966 [00:26<01:40,  8.56it/s] 11%|█         | 103/966 [00:26<01:40,  8.56it/s] 11%|█         | 104/966 [00:26<01:40,  8.56it/s] 11%|█         | 105/966 [00:27<01:40,  8.57it/s] 11%|█         | 106/966 [00:27<01:40,  8.56it/s] 11%|█         | 107/966 [00:27<01:40,  8.56it/s] 11%|█         | 108/966 [00:27<01:40,  8.57it/s] 11%|█▏        | 109/966 [00:27<01:39,  8.58it/s] 11%|█▏        | 110/966 [00:27<01:39,  8.58it/s] 11%|█▏        | 111/966 [00:27<01:39,  8.58it/s] 12%|█▏        | 112/966 [00:27<01:39,  8.59it/s] 12%|█▏        | 113/966 [00:28<01:39,  8.59it/s] 12%|█▏        | 114/966 [00:28<01:39,  8.59it/s] 12%|█▏        | 115/966 [00:28<01:39,  8.59it/s] 12%|█▏        | 116/966 [00:28<01:39,  8.57it/s] 12%|█▏        | 117/966 [00:28<01:39,  8.56it/s] 12%|█▏        | 118/966 [00:28<01:38,  8.57it/s] 12%|█▏        | 119/966 [00:28<01:38,  8.57it/s] 12%|█▏        | 120/966 [00:28<01:38,  8.58it/s] 13%|█▎        | 121/966 [00:28<01:38,  8.58it/s] 13%|█▎        | 122/966 [00:29<01:38,  8.59it/s] 13%|█▎        | 123/966 [00:29<01:38,  8.59it/s] 13%|█▎        | 124/966 [00:29<01:38,  8.59it/s] 13%|█▎        | 125/966 [00:29<01:37,  8.60it/s] 13%|█▎        | 126/966 [00:29<01:37,  8.61it/s] 13%|█▎        | 127/966 [00:29<01:37,  8.61it/s] 13%|█▎        | 128/966 [00:29<01:37,  8.62it/s] 13%|█▎        | 129/966 [00:29<01:37,  8.61it/s] 13%|█▎        | 130/966 [00:29<01:37,  8.60it/s] 14%|█▎        | 131/966 [00:30<01:37,  8.57it/s] 14%|█▎        | 132/966 [00:30<01:37,  8.56it/s] 14%|█▍        | 133/966 [00:30<01:37,  8.56it/s] 14%|█▍        | 134/966 [00:30<01:37,  8.56it/s] 14%|█▍        | 135/966 [00:30<01:37,  8.55it/s] 14%|█▍        | 136/966 [00:30<01:37,  8.53it/s] 14%|█▍        | 137/966 [00:30<01:37,  8.54it/s] 14%|█▍        | 138/966 [00:30<01:36,  8.55it/s] 14%|█▍        | 139/966 [00:31<01:36,  8.56it/s] 14%|█▍        | 140/966 [00:31<01:36,  8.56it/s] 15%|█▍        | 141/966 [00:31<01:36,  8.57it/s] 15%|█▍        | 142/966 [00:31<01:36,  8.55it/s] 15%|█▍        | 143/966 [00:31<01:36,  8.54it/s] 15%|█▍        | 144/966 [00:31<01:36,  8.56it/s] 15%|█▌        | 145/966 [00:31<01:35,  8.55it/s] 15%|█▌        | 146/966 [00:31<01:35,  8.55it/s] 15%|█▌        | 147/966 [00:31<01:35,  8.55it/s] 15%|█▌        | 148/966 [00:32<01:35,  8.56it/s] 15%|█▌        | 149/966 [00:32<01:35,  8.57it/s] 16%|█▌        | 150/966 [00:32<01:35,  8.55it/s] 16%|█▌        | 151/966 [00:32<01:35,  8.55it/s] 16%|█▌        | 152/966 [00:32<01:35,  8.55it/s] 16%|█▌        | 153/966 [00:32<01:35,  8.54it/s] 16%|█▌        | 154/966 [00:32<01:34,  8.55it/s] 16%|█▌        | 155/966 [00:32<01:34,  8.57it/s] 16%|█▌        | 156/966 [00:33<01:34,  8.57it/s] 16%|█▋        | 157/966 [00:33<01:34,  8.58it/s] 16%|█▋        | 158/966 [00:33<01:34,  8.58it/s] 16%|█▋        | 159/966 [00:33<01:34,  8.58it/s] 17%|█▋        | 160/966 [00:33<01:34,  8.57it/s] 17%|█▋        | 161/966 [00:33<01:33,  8.57it/s] 17%|█▋        | 162/966 [00:33<01:33,  8.57it/s] 17%|█▋        | 163/966 [00:33<01:33,  8.58it/s] 17%|█▋        | 164/966 [00:33<01:33,  8.60it/s] 17%|█▋        | 165/966 [00:34<01:33,  8.60it/s] 17%|█▋        | 166/966 [00:34<01:33,  8.58it/s] 17%|█▋        | 167/966 [00:34<01:33,  8.55it/s] 17%|█▋        | 168/966 [00:34<01:33,  8.54it/s] 17%|█▋        | 169/966 [00:34<01:33,  8.56it/s] 18%|█▊        | 170/966 [00:34<01:32,  8.58it/s] 18%|█▊        | 171/966 [00:34<01:32,  8.58it/s] 18%|█▊        | 172/966 [00:34<01:32,  8.57it/s] 18%|█▊        | 173/966 [00:35<01:32,  8.53it/s] 18%|█▊        | 174/966 [00:35<01:32,  8.54it/s] 18%|█▊        | 175/966 [00:35<01:32,  8.56it/s] 18%|█▊        | 176/966 [00:35<01:32,  8.59it/s] 18%|█▊        | 177/966 [00:35<01:31,  8.59it/s] 18%|█▊        | 178/966 [00:35<01:31,  8.59it/s] 19%|█▊        | 179/966 [00:35<01:31,  8.59it/s] 19%|█▊        | 180/966 [00:35<01:31,  8.58it/s] 19%|█▊        | 181/966 [00:35<01:31,  8.56it/s] 19%|█▉        | 182/966 [00:36<01:31,  8.57it/s] 19%|█▉        | 183/966 [00:36<01:31,  8.59it/s] 19%|█▉        | 184/966 [00:36<01:31,  8.58it/s] 19%|█▉        | 185/966 [00:36<01:31,  8.56it/s] 19%|█▉        | 186/966 [00:36<01:31,  8.57it/s] 19%|█▉        | 187/966 [00:36<01:31,  8.56it/s] 19%|█▉        | 188/966 [00:36<01:30,  8.55it/s] 20%|█▉        | 189/966 [00:36<01:30,  8.54it/s] 20%|█▉        | 190/966 [00:37<01:30,  8.56it/s] 20%|█▉        | 191/966 [00:37<01:30,  8.56it/s] 20%|█▉        | 192/966 [00:37<01:30,  8.57it/s] 20%|█▉        | 193/966 [00:37<01:30,  8.58it/s] 20%|██        | 194/966 [00:37<01:29,  8.58it/s] 20%|██        | 195/966 [00:37<01:29,  8.57it/s] 20%|██        | 196/966 [00:37<01:29,  8.58it/s] 20%|██        | 197/966 [00:37<01:29,  8.57it/s] 20%|██        | 198/966 [00:37<01:29,  8.56it/s] 21%|██        | 199/966 [00:38<01:29,  8.55it/s] 21%|██        | 200/966 [00:38<01:29,  8.55it/s] 21%|██        | 201/966 [00:38<01:29,  8.56it/s] 21%|██        | 202/966 [00:38<01:29,  8.57it/s] 21%|██        | 203/966 [00:38<01:29,  8.57it/s] 21%|██        | 204/966 [00:38<01:29,  8.56it/s] 21%|██        | 205/966 [00:38<01:28,  8.56it/s] 21%|██▏       | 206/966 [00:38<01:28,  8.59it/s] 21%|██▏       | 207/966 [00:38<01:28,  8.59it/s] 22%|██▏       | 208/966 [00:39<01:28,  8.59it/s] 22%|██▏       | 209/966 [00:39<01:28,  8.59it/s] 22%|██▏       | 210/966 [00:39<01:28,  8.59it/s] 22%|██▏       | 211/966 [00:39<01:27,  8.59it/s] 22%|██▏       | 212/966 [00:39<01:27,  8.61it/s] 22%|██▏       | 213/966 [00:39<01:27,  8.60it/s] 22%|██▏       | 214/966 [00:39<01:27,  8.59it/s] 22%|██▏       | 215/966 [00:39<01:27,  8.58it/s] 22%|██▏       | 216/966 [00:40<01:27,  8.58it/s] 22%|██▏       | 217/966 [00:40<01:27,  8.59it/s] 23%|██▎       | 218/966 [00:40<01:27,  8.58it/s] 23%|██▎       | 219/966 [00:40<01:27,  8.58it/s] 23%|██▎       | 220/966 [00:40<01:26,  8.58it/s] 23%|██▎       | 221/966 [00:40<01:26,  8.58it/s] 23%|██▎       | 222/966 [00:40<01:26,  8.58it/s] 23%|██▎       | 223/966 [00:40<01:26,  8.57it/s] 23%|██▎       | 224/966 [00:40<01:26,  8.57it/s] 23%|██▎       | 225/966 [00:41<01:26,  8.56it/s] 23%|██▎       | 226/966 [00:41<01:26,  8.56it/s] 23%|██▎       | 227/966 [00:41<01:26,  8.55it/s] 24%|██▎       | 228/966 [00:41<01:26,  8.57it/s] 24%|██▎       | 229/966 [00:41<01:25,  8.57it/s] 24%|██▍       | 230/966 [00:41<01:25,  8.58it/s] 24%|██▍       | 231/966 [00:41<01:25,  8.59it/s] 24%|██▍       | 232/966 [00:41<01:25,  8.59it/s] 24%|██▍       | 233/966 [00:42<01:25,  8.58it/s] 24%|██▍       | 234/966 [00:42<01:25,  8.59it/s] 24%|██▍       | 235/966 [00:42<01:25,  8.57it/s] 24%|██▍       | 236/966 [00:42<01:25,  8.57it/s] 25%|██▍       | 237/966 [00:42<01:25,  8.56it/s] 25%|██▍       | 238/966 [00:42<01:24,  8.57it/s] 25%|██▍       | 239/966 [00:42<01:24,  8.55it/s] 25%|██▍       | 240/966 [00:42<01:24,  8.55it/s] 25%|██▍       | 241/966 [00:42<01:24,  8.55it/s] 25%|██▌       | 242/966 [00:43<01:24,  8.56it/s] 25%|██▌       | 243/966 [00:43<01:24,  8.57it/s] 25%|██▌       | 244/966 [00:43<01:24,  8.57it/s] 25%|██▌       | 245/966 [00:43<01:23,  8.58it/s] 25%|██▌       | 246/966 [00:43<01:23,  8.58it/s] 26%|██▌       | 247/966 [00:43<01:23,  8.60it/s] 26%|██▌       | 248/966 [00:43<01:23,  8.57it/s] 26%|██▌       | 249/966 [00:43<01:23,  8.56it/s] 26%|██▌       | 250/966 [00:43<01:23,  8.56it/s] 26%|██▌       | 251/966 [00:44<01:23,  8.54it/s] 26%|██▌       | 252/966 [00:44<01:23,  8.55it/s] 26%|██▌       | 253/966 [00:44<01:23,  8.57it/s] 26%|██▋       | 254/966 [00:44<01:22,  8.59it/s] 26%|██▋       | 255/966 [00:44<01:22,  8.59it/s] 27%|██▋       | 256/966 [00:44<01:22,  8.57it/s] 27%|██▋       | 257/966 [00:44<01:22,  8.56it/s] 27%|██▋       | 258/966 [00:44<01:22,  8.56it/s] 27%|██▋       | 259/966 [00:45<01:22,  8.56it/s] 27%|██▋       | 260/966 [00:45<01:22,  8.57it/s] 27%|██▋       | 261/966 [00:45<01:22,  8.58it/s] 27%|██▋       | 262/966 [00:45<01:22,  8.57it/s] 27%|██▋       | 263/966 [00:45<01:22,  8.56it/s] 27%|██▋       | 264/966 [00:45<01:21,  8.57it/s] 27%|██▋       | 265/966 [00:45<01:21,  8.57it/s] 28%|██▊       | 266/966 [00:45<01:21,  8.57it/s] 28%|██▊       | 267/966 [00:45<01:21,  8.57it/s] 28%|██▊       | 268/966 [00:46<01:21,  8.55it/s] 28%|██▊       | 269/966 [00:46<01:21,  8.54it/s] 28%|██▊       | 270/966 [00:46<01:21,  8.55it/s] 28%|██▊       | 271/966 [00:46<01:21,  8.55it/s] 28%|██▊       | 272/966 [00:46<01:21,  8.56it/s] 28%|██▊       | 273/966 [00:46<01:20,  8.57it/s] 28%|██▊       | 274/966 [00:46<01:20,  8.56it/s] 28%|██▊       | 275/966 [00:46<01:20,  8.54it/s] 29%|██▊       | 276/966 [00:47<01:20,  8.54it/s] 29%|██▊       | 277/966 [00:47<01:20,  8.54it/s] 29%|██▉       | 278/966 [00:47<01:20,  8.54it/s] 29%|██▉       | 279/966 [00:47<01:20,  8.56it/s] 29%|██▉       | 280/966 [00:47<01:20,  8.56it/s] 29%|██▉       | 281/966 [00:47<01:20,  8.56it/s] 29%|██▉       | 282/966 [00:47<01:19,  8.57it/s] 29%|██▉       | 283/966 [00:47<01:19,  8.56it/s] 29%|██▉       | 284/966 [00:47<01:19,  8.56it/s] 30%|██▉       | 285/966 [00:48<01:19,  8.57it/s] 30%|██▉       | 286/966 [00:48<01:19,  8.57it/s] 30%|██▉       | 287/966 [00:48<01:19,  8.56it/s] 30%|██▉       | 288/966 [00:48<01:19,  8.56it/s] 30%|██▉       | 289/966 [00:48<01:19,  8.56it/s] 30%|███       | 290/966 [00:48<01:19,  8.55it/s] 30%|███       | 291/966 [00:48<01:18,  8.55it/s] 30%|███       | 292/966 [00:48<01:18,  8.55it/s] 30%|███       | 293/966 [00:49<01:18,  8.54it/s] 30%|███       | 294/966 [00:49<01:18,  8.53it/s] 31%|███       | 295/966 [00:49<01:18,  8.54it/s] 31%|███       | 296/966 [00:49<01:18,  8.55it/s] 31%|███       | 297/966 [00:49<01:18,  8.57it/s] 31%|███       | 298/966 [00:49<01:17,  8.57it/s] 31%|███       | 299/966 [00:49<01:17,  8.57it/s] 31%|███       | 300/966 [00:49<01:17,  8.56it/s] 31%|███       | 301/966 [00:49<01:17,  8.57it/s] 31%|███▏      | 302/966 [00:50<01:17,  8.58it/s] 31%|███▏      | 303/966 [00:50<01:17,  8.58it/s] 31%|███▏      | 304/966 [00:50<01:17,  8.57it/s] 32%|███▏      | 305/966 [00:50<01:17,  8.55it/s] 32%|███▏      | 306/966 [00:50<01:17,  8.53it/s] 32%|███▏      | 307/966 [00:50<01:17,  8.53it/s] 32%|███▏      | 308/966 [00:50<01:17,  8.52it/s] 32%|███▏      | 309/966 [00:50<01:17,  8.52it/s] 32%|███▏      | 310/966 [00:51<01:16,  8.52it/s] 32%|███▏      | 311/966 [00:51<01:16,  8.52it/s] 32%|███▏      | 312/966 [00:51<01:16,  8.52it/s] 32%|███▏      | 313/966 [00:51<01:16,  8.53it/s] 33%|███▎      | 314/966 [00:51<01:16,  8.53it/s] 33%|███▎      | 315/966 [00:51<01:16,  8.52it/s] 33%|███▎      | 316/966 [00:51<01:16,  8.53it/s] 33%|███▎      | 317/966 [00:51<01:16,  8.53it/s] 33%|███▎      | 318/966 [00:51<01:16,  8.52it/s] 33%|███▎      | 319/966 [00:52<01:16,  8.51it/s] 33%|███▎      | 320/966 [00:52<01:15,  8.50it/s] 33%|███▎      | 321/966 [00:52<01:15,  8.50it/s] 33%|███▎      | 322/966 [00:52<01:15,  8.51it/s] 33%|███▎      | 323/966 [00:52<01:15,  8.49it/s] 34%|███▎      | 324/966 [00:52<01:15,  8.50it/s] 34%|███▎      | 325/966 [00:52<01:15,  8.50it/s] 34%|███▎      | 326/966 [00:52<01:15,  8.51it/s] 34%|███▍      | 327/966 [00:53<01:15,  8.52it/s] 34%|███▍      | 328/966 [00:53<01:14,  8.53it/s] 34%|███▍      | 329/966 [00:53<01:14,  8.54it/s] 34%|███▍      | 330/966 [00:53<01:14,  8.55it/s] 34%|███▍      | 331/966 [00:53<01:14,  8.58it/s] 34%|███▍      | 332/966 [00:53<01:14,  8.57it/s] 34%|███▍      | 333/966 [00:53<01:14,  8.55it/s] 35%|███▍      | 334/966 [00:53<01:13,  8.56it/s] 35%|███▍      | 335/966 [00:53<01:13,  8.57it/s] 35%|███▍      | 336/966 [00:54<01:13,  8.56it/s] 35%|███▍      | 337/966 [00:54<01:13,  8.57it/s] 35%|███▍      | 338/966 [00:54<01:13,  8.59it/s] 35%|███▌      | 339/966 [00:54<01:13,  8.57it/s] 35%|███▌      | 340/966 [00:54<01:13,  8.57it/s] 35%|███▌      | 341/966 [00:54<01:13,  8.56it/s] 35%|███▌      | 342/966 [00:54<01:12,  8.55it/s] 36%|███▌      | 343/966 [00:54<01:12,  8.57it/s] 36%|███▌      | 344/966 [00:54<01:12,  8.58it/s] 36%|███▌      | 345/966 [00:55<01:12,  8.57it/s] 36%|███▌      | 346/966 [00:55<01:12,  8.55it/s] 36%|███▌      | 347/966 [00:55<01:12,  8.54it/s] 36%|███▌      | 348/966 [00:55<01:12,  8.54it/s] 36%|███▌      | 349/966 [00:55<01:12,  8.55it/s] 36%|███▌      | 350/966 [00:55<01:11,  8.57it/s] 36%|███▋      | 351/966 [00:55<01:11,  8.58it/s] 36%|███▋      | 352/966 [00:55<01:11,  8.57it/s] 37%|███▋      | 353/966 [00:56<01:11,  8.56it/s] 37%|███▋      | 354/966 [00:56<01:11,  8.54it/s] 37%|███▋      | 355/966 [00:56<01:11,  8.55it/s] 37%|███▋      | 356/966 [00:56<01:11,  8.53it/s] 37%|███▋      | 357/966 [00:56<01:11,  8.51it/s] 37%|███▋      | 358/966 [00:56<01:11,  8.52it/s] 37%|███▋      | 359/966 [00:56<01:11,  8.54it/s] 37%|███▋      | 360/966 [00:56<01:10,  8.55it/s] 37%|███▋      | 361/966 [00:56<01:10,  8.54it/s] 37%|███▋      | 362/966 [00:57<01:10,  8.53it/s] 38%|███▊      | 363/966 [00:57<01:10,  8.54it/s] 38%|███▊      | 364/966 [00:57<01:10,  8.53it/s] 38%|███▊      | 365/966 [00:57<01:10,  8.53it/s] 38%|███▊      | 366/966 [00:57<01:10,  8.53it/s] 38%|███▊      | 367/966 [00:57<01:10,  8.51it/s] 38%|███▊      | 368/966 [00:57<01:10,  8.53it/s] 38%|███▊      | 369/966 [00:57<01:09,  8.53it/s] 38%|███▊      | 370/966 [00:58<01:09,  8.53it/s] 38%|███▊      | 371/966 [00:58<01:09,  8.52it/s] 39%|███▊      | 372/966 [00:58<01:09,  8.52it/s] 39%|███▊      | 373/966 [00:58<01:09,  8.53it/s] 39%|███▊      | 374/966 [00:58<01:09,  8.51it/s] 39%|███▉      | 375/966 [00:58<01:09,  8.54it/s] 39%|███▉      | 376/966 [00:58<01:09,  8.55it/s] 39%|███▉      | 377/966 [00:58<01:08,  8.54it/s] 39%|███▉      | 378/966 [00:58<01:08,  8.55it/s] 39%|███▉      | 379/966 [00:59<01:08,  8.57it/s] 39%|███▉      | 380/966 [00:59<01:08,  8.58it/s] 39%|███▉      | 381/966 [00:59<01:08,  8.59it/s] 40%|███▉      | 382/966 [00:59<01:07,  8.59it/s] 40%|███▉      | 383/966 [00:59<01:07,  8.58it/s] 40%|███▉      | 384/966 [00:59<01:07,  8.57it/s] 40%|███▉      | 385/966 [00:59<01:07,  8.55it/s] 40%|███▉      | 386/966 [00:59<01:07,  8.54it/s] 40%|████      | 387/966 [01:00<01:07,  8.52it/s] 40%|████      | 388/966 [01:00<01:07,  8.53it/s] 40%|████      | 389/966 [01:00<01:07,  8.55it/s] 40%|████      | 390/966 [01:00<01:07,  8.55it/s] 40%|████      | 391/966 [01:00<01:07,  8.55it/s] 41%|████      | 392/966 [01:00<01:07,  8.54it/s] 41%|████      | 393/966 [01:00<01:07,  8.53it/s] 41%|████      | 394/966 [01:00<01:07,  8.52it/s] 41%|████      | 395/966 [01:00<01:07,  8.51it/s] 41%|████      | 396/966 [01:01<01:06,  8.52it/s] 41%|████      | 397/966 [01:01<01:06,  8.55it/s] 41%|████      | 398/966 [01:01<01:06,  8.53it/s] 41%|████▏     | 399/966 [01:01<01:06,  8.54it/s] 41%|████▏     | 400/966 [01:01<01:06,  8.52it/s] 42%|████▏     | 401/966 [01:01<01:06,  8.52it/s] 42%|████▏     | 402/966 [01:01<01:06,  8.52it/s] 42%|████▏     | 403/966 [01:01<01:06,  8.52it/s] 42%|████▏     | 404/966 [01:02<01:05,  8.55it/s] 42%|████▏     | 405/966 [01:02<01:05,  8.56it/s] 42%|████▏     | 406/966 [01:02<01:05,  8.54it/s] 42%|████▏     | 407/966 [01:02<01:05,  8.54it/s] 42%|████▏     | 408/966 [01:02<01:05,  8.54it/s] 42%|████▏     | 409/966 [01:02<01:05,  8.54it/s] 42%|████▏     | 410/966 [01:02<01:05,  8.55it/s] 43%|████▎     | 411/966 [01:02<01:04,  8.55it/s] 43%|████▎     | 412/966 [01:02<01:04,  8.55it/s] 43%|████▎     | 413/966 [01:03<01:04,  8.55it/s] 43%|████▎     | 414/966 [01:03<01:04,  8.52it/s] 43%|████▎     | 415/966 [01:03<01:04,  8.52it/s] 43%|████▎     | 416/966 [01:03<01:04,  8.54it/s] 43%|████▎     | 417/966 [01:03<01:04,  8.55it/s] 43%|████▎     | 418/966 [01:03<01:04,  8.56it/s] 43%|████▎     | 419/966 [01:03<01:04,  8.54it/s] 43%|████▎     | 420/966 [01:03<01:03,  8.56it/s] 44%|████▎     | 421/966 [01:04<01:03,  8.57it/s] 44%|████▎     | 422/966 [01:04<01:03,  8.55it/s] 44%|████▍     | 423/966 [01:04<01:03,  8.55it/s] 44%|████▍     | 424/966 [01:04<01:03,  8.54it/s] 44%|████▍     | 425/966 [01:04<01:03,  8.55it/s] 44%|████▍     | 426/966 [01:04<01:03,  8.55it/s] 44%|████▍     | 427/966 [01:04<01:03,  8.55it/s] 44%|████▍     | 428/966 [01:04<01:02,  8.56it/s] 44%|████▍     | 429/966 [01:04<01:02,  8.55it/s] 45%|████▍     | 430/966 [01:05<01:02,  8.56it/s] 45%|████▍     | 431/966 [01:05<01:02,  8.55it/s] 45%|████▍     | 432/966 [01:05<01:02,  8.57it/s] 45%|████▍     | 433/966 [01:05<01:02,  8.56it/s] 45%|████▍     | 434/966 [01:05<01:02,  8.56it/s] 45%|████▌     | 435/966 [01:05<01:02,  8.55it/s] 45%|████▌     | 436/966 [01:05<01:02,  8.54it/s] 45%|████▌     | 437/966 [01:05<01:01,  8.55it/s] 45%|████▌     | 438/966 [01:05<01:01,  8.55it/s] 45%|████▌     | 439/966 [01:06<01:01,  8.53it/s] 46%|████▌     | 440/966 [01:06<01:01,  8.53it/s] 46%|████▌     | 441/966 [01:06<01:01,  8.53it/s] 46%|████▌     | 442/966 [01:06<01:01,  8.54it/s] 46%|████▌     | 443/966 [01:06<01:01,  8.53it/s] 46%|████▌     | 444/966 [01:06<01:01,  8.54it/s] 46%|████▌     | 445/966 [01:06<01:00,  8.54it/s] 46%|████▌     | 446/966 [01:06<01:00,  8.53it/s] 46%|████▋     | 447/966 [01:07<01:00,  8.51it/s] 46%|████▋     | 448/966 [01:07<01:00,  8.50it/s] 46%|████▋     | 449/966 [01:07<01:00,  8.51it/s] 47%|████▋     | 450/966 [01:07<01:00,  8.52it/s] 47%|████▋     | 451/966 [01:07<01:00,  8.52it/s] 47%|████▋     | 452/966 [01:07<01:00,  8.52it/s] 47%|████▋     | 453/966 [01:07<01:00,  8.53it/s] 47%|████▋     | 454/966 [01:07<01:00,  8.53it/s] 47%|████▋     | 455/966 [01:07<00:59,  8.53it/s] 47%|████▋     | 456/966 [01:08<00:59,  8.53it/s] 47%|████▋     | 457/966 [01:08<00:59,  8.54it/s] 47%|████▋     | 458/966 [01:08<00:59,  8.55it/s] 48%|████▊     | 459/966 [01:08<00:59,  8.54it/s] 48%|████▊     | 460/966 [01:08<00:59,  8.55it/s] 48%|████▊     | 461/966 [01:08<00:59,  8.55it/s] 48%|████▊     | 462/966 [01:08<00:58,  8.56it/s] 48%|████▊     | 463/966 [01:08<00:58,  8.57it/s] 48%|████▊     | 464/966 [01:09<00:58,  8.57it/s] 48%|████▊     | 465/966 [01:09<00:58,  8.55it/s] 48%|████▊     | 466/966 [01:09<00:58,  8.52it/s] 48%|████▊     | 467/966 [01:09<00:58,  8.51it/s] 48%|████▊     | 468/966 [01:09<00:58,  8.51it/s] 49%|████▊     | 469/966 [01:09<00:58,  8.52it/s] 49%|████▊     | 470/966 [01:09<00:58,  8.52it/s] 49%|████▉     | 471/966 [01:09<00:58,  8.51it/s] 49%|████▉     | 472/966 [01:09<00:57,  8.53it/s] 49%|████▉     | 473/966 [01:10<00:57,  8.53it/s] 49%|████▉     | 474/966 [01:10<00:57,  8.53it/s] 49%|████▉     | 475/966 [01:10<00:57,  8.55it/s] 49%|████▉     | 476/966 [01:10<00:57,  8.53it/s] 49%|████▉     | 477/966 [01:10<00:57,  8.52it/s] 49%|████▉     | 478/966 [01:10<00:57,  8.52it/s] 50%|████▉     | 479/966 [01:10<00:56,  8.55it/s] 50%|████▉     | 480/966 [01:10<00:56,  8.55it/s] 50%|████▉     | 481/966 [01:11<00:56,  8.54it/s] 50%|████▉     | 482/966 [01:11<00:56,  8.55it/s] 50%|█████     | 483/966 [01:11<00:56,  8.56it/s] 50%|█████     | 484/966 [01:11<00:56,  8.55it/s] 50%|█████     | 485/966 [01:11<00:56,  8.54it/s] 50%|█████     | 486/966 [01:11<00:56,  8.56it/s] 50%|█████     | 487/966 [01:11<00:55,  8.56it/s] 51%|█████     | 488/966 [01:11<00:55,  8.55it/s] 51%|█████     | 489/966 [01:11<00:55,  8.53it/s] 51%|█████     | 490/966 [01:12<00:55,  8.53it/s] 51%|█████     | 491/966 [01:12<00:55,  8.51it/s] 51%|█████     | 492/966 [01:12<00:55,  8.51it/s] 51%|█████     | 493/966 [01:12<00:55,  8.51it/s] 51%|█████     | 494/966 [01:12<00:55,  8.51it/s] 51%|█████     | 495/966 [01:12<00:55,  8.52it/s] 51%|█████▏    | 496/966 [01:12<00:55,  8.53it/s] 51%|█████▏    | 497/966 [01:12<00:54,  8.55it/s] 52%|█████▏    | 498/966 [01:13<00:54,  8.54it/s] 52%|█████▏    | 499/966 [01:13<00:54,  8.54it/s] 52%|█████▏    | 500/966 [01:13<00:54,  8.52it/s] 52%|█████▏    | 501/966 [01:13<00:54,  8.55it/s] 52%|█████▏    | 502/966 [01:13<00:54,  8.55it/s] 52%|█████▏    | 503/966 [01:13<00:54,  8.55it/s] 52%|█████▏    | 504/966 [01:13<00:54,  8.55it/s] 52%|█████▏    | 505/966 [01:13<00:53,  8.57it/s] 52%|█████▏    | 506/966 [01:13<00:53,  8.58it/s] 52%|█████▏    | 507/966 [01:14<00:53,  8.57it/s] 53%|█████▎    | 508/966 [01:14<00:53,  8.56it/s] 53%|█████▎    | 509/966 [01:14<00:53,  8.55it/s] 53%|█████▎    | 510/966 [01:14<00:53,  8.55it/s] 53%|█████▎    | 511/966 [01:14<00:53,  8.56it/s] 53%|█████▎    | 512/966 [01:14<00:52,  8.57it/s] 53%|█████▎    | 513/966 [01:14<00:52,  8.57it/s] 53%|█████▎    | 514/966 [01:14<00:52,  8.56it/s] 53%|█████▎    | 515/966 [01:15<00:52,  8.56it/s] 53%|█████▎    | 516/966 [01:15<00:52,  8.54it/s] 54%|█████▎    | 517/966 [01:15<00:52,  8.53it/s] 54%|█████▎    | 518/966 [01:15<00:52,  8.52it/s] 54%|█████▎    | 519/966 [01:15<00:52,  8.54it/s] 54%|█████▍    | 520/966 [01:15<00:52,  8.54it/s] 54%|█████▍    | 521/966 [01:15<00:52,  8.52it/s] 54%|█████▍    | 522/966 [01:15<00:52,  8.51it/s] 54%|█████▍    | 523/966 [01:15<00:52,  8.50it/s] 54%|█████▍    | 524/966 [01:16<00:51,  8.50it/s] 54%|█████▍    | 525/966 [01:16<00:51,  8.51it/s] 54%|█████▍    | 526/966 [01:16<00:51,  8.51it/s] 55%|█████▍    | 527/966 [01:16<00:51,  8.51it/s] 55%|█████▍    | 528/966 [01:16<00:51,  8.53it/s] 55%|█████▍    | 529/966 [01:16<00:51,  8.54it/s] 55%|█████▍    | 530/966 [01:16<00:51,  8.54it/s] 55%|█████▍    | 531/966 [01:16<00:51,  8.53it/s] 55%|█████▌    | 532/966 [01:17<00:50,  8.53it/s] 55%|█████▌    | 533/966 [01:17<00:50,  8.53it/s] 55%|█████▌    | 534/966 [01:17<00:50,  8.53it/s] 55%|█████▌    | 535/966 [01:17<00:50,  8.54it/s] 55%|█████▌    | 536/966 [01:17<00:50,  8.54it/s] 56%|█████▌    | 537/966 [01:17<00:50,  8.55it/s] 56%|█████▌    | 538/966 [01:17<00:50,  8.55it/s] 56%|█████▌    | 539/966 [01:17<00:49,  8.54it/s] 56%|█████▌    | 540/966 [01:17<00:49,  8.54it/s] 56%|█████▌    | 541/966 [01:18<00:49,  8.55it/s] 56%|█████▌    | 542/966 [01:18<00:49,  8.55it/s] 56%|█████▌    | 543/966 [01:18<00:49,  8.55it/s] 56%|█████▋    | 544/966 [01:18<00:49,  8.55it/s] 56%|█████▋    | 545/966 [01:18<00:49,  8.55it/s] 57%|█████▋    | 546/966 [01:18<00:49,  8.56it/s] 57%|█████▋    | 547/966 [01:18<00:48,  8.57it/s] 57%|█████▋    | 548/966 [01:18<00:48,  8.57it/s] 57%|█████▋    | 549/966 [01:18<00:48,  8.56it/s] 57%|█████▋    | 550/966 [01:19<00:48,  8.56it/s] 57%|█████▋    | 551/966 [01:19<00:48,  8.56it/s] 57%|█████▋    | 552/966 [01:19<00:48,  8.57it/s] 57%|█████▋    | 553/966 [01:19<00:48,  8.56it/s] 57%|█████▋    | 554/966 [01:19<00:48,  8.57it/s] 57%|█████▋    | 555/966 [01:19<00:48,  8.55it/s] 58%|█████▊    | 556/966 [01:19<00:47,  8.55it/s] 58%|█████▊    | 557/966 [01:19<00:47,  8.56it/s] 58%|█████▊    | 558/966 [01:20<00:47,  8.56it/s] 58%|█████▊    | 559/966 [01:20<00:47,  8.55it/s] 58%|█████▊    | 560/966 [01:20<00:47,  8.55it/s] 58%|█████▊    | 561/966 [01:20<00:47,  8.55it/s] 58%|█████▊    | 562/966 [01:20<00:47,  8.53it/s] 58%|█████▊    | 563/966 [01:20<00:47,  8.52it/s] 58%|█████▊    | 564/966 [01:20<00:47,  8.52it/s] 58%|█████▊    | 565/966 [01:20<00:47,  8.52it/s] 59%|█████▊    | 566/966 [01:20<00:46,  8.52it/s] 59%|█████▊    | 567/966 [01:21<00:46,  8.52it/s] 59%|█████▉    | 568/966 [01:21<00:46,  8.52it/s] 59%|█████▉    | 569/966 [01:21<00:46,  8.52it/s] 59%|█████▉    | 570/966 [01:21<00:46,  8.52it/s] 59%|█████▉    | 571/966 [01:21<00:46,  8.52it/s] 59%|█████▉    | 572/966 [01:21<00:46,  8.52it/s] 59%|█████▉    | 573/966 [01:21<00:46,  8.53it/s] 59%|█████▉    | 574/966 [01:21<00:45,  8.54it/s] 60%|█████▉    | 575/966 [01:22<00:45,  8.54it/s] 60%|█████▉    | 576/966 [01:22<00:45,  8.53it/s] 60%|█████▉    | 577/966 [01:22<00:45,  8.53it/s] 60%|█████▉    | 578/966 [01:22<00:45,  8.52it/s] 60%|█████▉    | 579/966 [01:22<00:45,  8.51it/s] 60%|██████    | 580/966 [01:22<00:45,  8.52it/s] 60%|██████    | 581/966 [01:22<00:45,  8.53it/s] 60%|██████    | 582/966 [01:22<00:44,  8.55it/s] 60%|██████    | 583/966 [01:22<00:44,  8.57it/s] 60%|██████    | 584/966 [01:23<00:44,  8.57it/s] 61%|██████    | 585/966 [01:23<00:44,  8.56it/s] 61%|██████    | 586/966 [01:23<00:44,  8.55it/s] 61%|██████    | 587/966 [01:23<00:44,  8.57it/s] 61%|██████    | 588/966 [01:23<00:44,  8.56it/s] 61%|██████    | 589/966 [01:23<00:43,  8.58it/s] 61%|██████    | 590/966 [01:23<00:43,  8.58it/s] 61%|██████    | 591/966 [01:23<00:43,  8.57it/s] 61%|██████▏   | 592/966 [01:24<00:43,  8.55it/s] 61%|██████▏   | 593/966 [01:24<00:43,  8.55it/s] 61%|██████▏   | 594/966 [01:24<00:43,  8.54it/s] 62%|██████▏   | 595/966 [01:24<00:43,  8.54it/s] 62%|██████▏   | 596/966 [01:24<00:43,  8.54it/s] 62%|██████▏   | 597/966 [01:24<00:43,  8.53it/s] 62%|██████▏   | 598/966 [01:24<00:43,  8.50it/s] 62%|██████▏   | 599/966 [01:24<00:43,  8.51it/s] 62%|██████▏   | 600/966 [01:24<00:42,  8.51it/s] 62%|██████▏   | 601/966 [01:25<00:42,  8.52it/s] 62%|██████▏   | 602/966 [01:25<00:42,  8.52it/s] 62%|██████▏   | 603/966 [01:25<00:42,  8.53it/s] 63%|██████▎   | 604/966 [01:25<00:42,  8.53it/s] 63%|██████▎   | 605/966 [01:25<00:42,  8.50it/s] 63%|██████▎   | 606/966 [01:25<00:42,  8.52it/s] 63%|██████▎   | 607/966 [01:25<00:42,  8.52it/s] 63%|██████▎   | 608/966 [01:25<00:42,  8.52it/s] 63%|██████▎   | 609/966 [01:26<00:41,  8.52it/s] 63%|██████▎   | 610/966 [01:26<00:41,  8.52it/s] 63%|██████▎   | 611/966 [01:26<00:41,  8.51it/s] 63%|██████▎   | 612/966 [01:26<00:41,  8.52it/s] 63%|██████▎   | 613/966 [01:26<00:41,  8.52it/s] 64%|██████▎   | 614/966 [01:26<00:41,  8.52it/s] 64%|██████▎   | 615/966 [01:26<00:41,  8.52it/s] 64%|██████▍   | 616/966 [01:26<00:41,  8.53it/s] 64%|██████▍   | 617/966 [01:26<00:40,  8.53it/s] 64%|██████▍   | 618/966 [01:27<00:40,  8.52it/s] 64%|██████▍   | 619/966 [01:27<00:40,  8.52it/s] 64%|██████▍   | 620/966 [01:27<00:40,  8.52it/s] 64%|██████▍   | 621/966 [01:27<00:40,  8.54it/s] 64%|██████▍   | 622/966 [01:27<00:40,  8.54it/s] 64%|██████▍   | 623/966 [01:27<00:40,  8.53it/s] 65%|██████▍   | 624/966 [01:27<00:40,  8.53it/s] 65%|██████▍   | 625/966 [01:27<00:39,  8.53it/s] 65%|██████▍   | 626/966 [01:28<00:39,  8.53it/s] 65%|██████▍   | 627/966 [01:28<00:39,  8.53it/s] 65%|██████▌   | 628/966 [01:28<00:39,  8.50it/s] 65%|██████▌   | 629/966 [01:28<00:39,  8.50it/s] 65%|██████▌   | 630/966 [01:28<00:39,  8.51it/s] 65%|██████▌   | 631/966 [01:28<00:39,  8.52it/s] 65%|██████▌   | 632/966 [01:28<00:39,  8.54it/s] 66%|██████▌   | 633/966 [01:28<00:38,  8.54it/s] 66%|██████▌   | 634/966 [01:28<00:38,  8.54it/s] 66%|██████▌   | 635/966 [01:29<00:38,  8.53it/s] 66%|██████▌   | 636/966 [01:29<00:38,  8.53it/s] 66%|██████▌   | 637/966 [01:29<00:38,  8.53it/s] 66%|██████▌   | 638/966 [01:29<00:38,  8.54it/s] 66%|██████▌   | 639/966 [01:29<00:38,  8.53it/s] 66%|██████▋   | 640/966 [01:29<00:38,  8.53it/s] 66%|██████▋   | 641/966 [01:29<00:38,  8.52it/s] 66%|██████▋   | 642/966 [01:29<00:37,  8.53it/s] 67%|██████▋   | 643/966 [01:30<00:37,  8.52it/s] 67%|██████▋   | 644/966 [01:30<00:37,  8.52it/s] 67%|██████▋   | 645/966 [01:30<00:37,  8.53it/s] 67%|██████▋   | 646/966 [01:30<00:37,  8.54it/s] 67%|██████▋   | 647/966 [01:30<00:37,  8.53it/s] 67%|██████▋   | 648/966 [01:30<00:37,  8.54it/s] 67%|██████▋   | 649/966 [01:30<00:37,  8.54it/s] 67%|██████▋   | 650/966 [01:30<00:37,  8.53it/s] 67%|██████▋   | 651/966 [01:30<00:36,  8.53it/s] 67%|██████▋   | 652/966 [01:31<00:36,  8.52it/s] 68%|██████▊   | 653/966 [01:31<00:36,  8.51it/s] 68%|██████▊   | 654/966 [01:31<00:36,  8.51it/s] 68%|██████▊   | 655/966 [01:31<00:36,  8.51it/s] 68%|██████▊   | 656/966 [01:31<00:36,  8.52it/s] 68%|██████▊   | 657/966 [01:31<00:36,  8.52it/s] 68%|██████▊   | 658/966 [01:31<00:36,  8.53it/s] 68%|██████▊   | 659/966 [01:31<00:35,  8.53it/s] 68%|██████▊   | 660/966 [01:32<00:35,  8.53it/s] 68%|██████▊   | 661/966 [01:32<00:35,  8.53it/s] 69%|██████▊   | 662/966 [01:32<00:35,  8.52it/s] 69%|██████▊   | 663/966 [01:32<00:35,  8.52it/s] 69%|██████▊   | 664/966 [01:32<00:35,  8.52it/s] 69%|██████▉   | 665/966 [01:32<00:35,  8.52it/s] 69%|██████▉   | 666/966 [01:32<00:35,  8.54it/s] 69%|██████▉   | 667/966 [01:32<00:34,  8.55it/s] 69%|██████▉   | 668/966 [01:32<00:34,  8.55it/s] 69%|██████▉   | 669/966 [01:33<00:34,  8.53it/s] 69%|██████▉   | 670/966 [01:33<00:34,  8.53it/s] 69%|██████▉   | 671/966 [01:33<00:34,  8.53it/s] 70%|██████▉   | 672/966 [01:33<00:34,  8.55it/s] 70%|██████▉   | 673/966 [01:33<00:34,  8.56it/s] 70%|██████▉   | 674/966 [01:33<00:34,  8.57it/s] 70%|██████▉   | 675/966 [01:33<00:33,  8.57it/s] 70%|██████▉   | 676/966 [01:33<00:33,  8.55it/s] 70%|███████   | 677/966 [01:33<00:33,  8.54it/s] 70%|███████   | 678/966 [01:34<00:33,  8.54it/s] 70%|███████   | 679/966 [01:34<00:33,  8.55it/s] 70%|███████   | 680/966 [01:34<00:33,  8.54it/s] 70%|███████   | 681/966 [01:34<00:33,  8.55it/s] 71%|███████   | 682/966 [01:34<00:33,  8.56it/s] 71%|███████   | 683/966 [01:34<00:33,  8.55it/s] 71%|███████   | 684/966 [01:34<00:32,  8.55it/s] 71%|███████   | 685/966 [01:34<00:32,  8.55it/s] 71%|███████   | 686/966 [01:35<00:32,  8.55it/s] 71%|███████   | 687/966 [01:35<00:32,  8.56it/s] 71%|███████   | 688/966 [01:35<00:32,  8.54it/s] 71%|███████▏  | 689/966 [01:35<00:32,  8.52it/s] 71%|███████▏  | 690/966 [01:35<00:32,  8.52it/s] 72%|███████▏  | 691/966 [01:35<00:32,  8.53it/s] 72%|███████▏  | 692/966 [01:35<00:32,  8.53it/s] 72%|███████▏  | 693/966 [01:35<00:32,  8.51it/s] 72%|███████▏  | 694/966 [01:35<00:32,  8.49it/s] 72%|███████▏  | 695/966 [01:36<00:31,  8.49it/s] 72%|███████▏  | 696/966 [01:36<00:31,  8.49it/s] 72%|███████▏  | 697/966 [01:36<00:31,  8.51it/s] 72%|███████▏  | 698/966 [01:36<00:31,  8.52it/s] 72%|███████▏  | 699/966 [01:36<00:31,  8.50it/s] 72%|███████▏  | 700/966 [01:36<00:31,  8.47it/s] 73%|███████▎  | 701/966 [01:36<00:31,  8.47it/s] 73%|███████▎  | 702/966 [01:36<00:31,  8.48it/s] 73%|███████▎  | 703/966 [01:37<00:30,  8.49it/s] 73%|███████▎  | 704/966 [01:37<00:30,  8.51it/s] 73%|███████▎  | 705/966 [01:37<00:30,  8.52it/s] 73%|███████▎  | 706/966 [01:37<00:30,  8.52it/s] 73%|███████▎  | 707/966 [01:37<00:30,  8.52it/s] 73%|███████▎  | 708/966 [01:37<00:30,  8.52it/s] 73%|███████▎  | 709/966 [01:37<00:30,  8.53it/s] 73%|███████▎  | 710/966 [01:37<00:29,  8.54it/s] 74%|███████▎  | 711/966 [01:37<00:29,  8.54it/s] 74%|███████▎  | 712/966 [01:38<00:29,  8.53it/s] 74%|███████▍  | 713/966 [01:38<00:29,  8.53it/s] 74%|███████▍  | 714/966 [01:38<00:29,  8.53it/s] 74%|███████▍  | 715/966 [01:38<00:29,  8.55it/s] 74%|███████▍  | 716/966 [01:38<00:29,  8.56it/s] 74%|███████▍  | 717/966 [01:38<00:29,  8.57it/s] 74%|███████▍  | 718/966 [01:38<00:28,  8.56it/s] 74%|███████▍  | 719/966 [01:38<00:28,  8.55it/s] 75%|███████▍  | 720/966 [01:39<00:28,  8.54it/s] 75%|███████▍  | 721/966 [01:39<00:28,  8.54it/s] 75%|███████▍  | 722/966 [01:39<00:28,  8.53it/s] 75%|███████▍  | 723/966 [01:39<00:28,  8.52it/s] 75%|███████▍  | 724/966 [01:39<00:28,  8.52it/s] 75%|███████▌  | 725/966 [01:39<00:28,  8.54it/s] 75%|███████▌  | 726/966 [01:39<00:28,  8.56it/s] 75%|███████▌  | 727/966 [01:39<00:27,  8.55it/s] 75%|███████▌  | 728/966 [01:39<00:27,  8.55it/s] 75%|███████▌  | 729/966 [01:40<00:27,  8.53it/s] 76%|███████▌  | 730/966 [01:40<00:27,  8.53it/s] 76%|███████▌  | 731/966 [01:40<00:27,  8.52it/s] 76%|███████▌  | 732/966 [01:40<00:27,  8.52it/s] 76%|███████▌  | 733/966 [01:40<00:27,  8.52it/s] 76%|███████▌  | 734/966 [01:40<00:27,  8.52it/s] 76%|███████▌  | 735/966 [01:40<00:27,  8.53it/s] 76%|███████▌  | 736/966 [01:40<00:26,  8.54it/s] 76%|███████▋  | 737/966 [01:41<00:26,  8.53it/s] 76%|███████▋  | 738/966 [01:41<00:26,  8.52it/s] 77%|███████▋  | 739/966 [01:41<00:26,  8.51it/s] 77%|███████▋  | 740/966 [01:41<00:26,  8.50it/s] 77%|███████▋  | 741/966 [01:41<00:26,  8.49it/s] 77%|███████▋  | 742/966 [01:41<00:26,  8.48it/s] 77%|███████▋  | 743/966 [01:41<00:26,  8.47it/s] 77%|███████▋  | 744/966 [01:41<00:26,  8.48it/s] 77%|███████▋  | 745/966 [01:41<00:26,  8.50it/s] 77%|███████▋  | 746/966 [01:42<00:25,  8.50it/s] 77%|███████▋  | 747/966 [01:42<00:25,  8.52it/s] 77%|███████▋  | 748/966 [01:42<00:25,  8.53it/s] 78%|███████▊  | 749/966 [01:42<00:25,  8.53it/s] 78%|███████▊  | 750/966 [01:42<00:25,  8.53it/s] 78%|███████▊  | 751/966 [01:42<00:25,  8.53it/s] 78%|███████▊  | 752/966 [01:42<00:25,  8.53it/s] 78%|███████▊  | 753/966 [01:42<00:25,  8.51it/s] 78%|███████▊  | 754/966 [01:43<00:24,  8.52it/s] 78%|███████▊  | 755/966 [01:43<00:24,  8.52it/s] 78%|███████▊  | 756/966 [01:43<00:24,  8.53it/s] 78%|███████▊  | 757/966 [01:43<00:24,  8.54it/s] 78%|███████▊  | 758/966 [01:43<00:24,  8.56it/s] 79%|███████▊  | 759/966 [01:43<00:24,  8.54it/s] 79%|███████▊  | 760/966 [01:43<00:24,  8.55it/s] 79%|███████▉  | 761/966 [01:43<00:24,  8.53it/s] 79%|███████▉  | 762/966 [01:43<00:23,  8.53it/s] 79%|███████▉  | 763/966 [01:44<00:23,  8.54it/s] 79%|███████▉  | 764/966 [01:44<00:23,  8.56it/s] 79%|███████▉  | 765/966 [01:44<00:23,  8.57it/s] 79%|███████▉  | 766/966 [01:44<00:23,  8.55it/s] 79%|███████▉  | 767/966 [01:44<00:23,  8.56it/s] 80%|███████▉  | 768/966 [01:44<00:23,  8.56it/s] 80%|███████▉  | 769/966 [01:44<00:23,  8.56it/s] 80%|███████▉  | 770/966 [01:44<00:22,  8.54it/s] 80%|███████▉  | 771/966 [01:45<00:22,  8.54it/s] 80%|███████▉  | 772/966 [01:45<00:22,  8.51it/s] 80%|████████  | 773/966 [01:45<00:22,  8.52it/s] 80%|████████  | 774/966 [01:45<00:22,  8.52it/s] 80%|████████  | 775/966 [01:45<00:22,  8.52it/s] 80%|████████  | 776/966 [01:45<00:22,  8.52it/s] 80%|████████  | 777/966 [01:45<00:22,  8.50it/s] 81%|████████  | 778/966 [01:45<00:22,  8.48it/s] 81%|████████  | 779/966 [01:45<00:22,  8.48it/s] 81%|████████  | 780/966 [01:46<00:21,  8.49it/s] 81%|████████  | 781/966 [01:46<00:21,  8.50it/s] 81%|████████  | 782/966 [01:46<00:21,  8.50it/s] 81%|████████  | 783/966 [01:46<00:21,  8.52it/s] 81%|████████  | 784/966 [01:46<00:21,  8.52it/s] 81%|████████▏ | 785/966 [01:46<00:21,  8.53it/s] 81%|████████▏ | 786/966 [01:46<00:21,  8.53it/s] 81%|████████▏ | 787/966 [01:46<00:20,  8.55it/s] 82%|████████▏ | 788/966 [01:47<00:20,  8.54it/s] 82%|████████▏ | 789/966 [01:47<00:20,  8.53it/s] 82%|████████▏ | 790/966 [01:47<00:20,  8.54it/s] 82%|████████▏ | 791/966 [01:47<00:20,  8.53it/s] 82%|████████▏ | 792/966 [01:47<00:20,  8.55it/s] 82%|████████▏ | 793/966 [01:47<00:20,  8.56it/s] 82%|████████▏ | 794/966 [01:47<00:20,  8.54it/s] 82%|████████▏ | 795/966 [01:47<00:20,  8.55it/s] 82%|████████▏ | 796/966 [01:47<00:19,  8.54it/s] 83%|████████▎ | 797/966 [01:48<00:19,  8.55it/s] 83%|████████▎ | 798/966 [01:48<00:19,  8.56it/s] 83%|████████▎ | 799/966 [01:48<00:19,  8.55it/s] 83%|████████▎ | 800/966 [01:48<00:19,  8.54it/s] 83%|████████▎ | 801/966 [01:48<00:19,  8.53it/s] 83%|████████▎ | 802/966 [01:48<00:19,  8.51it/s] 83%|████████▎ | 803/966 [01:48<00:19,  8.51it/s] 83%|████████▎ | 804/966 [01:48<00:19,  8.51it/s] 83%|████████▎ | 805/966 [01:49<00:18,  8.51it/s] 83%|████████▎ | 806/966 [01:49<00:18,  8.53it/s] 84%|████████▎ | 807/966 [01:49<00:18,  8.52it/s] 84%|████████▎ | 808/966 [01:49<00:18,  8.52it/s] 84%|████████▎ | 809/966 [01:49<00:18,  8.49it/s] 84%|████████▍ | 810/966 [01:49<00:18,  8.49it/s] 84%|████████▍ | 811/966 [01:49<00:18,  8.51it/s] 84%|████████▍ | 812/966 [01:49<00:18,  8.51it/s] 84%|████████▍ | 813/966 [01:49<00:17,  8.53it/s] 84%|████████▍ | 814/966 [01:50<00:17,  8.53it/s] 84%|████████▍ | 815/966 [01:50<00:17,  8.53it/s] 84%|████████▍ | 816/966 [01:50<00:17,  8.55it/s] 85%|████████▍ | 817/966 [01:50<00:17,  8.54it/s] 85%|████████▍ | 818/966 [01:50<00:17,  8.53it/s] 85%|████████▍ | 819/966 [01:50<00:17,  8.53it/s] 85%|████████▍ | 820/966 [01:50<00:17,  8.52it/s] 85%|████████▍ | 821/966 [01:50<00:17,  8.49it/s] 85%|████████▌ | 822/966 [01:51<00:16,  8.50it/s] 85%|████████▌ | 823/966 [01:51<00:16,  8.52it/s] 85%|████████▌ | 824/966 [01:51<00:16,  8.52it/s] 85%|████████▌ | 825/966 [01:51<00:16,  8.52it/s] 86%|████████▌ | 826/966 [01:51<00:16,  8.52it/s] 86%|████████▌ | 827/966 [01:51<00:16,  8.53it/s] 86%|████████▌ | 828/966 [01:51<00:16,  8.52it/s] 86%|████████▌ | 829/966 [01:51<00:16,  8.51it/s] 86%|████████▌ | 830/966 [01:51<00:16,  8.49it/s] 86%|████████▌ | 831/966 [01:52<00:15,  8.48it/s] 86%|████████▌ | 832/966 [01:52<00:15,  8.47it/s] 86%|████████▌ | 833/966 [01:52<00:15,  8.48it/s] 86%|████████▋ | 834/966 [01:52<00:15,  8.49it/s] 86%|████████▋ | 835/966 [01:52<00:15,  8.50it/s] 87%|████████▋ | 836/966 [01:52<00:15,  8.50it/s] 87%|████████▋ | 837/966 [01:52<00:15,  8.51it/s] 87%|████████▋ | 838/966 [01:52<00:15,  8.51it/s] 87%|████████▋ | 839/966 [01:53<00:14,  8.52it/s] 87%|████████▋ | 840/966 [01:53<00:14,  8.52it/s] 87%|████████▋ | 841/966 [01:53<00:14,  8.50it/s] 87%|████████▋ | 842/966 [01:53<00:14,  8.51it/s] 87%|████████▋ | 843/966 [01:53<00:14,  8.51it/s] 87%|████████▋ | 844/966 [01:53<00:14,  8.51it/s] 87%|████████▋ | 845/966 [01:53<00:14,  8.51it/s] 88%|████████▊ | 846/966 [01:53<00:14,  8.51it/s] 88%|████████▊ | 847/966 [01:53<00:13,  8.51it/s] 88%|████████▊ | 848/966 [01:54<00:13,  8.54it/s] 88%|████████▊ | 849/966 [01:54<00:13,  8.54it/s] 88%|████████▊ | 850/966 [01:54<00:13,  8.53it/s] 88%|████████▊ | 851/966 [01:54<00:13,  8.52it/s] 88%|████████▊ | 852/966 [01:54<00:13,  8.50it/s] 88%|████████▊ | 853/966 [01:54<00:13,  8.51it/s] 88%|████████▊ | 854/966 [01:54<00:13,  8.49it/s] 89%|████████▊ | 855/966 [01:54<00:13,  8.51it/s] 89%|████████▊ | 856/966 [01:55<00:12,  8.51it/s] 89%|████████▊ | 857/966 [01:55<00:12,  8.51it/s] 89%|████████▉ | 858/966 [01:55<00:12,  8.51it/s] 89%|████████▉ | 859/966 [01:55<00:12,  8.51it/s] 89%|████████▉ | 860/966 [01:55<00:12,  8.51it/s] 89%|████████▉ | 861/966 [01:55<00:12,  8.51it/s] 89%|████████▉ | 862/966 [01:55<00:12,  8.49it/s] 89%|████████▉ | 863/966 [01:55<00:12,  8.48it/s] 89%|████████▉ | 864/966 [01:55<00:12,  8.48it/s] 90%|████████▉ | 865/966 [01:56<00:11,  8.51it/s] 90%|████████▉ | 866/966 [01:56<00:11,  8.49it/s] 90%|████████▉ | 867/966 [01:56<00:11,  8.51it/s] 90%|████████▉ | 868/966 [01:56<00:11,  8.52it/s] 90%|████████▉ | 869/966 [01:56<00:11,  8.53it/s] 90%|█████████ | 870/966 [01:56<00:11,  8.53it/s] 90%|█████████ | 871/966 [01:56<00:11,  8.53it/s] 90%|█████████ | 872/966 [01:56<00:11,  8.53it/s] 90%|█████████ | 873/966 [01:56<00:10,  8.53it/s] 90%|█████████ | 874/966 [01:57<00:10,  8.49it/s] 91%|█████████ | 875/966 [01:57<00:10,  8.50it/s] 91%|█████████ | 876/966 [01:57<00:10,  8.50it/s] 91%|█████████ | 877/966 [01:57<00:10,  8.51it/s] 91%|█████████ | 878/966 [01:57<00:10,  8.52it/s] 91%|█████████ | 879/966 [01:57<00:10,  8.52it/s] 91%|█████████ | 880/966 [01:57<00:10,  8.52it/s] 91%|█████████ | 881/966 [01:57<00:09,  8.52it/s] 91%|█████████▏| 882/966 [01:58<00:09,  8.51it/s] 91%|█████████▏| 883/966 [01:58<00:09,  8.50it/s] 92%|█████████▏| 884/966 [01:58<00:09,  8.53it/s] 92%|█████████▏| 885/966 [01:58<00:09,  8.52it/s] 92%|█████████▏| 886/966 [01:58<00:09,  8.51it/s] 92%|█████████▏| 887/966 [01:58<00:09,  8.49it/s] 92%|█████████▏| 888/966 [01:58<00:09,  8.49it/s] 92%|█████████▏| 889/966 [01:58<00:09,  8.49it/s] 92%|█████████▏| 890/966 [01:58<00:08,  8.51it/s] 92%|█████████▏| 891/966 [01:59<00:08,  8.50it/s] 92%|█████████▏| 892/966 [01:59<00:08,  8.50it/s] 92%|█████████▏| 893/966 [01:59<00:08,  8.51it/s] 93%|█████████▎| 894/966 [01:59<00:08,  8.49it/s] 93%|█████████▎| 895/966 [01:59<00:08,  8.49it/s] 93%|█████████▎| 896/966 [01:59<00:08,  8.50it/s] 93%|█████████▎| 897/966 [01:59<00:08,  8.51it/s] 93%|█████████▎| 898/966 [01:59<00:07,  8.52it/s] 93%|█████████▎| 899/966 [02:00<00:07,  8.52it/s] 93%|█████████▎| 900/966 [02:00<00:07,  8.52it/s] 93%|█████████▎| 901/966 [02:00<00:07,  8.53it/s] 93%|█████████▎| 902/966 [02:00<00:07,  8.53it/s] 93%|█████████▎| 903/966 [02:00<00:07,  8.52it/s] 94%|█████████▎| 904/966 [02:00<00:07,  8.52it/s] 94%|█████████▎| 905/966 [02:00<00:07,  8.52it/s] 94%|█████████▍| 906/966 [02:00<00:07,  8.52it/s] 94%|█████████▍| 907/966 [02:00<00:06,  8.52it/s] 94%|█████████▍| 908/966 [02:01<00:06,  8.50it/s] 94%|█████████▍| 909/966 [02:01<00:06,  8.51it/s] 94%|█████████▍| 910/966 [02:01<00:06,  8.52it/s] 94%|█████████▍| 911/966 [02:01<00:06,  8.52it/s] 94%|█████████▍| 912/966 [02:01<00:06,  8.51it/s] 95%|█████████▍| 913/966 [02:01<00:06,  8.50it/s] 95%|█████████▍| 914/966 [02:01<00:06,  8.49it/s] 95%|█████████▍| 915/966 [02:01<00:06,  8.49it/s] 95%|█████████▍| 916/966 [02:02<00:05,  8.51it/s] 95%|█████████▍| 917/966 [02:02<00:05,  8.49it/s] 95%|█████████▌| 918/966 [02:02<00:05,  8.48it/s] 95%|█████████▌| 919/966 [02:02<00:05,  8.50it/s] 95%|█████████▌| 920/966 [02:02<00:05,  8.51it/s] 95%|█████████▌| 921/966 [02:02<00:05,  8.50it/s] 95%|█████████▌| 922/966 [02:02<00:05,  8.51it/s] 96%|█████████▌| 923/966 [02:02<00:05,  8.51it/s] 96%|█████████▌| 924/966 [02:02<00:04,  8.52it/s] 96%|█████████▌| 925/966 [02:03<00:04,  8.53it/s] 96%|█████████▌| 926/966 [02:03<00:04,  8.54it/s] 96%|█████████▌| 927/966 [02:03<00:04,  8.54it/s] 96%|█████████▌| 928/966 [02:03<00:04,  8.53it/s] 96%|█████████▌| 929/966 [02:03<00:04,  8.52it/s] 96%|█████████▋| 930/966 [02:03<00:04,  8.52it/s] 96%|█████████▋| 931/966 [02:03<00:04,  8.51it/s] 96%|█████████▋| 932/966 [02:03<00:03,  8.52it/s] 97%|█████████▋| 933/966 [02:04<00:03,  8.53it/s] 97%|█████████▋| 934/966 [02:04<00:03,  8.52it/s] 97%|█████████▋| 935/966 [02:04<00:03,  8.53it/s] 97%|█████████▋| 936/966 [02:04<00:03,  8.52it/s] 97%|█████████▋| 937/966 [02:04<00:03,  8.52it/s] 97%|█████████▋| 938/966 [02:04<00:03,  8.52it/s] 97%|█████████▋| 939/966 [02:04<00:03,  8.52it/s] 97%|█████████▋| 940/966 [02:04<00:03,  8.52it/s] 97%|█████████▋| 941/966 [02:04<00:02,  8.53it/s] 98%|█████████▊| 942/966 [02:05<00:02,  8.54it/s] 98%|█████████▊| 943/966 [02:05<00:02,  8.52it/s] 98%|█████████▊| 944/966 [02:05<00:02,  8.53it/s] 98%|█████████▊| 945/966 [02:05<00:02,  8.52it/s] 98%|█████████▊| 946/966 [02:05<00:02,  8.51it/s] 98%|█████████▊| 947/966 [02:05<00:02,  8.53it/s] 98%|█████████▊| 948/966 [02:05<00:02,  8.52it/s] 98%|█████████▊| 949/966 [02:05<00:01,  8.50it/s] 98%|█████████▊| 950/966 [02:06<00:01,  8.49it/s] 98%|█████████▊| 951/966 [02:06<00:01,  8.49it/s] 99%|█████████▊| 952/966 [02:06<00:01,  8.49it/s] 99%|█████████▊| 953/966 [02:06<00:01,  8.52it/s] 99%|█████████▉| 954/966 [02:06<00:01,  8.53it/s] 99%|█████████▉| 955/966 [02:06<00:01,  8.53it/s] 99%|█████████▉| 956/966 [02:06<00:01,  8.52it/s] 99%|█████████▉| 957/966 [02:06<00:01,  8.54it/s] 99%|█████████▉| 958/966 [02:06<00:00,  8.54it/s] 99%|█████████▉| 959/966 [02:07<00:00,  8.53it/s] 99%|█████████▉| 960/966 [02:07<00:00,  8.52it/s] 99%|█████████▉| 961/966 [02:07<00:00,  8.53it/s]100%|█████████▉| 962/966 [02:07<00:00,  8.52it/s]100%|█████████▉| 963/966 [02:07<00:00,  8.53it/s]100%|█████████▉| 964/966 [02:07<00:00,  8.53it/s]100%|█████████▉| 965/966 [02:07<00:00,  8.52it/s]100%|██████████| 966/966 [02:07<00:00,  8.52it/s]100%|██████████| 966/966 [02:07<00:00,  7.55it/s]
sending off prediction to background worker for resampling and export
done with 101-045

Predicting 706-005:
perform_everything_on_device: True
  0%|          | 0/966 [00:00<?, ?it/s]  0%|          | 2/966 [00:00<01:26, 11.08it/s]  0%|          | 4/966 [00:00<01:42,  9.43it/s]  1%|          | 5/966 [00:00<01:44,  9.16it/s]  1%|          | 6/966 [00:00<01:46,  8.97it/s]  1%|          | 7/966 [00:00<01:48,  8.86it/s]  1%|          | 8/966 [00:00<01:49,  8.77it/s]  1%|          | 9/966 [00:00<01:49,  8.70it/s]  1%|          | 10/966 [00:01<01:50,  8.65it/s]  1%|          | 11/966 [00:01<01:50,  8.62it/s]  1%|          | 12/966 [00:01<01:50,  8.60it/s]  1%|▏         | 13/966 [00:01<01:51,  8.58it/s]  1%|▏         | 14/966 [00:01<01:51,  8.55it/s]  2%|▏         | 15/966 [00:01<01:51,  8.55it/s]  2%|▏         | 16/966 [00:01<01:51,  8.54it/s]  2%|▏         | 17/966 [00:01<01:50,  8.56it/s]  2%|▏         | 18/966 [00:02<01:50,  8.56it/s]  2%|▏         | 19/966 [00:02<01:50,  8.54it/s]  2%|▏         | 20/966 [00:02<01:50,  8.54it/s]  2%|▏         | 21/966 [00:02<01:50,  8.54it/s]  2%|▏         | 22/966 [00:02<01:50,  8.54it/s]  2%|▏         | 23/966 [00:02<01:50,  8.54it/s]  2%|▏         | 24/966 [00:02<01:50,  8.53it/s]  3%|▎         | 25/966 [00:02<01:50,  8.54it/s]  3%|▎         | 26/966 [00:02<01:50,  8.54it/s]  3%|▎         | 27/966 [00:03<01:49,  8.54it/s]  3%|▎         | 28/966 [00:03<01:50,  8.51it/s]  3%|▎         | 29/966 [00:03<01:50,  8.50it/s]  3%|▎         | 30/966 [00:03<01:49,  8.51it/s]  3%|▎         | 31/966 [00:03<01:49,  8.51it/s]  3%|▎         | 32/966 [00:03<01:49,  8.52it/s]  3%|▎         | 33/966 [00:03<01:49,  8.52it/s]  4%|▎         | 34/966 [00:03<01:49,  8.52it/s]  4%|▎         | 35/966 [00:04<01:49,  8.52it/s]  4%|▎         | 36/966 [00:04<01:49,  8.52it/s]  4%|▍         | 37/966 [00:04<01:48,  8.53it/s]  4%|▍         | 38/966 [00:04<01:48,  8.53it/s]  4%|▍         | 39/966 [00:04<01:48,  8.53it/s]  4%|▍         | 40/966 [00:04<01:48,  8.54it/s]  4%|▍         | 41/966 [00:04<01:48,  8.54it/s]  4%|▍         | 42/966 [00:04<01:48,  8.55it/s]  4%|▍         | 43/966 [00:04<01:47,  8.56it/s]  5%|▍         | 44/966 [00:05<01:47,  8.57it/s]  5%|▍         | 45/966 [00:05<01:47,  8.57it/s]  5%|▍         | 46/966 [00:05<01:47,  8.55it/s]  5%|▍         | 47/966 [00:05<01:47,  8.54it/s]  5%|▍         | 48/966 [00:05<01:47,  8.54it/s]  5%|▌         | 49/966 [00:05<01:47,  8.52it/s]  5%|▌         | 50/966 [00:05<01:47,  8.54it/s]  5%|▌         | 51/966 [00:05<01:47,  8.54it/s]  5%|▌         | 52/966 [00:06<01:47,  8.52it/s]  5%|▌         | 53/966 [00:06<01:47,  8.50it/s]  6%|▌         | 54/966 [00:06<01:47,  8.49it/s]  6%|▌         | 55/966 [00:06<01:47,  8.49it/s]  6%|▌         | 56/966 [00:06<01:47,  8.48it/s]  6%|▌         | 57/966 [00:06<01:47,  8.48it/s]  6%|▌         | 58/966 [00:06<01:47,  8.47it/s]  6%|▌         | 59/966 [00:06<01:46,  8.49it/s]  6%|▌         | 60/966 [00:06<01:46,  8.50it/s]  6%|▋         | 61/966 [00:07<01:46,  8.50it/s]  6%|▋         | 62/966 [00:07<01:46,  8.51it/s]  7%|▋         | 63/966 [00:07<01:46,  8.51it/s]  7%|▋         | 64/966 [00:07<01:45,  8.52it/s]  7%|▋         | 65/966 [00:07<01:45,  8.53it/s]  7%|▋         | 66/966 [00:07<01:45,  8.53it/s]  7%|▋         | 67/966 [00:07<01:45,  8.53it/s]  7%|▋         | 68/966 [00:07<01:45,  8.51it/s]  7%|▋         | 69/966 [00:08<01:45,  8.50it/s]  7%|▋         | 70/966 [00:08<01:45,  8.48it/s]  7%|▋         | 71/966 [00:08<01:45,  8.49it/s]  7%|▋         | 72/966 [00:08<01:45,  8.49it/s]  8%|▊         | 73/966 [00:08<01:44,  8.52it/s]  8%|▊         | 74/966 [00:08<01:44,  8.54it/s]  8%|▊         | 75/966 [00:08<01:44,  8.53it/s]  8%|▊         | 76/966 [00:08<01:44,  8.54it/s]  8%|▊         | 77/966 [00:08<01:44,  8.54it/s]  8%|▊         | 78/966 [00:09<01:44,  8.52it/s]  8%|▊         | 79/966 [00:09<01:44,  8.50it/s]  8%|▊         | 80/966 [00:09<01:44,  8.51it/s]  8%|▊         | 81/966 [00:09<01:43,  8.52it/s]  8%|▊         | 82/966 [00:09<01:43,  8.53it/s]  9%|▊         | 83/966 [00:09<01:43,  8.54it/s]  9%|▊         | 84/966 [00:09<01:43,  8.54it/s]  9%|▉         | 85/966 [00:09<01:43,  8.54it/s]  9%|▉         | 86/966 [00:10<01:42,  8.54it/s]  9%|▉         | 87/966 [00:10<01:43,  8.53it/s]  9%|▉         | 88/966 [00:10<01:42,  8.53it/s]  9%|▉         | 89/966 [00:10<01:42,  8.53it/s]  9%|▉         | 90/966 [00:10<01:42,  8.52it/s]  9%|▉         | 91/966 [00:10<01:42,  8.52it/s] 10%|▉         | 92/966 [00:10<01:42,  8.52it/s] 10%|▉         | 93/966 [00:10<01:42,  8.53it/s] 10%|▉         | 94/966 [00:10<01:42,  8.54it/s] 10%|▉         | 95/966 [00:11<01:42,  8.51it/s] 10%|▉         | 96/966 [00:11<01:42,  8.51it/s] 10%|█         | 97/966 [00:11<01:42,  8.51it/s] 10%|█         | 98/966 [00:11<01:41,  8.52it/s] 10%|█         | 99/966 [00:11<01:41,  8.53it/s] 10%|█         | 100/966 [00:11<01:41,  8.52it/s] 10%|█         | 101/966 [00:11<01:41,  8.52it/s] 11%|█         | 102/966 [00:11<01:41,  8.52it/s] 11%|█         | 103/966 [00:12<01:41,  8.52it/s] 11%|█         | 104/966 [00:12<01:41,  8.50it/s] 11%|█         | 105/966 [00:12<01:41,  8.48it/s] 11%|█         | 106/966 [00:12<01:41,  8.48it/s] 11%|█         | 107/966 [00:12<01:41,  8.48it/s] 11%|█         | 108/966 [00:12<01:41,  8.47it/s] 11%|█▏        | 109/966 [00:12<01:41,  8.48it/s] 11%|█▏        | 110/966 [00:12<01:41,  8.47it/s] 11%|█▏        | 111/966 [00:12<01:40,  8.48it/s] 12%|█▏        | 112/966 [00:13<01:40,  8.49it/s] 12%|█▏        | 113/966 [00:13<01:40,  8.52it/s] 12%|█▏        | 114/966 [00:13<01:40,  8.52it/s] 12%|█▏        | 115/966 [00:13<01:40,  8.50it/s] 12%|█▏        | 116/966 [00:13<01:40,  8.48it/s] 12%|█▏        | 117/966 [00:13<01:40,  8.48it/s] 12%|█▏        | 118/966 [00:13<01:39,  8.50it/s] 12%|█▏        | 119/966 [00:13<01:39,  8.49it/s] 12%|█▏        | 120/966 [00:14<01:39,  8.49it/s] 13%|█▎        | 121/966 [00:14<01:39,  8.50it/s] 13%|█▎        | 122/966 [00:14<01:39,  8.51it/s] 13%|█▎        | 123/966 [00:14<01:39,  8.50it/s] 13%|█▎        | 124/966 [00:14<01:38,  8.51it/s] 13%|█▎        | 125/966 [00:14<01:38,  8.51it/s] 13%|█▎        | 126/966 [00:14<01:38,  8.53it/s] 13%|█▎        | 127/966 [00:14<01:38,  8.55it/s] 13%|█▎        | 128/966 [00:14<01:37,  8.56it/s] 13%|█▎        | 129/966 [00:15<01:37,  8.56it/s] 13%|█▎        | 130/966 [00:15<01:37,  8.56it/s] 14%|█▎        | 131/966 [00:15<01:37,  8.55it/s] 14%|█▎        | 132/966 [00:15<01:37,  8.56it/s] 14%|█▍        | 133/966 [00:15<01:37,  8.56it/s] 14%|█▍        | 134/966 [00:15<01:37,  8.56it/s] 14%|█▍        | 135/966 [00:15<01:37,  8.54it/s] 14%|█▍        | 136/966 [00:15<01:37,  8.54it/s] 14%|█▍        | 137/966 [00:16<01:37,  8.54it/s] 14%|█▍        | 138/966 [00:16<01:36,  8.54it/s] 14%|█▍        | 139/966 [00:16<01:37,  8.52it/s] 14%|█▍        | 140/966 [00:16<01:37,  8.51it/s] 15%|█▍        | 141/966 [00:16<01:36,  8.51it/s] 15%|█▍        | 142/966 [00:16<01:36,  8.52it/s] 15%|█▍        | 143/966 [00:16<01:36,  8.53it/s] 15%|█▍        | 144/966 [00:16<01:36,  8.53it/s] 15%|█▌        | 145/966 [00:16<01:36,  8.54it/s] 15%|█▌        | 146/966 [00:17<01:36,  8.54it/s] 15%|█▌        | 147/966 [00:17<01:36,  8.52it/s] 15%|█▌        | 148/966 [00:17<01:36,  8.52it/s] 15%|█▌        | 149/966 [00:17<01:35,  8.52it/s] 16%|█▌        | 150/966 [00:17<01:35,  8.51it/s] 16%|█▌        | 151/966 [00:17<01:35,  8.50it/s] 16%|█▌        | 152/966 [00:17<01:35,  8.50it/s] 16%|█▌        | 153/966 [00:17<01:35,  8.50it/s] 16%|█▌        | 154/966 [00:18<01:35,  8.50it/s] 16%|█▌        | 155/966 [00:18<01:35,  8.51it/s] 16%|█▌        | 156/966 [00:18<01:35,  8.52it/s] 16%|█▋        | 157/966 [00:18<01:35,  8.50it/s] 16%|█▋        | 158/966 [00:18<01:34,  8.52it/s] 16%|█▋        | 159/966 [00:18<01:34,  8.52it/s] 17%|█▋        | 160/966 [00:18<01:34,  8.52it/s] 17%|█▋        | 161/966 [00:18<01:34,  8.51it/s] 17%|█▋        | 162/966 [00:18<01:34,  8.52it/s] 17%|█▋        | 163/966 [00:19<01:34,  8.52it/s] 17%|█▋        | 164/966 [00:19<01:33,  8.54it/s] 17%|█▋        | 165/966 [00:19<01:33,  8.54it/s] 17%|█▋        | 166/966 [00:19<01:33,  8.54it/s] 17%|█▋        | 167/966 [00:19<01:33,  8.55it/s] 17%|█▋        | 168/966 [00:19<01:33,  8.55it/s] 17%|█▋        | 169/966 [00:19<01:33,  8.56it/s] 18%|█▊        | 170/966 [00:19<01:32,  8.57it/s] 18%|█▊        | 171/966 [00:20<01:32,  8.56it/s] 18%|█▊        | 172/966 [00:20<01:32,  8.55it/s] 18%|█▊        | 173/966 [00:20<01:33,  8.52it/s] 18%|█▊        | 174/966 [00:20<01:33,  8.51it/s] 18%|█▊        | 175/966 [00:20<01:33,  8.50it/s] 18%|█▊        | 176/966 [00:20<01:32,  8.52it/s] 18%|█▊        | 177/966 [00:20<01:32,  8.50it/s] 18%|█▊        | 178/966 [00:20<01:32,  8.51it/s] 19%|█▊        | 179/966 [00:20<01:32,  8.51it/s] 19%|█▊        | 180/966 [00:21<01:32,  8.50it/s] 19%|█▊        | 181/966 [00:21<01:32,  8.49it/s] 19%|█▉        | 182/966 [00:21<01:32,  8.49it/s] 19%|█▉        | 183/966 [00:21<01:32,  8.50it/s] 19%|█▉        | 184/966 [00:21<01:32,  8.49it/s] 19%|█▉        | 185/966 [00:21<01:31,  8.50it/s] 19%|█▉        | 186/966 [00:21<01:31,  8.50it/s] 19%|█▉        | 187/966 [00:21<01:31,  8.51it/s] 19%|█▉        | 188/966 [00:22<01:31,  8.51it/s] 20%|█▉        | 189/966 [00:22<01:31,  8.51it/s] 20%|█▉        | 190/966 [00:22<01:31,  8.52it/s] 20%|█▉        | 191/966 [00:22<01:30,  8.52it/s] 20%|█▉        | 192/966 [00:22<01:30,  8.51it/s] 20%|█▉        | 193/966 [00:22<01:30,  8.51it/s] 20%|██        | 194/966 [00:22<01:30,  8.49it/s] 20%|██        | 195/966 [00:22<01:30,  8.49it/s] 20%|██        | 196/966 [00:22<01:30,  8.48it/s] 20%|██        | 197/966 [00:23<01:30,  8.50it/s] 20%|██        | 198/966 [00:23<01:30,  8.50it/s] 21%|██        | 199/966 [00:23<01:30,  8.51it/s] 21%|██        | 200/966 [00:23<01:29,  8.51it/s] 21%|██        | 201/966 [00:23<01:29,  8.52it/s] 21%|██        | 202/966 [00:23<01:29,  8.52it/s] 21%|██        | 203/966 [00:23<01:29,  8.52it/s] 21%|██        | 204/966 [00:23<01:29,  8.52it/s] 21%|██        | 205/966 [00:24<01:29,  8.54it/s] 21%|██▏       | 206/966 [00:24<01:29,  8.53it/s] 21%|██▏       | 207/966 [00:24<01:28,  8.54it/s] 22%|██▏       | 208/966 [00:24<01:28,  8.54it/s] 22%|██▏       | 209/966 [00:24<01:28,  8.52it/s] 22%|██▏       | 210/966 [00:24<01:28,  8.53it/s] 22%|██▏       | 211/966 [00:24<01:28,  8.49it/s] 22%|██▏       | 212/966 [00:24<01:28,  8.50it/s] 22%|██▏       | 213/966 [00:24<01:28,  8.52it/s] 22%|██▏       | 214/966 [00:25<01:28,  8.52it/s] 22%|██▏       | 215/966 [00:25<01:28,  8.52it/s] 22%|██▏       | 216/966 [00:25<01:27,  8.52it/s] 22%|██▏       | 217/966 [00:25<01:27,  8.55it/s] 23%|██▎       | 218/966 [00:25<01:27,  8.54it/s] 23%|██▎       | 219/966 [00:25<01:27,  8.54it/s] 23%|██▎       | 220/966 [00:25<01:27,  8.52it/s] 23%|██▎       | 221/966 [00:25<01:27,  8.51it/s] 23%|██▎       | 222/966 [00:25<01:27,  8.50it/s] 23%|██▎       | 223/966 [00:26<01:27,  8.51it/s] 23%|██▎       | 224/966 [00:26<01:27,  8.50it/s] 23%|██▎       | 225/966 [00:26<01:27,  8.50it/s] 23%|██▎       | 226/966 [00:26<01:26,  8.51it/s] 23%|██▎       | 227/966 [00:26<01:26,  8.50it/s] 24%|██▎       | 228/966 [00:26<01:26,  8.51it/s] 24%|██▎       | 229/966 [00:26<01:26,  8.52it/s] 24%|██▍       | 230/966 [00:26<01:26,  8.53it/s] 24%|██▍       | 231/966 [00:27<01:26,  8.53it/s] 24%|██▍       | 232/966 [00:27<01:26,  8.49it/s] 24%|██▍       | 233/966 [00:27<01:26,  8.48it/s] 24%|██▍       | 234/966 [00:27<01:26,  8.48it/s] 24%|██▍       | 235/966 [00:27<01:26,  8.49it/s] 24%|██▍       | 236/966 [00:27<01:25,  8.51it/s] 25%|██▍       | 237/966 [00:27<01:25,  8.51it/s] 25%|██▍       | 238/966 [00:27<01:25,  8.50it/s] 25%|██▍       | 239/966 [00:27<01:25,  8.49it/s] 25%|██▍       | 240/966 [00:28<01:25,  8.50it/s] 25%|██▍       | 241/966 [00:28<01:25,  8.51it/s] 25%|██▌       | 242/966 [00:28<01:25,  8.52it/s] 25%|██▌       | 243/966 [00:28<01:24,  8.51it/s] 25%|██▌       | 244/966 [00:28<01:24,  8.52it/s] 25%|██▌       | 245/966 [00:28<01:24,  8.51it/s] 25%|██▌       | 246/966 [00:28<01:24,  8.51it/s] 26%|██▌       | 247/966 [00:28<01:24,  8.51it/s] 26%|██▌       | 248/966 [00:29<01:24,  8.50it/s] 26%|██▌       | 249/966 [00:29<01:24,  8.50it/s] 26%|██▌       | 250/966 [00:29<01:24,  8.50it/s] 26%|██▌       | 251/966 [00:29<01:24,  8.51it/s] 26%|██▌       | 252/966 [00:29<01:23,  8.51it/s] 26%|██▌       | 253/966 [00:29<01:23,  8.53it/s] 26%|██▋       | 254/966 [00:29<01:23,  8.55it/s] 26%|██▋       | 255/966 [00:29<01:23,  8.54it/s] 27%|██▋       | 256/966 [00:29<01:23,  8.53it/s] 27%|██▋       | 257/966 [00:30<01:23,  8.53it/s] 27%|██▋       | 258/966 [00:30<01:23,  8.52it/s] 27%|██▋       | 259/966 [00:30<01:22,  8.54it/s] 27%|██▋       | 260/966 [00:30<01:22,  8.57it/s] 27%|██▋       | 261/966 [00:30<01:22,  8.56it/s] 27%|██▋       | 262/966 [00:30<01:22,  8.54it/s] 27%|██▋       | 263/966 [00:30<01:22,  8.53it/s] 27%|██▋       | 264/966 [00:30<01:22,  8.52it/s] 27%|██▋       | 265/966 [00:31<01:22,  8.51it/s] 28%|██▊       | 266/966 [00:31<01:22,  8.49it/s] 28%|██▊       | 267/966 [00:31<01:22,  8.50it/s] 28%|██▊       | 268/966 [00:31<01:22,  8.50it/s] 28%|██▊       | 269/966 [00:31<01:22,  8.50it/s] 28%|██▊       | 270/966 [00:31<01:21,  8.50it/s] 28%|██▊       | 271/966 [00:31<01:21,  8.49it/s] 28%|██▊       | 272/966 [00:31<01:21,  8.48it/s] 28%|██▊       | 273/966 [00:31<01:21,  8.50it/s] 28%|██▊       | 274/966 [00:32<01:21,  8.50it/s] 28%|██▊       | 275/966 [00:32<01:21,  8.50it/s] 29%|██▊       | 276/966 [00:32<01:21,  8.47it/s] 29%|██▊       | 277/966 [00:32<01:21,  8.49it/s] 29%|██▉       | 278/966 [00:32<01:20,  8.50it/s] 29%|██▉       | 279/966 [00:32<01:20,  8.49it/s] 29%|██▉       | 280/966 [00:32<01:20,  8.50it/s] 29%|██▉       | 281/966 [00:32<01:20,  8.50it/s] 29%|██▉       | 282/966 [00:33<01:20,  8.51it/s] 29%|██▉       | 283/966 [00:33<01:20,  8.51it/s] 29%|██▉       | 284/966 [00:33<01:20,  8.51it/s] 30%|██▉       | 285/966 [00:33<01:20,  8.49it/s] 30%|██▉       | 286/966 [00:33<01:20,  8.50it/s] 30%|██▉       | 287/966 [00:33<01:19,  8.51it/s] 30%|██▉       | 288/966 [00:33<01:19,  8.50it/s] 30%|██▉       | 289/966 [00:33<01:19,  8.52it/s] 30%|███       | 290/966 [00:33<01:19,  8.54it/s] 30%|███       | 291/966 [00:34<01:18,  8.56it/s] 30%|███       | 292/966 [00:34<01:18,  8.54it/s] 30%|███       | 293/966 [00:34<01:18,  8.52it/s] 30%|███       | 294/966 [00:34<01:18,  8.51it/s] 31%|███       | 295/966 [00:34<01:18,  8.50it/s] 31%|███       | 296/966 [00:34<01:18,  8.52it/s] 31%|███       | 297/966 [00:34<01:18,  8.53it/s] 31%|███       | 298/966 [00:34<01:18,  8.51it/s] 31%|███       | 299/966 [00:35<01:18,  8.53it/s] 31%|███       | 300/966 [00:35<01:17,  8.54it/s] 31%|███       | 301/966 [00:35<01:17,  8.54it/s] 31%|███▏      | 302/966 [00:35<01:17,  8.53it/s] 31%|███▏      | 303/966 [00:35<01:17,  8.52it/s] 31%|███▏      | 304/966 [00:35<01:17,  8.51it/s] 32%|███▏      | 305/966 [00:35<01:17,  8.50it/s] 32%|███▏      | 306/966 [00:35<01:17,  8.52it/s] 32%|███▏      | 307/966 [00:35<01:17,  8.52it/s] 32%|███▏      | 308/966 [00:36<01:17,  8.53it/s] 32%|███▏      | 309/966 [00:36<01:17,  8.53it/s] 32%|███▏      | 310/966 [00:36<01:16,  8.54it/s] 32%|███▏      | 311/966 [00:36<01:16,  8.54it/s] 32%|███▏      | 312/966 [00:36<01:16,  8.53it/s] 32%|███▏      | 313/966 [00:36<01:16,  8.53it/s] 33%|███▎      | 314/966 [00:36<01:16,  8.52it/s] 33%|███▎      | 315/966 [00:36<01:16,  8.51it/s] 33%|███▎      | 316/966 [00:37<01:16,  8.51it/s] 33%|███▎      | 317/966 [00:37<01:16,  8.51it/s] 33%|███▎      | 318/966 [00:37<01:16,  8.52it/s] 33%|███▎      | 319/966 [00:37<01:15,  8.52it/s] 33%|███▎      | 320/966 [00:37<01:15,  8.50it/s] 33%|███▎      | 321/966 [00:37<01:16,  8.49it/s] 33%|███▎      | 322/966 [00:37<01:15,  8.50it/s] 33%|███▎      | 323/966 [00:37<01:15,  8.50it/s] 34%|███▎      | 324/966 [00:37<01:15,  8.51it/s] 34%|███▎      | 325/966 [00:38<01:15,  8.52it/s] 34%|███▎      | 326/966 [00:38<01:15,  8.51it/s] 34%|███▍      | 327/966 [00:38<01:15,  8.49it/s] 34%|███▍      | 328/966 [00:38<01:15,  8.47it/s] 34%|███▍      | 329/966 [00:38<01:15,  8.49it/s] 34%|███▍      | 330/966 [00:38<01:14,  8.50it/s] 34%|███▍      | 331/966 [00:38<01:14,  8.50it/s] 34%|███▍      | 332/966 [00:38<01:14,  8.51it/s] 34%|███▍      | 333/966 [00:39<01:14,  8.51it/s] 35%|███▍      | 334/966 [00:39<01:14,  8.51it/s] 35%|███▍      | 335/966 [00:39<01:14,  8.50it/s] 35%|███▍      | 336/966 [00:39<01:13,  8.52it/s] 35%|███▍      | 337/966 [00:39<01:13,  8.54it/s] 35%|███▍      | 338/966 [00:39<01:13,  8.55it/s] 35%|███▌      | 339/966 [00:39<01:13,  8.55it/s] 35%|███▌      | 340/966 [00:39<01:13,  8.55it/s] 35%|███▌      | 341/966 [00:39<01:13,  8.51it/s] 35%|███▌      | 342/966 [00:40<01:13,  8.53it/s] 36%|███▌      | 343/966 [00:40<01:12,  8.54it/s] 36%|███▌      | 344/966 [00:40<01:12,  8.54it/s] 36%|███▌      | 345/966 [00:40<01:12,  8.55it/s] 36%|███▌      | 346/966 [00:40<01:12,  8.53it/s] 36%|███▌      | 347/966 [00:40<01:12,  8.53it/s] 36%|███▌      | 348/966 [00:40<01:12,  8.52it/s] 36%|███▌      | 349/966 [00:40<01:12,  8.50it/s] 36%|███▌      | 350/966 [00:41<01:12,  8.48it/s] 36%|███▋      | 351/966 [00:41<01:12,  8.47it/s] 36%|███▋      | 352/966 [00:41<01:12,  8.47it/s] 37%|███▋      | 353/966 [00:41<01:12,  8.47it/s] 37%|███▋      | 354/966 [00:41<01:12,  8.48it/s] 37%|███▋      | 355/966 [00:41<01:11,  8.49it/s] 37%|███▋      | 356/966 [00:41<01:11,  8.49it/s] 37%|███▋      | 357/966 [00:41<01:11,  8.48it/s] 37%|███▋      | 358/966 [00:41<01:11,  8.47it/s] 37%|███▋      | 359/966 [00:42<01:11,  8.48it/s] 37%|███▋      | 360/966 [00:42<01:11,  8.50it/s] 37%|███▋      | 361/966 [00:42<01:11,  8.50it/s] 37%|███▋      | 362/966 [00:42<01:10,  8.51it/s] 38%|███▊      | 363/966 [00:42<01:10,  8.51it/s] 38%|███▊      | 364/966 [00:42<01:10,  8.51it/s] 38%|███▊      | 365/966 [00:42<01:10,  8.50it/s] 38%|███▊      | 366/966 [00:42<01:10,  8.50it/s] 38%|███▊      | 367/966 [00:43<01:10,  8.50it/s] 38%|███▊      | 368/966 [00:43<01:10,  8.51it/s] 38%|███▊      | 369/966 [00:43<01:10,  8.48it/s] 38%|███▊      | 370/966 [00:43<01:10,  8.47it/s] 38%|███▊      | 371/966 [00:43<01:10,  8.48it/s] 39%|███▊      | 372/966 [00:43<01:10,  8.49it/s] 39%|███▊      | 373/966 [00:43<01:09,  8.52it/s] 39%|███▊      | 374/966 [00:43<01:09,  8.52it/s] 39%|███▉      | 375/966 [00:43<01:09,  8.49it/s] 39%|███▉      | 376/966 [00:44<01:09,  8.49it/s] 39%|███▉      | 377/966 [00:44<01:09,  8.47it/s] 39%|███▉      | 378/966 [00:44<01:09,  8.46it/s] 39%|███▉      | 379/966 [00:44<01:09,  8.47it/s] 39%|███▉      | 380/966 [00:44<01:09,  8.48it/s] 39%|███▉      | 381/966 [00:44<01:08,  8.50it/s] 40%|███▉      | 382/966 [00:44<01:08,  8.50it/s] 40%|███▉      | 383/966 [00:44<01:08,  8.50it/s] 40%|███▉      | 384/966 [00:45<01:08,  8.51it/s] 40%|███▉      | 385/966 [00:45<01:08,  8.51it/s] 40%|███▉      | 386/966 [00:45<01:07,  8.54it/s] 40%|████      | 387/966 [00:45<01:07,  8.55it/s] 40%|████      | 388/966 [00:45<01:07,  8.54it/s] 40%|████      | 389/966 [00:45<01:07,  8.54it/s] 40%|████      | 390/966 [00:45<01:07,  8.53it/s] 40%|████      | 391/966 [00:45<01:07,  8.52it/s] 41%|████      | 392/966 [00:45<01:07,  8.51it/s] 41%|████      | 393/966 [00:46<01:07,  8.50it/s] 41%|████      | 394/966 [00:46<01:07,  8.51it/s] 41%|████      | 395/966 [00:46<01:07,  8.51it/s] 41%|████      | 396/966 [00:46<01:06,  8.52it/s] 41%|████      | 397/966 [00:46<01:06,  8.51it/s] 41%|████      | 398/966 [00:46<01:06,  8.53it/s] 41%|████▏     | 399/966 [00:46<01:06,  8.52it/s] 41%|████▏     | 400/966 [00:46<01:06,  8.50it/s] 42%|████▏     | 401/966 [00:47<01:06,  8.51it/s] 42%|████▏     | 402/966 [00:47<01:06,  8.49it/s] 42%|████▏     | 403/966 [00:47<01:06,  8.49it/s] 42%|████▏     | 404/966 [00:47<01:06,  8.48it/s] 42%|████▏     | 405/966 [00:47<01:06,  8.49it/s] 42%|████▏     | 406/966 [00:47<01:05,  8.49it/s] 42%|████▏     | 407/966 [00:47<01:05,  8.50it/s] 42%|████▏     | 408/966 [00:47<01:05,  8.52it/s] 42%|████▏     | 409/966 [00:47<01:05,  8.53it/s] 42%|████▏     | 410/966 [00:48<01:05,  8.52it/s] 43%|████▎     | 411/966 [00:48<01:05,  8.50it/s] 43%|████▎     | 412/966 [00:48<01:05,  8.48it/s] 43%|████▎     | 413/966 [00:48<01:05,  8.48it/s] 43%|████▎     | 414/966 [00:48<01:05,  8.49it/s] 43%|████▎     | 415/966 [00:48<01:04,  8.51it/s] 43%|████▎     | 416/966 [00:48<01:04,  8.52it/s] 43%|████▎     | 417/966 [00:48<01:04,  8.53it/s] 43%|████▎     | 418/966 [00:49<01:04,  8.51it/s] 43%|████▎     | 419/966 [00:49<01:04,  8.50it/s] 43%|████▎     | 420/966 [00:49<01:04,  8.51it/s] 44%|████▎     | 421/966 [00:49<01:04,  8.50it/s] 44%|████▎     | 422/966 [00:49<01:03,  8.52it/s] 44%|████▍     | 423/966 [00:49<01:03,  8.54it/s] 44%|████▍     | 424/966 [00:49<01:03,  8.52it/s] 44%|████▍     | 425/966 [00:49<01:03,  8.52it/s] 44%|████▍     | 426/966 [00:49<01:03,  8.52it/s] 44%|████▍     | 427/966 [00:50<01:03,  8.53it/s] 44%|████▍     | 428/966 [00:50<01:03,  8.53it/s] 44%|████▍     | 429/966 [00:50<01:02,  8.53it/s] 45%|████▍     | 430/966 [00:50<01:02,  8.54it/s] 45%|████▍     | 431/966 [00:50<01:02,  8.54it/s] 45%|████▍     | 432/966 [00:50<01:02,  8.54it/s] 45%|████▍     | 433/966 [00:50<01:02,  8.52it/s] 45%|████▍     | 434/966 [00:50<01:02,  8.50it/s] 45%|████▌     | 435/966 [00:51<01:02,  8.49it/s] 45%|████▌     | 436/966 [00:51<01:02,  8.49it/s] 45%|████▌     | 437/966 [00:51<01:02,  8.50it/s] 45%|████▌     | 438/966 [00:51<01:02,  8.50it/s] 45%|████▌     | 439/966 [00:51<01:01,  8.51it/s] 46%|████▌     | 440/966 [00:51<01:01,  8.52it/s] 46%|████▌     | 441/966 [00:51<01:01,  8.52it/s] 46%|████▌     | 442/966 [00:51<01:01,  8.49it/s] 46%|████▌     | 443/966 [00:51<01:01,  8.46it/s] 46%|████▌     | 444/966 [00:52<01:01,  8.47it/s] 46%|████▌     | 445/966 [00:52<01:01,  8.47it/s] 46%|████▌     | 446/966 [00:52<01:01,  8.47it/s] 46%|████▋     | 447/966 [00:52<01:01,  8.48it/s] 46%|████▋     | 448/966 [00:52<01:01,  8.49it/s] 46%|████▋     | 449/966 [00:52<01:00,  8.50it/s] 47%|████▋     | 450/966 [00:52<01:00,  8.51it/s] 47%|████▋     | 451/966 [00:52<01:00,  8.51it/s] 47%|████▋     | 452/966 [00:53<01:00,  8.49it/s] 47%|████▋     | 453/966 [00:53<01:00,  8.48it/s] 47%|████▋     | 454/966 [00:53<01:00,  8.48it/s] 47%|████▋     | 455/966 [00:53<01:00,  8.47it/s] 47%|████▋     | 456/966 [00:53<01:00,  8.49it/s] 47%|████▋     | 457/966 [00:53<00:59,  8.52it/s] 47%|████▋     | 458/966 [00:53<00:59,  8.52it/s] 48%|████▊     | 459/966 [00:53<00:59,  8.52it/s] 48%|████▊     | 460/966 [00:53<00:59,  8.50it/s] 48%|████▊     | 461/966 [00:54<00:59,  8.50it/s] 48%|████▊     | 462/966 [00:54<00:59,  8.50it/s] 48%|████▊     | 463/966 [00:54<00:58,  8.53it/s] 48%|████▊     | 464/966 [00:54<00:58,  8.54it/s] 48%|████▊     | 465/966 [00:54<00:58,  8.54it/s] 48%|████▊     | 466/966 [00:54<00:58,  8.50it/s] 48%|████▊     | 467/966 [00:54<00:58,  8.52it/s] 48%|████▊     | 468/966 [00:54<00:58,  8.53it/s] 49%|████▊     | 469/966 [00:55<00:58,  8.55it/s] 49%|████▊     | 470/966 [00:55<00:57,  8.55it/s] 49%|████▉     | 471/966 [00:55<00:57,  8.55it/s] 49%|████▉     | 472/966 [00:55<00:57,  8.54it/s] 49%|████▉     | 473/966 [00:55<00:57,  8.55it/s] 49%|████▉     | 474/966 [00:55<00:57,  8.54it/s] 49%|████▉     | 475/966 [00:55<00:57,  8.51it/s] 49%|████▉     | 476/966 [00:55<00:57,  8.52it/s] 49%|████▉     | 477/966 [00:55<00:57,  8.51it/s] 49%|████▉     | 478/966 [00:56<00:57,  8.50it/s] 50%|████▉     | 479/966 [00:56<00:57,  8.51it/s] 50%|████▉     | 480/966 [00:56<00:57,  8.50it/s] 50%|████▉     | 481/966 [00:56<00:57,  8.49it/s] 50%|████▉     | 482/966 [00:56<00:56,  8.50it/s] 50%|█████     | 483/966 [00:56<00:56,  8.50it/s] 50%|█████     | 484/966 [00:56<00:56,  8.49it/s] 50%|█████     | 485/966 [00:56<00:56,  8.49it/s] 50%|█████     | 486/966 [00:57<00:56,  8.49it/s] 50%|█████     | 487/966 [00:57<00:56,  8.49it/s] 51%|█████     | 488/966 [00:57<00:56,  8.49it/s] 51%|█████     | 489/966 [00:57<00:56,  8.49it/s] 51%|█████     | 490/966 [00:57<00:55,  8.51it/s] 51%|█████     | 491/966 [00:57<00:55,  8.51it/s] 51%|█████     | 492/966 [00:57<00:55,  8.52it/s] 51%|█████     | 493/966 [00:57<00:55,  8.52it/s] 51%|█████     | 494/966 [00:57<00:55,  8.50it/s] 51%|█████     | 495/966 [00:58<00:55,  8.48it/s] 51%|█████▏    | 496/966 [00:58<00:55,  8.50it/s] 51%|█████▏    | 497/966 [00:58<00:55,  8.51it/s] 52%|█████▏    | 498/966 [00:58<00:55,  8.50it/s] 52%|█████▏    | 499/966 [00:58<00:54,  8.52it/s] 52%|█████▏    | 500/966 [00:58<00:54,  8.51it/s] 52%|█████▏    | 501/966 [00:58<00:54,  8.52it/s] 52%|█████▏    | 502/966 [00:58<00:54,  8.53it/s] 52%|█████▏    | 503/966 [00:59<00:54,  8.53it/s] 52%|█████▏    | 504/966 [00:59<00:54,  8.53it/s] 52%|█████▏    | 505/966 [00:59<00:54,  8.54it/s] 52%|█████▏    | 506/966 [00:59<00:53,  8.54it/s] 52%|█████▏    | 507/966 [00:59<00:53,  8.53it/s] 53%|█████▎    | 508/966 [00:59<00:53,  8.51it/s] 53%|█████▎    | 509/966 [00:59<00:53,  8.50it/s] 53%|█████▎    | 510/966 [00:59<00:53,  8.50it/s] 53%|█████▎    | 511/966 [00:59<00:53,  8.52it/s] 53%|█████▎    | 512/966 [01:00<00:53,  8.53it/s] 53%|█████▎    | 513/966 [01:00<00:53,  8.53it/s] 53%|█████▎    | 514/966 [01:00<00:52,  8.53it/s] 53%|█████▎    | 515/966 [01:00<00:52,  8.53it/s] 53%|█████▎    | 516/966 [01:00<00:52,  8.53it/s] 54%|█████▎    | 517/966 [01:00<00:52,  8.50it/s] 54%|█████▎    | 518/966 [01:00<00:52,  8.50it/s] 54%|█████▎    | 519/966 [01:00<00:52,  8.51it/s] 54%|█████▍    | 520/966 [01:01<00:52,  8.51it/s] 54%|█████▍    | 521/966 [01:01<00:52,  8.51it/s] 54%|█████▍    | 522/966 [01:01<00:52,  8.51it/s] 54%|█████▍    | 523/966 [01:01<00:52,  8.50it/s] 54%|█████▍    | 524/966 [01:01<00:51,  8.51it/s] 54%|█████▍    | 525/966 [01:01<00:51,  8.49it/s] 54%|█████▍    | 526/966 [01:01<00:51,  8.49it/s] 55%|█████▍    | 527/966 [01:01<00:51,  8.49it/s] 55%|█████▍    | 528/966 [01:01<00:51,  8.50it/s] 55%|█████▍    | 529/966 [01:02<00:51,  8.49it/s] 55%|█████▍    | 530/966 [01:02<00:51,  8.50it/s] 55%|█████▍    | 531/966 [01:02<00:51,  8.51it/s] 55%|█████▌    | 532/966 [01:02<00:51,  8.50it/s] 55%|█████▌    | 533/966 [01:02<00:51,  8.48it/s] 55%|█████▌    | 534/966 [01:02<00:50,  8.48it/s] 55%|█████▌    | 535/966 [01:02<00:50,  8.49it/s] 55%|█████▌    | 536/966 [01:02<00:50,  8.49it/s] 56%|█████▌    | 537/966 [01:03<00:50,  8.50it/s] 56%|█████▌    | 538/966 [01:03<00:50,  8.49it/s] 56%|█████▌    | 539/966 [01:03<00:50,  8.49it/s] 56%|█████▌    | 540/966 [01:03<00:50,  8.48it/s] 56%|█████▌    | 541/966 [01:03<00:50,  8.49it/s] 56%|█████▌    | 542/966 [01:03<00:49,  8.51it/s] 56%|█████▌    | 543/966 [01:03<00:49,  8.51it/s] 56%|█████▋    | 544/966 [01:03<00:49,  8.51it/s] 56%|█████▋    | 545/966 [01:03<00:49,  8.52it/s] 57%|█████▋    | 546/966 [01:04<00:49,  8.51it/s] 57%|█████▋    | 547/966 [01:04<00:49,  8.53it/s] 57%|█████▋    | 548/966 [01:04<00:48,  8.54it/s] 57%|█████▋    | 549/966 [01:04<00:48,  8.54it/s] 57%|█████▋    | 550/966 [01:04<00:48,  8.53it/s] 57%|█████▋    | 551/966 [01:04<00:48,  8.53it/s] 57%|█████▋    | 552/966 [01:04<00:48,  8.53it/s] 57%|█████▋    | 553/966 [01:04<00:48,  8.52it/s] 57%|█████▋    | 554/966 [01:05<00:48,  8.53it/s] 57%|█████▋    | 555/966 [01:05<00:48,  8.52it/s] 58%|█████▊    | 556/966 [01:05<00:48,  8.50it/s] 58%|█████▊    | 557/966 [01:05<00:48,  8.49it/s] 58%|█████▊    | 558/966 [01:05<00:48,  8.49it/s] 58%|█████▊    | 559/966 [01:05<00:47,  8.51it/s] 58%|█████▊    | 560/966 [01:05<00:47,  8.52it/s] 58%|█████▊    | 561/966 [01:05<00:47,  8.52it/s] 58%|█████▊    | 562/966 [01:05<00:47,  8.50it/s] 58%|█████▊    | 563/966 [01:06<00:47,  8.49it/s] 58%|█████▊    | 564/966 [01:06<00:47,  8.50it/s] 58%|█████▊    | 565/966 [01:06<00:47,  8.51it/s] 59%|█████▊    | 566/966 [01:06<00:46,  8.51it/s] 59%|█████▊    | 567/966 [01:06<00:46,  8.49it/s] 59%|█████▉    | 568/966 [01:06<00:46,  8.49it/s] 59%|█████▉    | 569/966 [01:06<00:46,  8.48it/s] 59%|█████▉    | 570/966 [01:06<00:46,  8.47it/s] 59%|█████▉    | 571/966 [01:07<00:46,  8.46it/s] 59%|█████▉    | 572/966 [01:07<00:46,  8.46it/s] 59%|█████▉    | 573/966 [01:07<00:46,  8.46it/s] 59%|█████▉    | 574/966 [01:07<00:46,  8.45it/s] 60%|█████▉    | 575/966 [01:07<00:46,  8.44it/s] 60%|█████▉    | 576/966 [01:07<00:46,  8.45it/s] 60%|█████▉    | 577/966 [01:07<00:46,  8.45it/s] 60%|█████▉    | 578/966 [01:07<00:45,  8.45it/s] 60%|█████▉    | 579/966 [01:07<00:45,  8.46it/s] 60%|██████    | 580/966 [01:08<00:45,  8.48it/s] 60%|██████    | 581/966 [01:08<00:45,  8.48it/s] 60%|██████    | 582/966 [01:08<00:45,  8.49it/s] 60%|██████    | 583/966 [01:08<00:44,  8.51it/s] 60%|██████    | 584/966 [01:08<00:44,  8.52it/s] 61%|██████    | 585/966 [01:08<00:44,  8.52it/s] 61%|██████    | 586/966 [01:08<00:44,  8.51it/s] 61%|██████    | 587/966 [01:08<00:44,  8.50it/s] 61%|██████    | 588/966 [01:09<00:44,  8.51it/s] 61%|██████    | 589/966 [01:09<00:44,  8.52it/s] 61%|██████    | 590/966 [01:09<00:44,  8.54it/s] 61%|██████    | 591/966 [01:09<00:43,  8.54it/s] 61%|██████▏   | 592/966 [01:09<00:43,  8.54it/s] 61%|██████▏   | 593/966 [01:09<00:43,  8.54it/s] 61%|██████▏   | 594/966 [01:09<00:43,  8.54it/s] 62%|██████▏   | 595/966 [01:09<00:43,  8.55it/s] 62%|██████▏   | 596/966 [01:09<00:43,  8.57it/s] 62%|██████▏   | 597/966 [01:10<00:43,  8.56it/s] 62%|██████▏   | 598/966 [01:10<00:43,  8.53it/s] 62%|██████▏   | 599/966 [01:10<00:43,  8.51it/s] 62%|██████▏   | 600/966 [01:10<00:43,  8.49it/s] 62%|██████▏   | 601/966 [01:10<00:43,  8.47it/s] 62%|██████▏   | 602/966 [01:10<00:42,  8.47it/s] 62%|██████▏   | 603/966 [01:10<00:42,  8.47it/s] 63%|██████▎   | 604/966 [01:10<00:42,  8.48it/s] 63%|██████▎   | 605/966 [01:11<00:42,  8.49it/s] 63%|██████▎   | 606/966 [01:11<00:42,  8.50it/s] 63%|██████▎   | 607/966 [01:11<00:42,  8.51it/s] 63%|██████▎   | 608/966 [01:11<00:42,  8.51it/s] 63%|██████▎   | 609/966 [01:11<00:41,  8.50it/s] 63%|██████▎   | 610/966 [01:11<00:41,  8.49it/s] 63%|██████▎   | 611/966 [01:11<00:41,  8.49it/s] 63%|██████▎   | 612/966 [01:11<00:41,  8.49it/s] 63%|██████▎   | 613/966 [01:11<00:41,  8.49it/s] 64%|██████▎   | 614/966 [01:12<00:41,  8.48it/s] 64%|██████▎   | 615/966 [01:12<00:41,  8.47it/s] 64%|██████▍   | 616/966 [01:12<00:41,  8.47it/s] 64%|██████▍   | 617/966 [01:12<00:41,  8.48it/s] 64%|██████▍   | 618/966 [01:12<00:40,  8.50it/s] 64%|██████▍   | 619/966 [01:12<00:40,  8.51it/s] 64%|██████▍   | 620/966 [01:12<00:40,  8.51it/s] 64%|██████▍   | 621/966 [01:12<00:40,  8.51it/s] 64%|██████▍   | 622/966 [01:13<00:40,  8.51it/s] 64%|██████▍   | 623/966 [01:13<00:40,  8.51it/s] 65%|██████▍   | 624/966 [01:13<00:40,  8.51it/s] 65%|██████▍   | 625/966 [01:13<00:40,  8.51it/s] 65%|██████▍   | 626/966 [01:13<00:39,  8.53it/s] 65%|██████▍   | 627/966 [01:13<00:39,  8.54it/s] 65%|██████▌   | 628/966 [01:13<00:39,  8.53it/s] 65%|██████▌   | 629/966 [01:13<00:39,  8.53it/s] 65%|██████▌   | 630/966 [01:13<00:39,  8.52it/s] 65%|██████▌   | 631/966 [01:14<00:39,  8.52it/s] 65%|██████▌   | 632/966 [01:14<00:39,  8.55it/s] 66%|██████▌   | 633/966 [01:14<00:38,  8.54it/s] 66%|██████▌   | 634/966 [01:14<00:38,  8.55it/s] 66%|██████▌   | 635/966 [01:14<00:38,  8.52it/s] 66%|██████▌   | 636/966 [01:14<00:38,  8.52it/s] 66%|██████▌   | 637/966 [01:14<00:38,  8.53it/s] 66%|██████▌   | 638/966 [01:14<00:38,  8.52it/s] 66%|██████▌   | 639/966 [01:15<00:38,  8.53it/s] 66%|██████▋   | 640/966 [01:15<00:38,  8.54it/s] 66%|██████▋   | 641/966 [01:15<00:38,  8.54it/s] 66%|██████▋   | 642/966 [01:15<00:38,  8.51it/s] 67%|██████▋   | 643/966 [01:15<00:38,  8.48it/s] 67%|██████▋   | 644/966 [01:15<00:38,  8.47it/s] 67%|██████▋   | 645/966 [01:15<00:37,  8.48it/s] 67%|██████▋   | 646/966 [01:15<00:37,  8.49it/s] 67%|██████▋   | 647/966 [01:15<00:37,  8.51it/s] 67%|██████▋   | 648/966 [01:16<00:37,  8.52it/s] 67%|██████▋   | 649/966 [01:16<00:37,  8.53it/s] 67%|██████▋   | 650/966 [01:16<00:37,  8.52it/s] 67%|██████▋   | 651/966 [01:16<00:36,  8.53it/s] 67%|██████▋   | 652/966 [01:16<00:36,  8.53it/s] 68%|██████▊   | 653/966 [01:16<00:36,  8.52it/s] 68%|██████▊   | 654/966 [01:16<00:36,  8.51it/s] 68%|██████▊   | 655/966 [01:16<00:36,  8.49it/s] 68%|██████▊   | 656/966 [01:17<00:36,  8.49it/s] 68%|██████▊   | 657/966 [01:17<00:36,  8.50it/s] 68%|██████▊   | 658/966 [01:17<00:36,  8.51it/s] 68%|██████▊   | 659/966 [01:17<00:36,  8.50it/s] 68%|██████▊   | 660/966 [01:17<00:35,  8.51it/s] 68%|██████▊   | 661/966 [01:17<00:35,  8.51it/s] 69%|██████▊   | 662/966 [01:17<00:35,  8.51it/s] 69%|██████▊   | 663/966 [01:17<00:35,  8.51it/s] 69%|██████▊   | 664/966 [01:17<00:35,  8.49it/s] 69%|██████▉   | 665/966 [01:18<00:35,  8.51it/s] 69%|██████▉   | 666/966 [01:18<00:35,  8.51it/s] 69%|██████▉   | 667/966 [01:18<00:35,  8.53it/s] 69%|██████▉   | 668/966 [01:18<00:34,  8.53it/s] 69%|██████▉   | 669/966 [01:18<00:34,  8.51it/s] 69%|██████▉   | 670/966 [01:18<00:34,  8.50it/s] 69%|██████▉   | 671/966 [01:18<00:34,  8.51it/s] 70%|██████▉   | 672/966 [01:18<00:34,  8.52it/s] 70%|██████▉   | 673/966 [01:19<00:34,  8.53it/s] 70%|██████▉   | 674/966 [01:19<00:34,  8.53it/s] 70%|██████▉   | 675/966 [01:19<00:34,  8.54it/s] 70%|██████▉   | 676/966 [01:19<00:34,  8.52it/s] 70%|███████   | 677/966 [01:19<00:33,  8.50it/s] 70%|███████   | 678/966 [01:19<00:33,  8.52it/s] 70%|███████   | 679/966 [01:19<00:33,  8.52it/s] 70%|███████   | 680/966 [01:19<00:33,  8.53it/s] 70%|███████   | 681/966 [01:19<00:33,  8.53it/s] 71%|███████   | 682/966 [01:20<00:33,  8.50it/s] 71%|███████   | 683/966 [01:20<00:33,  8.50it/s] 71%|███████   | 684/966 [01:20<00:33,  8.50it/s] 71%|███████   | 685/966 [01:20<00:33,  8.51it/s] 71%|███████   | 686/966 [01:20<00:32,  8.49it/s] 71%|███████   | 687/966 [01:20<00:32,  8.50it/s] 71%|███████   | 688/966 [01:20<00:32,  8.51it/s] 71%|███████▏  | 689/966 [01:20<00:32,  8.51it/s] 71%|███████▏  | 690/966 [01:21<00:32,  8.51it/s] 72%|███████▏  | 691/966 [01:21<00:32,  8.51it/s] 72%|███████▏  | 692/966 [01:21<00:32,  8.52it/s] 72%|███████▏  | 693/966 [01:21<00:32,  8.53it/s] 72%|███████▏  | 694/966 [01:21<00:31,  8.51it/s] 72%|███████▏  | 695/966 [01:21<00:31,  8.51it/s] 72%|███████▏  | 696/966 [01:21<00:31,  8.51it/s] 72%|███████▏  | 697/966 [01:21<00:31,  8.51it/s] 72%|███████▏  | 698/966 [01:21<00:31,  8.50it/s] 72%|███████▏  | 699/966 [01:22<00:31,  8.49it/s] 72%|███████▏  | 700/966 [01:22<00:31,  8.47it/s] 73%|███████▎  | 701/966 [01:22<00:31,  8.47it/s] 73%|███████▎  | 702/966 [01:22<00:31,  8.46it/s] 73%|███████▎  | 703/966 [01:22<00:31,  8.45it/s] 73%|███████▎  | 704/966 [01:22<00:30,  8.48it/s] 73%|███████▎  | 705/966 [01:22<00:30,  8.50it/s] 73%|███████▎  | 706/966 [01:22<00:30,  8.50it/s] 73%|███████▎  | 707/966 [01:23<00:30,  8.51it/s] 73%|███████▎  | 708/966 [01:23<00:30,  8.52it/s] 73%|███████▎  | 709/966 [01:23<00:30,  8.52it/s] 73%|███████▎  | 710/966 [01:23<00:30,  8.50it/s] 74%|███████▎  | 711/966 [01:23<00:29,  8.52it/s] 74%|███████▎  | 712/966 [01:23<00:29,  8.51it/s] 74%|███████▍  | 713/966 [01:23<00:29,  8.51it/s] 74%|███████▍  | 714/966 [01:23<00:29,  8.52it/s] 74%|███████▍  | 715/966 [01:23<00:29,  8.54it/s] 74%|███████▍  | 716/966 [01:24<00:29,  8.54it/s] 74%|███████▍  | 717/966 [01:24<00:29,  8.54it/s] 74%|███████▍  | 718/966 [01:24<00:29,  8.54it/s] 74%|███████▍  | 719/966 [01:24<00:28,  8.54it/s] 75%|███████▍  | 720/966 [01:24<00:28,  8.54it/s] 75%|███████▍  | 721/966 [01:24<00:28,  8.54it/s] 75%|███████▍  | 722/966 [01:24<00:28,  8.54it/s] 75%|███████▍  | 723/966 [01:24<00:28,  8.54it/s] 75%|███████▍  | 724/966 [01:24<00:28,  8.54it/s] 75%|███████▌  | 725/966 [01:25<00:28,  8.53it/s] 75%|███████▌  | 726/966 [01:25<00:28,  8.53it/s] 75%|███████▌  | 727/966 [01:25<00:28,  8.52it/s] 75%|███████▌  | 728/966 [01:25<00:27,  8.53it/s] 75%|███████▌  | 729/966 [01:25<00:27,  8.51it/s] 76%|███████▌  | 730/966 [01:25<00:27,  8.52it/s] 76%|███████▌  | 731/966 [01:25<00:27,  8.53it/s] 76%|███████▌  | 732/966 [01:25<00:27,  8.53it/s] 76%|███████▌  | 733/966 [01:26<00:27,  8.52it/s] 76%|███████▌  | 734/966 [01:26<00:27,  8.52it/s] 76%|███████▌  | 735/966 [01:26<00:27,  8.51it/s] 76%|███████▌  | 736/966 [01:26<00:27,  8.51it/s] 76%|███████▋  | 737/966 [01:26<00:26,  8.50it/s] 76%|███████▋  | 738/966 [01:26<00:26,  8.50it/s] 77%|███████▋  | 739/966 [01:26<00:26,  8.50it/s] 77%|███████▋  | 740/966 [01:26<00:26,  8.50it/s] 77%|███████▋  | 741/966 [01:26<00:26,  8.50it/s] 77%|███████▋  | 742/966 [01:27<00:26,  8.48it/s] 77%|███████▋  | 743/966 [01:27<00:26,  8.49it/s] 77%|███████▋  | 744/966 [01:27<00:26,  8.50it/s] 77%|███████▋  | 745/966 [01:27<00:25,  8.51it/s] 77%|███████▋  | 746/966 [01:27<00:25,  8.51it/s] 77%|███████▋  | 747/966 [01:27<00:25,  8.51it/s] 77%|███████▋  | 748/966 [01:27<00:25,  8.51it/s] 78%|███████▊  | 749/966 [01:27<00:25,  8.51it/s] 78%|███████▊  | 750/966 [01:28<00:25,  8.51it/s] 78%|███████▊  | 751/966 [01:28<00:25,  8.52it/s] 78%|███████▊  | 752/966 [01:28<00:25,  8.53it/s] 78%|███████▊  | 753/966 [01:28<00:24,  8.53it/s] 78%|███████▊  | 754/966 [01:28<00:24,  8.52it/s] 78%|███████▊  | 755/966 [01:28<00:24,  8.51it/s] 78%|███████▊  | 756/966 [01:28<00:24,  8.51it/s] 78%|███████▊  | 757/966 [01:28<00:24,  8.52it/s] 78%|███████▊  | 758/966 [01:28<00:24,  8.52it/s] 79%|███████▊  | 759/966 [01:29<00:24,  8.50it/s] 79%|███████▊  | 760/966 [01:29<00:24,  8.51it/s] 79%|███████▉  | 761/966 [01:29<00:24,  8.52it/s] 79%|███████▉  | 762/966 [01:29<00:23,  8.52it/s] 79%|███████▉  | 763/966 [01:29<00:23,  8.52it/s] 79%|███████▉  | 764/966 [01:29<00:23,  8.50it/s] 79%|███████▉  | 765/966 [01:29<00:23,  8.50it/s] 79%|███████▉  | 766/966 [01:29<00:23,  8.50it/s] 79%|███████▉  | 767/966 [01:30<00:23,  8.51it/s] 80%|███████▉  | 768/966 [01:30<00:23,  8.51it/s] 80%|███████▉  | 769/966 [01:30<00:23,  8.51it/s] 80%|███████▉  | 770/966 [01:30<00:22,  8.53it/s] 80%|███████▉  | 771/966 [01:30<00:22,  8.53it/s] 80%|███████▉  | 772/966 [01:30<00:22,  8.52it/s] 80%|████████  | 773/966 [01:30<00:22,  8.49it/s] 80%|████████  | 774/966 [01:30<00:22,  8.48it/s] 80%|████████  | 775/966 [01:30<00:22,  8.46it/s] 80%|████████  | 776/966 [01:31<00:22,  8.47it/s] 80%|████████  | 777/966 [01:31<00:22,  8.48it/s] 81%|████████  | 778/966 [01:31<00:22,  8.49it/s] 81%|████████  | 779/966 [01:31<00:22,  8.48it/s] 81%|████████  | 780/966 [01:31<00:21,  8.49it/s] 81%|████████  | 781/966 [01:31<00:21,  8.48it/s] 81%|████████  | 782/966 [01:31<00:21,  8.47it/s] 81%|████████  | 783/966 [01:31<00:21,  8.46it/s] 81%|████████  | 784/966 [01:32<00:21,  8.46it/s] 81%|████████▏ | 785/966 [01:32<00:21,  8.45it/s] 81%|████████▏ | 786/966 [01:32<00:21,  8.45it/s] 81%|████████▏ | 787/966 [01:32<00:21,  8.46it/s] 82%|████████▏ | 788/966 [01:32<00:20,  8.48it/s] 82%|████████▏ | 789/966 [01:32<00:20,  8.50it/s] 82%|████████▏ | 790/966 [01:32<00:20,  8.51it/s] 82%|████████▏ | 791/966 [01:32<00:20,  8.51it/s] 82%|████████▏ | 792/966 [01:32<00:20,  8.51it/s] 82%|████████▏ | 793/966 [01:33<00:20,  8.52it/s] 82%|████████▏ | 794/966 [01:33<00:20,  8.53it/s] 82%|████████▏ | 795/966 [01:33<00:20,  8.53it/s] 82%|████████▏ | 796/966 [01:33<00:19,  8.54it/s] 83%|████████▎ | 797/966 [01:33<00:19,  8.54it/s] 83%|████████▎ | 798/966 [01:33<00:19,  8.53it/s] 83%|████████▎ | 799/966 [01:33<00:19,  8.54it/s] 83%|████████▎ | 800/966 [01:33<00:19,  8.55it/s] 83%|████████▎ | 801/966 [01:34<00:19,  8.55it/s] 83%|████████▎ | 802/966 [01:34<00:19,  8.53it/s] 83%|████████▎ | 803/966 [01:34<00:19,  8.53it/s] 83%|████████▎ | 804/966 [01:34<00:18,  8.53it/s] 83%|████████▎ | 805/966 [01:34<00:18,  8.54it/s] 83%|████████▎ | 806/966 [01:34<00:18,  8.54it/s] 84%|████████▎ | 807/966 [01:34<00:18,  8.54it/s] 84%|████████▎ | 808/966 [01:34<00:18,  8.53it/s] 84%|████████▎ | 809/966 [01:34<00:18,  8.52it/s] 84%|████████▍ | 810/966 [01:35<00:18,  8.51it/s] 84%|████████▍ | 811/966 [01:35<00:18,  8.52it/s] 84%|████████▍ | 812/966 [01:35<00:18,  8.52it/s] 84%|████████▍ | 813/966 [01:35<00:17,  8.52it/s] 84%|████████▍ | 814/966 [01:35<00:17,  8.52it/s] 84%|████████▍ | 815/966 [01:35<00:17,  8.52it/s] 84%|████████▍ | 816/966 [01:35<00:17,  8.54it/s] 85%|████████▍ | 817/966 [01:35<00:17,  8.53it/s] 85%|████████▍ | 818/966 [01:36<00:17,  8.53it/s] 85%|████████▍ | 819/966 [01:36<00:17,  8.51it/s] 85%|████████▍ | 820/966 [01:36<00:17,  8.51it/s] 85%|████████▍ | 821/966 [01:36<00:17,  8.51it/s] 85%|████████▌ | 822/966 [01:36<00:16,  8.50it/s] 85%|████████▌ | 823/966 [01:36<00:16,  8.49it/s] 85%|████████▌ | 824/966 [01:36<00:16,  8.48it/s] 85%|████████▌ | 825/966 [01:36<00:16,  8.49it/s] 86%|████████▌ | 826/966 [01:36<00:16,  8.49it/s] 86%|████████▌ | 827/966 [01:37<00:16,  8.50it/s] 86%|████████▌ | 828/966 [01:37<00:16,  8.50it/s] 86%|████████▌ | 829/966 [01:37<00:16,  8.51it/s] 86%|████████▌ | 830/966 [01:37<00:15,  8.51it/s] 86%|████████▌ | 831/966 [01:37<00:15,  8.52it/s] 86%|████████▌ | 832/966 [01:37<00:15,  8.54it/s] 86%|████████▌ | 833/966 [01:37<00:15,  8.54it/s] 86%|████████▋ | 834/966 [01:37<00:15,  8.52it/s] 86%|████████▋ | 835/966 [01:38<00:15,  8.54it/s] 87%|████████▋ | 836/966 [01:38<00:15,  8.54it/s] 87%|████████▋ | 837/966 [01:38<00:15,  8.53it/s] 87%|████████▋ | 838/966 [01:38<00:15,  8.50it/s] 87%|████████▋ | 839/966 [01:38<00:14,  8.49it/s] 87%|████████▋ | 840/966 [01:38<00:14,  8.49it/s] 87%|████████▋ | 841/966 [01:38<00:14,  8.48it/s] 87%|████████▋ | 842/966 [01:38<00:14,  8.50it/s] 87%|████████▋ | 843/966 [01:38<00:14,  8.51it/s] 87%|████████▋ | 844/966 [01:39<00:14,  8.51it/s] 87%|████████▋ | 845/966 [01:39<00:14,  8.52it/s] 88%|████████▊ | 846/966 [01:39<00:14,  8.53it/s] 88%|████████▊ | 847/966 [01:39<00:13,  8.51it/s] 88%|████████▊ | 848/966 [01:39<00:13,  8.52it/s] 88%|████████▊ | 849/966 [01:39<00:13,  8.53it/s] 88%|████████▊ | 850/966 [01:39<00:13,  8.54it/s] 88%|████████▊ | 851/966 [01:39<00:13,  8.54it/s] 88%|████████▊ | 852/966 [01:40<00:13,  8.56it/s] 88%|████████▊ | 853/966 [01:40<00:13,  8.54it/s] 88%|████████▊ | 854/966 [01:40<00:13,  8.52it/s] 89%|████████▊ | 855/966 [01:40<00:13,  8.52it/s] 89%|████████▊ | 856/966 [01:40<00:12,  8.51it/s] 89%|████████▊ | 857/966 [01:40<00:12,  8.52it/s] 89%|████████▉ | 858/966 [01:40<00:12,  8.52it/s] 89%|████████▉ | 859/966 [01:40<00:12,  8.52it/s] 89%|████████▉ | 860/966 [01:40<00:12,  8.53it/s] 89%|████████▉ | 861/966 [01:41<00:12,  8.53it/s] 89%|████████▉ | 862/966 [01:41<00:12,  8.53it/s] 89%|████████▉ | 863/966 [01:41<00:12,  8.51it/s] 89%|████████▉ | 864/966 [01:41<00:12,  8.49it/s] 90%|████████▉ | 865/966 [01:41<00:11,  8.49it/s] 90%|████████▉ | 866/966 [01:41<00:11,  8.48it/s] 90%|████████▉ | 867/966 [01:41<00:11,  8.47it/s] 90%|████████▉ | 868/966 [01:41<00:11,  8.47it/s] 90%|████████▉ | 869/966 [01:42<00:11,  8.46it/s] 90%|█████████ | 870/966 [01:42<00:11,  8.46it/s] 90%|█████████ | 871/966 [01:42<00:11,  8.47it/s] 90%|█████████ | 872/966 [01:42<00:11,  8.51it/s] 90%|█████████ | 873/966 [01:42<00:10,  8.51it/s] 90%|█████████ | 874/966 [01:42<00:10,  8.50it/s] 91%|█████████ | 875/966 [01:42<00:10,  8.52it/s] 91%|█████████ | 876/966 [01:42<00:10,  8.52it/s] 91%|█████████ | 877/966 [01:42<00:10,  8.55it/s] 91%|█████████ | 878/966 [01:43<00:10,  8.56it/s] 91%|█████████ | 879/966 [01:43<00:10,  8.53it/s] 91%|█████████ | 880/966 [01:43<00:10,  8.53it/s] 91%|█████████ | 881/966 [01:43<00:09,  8.50it/s] 91%|█████████▏| 882/966 [01:43<00:09,  8.51it/s] 91%|█████████▏| 883/966 [01:43<00:09,  8.53it/s] 92%|█████████▏| 884/966 [01:43<00:09,  8.55it/s] 92%|█████████▏| 885/966 [01:43<00:09,  8.55it/s] 92%|█████████▏| 886/966 [01:44<00:09,  8.54it/s] 92%|█████████▏| 887/966 [01:44<00:09,  8.51it/s] 92%|█████████▏| 888/966 [01:44<00:09,  8.51it/s] 92%|█████████▏| 889/966 [01:44<00:09,  8.52it/s] 92%|█████████▏| 890/966 [01:44<00:08,  8.52it/s] 92%|█████████▏| 891/966 [01:44<00:08,  8.50it/s] 92%|█████████▏| 892/966 [01:44<00:08,  8.49it/s] 92%|█████████▏| 893/966 [01:44<00:08,  8.50it/s] 93%|█████████▎| 894/966 [01:44<00:08,  8.50it/s] 93%|█████████▎| 895/966 [01:45<00:08,  8.49it/s] 93%|█████████▎| 896/966 [01:45<00:08,  8.49it/s] 93%|█████████▎| 897/966 [01:45<00:08,  8.50it/s] 93%|█████████▎| 898/966 [01:45<00:07,  8.50it/s] 93%|█████████▎| 899/966 [01:45<00:07,  8.51it/s] 93%|█████████▎| 900/966 [01:45<00:07,  8.49it/s] 93%|█████████▎| 901/966 [01:45<00:07,  8.52it/s] 93%|█████████▎| 902/966 [01:45<00:07,  8.53it/s] 93%|█████████▎| 903/966 [01:46<00:07,  8.54it/s] 94%|█████████▎| 904/966 [01:46<00:07,  8.55it/s] 94%|█████████▎| 905/966 [01:46<00:07,  8.54it/s] 94%|█████████▍| 906/966 [01:46<00:07,  8.54it/s] 94%|█████████▍| 907/966 [01:46<00:06,  8.52it/s] 94%|█████████▍| 908/966 [01:46<00:06,  8.51it/s] 94%|█████████▍| 909/966 [01:46<00:06,  8.51it/s] 94%|█████████▍| 910/966 [01:46<00:06,  8.50it/s] 94%|█████████▍| 911/966 [01:46<00:06,  8.51it/s] 94%|█████████▍| 912/966 [01:47<00:06,  8.50it/s] 95%|█████████▍| 913/966 [01:47<00:06,  8.51it/s] 95%|█████████▍| 914/966 [01:47<00:06,  8.49it/s] 95%|█████████▍| 915/966 [01:47<00:06,  8.49it/s] 95%|█████████▍| 916/966 [01:47<00:05,  8.48it/s] 95%|█████████▍| 917/966 [01:47<00:05,  8.48it/s] 95%|█████████▌| 918/966 [01:47<00:05,  8.48it/s] 95%|█████████▌| 919/966 [01:47<00:05,  8.50it/s] 95%|█████████▌| 920/966 [01:48<00:05,  8.50it/s] 95%|█████████▌| 921/966 [01:48<00:05,  8.50it/s] 95%|█████████▌| 922/966 [01:48<00:05,  8.51it/s] 96%|█████████▌| 923/966 [01:48<00:05,  8.52it/s] 96%|█████████▌| 924/966 [01:48<00:04,  8.51it/s] 96%|█████████▌| 925/966 [01:48<00:04,  8.53it/s] 96%|█████████▌| 926/966 [01:48<00:04,  8.54it/s] 96%|█████████▌| 927/966 [01:48<00:04,  8.54it/s] 96%|█████████▌| 928/966 [01:48<00:04,  8.55it/s] 96%|█████████▌| 929/966 [01:49<00:04,  8.53it/s] 96%|█████████▋| 930/966 [01:49<00:04,  8.49it/s] 96%|█████████▋| 931/966 [01:49<00:04,  8.49it/s] 96%|█████████▋| 932/966 [01:49<00:03,  8.51it/s] 97%|█████████▋| 933/966 [01:49<00:03,  8.50it/s] 97%|█████████▋| 934/966 [01:49<00:03,  8.51it/s] 97%|█████████▋| 935/966 [01:49<00:03,  8.51it/s] 97%|█████████▋| 936/966 [01:49<00:03,  8.51it/s] 97%|█████████▋| 937/966 [01:50<00:03,  8.52it/s] 97%|█████████▋| 938/966 [01:50<00:03,  8.53it/s] 97%|█████████▋| 939/966 [01:50<00:03,  8.53it/s] 97%|█████████▋| 940/966 [01:50<00:03,  8.52it/s] 97%|█████████▋| 941/966 [01:50<00:02,  8.50it/s] 98%|█████████▊| 942/966 [01:50<00:02,  8.50it/s] 98%|█████████▊| 943/966 [01:50<00:02,  8.51it/s] 98%|█████████▊| 944/966 [01:50<00:02,  8.52it/s] 98%|█████████▊| 945/966 [01:50<00:02,  8.51it/s] 98%|█████████▊| 946/966 [01:51<00:02,  8.49it/s] 98%|█████████▊| 947/966 [01:51<00:02,  8.47it/s] 98%|█████████▊| 948/966 [01:51<00:02,  8.47it/s] 98%|█████████▊| 949/966 [01:51<00:02,  8.49it/s] 98%|█████████▊| 950/966 [01:51<00:01,  8.50it/s] 98%|█████████▊| 951/966 [01:51<00:01,  8.51it/s] 99%|█████████▊| 952/966 [01:51<00:01,  8.52it/s] 99%|█████████▊| 953/966 [01:51<00:01,  8.52it/s] 99%|█████████▉| 954/966 [01:52<00:01,  8.53it/s] 99%|█████████▉| 955/966 [01:52<00:01,  8.51it/s] 99%|█████████▉| 956/966 [01:52<00:01,  8.50it/s] 99%|█████████▉| 957/966 [01:52<00:01,  8.49it/s] 99%|█████████▉| 958/966 [01:52<00:00,  8.50it/s] 99%|█████████▉| 959/966 [01:52<00:00,  8.51it/s] 99%|█████████▉| 960/966 [01:52<00:00,  8.50it/s] 99%|█████████▉| 961/966 [01:52<00:00,  8.49it/s]100%|█████████▉| 962/966 [01:52<00:00,  8.49it/s]100%|█████████▉| 963/966 [01:53<00:00,  8.50it/s]100%|█████████▉| 964/966 [01:53<00:00,  8.51it/s]100%|█████████▉| 965/966 [01:53<00:00,  8.50it/s]100%|██████████| 966/966 [01:53<00:00,  8.49it/s]100%|██████████| 966/966 [01:53<00:00,  8.52it/s]
sending off prediction to background worker for resampling and export
done with 706-005
Renaming  to _finetuned_with_Genesis
Completed FOLD 2 CONFIG 3d_32x160x128_b10 TRAINER nnUNetTrainer
