/home/gridsan/nchutisilp/.conda/envs/nnunet/bin/python
wandb: Tracking run with wandb version 0.16.6
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2024-07-03 18:21:11.029328: Using torch.compile...
/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
################### Loading pretrained weights from file  /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset300_Lumen_and_Wall_OCT/nnUNetTrainer__nnUNetPreprocessPlans__3d_fullres/fold_all/checkpoint_best.pth ###################
Below is the list of overlapping blocks in pretrained model and nnUNet architecture:
encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])
encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])
encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])
encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])
encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])
encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])
encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])
encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])
encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])
encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])
encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])
encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])
encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])
encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])
encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])
encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])
encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])
encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])
encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])
encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])
encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])
encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])
encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])
encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])
encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])
encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])
encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])
decoder.encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])
decoder.encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])
decoder.encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])
decoder.encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])
decoder.encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])
decoder.encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])
decoder.encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])
decoder.encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])
decoder.encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])
decoder.encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])
decoder.encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])
decoder.encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])
decoder.encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])
decoder.encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.stages.0.convs.0.conv.weight shape torch.Size([320, 640, 3, 3, 3])
decoder.stages.0.convs.0.conv.bias shape torch.Size([320])
decoder.stages.0.convs.0.norm.weight shape torch.Size([320])
decoder.stages.0.convs.0.norm.bias shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.0.weight shape torch.Size([320, 640, 3, 3, 3])
decoder.stages.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.stages.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.stages.0.convs.1.conv.bias shape torch.Size([320])
decoder.stages.0.convs.1.norm.weight shape torch.Size([320])
decoder.stages.0.convs.1.norm.bias shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.stages.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.stages.1.convs.0.conv.weight shape torch.Size([256, 512, 3, 3, 3])
decoder.stages.1.convs.0.conv.bias shape torch.Size([256])
decoder.stages.1.convs.0.norm.weight shape torch.Size([256])
decoder.stages.1.convs.0.norm.bias shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.0.weight shape torch.Size([256, 512, 3, 3, 3])
decoder.stages.1.convs.0.all_modules.0.bias shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.1.weight shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.1.bias shape torch.Size([256])
decoder.stages.1.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.stages.1.convs.1.conv.bias shape torch.Size([256])
decoder.stages.1.convs.1.norm.weight shape torch.Size([256])
decoder.stages.1.convs.1.norm.bias shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.stages.1.convs.1.all_modules.0.bias shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.1.weight shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.1.bias shape torch.Size([256])
decoder.stages.2.convs.0.conv.weight shape torch.Size([128, 256, 3, 3, 3])
decoder.stages.2.convs.0.conv.bias shape torch.Size([128])
decoder.stages.2.convs.0.norm.weight shape torch.Size([128])
decoder.stages.2.convs.0.norm.bias shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.0.weight shape torch.Size([128, 256, 3, 3, 3])
decoder.stages.2.convs.0.all_modules.0.bias shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.1.weight shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.1.bias shape torch.Size([128])
decoder.stages.2.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.stages.2.convs.1.conv.bias shape torch.Size([128])
decoder.stages.2.convs.1.norm.weight shape torch.Size([128])
decoder.stages.2.convs.1.norm.bias shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.stages.2.convs.1.all_modules.0.bias shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.1.weight shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.1.bias shape torch.Size([128])
decoder.stages.3.convs.0.conv.weight shape torch.Size([64, 128, 3, 3, 3])
decoder.stages.3.convs.0.conv.bias shape torch.Size([64])
decoder.stages.3.convs.0.norm.weight shape torch.Size([64])
decoder.stages.3.convs.0.norm.bias shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.0.weight shape torch.Size([64, 128, 3, 3, 3])
decoder.stages.3.convs.0.all_modules.0.bias shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.1.weight shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.1.bias shape torch.Size([64])
decoder.stages.3.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.stages.3.convs.1.conv.bias shape torch.Size([64])
decoder.stages.3.convs.1.norm.weight shape torch.Size([64])
decoder.stages.3.convs.1.norm.bias shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.stages.3.convs.1.all_modules.0.bias shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.1.weight shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.1.bias shape torch.Size([64])
decoder.stages.4.convs.0.conv.weight shape torch.Size([32, 64, 3, 3, 3])
decoder.stages.4.convs.0.conv.bias shape torch.Size([32])
decoder.stages.4.convs.0.norm.weight shape torch.Size([32])
decoder.stages.4.convs.0.norm.bias shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.0.weight shape torch.Size([32, 64, 3, 3, 3])
decoder.stages.4.convs.0.all_modules.0.bias shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.1.weight shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.1.bias shape torch.Size([32])
decoder.stages.4.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.stages.4.convs.1.conv.bias shape torch.Size([32])
decoder.stages.4.convs.1.norm.weight shape torch.Size([32])
decoder.stages.4.convs.1.norm.bias shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.stages.4.convs.1.all_modules.0.bias shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.1.weight shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.1.bias shape torch.Size([32])
decoder.transpconvs.0.weight shape torch.Size([320, 320, 1, 2, 2])
decoder.transpconvs.0.bias shape torch.Size([320])
decoder.transpconvs.1.weight shape torch.Size([320, 256, 2, 2, 2])
decoder.transpconvs.1.bias shape torch.Size([256])
decoder.transpconvs.2.weight shape torch.Size([256, 128, 2, 2, 2])
decoder.transpconvs.2.bias shape torch.Size([128])
decoder.transpconvs.3.weight shape torch.Size([128, 64, 2, 2, 2])
decoder.transpconvs.3.bias shape torch.Size([64])
decoder.transpconvs.4.weight shape torch.Size([64, 32, 2, 2, 2])
decoder.transpconvs.4.bias shape torch.Size([32])
################### Done ###################
2024-07-03 18:21:25.615700: do_dummy_2d_data_aug: False
using pin_memory on device 0
using pin_memory on device 0

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [112, 160, 128], 'median_image_size_in_voxels': [375.0, 498.0, 498.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset302_Calcium_OCTv2', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.4977976381778717, 'mean': 0.13332499563694, 'median': 0.08871842920780182, 'min': 0.0, 'percentile_00_5': 0.014754901640117168, 'percentile_99_5': 0.4977976381778717, 'std': 0.12022686749696732}}} 

2024-07-03 18:21:36.780865: unpacking dataset...
2024-07-03 18:21:43.239527: unpacking done...
2024-07-03 18:21:43.454754: Unable to plot network architecture: nnUNet_compile is enabled!
2024-07-03 18:21:43.971565: 
2024-07-03 18:21:43.973820: Epoch 0
2024-07-03 18:21:43.975790: Current learning rate: 0.01
2024-07-03 18:25:02.940666: Validation loss improved from 1000.00000 to -0.35993! Patience: 0/50
2024-07-03 18:25:02.976347: train_loss -0.2888
2024-07-03 18:25:02.990021: val_loss -0.3599
2024-07-03 18:25:02.991677: Pseudo dice [0.6746]
2024-07-03 18:25:02.992925: Epoch time: 198.97 s
2024-07-03 18:25:02.994123: Yayy! New best EMA pseudo Dice: 0.6746
2024-07-03 18:25:05.511476: 
2024-07-03 18:25:05.513529: Epoch 1
2024-07-03 18:25:05.514924: Current learning rate: 0.00999
2024-07-03 18:26:10.933135: Validation loss improved from -0.35993 to -0.46487! Patience: 0/50
2024-07-03 18:26:10.934807: train_loss -0.3997
2024-07-03 18:26:10.936152: val_loss -0.4649
2024-07-03 18:26:10.937399: Pseudo dice [0.73]
2024-07-03 18:26:10.938505: Epoch time: 65.43 s
2024-07-03 18:26:10.939571: Yayy! New best EMA pseudo Dice: 0.6802
2024-07-03 18:26:12.482167: 
2024-07-03 18:26:12.484434: Epoch 2
2024-07-03 18:26:12.485702: Current learning rate: 0.00998
2024-07-03 18:27:18.755701: Validation loss did not improve from -0.46487. Patience: 1/50
2024-07-03 18:27:18.757702: train_loss -0.4144
2024-07-03 18:27:18.759080: val_loss -0.4227
2024-07-03 18:27:18.760126: Pseudo dice [0.7127]
2024-07-03 18:27:18.761193: Epoch time: 66.28 s
2024-07-03 18:27:18.762253: Yayy! New best EMA pseudo Dice: 0.6834
2024-07-03 18:27:20.374055: 
2024-07-03 18:27:20.377076: Epoch 3
2024-07-03 18:27:20.378709: Current learning rate: 0.00997
2024-07-03 18:28:26.157712: Validation loss improved from -0.46487 to -0.50217! Patience: 1/50
2024-07-03 18:28:26.159845: train_loss -0.4433
2024-07-03 18:28:26.161687: val_loss -0.5022
2024-07-03 18:28:26.162893: Pseudo dice [0.7381]
2024-07-03 18:28:26.164107: Epoch time: 65.79 s
2024-07-03 18:28:26.165379: Yayy! New best EMA pseudo Dice: 0.6889
2024-07-03 18:28:27.719643: 
2024-07-03 18:28:27.722008: Epoch 4
2024-07-03 18:28:27.723285: Current learning rate: 0.00996
2024-07-03 18:29:33.348028: Validation loss did not improve from -0.50217. Patience: 1/50
2024-07-03 18:29:33.350077: train_loss -0.4891
2024-07-03 18:29:33.351722: val_loss -0.4978
2024-07-03 18:29:33.352944: Pseudo dice [0.7317]
2024-07-03 18:29:33.354084: Epoch time: 65.63 s
2024-07-03 18:29:33.645807: Yayy! New best EMA pseudo Dice: 0.6932
2024-07-03 18:29:35.201691: 
2024-07-03 18:29:35.204753: Epoch 5
2024-07-03 18:29:35.206579: Current learning rate: 0.00995
2024-07-03 18:30:40.889594: Validation loss improved from -0.50217 to -0.52349! Patience: 1/50
2024-07-03 18:30:40.892036: train_loss -0.4735
2024-07-03 18:30:40.893559: val_loss -0.5235
2024-07-03 18:30:40.894587: Pseudo dice [0.753]
2024-07-03 18:30:40.895672: Epoch time: 65.69 s
2024-07-03 18:30:40.896695: Yayy! New best EMA pseudo Dice: 0.6991
2024-07-03 18:30:42.436646: 
2024-07-03 18:30:42.439315: Epoch 6
2024-07-03 18:30:42.441029: Current learning rate: 0.00995
2024-07-03 18:31:48.316505: Validation loss did not improve from -0.52349. Patience: 1/50
2024-07-03 18:31:48.318115: train_loss -0.4886
2024-07-03 18:31:48.319523: val_loss -0.5013
2024-07-03 18:31:48.320707: Pseudo dice [0.7355]
2024-07-03 18:31:48.321696: Epoch time: 65.88 s
2024-07-03 18:31:48.322749: Yayy! New best EMA pseudo Dice: 0.7028
2024-07-03 18:31:50.325073: 
2024-07-03 18:31:50.327433: Epoch 7
2024-07-03 18:31:50.328686: Current learning rate: 0.00994
2024-07-03 18:32:56.161024: Validation loss improved from -0.52349 to -0.52767! Patience: 1/50
2024-07-03 18:32:56.162909: train_loss -0.5179
2024-07-03 18:32:56.164275: val_loss -0.5277
2024-07-03 18:32:56.165411: Pseudo dice [0.7534]
2024-07-03 18:32:56.166504: Epoch time: 65.84 s
2024-07-03 18:32:56.167757: Yayy! New best EMA pseudo Dice: 0.7078
2024-07-03 18:32:57.807144: 
2024-07-03 18:32:57.808860: Epoch 8
2024-07-03 18:32:57.810021: Current learning rate: 0.00993
2024-07-03 18:34:03.819219: Validation loss improved from -0.52767 to -0.55901! Patience: 0/50
2024-07-03 18:34:03.821950: train_loss -0.4978
2024-07-03 18:34:03.823995: val_loss -0.559
2024-07-03 18:34:03.825082: Pseudo dice [0.7813]
2024-07-03 18:34:03.826181: Epoch time: 66.02 s
2024-07-03 18:34:03.827139: Yayy! New best EMA pseudo Dice: 0.7152
2024-07-03 18:34:05.400195: 
2024-07-03 18:34:05.403064: Epoch 9
2024-07-03 18:34:05.404938: Current learning rate: 0.00992
2024-07-03 18:35:11.180216: Validation loss did not improve from -0.55901. Patience: 1/50
2024-07-03 18:35:11.182567: train_loss -0.5293
2024-07-03 18:35:11.184503: val_loss -0.5543
2024-07-03 18:35:11.185544: Pseudo dice [0.7767]
2024-07-03 18:35:11.186646: Epoch time: 65.78 s
2024-07-03 18:35:11.521026: Yayy! New best EMA pseudo Dice: 0.7213
2024-07-03 18:35:13.037575: 
2024-07-03 18:35:13.039573: Epoch 10
2024-07-03 18:35:13.040530: Current learning rate: 0.00991
2024-07-03 18:36:18.951214: Validation loss improved from -0.55901 to -0.57696! Patience: 1/50
2024-07-03 18:36:18.952484: train_loss -0.537
2024-07-03 18:36:18.953761: val_loss -0.577
2024-07-03 18:36:18.955192: Pseudo dice [0.7779]
2024-07-03 18:36:18.956255: Epoch time: 65.92 s
2024-07-03 18:36:18.957216: Yayy! New best EMA pseudo Dice: 0.727
2024-07-03 18:36:20.480146: 
2024-07-03 18:36:20.482696: Epoch 11
2024-07-03 18:36:20.484186: Current learning rate: 0.0099
2024-07-03 18:37:26.354351: Validation loss did not improve from -0.57696. Patience: 1/50
2024-07-03 18:37:26.355991: train_loss -0.5404
2024-07-03 18:37:26.357350: val_loss -0.5603
2024-07-03 18:37:26.358759: Pseudo dice [0.769]
2024-07-03 18:37:26.359850: Epoch time: 65.88 s
2024-07-03 18:37:26.361081: Yayy! New best EMA pseudo Dice: 0.7312
2024-07-03 18:37:27.901361: 
2024-07-03 18:37:27.903997: Epoch 12
2024-07-03 18:37:27.905864: Current learning rate: 0.00989
2024-07-03 18:38:33.863800: Validation loss improved from -0.57696 to -0.59915! Patience: 1/50
2024-07-03 18:38:33.865289: train_loss -0.5552
2024-07-03 18:38:33.866818: val_loss -0.5991
2024-07-03 18:38:33.868518: Pseudo dice [0.804]
2024-07-03 18:38:33.869546: Epoch time: 65.97 s
2024-07-03 18:38:33.870607: Yayy! New best EMA pseudo Dice: 0.7385
2024-07-03 18:38:35.450899: 
2024-07-03 18:38:35.453673: Epoch 13
2024-07-03 18:38:35.454847: Current learning rate: 0.00988
2024-07-03 18:39:41.494724: Validation loss did not improve from -0.59915. Patience: 1/50
2024-07-03 18:39:41.496081: train_loss -0.5688
2024-07-03 18:39:41.497214: val_loss -0.5814
2024-07-03 18:39:41.498122: Pseudo dice [0.7801]
2024-07-03 18:39:41.499134: Epoch time: 66.05 s
2024-07-03 18:39:41.500065: Yayy! New best EMA pseudo Dice: 0.7426
2024-07-03 18:39:43.062064: 
2024-07-03 18:39:43.064765: Epoch 14
2024-07-03 18:39:43.066052: Current learning rate: 0.00987
2024-07-03 18:40:48.868473: Validation loss improved from -0.59915 to -0.61797! Patience: 1/50
2024-07-03 18:40:48.871349: train_loss -0.573
2024-07-03 18:40:48.873059: val_loss -0.618
2024-07-03 18:40:48.874106: Pseudo dice [0.802]
2024-07-03 18:40:48.875304: Epoch time: 65.81 s
2024-07-03 18:40:49.214360: Yayy! New best EMA pseudo Dice: 0.7486
2024-07-03 18:40:50.807024: 
2024-07-03 18:40:50.809696: Epoch 15
2024-07-03 18:40:50.810808: Current learning rate: 0.00986
2024-07-03 18:41:56.898848: Validation loss did not improve from -0.61797. Patience: 1/50
2024-07-03 18:41:56.900538: train_loss -0.5473
2024-07-03 18:41:56.901960: val_loss -0.5742
2024-07-03 18:41:56.903225: Pseudo dice [0.7775]
2024-07-03 18:41:56.904366: Epoch time: 66.09 s
2024-07-03 18:41:56.905403: Yayy! New best EMA pseudo Dice: 0.7515
2024-07-03 18:41:58.506355: 
2024-07-03 18:41:58.509394: Epoch 16
2024-07-03 18:41:58.511013: Current learning rate: 0.00986
2024-07-03 18:43:04.891084: Validation loss did not improve from -0.61797. Patience: 2/50
2024-07-03 18:43:04.892932: train_loss -0.5743
2024-07-03 18:43:04.894102: val_loss -0.5971
2024-07-03 18:43:04.895093: Pseudo dice [0.7931]
2024-07-03 18:43:04.896033: Epoch time: 66.39 s
2024-07-03 18:43:04.896905: Yayy! New best EMA pseudo Dice: 0.7556
2024-07-03 18:43:06.518005: 
2024-07-03 18:43:06.520685: Epoch 17
2024-07-03 18:43:06.521907: Current learning rate: 0.00985
2024-07-03 18:44:12.451442: Validation loss improved from -0.61797 to -0.62190! Patience: 2/50
2024-07-03 18:44:12.453018: train_loss -0.5891
2024-07-03 18:44:12.454800: val_loss -0.6219
2024-07-03 18:44:12.456011: Pseudo dice [0.8113]
2024-07-03 18:44:12.457083: Epoch time: 65.94 s
2024-07-03 18:44:12.458090: Yayy! New best EMA pseudo Dice: 0.7612
2024-07-03 18:44:14.456887: 
2024-07-03 18:44:14.459164: Epoch 18
2024-07-03 18:44:14.460270: Current learning rate: 0.00984
2024-07-03 18:45:20.445228: Validation loss improved from -0.62190 to -0.63141! Patience: 0/50
2024-07-03 18:45:20.447076: train_loss -0.5837
2024-07-03 18:45:20.449034: val_loss -0.6314
2024-07-03 18:45:20.450838: Pseudo dice [0.8114]
2024-07-03 18:45:20.452643: Epoch time: 65.99 s
2024-07-03 18:45:20.453800: Yayy! New best EMA pseudo Dice: 0.7662
2024-07-03 18:45:22.059261: 
2024-07-03 18:45:22.061017: Epoch 19
2024-07-03 18:45:22.062131: Current learning rate: 0.00983
2024-07-03 18:46:28.299013: Validation loss did not improve from -0.63141. Patience: 1/50
2024-07-03 18:46:28.300390: train_loss -0.5712
2024-07-03 18:46:28.301477: val_loss -0.5982
2024-07-03 18:46:28.302443: Pseudo dice [0.8036]
2024-07-03 18:46:28.303437: Epoch time: 66.24 s
2024-07-03 18:46:28.643083: Yayy! New best EMA pseudo Dice: 0.7699
2024-07-03 18:46:30.251726: 
2024-07-03 18:46:30.254318: Epoch 20
2024-07-03 18:46:30.255702: Current learning rate: 0.00982
2024-07-03 18:47:36.320102: Validation loss improved from -0.63141 to -0.64080! Patience: 1/50
2024-07-03 18:47:36.322148: train_loss -0.5887
2024-07-03 18:47:36.323782: val_loss -0.6408
2024-07-03 18:47:36.324916: Pseudo dice [0.8146]
2024-07-03 18:47:36.326186: Epoch time: 66.07 s
2024-07-03 18:47:36.327183: Yayy! New best EMA pseudo Dice: 0.7744
2024-07-03 18:47:37.964597: 
2024-07-03 18:47:37.967266: Epoch 21
2024-07-03 18:47:37.968535: Current learning rate: 0.00981
2024-07-03 18:48:43.863365: Validation loss did not improve from -0.64080. Patience: 1/50
2024-07-03 18:48:43.864991: train_loss -0.5951
2024-07-03 18:48:43.866241: val_loss -0.6229
2024-07-03 18:48:43.867223: Pseudo dice [0.814]
2024-07-03 18:48:43.868189: Epoch time: 65.9 s
2024-07-03 18:48:43.869216: Yayy! New best EMA pseudo Dice: 0.7784
2024-07-03 18:48:45.480502: 
2024-07-03 18:48:45.482900: Epoch 22
2024-07-03 18:48:45.484458: Current learning rate: 0.0098
2024-07-03 18:49:51.309587: Validation loss improved from -0.64080 to -0.65457! Patience: 1/50
2024-07-03 18:49:51.310855: train_loss -0.5921
2024-07-03 18:49:51.311994: val_loss -0.6546
2024-07-03 18:49:51.313219: Pseudo dice [0.824]
2024-07-03 18:49:51.314317: Epoch time: 65.83 s
2024-07-03 18:49:51.315274: Yayy! New best EMA pseudo Dice: 0.7829
2024-07-03 18:49:52.905637: 
2024-07-03 18:49:52.908141: Epoch 23
2024-07-03 18:49:52.909200: Current learning rate: 0.00979
2024-07-03 18:50:59.060137: Validation loss did not improve from -0.65457. Patience: 1/50
2024-07-03 18:50:59.061940: train_loss -0.6031
2024-07-03 18:50:59.063110: val_loss -0.636
2024-07-03 18:50:59.064302: Pseudo dice [0.7998]
2024-07-03 18:50:59.065372: Epoch time: 66.16 s
2024-07-03 18:50:59.066309: Yayy! New best EMA pseudo Dice: 0.7846
2024-07-03 18:51:00.614037: 
2024-07-03 18:51:00.616594: Epoch 24
2024-07-03 18:51:00.617994: Current learning rate: 0.00978
2024-07-03 18:52:06.978963: Validation loss did not improve from -0.65457. Patience: 2/50
2024-07-03 18:52:06.980827: train_loss -0.6047
2024-07-03 18:52:06.982051: val_loss -0.6408
2024-07-03 18:52:06.983145: Pseudo dice [0.8147]
2024-07-03 18:52:06.984114: Epoch time: 66.37 s
2024-07-03 18:52:07.334156: Yayy! New best EMA pseudo Dice: 0.7876
2024-07-03 18:52:08.848223: 
2024-07-03 18:52:08.850476: Epoch 25
2024-07-03 18:52:08.852038: Current learning rate: 0.00977
2024-07-03 18:53:15.077009: Validation loss improved from -0.65457 to -0.65730! Patience: 2/50
2024-07-03 18:53:15.078891: train_loss -0.618
2024-07-03 18:53:15.080247: val_loss -0.6573
2024-07-03 18:53:15.081558: Pseudo dice [0.8223]
2024-07-03 18:53:15.082783: Epoch time: 66.23 s
2024-07-03 18:53:15.084014: Yayy! New best EMA pseudo Dice: 0.7911
2024-07-03 18:53:16.645710: 
2024-07-03 18:53:16.647980: Epoch 26
2024-07-03 18:53:16.649205: Current learning rate: 0.00977
2024-07-03 18:54:22.851940: Validation loss did not improve from -0.65730. Patience: 1/50
2024-07-03 18:54:22.853608: train_loss -0.5946
2024-07-03 18:54:22.855091: val_loss -0.643
2024-07-03 18:54:22.856548: Pseudo dice [0.8157]
2024-07-03 18:54:22.858031: Epoch time: 66.21 s
2024-07-03 18:54:22.859261: Yayy! New best EMA pseudo Dice: 0.7935
2024-07-03 18:54:24.390819: 
2024-07-03 18:54:24.392958: Epoch 27
2024-07-03 18:54:24.394330: Current learning rate: 0.00976
2024-07-03 18:55:30.506749: Validation loss did not improve from -0.65730. Patience: 2/50
2024-07-03 18:55:30.508443: train_loss -0.6101
2024-07-03 18:55:30.509618: val_loss -0.6454
2024-07-03 18:55:30.510781: Pseudo dice [0.8178]
2024-07-03 18:55:30.512225: Epoch time: 66.12 s
2024-07-03 18:55:30.513344: Yayy! New best EMA pseudo Dice: 0.796
2024-07-03 18:55:32.453228: 
2024-07-03 18:55:32.455557: Epoch 28
2024-07-03 18:55:32.456713: Current learning rate: 0.00975
2024-07-03 18:56:38.548179: Validation loss did not improve from -0.65730. Patience: 3/50
2024-07-03 18:56:38.550745: train_loss -0.6294
2024-07-03 18:56:38.552590: val_loss -0.6363
2024-07-03 18:56:38.553989: Pseudo dice [0.8199]
2024-07-03 18:56:38.555221: Epoch time: 66.1 s
2024-07-03 18:56:38.556534: Yayy! New best EMA pseudo Dice: 0.7984
2024-07-03 18:56:40.111258: 
2024-07-03 18:56:40.113250: Epoch 29
2024-07-03 18:56:40.114511: Current learning rate: 0.00974
2024-07-03 18:57:46.008543: Validation loss improved from -0.65730 to -0.66651! Patience: 3/50
2024-07-03 18:57:46.010789: train_loss -0.6316
2024-07-03 18:57:46.012393: val_loss -0.6665
2024-07-03 18:57:46.013492: Pseudo dice [0.8357]
2024-07-03 18:57:46.014609: Epoch time: 65.9 s
2024-07-03 18:57:46.370174: Yayy! New best EMA pseudo Dice: 0.8021
2024-07-03 18:57:47.961697: 
2024-07-03 18:57:47.964632: Epoch 30
2024-07-03 18:57:47.966217: Current learning rate: 0.00973
2024-07-03 18:58:53.978887: Validation loss did not improve from -0.66651. Patience: 1/50
2024-07-03 18:58:53.980425: train_loss -0.6269
2024-07-03 18:58:53.981613: val_loss -0.6087
2024-07-03 18:58:53.982630: Pseudo dice [0.8125]
2024-07-03 18:58:53.983577: Epoch time: 66.02 s
2024-07-03 18:58:53.984598: Yayy! New best EMA pseudo Dice: 0.8031
2024-07-03 18:58:55.590330: 
2024-07-03 18:58:55.592275: Epoch 31
2024-07-03 18:58:55.593343: Current learning rate: 0.00972
2024-07-03 19:00:01.882684: Validation loss improved from -0.66651 to -0.66769! Patience: 1/50
2024-07-03 19:00:01.884435: train_loss -0.6077
2024-07-03 19:00:01.885696: val_loss -0.6677
2024-07-03 19:00:01.886870: Pseudo dice [0.83]
2024-07-03 19:00:01.887893: Epoch time: 66.3 s
2024-07-03 19:00:01.889034: Yayy! New best EMA pseudo Dice: 0.8058
2024-07-03 19:00:03.450016: 
2024-07-03 19:00:03.452337: Epoch 32
2024-07-03 19:00:03.453601: Current learning rate: 0.00971
2024-07-03 19:01:09.945936: Validation loss did not improve from -0.66769. Patience: 1/50
2024-07-03 19:01:09.947645: train_loss -0.6387
2024-07-03 19:01:09.949190: val_loss -0.6668
2024-07-03 19:01:09.950937: Pseudo dice [0.8212]
2024-07-03 19:01:09.952516: Epoch time: 66.5 s
2024-07-03 19:01:09.954001: Yayy! New best EMA pseudo Dice: 0.8074
2024-07-03 19:01:11.565866: 
2024-07-03 19:01:11.568249: Epoch 33
2024-07-03 19:01:11.569913: Current learning rate: 0.0097
2024-07-03 19:02:17.617231: Validation loss improved from -0.66769 to -0.66861! Patience: 1/50
2024-07-03 19:02:17.619320: train_loss -0.6322
2024-07-03 19:02:17.620699: val_loss -0.6686
2024-07-03 19:02:17.622101: Pseudo dice [0.8212]
2024-07-03 19:02:17.623409: Epoch time: 66.06 s
2024-07-03 19:02:17.624479: Yayy! New best EMA pseudo Dice: 0.8088
2024-07-03 19:02:19.249280: 
2024-07-03 19:02:19.252065: Epoch 34
2024-07-03 19:02:19.253987: Current learning rate: 0.00969
2024-07-03 19:03:25.653014: Validation loss did not improve from -0.66861. Patience: 1/50
2024-07-03 19:03:25.654443: train_loss -0.631
2024-07-03 19:03:25.656036: val_loss -0.6665
2024-07-03 19:03:25.657312: Pseudo dice [0.8256]
2024-07-03 19:03:25.658355: Epoch time: 66.41 s
2024-07-03 19:03:26.015055: Yayy! New best EMA pseudo Dice: 0.8104
2024-07-03 19:03:27.643949: 
2024-07-03 19:03:27.646024: Epoch 35
2024-07-03 19:03:27.647978: Current learning rate: 0.00968
2024-07-03 19:04:34.044886: Validation loss improved from -0.66861 to -0.67764! Patience: 1/50
2024-07-03 19:04:34.046421: train_loss -0.6323
2024-07-03 19:04:34.047976: val_loss -0.6776
2024-07-03 19:04:34.049272: Pseudo dice [0.8343]
2024-07-03 19:04:34.050279: Epoch time: 66.4 s
2024-07-03 19:04:34.051185: Yayy! New best EMA pseudo Dice: 0.8128
2024-07-03 19:04:35.661668: 
2024-07-03 19:04:35.663889: Epoch 36
2024-07-03 19:04:35.665006: Current learning rate: 0.00968
2024-07-03 19:05:41.843220: Validation loss did not improve from -0.67764. Patience: 1/50
2024-07-03 19:05:41.844584: train_loss -0.6432
2024-07-03 19:05:41.845935: val_loss -0.6696
2024-07-03 19:05:41.847107: Pseudo dice [0.8284]
2024-07-03 19:05:41.848304: Epoch time: 66.18 s
2024-07-03 19:05:41.849409: Yayy! New best EMA pseudo Dice: 0.8144
2024-07-03 19:05:43.441586: 
2024-07-03 19:05:43.443471: Epoch 37
2024-07-03 19:05:43.444933: Current learning rate: 0.00967
2024-07-03 19:06:49.911622: Validation loss improved from -0.67764 to -0.68738! Patience: 1/50
2024-07-03 19:06:49.912850: train_loss -0.6502
2024-07-03 19:06:49.914262: val_loss -0.6874
2024-07-03 19:06:49.915455: Pseudo dice [0.8393]
2024-07-03 19:06:49.916651: Epoch time: 66.47 s
2024-07-03 19:06:49.917768: Yayy! New best EMA pseudo Dice: 0.8169
2024-07-03 19:06:51.530076: 
2024-07-03 19:06:51.532926: Epoch 38
2024-07-03 19:06:51.534391: Current learning rate: 0.00966
2024-07-03 19:07:58.241408: Validation loss improved from -0.68738 to -0.68880! Patience: 0/50
2024-07-03 19:07:58.242739: train_loss -0.655
2024-07-03 19:07:58.244077: val_loss -0.6888
2024-07-03 19:07:58.245176: Pseudo dice [0.8476]
2024-07-03 19:07:58.246311: Epoch time: 66.71 s
2024-07-03 19:07:58.247284: Yayy! New best EMA pseudo Dice: 0.8199
2024-07-03 19:08:00.357248: 
2024-07-03 19:08:00.359476: Epoch 39
2024-07-03 19:08:00.360718: Current learning rate: 0.00965
2024-07-03 19:09:06.588864: Validation loss did not improve from -0.68880. Patience: 1/50
2024-07-03 19:09:06.590333: train_loss -0.6577
2024-07-03 19:09:06.592633: val_loss -0.6877
2024-07-03 19:09:06.594436: Pseudo dice [0.8408]
2024-07-03 19:09:06.595780: Epoch time: 66.23 s
2024-07-03 19:09:06.972240: Yayy! New best EMA pseudo Dice: 0.822
2024-07-03 19:09:08.633883: 
2024-07-03 19:09:08.636262: Epoch 40
2024-07-03 19:09:08.637844: Current learning rate: 0.00964
2024-07-03 19:10:14.590558: Validation loss improved from -0.68880 to -0.68993! Patience: 1/50
2024-07-03 19:10:14.592903: train_loss -0.6706
2024-07-03 19:10:14.594859: val_loss -0.6899
2024-07-03 19:10:14.595905: Pseudo dice [0.8352]
2024-07-03 19:10:14.596926: Epoch time: 65.96 s
2024-07-03 19:10:14.599443: Yayy! New best EMA pseudo Dice: 0.8233
2024-07-03 19:10:16.296087: 
2024-07-03 19:10:16.298941: Epoch 41
2024-07-03 19:10:16.300484: Current learning rate: 0.00963
2024-07-03 19:11:22.424529: Validation loss did not improve from -0.68993. Patience: 1/50
2024-07-03 19:11:22.426559: train_loss -0.6681
2024-07-03 19:11:22.428435: val_loss -0.671
2024-07-03 19:11:22.429893: Pseudo dice [0.8319]
2024-07-03 19:11:22.431632: Epoch time: 66.13 s
2024-07-03 19:11:22.433237: Yayy! New best EMA pseudo Dice: 0.8242
2024-07-03 19:11:24.005071: 
2024-07-03 19:11:24.007409: Epoch 42
2024-07-03 19:11:24.009186: Current learning rate: 0.00962
2024-07-03 19:12:30.332841: Validation loss improved from -0.68993 to -0.70103! Patience: 1/50
2024-07-03 19:12:30.334271: train_loss -0.6577
2024-07-03 19:12:30.335612: val_loss -0.701
2024-07-03 19:12:30.337000: Pseudo dice [0.8453]
2024-07-03 19:12:30.338104: Epoch time: 66.33 s
2024-07-03 19:12:30.339496: Yayy! New best EMA pseudo Dice: 0.8263
2024-07-03 19:12:31.872298: 
2024-07-03 19:12:31.874218: Epoch 43
2024-07-03 19:12:31.875899: Current learning rate: 0.00961
2024-07-03 19:13:37.976361: Validation loss did not improve from -0.70103. Patience: 1/50
2024-07-03 19:13:37.977838: train_loss -0.6607
2024-07-03 19:13:37.979807: val_loss -0.6968
2024-07-03 19:13:37.980946: Pseudo dice [0.838]
2024-07-03 19:13:37.982399: Epoch time: 66.11 s
2024-07-03 19:13:37.983560: Yayy! New best EMA pseudo Dice: 0.8275
2024-07-03 19:13:39.571381: 
2024-07-03 19:13:39.573409: Epoch 44
2024-07-03 19:13:39.574644: Current learning rate: 0.0096
2024-07-03 19:14:45.806798: Validation loss improved from -0.70103 to -0.71038! Patience: 1/50
2024-07-03 19:14:45.808269: train_loss -0.6656
2024-07-03 19:14:45.809747: val_loss -0.7104
2024-07-03 19:14:45.811205: Pseudo dice [0.8512]
2024-07-03 19:14:45.812581: Epoch time: 66.24 s
2024-07-03 19:14:46.170102: Yayy! New best EMA pseudo Dice: 0.8299
2024-07-03 19:14:47.682735: 
2024-07-03 19:14:47.684839: Epoch 45
2024-07-03 19:14:47.686619: Current learning rate: 0.00959
2024-07-03 19:15:53.623207: Validation loss did not improve from -0.71038. Patience: 1/50
2024-07-03 19:15:53.624803: train_loss -0.6639
2024-07-03 19:15:53.626356: val_loss -0.6843
2024-07-03 19:15:53.627587: Pseudo dice [0.8427]
2024-07-03 19:15:53.628946: Epoch time: 65.94 s
2024-07-03 19:15:53.630122: Yayy! New best EMA pseudo Dice: 0.8311
2024-07-03 19:15:55.157807: 
2024-07-03 19:15:55.160314: Epoch 46
2024-07-03 19:15:55.161939: Current learning rate: 0.00959
2024-07-03 19:17:01.318330: Validation loss improved from -0.71038 to -0.71413! Patience: 1/50
2024-07-03 19:17:01.319847: train_loss -0.6528
2024-07-03 19:17:01.321024: val_loss -0.7141
2024-07-03 19:17:01.322068: Pseudo dice [0.8524]
2024-07-03 19:17:01.323176: Epoch time: 66.16 s
2024-07-03 19:17:01.324173: Yayy! New best EMA pseudo Dice: 0.8333
2024-07-03 19:17:02.832738: 
2024-07-03 19:17:02.834920: Epoch 47
2024-07-03 19:17:02.836313: Current learning rate: 0.00958
2024-07-03 19:18:08.914651: Validation loss did not improve from -0.71413. Patience: 1/50
2024-07-03 19:18:08.916178: train_loss -0.6653
2024-07-03 19:18:08.917689: val_loss -0.7128
2024-07-03 19:18:08.919085: Pseudo dice [0.8531]
2024-07-03 19:18:08.920723: Epoch time: 66.08 s
2024-07-03 19:18:08.922482: Yayy! New best EMA pseudo Dice: 0.8352
2024-07-03 19:18:10.447244: 
2024-07-03 19:18:10.449798: Epoch 48
2024-07-03 19:18:10.451329: Current learning rate: 0.00957
2024-07-03 19:19:16.570355: Validation loss did not improve from -0.71413. Patience: 2/50
2024-07-03 19:19:16.571835: train_loss -0.6649
2024-07-03 19:19:16.573083: val_loss -0.6912
2024-07-03 19:19:16.574298: Pseudo dice [0.8463]
2024-07-03 19:19:16.575340: Epoch time: 66.13 s
2024-07-03 19:19:16.576584: Yayy! New best EMA pseudo Dice: 0.8364
2024-07-03 19:19:18.094408: 
2024-07-03 19:19:18.097155: Epoch 49
2024-07-03 19:19:18.098939: Current learning rate: 0.00956
2024-07-03 19:20:24.176284: Validation loss did not improve from -0.71413. Patience: 3/50
2024-07-03 19:20:24.177765: train_loss -0.6584
2024-07-03 19:20:24.179320: val_loss -0.6785
2024-07-03 19:20:24.180693: Pseudo dice [0.8388]
2024-07-03 19:20:24.182023: Epoch time: 66.08 s
2024-07-03 19:20:24.556185: Yayy! New best EMA pseudo Dice: 0.8366
2024-07-03 19:20:26.732820: 
2024-07-03 19:20:26.734559: Epoch 50
2024-07-03 19:20:26.736372: Current learning rate: 0.00955
2024-07-03 19:21:33.024701: Validation loss did not improve from -0.71413. Patience: 4/50
2024-07-03 19:21:33.026535: train_loss -0.6714
2024-07-03 19:21:33.028329: val_loss -0.6948
2024-07-03 19:21:33.029550: Pseudo dice [0.8389]
2024-07-03 19:21:33.030581: Epoch time: 66.29 s
2024-07-03 19:21:33.031519: Yayy! New best EMA pseudo Dice: 0.8368
2024-07-03 19:21:34.620589: 
2024-07-03 19:21:34.623193: Epoch 51
2024-07-03 19:21:34.624913: Current learning rate: 0.00954
2024-07-03 19:22:40.805850: Validation loss did not improve from -0.71413. Patience: 5/50
2024-07-03 19:22:40.807305: train_loss -0.6596
2024-07-03 19:22:40.808959: val_loss -0.7013
2024-07-03 19:22:40.810038: Pseudo dice [0.8552]
2024-07-03 19:22:40.811244: Epoch time: 66.19 s
2024-07-03 19:22:40.812177: Yayy! New best EMA pseudo Dice: 0.8387
2024-07-03 19:22:42.386997: 
2024-07-03 19:22:42.389160: Epoch 52
2024-07-03 19:22:42.390635: Current learning rate: 0.00953
2024-07-03 19:23:48.746230: Validation loss did not improve from -0.71413. Patience: 6/50
2024-07-03 19:23:48.747736: train_loss -0.6718
2024-07-03 19:23:48.749635: val_loss -0.702
2024-07-03 19:23:48.750922: Pseudo dice [0.8482]
2024-07-03 19:23:48.752036: Epoch time: 66.36 s
2024-07-03 19:23:48.753474: Yayy! New best EMA pseudo Dice: 0.8396
2024-07-03 19:23:50.480681: 
2024-07-03 19:23:50.482598: Epoch 53
2024-07-03 19:23:50.483892: Current learning rate: 0.00952
2024-07-03 19:24:56.961618: Validation loss improved from -0.71413 to -0.72537! Patience: 6/50
2024-07-03 19:24:56.963654: train_loss -0.679
2024-07-03 19:24:56.965629: val_loss -0.7254
2024-07-03 19:24:56.967598: Pseudo dice [0.8604]
2024-07-03 19:24:56.969495: Epoch time: 66.48 s
2024-07-03 19:24:56.970948: Yayy! New best EMA pseudo Dice: 0.8417
2024-07-03 19:24:58.514330: 
2024-07-03 19:24:58.517142: Epoch 54
2024-07-03 19:24:58.518703: Current learning rate: 0.00951
2024-07-03 19:26:04.819064: Validation loss did not improve from -0.72537. Patience: 1/50
2024-07-03 19:26:04.820800: train_loss -0.693
2024-07-03 19:26:04.822267: val_loss -0.7127
2024-07-03 19:26:04.823491: Pseudo dice [0.8485]
2024-07-03 19:26:04.825362: Epoch time: 66.31 s
2024-07-03 19:26:05.200562: Yayy! New best EMA pseudo Dice: 0.8424
2024-07-03 19:26:06.740896: 
2024-07-03 19:26:06.743556: Epoch 55
2024-07-03 19:26:06.744764: Current learning rate: 0.0095
2024-07-03 19:27:13.923585: Validation loss improved from -0.72537 to -0.72631! Patience: 1/50
2024-07-03 19:27:13.926251: train_loss -0.6902
2024-07-03 19:27:13.928391: val_loss -0.7263
2024-07-03 19:27:13.929865: Pseudo dice [0.8572]
2024-07-03 19:27:13.931210: Epoch time: 67.19 s
2024-07-03 19:27:13.933232: Yayy! New best EMA pseudo Dice: 0.8439
2024-07-03 19:27:15.561090: 
2024-07-03 19:27:15.564090: Epoch 56
2024-07-03 19:27:15.566177: Current learning rate: 0.00949
2024-07-03 19:28:21.856408: Validation loss did not improve from -0.72631. Patience: 1/50
2024-07-03 19:28:21.857922: train_loss -0.6747
2024-07-03 19:28:21.859267: val_loss -0.7161
2024-07-03 19:28:21.860864: Pseudo dice [0.8481]
2024-07-03 19:28:21.862537: Epoch time: 66.3 s
2024-07-03 19:28:21.863541: Yayy! New best EMA pseudo Dice: 0.8443
2024-07-03 19:28:23.447255: 
2024-07-03 19:28:23.449857: Epoch 57
2024-07-03 19:28:23.451281: Current learning rate: 0.00949
2024-07-03 19:29:31.010218: Validation loss did not improve from -0.72631. Patience: 2/50
2024-07-03 19:29:31.013266: train_loss -0.6836
2024-07-03 19:29:31.014891: val_loss -0.7189
2024-07-03 19:29:31.016132: Pseudo dice [0.8569]
2024-07-03 19:29:31.017114: Epoch time: 67.57 s
2024-07-03 19:29:31.018178: Yayy! New best EMA pseudo Dice: 0.8455
2024-07-03 19:29:32.894781: 
2024-07-03 19:29:32.896852: Epoch 58
2024-07-03 19:29:32.898071: Current learning rate: 0.00948
2024-07-03 19:30:42.373230: Validation loss did not improve from -0.72631. Patience: 3/50
2024-07-03 19:30:42.414798: train_loss -0.6904
2024-07-03 19:30:42.417964: val_loss -0.6931
2024-07-03 19:30:42.420007: Pseudo dice [0.8414]
2024-07-03 19:30:42.421693: Epoch time: 69.5 s
2024-07-03 19:30:44.424962: 
2024-07-03 19:30:44.427504: Epoch 59
2024-07-03 19:30:44.428918: Current learning rate: 0.00947
2024-07-03 19:31:50.550889: Validation loss did not improve from -0.72631. Patience: 4/50
2024-07-03 19:31:50.552833: train_loss -0.6813
2024-07-03 19:31:50.554719: val_loss -0.7069
2024-07-03 19:31:50.556004: Pseudo dice [0.8534]
2024-07-03 19:31:50.557195: Epoch time: 66.13 s
2024-07-03 19:31:51.040201: Yayy! New best EMA pseudo Dice: 0.846
2024-07-03 19:31:52.551888: 
2024-07-03 19:31:52.554873: Epoch 60
2024-07-03 19:31:52.556951: Current learning rate: 0.00946
2024-07-03 19:32:58.596699: Validation loss did not improve from -0.72631. Patience: 5/50
2024-07-03 19:32:58.598048: train_loss -0.6815
2024-07-03 19:32:58.599378: val_loss -0.6864
2024-07-03 19:32:58.600751: Pseudo dice [0.8371]
2024-07-03 19:32:58.601822: Epoch time: 66.05 s
2024-07-03 19:32:59.822960: 
2024-07-03 19:32:59.825081: Epoch 61
2024-07-03 19:32:59.826350: Current learning rate: 0.00945
2024-07-03 19:34:06.011520: Validation loss did not improve from -0.72631. Patience: 6/50
2024-07-03 19:34:06.013441: train_loss -0.676
2024-07-03 19:34:06.014996: val_loss -0.7206
2024-07-03 19:34:06.016274: Pseudo dice [0.8561]
2024-07-03 19:34:06.017478: Epoch time: 66.19 s
2024-07-03 19:34:06.018628: Yayy! New best EMA pseudo Dice: 0.8462
2024-07-03 19:34:09.693228: 
2024-07-03 19:34:09.695319: Epoch 62
2024-07-03 19:34:09.696769: Current learning rate: 0.00944
2024-07-03 19:35:15.940988: Validation loss did not improve from -0.72631. Patience: 7/50
2024-07-03 19:35:15.943944: train_loss -0.6933
2024-07-03 19:35:15.945926: val_loss -0.7172
2024-07-03 19:35:15.947026: Pseudo dice [0.8489]
2024-07-03 19:35:15.948423: Epoch time: 66.25 s
2024-07-03 19:35:15.949530: Yayy! New best EMA pseudo Dice: 0.8465
2024-07-03 19:35:17.522980: 
2024-07-03 19:35:17.524973: Epoch 63
2024-07-03 19:35:17.526383: Current learning rate: 0.00943
2024-07-03 19:36:23.739590: Validation loss did not improve from -0.72631. Patience: 8/50
2024-07-03 19:36:23.741244: train_loss -0.6751
2024-07-03 19:36:23.742795: val_loss -0.7108
2024-07-03 19:36:23.743812: Pseudo dice [0.8511]
2024-07-03 19:36:23.745180: Epoch time: 66.22 s
2024-07-03 19:36:23.746257: Yayy! New best EMA pseudo Dice: 0.8469
2024-07-03 19:36:25.274446: 
2024-07-03 19:36:25.277220: Epoch 64
2024-07-03 19:36:25.278854: Current learning rate: 0.00942
2024-07-03 19:37:31.368932: Validation loss did not improve from -0.72631. Patience: 9/50
2024-07-03 19:37:31.370749: train_loss -0.6725
2024-07-03 19:37:31.372321: val_loss -0.6971
2024-07-03 19:37:31.373717: Pseudo dice [0.8373]
2024-07-03 19:37:31.374801: Epoch time: 66.1 s
2024-07-03 19:37:32.934674: 
2024-07-03 19:37:32.937660: Epoch 65
2024-07-03 19:37:32.939404: Current learning rate: 0.00941
2024-07-03 19:38:38.967577: Validation loss did not improve from -0.72631. Patience: 10/50
2024-07-03 19:38:38.969191: train_loss -0.6642
2024-07-03 19:38:38.970476: val_loss -0.6516
2024-07-03 19:38:38.971941: Pseudo dice [0.833]
2024-07-03 19:38:38.973228: Epoch time: 66.04 s
2024-07-03 19:38:40.196671: 
2024-07-03 19:38:40.199722: Epoch 66
2024-07-03 19:38:40.201501: Current learning rate: 0.0094
2024-07-03 19:39:46.155791: Validation loss did not improve from -0.72631. Patience: 11/50
2024-07-03 19:39:46.157176: train_loss -0.6424
2024-07-03 19:39:46.158628: val_loss -0.6642
2024-07-03 19:39:46.159774: Pseudo dice [0.8275]
2024-07-03 19:39:46.161062: Epoch time: 65.96 s
2024-07-03 19:39:47.385742: 
2024-07-03 19:39:47.387471: Epoch 67
2024-07-03 19:39:47.388588: Current learning rate: 0.00939
2024-07-03 19:40:53.317013: Validation loss did not improve from -0.72631. Patience: 12/50
2024-07-03 19:40:53.318782: train_loss -0.6471
2024-07-03 19:40:53.320726: val_loss -0.7031
2024-07-03 19:40:53.322312: Pseudo dice [0.8516]
2024-07-03 19:40:53.323747: Epoch time: 65.93 s
2024-07-03 19:40:54.570393: 
2024-07-03 19:40:54.572810: Epoch 68
2024-07-03 19:40:54.574195: Current learning rate: 0.00939
2024-07-03 19:42:00.290121: Validation loss did not improve from -0.72631. Patience: 13/50
2024-07-03 19:42:00.291808: train_loss -0.6689
2024-07-03 19:42:00.293619: val_loss -0.7237
2024-07-03 19:42:00.294880: Pseudo dice [0.8573]
2024-07-03 19:42:00.296185: Epoch time: 65.72 s
2024-07-03 19:42:01.546461: 
2024-07-03 19:42:01.549038: Epoch 69
2024-07-03 19:42:01.550771: Current learning rate: 0.00938
2024-07-03 19:43:07.605477: Validation loss did not improve from -0.72631. Patience: 14/50
2024-07-03 19:43:07.607285: train_loss -0.6634
2024-07-03 19:43:07.609265: val_loss -0.7121
2024-07-03 19:43:07.610665: Pseudo dice [0.8526]
2024-07-03 19:43:07.612424: Epoch time: 66.06 s
2024-07-03 19:43:09.133935: 
2024-07-03 19:43:09.135786: Epoch 70
2024-07-03 19:43:09.137196: Current learning rate: 0.00937
2024-07-03 19:44:15.043067: Validation loss did not improve from -0.72631. Patience: 15/50
2024-07-03 19:44:15.044836: train_loss -0.6823
2024-07-03 19:44:15.046234: val_loss -0.7246
2024-07-03 19:44:15.047510: Pseudo dice [0.86]
2024-07-03 19:44:15.048695: Epoch time: 65.91 s
2024-07-03 19:44:15.050541: Yayy! New best EMA pseudo Dice: 0.8473
2024-07-03 19:44:16.601667: 
2024-07-03 19:44:16.603648: Epoch 71
2024-07-03 19:44:16.605373: Current learning rate: 0.00936
2024-07-03 19:45:22.434404: Validation loss improved from -0.72631 to -0.73609! Patience: 15/50
2024-07-03 19:45:22.436306: train_loss -0.682
2024-07-03 19:45:22.437822: val_loss -0.7361
2024-07-03 19:45:22.439118: Pseudo dice [0.8593]
2024-07-03 19:45:22.440283: Epoch time: 65.84 s
2024-07-03 19:45:22.441449: Yayy! New best EMA pseudo Dice: 0.8485
2024-07-03 19:45:24.026298: 
2024-07-03 19:45:24.028708: Epoch 72
2024-07-03 19:45:24.030423: Current learning rate: 0.00935
2024-07-03 19:46:29.864795: Validation loss did not improve from -0.73609. Patience: 1/50
2024-07-03 19:46:29.866611: train_loss -0.6823
2024-07-03 19:46:29.868129: val_loss -0.7246
2024-07-03 19:46:29.869648: Pseudo dice [0.8605]
2024-07-03 19:46:29.870999: Epoch time: 65.84 s
2024-07-03 19:46:29.872061: Yayy! New best EMA pseudo Dice: 0.8497
2024-07-03 19:46:31.763915: 
2024-07-03 19:46:31.766096: Epoch 73
2024-07-03 19:46:31.767964: Current learning rate: 0.00934
2024-07-03 19:47:37.663251: Validation loss did not improve from -0.73609. Patience: 2/50
2024-07-03 19:47:37.665300: train_loss -0.6826
2024-07-03 19:47:37.667716: val_loss -0.7283
2024-07-03 19:47:37.668984: Pseudo dice [0.8614]
2024-07-03 19:47:37.670415: Epoch time: 65.9 s
2024-07-03 19:47:37.671684: Yayy! New best EMA pseudo Dice: 0.8509
2024-07-03 19:47:39.189575: 
2024-07-03 19:47:39.192126: Epoch 74
2024-07-03 19:47:39.193910: Current learning rate: 0.00933
2024-07-03 19:48:44.826573: Validation loss improved from -0.73609 to -0.73830! Patience: 2/50
2024-07-03 19:48:44.828311: train_loss -0.7043
2024-07-03 19:48:44.829960: val_loss -0.7383
2024-07-03 19:48:44.831420: Pseudo dice [0.8672]
2024-07-03 19:48:44.832603: Epoch time: 65.64 s
2024-07-03 19:48:45.185822: Yayy! New best EMA pseudo Dice: 0.8525
2024-07-03 19:48:46.740966: 
2024-07-03 19:48:46.743920: Epoch 75
2024-07-03 19:48:46.745224: Current learning rate: 0.00932
2024-07-03 19:49:52.519754: Validation loss did not improve from -0.73830. Patience: 1/50
2024-07-03 19:49:52.521377: train_loss -0.704
2024-07-03 19:49:52.522719: val_loss -0.727
2024-07-03 19:49:52.523802: Pseudo dice [0.8645]
2024-07-03 19:49:52.524960: Epoch time: 65.78 s
2024-07-03 19:49:52.525912: Yayy! New best EMA pseudo Dice: 0.8537
2024-07-03 19:49:54.093330: 
2024-07-03 19:49:54.095697: Epoch 76
2024-07-03 19:49:54.096834: Current learning rate: 0.00931
2024-07-03 19:51:00.438528: Validation loss did not improve from -0.73830. Patience: 2/50
2024-07-03 19:51:00.440281: train_loss -0.6974
2024-07-03 19:51:00.442223: val_loss -0.7238
2024-07-03 19:51:00.443538: Pseudo dice [0.8537]
2024-07-03 19:51:00.492779: Epoch time: 66.35 s
2024-07-03 19:51:00.494985: Yayy! New best EMA pseudo Dice: 0.8537
2024-07-03 19:51:02.059660: 
2024-07-03 19:51:02.062268: Epoch 77
2024-07-03 19:51:02.063930: Current learning rate: 0.0093
2024-07-03 19:52:08.358194: Validation loss did not improve from -0.73830. Patience: 3/50
2024-07-03 19:52:08.359864: train_loss -0.708
2024-07-03 19:52:08.360970: val_loss -0.7291
2024-07-03 19:52:08.361883: Pseudo dice [0.8624]
2024-07-03 19:52:08.362872: Epoch time: 66.3 s
2024-07-03 19:52:08.363874: Yayy! New best EMA pseudo Dice: 0.8546
2024-07-03 19:52:09.968255: 
2024-07-03 19:52:09.970766: Epoch 78
2024-07-03 19:52:09.972379: Current learning rate: 0.0093
2024-07-03 19:53:16.055088: Validation loss improved from -0.73830 to -0.73942! Patience: 3/50
2024-07-03 19:53:16.057364: train_loss -0.702
2024-07-03 19:53:16.059483: val_loss -0.7394
2024-07-03 19:53:16.060794: Pseudo dice [0.862]
2024-07-03 19:53:16.062022: Epoch time: 66.09 s
2024-07-03 19:53:16.063446: Yayy! New best EMA pseudo Dice: 0.8553
2024-07-03 19:53:17.755778: 
2024-07-03 19:53:17.758176: Epoch 79
2024-07-03 19:53:17.759620: Current learning rate: 0.00929
2024-07-03 19:54:24.112183: Validation loss did not improve from -0.73942. Patience: 1/50
2024-07-03 19:54:24.113976: train_loss -0.7046
2024-07-03 19:54:24.115436: val_loss -0.7161
2024-07-03 19:54:24.116773: Pseudo dice [0.8583]
2024-07-03 19:54:24.118099: Epoch time: 66.36 s
2024-07-03 19:54:24.471307: Yayy! New best EMA pseudo Dice: 0.8556
2024-07-03 19:54:26.061848: 
2024-07-03 19:54:26.064637: Epoch 80
2024-07-03 19:54:26.066783: Current learning rate: 0.00928
2024-07-03 19:55:32.339169: Validation loss did not improve from -0.73942. Patience: 2/50
2024-07-03 19:55:32.340937: train_loss -0.7065
2024-07-03 19:55:32.342950: val_loss -0.7349
2024-07-03 19:55:32.344373: Pseudo dice [0.8645]
2024-07-03 19:55:32.345788: Epoch time: 66.28 s
2024-07-03 19:55:32.347134: Yayy! New best EMA pseudo Dice: 0.8565
2024-07-03 19:55:33.948812: 
2024-07-03 19:55:33.951217: Epoch 81
2024-07-03 19:55:33.952885: Current learning rate: 0.00927
2024-07-03 19:56:39.870687: Validation loss improved from -0.73942 to -0.74066! Patience: 2/50
2024-07-03 19:56:39.873286: train_loss -0.7071
2024-07-03 19:56:39.875545: val_loss -0.7407
2024-07-03 19:56:39.876760: Pseudo dice [0.872]
2024-07-03 19:56:39.877832: Epoch time: 65.93 s
2024-07-03 19:56:39.879045: Yayy! New best EMA pseudo Dice: 0.8581
2024-07-03 19:56:41.471320: 
2024-07-03 19:56:41.474288: Epoch 82
2024-07-03 19:56:41.475551: Current learning rate: 0.00926
2024-07-03 19:57:47.586641: Validation loss did not improve from -0.74066. Patience: 1/50
2024-07-03 19:57:47.588515: train_loss -0.7012
2024-07-03 19:57:47.589966: val_loss -0.7264
2024-07-03 19:57:47.591280: Pseudo dice [0.858]
2024-07-03 19:57:47.592689: Epoch time: 66.12 s
2024-07-03 19:57:48.787561: 
2024-07-03 19:57:48.790329: Epoch 83
2024-07-03 19:57:48.791877: Current learning rate: 0.00925
2024-07-03 19:58:55.187755: Validation loss improved from -0.74066 to -0.74095! Patience: 1/50
2024-07-03 19:58:55.189486: train_loss -0.7006
2024-07-03 19:58:55.191035: val_loss -0.7409
2024-07-03 19:58:55.192652: Pseudo dice [0.8706]
2024-07-03 19:58:55.194109: Epoch time: 66.4 s
2024-07-03 19:58:55.195458: Yayy! New best EMA pseudo Dice: 0.8593
2024-07-03 19:58:57.131261: 
2024-07-03 19:58:57.133748: Epoch 84
2024-07-03 19:58:57.135440: Current learning rate: 0.00924
2024-07-03 20:00:03.259900: Validation loss improved from -0.74095 to -0.74842! Patience: 0/50
2024-07-03 20:00:03.262228: train_loss -0.7032
2024-07-03 20:00:03.263919: val_loss -0.7484
2024-07-03 20:00:03.265392: Pseudo dice [0.8711]
2024-07-03 20:00:03.266788: Epoch time: 66.13 s
2024-07-03 20:00:03.618686: Yayy! New best EMA pseudo Dice: 0.8605
2024-07-03 20:00:05.106326: 
2024-07-03 20:00:05.108693: Epoch 85
2024-07-03 20:00:05.110238: Current learning rate: 0.00923
2024-07-03 20:01:11.430083: Validation loss did not improve from -0.74842. Patience: 1/50
2024-07-03 20:01:11.431611: train_loss -0.7074
2024-07-03 20:01:11.433240: val_loss -0.7107
2024-07-03 20:01:11.434542: Pseudo dice [0.8504]
2024-07-03 20:01:11.435832: Epoch time: 66.33 s
2024-07-03 20:01:12.645045: 
2024-07-03 20:01:12.647151: Epoch 86
2024-07-03 20:01:12.648975: Current learning rate: 0.00922
2024-07-03 20:02:18.773935: Validation loss did not improve from -0.74842. Patience: 2/50
2024-07-03 20:02:18.775460: train_loss -0.6895
2024-07-03 20:02:18.776702: val_loss -0.7394
2024-07-03 20:02:18.777798: Pseudo dice [0.8656]
2024-07-03 20:02:18.778791: Epoch time: 66.13 s
2024-07-03 20:02:19.989113: 
2024-07-03 20:02:19.992081: Epoch 87
2024-07-03 20:02:19.994044: Current learning rate: 0.00921
2024-07-03 20:03:26.277855: Validation loss improved from -0.74842 to -0.75548! Patience: 2/50
2024-07-03 20:03:26.279472: train_loss -0.7096
2024-07-03 20:03:26.280672: val_loss -0.7555
2024-07-03 20:03:26.281782: Pseudo dice [0.8761]
2024-07-03 20:03:26.282793: Epoch time: 66.29 s
2024-07-03 20:03:26.283834: Yayy! New best EMA pseudo Dice: 0.8617
2024-07-03 20:03:27.851496: 
2024-07-03 20:03:27.854142: Epoch 88
2024-07-03 20:03:27.855416: Current learning rate: 0.0092
2024-07-03 20:04:33.963484: Validation loss did not improve from -0.75548. Patience: 1/50
2024-07-03 20:04:33.966121: train_loss -0.7085
2024-07-03 20:04:33.967977: val_loss -0.7432
2024-07-03 20:04:33.969479: Pseudo dice [0.8658]
2024-07-03 20:04:33.970816: Epoch time: 66.12 s
2024-07-03 20:04:33.972180: Yayy! New best EMA pseudo Dice: 0.8621
2024-07-03 20:04:35.553705: 
2024-07-03 20:04:35.556839: Epoch 89
2024-07-03 20:04:35.558837: Current learning rate: 0.0092
2024-07-03 20:05:41.689138: Validation loss did not improve from -0.75548. Patience: 2/50
2024-07-03 20:05:41.690745: train_loss -0.7043
2024-07-03 20:05:41.692277: val_loss -0.7234
2024-07-03 20:05:41.693573: Pseudo dice [0.8642]
2024-07-03 20:05:41.695053: Epoch time: 66.14 s
2024-07-03 20:05:42.052352: Yayy! New best EMA pseudo Dice: 0.8623
2024-07-03 20:05:43.519211: 
2024-07-03 20:05:43.521235: Epoch 90
2024-07-03 20:05:43.522801: Current learning rate: 0.00919
2024-07-03 20:06:49.916674: Validation loss did not improve from -0.75548. Patience: 3/50
2024-07-03 20:06:49.918165: train_loss -0.7027
2024-07-03 20:06:49.919527: val_loss -0.7386
2024-07-03 20:06:49.920648: Pseudo dice [0.8687]
2024-07-03 20:06:49.921759: Epoch time: 66.4 s
2024-07-03 20:06:49.923026: Yayy! New best EMA pseudo Dice: 0.8629
2024-07-03 20:06:51.459752: 
2024-07-03 20:06:51.461747: Epoch 91
2024-07-03 20:06:51.463351: Current learning rate: 0.00918
2024-07-03 20:07:57.833997: Validation loss did not improve from -0.75548. Patience: 4/50
2024-07-03 20:07:57.835611: train_loss -0.701
2024-07-03 20:07:57.836915: val_loss -0.75
2024-07-03 20:07:57.837847: Pseudo dice [0.8734]
2024-07-03 20:07:57.838972: Epoch time: 66.38 s
2024-07-03 20:07:57.839850: Yayy! New best EMA pseudo Dice: 0.864
2024-07-03 20:07:59.325675: 
2024-07-03 20:07:59.328491: Epoch 92
2024-07-03 20:07:59.329855: Current learning rate: 0.00917
2024-07-03 20:09:05.400673: Validation loss did not improve from -0.75548. Patience: 5/50
2024-07-03 20:09:05.402288: train_loss -0.694
2024-07-03 20:09:05.404009: val_loss -0.7333
2024-07-03 20:09:05.405022: Pseudo dice [0.8632]
2024-07-03 20:09:05.406138: Epoch time: 66.08 s
2024-07-03 20:09:06.584530: 
2024-07-03 20:09:06.587155: Epoch 93
2024-07-03 20:09:06.588664: Current learning rate: 0.00916
2024-07-03 20:10:12.707841: Validation loss did not improve from -0.75548. Patience: 6/50
2024-07-03 20:10:12.709630: train_loss -0.71
2024-07-03 20:10:12.711106: val_loss -0.7305
2024-07-03 20:10:12.712202: Pseudo dice [0.8607]
2024-07-03 20:10:12.713469: Epoch time: 66.13 s
2024-07-03 20:10:13.892649: 
2024-07-03 20:10:13.895416: Epoch 94
2024-07-03 20:10:13.896701: Current learning rate: 0.00915
2024-07-03 20:11:19.754760: Validation loss did not improve from -0.75548. Patience: 7/50
2024-07-03 20:11:19.756417: train_loss -0.7199
2024-07-03 20:11:19.758100: val_loss -0.7544
2024-07-03 20:11:19.759207: Pseudo dice [0.87]
2024-07-03 20:11:19.760171: Epoch time: 65.86 s
2024-07-03 20:11:20.119939: Yayy! New best EMA pseudo Dice: 0.8642
2024-07-03 20:11:21.635619: 
2024-07-03 20:11:21.637949: Epoch 95
2024-07-03 20:11:21.639374: Current learning rate: 0.00914
2024-07-03 20:12:27.692359: Validation loss did not improve from -0.75548. Patience: 8/50
2024-07-03 20:12:27.694271: train_loss -0.7157
2024-07-03 20:12:27.696203: val_loss -0.746
2024-07-03 20:12:27.697630: Pseudo dice [0.8746]
2024-07-03 20:12:27.699062: Epoch time: 66.06 s
2024-07-03 20:12:27.700864: Yayy! New best EMA pseudo Dice: 0.8653
2024-07-03 20:12:29.174706: 
2024-07-03 20:12:29.177027: Epoch 96
2024-07-03 20:12:29.178419: Current learning rate: 0.00913
2024-07-03 20:13:35.079476: Validation loss did not improve from -0.75548. Patience: 9/50
2024-07-03 20:13:35.081295: train_loss -0.7137
2024-07-03 20:13:35.083534: val_loss -0.747
2024-07-03 20:13:35.085142: Pseudo dice [0.8693]
2024-07-03 20:13:35.086653: Epoch time: 65.91 s
2024-07-03 20:13:35.088070: Yayy! New best EMA pseudo Dice: 0.8657
2024-07-03 20:13:37.083312: 
2024-07-03 20:13:37.086320: Epoch 97
2024-07-03 20:13:37.088377: Current learning rate: 0.00912
2024-07-03 20:14:43.115592: Validation loss did not improve from -0.75548. Patience: 10/50
2024-07-03 20:14:43.117557: train_loss -0.7153
2024-07-03 20:14:43.118865: val_loss -0.7421
2024-07-03 20:14:43.120158: Pseudo dice [0.8689]
2024-07-03 20:14:43.121436: Epoch time: 66.04 s
2024-07-03 20:14:43.122859: Yayy! New best EMA pseudo Dice: 0.866
2024-07-03 20:14:44.659249: 
2024-07-03 20:14:44.660876: Epoch 98
2024-07-03 20:14:44.662128: Current learning rate: 0.00911
2024-07-03 20:15:50.641363: Validation loss improved from -0.75548 to -0.76182! Patience: 10/50
2024-07-03 20:15:50.643317: train_loss -0.7152
2024-07-03 20:15:50.645504: val_loss -0.7618
2024-07-03 20:15:50.647355: Pseudo dice [0.8732]
2024-07-03 20:15:50.648572: Epoch time: 65.99 s
2024-07-03 20:15:50.649755: Yayy! New best EMA pseudo Dice: 0.8667
2024-07-03 20:15:52.210757: 
2024-07-03 20:15:52.213624: Epoch 99
2024-07-03 20:15:52.215467: Current learning rate: 0.0091
2024-07-03 20:16:58.333839: Validation loss did not improve from -0.76182. Patience: 1/50
2024-07-03 20:16:58.335361: train_loss -0.7209
2024-07-03 20:16:58.336721: val_loss -0.7412
2024-07-03 20:16:58.337860: Pseudo dice [0.8716]
2024-07-03 20:16:58.339076: Epoch time: 66.13 s
2024-07-03 20:16:58.688923: Yayy! New best EMA pseudo Dice: 0.8672
2024-07-03 20:17:00.206538: 
2024-07-03 20:17:00.209031: Epoch 100
2024-07-03 20:17:00.210259: Current learning rate: 0.0091
2024-07-03 20:18:06.442941: Validation loss did not improve from -0.76182. Patience: 2/50
2024-07-03 20:18:06.445574: train_loss -0.7243
2024-07-03 20:18:06.448432: val_loss -0.7441
2024-07-03 20:18:06.449955: Pseudo dice [0.8692]
2024-07-03 20:18:06.451021: Epoch time: 66.24 s
2024-07-03 20:18:06.451999: Yayy! New best EMA pseudo Dice: 0.8674
2024-07-03 20:18:07.986067: 
2024-07-03 20:18:07.988734: Epoch 101
2024-07-03 20:18:07.990371: Current learning rate: 0.00909
2024-07-03 20:19:14.695506: Validation loss did not improve from -0.76182. Patience: 3/50
2024-07-03 20:19:14.705941: train_loss -0.6777
2024-07-03 20:19:14.737374: val_loss -0.7263
2024-07-03 20:19:14.739568: Pseudo dice [0.8601]
2024-07-03 20:19:14.744581: Epoch time: 66.71 s
2024-07-03 20:19:16.055526: 
2024-07-03 20:19:16.057443: Epoch 102
2024-07-03 20:19:16.058736: Current learning rate: 0.00908
2024-07-03 20:20:22.513375: Validation loss did not improve from -0.76182. Patience: 4/50
2024-07-03 20:20:22.515185: train_loss -0.7049
2024-07-03 20:20:22.516808: val_loss -0.7431
2024-07-03 20:20:22.518034: Pseudo dice [0.8712]
2024-07-03 20:20:22.519342: Epoch time: 66.46 s
2024-07-03 20:20:23.723573: 
2024-07-03 20:20:23.725897: Epoch 103
2024-07-03 20:20:23.727470: Current learning rate: 0.00907
2024-07-03 20:21:29.908641: Validation loss did not improve from -0.76182. Patience: 5/50
2024-07-03 20:21:29.910643: train_loss -0.7152
2024-07-03 20:21:29.911943: val_loss -0.7548
2024-07-03 20:21:29.913097: Pseudo dice [0.8746]
2024-07-03 20:21:29.914280: Epoch time: 66.19 s
2024-07-03 20:21:29.915502: Yayy! New best EMA pseudo Dice: 0.8679
2024-07-03 20:21:31.451608: 
2024-07-03 20:21:31.453866: Epoch 104
2024-07-03 20:21:31.455783: Current learning rate: 0.00906
2024-07-03 20:22:37.960648: Validation loss did not improve from -0.76182. Patience: 6/50
2024-07-03 20:22:37.962613: train_loss -0.715
2024-07-03 20:22:37.964314: val_loss -0.7518
2024-07-03 20:22:37.965302: Pseudo dice [0.8712]
2024-07-03 20:22:37.966563: Epoch time: 66.51 s
2024-07-03 20:22:38.318261: Yayy! New best EMA pseudo Dice: 0.8682
2024-07-03 20:22:39.853920: 
2024-07-03 20:22:39.856441: Epoch 105
2024-07-03 20:22:39.858228: Current learning rate: 0.00905
2024-07-03 20:23:46.186426: Validation loss did not improve from -0.76182. Patience: 7/50
2024-07-03 20:23:46.189087: train_loss -0.7164
2024-07-03 20:23:46.191257: val_loss -0.7395
2024-07-03 20:23:46.193032: Pseudo dice [0.8704]
2024-07-03 20:23:46.194625: Epoch time: 66.34 s
2024-07-03 20:23:46.196583: Yayy! New best EMA pseudo Dice: 0.8684
2024-07-03 20:23:47.728751: 
2024-07-03 20:23:47.730934: Epoch 106
2024-07-03 20:23:47.732394: Current learning rate: 0.00904
2024-07-03 20:24:53.939521: Validation loss did not improve from -0.76182. Patience: 8/50
2024-07-03 20:24:53.941877: train_loss -0.7187
2024-07-03 20:24:53.944229: val_loss -0.7446
2024-07-03 20:24:53.946662: Pseudo dice [0.8681]
2024-07-03 20:24:53.948833: Epoch time: 66.21 s
2024-07-03 20:24:55.130845: 
2024-07-03 20:24:55.133369: Epoch 107
2024-07-03 20:24:55.134814: Current learning rate: 0.00903
2024-07-03 20:26:01.155375: Validation loss did not improve from -0.76182. Patience: 9/50
2024-07-03 20:26:01.156851: train_loss -0.6992
2024-07-03 20:26:01.158680: val_loss -0.7367
2024-07-03 20:26:01.160096: Pseudo dice [0.868]
2024-07-03 20:26:01.161324: Epoch time: 66.03 s
2024-07-03 20:26:02.828039: 
2024-07-03 20:26:02.830351: Epoch 108
2024-07-03 20:26:02.831642: Current learning rate: 0.00902
2024-07-03 20:27:09.293702: Validation loss did not improve from -0.76182. Patience: 10/50
2024-07-03 20:27:09.295097: train_loss -0.7089
2024-07-03 20:27:09.296240: val_loss -0.7471
2024-07-03 20:27:09.297370: Pseudo dice [0.8746]
2024-07-03 20:27:09.298357: Epoch time: 66.47 s
2024-07-03 20:27:09.299346: Yayy! New best EMA pseudo Dice: 0.869
2024-07-03 20:27:10.837190: 
2024-07-03 20:27:10.839248: Epoch 109
2024-07-03 20:27:10.840392: Current learning rate: 0.00901
2024-07-03 20:28:16.880685: Validation loss did not improve from -0.76182. Patience: 11/50
2024-07-03 20:28:16.882463: train_loss -0.72
2024-07-03 20:28:16.884146: val_loss -0.7585
2024-07-03 20:28:16.885451: Pseudo dice [0.8745]
2024-07-03 20:28:16.886548: Epoch time: 66.05 s
2024-07-03 20:28:17.241169: Yayy! New best EMA pseudo Dice: 0.8695
2024-07-03 20:28:18.764627: 
2024-07-03 20:28:18.766884: Epoch 110
2024-07-03 20:28:18.768766: Current learning rate: 0.009
2024-07-03 20:29:24.894783: Validation loss did not improve from -0.76182. Patience: 12/50
2024-07-03 20:29:24.896209: train_loss -0.7188
2024-07-03 20:29:24.897462: val_loss -0.7583
2024-07-03 20:29:24.899518: Pseudo dice [0.8751]
2024-07-03 20:29:24.901036: Epoch time: 66.13 s
2024-07-03 20:29:24.902757: Yayy! New best EMA pseudo Dice: 0.8701
2024-07-03 20:29:26.424787: 
2024-07-03 20:29:26.427111: Epoch 111
2024-07-03 20:29:26.428721: Current learning rate: 0.009
2024-07-03 20:30:32.345634: Validation loss did not improve from -0.76182. Patience: 13/50
2024-07-03 20:30:32.347140: train_loss -0.7276
2024-07-03 20:30:32.348580: val_loss -0.7407
2024-07-03 20:30:32.349914: Pseudo dice [0.8728]
2024-07-03 20:30:32.351452: Epoch time: 65.92 s
2024-07-03 20:30:32.352782: Yayy! New best EMA pseudo Dice: 0.8704
2024-07-03 20:30:33.884953: 
2024-07-03 20:30:33.887041: Epoch 112
2024-07-03 20:30:33.888826: Current learning rate: 0.00899
2024-07-03 20:31:40.067756: Validation loss did not improve from -0.76182. Patience: 14/50
2024-07-03 20:31:40.069370: train_loss -0.7305
2024-07-03 20:31:40.070963: val_loss -0.7586
2024-07-03 20:31:40.072202: Pseudo dice [0.8766]
2024-07-03 20:31:40.075188: Epoch time: 66.19 s
2024-07-03 20:31:40.076771: Yayy! New best EMA pseudo Dice: 0.871
2024-07-03 20:31:41.698508: 
2024-07-03 20:31:41.701670: Epoch 113
2024-07-03 20:31:41.703557: Current learning rate: 0.00898
2024-07-03 20:32:50.122088: Validation loss did not improve from -0.76182. Patience: 15/50
2024-07-03 20:32:50.139559: train_loss -0.7306
2024-07-03 20:32:50.140822: val_loss -0.757
2024-07-03 20:32:50.142170: Pseudo dice [0.8722]
2024-07-03 20:32:50.143486: Epoch time: 68.44 s
2024-07-03 20:32:50.144637: Yayy! New best EMA pseudo Dice: 0.8711
2024-07-03 20:32:52.089462: 
2024-07-03 20:32:52.091652: Epoch 114
2024-07-03 20:32:52.093544: Current learning rate: 0.00897
2024-07-03 20:33:58.316086: Validation loss improved from -0.76182 to -0.76988! Patience: 15/50
2024-07-03 20:33:58.330121: train_loss -0.7377
2024-07-03 20:33:58.332019: val_loss -0.7699
2024-07-03 20:33:58.333499: Pseudo dice [0.8746]
2024-07-03 20:33:58.335170: Epoch time: 66.23 s
2024-07-03 20:33:58.670215: Yayy! New best EMA pseudo Dice: 0.8715
2024-07-03 20:34:00.588253: 
2024-07-03 20:34:00.590713: Epoch 115
2024-07-03 20:34:00.592201: Current learning rate: 0.00896
2024-07-03 20:35:10.726273: Validation loss did not improve from -0.76988. Patience: 1/50
2024-07-03 20:35:10.735134: train_loss -0.7269
2024-07-03 20:35:10.737067: val_loss -0.763
2024-07-03 20:35:10.738340: Pseudo dice [0.8818]
2024-07-03 20:35:10.739436: Epoch time: 70.14 s
2024-07-03 20:35:10.740565: Yayy! New best EMA pseudo Dice: 0.8725
2024-07-03 20:35:12.857775: 
2024-07-03 20:35:12.859885: Epoch 116
2024-07-03 20:35:12.861369: Current learning rate: 0.00895
2024-07-03 20:36:19.379135: Validation loss did not improve from -0.76988. Patience: 2/50
2024-07-03 20:36:19.380482: train_loss -0.7278
2024-07-03 20:36:19.382351: val_loss -0.7553
2024-07-03 20:36:19.383975: Pseudo dice [0.8811]
2024-07-03 20:36:19.385201: Epoch time: 66.52 s
2024-07-03 20:36:19.386611: Yayy! New best EMA pseudo Dice: 0.8734
2024-07-03 20:36:20.929592: 
2024-07-03 20:36:20.931348: Epoch 117
2024-07-03 20:36:20.932677: Current learning rate: 0.00894
2024-07-03 20:37:26.983531: Validation loss did not improve from -0.76988. Patience: 3/50
2024-07-03 20:37:26.984941: train_loss -0.7337
2024-07-03 20:37:26.986176: val_loss -0.7615
2024-07-03 20:37:26.987212: Pseudo dice [0.8747]
2024-07-03 20:37:26.988437: Epoch time: 66.06 s
2024-07-03 20:37:26.989480: Yayy! New best EMA pseudo Dice: 0.8735
2024-07-03 20:37:28.529552: 
2024-07-03 20:37:28.531884: Epoch 118
2024-07-03 20:37:28.533420: Current learning rate: 0.00893
2024-07-03 20:38:34.767349: Validation loss did not improve from -0.76988. Patience: 4/50
2024-07-03 20:38:34.768731: train_loss -0.7248
2024-07-03 20:38:34.770203: val_loss -0.7646
2024-07-03 20:38:34.771291: Pseudo dice [0.8747]
2024-07-03 20:38:34.772907: Epoch time: 66.24 s
2024-07-03 20:38:34.774594: Yayy! New best EMA pseudo Dice: 0.8736
2024-07-03 20:38:36.317033: 
2024-07-03 20:38:36.318946: Epoch 119
2024-07-03 20:38:36.320399: Current learning rate: 0.00892
2024-07-03 20:39:42.814353: Validation loss did not improve from -0.76988. Patience: 5/50
2024-07-03 20:39:42.815736: train_loss -0.73
2024-07-03 20:39:42.817556: val_loss -0.7582
2024-07-03 20:39:42.819485: Pseudo dice [0.8745]
2024-07-03 20:39:42.820877: Epoch time: 66.5 s
2024-07-03 20:39:45.140214: Yayy! New best EMA pseudo Dice: 0.8737
2024-07-03 20:39:46.676837: 
2024-07-03 20:39:46.678540: Epoch 120
2024-07-03 20:39:46.680243: Current learning rate: 0.00891
2024-07-03 20:40:52.847447: Validation loss did not improve from -0.76988. Patience: 6/50
2024-07-03 20:40:52.848776: train_loss -0.7322
2024-07-03 20:40:52.849952: val_loss -0.7584
2024-07-03 20:40:52.851257: Pseudo dice [0.8749]
2024-07-03 20:40:52.852272: Epoch time: 66.17 s
2024-07-03 20:40:52.853255: Yayy! New best EMA pseudo Dice: 0.8738
2024-07-03 20:40:54.421347: 
2024-07-03 20:40:54.423474: Epoch 121
2024-07-03 20:40:54.425055: Current learning rate: 0.0089
2024-07-03 20:42:00.521145: Validation loss did not improve from -0.76988. Patience: 7/50
2024-07-03 20:42:00.522438: train_loss -0.7296
2024-07-03 20:42:00.523629: val_loss -0.76
2024-07-03 20:42:00.524796: Pseudo dice [0.8778]
2024-07-03 20:42:00.526346: Epoch time: 66.1 s
2024-07-03 20:42:00.527641: Yayy! New best EMA pseudo Dice: 0.8742
2024-07-03 20:42:02.078378: 
2024-07-03 20:42:02.080619: Epoch 122
2024-07-03 20:42:02.082030: Current learning rate: 0.00889
2024-07-03 20:43:08.131257: Validation loss did not improve from -0.76988. Patience: 8/50
2024-07-03 20:43:08.132766: train_loss -0.7353
2024-07-03 20:43:08.134132: val_loss -0.7622
2024-07-03 20:43:08.135309: Pseudo dice [0.8816]
2024-07-03 20:43:08.136375: Epoch time: 66.06 s
2024-07-03 20:43:08.137397: Yayy! New best EMA pseudo Dice: 0.875
2024-07-03 20:43:09.678087: 
2024-07-03 20:43:09.680007: Epoch 123
2024-07-03 20:43:09.681754: Current learning rate: 0.00889
2024-07-03 20:44:15.653509: Validation loss did not improve from -0.76988. Patience: 9/50
2024-07-03 20:44:15.654992: train_loss -0.7351
2024-07-03 20:44:15.656635: val_loss -0.7633
2024-07-03 20:44:15.658284: Pseudo dice [0.8724]
2024-07-03 20:44:15.660125: Epoch time: 65.98 s
2024-07-03 20:44:16.897982: 
2024-07-03 20:44:16.899792: Epoch 124
2024-07-03 20:44:16.900849: Current learning rate: 0.00888
2024-07-03 20:45:22.978276: Validation loss did not improve from -0.76988. Patience: 10/50
2024-07-03 20:45:22.979903: train_loss -0.735
2024-07-03 20:45:22.981788: val_loss -0.7468
2024-07-03 20:45:22.983089: Pseudo dice [0.8713]
2024-07-03 20:45:22.984782: Epoch time: 66.08 s
2024-07-03 20:45:24.548550: 
2024-07-03 20:45:24.550280: Epoch 125
2024-07-03 20:45:24.551616: Current learning rate: 0.00887
2024-07-03 20:46:30.315212: Validation loss improved from -0.76988 to -0.77050! Patience: 10/50
2024-07-03 20:46:30.316761: train_loss -0.731
2024-07-03 20:46:30.317994: val_loss -0.7705
2024-07-03 20:46:30.319314: Pseudo dice [0.8792]
2024-07-03 20:46:30.320498: Epoch time: 65.77 s
2024-07-03 20:46:31.556783: 
2024-07-03 20:46:31.558758: Epoch 126
2024-07-03 20:46:31.560154: Current learning rate: 0.00886
2024-07-03 20:47:37.565638: Validation loss did not improve from -0.77050. Patience: 1/50
2024-07-03 20:47:37.567708: train_loss -0.735
2024-07-03 20:47:37.569519: val_loss -0.7553
2024-07-03 20:47:37.571362: Pseudo dice [0.8712]
2024-07-03 20:47:37.572872: Epoch time: 66.01 s
2024-07-03 20:47:38.746774: 
2024-07-03 20:47:38.748828: Epoch 127
2024-07-03 20:47:38.750350: Current learning rate: 0.00885
2024-07-03 20:48:44.788130: Validation loss did not improve from -0.77050. Patience: 2/50
2024-07-03 20:48:44.789573: train_loss -0.7275
2024-07-03 20:48:44.790711: val_loss -0.7512
2024-07-03 20:48:44.791744: Pseudo dice [0.8721]
2024-07-03 20:48:44.792771: Epoch time: 66.04 s
2024-07-03 20:48:46.009139: 
2024-07-03 20:48:46.010929: Epoch 128
2024-07-03 20:48:46.012341: Current learning rate: 0.00884
2024-07-03 20:49:52.133695: Validation loss did not improve from -0.77050. Patience: 3/50
2024-07-03 20:49:52.134923: train_loss -0.7301
2024-07-03 20:49:52.136137: val_loss -0.7651
2024-07-03 20:49:52.137265: Pseudo dice [0.8771]
2024-07-03 20:49:52.138585: Epoch time: 66.13 s
2024-07-03 20:49:53.366972: 
2024-07-03 20:49:53.368969: Epoch 129
2024-07-03 20:49:53.370566: Current learning rate: 0.00883
2024-07-03 20:50:59.588364: Validation loss did not improve from -0.77050. Patience: 4/50
2024-07-03 20:50:59.589874: train_loss -0.7401
2024-07-03 20:50:59.591151: val_loss -0.7624
2024-07-03 20:50:59.592565: Pseudo dice [0.8829]
2024-07-03 20:50:59.593726: Epoch time: 66.22 s
2024-07-03 20:50:59.950091: Yayy! New best EMA pseudo Dice: 0.8754
2024-07-03 20:51:01.513168: 
2024-07-03 20:51:01.515417: Epoch 130
2024-07-03 20:51:01.517476: Current learning rate: 0.00882
2024-07-03 20:52:07.551304: Validation loss improved from -0.77050 to -0.77099! Patience: 4/50
2024-07-03 20:52:07.552773: train_loss -0.7456
2024-07-03 20:52:07.554219: val_loss -0.771
2024-07-03 20:52:07.555428: Pseudo dice [0.8847]
2024-07-03 20:52:07.556569: Epoch time: 66.04 s
2024-07-03 20:52:07.558259: Yayy! New best EMA pseudo Dice: 0.8763
2024-07-03 20:52:09.421850: 
2024-07-03 20:52:09.424593: Epoch 131
2024-07-03 20:52:09.480864: Current learning rate: 0.00881
2024-07-03 20:53:15.665312: Validation loss did not improve from -0.77099. Patience: 1/50
2024-07-03 20:53:15.666858: train_loss -0.7312
2024-07-03 20:53:15.668423: val_loss -0.7582
2024-07-03 20:53:15.670113: Pseudo dice [0.8688]
2024-07-03 20:53:15.671305: Epoch time: 66.25 s
2024-07-03 20:53:16.871861: 
2024-07-03 20:53:16.874274: Epoch 132
2024-07-03 20:53:16.875797: Current learning rate: 0.0088
2024-07-03 20:54:22.770354: Validation loss did not improve from -0.77099. Patience: 2/50
2024-07-03 20:54:22.771768: train_loss -0.7306
2024-07-03 20:54:22.773231: val_loss -0.7571
2024-07-03 20:54:22.774416: Pseudo dice [0.8765]
2024-07-03 20:54:22.775625: Epoch time: 65.9 s
2024-07-03 20:54:23.928712: 
2024-07-03 20:54:23.930791: Epoch 133
2024-07-03 20:54:23.932415: Current learning rate: 0.00879
2024-07-03 20:55:30.074709: Validation loss did not improve from -0.77099. Patience: 3/50
2024-07-03 20:55:30.076330: train_loss -0.7319
2024-07-03 20:55:30.077470: val_loss -0.7627
2024-07-03 20:55:30.078708: Pseudo dice [0.8768]
2024-07-03 20:55:30.079745: Epoch time: 66.15 s
2024-07-03 20:55:31.287612: 
2024-07-03 20:55:31.290273: Epoch 134
2024-07-03 20:55:31.291896: Current learning rate: 0.00879
2024-07-03 20:56:37.590812: Validation loss did not improve from -0.77099. Patience: 4/50
2024-07-03 20:56:37.592319: train_loss -0.7274
2024-07-03 20:56:37.593622: val_loss -0.7603
2024-07-03 20:56:37.594621: Pseudo dice [0.8771]
2024-07-03 20:56:37.595607: Epoch time: 66.31 s
2024-07-03 20:56:39.156071: 
2024-07-03 20:56:39.158309: Epoch 135
2024-07-03 20:56:39.159657: Current learning rate: 0.00878
2024-07-03 20:57:45.110363: Validation loss did not improve from -0.77099. Patience: 5/50
2024-07-03 20:57:45.112086: train_loss -0.7201
2024-07-03 20:57:45.114183: val_loss -0.7567
2024-07-03 20:57:45.115811: Pseudo dice [0.8764]
2024-07-03 20:57:45.117169: Epoch time: 65.96 s
2024-07-03 20:57:46.344195: 
2024-07-03 20:57:46.346164: Epoch 136
2024-07-03 20:57:46.347414: Current learning rate: 0.00877
2024-07-03 20:58:52.388476: Validation loss did not improve from -0.77099. Patience: 6/50
2024-07-03 20:58:52.389903: train_loss -0.7227
2024-07-03 20:58:52.391023: val_loss -0.751
2024-07-03 20:58:52.392023: Pseudo dice [0.8743]
2024-07-03 20:58:52.393212: Epoch time: 66.05 s
2024-07-03 20:58:53.606238: 
2024-07-03 20:58:53.608559: Epoch 137
2024-07-03 20:58:53.609845: Current learning rate: 0.00876
2024-07-03 20:59:59.591935: Validation loss did not improve from -0.77099. Patience: 7/50
2024-07-03 20:59:59.593526: train_loss -0.7375
2024-07-03 20:59:59.595102: val_loss -0.7584
2024-07-03 20:59:59.596260: Pseudo dice [0.8779]
2024-07-03 20:59:59.597234: Epoch time: 65.99 s
2024-07-03 21:00:00.820826: 
2024-07-03 21:00:00.822695: Epoch 138
2024-07-03 21:00:00.823946: Current learning rate: 0.00875
2024-07-03 21:01:06.838412: Validation loss did not improve from -0.77099. Patience: 8/50
2024-07-03 21:01:06.840020: train_loss -0.7392
2024-07-03 21:01:06.841275: val_loss -0.7679
2024-07-03 21:01:06.842292: Pseudo dice [0.8875]
2024-07-03 21:01:06.844218: Epoch time: 66.02 s
2024-07-03 21:01:06.845596: Yayy! New best EMA pseudo Dice: 0.8771
2024-07-03 21:01:08.396586: 
2024-07-03 21:01:08.398412: Epoch 139
2024-07-03 21:01:08.399993: Current learning rate: 0.00874
2024-07-03 21:02:14.373843: Validation loss did not improve from -0.77099. Patience: 9/50
2024-07-03 21:02:14.375131: train_loss -0.7358
2024-07-03 21:02:14.376348: val_loss -0.7617
2024-07-03 21:02:14.377276: Pseudo dice [0.8769]
2024-07-03 21:02:14.378328: Epoch time: 65.98 s
2024-07-03 21:02:15.898348: 
2024-07-03 21:02:15.899935: Epoch 140
2024-07-03 21:02:15.901031: Current learning rate: 0.00873
2024-07-03 21:03:22.251905: Validation loss did not improve from -0.77099. Patience: 10/50
2024-07-03 21:03:22.253092: train_loss -0.7253
2024-07-03 21:03:22.255002: val_loss -0.7637
2024-07-03 21:03:22.256635: Pseudo dice [0.878]
2024-07-03 21:03:22.257997: Epoch time: 66.36 s
2024-07-03 21:03:22.259628: Yayy! New best EMA pseudo Dice: 0.8772
2024-07-03 21:03:23.805038: 
2024-07-03 21:03:23.806602: Epoch 141
2024-07-03 21:03:23.808329: Current learning rate: 0.00872
2024-07-03 21:04:29.999017: Validation loss did not improve from -0.77099. Patience: 11/50
2024-07-03 21:04:30.000262: train_loss -0.7247
2024-07-03 21:04:30.001765: val_loss -0.763
2024-07-03 21:04:30.002841: Pseudo dice [0.8812]
2024-07-03 21:04:30.004057: Epoch time: 66.2 s
2024-07-03 21:04:30.005170: Yayy! New best EMA pseudo Dice: 0.8776
2024-07-03 21:04:31.536000: 
2024-07-03 21:04:31.537736: Epoch 142
2024-07-03 21:04:31.538873: Current learning rate: 0.00871
2024-07-03 21:05:38.016262: Validation loss did not improve from -0.77099. Patience: 12/50
2024-07-03 21:05:38.017559: train_loss -0.7211
2024-07-03 21:05:38.018870: val_loss -0.7432
2024-07-03 21:05:38.020070: Pseudo dice [0.869]
2024-07-03 21:05:38.021237: Epoch time: 66.48 s
2024-07-03 21:05:39.560554: 
2024-07-03 21:05:39.562333: Epoch 143
2024-07-03 21:05:39.563505: Current learning rate: 0.0087
2024-07-03 21:06:45.791928: Validation loss did not improve from -0.77099. Patience: 13/50
2024-07-03 21:06:45.793326: train_loss -0.7225
2024-07-03 21:06:45.794705: val_loss -0.7484
2024-07-03 21:06:45.795886: Pseudo dice [0.87]
2024-07-03 21:06:45.797459: Epoch time: 66.23 s
2024-07-03 21:06:47.007947: 
2024-07-03 21:06:47.010100: Epoch 144
2024-07-03 21:06:47.011634: Current learning rate: 0.00869
2024-07-03 21:07:53.105157: Validation loss did not improve from -0.77099. Patience: 14/50
2024-07-03 21:07:53.106661: train_loss -0.7322
2024-07-03 21:07:53.108775: val_loss -0.7555
2024-07-03 21:07:53.110192: Pseudo dice [0.8761]
2024-07-03 21:07:53.111541: Epoch time: 66.1 s
2024-07-03 21:07:54.683946: 
2024-07-03 21:07:54.686177: Epoch 145
2024-07-03 21:07:54.687679: Current learning rate: 0.00868
2024-07-03 21:09:01.182955: Validation loss improved from -0.77099 to -0.77195! Patience: 14/50
2024-07-03 21:09:01.184795: train_loss -0.7434
2024-07-03 21:09:01.186323: val_loss -0.772
2024-07-03 21:09:01.187556: Pseudo dice [0.8842]
2024-07-03 21:09:01.188814: Epoch time: 66.5 s
2024-07-03 21:09:02.420025: 
2024-07-03 21:09:02.421811: Epoch 146
2024-07-03 21:09:02.423001: Current learning rate: 0.00868
2024-07-03 21:10:08.334396: Validation loss did not improve from -0.77195. Patience: 1/50
2024-07-03 21:10:08.335769: train_loss -0.7384
2024-07-03 21:10:08.337128: val_loss -0.7664
2024-07-03 21:10:08.338360: Pseudo dice [0.8803]
2024-07-03 21:10:08.339955: Epoch time: 65.92 s
2024-07-03 21:10:09.584835: 
2024-07-03 21:10:09.586966: Epoch 147
2024-07-03 21:10:09.588669: Current learning rate: 0.00867
2024-07-03 21:11:15.914121: Validation loss improved from -0.77195 to -0.77601! Patience: 1/50
2024-07-03 21:11:15.915514: train_loss -0.7379
2024-07-03 21:11:15.917000: val_loss -0.776
2024-07-03 21:11:15.918485: Pseudo dice [0.8833]
2024-07-03 21:11:15.919828: Epoch time: 66.33 s
2024-07-03 21:11:15.921240: Yayy! New best EMA pseudo Dice: 0.8778
2024-07-03 21:11:17.482537: 
2024-07-03 21:11:17.484339: Epoch 148
2024-07-03 21:11:17.485741: Current learning rate: 0.00866
2024-07-03 21:12:23.437067: Validation loss did not improve from -0.77601. Patience: 1/50
2024-07-03 21:12:23.438338: train_loss -0.7402
2024-07-03 21:12:23.439618: val_loss -0.7696
2024-07-03 21:12:23.440820: Pseudo dice [0.8783]
2024-07-03 21:12:23.442000: Epoch time: 65.96 s
2024-07-03 21:12:23.443192: Yayy! New best EMA pseudo Dice: 0.8779
2024-07-03 21:12:24.976718: 
2024-07-03 21:12:24.978533: Epoch 149
2024-07-03 21:12:24.980404: Current learning rate: 0.00865
2024-07-03 21:13:31.064429: Validation loss did not improve from -0.77601. Patience: 2/50
2024-07-03 21:13:31.066363: train_loss -0.7419
2024-07-03 21:13:31.068283: val_loss -0.767
2024-07-03 21:13:31.069585: Pseudo dice [0.88]
2024-07-03 21:13:31.070943: Epoch time: 66.09 s
2024-07-03 21:13:31.424585: Yayy! New best EMA pseudo Dice: 0.8781
2024-07-03 21:13:33.007881: 
2024-07-03 21:13:33.010459: Epoch 150
2024-07-03 21:13:33.011850: Current learning rate: 0.00864
2024-07-03 21:14:39.370937: Validation loss did not improve from -0.77601. Patience: 3/50
2024-07-03 21:14:39.372496: train_loss -0.748
2024-07-03 21:14:39.374096: val_loss -0.758
2024-07-03 21:14:39.375455: Pseudo dice [0.8732]
2024-07-03 21:14:39.376728: Epoch time: 66.37 s
2024-07-03 21:14:40.623169: 
2024-07-03 21:14:40.625570: Epoch 151
2024-07-03 21:14:40.627088: Current learning rate: 0.00863
2024-07-03 21:15:46.621323: Validation loss did not improve from -0.77601. Patience: 4/50
2024-07-03 21:15:46.622787: train_loss -0.734
2024-07-03 21:15:46.624471: val_loss -0.7701
2024-07-03 21:15:46.625807: Pseudo dice [0.8781]
2024-07-03 21:15:46.627256: Epoch time: 66.0 s
2024-07-03 21:15:47.881048: 
2024-07-03 21:15:47.882789: Epoch 152
2024-07-03 21:15:47.884112: Current learning rate: 0.00862
2024-07-03 21:16:53.878023: Validation loss did not improve from -0.77601. Patience: 5/50
2024-07-03 21:16:53.879152: train_loss -0.7319
2024-07-03 21:16:53.880502: val_loss -0.7621
2024-07-03 21:16:53.881595: Pseudo dice [0.8822]
2024-07-03 21:16:53.882851: Epoch time: 66.0 s
2024-07-03 21:16:53.884146: Yayy! New best EMA pseudo Dice: 0.8781
2024-07-03 21:16:55.423166: 
2024-07-03 21:16:55.425161: Epoch 153
2024-07-03 21:16:55.426859: Current learning rate: 0.00861
2024-07-03 21:18:01.995413: Validation loss did not improve from -0.77601. Patience: 6/50
2024-07-03 21:18:01.996776: train_loss -0.735
2024-07-03 21:18:01.998074: val_loss -0.7524
2024-07-03 21:18:01.999311: Pseudo dice [0.875]
2024-07-03 21:18:02.000463: Epoch time: 66.57 s
2024-07-03 21:18:03.693953: 
2024-07-03 21:18:03.695871: Epoch 154
2024-07-03 21:18:03.697161: Current learning rate: 0.0086
2024-07-03 21:19:09.888530: Validation loss did not improve from -0.77601. Patience: 7/50
2024-07-03 21:19:09.889891: train_loss -0.7316
2024-07-03 21:19:09.891103: val_loss -0.7707
2024-07-03 21:19:09.892503: Pseudo dice [0.8771]
2024-07-03 21:19:09.893756: Epoch time: 66.2 s
2024-07-03 21:19:11.520732: 
2024-07-03 21:19:11.523147: Epoch 155
2024-07-03 21:19:11.524728: Current learning rate: 0.00859
2024-07-03 21:20:17.292855: Validation loss did not improve from -0.77601. Patience: 8/50
2024-07-03 21:20:17.294123: train_loss -0.7412
2024-07-03 21:20:17.295757: val_loss -0.7589
2024-07-03 21:20:17.297097: Pseudo dice [0.8768]
2024-07-03 21:20:17.298442: Epoch time: 65.77 s
2024-07-03 21:20:18.638948: 
2024-07-03 21:20:18.641537: Epoch 156
2024-07-03 21:20:18.643044: Current learning rate: 0.00858
2024-07-03 21:21:24.803224: Validation loss did not improve from -0.77601. Patience: 9/50
2024-07-03 21:21:24.804630: train_loss -0.7361
2024-07-03 21:21:24.805762: val_loss -0.7552
2024-07-03 21:21:24.807075: Pseudo dice [0.8734]
2024-07-03 21:21:24.808470: Epoch time: 66.17 s
2024-07-03 21:21:26.079128: 
2024-07-03 21:21:26.081216: Epoch 157
2024-07-03 21:21:26.082428: Current learning rate: 0.00858
2024-07-03 21:22:32.003329: Validation loss did not improve from -0.77601. Patience: 10/50
2024-07-03 21:22:32.004827: train_loss -0.7378
2024-07-03 21:22:32.006478: val_loss -0.7724
2024-07-03 21:22:32.007660: Pseudo dice [0.8851]
2024-07-03 21:22:32.008818: Epoch time: 65.93 s
2024-07-03 21:22:33.240301: 
2024-07-03 21:22:33.242170: Epoch 158
2024-07-03 21:22:33.243397: Current learning rate: 0.00857
2024-07-03 21:23:39.285794: Validation loss did not improve from -0.77601. Patience: 11/50
2024-07-03 21:23:39.287178: train_loss -0.7373
2024-07-03 21:23:39.289506: val_loss -0.7657
2024-07-03 21:23:39.290677: Pseudo dice [0.8824]
2024-07-03 21:23:39.292011: Epoch time: 66.05 s
2024-07-03 21:23:39.293224: Yayy! New best EMA pseudo Dice: 0.8784
2024-07-03 21:23:40.886089: 
2024-07-03 21:23:40.887974: Epoch 159
2024-07-03 21:23:40.889533: Current learning rate: 0.00856
2024-07-03 21:24:47.078991: Validation loss did not improve from -0.77601. Patience: 12/50
2024-07-03 21:24:47.084541: train_loss -0.7475
2024-07-03 21:24:47.086141: val_loss -0.7676
2024-07-03 21:24:47.087481: Pseudo dice [0.8839]
2024-07-03 21:24:47.088790: Epoch time: 66.2 s
2024-07-03 21:24:47.449298: Yayy! New best EMA pseudo Dice: 0.879
2024-07-03 21:24:49.080769: 
2024-07-03 21:24:49.082917: Epoch 160
2024-07-03 21:24:49.084043: Current learning rate: 0.00855
2024-07-03 21:25:55.340301: Validation loss improved from -0.77601 to -0.78249! Patience: 12/50
2024-07-03 21:25:55.341855: train_loss -0.7528
2024-07-03 21:25:55.343522: val_loss -0.7825
2024-07-03 21:25:55.344630: Pseudo dice [0.8843]
2024-07-03 21:25:55.346010: Epoch time: 66.26 s
2024-07-03 21:25:55.347126: Yayy! New best EMA pseudo Dice: 0.8795
2024-07-03 21:25:56.939769: 
2024-07-03 21:25:56.941775: Epoch 161
2024-07-03 21:25:56.943638: Current learning rate: 0.00854
2024-07-03 21:27:02.793125: Validation loss did not improve from -0.78249. Patience: 1/50
2024-07-03 21:27:02.794793: train_loss -0.7444
2024-07-03 21:27:02.796180: val_loss -0.7803
2024-07-03 21:27:02.797534: Pseudo dice [0.887]
2024-07-03 21:27:02.798548: Epoch time: 65.86 s
2024-07-03 21:27:02.799716: Yayy! New best EMA pseudo Dice: 0.8803
2024-07-03 21:27:04.359391: 
2024-07-03 21:27:04.361195: Epoch 162
2024-07-03 21:27:04.362424: Current learning rate: 0.00853
2024-07-03 21:28:10.639592: Validation loss did not improve from -0.78249. Patience: 2/50
2024-07-03 21:28:10.641217: train_loss -0.7457
2024-07-03 21:28:10.642943: val_loss -0.7712
2024-07-03 21:28:10.644457: Pseudo dice [0.8865]
2024-07-03 21:28:10.645734: Epoch time: 66.28 s
2024-07-03 21:28:10.646933: Yayy! New best EMA pseudo Dice: 0.8809
2024-07-03 21:28:12.269393: 
2024-07-03 21:28:12.271843: Epoch 163
2024-07-03 21:28:12.274046: Current learning rate: 0.00852
2024-07-03 21:29:18.943715: Validation loss did not improve from -0.78249. Patience: 3/50
2024-07-03 21:29:18.944989: train_loss -0.7448
2024-07-03 21:29:18.946221: val_loss -0.7712
2024-07-03 21:29:18.947708: Pseudo dice [0.8815]
2024-07-03 21:29:18.949090: Epoch time: 66.68 s
2024-07-03 21:29:18.950458: Yayy! New best EMA pseudo Dice: 0.881
2024-07-03 21:29:20.531875: 
2024-07-03 21:29:20.533909: Epoch 164
2024-07-03 21:29:20.535208: Current learning rate: 0.00851
2024-07-03 21:30:26.536136: Validation loss did not improve from -0.78249. Patience: 4/50
2024-07-03 21:30:26.537999: train_loss -0.7496
2024-07-03 21:30:26.539850: val_loss -0.7705
2024-07-03 21:30:26.541030: Pseudo dice [0.8809]
2024-07-03 21:30:26.542222: Epoch time: 66.01 s
2024-07-03 21:30:28.604563: 
2024-07-03 21:30:28.606965: Epoch 165
2024-07-03 21:30:28.608276: Current learning rate: 0.0085
2024-07-03 21:31:34.870922: Validation loss did not improve from -0.78249. Patience: 5/50
2024-07-03 21:31:34.872320: train_loss -0.7422
2024-07-03 21:31:34.873834: val_loss -0.7717
2024-07-03 21:31:34.875189: Pseudo dice [0.8837]
2024-07-03 21:31:34.876544: Epoch time: 66.27 s
2024-07-03 21:31:34.877745: Yayy! New best EMA pseudo Dice: 0.8812
2024-07-03 21:31:36.439817: 
2024-07-03 21:31:36.441910: Epoch 166
2024-07-03 21:31:36.443648: Current learning rate: 0.00849
2024-07-03 21:32:42.856876: Validation loss did not improve from -0.78249. Patience: 6/50
2024-07-03 21:32:42.858267: train_loss -0.7405
2024-07-03 21:32:42.859666: val_loss -0.7816
2024-07-03 21:32:42.860780: Pseudo dice [0.8884]
2024-07-03 21:32:42.861956: Epoch time: 66.42 s
2024-07-03 21:32:42.863179: Yayy! New best EMA pseudo Dice: 0.8819
2024-07-03 21:32:44.371052: 
2024-07-03 21:32:44.373421: Epoch 167
2024-07-03 21:32:44.374948: Current learning rate: 0.00848
2024-07-03 21:33:50.286161: Validation loss did not improve from -0.78249. Patience: 7/50
2024-07-03 21:33:50.287364: train_loss -0.7489
2024-07-03 21:33:50.290640: val_loss -0.7695
2024-07-03 21:33:50.291934: Pseudo dice [0.8809]
2024-07-03 21:33:50.293263: Epoch time: 65.92 s
2024-07-03 21:33:51.502966: 
2024-07-03 21:33:51.504778: Epoch 168
2024-07-03 21:33:51.506543: Current learning rate: 0.00847
2024-07-03 21:34:57.792935: Validation loss did not improve from -0.78249. Patience: 8/50
2024-07-03 21:34:57.794394: train_loss -0.7359
2024-07-03 21:34:57.796077: val_loss -0.7444
2024-07-03 21:34:57.797437: Pseudo dice [0.8712]
2024-07-03 21:34:57.798885: Epoch time: 66.29 s
2024-07-03 21:34:59.046165: 
2024-07-03 21:34:59.048697: Epoch 169
2024-07-03 21:34:59.050570: Current learning rate: 0.00847
2024-07-03 21:36:05.526181: Validation loss did not improve from -0.78249. Patience: 9/50
2024-07-03 21:36:05.527718: train_loss -0.7136
2024-07-03 21:36:05.528966: val_loss -0.7536
2024-07-03 21:36:05.530236: Pseudo dice [0.8735]
2024-07-03 21:36:05.531615: Epoch time: 66.48 s
2024-07-03 21:36:07.150038: 
2024-07-03 21:36:07.152150: Epoch 170
2024-07-03 21:36:07.154011: Current learning rate: 0.00846
2024-07-03 21:37:14.128756: Validation loss did not improve from -0.78249. Patience: 10/50
2024-07-03 21:37:14.130090: train_loss -0.733
2024-07-03 21:37:14.131582: val_loss -0.7569
2024-07-03 21:37:14.132790: Pseudo dice [0.8753]
2024-07-03 21:37:14.133925: Epoch time: 66.98 s
2024-07-03 21:37:15.815303: 
2024-07-03 21:37:15.817766: Epoch 171
2024-07-03 21:37:15.819214: Current learning rate: 0.00845
2024-07-03 21:38:23.660620: Validation loss did not improve from -0.78249. Patience: 11/50
2024-07-03 21:38:23.669294: train_loss -0.7371
2024-07-03 21:38:23.670917: val_loss -0.7678
2024-07-03 21:38:23.671947: Pseudo dice [0.8815]
2024-07-03 21:38:23.673175: Epoch time: 67.86 s
2024-07-03 21:38:25.087943: 
2024-07-03 21:38:25.090202: Epoch 172
2024-07-03 21:38:25.091579: Current learning rate: 0.00844
2024-07-03 21:39:31.792061: Validation loss did not improve from -0.78249. Patience: 12/50
2024-07-03 21:39:31.819960: train_loss -0.7485
2024-07-03 21:39:31.821643: val_loss -0.7807
2024-07-03 21:39:31.823116: Pseudo dice [0.8825]
2024-07-03 21:39:31.824284: Epoch time: 66.71 s
2024-07-03 21:39:33.514097: 
2024-07-03 21:39:33.516654: Epoch 173
2024-07-03 21:39:33.518147: Current learning rate: 0.00843
2024-07-03 21:40:41.295857: Validation loss did not improve from -0.78249. Patience: 13/50
2024-07-03 21:40:41.315427: train_loss -0.7374
2024-07-03 21:40:41.317463: val_loss -0.7679
2024-07-03 21:40:41.318944: Pseudo dice [0.886]
2024-07-03 21:40:41.319944: Epoch time: 67.8 s
2024-07-03 21:40:42.875724: 
2024-07-03 21:40:42.877449: Epoch 174
2024-07-03 21:40:42.878549: Current learning rate: 0.00842
2024-07-03 21:41:48.921888: Validation loss did not improve from -0.78249. Patience: 14/50
2024-07-03 21:41:48.923258: train_loss -0.7286
2024-07-03 21:41:48.924474: val_loss -0.763
2024-07-03 21:41:48.925620: Pseudo dice [0.8822]
2024-07-03 21:41:48.926876: Epoch time: 66.05 s
2024-07-03 21:41:50.846581: 
2024-07-03 21:41:50.849148: Epoch 175
2024-07-03 21:41:50.851239: Current learning rate: 0.00841
2024-07-03 21:42:57.088800: Validation loss did not improve from -0.78249. Patience: 15/50
2024-07-03 21:42:57.090092: train_loss -0.7427
2024-07-03 21:42:57.091479: val_loss -0.7714
2024-07-03 21:42:57.092767: Pseudo dice [0.8816]
2024-07-03 21:42:57.094151: Epoch time: 66.24 s
2024-07-03 21:43:00.192958: 
2024-07-03 21:43:00.195189: Epoch 176
2024-07-03 21:43:00.196771: Current learning rate: 0.0084
2024-07-03 21:44:06.573961: Validation loss did not improve from -0.78249. Patience: 16/50
2024-07-03 21:44:06.575260: train_loss -0.7462
2024-07-03 21:44:06.576606: val_loss -0.7771
2024-07-03 21:44:06.577639: Pseudo dice [0.8834]
2024-07-03 21:44:06.578603: Epoch time: 66.38 s
2024-07-03 21:44:07.818112: 
2024-07-03 21:44:07.820511: Epoch 177
2024-07-03 21:44:07.821868: Current learning rate: 0.00839
2024-07-03 21:45:14.465623: Validation loss did not improve from -0.78249. Patience: 17/50
2024-07-03 21:45:14.467165: train_loss -0.7475
2024-07-03 21:45:14.468500: val_loss -0.7738
2024-07-03 21:45:14.469575: Pseudo dice [0.8846]
2024-07-03 21:45:14.470800: Epoch time: 66.65 s
2024-07-03 21:45:15.699373: 
2024-07-03 21:45:15.701463: Epoch 178
2024-07-03 21:45:15.702778: Current learning rate: 0.00838
2024-07-03 21:46:21.967955: Validation loss improved from -0.78249 to -0.78298! Patience: 17/50
2024-07-03 21:46:21.969391: train_loss -0.7587
2024-07-03 21:46:21.970802: val_loss -0.783
2024-07-03 21:46:21.971919: Pseudo dice [0.8832]
2024-07-03 21:46:21.972883: Epoch time: 66.27 s
2024-07-03 21:46:23.197782: 
2024-07-03 21:46:23.199650: Epoch 179
2024-07-03 21:46:23.200894: Current learning rate: 0.00837
2024-07-03 21:47:29.157623: Validation loss improved from -0.78298 to -0.78340! Patience: 0/50
2024-07-03 21:47:29.159257: train_loss -0.7535
2024-07-03 21:47:29.160684: val_loss -0.7834
2024-07-03 21:47:29.161904: Pseudo dice [0.8902]
2024-07-03 21:47:29.163161: Epoch time: 65.96 s
2024-07-03 21:47:29.623835: Yayy! New best EMA pseudo Dice: 0.8825
2024-07-03 21:47:31.129609: 
2024-07-03 21:47:31.131527: Epoch 180
2024-07-03 21:47:31.133191: Current learning rate: 0.00836
2024-07-03 21:48:37.459382: Validation loss did not improve from -0.78340. Patience: 1/50
2024-07-03 21:48:37.460603: train_loss -0.7493
2024-07-03 21:48:37.461838: val_loss -0.7481
2024-07-03 21:48:37.462976: Pseudo dice [0.8762]
2024-07-03 21:48:37.464177: Epoch time: 66.33 s
2024-07-03 21:48:38.714218: 
2024-07-03 21:48:38.716313: Epoch 181
2024-07-03 21:48:38.718186: Current learning rate: 0.00836
2024-07-03 21:49:44.845115: Validation loss did not improve from -0.78340. Patience: 2/50
2024-07-03 21:49:44.846891: train_loss -0.7164
2024-07-03 21:49:44.848301: val_loss -0.7591
2024-07-03 21:49:44.849321: Pseudo dice [0.882]
2024-07-03 21:49:44.850329: Epoch time: 66.13 s
2024-07-03 21:49:46.085258: 
2024-07-03 21:49:46.087212: Epoch 182
2024-07-03 21:49:46.088713: Current learning rate: 0.00835
2024-07-03 21:50:52.314841: Validation loss did not improve from -0.78340. Patience: 3/50
2024-07-03 21:50:52.316729: train_loss -0.7263
2024-07-03 21:50:52.318534: val_loss -0.7626
2024-07-03 21:50:52.319589: Pseudo dice [0.8802]
2024-07-03 21:50:52.320798: Epoch time: 66.23 s
2024-07-03 21:50:53.574055: 
2024-07-03 21:50:53.575981: Epoch 183
2024-07-03 21:50:53.577404: Current learning rate: 0.00834
2024-07-03 21:51:59.834299: Validation loss did not improve from -0.78340. Patience: 4/50
2024-07-03 21:51:59.835914: train_loss -0.7402
2024-07-03 21:51:59.837492: val_loss -0.7687
2024-07-03 21:51:59.838562: Pseudo dice [0.8804]
2024-07-03 21:51:59.839673: Epoch time: 66.26 s
2024-07-03 21:52:01.092158: 
2024-07-03 21:52:01.094155: Epoch 184
2024-07-03 21:52:01.096127: Current learning rate: 0.00833
2024-07-03 21:53:07.300905: Validation loss improved from -0.78340 to -0.78494! Patience: 4/50
2024-07-03 21:53:07.302247: train_loss -0.7503
2024-07-03 21:53:07.303679: val_loss -0.7849
2024-07-03 21:53:07.304807: Pseudo dice [0.891]
2024-07-03 21:53:07.305943: Epoch time: 66.21 s
2024-07-03 21:53:07.658352: Yayy! New best EMA pseudo Dice: 0.8825
2024-07-03 21:53:09.206863: 
2024-07-03 21:53:09.209105: Epoch 185
2024-07-03 21:53:09.210991: Current learning rate: 0.00832
2024-07-03 21:54:15.470477: Validation loss did not improve from -0.78494. Patience: 1/50
2024-07-03 21:54:15.472332: train_loss -0.7497
2024-07-03 21:54:15.474110: val_loss -0.774
2024-07-03 21:54:15.475490: Pseudo dice [0.8821]
2024-07-03 21:54:15.476737: Epoch time: 66.27 s
2024-07-03 21:54:16.743589: 
2024-07-03 21:54:16.745315: Epoch 186
2024-07-03 21:54:16.746420: Current learning rate: 0.00831
2024-07-03 21:55:22.856599: Validation loss did not improve from -0.78494. Patience: 2/50
2024-07-03 21:55:22.857912: train_loss -0.7443
2024-07-03 21:55:22.859200: val_loss -0.7825
2024-07-03 21:55:22.860269: Pseudo dice [0.8861]
2024-07-03 21:55:22.861214: Epoch time: 66.12 s
2024-07-03 21:55:22.862090: Yayy! New best EMA pseudo Dice: 0.8828
2024-07-03 21:55:24.430617: 
2024-07-03 21:55:24.432981: Epoch 187
2024-07-03 21:55:24.434605: Current learning rate: 0.0083
2024-07-03 21:56:31.896388: Validation loss did not improve from -0.78494. Patience: 3/50
2024-07-03 21:56:31.898092: train_loss -0.7364
2024-07-03 21:56:31.899300: val_loss -0.7795
2024-07-03 21:56:31.900477: Pseudo dice [0.8832]
2024-07-03 21:56:31.901813: Epoch time: 67.47 s
2024-07-03 21:56:31.902909: Yayy! New best EMA pseudo Dice: 0.8829
2024-07-03 21:56:33.479954: 
2024-07-03 21:56:33.481762: Epoch 188
2024-07-03 21:56:33.483037: Current learning rate: 0.00829
2024-07-03 21:57:39.438832: Validation loss did not improve from -0.78494. Patience: 4/50
2024-07-03 21:57:39.440011: train_loss -0.7451
2024-07-03 21:57:39.441150: val_loss -0.7796
2024-07-03 21:57:39.442308: Pseudo dice [0.8879]
2024-07-03 21:57:39.443564: Epoch time: 65.96 s
2024-07-03 21:57:39.444668: Yayy! New best EMA pseudo Dice: 0.8834
2024-07-03 21:57:41.014231: 
2024-07-03 21:57:41.016142: Epoch 189
2024-07-03 21:57:41.017324: Current learning rate: 0.00828
2024-07-03 21:58:47.520177: Validation loss did not improve from -0.78494. Patience: 5/50
2024-07-03 21:58:47.522036: train_loss -0.7479
2024-07-03 21:58:47.523390: val_loss -0.777
2024-07-03 21:58:47.524970: Pseudo dice [0.8839]
2024-07-03 21:58:47.526517: Epoch time: 66.51 s
2024-07-03 21:58:47.880108: Yayy! New best EMA pseudo Dice: 0.8834
2024-07-03 21:58:49.423178: 
2024-07-03 21:58:49.424956: Epoch 190
2024-07-03 21:58:49.426206: Current learning rate: 0.00827
2024-07-03 21:59:55.934066: Validation loss did not improve from -0.78494. Patience: 6/50
2024-07-03 21:59:55.935723: train_loss -0.7562
2024-07-03 21:59:55.937181: val_loss -0.7753
2024-07-03 21:59:55.938324: Pseudo dice [0.8826]
2024-07-03 21:59:55.939492: Epoch time: 66.51 s
2024-07-03 21:59:57.175801: 
2024-07-03 21:59:57.178339: Epoch 191
2024-07-03 21:59:57.179846: Current learning rate: 0.00826
2024-07-03 22:01:03.234191: Validation loss did not improve from -0.78494. Patience: 7/50
2024-07-03 22:01:03.235764: train_loss -0.737
2024-07-03 22:01:03.237072: val_loss -0.7778
2024-07-03 22:01:03.238351: Pseudo dice [0.8845]
2024-07-03 22:01:03.239508: Epoch time: 66.06 s
2024-07-03 22:01:03.240592: Yayy! New best EMA pseudo Dice: 0.8835
2024-07-03 22:01:04.836505: 
2024-07-03 22:01:04.838750: Epoch 192
2024-07-03 22:01:04.840024: Current learning rate: 0.00825
2024-07-03 22:02:11.384517: Validation loss did not improve from -0.78494. Patience: 8/50
2024-07-03 22:02:11.386093: train_loss -0.7485
2024-07-03 22:02:11.387443: val_loss -0.7726
2024-07-03 22:02:11.388520: Pseudo dice [0.8895]
2024-07-03 22:02:11.389731: Epoch time: 66.55 s
2024-07-03 22:02:11.390982: Yayy! New best EMA pseudo Dice: 0.8841
2024-07-03 22:02:13.002482: 
2024-07-03 22:02:13.004734: Epoch 193
2024-07-03 22:02:13.006391: Current learning rate: 0.00824
2024-07-03 22:03:19.522445: Validation loss improved from -0.78494 to -0.78906! Patience: 8/50
2024-07-03 22:03:19.523854: train_loss -0.7613
2024-07-03 22:03:19.525141: val_loss -0.7891
2024-07-03 22:03:19.526263: Pseudo dice [0.8864]
2024-07-03 22:03:19.527328: Epoch time: 66.52 s
2024-07-03 22:03:19.528333: Yayy! New best EMA pseudo Dice: 0.8843
2024-07-03 22:03:21.177483: 
2024-07-03 22:03:21.179585: Epoch 194
2024-07-03 22:03:21.180552: Current learning rate: 0.00824
2024-07-03 22:04:27.343536: Validation loss did not improve from -0.78906. Patience: 1/50
2024-07-03 22:04:27.345036: train_loss -0.7553
2024-07-03 22:04:27.346504: val_loss -0.7744
2024-07-03 22:04:27.347820: Pseudo dice [0.8806]
2024-07-03 22:04:27.349115: Epoch time: 66.17 s
2024-07-03 22:04:28.898714: 
2024-07-03 22:04:28.900666: Epoch 195
2024-07-03 22:04:28.902538: Current learning rate: 0.00823
2024-07-03 22:05:35.420425: Validation loss did not improve from -0.78906. Patience: 2/50
2024-07-03 22:05:35.421802: train_loss -0.7379
2024-07-03 22:05:35.423307: val_loss -0.7635
2024-07-03 22:05:35.424454: Pseudo dice [0.8797]
2024-07-03 22:05:35.425570: Epoch time: 66.52 s
2024-07-03 22:05:36.656050: 
2024-07-03 22:05:36.657498: Epoch 196
2024-07-03 22:05:36.658917: Current learning rate: 0.00822
2024-07-03 22:06:43.222927: Validation loss did not improve from -0.78906. Patience: 3/50
2024-07-03 22:06:43.224266: train_loss -0.7439
2024-07-03 22:06:43.225601: val_loss -0.7632
2024-07-03 22:06:43.226655: Pseudo dice [0.8771]
2024-07-03 22:06:43.227850: Epoch time: 66.57 s
2024-07-03 22:06:44.490137: 
2024-07-03 22:06:44.492025: Epoch 197
2024-07-03 22:06:44.493931: Current learning rate: 0.00821
2024-07-03 22:07:50.773138: Validation loss did not improve from -0.78906. Patience: 4/50
2024-07-03 22:07:50.774652: train_loss -0.747
2024-07-03 22:07:50.776129: val_loss -0.78
2024-07-03 22:07:50.777725: Pseudo dice [0.8887]
2024-07-03 22:07:50.779785: Epoch time: 66.29 s
2024-07-03 22:07:52.050811: 
2024-07-03 22:07:52.053230: Epoch 198
2024-07-03 22:07:52.054710: Current learning rate: 0.0082
2024-07-03 22:08:58.018026: Validation loss did not improve from -0.78906. Patience: 5/50
2024-07-03 22:08:58.019773: train_loss -0.7424
2024-07-03 22:08:58.021018: val_loss -0.7786
2024-07-03 22:08:58.022446: Pseudo dice [0.8905]
2024-07-03 22:08:58.023772: Epoch time: 65.97 s
2024-07-03 22:08:59.700208: 
2024-07-03 22:08:59.702495: Epoch 199
2024-07-03 22:08:59.704086: Current learning rate: 0.00819
2024-07-03 22:10:05.784395: Validation loss did not improve from -0.78906. Patience: 6/50
2024-07-03 22:10:05.785897: train_loss -0.7451
2024-07-03 22:10:05.787588: val_loss -0.7736
2024-07-03 22:10:05.788726: Pseudo dice [0.8847]
2024-07-03 22:10:05.789877: Epoch time: 66.09 s
2024-07-03 22:10:07.373966: 
2024-07-03 22:10:07.376508: Epoch 200
2024-07-03 22:10:07.378096: Current learning rate: 0.00818
2024-07-03 22:11:13.352850: Validation loss did not improve from -0.78906. Patience: 7/50
2024-07-03 22:11:13.354225: train_loss -0.7475
2024-07-03 22:11:13.355461: val_loss -0.7769
2024-07-03 22:11:13.356432: Pseudo dice [0.8869]
2024-07-03 22:11:13.357562: Epoch time: 65.98 s
2024-07-03 22:11:13.358513: Yayy! New best EMA pseudo Dice: 0.8845
2024-07-03 22:11:14.974457: 
2024-07-03 22:11:14.976650: Epoch 201
2024-07-03 22:11:14.978161: Current learning rate: 0.00817
2024-07-03 22:12:21.043822: Validation loss did not improve from -0.78906. Patience: 8/50
2024-07-03 22:12:21.045520: train_loss -0.7529
2024-07-03 22:12:21.047620: val_loss -0.7793
2024-07-03 22:12:21.049348: Pseudo dice [0.8945]
2024-07-03 22:12:21.050937: Epoch time: 66.07 s
2024-07-03 22:12:21.052324: Yayy! New best EMA pseudo Dice: 0.8855
2024-07-03 22:12:22.650609: 
2024-07-03 22:12:22.653683: Epoch 202
2024-07-03 22:12:22.655207: Current learning rate: 0.00816
2024-07-03 22:13:28.705173: Validation loss improved from -0.78906 to -0.79207! Patience: 8/50
2024-07-03 22:13:28.706783: train_loss -0.7553
2024-07-03 22:13:28.708485: val_loss -0.7921
2024-07-03 22:13:28.709749: Pseudo dice [0.8885]
2024-07-03 22:13:28.711005: Epoch time: 66.06 s
2024-07-03 22:13:28.712274: Yayy! New best EMA pseudo Dice: 0.8858
2024-07-03 22:13:30.328281: 
2024-07-03 22:13:30.330648: Epoch 203
2024-07-03 22:13:30.332134: Current learning rate: 0.00815
2024-07-03 22:14:36.262878: Validation loss did not improve from -0.79207. Patience: 1/50
2024-07-03 22:14:36.264512: train_loss -0.7578
2024-07-03 22:14:36.265863: val_loss -0.7855
2024-07-03 22:14:36.267228: Pseudo dice [0.889]
2024-07-03 22:14:36.268617: Epoch time: 65.94 s
2024-07-03 22:14:36.269887: Yayy! New best EMA pseudo Dice: 0.8861
2024-07-03 22:14:37.886273: 
2024-07-03 22:14:37.888095: Epoch 204
2024-07-03 22:14:37.889556: Current learning rate: 0.00814
2024-07-03 22:15:44.123636: Validation loss did not improve from -0.79207. Patience: 2/50
2024-07-03 22:15:44.125013: train_loss -0.7589
2024-07-03 22:15:44.127860: val_loss -0.7778
2024-07-03 22:15:44.129184: Pseudo dice [0.8887]
2024-07-03 22:15:44.130373: Epoch time: 66.24 s
2024-07-03 22:15:44.484313: Yayy! New best EMA pseudo Dice: 0.8864
2024-07-03 22:15:46.075169: 
2024-07-03 22:15:46.077209: Epoch 205
2024-07-03 22:15:46.078407: Current learning rate: 0.00813
2024-07-03 22:16:52.043337: Validation loss did not improve from -0.79207. Patience: 3/50
2024-07-03 22:16:52.044662: train_loss -0.7515
2024-07-03 22:16:52.046352: val_loss -0.7706
2024-07-03 22:16:52.047586: Pseudo dice [0.8849]
2024-07-03 22:16:52.048854: Epoch time: 65.97 s
2024-07-03 22:16:53.215153: 
2024-07-03 22:16:53.217063: Epoch 206
2024-07-03 22:16:53.218755: Current learning rate: 0.00813
2024-07-03 22:17:59.509776: Validation loss did not improve from -0.79207. Patience: 4/50
2024-07-03 22:17:59.511428: train_loss -0.7481
2024-07-03 22:17:59.512715: val_loss -0.7755
2024-07-03 22:17:59.513847: Pseudo dice [0.8893]
2024-07-03 22:17:59.514885: Epoch time: 66.3 s
2024-07-03 22:17:59.515891: Yayy! New best EMA pseudo Dice: 0.8865
2024-07-03 22:18:01.006585: 
2024-07-03 22:18:01.008626: Epoch 207
2024-07-03 22:18:01.010134: Current learning rate: 0.00812
2024-07-03 22:19:07.341194: Validation loss did not improve from -0.79207. Patience: 5/50
2024-07-03 22:19:07.342680: train_loss -0.7534
2024-07-03 22:19:07.343910: val_loss -0.7913
2024-07-03 22:19:07.345292: Pseudo dice [0.8959]
2024-07-03 22:19:07.346555: Epoch time: 66.34 s
2024-07-03 22:19:07.347795: Yayy! New best EMA pseudo Dice: 0.8875
2024-07-03 22:19:08.887645: 
2024-07-03 22:19:08.889225: Epoch 208
2024-07-03 22:19:08.890459: Current learning rate: 0.00811
2024-07-03 22:20:14.987395: Validation loss improved from -0.79207 to -0.79476! Patience: 5/50
2024-07-03 22:20:14.988873: train_loss -0.7581
2024-07-03 22:20:14.990380: val_loss -0.7948
2024-07-03 22:20:14.991528: Pseudo dice [0.8897]
2024-07-03 22:20:14.992818: Epoch time: 66.1 s
2024-07-03 22:20:14.993973: Yayy! New best EMA pseudo Dice: 0.8877
2024-07-03 22:20:16.502985: 
2024-07-03 22:20:16.505392: Epoch 209
2024-07-03 22:20:16.506715: Current learning rate: 0.0081
2024-07-03 22:21:22.918489: Validation loss did not improve from -0.79476. Patience: 1/50
2024-07-03 22:21:22.920209: train_loss -0.7574
2024-07-03 22:21:22.921970: val_loss -0.7879
2024-07-03 22:21:22.923275: Pseudo dice [0.8939]
2024-07-03 22:21:22.924292: Epoch time: 66.42 s
2024-07-03 22:21:23.646900: Yayy! New best EMA pseudo Dice: 0.8883
2024-07-03 22:21:25.147468: 
2024-07-03 22:21:25.150275: Epoch 210
2024-07-03 22:21:25.151973: Current learning rate: 0.00809
2024-07-03 22:22:32.045688: Validation loss did not improve from -0.79476. Patience: 2/50
2024-07-03 22:22:32.047889: train_loss -0.7603
2024-07-03 22:22:32.049537: val_loss -0.7909
2024-07-03 22:22:32.050620: Pseudo dice [0.8943]
2024-07-03 22:22:32.052148: Epoch time: 66.9 s
2024-07-03 22:22:32.053454: Yayy! New best EMA pseudo Dice: 0.8889
2024-07-03 22:22:33.586261: 
2024-07-03 22:22:33.588135: Epoch 211
2024-07-03 22:22:33.589450: Current learning rate: 0.00808
2024-07-03 22:23:39.772989: Validation loss did not improve from -0.79476. Patience: 3/50
2024-07-03 22:23:39.774366: train_loss -0.7649
2024-07-03 22:23:39.775848: val_loss -0.7838
2024-07-03 22:23:39.777209: Pseudo dice [0.887]
2024-07-03 22:23:39.778358: Epoch time: 66.19 s
2024-07-03 22:23:40.967449: 
2024-07-03 22:23:40.969430: Epoch 212
2024-07-03 22:23:40.970527: Current learning rate: 0.00807
2024-07-03 22:24:47.252017: Validation loss did not improve from -0.79476. Patience: 4/50
2024-07-03 22:24:47.253680: train_loss -0.7575
2024-07-03 22:24:47.255531: val_loss -0.7874
2024-07-03 22:24:47.256862: Pseudo dice [0.8919]
2024-07-03 22:24:47.257955: Epoch time: 66.29 s
2024-07-03 22:24:47.259069: Yayy! New best EMA pseudo Dice: 0.889
2024-07-03 22:24:48.856507: 
2024-07-03 22:24:48.858583: Epoch 213
2024-07-03 22:24:48.860130: Current learning rate: 0.00806
2024-07-03 22:25:55.057627: Validation loss did not improve from -0.79476. Patience: 5/50
2024-07-03 22:25:55.059129: train_loss -0.7588
2024-07-03 22:25:55.060802: val_loss -0.7856
2024-07-03 22:25:55.062163: Pseudo dice [0.8865]
2024-07-03 22:25:55.063704: Epoch time: 66.2 s
2024-07-03 22:25:56.277323: 
2024-07-03 22:25:56.280095: Epoch 214
2024-07-03 22:25:56.281971: Current learning rate: 0.00805
2024-07-03 22:27:02.596417: Validation loss did not improve from -0.79476. Patience: 6/50
2024-07-03 22:27:02.598186: train_loss -0.762
2024-07-03 22:27:02.599691: val_loss -0.7871
2024-07-03 22:27:02.600858: Pseudo dice [0.8951]
2024-07-03 22:27:02.601888: Epoch time: 66.32 s
2024-07-03 22:27:02.961595: Yayy! New best EMA pseudo Dice: 0.8894
2024-07-03 22:27:04.947861: 
2024-07-03 22:27:04.950089: Epoch 215
2024-07-03 22:27:04.951083: Current learning rate: 0.00804
2024-07-03 22:28:11.649777: Validation loss did not improve from -0.79476. Patience: 7/50
2024-07-03 22:28:11.651109: train_loss -0.7659
2024-07-03 22:28:11.652518: val_loss -0.7939
2024-07-03 22:28:11.653867: Pseudo dice [0.8927]
2024-07-03 22:28:11.655213: Epoch time: 66.7 s
2024-07-03 22:28:11.656453: Yayy! New best EMA pseudo Dice: 0.8897
2024-07-03 22:28:13.214497: 
2024-07-03 22:28:13.216000: Epoch 216
2024-07-03 22:28:13.217252: Current learning rate: 0.00803
2024-07-03 22:29:19.664266: Validation loss did not improve from -0.79476. Patience: 8/50
2024-07-03 22:29:19.674580: train_loss -0.77
2024-07-03 22:29:19.677119: val_loss -0.784
2024-07-03 22:29:19.678409: Pseudo dice [0.8953]
2024-07-03 22:29:19.679992: Epoch time: 66.45 s
2024-07-03 22:29:19.681153: Yayy! New best EMA pseudo Dice: 0.8903
2024-07-03 22:29:21.334058: 
2024-07-03 22:29:21.335840: Epoch 217
2024-07-03 22:29:21.336969: Current learning rate: 0.00802
2024-07-03 22:30:27.495058: Validation loss did not improve from -0.79476. Patience: 9/50
2024-07-03 22:30:27.496451: train_loss -0.7569
2024-07-03 22:30:27.497623: val_loss -0.7804
2024-07-03 22:30:27.498681: Pseudo dice [0.8807]
2024-07-03 22:30:27.499897: Epoch time: 66.16 s
2024-07-03 22:30:28.697550: 
2024-07-03 22:30:28.699147: Epoch 218
2024-07-03 22:30:28.700621: Current learning rate: 0.00801
2024-07-03 22:31:35.080511: Validation loss did not improve from -0.79476. Patience: 10/50
2024-07-03 22:31:35.081850: train_loss -0.765
2024-07-03 22:31:35.083467: val_loss -0.7929
2024-07-03 22:31:35.084544: Pseudo dice [0.8932]
2024-07-03 22:31:35.085575: Epoch time: 66.39 s
2024-07-03 22:31:36.273325: 
2024-07-03 22:31:36.275384: Epoch 219
2024-07-03 22:31:36.277117: Current learning rate: 0.00801
2024-07-03 22:32:42.540895: Validation loss improved from -0.79476 to -0.79533! Patience: 10/50
2024-07-03 22:32:42.542319: train_loss -0.7592
2024-07-03 22:32:42.543829: val_loss -0.7953
2024-07-03 22:32:42.545090: Pseudo dice [0.8916]
2024-07-03 22:32:42.546276: Epoch time: 66.27 s
2024-07-03 22:32:44.079385: 
2024-07-03 22:32:44.081237: Epoch 220
2024-07-03 22:32:44.082826: Current learning rate: 0.008
2024-07-03 22:33:50.263464: Validation loss did not improve from -0.79533. Patience: 1/50
2024-07-03 22:33:50.264773: train_loss -0.7558
2024-07-03 22:33:50.265881: val_loss -0.793
2024-07-03 22:33:50.266912: Pseudo dice [0.8966]
2024-07-03 22:33:50.267975: Epoch time: 66.19 s
2024-07-03 22:33:50.268873: Yayy! New best EMA pseudo Dice: 0.8906
2024-07-03 22:33:52.399627: 
2024-07-03 22:33:52.401722: Epoch 221
2024-07-03 22:33:52.403522: Current learning rate: 0.00799
2024-07-03 22:34:59.031025: Validation loss did not improve from -0.79533. Patience: 2/50
2024-07-03 22:34:59.032381: train_loss -0.7668
2024-07-03 22:34:59.033875: val_loss -0.7912
2024-07-03 22:34:59.035098: Pseudo dice [0.8903]
2024-07-03 22:34:59.036312: Epoch time: 66.63 s
2024-07-03 22:35:00.273554: 
2024-07-03 22:35:00.275759: Epoch 222
2024-07-03 22:35:00.277421: Current learning rate: 0.00798
2024-07-03 22:36:06.479841: Validation loss improved from -0.79533 to -0.80054! Patience: 2/50
2024-07-03 22:36:06.481240: train_loss -0.7604
2024-07-03 22:36:06.482645: val_loss -0.8005
2024-07-03 22:36:06.486138: Pseudo dice [0.8949]
2024-07-03 22:36:06.487720: Epoch time: 66.21 s
2024-07-03 22:36:06.489002: Yayy! New best EMA pseudo Dice: 0.891
2024-07-03 22:36:08.023301: 
2024-07-03 22:36:08.025403: Epoch 223
2024-07-03 22:36:08.026698: Current learning rate: 0.00797
2024-07-03 22:37:14.171250: Validation loss did not improve from -0.80054. Patience: 1/50
2024-07-03 22:37:14.172785: train_loss -0.7598
2024-07-03 22:37:14.173975: val_loss -0.7793
2024-07-03 22:37:14.175003: Pseudo dice [0.8904]
2024-07-03 22:37:14.176229: Epoch time: 66.15 s
2024-07-03 22:37:15.333277: 
2024-07-03 22:37:15.335311: Epoch 224
2024-07-03 22:37:15.337166: Current learning rate: 0.00796
2024-07-03 22:38:22.002918: Validation loss did not improve from -0.80054. Patience: 2/50
2024-07-03 22:38:22.004637: train_loss -0.7571
2024-07-03 22:38:22.006891: val_loss -0.7895
2024-07-03 22:38:22.008293: Pseudo dice [0.8941]
2024-07-03 22:38:22.009419: Epoch time: 66.67 s
2024-07-03 22:38:22.372046: Yayy! New best EMA pseudo Dice: 0.8912
2024-07-03 22:38:23.900841: 
2024-07-03 22:38:23.903254: Epoch 225
2024-07-03 22:38:23.904633: Current learning rate: 0.00795
2024-07-03 22:39:30.197151: Validation loss did not improve from -0.80054. Patience: 3/50
2024-07-03 22:39:30.198563: train_loss -0.7693
2024-07-03 22:39:30.200078: val_loss -0.7899
2024-07-03 22:39:30.201386: Pseudo dice [0.8937]
2024-07-03 22:39:30.202682: Epoch time: 66.3 s
2024-07-03 22:39:30.204007: Yayy! New best EMA pseudo Dice: 0.8915
2024-07-03 22:39:31.672047: 
2024-07-03 22:39:31.674159: Epoch 226
2024-07-03 22:39:31.675576: Current learning rate: 0.00794
2024-07-03 22:40:37.849087: Validation loss did not improve from -0.80054. Patience: 4/50
2024-07-03 22:40:37.850703: train_loss -0.7571
2024-07-03 22:40:37.851996: val_loss -0.7701
2024-07-03 22:40:37.852975: Pseudo dice [0.8812]
2024-07-03 22:40:37.854007: Epoch time: 66.18 s
2024-07-03 22:40:39.025193: 
2024-07-03 22:40:39.027521: Epoch 227
2024-07-03 22:40:39.028678: Current learning rate: 0.00793
2024-07-03 22:41:45.597309: Validation loss did not improve from -0.80054. Patience: 5/50
2024-07-03 22:41:45.598814: train_loss -0.7529
2024-07-03 22:41:45.600086: val_loss -0.7832
2024-07-03 22:41:45.601114: Pseudo dice [0.8913]
2024-07-03 22:41:45.602245: Epoch time: 66.57 s
2024-07-03 22:41:47.016563: 
2024-07-03 22:41:47.018488: Epoch 228
2024-07-03 22:41:47.019552: Current learning rate: 0.00792
2024-07-03 22:42:54.187010: Validation loss did not improve from -0.80054. Patience: 6/50
2024-07-03 22:42:54.200431: train_loss -0.7672
2024-07-03 22:42:54.202138: val_loss -0.7911
2024-07-03 22:42:54.203414: Pseudo dice [0.8861]
2024-07-03 22:42:54.204747: Epoch time: 67.18 s
2024-07-03 22:42:55.502483: 
2024-07-03 22:42:55.504486: Epoch 229
2024-07-03 22:42:55.506184: Current learning rate: 0.00791
2024-07-03 22:44:02.163553: Validation loss did not improve from -0.80054. Patience: 7/50
2024-07-03 22:44:02.186021: train_loss -0.7708
2024-07-03 22:44:02.187537: val_loss -0.784
2024-07-03 22:44:02.188702: Pseudo dice [0.891]
2024-07-03 22:44:02.189933: Epoch time: 66.66 s
2024-07-03 22:44:03.922305: 
2024-07-03 22:44:03.924300: Epoch 230
2024-07-03 22:44:03.925724: Current learning rate: 0.0079
2024-07-03 22:45:11.653037: Validation loss did not improve from -0.80054. Patience: 8/50
2024-07-03 22:45:11.656096: train_loss -0.7712
2024-07-03 22:45:11.657740: val_loss -0.7893
2024-07-03 22:45:11.658962: Pseudo dice [0.8902]
2024-07-03 22:45:11.660406: Epoch time: 67.73 s
2024-07-03 22:45:12.854660: 
2024-07-03 22:45:12.857093: Epoch 231
2024-07-03 22:45:12.858354: Current learning rate: 0.00789
2024-07-03 22:46:19.816851: Validation loss did not improve from -0.80054. Patience: 9/50
2024-07-03 22:46:19.819333: train_loss -0.7716
2024-07-03 22:46:19.820539: val_loss -0.797
2024-07-03 22:46:19.821559: Pseudo dice [0.8908]
2024-07-03 22:46:19.822769: Epoch time: 66.96 s
2024-07-03 22:46:21.476170: 
2024-07-03 22:46:21.520502: Epoch 232
2024-07-03 22:46:21.521730: Current learning rate: 0.00789
2024-07-03 22:47:27.697375: Validation loss did not improve from -0.80054. Patience: 10/50
2024-07-03 22:47:27.699360: train_loss -0.7596
2024-07-03 22:47:27.701358: val_loss -0.7815
2024-07-03 22:47:27.702397: Pseudo dice [0.8851]
2024-07-03 22:47:27.703372: Epoch time: 66.22 s
2024-07-03 22:47:30.566669: 
2024-07-03 22:47:30.569385: Epoch 233
2024-07-03 22:47:30.570793: Current learning rate: 0.00788
2024-07-03 22:48:36.845060: Validation loss did not improve from -0.80054. Patience: 11/50
2024-07-03 22:48:36.846427: train_loss -0.7343
2024-07-03 22:48:36.847894: val_loss -0.7738
2024-07-03 22:48:36.848924: Pseudo dice [0.8839]
2024-07-03 22:48:36.850039: Epoch time: 66.28 s
2024-07-03 22:48:38.024385: 
2024-07-03 22:48:38.026576: Epoch 234
2024-07-03 22:48:38.027544: Current learning rate: 0.00787
2024-07-03 22:49:44.187323: Validation loss did not improve from -0.80054. Patience: 12/50
2024-07-03 22:49:44.188623: train_loss -0.7276
2024-07-03 22:49:44.190364: val_loss -0.7571
2024-07-03 22:49:44.192282: Pseudo dice [0.878]
2024-07-03 22:49:44.194301: Epoch time: 66.17 s
2024-07-03 22:49:45.834219: 
2024-07-03 22:49:45.836186: Epoch 235
2024-07-03 22:49:45.837616: Current learning rate: 0.00786
2024-07-03 22:50:52.411738: Validation loss did not improve from -0.80054. Patience: 13/50
2024-07-03 22:50:52.413207: train_loss -0.7526
2024-07-03 22:50:52.414683: val_loss -0.773
2024-07-03 22:50:52.415755: Pseudo dice [0.8826]
2024-07-03 22:50:52.417103: Epoch time: 66.58 s
2024-07-03 22:50:53.592646: 
2024-07-03 22:50:53.594511: Epoch 236
2024-07-03 22:50:53.595576: Current learning rate: 0.00785
2024-07-03 22:51:59.537914: Validation loss did not improve from -0.80054. Patience: 14/50
2024-07-03 22:51:59.539593: train_loss -0.7426
2024-07-03 22:51:59.541025: val_loss -0.7617
2024-07-03 22:51:59.542522: Pseudo dice [0.8784]
2024-07-03 22:51:59.543898: Epoch time: 65.95 s
2024-07-03 22:52:00.725725: 
2024-07-03 22:52:00.728179: Epoch 237
2024-07-03 22:52:00.729656: Current learning rate: 0.00784
2024-07-03 22:53:06.866774: Validation loss did not improve from -0.80054. Patience: 15/50
2024-07-03 22:53:06.868348: train_loss -0.7429
2024-07-03 22:53:06.869890: val_loss -0.7695
2024-07-03 22:53:06.870885: Pseudo dice [0.8832]
2024-07-03 22:53:06.871899: Epoch time: 66.14 s
2024-07-03 22:53:08.027992: 
2024-07-03 22:53:08.030116: Epoch 238
2024-07-03 22:53:08.031300: Current learning rate: 0.00783
2024-07-03 22:54:14.090087: Validation loss did not improve from -0.80054. Patience: 16/50
2024-07-03 22:54:14.091768: train_loss -0.751
2024-07-03 22:54:14.093529: val_loss -0.7749
2024-07-03 22:54:14.094900: Pseudo dice [0.885]
2024-07-03 22:54:14.096377: Epoch time: 66.06 s
2024-07-03 22:54:15.269495: 
2024-07-03 22:54:15.271932: Epoch 239
2024-07-03 22:54:15.273780: Current learning rate: 0.00782
2024-07-03 22:55:21.497088: Validation loss did not improve from -0.80054. Patience: 17/50
2024-07-03 22:55:21.498502: train_loss -0.7549
2024-07-03 22:55:21.499860: val_loss -0.7898
2024-07-03 22:55:21.501000: Pseudo dice [0.8951]
2024-07-03 22:55:21.502448: Epoch time: 66.23 s
2024-07-03 22:55:23.015974: 
2024-07-03 22:55:23.018600: Epoch 240
2024-07-03 22:55:23.020372: Current learning rate: 0.00781
2024-07-03 22:56:29.038865: Validation loss did not improve from -0.80054. Patience: 18/50
2024-07-03 22:56:29.040212: train_loss -0.7621
2024-07-03 22:56:29.041725: val_loss -0.7809
2024-07-03 22:56:29.043177: Pseudo dice [0.8916]
2024-07-03 22:56:29.044686: Epoch time: 66.03 s
2024-07-03 22:56:30.217750: 
2024-07-03 22:56:30.220309: Epoch 241
2024-07-03 22:56:30.221791: Current learning rate: 0.0078
2024-07-03 22:57:35.995070: Validation loss did not improve from -0.80054. Patience: 19/50
2024-07-03 22:57:35.997407: train_loss -0.7562
2024-07-03 22:57:35.999174: val_loss -0.7813
2024-07-03 22:57:36.000733: Pseudo dice [0.8916]
2024-07-03 22:57:36.002451: Epoch time: 65.78 s
2024-07-03 22:57:37.175797: 
2024-07-03 22:57:37.178073: Epoch 242
2024-07-03 22:57:37.180084: Current learning rate: 0.00779
2024-07-03 22:58:43.296764: Validation loss did not improve from -0.80054. Patience: 20/50
2024-07-03 22:58:43.297957: train_loss -0.7522
2024-07-03 22:58:43.299419: val_loss -0.7765
2024-07-03 22:58:43.300912: Pseudo dice [0.8897]
2024-07-03 22:58:43.302261: Epoch time: 66.12 s
2024-07-03 22:58:44.481101: 
2024-07-03 22:58:44.482593: Epoch 243
2024-07-03 22:58:44.530438: Current learning rate: 0.00778
2024-07-03 22:59:50.820601: Validation loss did not improve from -0.80054. Patience: 21/50
2024-07-03 22:59:50.821896: train_loss -0.7695
2024-07-03 22:59:50.823247: val_loss -0.7906
2024-07-03 22:59:50.824506: Pseudo dice [0.8923]
2024-07-03 22:59:50.825710: Epoch time: 66.34 s
2024-07-03 22:59:52.018986: 
2024-07-03 22:59:52.021196: Epoch 244
2024-07-03 22:59:52.022867: Current learning rate: 0.00777
2024-07-03 23:00:58.605273: Validation loss did not improve from -0.80054. Patience: 22/50
2024-07-03 23:00:58.606555: train_loss -0.7554
2024-07-03 23:00:58.607963: val_loss -0.7748
2024-07-03 23:00:58.609478: Pseudo dice [0.8868]
2024-07-03 23:00:58.610615: Epoch time: 66.59 s
2024-07-03 23:01:00.142131: 
2024-07-03 23:01:00.144206: Epoch 245
2024-07-03 23:01:00.145635: Current learning rate: 0.00777
2024-07-03 23:02:06.472198: Validation loss did not improve from -0.80054. Patience: 23/50
2024-07-03 23:02:06.473662: train_loss -0.757
2024-07-03 23:02:06.475097: val_loss -0.7862
2024-07-03 23:02:06.476226: Pseudo dice [0.8921]
2024-07-03 23:02:06.477338: Epoch time: 66.33 s
2024-07-03 23:02:08.495376: 
2024-07-03 23:02:08.497872: Epoch 246
2024-07-03 23:02:08.499282: Current learning rate: 0.00776
2024-07-03 23:03:14.846632: Validation loss did not improve from -0.80054. Patience: 24/50
2024-07-03 23:03:14.847939: train_loss -0.765
2024-07-03 23:03:14.849212: val_loss -0.796
2024-07-03 23:03:14.850400: Pseudo dice [0.8922]
2024-07-03 23:03:14.851717: Epoch time: 66.35 s
2024-07-03 23:03:16.040978: 
2024-07-03 23:03:16.043433: Epoch 247
2024-07-03 23:03:16.045005: Current learning rate: 0.00775
2024-07-03 23:04:22.443767: Validation loss did not improve from -0.80054. Patience: 25/50
2024-07-03 23:04:22.444982: train_loss -0.7624
2024-07-03 23:04:22.446659: val_loss -0.7992
2024-07-03 23:04:22.448088: Pseudo dice [0.8906]
2024-07-03 23:04:22.449534: Epoch time: 66.41 s
2024-07-03 23:04:23.644898: 
2024-07-03 23:04:23.647957: Epoch 248
2024-07-03 23:04:23.649528: Current learning rate: 0.00774
2024-07-03 23:05:29.699213: Validation loss did not improve from -0.80054. Patience: 26/50
2024-07-03 23:05:29.700666: train_loss -0.7618
2024-07-03 23:05:29.702142: val_loss -0.7931
2024-07-03 23:05:29.703388: Pseudo dice [0.8958]
2024-07-03 23:05:29.704727: Epoch time: 66.06 s
2024-07-03 23:05:30.905847: 
2024-07-03 23:05:30.908058: Epoch 249
2024-07-03 23:05:30.909417: Current learning rate: 0.00773
2024-07-03 23:06:36.820790: Validation loss did not improve from -0.80054. Patience: 27/50
2024-07-03 23:06:36.822414: train_loss -0.7701
2024-07-03 23:06:36.824174: val_loss -0.794
2024-07-03 23:06:36.826136: Pseudo dice [0.8956]
2024-07-03 23:06:36.827189: Epoch time: 65.92 s
2024-07-03 23:06:38.469238: 
2024-07-03 23:06:38.472981: Epoch 250
2024-07-03 23:06:38.475268: Current learning rate: 0.00772
2024-07-03 23:07:44.952074: Validation loss improved from -0.80054 to -0.80207! Patience: 27/50
2024-07-03 23:07:44.953553: train_loss -0.7674
2024-07-03 23:07:44.955486: val_loss -0.8021
2024-07-03 23:07:44.956964: Pseudo dice [0.896]
2024-07-03 23:07:44.958127: Epoch time: 66.49 s
2024-07-03 23:07:46.133881: 
2024-07-03 23:07:46.135916: Epoch 251
2024-07-03 23:07:46.137571: Current learning rate: 0.00771
2024-07-03 23:08:52.156191: Validation loss did not improve from -0.80207. Patience: 1/50
2024-07-03 23:08:52.157600: train_loss -0.7671
2024-07-03 23:08:52.159122: val_loss -0.7871
2024-07-03 23:08:52.160274: Pseudo dice [0.893]
2024-07-03 23:08:52.161493: Epoch time: 66.02 s
2024-07-03 23:08:53.352012: 
2024-07-03 23:08:53.354395: Epoch 252
2024-07-03 23:08:53.355619: Current learning rate: 0.0077
2024-07-03 23:09:59.411631: Validation loss did not improve from -0.80207. Patience: 2/50
2024-07-03 23:09:59.413373: train_loss -0.7648
2024-07-03 23:09:59.414858: val_loss -0.7949
2024-07-03 23:09:59.416676: Pseudo dice [0.8931]
2024-07-03 23:09:59.418874: Epoch time: 66.06 s
2024-07-03 23:10:00.588246: 
2024-07-03 23:10:00.591140: Epoch 253
2024-07-03 23:10:00.592993: Current learning rate: 0.00769
2024-07-03 23:11:06.717196: Validation loss did not improve from -0.80207. Patience: 3/50
2024-07-03 23:11:06.718795: train_loss -0.7627
2024-07-03 23:11:06.720473: val_loss -0.7891
2024-07-03 23:11:06.721869: Pseudo dice [0.8857]
2024-07-03 23:11:06.722794: Epoch time: 66.13 s
2024-07-03 23:11:07.894000: 
2024-07-03 23:11:07.895939: Epoch 254
2024-07-03 23:11:07.897152: Current learning rate: 0.00768
2024-07-03 23:12:14.074677: Validation loss did not improve from -0.80207. Patience: 4/50
2024-07-03 23:12:14.075993: train_loss -0.7754
2024-07-03 23:12:14.077957: val_loss -0.7895
2024-07-03 23:12:14.079193: Pseudo dice [0.896]
2024-07-03 23:12:14.080243: Epoch time: 66.18 s
2024-07-03 23:12:15.559807: 
2024-07-03 23:12:15.562031: Epoch 255
2024-07-03 23:12:15.563884: Current learning rate: 0.00767
2024-07-03 23:13:22.235667: Validation loss did not improve from -0.80207. Patience: 5/50
2024-07-03 23:13:22.237534: train_loss -0.7776
2024-07-03 23:13:22.239167: val_loss -0.8016
2024-07-03 23:13:22.240263: Pseudo dice [0.899]
2024-07-03 23:13:22.241443: Epoch time: 66.68 s
2024-07-03 23:13:22.242529: Yayy! New best EMA pseudo Dice: 0.8921
2024-07-03 23:13:23.736961: 
2024-07-03 23:13:23.739423: Epoch 256
2024-07-03 23:13:23.740963: Current learning rate: 0.00766
2024-07-03 23:14:29.816375: Validation loss did not improve from -0.80207. Patience: 6/50
2024-07-03 23:14:29.818033: train_loss -0.7705
2024-07-03 23:14:29.819451: val_loss -0.7846
2024-07-03 23:14:29.820597: Pseudo dice [0.8893]
2024-07-03 23:14:29.821760: Epoch time: 66.08 s
2024-07-03 23:14:31.029749: 
2024-07-03 23:14:31.032469: Epoch 257
2024-07-03 23:14:31.034168: Current learning rate: 0.00765
2024-07-03 23:15:37.512381: Validation loss did not improve from -0.80207. Patience: 7/50
2024-07-03 23:15:37.513971: train_loss -0.7705
2024-07-03 23:15:37.515321: val_loss -0.7969
2024-07-03 23:15:37.516432: Pseudo dice [0.8956]
2024-07-03 23:15:37.517768: Epoch time: 66.49 s
2024-07-03 23:15:37.518858: Yayy! New best EMA pseudo Dice: 0.8922
2024-07-03 23:15:39.012154: 
2024-07-03 23:15:39.014228: Epoch 258
2024-07-03 23:15:39.015652: Current learning rate: 0.00764
2024-07-03 23:16:45.669542: Validation loss did not improve from -0.80207. Patience: 8/50
2024-07-03 23:16:45.671618: train_loss -0.7741
2024-07-03 23:16:45.673484: val_loss -0.8013
2024-07-03 23:16:45.674814: Pseudo dice [0.8926]
2024-07-03 23:16:45.676265: Epoch time: 66.66 s
2024-07-03 23:16:45.677378: Yayy! New best EMA pseudo Dice: 0.8922
2024-07-03 23:16:47.189398: 
2024-07-03 23:16:47.191315: Epoch 259
2024-07-03 23:16:47.193136: Current learning rate: 0.00764
2024-07-03 23:17:53.422880: Validation loss did not improve from -0.80207. Patience: 9/50
2024-07-03 23:17:53.424165: train_loss -0.7651
2024-07-03 23:17:53.425423: val_loss -0.7976
2024-07-03 23:17:53.426562: Pseudo dice [0.8931]
2024-07-03 23:17:53.427892: Epoch time: 66.24 s
2024-07-03 23:17:53.788315: Yayy! New best EMA pseudo Dice: 0.8923
2024-07-03 23:17:55.333385: 
2024-07-03 23:17:55.336070: Epoch 260
2024-07-03 23:17:55.339544: Current learning rate: 0.00763
2024-07-03 23:19:01.470363: Validation loss did not improve from -0.80207. Patience: 10/50
2024-07-03 23:19:01.471697: train_loss -0.7689
2024-07-03 23:19:01.472930: val_loss -0.7973
2024-07-03 23:19:01.474292: Pseudo dice [0.895]
2024-07-03 23:19:01.475402: Epoch time: 66.14 s
2024-07-03 23:19:01.476507: Yayy! New best EMA pseudo Dice: 0.8926
2024-07-03 23:19:03.096083: 
2024-07-03 23:19:03.098649: Epoch 261
2024-07-03 23:19:03.100127: Current learning rate: 0.00762
2024-07-03 23:20:09.524560: Validation loss did not improve from -0.80207. Patience: 11/50
2024-07-03 23:20:09.525841: train_loss -0.7805
2024-07-03 23:20:09.527105: val_loss -0.7989
2024-07-03 23:20:09.528496: Pseudo dice [0.893]
2024-07-03 23:20:09.529782: Epoch time: 66.43 s
2024-07-03 23:20:09.531103: Yayy! New best EMA pseudo Dice: 0.8926
2024-07-03 23:20:11.094866: 
2024-07-03 23:20:11.097631: Epoch 262
2024-07-03 23:20:11.099286: Current learning rate: 0.00761
2024-07-03 23:21:17.306872: Validation loss did not improve from -0.80207. Patience: 12/50
2024-07-03 23:21:17.308341: train_loss -0.7777
2024-07-03 23:21:17.309729: val_loss -0.7988
2024-07-03 23:21:17.310959: Pseudo dice [0.9001]
2024-07-03 23:21:17.312180: Epoch time: 66.21 s
2024-07-03 23:21:17.313348: Yayy! New best EMA pseudo Dice: 0.8934
2024-07-03 23:21:18.833139: 
2024-07-03 23:21:18.836130: Epoch 263
2024-07-03 23:21:18.837902: Current learning rate: 0.0076
2024-07-03 23:22:24.999617: Validation loss did not improve from -0.80207. Patience: 13/50
2024-07-03 23:22:25.001008: train_loss -0.7742
2024-07-03 23:22:25.002137: val_loss -0.7931
2024-07-03 23:22:25.003150: Pseudo dice [0.8904]
2024-07-03 23:22:25.004101: Epoch time: 66.17 s
2024-07-03 23:22:26.202204: 
2024-07-03 23:22:26.204497: Epoch 264
2024-07-03 23:22:26.206084: Current learning rate: 0.00759
2024-07-03 23:23:32.222744: Validation loss did not improve from -0.80207. Patience: 14/50
2024-07-03 23:23:32.224538: train_loss -0.7691
2024-07-03 23:23:32.226251: val_loss -0.7939
2024-07-03 23:23:32.227865: Pseudo dice [0.8954]
2024-07-03 23:23:32.229184: Epoch time: 66.02 s
2024-07-03 23:23:33.786353: 
2024-07-03 23:23:33.788608: Epoch 265
2024-07-03 23:23:33.790344: Current learning rate: 0.00758
2024-07-03 23:24:39.806304: Validation loss did not improve from -0.80207. Patience: 15/50
2024-07-03 23:24:39.807736: train_loss -0.7717
2024-07-03 23:24:39.809149: val_loss -0.7947
2024-07-03 23:24:39.810740: Pseudo dice [0.8962]
2024-07-03 23:24:39.812095: Epoch time: 66.02 s
2024-07-03 23:24:39.813459: Yayy! New best EMA pseudo Dice: 0.8936
2024-07-03 23:24:41.317396: 
2024-07-03 23:24:41.320206: Epoch 266
2024-07-03 23:24:41.321768: Current learning rate: 0.00757
2024-07-03 23:25:47.408405: Validation loss did not improve from -0.80207. Patience: 16/50
2024-07-03 23:25:47.409773: train_loss -0.7719
2024-07-03 23:25:47.411032: val_loss -0.7998
2024-07-03 23:25:47.411960: Pseudo dice [0.9001]
2024-07-03 23:25:47.413109: Epoch time: 66.09 s
2024-07-03 23:25:47.414128: Yayy! New best EMA pseudo Dice: 0.8942
2024-07-03 23:25:48.908808: 
2024-07-03 23:25:48.911599: Epoch 267
2024-07-03 23:25:48.913516: Current learning rate: 0.00756
2024-07-03 23:26:54.955714: Validation loss did not improve from -0.80207. Patience: 17/50
2024-07-03 23:26:54.957258: train_loss -0.7745
2024-07-03 23:26:54.958465: val_loss -0.7959
2024-07-03 23:26:54.959908: Pseudo dice [0.8956]
2024-07-03 23:26:54.961149: Epoch time: 66.05 s
2024-07-03 23:26:54.962436: Yayy! New best EMA pseudo Dice: 0.8944
2024-07-03 23:26:56.501541: 
2024-07-03 23:26:56.503659: Epoch 268
2024-07-03 23:26:56.505321: Current learning rate: 0.00755
2024-07-03 23:28:03.025496: Validation loss did not improve from -0.80207. Patience: 18/50
2024-07-03 23:28:03.027172: train_loss -0.7608
2024-07-03 23:28:03.028961: val_loss -0.7921
2024-07-03 23:28:03.030206: Pseudo dice [0.8951]
2024-07-03 23:28:03.031531: Epoch time: 66.53 s
2024-07-03 23:28:03.032991: Yayy! New best EMA pseudo Dice: 0.8945
2024-07-03 23:28:05.030700: 
2024-07-03 23:28:05.032861: Epoch 269
2024-07-03 23:28:05.034459: Current learning rate: 0.00754
2024-07-03 23:29:11.228420: Validation loss did not improve from -0.80207. Patience: 19/50
2024-07-03 23:29:11.230016: train_loss -0.7653
2024-07-03 23:29:11.231150: val_loss -0.7925
2024-07-03 23:29:11.232225: Pseudo dice [0.896]
2024-07-03 23:29:11.233528: Epoch time: 66.2 s
2024-07-03 23:29:11.590978: Yayy! New best EMA pseudo Dice: 0.8946
2024-07-03 23:29:13.112823: 
2024-07-03 23:29:13.115006: Epoch 270
2024-07-03 23:29:13.116782: Current learning rate: 0.00753
2024-07-03 23:30:19.488860: Validation loss improved from -0.80207 to -0.80292! Patience: 19/50
2024-07-03 23:30:19.490466: train_loss -0.7756
2024-07-03 23:30:19.492011: val_loss -0.8029
2024-07-03 23:30:19.493229: Pseudo dice [0.8947]
2024-07-03 23:30:19.494703: Epoch time: 66.38 s
2024-07-03 23:30:19.496234: Yayy! New best EMA pseudo Dice: 0.8946
2024-07-03 23:30:21.091312: 
2024-07-03 23:30:21.093639: Epoch 271
2024-07-03 23:30:21.095295: Current learning rate: 0.00752
2024-07-03 23:31:27.469905: Validation loss did not improve from -0.80292. Patience: 1/50
2024-07-03 23:31:27.471226: train_loss -0.7748
2024-07-03 23:31:27.472399: val_loss -0.7994
2024-07-03 23:31:27.473494: Pseudo dice [0.901]
2024-07-03 23:31:27.474784: Epoch time: 66.38 s
2024-07-03 23:31:27.475781: Yayy! New best EMA pseudo Dice: 0.8953
2024-07-03 23:31:29.002199: 
2024-07-03 23:31:29.004693: Epoch 272
2024-07-03 23:31:29.006269: Current learning rate: 0.00751
2024-07-03 23:32:35.697747: Validation loss did not improve from -0.80292. Patience: 2/50
2024-07-03 23:32:35.699121: train_loss -0.772
2024-07-03 23:32:35.700416: val_loss -0.7981
2024-07-03 23:32:35.701567: Pseudo dice [0.9006]
2024-07-03 23:32:35.702725: Epoch time: 66.7 s
2024-07-03 23:32:35.703889: Yayy! New best EMA pseudo Dice: 0.8958
2024-07-03 23:32:37.249580: 
2024-07-03 23:32:37.251355: Epoch 273
2024-07-03 23:32:37.252790: Current learning rate: 0.00751
2024-07-03 23:33:44.622642: Validation loss did not improve from -0.80292. Patience: 3/50
2024-07-03 23:33:44.654142: train_loss -0.7762
2024-07-03 23:33:44.657960: val_loss -0.7973
2024-07-03 23:33:44.659681: Pseudo dice [0.9004]
2024-07-03 23:33:44.661298: Epoch time: 67.41 s
2024-07-03 23:33:44.662456: Yayy! New best EMA pseudo Dice: 0.8962
2024-07-03 23:33:46.241730: 
2024-07-03 23:33:46.243696: Epoch 274
2024-07-03 23:33:46.245145: Current learning rate: 0.0075
2024-07-03 23:34:53.633782: Validation loss did not improve from -0.80292. Patience: 4/50
2024-07-03 23:34:53.635308: train_loss -0.7732
2024-07-03 23:34:53.636376: val_loss -0.7921
2024-07-03 23:34:53.637676: Pseudo dice [0.895]
2024-07-03 23:34:53.638796: Epoch time: 67.39 s
2024-07-03 23:34:55.170363: 
2024-07-03 23:34:55.172318: Epoch 275
2024-07-03 23:34:55.173920: Current learning rate: 0.00749
2024-07-03 23:36:02.251093: Validation loss did not improve from -0.80292. Patience: 5/50
2024-07-03 23:36:02.253407: train_loss -0.7677
2024-07-03 23:36:02.255356: val_loss -0.8011
2024-07-03 23:36:02.256942: Pseudo dice [0.8992]
2024-07-03 23:36:02.258237: Epoch time: 67.08 s
2024-07-03 23:36:02.259183: Yayy! New best EMA pseudo Dice: 0.8964
2024-07-03 23:36:03.792953: 
2024-07-03 23:36:03.794785: Epoch 276
2024-07-03 23:36:03.796082: Current learning rate: 0.00748
2024-07-03 23:37:10.738667: Validation loss improved from -0.80292 to -0.80736! Patience: 5/50
2024-07-03 23:37:10.740127: train_loss -0.7732
2024-07-03 23:37:10.741652: val_loss -0.8074
2024-07-03 23:37:10.742971: Pseudo dice [0.8993]
2024-07-03 23:37:10.744241: Epoch time: 66.95 s
2024-07-03 23:37:10.745652: Yayy! New best EMA pseudo Dice: 0.8967
2024-07-03 23:37:12.309512: 
2024-07-03 23:37:12.311781: Epoch 277
2024-07-03 23:37:12.313007: Current learning rate: 0.00747
2024-07-03 23:38:19.498909: Validation loss did not improve from -0.80736. Patience: 1/50
2024-07-03 23:38:19.500915: train_loss -0.7828
2024-07-03 23:38:19.502901: val_loss -0.7932
2024-07-03 23:38:19.504468: Pseudo dice [0.8974]
2024-07-03 23:38:19.505745: Epoch time: 67.19 s
2024-07-03 23:38:19.507001: Yayy! New best EMA pseudo Dice: 0.8968
2024-07-03 23:38:21.236238: 
2024-07-03 23:38:21.238192: Epoch 278
2024-07-03 23:38:21.239599: Current learning rate: 0.00746
2024-07-03 23:39:28.220807: Validation loss did not improve from -0.80736. Patience: 2/50
2024-07-03 23:39:28.222151: train_loss -0.7778
2024-07-03 23:39:28.223420: val_loss -0.8034
2024-07-03 23:39:28.224688: Pseudo dice [0.8957]
2024-07-03 23:39:28.226017: Epoch time: 66.99 s
2024-07-03 23:39:29.422850: 
2024-07-03 23:39:29.425649: Epoch 279
2024-07-03 23:39:29.427430: Current learning rate: 0.00745
2024-07-03 23:40:36.460376: Validation loss did not improve from -0.80736. Patience: 3/50
2024-07-03 23:40:36.462318: train_loss -0.7216
2024-07-03 23:40:36.463877: val_loss -0.7307
2024-07-03 23:40:36.465638: Pseudo dice [0.8686]
2024-07-03 23:40:36.467331: Epoch time: 67.04 s
2024-07-03 23:40:38.378357: 
2024-07-03 23:40:38.380856: Epoch 280
2024-07-03 23:40:38.382553: Current learning rate: 0.00744
2024-07-03 23:41:45.662779: Validation loss did not improve from -0.80736. Patience: 4/50
2024-07-03 23:41:45.664753: train_loss -0.7105
2024-07-03 23:41:45.666434: val_loss -0.7483
2024-07-03 23:41:45.667703: Pseudo dice [0.8716]
2024-07-03 23:41:45.668994: Epoch time: 67.29 s
2024-07-03 23:41:46.849139: 
2024-07-03 23:41:46.852123: Epoch 281
2024-07-03 23:41:46.853977: Current learning rate: 0.00743
2024-07-03 23:42:53.809169: Validation loss did not improve from -0.80736. Patience: 5/50
2024-07-03 23:42:53.810667: train_loss -0.7356
2024-07-03 23:42:53.812515: val_loss -0.7904
2024-07-03 23:42:53.813987: Pseudo dice [0.889]
2024-07-03 23:42:53.815320: Epoch time: 66.96 s
2024-07-03 23:42:55.010186: 
2024-07-03 23:42:55.012719: Epoch 282
2024-07-03 23:42:55.014676: Current learning rate: 0.00742
2024-07-03 23:44:01.953296: Validation loss did not improve from -0.80736. Patience: 6/50
2024-07-03 23:44:01.955387: train_loss -0.7287
2024-07-03 23:44:01.956911: val_loss -0.7567
2024-07-03 23:44:01.957917: Pseudo dice [0.8758]
2024-07-03 23:44:01.959091: Epoch time: 66.95 s
2024-07-03 23:44:03.195011: 
2024-07-03 23:44:03.196898: Epoch 283
2024-07-03 23:44:03.198590: Current learning rate: 0.00741
2024-07-03 23:45:10.557795: Validation loss did not improve from -0.80736. Patience: 7/50
2024-07-03 23:45:10.560028: train_loss -0.7388
2024-07-03 23:45:10.561241: val_loss -0.7853
2024-07-03 23:45:10.562461: Pseudo dice [0.8852]
2024-07-03 23:45:10.563694: Epoch time: 67.37 s
2024-07-03 23:45:11.767592: 
2024-07-03 23:45:11.769362: Epoch 284
2024-07-03 23:45:11.770696: Current learning rate: 0.0074
2024-07-03 23:46:18.832098: Validation loss did not improve from -0.80736. Patience: 8/50
2024-07-03 23:46:18.833861: train_loss -0.7535
2024-07-03 23:46:18.835621: val_loss -0.787
2024-07-03 23:46:18.837041: Pseudo dice [0.8878]
2024-07-03 23:46:18.838471: Epoch time: 67.07 s
2024-07-03 23:46:20.336174: 
2024-07-03 23:46:20.338768: Epoch 285
2024-07-03 23:46:20.340484: Current learning rate: 0.00739
2024-07-03 23:47:28.720385: Validation loss did not improve from -0.80736. Patience: 9/50
2024-07-03 23:47:28.722201: train_loss -0.7553
2024-07-03 23:47:28.724233: val_loss -0.7855
2024-07-03 23:47:28.725428: Pseudo dice [0.8901]
2024-07-03 23:47:28.726594: Epoch time: 68.39 s
2024-07-03 23:47:30.043071: 
2024-07-03 23:47:30.044889: Epoch 286
2024-07-03 23:47:30.046106: Current learning rate: 0.00738
2024-07-03 23:48:37.754693: Validation loss did not improve from -0.80736. Patience: 10/50
2024-07-03 23:48:37.758640: train_loss -0.7587
2024-07-03 23:48:37.759986: val_loss -0.8006
2024-07-03 23:48:37.761049: Pseudo dice [0.8936]
2024-07-03 23:48:37.762191: Epoch time: 67.72 s
2024-07-03 23:48:38.991871: 
2024-07-03 23:48:38.994044: Epoch 287
2024-07-03 23:48:38.995419: Current learning rate: 0.00738
2024-07-03 23:49:46.222201: Validation loss did not improve from -0.80736. Patience: 11/50
2024-07-03 23:49:46.236308: train_loss -0.7653
2024-07-03 23:49:46.238045: val_loss -0.7953
2024-07-03 23:49:46.239522: Pseudo dice [0.8969]
2024-07-03 23:49:46.240684: Epoch time: 67.23 s
2024-07-03 23:49:47.788524: 
2024-07-03 23:49:47.790481: Epoch 288
2024-07-03 23:49:47.792176: Current learning rate: 0.00737
2024-07-03 23:50:55.470848: Validation loss did not improve from -0.80736. Patience: 12/50
2024-07-03 23:50:55.478677: train_loss -0.7704
2024-07-03 23:50:55.480683: val_loss -0.7941
2024-07-03 23:50:55.482105: Pseudo dice [0.897]
2024-07-03 23:50:55.483268: Epoch time: 67.69 s
2024-07-03 23:50:57.132472: 
2024-07-03 23:50:57.134572: Epoch 289
2024-07-03 23:50:57.136265: Current learning rate: 0.00736
2024-07-03 23:52:04.188949: Validation loss did not improve from -0.80736. Patience: 13/50
2024-07-03 23:52:04.190413: train_loss -0.7702
2024-07-03 23:52:04.191686: val_loss -0.7855
2024-07-03 23:52:04.192971: Pseudo dice [0.8904]
2024-07-03 23:52:04.194291: Epoch time: 67.06 s
2024-07-03 23:52:05.850507: 
2024-07-03 23:52:05.852433: Epoch 290
2024-07-03 23:52:05.854117: Current learning rate: 0.00735
2024-07-03 23:53:13.059992: Validation loss did not improve from -0.80736. Patience: 14/50
2024-07-03 23:53:13.061882: train_loss -0.7617
2024-07-03 23:53:13.064080: val_loss -0.7884
2024-07-03 23:53:13.065930: Pseudo dice [0.8944]
2024-07-03 23:53:13.067381: Epoch time: 67.21 s
2024-07-03 23:53:14.286398: 
2024-07-03 23:53:14.288538: Epoch 291
2024-07-03 23:53:14.290463: Current learning rate: 0.00734
2024-07-03 23:54:21.347225: Validation loss did not improve from -0.80736. Patience: 15/50
2024-07-03 23:54:21.348695: train_loss -0.746
2024-07-03 23:54:21.350343: val_loss -0.7726
2024-07-03 23:54:21.351694: Pseudo dice [0.8804]
2024-07-03 23:54:21.352936: Epoch time: 67.06 s
2024-07-03 23:54:23.798562: 
2024-07-03 23:54:23.801172: Epoch 292
2024-07-03 23:54:23.802929: Current learning rate: 0.00733
2024-07-03 23:55:31.447172: Validation loss did not improve from -0.80736. Patience: 16/50
2024-07-03 23:55:31.448634: train_loss -0.7111
2024-07-03 23:55:31.449921: val_loss -0.7474
2024-07-03 23:55:31.450948: Pseudo dice [0.8769]
2024-07-03 23:55:31.452144: Epoch time: 67.65 s
2024-07-03 23:55:32.676677: 
2024-07-03 23:55:32.678370: Epoch 293
2024-07-03 23:55:32.679420: Current learning rate: 0.00732
2024-07-03 23:56:40.111214: Validation loss did not improve from -0.80736. Patience: 17/50
2024-07-03 23:56:40.113092: train_loss -0.7256
2024-07-03 23:56:40.114403: val_loss -0.7717
2024-07-03 23:56:40.115484: Pseudo dice [0.8849]
2024-07-03 23:56:40.116467: Epoch time: 67.44 s
2024-07-03 23:56:41.335716: 
2024-07-03 23:56:41.337639: Epoch 294
2024-07-03 23:56:41.338644: Current learning rate: 0.00731
2024-07-03 23:57:48.557332: Validation loss did not improve from -0.80736. Patience: 18/50
2024-07-03 23:57:48.558688: train_loss -0.7543
2024-07-03 23:57:48.560326: val_loss -0.79
2024-07-03 23:57:48.561291: Pseudo dice [0.8931]
2024-07-03 23:57:48.562486: Epoch time: 67.22 s
2024-07-03 23:57:50.159105: 
2024-07-03 23:57:50.161236: Epoch 295
2024-07-03 23:57:50.163408: Current learning rate: 0.0073
2024-07-03 23:58:57.504297: Validation loss did not improve from -0.80736. Patience: 19/50
2024-07-03 23:58:57.505635: train_loss -0.7612
2024-07-03 23:58:57.506869: val_loss -0.7884
2024-07-03 23:58:57.507920: Pseudo dice [0.8905]
2024-07-03 23:58:57.509062: Epoch time: 67.35 s
2024-07-03 23:58:58.712269: 
2024-07-03 23:58:58.713973: Epoch 296
2024-07-03 23:58:58.715210: Current learning rate: 0.00729
2024-07-04 00:00:05.798213: Validation loss did not improve from -0.80736. Patience: 20/50
2024-07-04 00:00:05.800005: train_loss -0.755
2024-07-04 00:00:05.801516: val_loss -0.785
2024-07-04 00:00:05.802813: Pseudo dice [0.8906]
2024-07-04 00:00:05.804024: Epoch time: 67.09 s
2024-07-04 00:00:07.035358: 
2024-07-04 00:00:07.037064: Epoch 297
2024-07-04 00:00:07.038431: Current learning rate: 0.00728
2024-07-04 00:01:14.245823: Validation loss did not improve from -0.80736. Patience: 21/50
2024-07-04 00:01:14.247935: train_loss -0.7676
2024-07-04 00:01:14.249570: val_loss -0.806
2024-07-04 00:01:14.250740: Pseudo dice [0.8994]
2024-07-04 00:01:14.252420: Epoch time: 67.21 s
2024-07-04 00:01:15.469319: 
2024-07-04 00:01:15.470891: Epoch 298
2024-07-04 00:01:15.472728: Current learning rate: 0.00727
2024-07-04 00:02:22.885435: Validation loss did not improve from -0.80736. Patience: 22/50
2024-07-04 00:02:22.886969: train_loss -0.7755
2024-07-04 00:02:22.888464: val_loss -0.8035
2024-07-04 00:02:22.890002: Pseudo dice [0.8994]
2024-07-04 00:02:22.891798: Epoch time: 67.42 s
2024-07-04 00:02:24.080954: 
2024-07-04 00:02:24.083419: Epoch 299
2024-07-04 00:02:24.084756: Current learning rate: 0.00726
2024-07-04 00:03:31.329118: Validation loss did not improve from -0.80736. Patience: 23/50
2024-07-04 00:03:31.330387: train_loss -0.773
2024-07-04 00:03:31.331847: val_loss -0.8034
2024-07-04 00:03:31.333243: Pseudo dice [0.901]
2024-07-04 00:03:31.334603: Epoch time: 67.25 s
2024-07-04 00:03:32.892611: 
2024-07-04 00:03:32.895373: Epoch 300
2024-07-04 00:03:32.897058: Current learning rate: 0.00725
2024-07-04 00:04:40.142386: Validation loss did not improve from -0.80736. Patience: 24/50
2024-07-04 00:04:40.144188: train_loss -0.7762
2024-07-04 00:04:40.145749: val_loss -0.7993
2024-07-04 00:04:40.147127: Pseudo dice [0.8972]
2024-07-04 00:04:40.148306: Epoch time: 67.25 s
2024-07-04 00:04:41.358715: 
2024-07-04 00:04:41.360698: Epoch 301
2024-07-04 00:04:41.362067: Current learning rate: 0.00724
2024-07-04 00:05:48.485924: Validation loss did not improve from -0.80736. Patience: 25/50
2024-07-04 00:05:48.487399: train_loss -0.7756
2024-07-04 00:05:48.489085: val_loss -0.7991
2024-07-04 00:05:48.490207: Pseudo dice [0.8985]
2024-07-04 00:05:48.491423: Epoch time: 67.13 s
2024-07-04 00:05:49.689477: 
2024-07-04 00:05:49.691352: Epoch 302
2024-07-04 00:05:49.693225: Current learning rate: 0.00724
2024-07-04 00:06:57.072077: Validation loss did not improve from -0.80736. Patience: 26/50
2024-07-04 00:06:57.073676: train_loss -0.7821
2024-07-04 00:06:57.074979: val_loss -0.801
2024-07-04 00:06:57.076178: Pseudo dice [0.8999]
2024-07-04 00:06:57.077478: Epoch time: 67.39 s
2024-07-04 00:06:58.294100: 
2024-07-04 00:06:58.296147: Epoch 303
2024-07-04 00:06:58.297950: Current learning rate: 0.00723
2024-07-04 00:08:05.752554: Validation loss improved from -0.80736 to -0.80746! Patience: 26/50
2024-07-04 00:08:05.754420: train_loss -0.7814
2024-07-04 00:08:05.756499: val_loss -0.8075
2024-07-04 00:08:05.758870: Pseudo dice [0.901]
2024-07-04 00:08:05.760160: Epoch time: 67.46 s
2024-07-04 00:08:07.609346: 
2024-07-04 00:08:07.611204: Epoch 304
2024-07-04 00:08:07.612503: Current learning rate: 0.00722
2024-07-04 00:09:14.919806: Validation loss improved from -0.80746 to -0.81234! Patience: 0/50
2024-07-04 00:09:14.921233: train_loss -0.7797
2024-07-04 00:09:14.922740: val_loss -0.8123
2024-07-04 00:09:14.924358: Pseudo dice [0.9061]
2024-07-04 00:09:14.926178: Epoch time: 67.31 s
2024-07-04 00:09:16.504709: 
2024-07-04 00:09:16.506332: Epoch 305
2024-07-04 00:09:16.507440: Current learning rate: 0.00721
2024-07-04 00:10:23.879523: Validation loss did not improve from -0.81234. Patience: 1/50
2024-07-04 00:10:23.881537: train_loss -0.777
2024-07-04 00:10:23.883489: val_loss -0.7933
2024-07-04 00:10:23.885127: Pseudo dice [0.8946]
2024-07-04 00:10:23.886431: Epoch time: 67.38 s
2024-07-04 00:10:25.441267: 
2024-07-04 00:10:25.443750: Epoch 306
2024-07-04 00:10:25.444969: Current learning rate: 0.0072
2024-07-04 00:11:32.530910: Validation loss did not improve from -0.81234. Patience: 2/50
2024-07-04 00:11:32.532799: train_loss -0.7772
2024-07-04 00:11:32.534528: val_loss -0.796
2024-07-04 00:11:32.536052: Pseudo dice [0.8931]
2024-07-04 00:11:32.537448: Epoch time: 67.09 s
2024-07-04 00:11:33.807805: 
2024-07-04 00:11:33.809883: Epoch 307
2024-07-04 00:11:33.811698: Current learning rate: 0.00719
2024-07-04 00:12:41.045425: Validation loss did not improve from -0.81234. Patience: 3/50
2024-07-04 00:12:41.046675: train_loss -0.7747
2024-07-04 00:12:41.047817: val_loss -0.7997
2024-07-04 00:12:41.048816: Pseudo dice [0.9006]
2024-07-04 00:12:41.050143: Epoch time: 67.24 s
2024-07-04 00:12:42.264364: 
2024-07-04 00:12:42.266318: Epoch 308
2024-07-04 00:12:42.267657: Current learning rate: 0.00718
2024-07-04 00:13:49.692227: Validation loss improved from -0.81234 to -0.81326! Patience: 3/50
2024-07-04 00:13:49.693665: train_loss -0.7783
2024-07-04 00:13:49.695093: val_loss -0.8133
2024-07-04 00:13:49.696470: Pseudo dice [0.9006]
2024-07-04 00:13:49.697828: Epoch time: 67.43 s
2024-07-04 00:13:50.919883: 
2024-07-04 00:13:50.921619: Epoch 309
2024-07-04 00:13:50.923142: Current learning rate: 0.00717
2024-07-04 00:14:58.468590: Validation loss improved from -0.81326 to -0.81344! Patience: 0/50
2024-07-04 00:14:58.469926: train_loss -0.7894
2024-07-04 00:14:58.471252: val_loss -0.8134
2024-07-04 00:14:58.472619: Pseudo dice [0.9073]
2024-07-04 00:14:58.474001: Epoch time: 67.55 s
2024-07-04 00:14:58.837409: Yayy! New best EMA pseudo Dice: 0.8975
2024-07-04 00:15:00.354807: 
2024-07-04 00:15:00.356730: Epoch 310
2024-07-04 00:15:00.358288: Current learning rate: 0.00716
2024-07-04 00:16:07.809097: Validation loss did not improve from -0.81344. Patience: 1/50
2024-07-04 00:16:07.810445: train_loss -0.7761
2024-07-04 00:16:07.811961: val_loss -0.7984
2024-07-04 00:16:07.813298: Pseudo dice [0.9019]
2024-07-04 00:16:07.814485: Epoch time: 67.46 s
2024-07-04 00:16:07.815486: Yayy! New best EMA pseudo Dice: 0.8979
2024-07-04 00:16:09.378068: 
2024-07-04 00:16:09.380280: Epoch 311
2024-07-04 00:16:09.381681: Current learning rate: 0.00715
2024-07-04 00:17:16.730207: Validation loss did not improve from -0.81344. Patience: 2/50
2024-07-04 00:17:16.732515: train_loss -0.783
2024-07-04 00:17:16.734859: val_loss -0.8049
2024-07-04 00:17:16.736375: Pseudo dice [0.8998]
2024-07-04 00:17:16.737493: Epoch time: 67.36 s
2024-07-04 00:17:16.738426: Yayy! New best EMA pseudo Dice: 0.8981
2024-07-04 00:17:18.286437: 
2024-07-04 00:17:18.288391: Epoch 312
2024-07-04 00:17:18.289550: Current learning rate: 0.00714
2024-07-04 00:18:25.398054: Validation loss did not improve from -0.81344. Patience: 3/50
2024-07-04 00:18:25.399280: train_loss -0.78
2024-07-04 00:18:25.400332: val_loss -0.802
2024-07-04 00:18:25.401465: Pseudo dice [0.9017]
2024-07-04 00:18:25.402463: Epoch time: 67.11 s
2024-07-04 00:18:25.403639: Yayy! New best EMA pseudo Dice: 0.8985
2024-07-04 00:18:26.968848: 
2024-07-04 00:18:26.970678: Epoch 313
2024-07-04 00:18:26.971802: Current learning rate: 0.00713
2024-07-04 00:19:34.171145: Validation loss did not improve from -0.81344. Patience: 4/50
2024-07-04 00:19:34.172807: train_loss -0.7855
2024-07-04 00:19:34.174464: val_loss -0.8008
2024-07-04 00:19:34.175709: Pseudo dice [0.8992]
2024-07-04 00:19:34.176967: Epoch time: 67.21 s
2024-07-04 00:19:34.178081: Yayy! New best EMA pseudo Dice: 0.8986
2024-07-04 00:19:35.687680: 
2024-07-04 00:19:35.689401: Epoch 314
2024-07-04 00:19:35.690945: Current learning rate: 0.00712
2024-07-04 00:20:43.020194: Validation loss did not improve from -0.81344. Patience: 5/50
2024-07-04 00:20:43.021577: train_loss -0.7567
2024-07-04 00:20:43.022993: val_loss -0.7911
2024-07-04 00:20:43.024285: Pseudo dice [0.893]
2024-07-04 00:20:43.025436: Epoch time: 67.33 s
2024-07-04 00:20:44.534539: 
2024-07-04 00:20:44.536531: Epoch 315
2024-07-04 00:20:44.537948: Current learning rate: 0.00711
2024-07-04 00:21:51.858241: Validation loss did not improve from -0.81344. Patience: 6/50
2024-07-04 00:21:51.861878: train_loss -0.7586
2024-07-04 00:21:51.863754: val_loss -0.8025
2024-07-04 00:21:51.865067: Pseudo dice [0.8961]
2024-07-04 00:21:51.866398: Epoch time: 67.33 s
2024-07-04 00:21:53.463271: 
2024-07-04 00:21:53.465227: Epoch 316
2024-07-04 00:21:53.466327: Current learning rate: 0.0071
2024-07-04 00:23:01.075173: Validation loss did not improve from -0.81344. Patience: 7/50
2024-07-04 00:23:01.076492: train_loss -0.7681
2024-07-04 00:23:01.078227: val_loss -0.7961
2024-07-04 00:23:01.079594: Pseudo dice [0.8972]
2024-07-04 00:23:01.080668: Epoch time: 67.61 s
2024-07-04 00:23:02.297697: 
2024-07-04 00:23:02.300205: Epoch 317
2024-07-04 00:23:02.301630: Current learning rate: 0.0071
2024-07-04 00:24:09.412961: Validation loss did not improve from -0.81344. Patience: 8/50
2024-07-04 00:24:09.414648: train_loss -0.7712
2024-07-04 00:24:09.416325: val_loss -0.7913
2024-07-04 00:24:09.417505: Pseudo dice [0.8911]
2024-07-04 00:24:09.418747: Epoch time: 67.12 s
2024-07-04 00:24:10.644377: 
2024-07-04 00:24:10.646374: Epoch 318
2024-07-04 00:24:10.647981: Current learning rate: 0.00709
2024-07-04 00:25:17.880064: Validation loss did not improve from -0.81344. Patience: 9/50
2024-07-04 00:25:17.881593: train_loss -0.7725
2024-07-04 00:25:17.883161: val_loss -0.799
2024-07-04 00:25:17.884258: Pseudo dice [0.8967]
2024-07-04 00:25:17.885568: Epoch time: 67.24 s
2024-07-04 00:25:19.122011: 
2024-07-04 00:25:19.124334: Epoch 319
2024-07-04 00:25:19.126149: Current learning rate: 0.00708
2024-07-04 00:26:26.280552: Validation loss did not improve from -0.81344. Patience: 10/50
2024-07-04 00:26:26.281941: train_loss -0.7801
2024-07-04 00:26:26.283546: val_loss -0.8011
2024-07-04 00:26:26.284991: Pseudo dice [0.8978]
2024-07-04 00:26:26.286358: Epoch time: 67.16 s
2024-07-04 00:26:27.842161: 
2024-07-04 00:26:27.844776: Epoch 320
2024-07-04 00:26:27.846442: Current learning rate: 0.00707
2024-07-04 00:27:35.092918: Validation loss did not improve from -0.81344. Patience: 11/50
2024-07-04 00:27:35.094139: train_loss -0.7794
2024-07-04 00:27:35.095805: val_loss -0.8107
2024-07-04 00:27:35.097127: Pseudo dice [0.9004]
2024-07-04 00:27:35.098364: Epoch time: 67.25 s
2024-07-04 00:27:36.278806: 
2024-07-04 00:27:36.280963: Epoch 321
2024-07-04 00:27:36.282721: Current learning rate: 0.00706
2024-07-04 00:28:43.576725: Validation loss did not improve from -0.81344. Patience: 12/50
2024-07-04 00:28:43.578805: train_loss -0.7832
2024-07-04 00:28:43.580080: val_loss -0.808
2024-07-04 00:28:43.581220: Pseudo dice [0.8998]
2024-07-04 00:28:43.582618: Epoch time: 67.3 s
2024-07-04 00:28:44.803294: 
2024-07-04 00:28:44.805041: Epoch 322
2024-07-04 00:28:44.806267: Current learning rate: 0.00705
2024-07-04 00:29:51.975877: Validation loss did not improve from -0.81344. Patience: 13/50
2024-07-04 00:29:51.977515: train_loss -0.7845
2024-07-04 00:29:51.978745: val_loss -0.8042
2024-07-04 00:29:51.980200: Pseudo dice [0.8977]
2024-07-04 00:29:51.981435: Epoch time: 67.18 s
2024-07-04 00:29:53.195405: 
2024-07-04 00:29:53.198043: Epoch 323
2024-07-04 00:29:53.199884: Current learning rate: 0.00704
2024-07-04 00:31:00.454985: Validation loss did not improve from -0.81344. Patience: 14/50
2024-07-04 00:31:00.456981: train_loss -0.7813
2024-07-04 00:31:00.458711: val_loss -0.8028
2024-07-04 00:31:00.459827: Pseudo dice [0.9032]
2024-07-04 00:31:00.460882: Epoch time: 67.26 s
2024-07-04 00:31:01.697132: 
2024-07-04 00:31:01.699154: Epoch 324
2024-07-04 00:31:01.700787: Current learning rate: 0.00703
2024-07-04 00:32:08.982794: Validation loss did not improve from -0.81344. Patience: 15/50
2024-07-04 00:32:08.984312: train_loss -0.7898
2024-07-04 00:32:08.986063: val_loss -0.8118
2024-07-04 00:32:08.987329: Pseudo dice [0.9011]
2024-07-04 00:32:08.988293: Epoch time: 67.29 s
2024-07-04 00:32:10.563399: 
2024-07-04 00:32:10.565797: Epoch 325
2024-07-04 00:32:10.567129: Current learning rate: 0.00702
2024-07-04 00:33:18.279979: Validation loss did not improve from -0.81344. Patience: 16/50
2024-07-04 00:33:18.281166: train_loss -0.7849
2024-07-04 00:33:18.282523: val_loss -0.8111
2024-07-04 00:33:18.283499: Pseudo dice [0.9048]
2024-07-04 00:33:18.284501: Epoch time: 67.72 s
2024-07-04 00:33:18.285458: Yayy! New best EMA pseudo Dice: 0.8991
2024-07-04 00:33:19.840145: 
2024-07-04 00:33:19.842459: Epoch 326
2024-07-04 00:33:19.843950: Current learning rate: 0.00701
2024-07-04 00:34:26.991535: Validation loss did not improve from -0.81344. Patience: 17/50
2024-07-04 00:34:26.992890: train_loss -0.7795
2024-07-04 00:34:26.994181: val_loss -0.8067
2024-07-04 00:34:26.995418: Pseudo dice [0.9057]
2024-07-04 00:34:26.996688: Epoch time: 67.15 s
2024-07-04 00:34:26.997916: Yayy! New best EMA pseudo Dice: 0.8998
2024-07-04 00:34:28.538986: 
2024-07-04 00:34:28.540485: Epoch 327
2024-07-04 00:34:28.542092: Current learning rate: 0.007
2024-07-04 00:35:35.588717: Validation loss did not improve from -0.81344. Patience: 18/50
2024-07-04 00:35:35.590108: train_loss -0.7775
2024-07-04 00:35:35.591214: val_loss -0.8058
2024-07-04 00:35:35.592220: Pseudo dice [0.9013]
2024-07-04 00:35:35.593142: Epoch time: 67.05 s
2024-07-04 00:35:35.594025: Yayy! New best EMA pseudo Dice: 0.9
2024-07-04 00:35:37.621602: 
2024-07-04 00:35:37.624129: Epoch 328
2024-07-04 00:35:37.625569: Current learning rate: 0.00699
2024-07-04 00:36:44.758203: Validation loss did not improve from -0.81344. Patience: 19/50
2024-07-04 00:36:44.760091: train_loss -0.7787
2024-07-04 00:36:44.762034: val_loss -0.8063
2024-07-04 00:36:44.763732: Pseudo dice [0.9013]
2024-07-04 00:36:44.765274: Epoch time: 67.14 s
2024-07-04 00:36:44.766516: Yayy! New best EMA pseudo Dice: 0.9001
2024-07-04 00:36:46.336287: 
2024-07-04 00:36:46.338371: Epoch 329
2024-07-04 00:36:46.339636: Current learning rate: 0.00698
2024-07-04 00:37:53.861492: Validation loss did not improve from -0.81344. Patience: 20/50
2024-07-04 00:37:53.863111: train_loss -0.7844
2024-07-04 00:37:53.864280: val_loss -0.8046
2024-07-04 00:37:53.865517: Pseudo dice [0.9]
2024-07-04 00:37:53.866658: Epoch time: 67.53 s
2024-07-04 00:37:55.426891: 
2024-07-04 00:37:55.429573: Epoch 330
2024-07-04 00:37:55.430687: Current learning rate: 0.00697
2024-07-04 00:39:03.144253: Validation loss improved from -0.81344 to -0.81754! Patience: 20/50
2024-07-04 00:39:03.232944: train_loss -0.7885
2024-07-04 00:39:03.236528: val_loss -0.8175
2024-07-04 00:39:03.237667: Pseudo dice [0.9043]
2024-07-04 00:39:03.239272: Epoch time: 67.8 s
2024-07-04 00:39:03.240355: Yayy! New best EMA pseudo Dice: 0.9005
2024-07-04 00:39:04.904267: 
2024-07-04 00:39:04.906982: Epoch 331
2024-07-04 00:39:04.908695: Current learning rate: 0.00696
2024-07-04 00:40:12.407607: Validation loss did not improve from -0.81754. Patience: 1/50
2024-07-04 00:40:12.409114: train_loss -0.7849
2024-07-04 00:40:12.410320: val_loss -0.8129
2024-07-04 00:40:12.411389: Pseudo dice [0.9033]
2024-07-04 00:40:12.412412: Epoch time: 67.51 s
2024-07-04 00:40:12.413566: Yayy! New best EMA pseudo Dice: 0.9008
2024-07-04 00:40:14.180971: 
2024-07-04 00:40:14.182791: Epoch 332
2024-07-04 00:40:14.184099: Current learning rate: 0.00696
2024-07-04 00:41:21.883529: Validation loss did not improve from -0.81754. Patience: 2/50
2024-07-04 00:41:21.884942: train_loss -0.7909
2024-07-04 00:41:21.886288: val_loss -0.8103
2024-07-04 00:41:21.887600: Pseudo dice [0.9001]
2024-07-04 00:41:21.888843: Epoch time: 67.71 s
2024-07-04 00:41:23.138398: 
2024-07-04 00:41:23.140295: Epoch 333
2024-07-04 00:41:23.141976: Current learning rate: 0.00695
2024-07-04 00:42:30.238092: Validation loss did not improve from -0.81754. Patience: 3/50
2024-07-04 00:42:30.239518: train_loss -0.7922
2024-07-04 00:42:30.240876: val_loss -0.8093
2024-07-04 00:42:30.242235: Pseudo dice [0.9009]
2024-07-04 00:42:30.243720: Epoch time: 67.1 s
2024-07-04 00:42:31.478800: 
2024-07-04 00:42:31.481966: Epoch 334
2024-07-04 00:42:31.483587: Current learning rate: 0.00694
2024-07-04 00:43:38.668124: Validation loss did not improve from -0.81754. Patience: 4/50
2024-07-04 00:43:38.670254: train_loss -0.7849
2024-07-04 00:43:38.672071: val_loss -0.8152
2024-07-04 00:43:38.673214: Pseudo dice [0.9003]
2024-07-04 00:43:38.674408: Epoch time: 67.19 s
2024-07-04 00:43:40.434515: 
2024-07-04 00:43:40.436528: Epoch 335
2024-07-04 00:43:40.438260: Current learning rate: 0.00693
2024-07-04 00:44:47.746630: Validation loss did not improve from -0.81754. Patience: 5/50
2024-07-04 00:44:47.747965: train_loss -0.7887
2024-07-04 00:44:47.749273: val_loss -0.8105
2024-07-04 00:44:47.750466: Pseudo dice [0.9029]
2024-07-04 00:44:47.751535: Epoch time: 67.31 s
2024-07-04 00:44:47.752592: Yayy! New best EMA pseudo Dice: 0.9009
2024-07-04 00:44:49.296240: 
2024-07-04 00:44:49.298108: Epoch 336
2024-07-04 00:44:49.299205: Current learning rate: 0.00692
2024-07-04 00:45:56.368128: Validation loss did not improve from -0.81754. Patience: 6/50
2024-07-04 00:45:56.369785: train_loss -0.785
2024-07-04 00:45:56.371397: val_loss -0.8005
2024-07-04 00:45:56.372669: Pseudo dice [0.8964]
2024-07-04 00:45:56.373979: Epoch time: 67.07 s
2024-07-04 00:45:57.623337: 
2024-07-04 00:45:57.625347: Epoch 337
2024-07-04 00:45:57.626743: Current learning rate: 0.00691
2024-07-04 00:47:04.702586: Validation loss did not improve from -0.81754. Patience: 7/50
2024-07-04 00:47:04.703928: train_loss -0.7896
2024-07-04 00:47:04.705497: val_loss -0.809
2024-07-04 00:47:04.706690: Pseudo dice [0.9038]
2024-07-04 00:47:04.707919: Epoch time: 67.08 s
2024-07-04 00:47:05.948757: 
2024-07-04 00:47:05.951155: Epoch 338
2024-07-04 00:47:05.952445: Current learning rate: 0.0069
2024-07-04 00:48:13.089604: Validation loss did not improve from -0.81754. Patience: 8/50
2024-07-04 00:48:13.090816: train_loss -0.7901
2024-07-04 00:48:13.092119: val_loss -0.8103
2024-07-04 00:48:13.093094: Pseudo dice [0.903]
2024-07-04 00:48:13.094082: Epoch time: 67.14 s
2024-07-04 00:48:13.095221: Yayy! New best EMA pseudo Dice: 0.901
2024-07-04 00:48:15.156638: 
2024-07-04 00:48:15.158943: Epoch 339
2024-07-04 00:48:15.160526: Current learning rate: 0.00689
2024-07-04 00:49:22.365428: Validation loss did not improve from -0.81754. Patience: 9/50
2024-07-04 00:49:22.366650: train_loss -0.7914
2024-07-04 00:49:22.367941: val_loss -0.8168
2024-07-04 00:49:22.368993: Pseudo dice [0.8993]
2024-07-04 00:49:22.370060: Epoch time: 67.21 s
2024-07-04 00:49:23.937023: 
2024-07-04 00:49:23.939071: Epoch 340
2024-07-04 00:49:23.940886: Current learning rate: 0.00688
2024-07-04 00:50:31.088932: Validation loss did not improve from -0.81754. Patience: 10/50
2024-07-04 00:50:31.090405: train_loss -0.7866
2024-07-04 00:50:31.091881: val_loss -0.8125
2024-07-04 00:50:31.093274: Pseudo dice [0.9026]
2024-07-04 00:50:31.094487: Epoch time: 67.15 s
2024-07-04 00:50:32.340891: 
2024-07-04 00:50:32.342723: Epoch 341
2024-07-04 00:50:32.343924: Current learning rate: 0.00687
2024-07-04 00:51:39.687708: Validation loss did not improve from -0.81754. Patience: 11/50
2024-07-04 00:51:39.689396: train_loss -0.7869
2024-07-04 00:51:39.691240: val_loss -0.8161
2024-07-04 00:51:39.692933: Pseudo dice [0.9041]
2024-07-04 00:51:39.694054: Epoch time: 67.35 s
2024-07-04 00:51:39.694994: Yayy! New best EMA pseudo Dice: 0.9013
2024-07-04 00:51:41.286795: 
2024-07-04 00:51:41.288608: Epoch 342
2024-07-04 00:51:41.289886: Current learning rate: 0.00686
2024-07-04 00:52:50.082289: Validation loss did not improve from -0.81754. Patience: 12/50
2024-07-04 00:52:50.083884: train_loss -0.7923
2024-07-04 00:52:50.085612: val_loss -0.8089
2024-07-04 00:52:50.087508: Pseudo dice [0.9026]
2024-07-04 00:52:50.089167: Epoch time: 68.8 s
2024-07-04 00:52:50.090448: Yayy! New best EMA pseudo Dice: 0.9015
2024-07-04 00:52:51.890465: 
2024-07-04 00:52:51.892489: Epoch 343
2024-07-04 00:52:51.894291: Current learning rate: 0.00685
2024-07-04 00:53:59.262657: Validation loss did not improve from -0.81754. Patience: 13/50
2024-07-04 00:53:59.282076: train_loss -0.7907
2024-07-04 00:53:59.283500: val_loss -0.8129
2024-07-04 00:53:59.284602: Pseudo dice [0.9038]
2024-07-04 00:53:59.285643: Epoch time: 67.39 s
2024-07-04 00:53:59.286821: Yayy! New best EMA pseudo Dice: 0.9017
2024-07-04 00:54:00.917732: 
2024-07-04 00:54:00.919576: Epoch 344
2024-07-04 00:54:00.921144: Current learning rate: 0.00684
2024-07-04 00:55:10.267777: Validation loss did not improve from -0.81754. Patience: 14/50
2024-07-04 00:55:10.271897: train_loss -0.7913
2024-07-04 00:55:10.273689: val_loss -0.8117
2024-07-04 00:55:10.275033: Pseudo dice [0.9068]
2024-07-04 00:55:10.276469: Epoch time: 69.35 s
2024-07-04 00:55:10.776177: Yayy! New best EMA pseudo Dice: 0.9022
2024-07-04 00:55:12.561602: 
2024-07-04 00:55:12.563721: Epoch 345
2024-07-04 00:55:12.565504: Current learning rate: 0.00683
2024-07-04 00:56:20.308652: Validation loss did not improve from -0.81754. Patience: 15/50
2024-07-04 00:56:20.318602: train_loss -0.7905
2024-07-04 00:56:20.320299: val_loss -0.8158
2024-07-04 00:56:20.321684: Pseudo dice [0.9026]
2024-07-04 00:56:20.322808: Epoch time: 67.75 s
2024-07-04 00:56:20.324324: Yayy! New best EMA pseudo Dice: 0.9022
2024-07-04 00:56:22.154024: 
2024-07-04 00:56:22.156534: Epoch 346
2024-07-04 00:56:22.158085: Current learning rate: 0.00682
2024-07-04 00:57:29.690031: Validation loss improved from -0.81754 to -0.82387! Patience: 15/50
2024-07-04 00:57:29.691914: train_loss -0.7956
2024-07-04 00:57:29.693918: val_loss -0.8239
2024-07-04 00:57:29.695047: Pseudo dice [0.9101]
2024-07-04 00:57:29.696153: Epoch time: 67.54 s
2024-07-04 00:57:29.697349: Yayy! New best EMA pseudo Dice: 0.903
2024-07-04 00:57:31.284943: 
2024-07-04 00:57:31.286974: Epoch 347
2024-07-04 00:57:31.288309: Current learning rate: 0.00681
2024-07-04 00:58:38.372082: Validation loss did not improve from -0.82387. Patience: 1/50
2024-07-04 00:58:38.373623: train_loss -0.7842
2024-07-04 00:58:38.374958: val_loss -0.8143
2024-07-04 00:58:38.376084: Pseudo dice [0.8995]
2024-07-04 00:58:38.377232: Epoch time: 67.09 s
2024-07-04 00:58:39.586556: 
2024-07-04 00:58:39.588511: Epoch 348
2024-07-04 00:58:39.589658: Current learning rate: 0.0068
2024-07-04 00:59:46.765638: Validation loss did not improve from -0.82387. Patience: 2/50
2024-07-04 00:59:46.767274: train_loss -0.7854
2024-07-04 00:59:46.768645: val_loss -0.8043
2024-07-04 00:59:46.769875: Pseudo dice [0.901]
2024-07-04 00:59:46.771051: Epoch time: 67.18 s
2024-07-04 00:59:48.007323: 
2024-07-04 00:59:48.009964: Epoch 349
2024-07-04 00:59:48.011795: Current learning rate: 0.0068
2024-07-04 01:00:55.611508: Validation loss did not improve from -0.82387. Patience: 3/50
2024-07-04 01:00:55.612892: train_loss -0.7826
2024-07-04 01:00:55.614468: val_loss -0.8067
2024-07-04 01:00:55.615899: Pseudo dice [0.8984]
2024-07-04 01:00:55.617280: Epoch time: 67.61 s
2024-07-04 01:00:58.847251: 
2024-07-04 01:00:58.849545: Epoch 350
2024-07-04 01:00:58.850957: Current learning rate: 0.00679
2024-07-04 01:02:06.338815: Validation loss did not improve from -0.82387. Patience: 4/50
2024-07-04 01:02:06.340176: train_loss -0.7814
2024-07-04 01:02:06.341341: val_loss -0.8094
2024-07-04 01:02:06.342561: Pseudo dice [0.9017]
2024-07-04 01:02:06.343871: Epoch time: 67.49 s
2024-07-04 01:02:07.588597: 
2024-07-04 01:02:07.591066: Epoch 351
2024-07-04 01:02:07.592558: Current learning rate: 0.00678
2024-07-04 01:03:14.888069: Validation loss did not improve from -0.82387. Patience: 5/50
2024-07-04 01:03:14.889500: train_loss -0.7884
2024-07-04 01:03:14.891344: val_loss -0.8178
2024-07-04 01:03:14.892910: Pseudo dice [0.9046]
2024-07-04 01:03:14.894323: Epoch time: 67.3 s
2024-07-04 01:03:16.118350: 
2024-07-04 01:03:16.120682: Epoch 352
2024-07-04 01:03:16.123074: Current learning rate: 0.00677
2024-07-04 01:04:23.093102: Validation loss did not improve from -0.82387. Patience: 6/50
2024-07-04 01:04:23.094651: train_loss -0.7789
2024-07-04 01:04:23.096225: val_loss -0.805
2024-07-04 01:04:23.097232: Pseudo dice [0.9017]
2024-07-04 01:04:23.098423: Epoch time: 66.98 s
2024-07-04 01:04:24.314714: 
2024-07-04 01:04:24.317329: Epoch 353
2024-07-04 01:04:24.319117: Current learning rate: 0.00676
2024-07-04 01:05:31.774634: Validation loss did not improve from -0.82387. Patience: 7/50
2024-07-04 01:05:31.776119: train_loss -0.784
2024-07-04 01:05:31.777386: val_loss -0.8062
2024-07-04 01:05:31.778687: Pseudo dice [0.8984]
2024-07-04 01:05:31.779992: Epoch time: 67.46 s
2024-07-04 01:05:33.009716: 
2024-07-04 01:05:33.011935: Epoch 354
2024-07-04 01:05:33.013361: Current learning rate: 0.00675
2024-07-04 01:06:40.183180: Validation loss did not improve from -0.82387. Patience: 8/50
2024-07-04 01:06:40.184707: train_loss -0.7805
2024-07-04 01:06:40.186438: val_loss -0.8088
2024-07-04 01:06:40.187667: Pseudo dice [0.9023]
2024-07-04 01:06:40.188663: Epoch time: 67.18 s
2024-07-04 01:06:41.836910: 
2024-07-04 01:06:41.838861: Epoch 355
2024-07-04 01:06:41.840370: Current learning rate: 0.00674
2024-07-04 01:07:49.066827: Validation loss did not improve from -0.82387. Patience: 9/50
2024-07-04 01:07:49.068762: train_loss -0.7816
2024-07-04 01:07:49.071175: val_loss -0.7978
2024-07-04 01:07:49.073352: Pseudo dice [0.9]
2024-07-04 01:07:49.075152: Epoch time: 67.23 s
2024-07-04 01:07:50.376901: 
2024-07-04 01:07:50.379327: Epoch 356
2024-07-04 01:07:50.380921: Current learning rate: 0.00673
2024-07-04 01:08:57.708491: Validation loss did not improve from -0.82387. Patience: 10/50
2024-07-04 01:08:57.710115: train_loss -0.7867
2024-07-04 01:08:57.711515: val_loss -0.813
2024-07-04 01:08:57.712592: Pseudo dice [0.9061]
2024-07-04 01:08:57.713989: Epoch time: 67.33 s
2024-07-04 01:08:58.963431: 
2024-07-04 01:08:58.965173: Epoch 357
2024-07-04 01:08:58.966336: Current learning rate: 0.00672
2024-07-04 01:10:06.025231: Validation loss did not improve from -0.82387. Patience: 11/50
2024-07-04 01:10:06.026589: train_loss -0.7927
2024-07-04 01:10:06.027799: val_loss -0.8092
2024-07-04 01:10:06.028772: Pseudo dice [0.9032]
2024-07-04 01:10:06.029811: Epoch time: 67.06 s
2024-07-04 01:10:07.265426: 
2024-07-04 01:10:07.267641: Epoch 358
2024-07-04 01:10:07.269053: Current learning rate: 0.00671
2024-07-04 01:11:14.512670: Validation loss did not improve from -0.82387. Patience: 12/50
2024-07-04 01:11:14.514009: train_loss -0.7805
2024-07-04 01:11:14.515292: val_loss -0.8036
2024-07-04 01:11:14.516361: Pseudo dice [0.8964]
2024-07-04 01:11:14.517497: Epoch time: 67.25 s
2024-07-04 01:11:15.779885: 
2024-07-04 01:11:15.782612: Epoch 359
2024-07-04 01:11:15.784786: Current learning rate: 0.0067
2024-07-04 01:12:22.950245: Validation loss did not improve from -0.82387. Patience: 13/50
2024-07-04 01:12:22.951656: train_loss -0.7829
2024-07-04 01:12:22.952906: val_loss -0.7977
2024-07-04 01:12:22.954024: Pseudo dice [0.8989]
2024-07-04 01:12:22.955255: Epoch time: 67.17 s
2024-07-04 01:12:24.538547: 
2024-07-04 01:12:24.540160: Epoch 360
2024-07-04 01:12:24.541690: Current learning rate: 0.00669
2024-07-04 01:13:31.906086: Validation loss did not improve from -0.82387. Patience: 14/50
2024-07-04 01:13:31.907443: train_loss -0.7826
2024-07-04 01:13:31.908638: val_loss -0.8079
2024-07-04 01:13:31.909969: Pseudo dice [0.9054]
2024-07-04 01:13:31.910902: Epoch time: 67.37 s
2024-07-04 01:13:33.779906: 
2024-07-04 01:13:33.781640: Epoch 361
2024-07-04 01:13:33.783263: Current learning rate: 0.00668
2024-07-04 01:14:41.191942: Validation loss did not improve from -0.82387. Patience: 15/50
2024-07-04 01:14:41.193335: train_loss -0.7795
2024-07-04 01:14:41.194711: val_loss -0.8061
2024-07-04 01:14:41.195758: Pseudo dice [0.8998]
2024-07-04 01:14:41.196918: Epoch time: 67.41 s
2024-07-04 01:14:42.419307: 
2024-07-04 01:14:42.421448: Epoch 362
2024-07-04 01:14:42.423022: Current learning rate: 0.00667
2024-07-04 01:15:49.486975: Validation loss did not improve from -0.82387. Patience: 16/50
2024-07-04 01:15:49.489002: train_loss -0.7844
2024-07-04 01:15:49.490727: val_loss -0.8174
2024-07-04 01:15:49.492349: Pseudo dice [0.9027]
2024-07-04 01:15:49.493954: Epoch time: 67.07 s
2024-07-04 01:15:50.750305: 
2024-07-04 01:15:50.752261: Epoch 363
2024-07-04 01:15:50.753712: Current learning rate: 0.00666
2024-07-04 01:16:57.898217: Validation loss did not improve from -0.82387. Patience: 17/50
2024-07-04 01:16:57.899622: train_loss -0.7696
2024-07-04 01:16:57.900824: val_loss -0.7627
2024-07-04 01:16:57.901938: Pseudo dice [0.877]
2024-07-04 01:16:57.903015: Epoch time: 67.15 s
2024-07-04 01:16:59.142318: 
2024-07-04 01:16:59.144332: Epoch 364
2024-07-04 01:16:59.145807: Current learning rate: 0.00665
2024-07-04 01:18:06.303390: Validation loss did not improve from -0.82387. Patience: 18/50
2024-07-04 01:18:06.305312: train_loss -0.7361
2024-07-04 01:18:06.308045: val_loss -0.7482
2024-07-04 01:18:06.310059: Pseudo dice [0.8751]
2024-07-04 01:18:06.311366: Epoch time: 67.16 s
2024-07-04 01:18:07.929026: 
2024-07-04 01:18:07.931227: Epoch 365
2024-07-04 01:18:07.932663: Current learning rate: 0.00665
2024-07-04 01:19:15.067444: Validation loss did not improve from -0.82387. Patience: 19/50
2024-07-04 01:19:15.069502: train_loss -0.7215
2024-07-04 01:19:15.071108: val_loss -0.7571
2024-07-04 01:19:15.072132: Pseudo dice [0.878]
2024-07-04 01:19:15.073342: Epoch time: 67.14 s
2024-07-04 01:19:16.331154: 
2024-07-04 01:19:16.333303: Epoch 366
2024-07-04 01:19:16.334844: Current learning rate: 0.00664
2024-07-04 01:20:23.398365: Validation loss did not improve from -0.82387. Patience: 20/50
2024-07-04 01:20:23.399822: train_loss -0.7393
2024-07-04 01:20:23.401090: val_loss -0.7724
2024-07-04 01:20:23.402195: Pseudo dice [0.8826]
2024-07-04 01:20:23.403248: Epoch time: 67.07 s
2024-07-04 01:20:24.663366: 
2024-07-04 01:20:24.665340: Epoch 367
2024-07-04 01:20:24.666474: Current learning rate: 0.00663
2024-07-04 01:21:31.855231: Validation loss did not improve from -0.82387. Patience: 21/50
2024-07-04 01:21:31.856634: train_loss -0.7493
2024-07-04 01:21:31.858139: val_loss -0.7897
2024-07-04 01:21:31.859494: Pseudo dice [0.8855]
2024-07-04 01:21:31.860786: Epoch time: 67.19 s
2024-07-04 01:21:33.095643: 
2024-07-04 01:21:33.097810: Epoch 368
2024-07-04 01:21:33.099388: Current learning rate: 0.00662
2024-07-04 01:22:40.093199: Validation loss did not improve from -0.82387. Patience: 22/50
2024-07-04 01:22:40.094665: train_loss -0.7598
2024-07-04 01:22:40.095829: val_loss -0.7873
2024-07-04 01:22:40.096919: Pseudo dice [0.8913]
2024-07-04 01:22:40.097874: Epoch time: 67.0 s
2024-07-04 01:22:41.363055: 
2024-07-04 01:22:41.365160: Epoch 369
2024-07-04 01:22:41.366633: Current learning rate: 0.00661
2024-07-04 01:23:48.483731: Validation loss did not improve from -0.82387. Patience: 23/50
2024-07-04 01:23:48.485327: train_loss -0.7687
2024-07-04 01:23:48.486638: val_loss -0.7918
2024-07-04 01:23:48.487928: Pseudo dice [0.8947]
2024-07-04 01:23:48.489168: Epoch time: 67.12 s
2024-07-04 01:23:50.066103: 
2024-07-04 01:23:50.068722: Epoch 370
2024-07-04 01:23:50.070539: Current learning rate: 0.0066
2024-07-04 01:24:57.483056: Validation loss did not improve from -0.82387. Patience: 24/50
2024-07-04 01:24:57.484965: train_loss -0.7761
2024-07-04 01:24:57.486979: val_loss -0.8086
2024-07-04 01:24:57.488263: Pseudo dice [0.9014]
2024-07-04 01:24:57.489442: Epoch time: 67.42 s
2024-07-04 01:24:58.775056: 
2024-07-04 01:24:58.778181: Epoch 371
2024-07-04 01:24:58.779604: Current learning rate: 0.00659
2024-07-04 01:26:05.829055: Validation loss did not improve from -0.82387. Patience: 25/50
2024-07-04 01:26:05.830522: train_loss -0.7803
2024-07-04 01:26:05.832141: val_loss -0.816
2024-07-04 01:26:05.833337: Pseudo dice [0.9051]
2024-07-04 01:26:05.834450: Epoch time: 67.06 s
2024-07-04 01:26:07.436672: 
2024-07-04 01:26:07.439269: Epoch 372
2024-07-04 01:26:07.440551: Current learning rate: 0.00658
2024-07-04 01:27:14.720166: Validation loss did not improve from -0.82387. Patience: 26/50
2024-07-04 01:27:14.721628: train_loss -0.7884
2024-07-04 01:27:14.722967: val_loss -0.8092
2024-07-04 01:27:14.724318: Pseudo dice [0.9021]
2024-07-04 01:27:14.725351: Epoch time: 67.29 s
2024-07-04 01:27:16.025102: 
2024-07-04 01:27:16.027168: Epoch 373
2024-07-04 01:27:16.029125: Current learning rate: 0.00657
2024-07-04 01:28:23.624094: Validation loss did not improve from -0.82387. Patience: 27/50
2024-07-04 01:28:23.625483: train_loss -0.7859
2024-07-04 01:28:23.626918: val_loss -0.8135
2024-07-04 01:28:23.628122: Pseudo dice [0.9079]
2024-07-04 01:28:23.629189: Epoch time: 67.6 s
2024-07-04 01:28:24.933250: 
2024-07-04 01:28:24.935638: Epoch 374
2024-07-04 01:28:24.937136: Current learning rate: 0.00656
2024-07-04 01:29:32.052696: Validation loss did not improve from -0.82387. Patience: 28/50
2024-07-04 01:29:32.054311: train_loss -0.7908
2024-07-04 01:29:32.055604: val_loss -0.81
2024-07-04 01:29:32.056897: Pseudo dice [0.9029]
2024-07-04 01:29:32.058336: Epoch time: 67.12 s
2024-07-04 01:29:33.725250: 
2024-07-04 01:29:33.727151: Epoch 375
2024-07-04 01:29:33.728735: Current learning rate: 0.00655
2024-07-04 01:30:40.936916: Validation loss did not improve from -0.82387. Patience: 29/50
2024-07-04 01:30:40.938174: train_loss -0.7898
2024-07-04 01:30:40.940173: val_loss -0.8106
2024-07-04 01:30:40.941737: Pseudo dice [0.9053]
2024-07-04 01:30:40.943398: Epoch time: 67.21 s
2024-07-04 01:30:42.202286: 
2024-07-04 01:30:42.204434: Epoch 376
2024-07-04 01:30:42.205782: Current learning rate: 0.00654
2024-07-04 01:31:49.218208: Validation loss did not improve from -0.82387. Patience: 30/50
2024-07-04 01:31:49.219797: train_loss -0.7939
2024-07-04 01:31:49.221321: val_loss -0.8084
2024-07-04 01:31:49.222299: Pseudo dice [0.906]
2024-07-04 01:31:49.223596: Epoch time: 67.02 s
2024-07-04 01:31:50.452701: 
2024-07-04 01:31:50.455348: Epoch 377
2024-07-04 01:31:50.457037: Current learning rate: 0.00653
2024-07-04 01:32:57.558901: Validation loss did not improve from -0.82387. Patience: 31/50
2024-07-04 01:32:57.560287: train_loss -0.7904
2024-07-04 01:32:57.561659: val_loss -0.8161
2024-07-04 01:32:57.562906: Pseudo dice [0.906]
2024-07-04 01:32:57.564201: Epoch time: 67.11 s
2024-07-04 01:32:58.787041: 
2024-07-04 01:32:58.789769: Epoch 378
2024-07-04 01:32:58.791237: Current learning rate: 0.00652
2024-07-04 01:34:06.095352: Validation loss did not improve from -0.82387. Patience: 32/50
2024-07-04 01:34:06.096636: train_loss -0.7845
2024-07-04 01:34:06.097727: val_loss -0.8105
2024-07-04 01:34:06.098856: Pseudo dice [0.9043]
2024-07-04 01:34:06.099943: Epoch time: 67.31 s
2024-07-04 01:34:07.334883: 
2024-07-04 01:34:07.336536: Epoch 379
2024-07-04 01:34:07.338311: Current learning rate: 0.00651
2024-07-04 01:35:14.523753: Validation loss did not improve from -0.82387. Patience: 33/50
2024-07-04 01:35:14.524980: train_loss -0.7792
2024-07-04 01:35:14.526138: val_loss -0.7967
2024-07-04 01:35:14.527294: Pseudo dice [0.8964]
2024-07-04 01:35:14.528408: Epoch time: 67.19 s
2024-07-04 01:35:16.108342: 
2024-07-04 01:35:16.110430: Epoch 380
2024-07-04 01:35:16.112118: Current learning rate: 0.0065
2024-07-04 01:36:23.301593: Validation loss did not improve from -0.82387. Patience: 34/50
2024-07-04 01:36:23.303319: train_loss -0.7852
2024-07-04 01:36:23.304654: val_loss -0.81
2024-07-04 01:36:23.305771: Pseudo dice [0.9045]
2024-07-04 01:36:23.307010: Epoch time: 67.2 s
2024-07-04 01:36:24.554625: 
2024-07-04 01:36:24.556799: Epoch 381
2024-07-04 01:36:24.558670: Current learning rate: 0.00649
2024-07-04 01:37:32.146963: Validation loss did not improve from -0.82387. Patience: 35/50
2024-07-04 01:37:32.148261: train_loss -0.7844
2024-07-04 01:37:32.149644: val_loss -0.8077
2024-07-04 01:37:32.150774: Pseudo dice [0.8972]
2024-07-04 01:37:32.151779: Epoch time: 67.59 s
2024-07-04 01:37:33.459207: 
2024-07-04 01:37:33.460811: Epoch 382
2024-07-04 01:37:33.462199: Current learning rate: 0.00648
2024-07-04 01:38:40.597204: Validation loss did not improve from -0.82387. Patience: 36/50
2024-07-04 01:38:40.598552: train_loss -0.7844
2024-07-04 01:38:40.599925: val_loss -0.8008
2024-07-04 01:38:40.601059: Pseudo dice [0.8979]
2024-07-04 01:38:40.602112: Epoch time: 67.14 s
2024-07-04 01:38:41.858087: 
2024-07-04 01:38:41.859796: Epoch 383
2024-07-04 01:38:41.861185: Current learning rate: 0.00648
2024-07-04 01:39:48.985045: Validation loss did not improve from -0.82387. Patience: 37/50
2024-07-04 01:39:48.986825: train_loss -0.7918
2024-07-04 01:39:48.989298: val_loss -0.8172
2024-07-04 01:39:48.991512: Pseudo dice [0.9067]
2024-07-04 01:39:48.993317: Epoch time: 67.13 s
2024-07-04 01:39:50.764053: 
2024-07-04 01:39:50.766738: Epoch 384
2024-07-04 01:39:50.768450: Current learning rate: 0.00647
2024-07-04 01:40:57.881178: Validation loss did not improve from -0.82387. Patience: 38/50
2024-07-04 01:40:57.882577: train_loss -0.7928
2024-07-04 01:40:57.883935: val_loss -0.8035
2024-07-04 01:40:57.885107: Pseudo dice [0.9027]
2024-07-04 01:40:57.886367: Epoch time: 67.12 s
2024-07-04 01:40:59.492357: 
2024-07-04 01:40:59.494379: Epoch 385
2024-07-04 01:40:59.495826: Current learning rate: 0.00646
2024-07-04 01:42:06.626469: Validation loss did not improve from -0.82387. Patience: 39/50
2024-07-04 01:42:06.627796: train_loss -0.7914
2024-07-04 01:42:06.629454: val_loss -0.8157
2024-07-04 01:42:06.630781: Pseudo dice [0.9038]
2024-07-04 01:42:06.631800: Epoch time: 67.14 s
2024-07-04 01:42:07.845505: 
2024-07-04 01:42:07.847192: Epoch 386
2024-07-04 01:42:07.848378: Current learning rate: 0.00645
2024-07-04 01:43:14.949344: Validation loss did not improve from -0.82387. Patience: 40/50
2024-07-04 01:43:14.950745: train_loss -0.7959
2024-07-04 01:43:14.952288: val_loss -0.8101
2024-07-04 01:43:14.953546: Pseudo dice [0.908]
2024-07-04 01:43:14.954887: Epoch time: 67.11 s
2024-07-04 01:43:16.234961: 
2024-07-04 01:43:16.237201: Epoch 387
2024-07-04 01:43:16.238460: Current learning rate: 0.00644
2024-07-04 01:44:23.652375: Validation loss did not improve from -0.82387. Patience: 41/50
2024-07-04 01:44:23.653719: train_loss -0.7912
2024-07-04 01:44:23.656226: val_loss -0.8171
2024-07-04 01:44:23.657695: Pseudo dice [0.9061]
2024-07-04 01:44:23.659452: Epoch time: 67.42 s
2024-07-04 01:44:24.927701: 
2024-07-04 01:44:24.930181: Epoch 388
2024-07-04 01:44:24.931468: Current learning rate: 0.00643
2024-07-04 01:45:32.075559: Validation loss did not improve from -0.82387. Patience: 42/50
2024-07-04 01:45:32.076937: train_loss -0.7907
2024-07-04 01:45:32.078365: val_loss -0.8003
2024-07-04 01:45:32.079780: Pseudo dice [0.9005]
2024-07-04 01:45:32.081249: Epoch time: 67.15 s
2024-07-04 01:45:33.363918: 
2024-07-04 01:45:33.365880: Epoch 389
2024-07-04 01:45:33.367349: Current learning rate: 0.00642
2024-07-04 01:46:40.740423: Validation loss did not improve from -0.82387. Patience: 43/50
2024-07-04 01:46:40.741876: train_loss -0.7908
2024-07-04 01:46:40.743244: val_loss -0.8126
2024-07-04 01:46:40.744534: Pseudo dice [0.9026]
2024-07-04 01:46:40.745714: Epoch time: 67.38 s
2024-07-04 01:46:42.375512: 
2024-07-04 01:46:42.377615: Epoch 390
2024-07-04 01:46:42.378930: Current learning rate: 0.00641
2024-07-04 01:47:49.599540: Validation loss did not improve from -0.82387. Patience: 44/50
2024-07-04 01:47:49.600887: train_loss -0.7898
2024-07-04 01:47:49.602272: val_loss -0.8128
2024-07-04 01:47:49.603560: Pseudo dice [0.9041]
2024-07-04 01:47:49.604837: Epoch time: 67.23 s
2024-07-04 01:47:50.881282: 
2024-07-04 01:47:50.883359: Epoch 391
2024-07-04 01:47:50.885010: Current learning rate: 0.0064
2024-07-04 01:48:58.168353: Validation loss did not improve from -0.82387. Patience: 45/50
2024-07-04 01:48:58.169656: train_loss -0.7913
2024-07-04 01:48:58.171045: val_loss -0.817
2024-07-04 01:48:58.172305: Pseudo dice [0.9074]
2024-07-04 01:48:58.173283: Epoch time: 67.29 s
2024-07-04 01:48:59.567754: 
2024-07-04 01:48:59.569601: Epoch 392
2024-07-04 01:48:59.571184: Current learning rate: 0.00639
2024-07-04 01:50:06.695857: Validation loss did not improve from -0.82387. Patience: 46/50
2024-07-04 01:50:06.697818: train_loss -0.79
2024-07-04 01:50:06.699739: val_loss -0.8122
2024-07-04 01:50:06.700989: Pseudo dice [0.9035]
2024-07-04 01:50:06.702097: Epoch time: 67.13 s
2024-07-04 01:50:07.963789: 
2024-07-04 01:50:07.965837: Epoch 393
2024-07-04 01:50:07.967469: Current learning rate: 0.00638
2024-07-04 01:51:15.057855: Validation loss did not improve from -0.82387. Patience: 47/50
2024-07-04 01:51:15.059331: train_loss -0.7938
2024-07-04 01:51:15.060792: val_loss -0.8011
2024-07-04 01:51:15.062236: Pseudo dice [0.9]
2024-07-04 01:51:15.063467: Epoch time: 67.1 s
2024-07-04 01:51:16.334345: 
2024-07-04 01:51:16.336273: Epoch 394
2024-07-04 01:51:16.337823: Current learning rate: 0.00637
2024-07-04 01:52:23.711148: Validation loss did not improve from -0.82387. Patience: 48/50
2024-07-04 01:52:23.712773: train_loss -0.7712
2024-07-04 01:52:23.714125: val_loss -0.8022
2024-07-04 01:52:23.715407: Pseudo dice [0.9022]
2024-07-04 01:52:23.716816: Epoch time: 67.38 s
2024-07-04 01:52:25.855697: 
2024-07-04 01:52:25.858274: Epoch 395
2024-07-04 01:52:25.859753: Current learning rate: 0.00636
2024-07-04 01:53:33.060737: Validation loss did not improve from -0.82387. Patience: 49/50
2024-07-04 01:53:33.062145: train_loss -0.7816
2024-07-04 01:53:33.063620: val_loss -0.8119
2024-07-04 01:53:33.064769: Pseudo dice [0.9044]
2024-07-04 01:53:33.065846: Epoch time: 67.21 s
2024-07-04 01:53:34.319884: 
2024-07-04 01:53:34.321648: Epoch 396
2024-07-04 01:53:34.323051: Current learning rate: 0.00635
2024-07-04 01:54:41.586132: Validation loss did not improve from -0.82387. Patience: 50/50
2024-07-04 01:54:41.587287: train_loss -0.7882
2024-07-04 01:54:41.588790: val_loss -0.8111
2024-07-04 01:54:41.590162: Pseudo dice [0.9018]
2024-07-04 01:54:41.591413: Epoch time: 67.27 s
2024-07-04 01:54:42.854137: Patience reached. Stopping training.
2024-07-04 01:54:43.258142: Training done.
2024-07-04 01:54:43.944212: predicting 101-019
2024-07-04 01:54:44.010479: 101-019, shape torch.Size([1, 375, 498, 498]), rank 0
2024-07-04 01:56:44.433635: predicting 101-044
2024-07-04 01:56:44.463997: 101-044, shape torch.Size([1, 404, 498, 498]), rank 0
2024-07-04 01:58:14.527821: predicting 106-002
2024-07-04 01:58:14.559587: 106-002, shape torch.Size([1, 539, 498, 498]), rank 0
2024-07-04 02:00:09.970040: predicting 401-004
2024-07-04 02:00:10.071226: 401-004, shape torch.Size([1, 375, 498, 498]), rank 0
2024-07-04 02:01:29.507704: predicting 701-013
2024-07-04 02:01:29.616034: 701-013, shape torch.Size([1, 375, 498, 498]), rank 0
2024-07-04 02:02:49.687068: predicting 704-003
2024-07-04 02:02:49.796631: 704-003, shape torch.Size([1, 375, 498, 498]), rank 0
2024-07-04 02:04:31.347396: Validation complete
2024-07-04 02:04:31.348585: Mean Validation Dice:  0.907448824571174
wandb: 
wandb: Run history:
wandb:            ema_fg_dice ▁▂▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████████
wandb:   epoch_end_timestamps ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb: epoch_start_timestamps ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:                    lrs ████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:           mean_fg_dice ▁▂▄▅▅▆▆▆▇▇▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██████▇███
wandb:           train_losses █▆▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁
wandb:             val_losses █▇▅▄▄▄▃▃▃▃▂▃▂▂▃▂▂▂▂▂▂▂▂▁▂▂▂▁▂▂▁▁▁▁▁▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:            ema_fg_dice 0.90262
wandb:   epoch_end_timestamps 1720072481.58715
wandb: epoch_start_timestamps 1720072414.31873
wandb:                    lrs 0.00635
wandb:           mean_fg_dice 0.90183
wandb:           train_losses -0.78817
wandb:             val_losses -0.81109
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset302_Calcium_OCTv2/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_all/wandb/offline-run-20240703_182104-t3rots61
wandb: Find logs at: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset302_Calcium_OCTv2/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_all/wandb/offline-run-20240703_182104-t3rots61/logs
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f964c0a2490>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f96c4570f10>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f96c44a9070>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f9634b0a6d0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f9654117c70>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f96347ddca0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
