/home/gridsan/nchutisilp/.conda/envs/nnunet/bin/python
Begin training and evaluating FOLD 0 CONFIG 3d_32x160x128_b10 TRAINER nnUNetTrainerScaleAnalysis5 Genesis
wandb: Tracking run with wandb version 0.16.6
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2024-08-12 15:52:50.699475: Using 8 processes for validation.
2024-08-12 15:52:50.716910: Using 12 processes for data augmentation.
2024-08-12 15:52:51.598926: Using torch.compile...
/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
################### Loading pretrained weights from file  /home/gridsan/nchutisilp/datasets/ModelGenesisOutputs/ModelGenesisNNUNetPretrainingV2_noNorm_correct_orientation/Converted_nnUNet_Genesis_OCT_Best.pt ###################
Below is the list of overlapping blocks in pretrained model and nnUNet architecture:
encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])
encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])
encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])
encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])
encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])
encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])
encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])
encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])
encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])
encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])
encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])
encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])
encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])
encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])
encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])
encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])
encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])
encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])
encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])
encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])
encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])
encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])
encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])
encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])
encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])
encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])
encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])
decoder.encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])
decoder.encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])
decoder.encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])
decoder.encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])
decoder.encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])
decoder.encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])
decoder.encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])
decoder.encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])
decoder.encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])
decoder.encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])
decoder.encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])
decoder.encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])
decoder.encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])
decoder.encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.stages.0.convs.0.conv.weight shape torch.Size([320, 640, 3, 3, 3])
decoder.stages.0.convs.0.conv.bias shape torch.Size([320])
decoder.stages.0.convs.0.norm.weight shape torch.Size([320])
decoder.stages.0.convs.0.norm.bias shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.0.weight shape torch.Size([320, 640, 3, 3, 3])
decoder.stages.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.stages.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.stages.0.convs.1.conv.bias shape torch.Size([320])
decoder.stages.0.convs.1.norm.weight shape torch.Size([320])
decoder.stages.0.convs.1.norm.bias shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.stages.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.stages.1.convs.0.conv.weight shape torch.Size([256, 512, 3, 3, 3])
decoder.stages.1.convs.0.conv.bias shape torch.Size([256])
decoder.stages.1.convs.0.norm.weight shape torch.Size([256])
decoder.stages.1.convs.0.norm.bias shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.0.weight shape torch.Size([256, 512, 3, 3, 3])
decoder.stages.1.convs.0.all_modules.0.bias shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.1.weight shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.1.bias shape torch.Size([256])
decoder.stages.1.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.stages.1.convs.1.conv.bias shape torch.Size([256])
decoder.stages.1.convs.1.norm.weight shape torch.Size([256])
decoder.stages.1.convs.1.norm.bias shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.stages.1.convs.1.all_modules.0.bias shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.1.weight shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.1.bias shape torch.Size([256])
decoder.stages.2.convs.0.conv.weight shape torch.Size([128, 256, 3, 3, 3])
decoder.stages.2.convs.0.conv.bias shape torch.Size([128])
decoder.stages.2.convs.0.norm.weight shape torch.Size([128])
decoder.stages.2.convs.0.norm.bias shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.0.weight shape torch.Size([128, 256, 3, 3, 3])
decoder.stages.2.convs.0.all_modules.0.bias shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.1.weight shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.1.bias shape torch.Size([128])
decoder.stages.2.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.stages.2.convs.1.conv.bias shape torch.Size([128])
decoder.stages.2.convs.1.norm.weight shape torch.Size([128])
decoder.stages.2.convs.1.norm.bias shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.stages.2.convs.1.all_modules.0.bias shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.1.weight shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.1.bias shape torch.Size([128])
decoder.stages.3.convs.0.conv.weight shape torch.Size([64, 128, 3, 3, 3])
decoder.stages.3.convs.0.conv.bias shape torch.Size([64])
decoder.stages.3.convs.0.norm.weight shape torch.Size([64])
decoder.stages.3.convs.0.norm.bias shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.0.weight shape torch.Size([64, 128, 3, 3, 3])
decoder.stages.3.convs.0.all_modules.0.bias shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.1.weight shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.1.bias shape torch.Size([64])
decoder.stages.3.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.stages.3.convs.1.conv.bias shape torch.Size([64])
decoder.stages.3.convs.1.norm.weight shape torch.Size([64])
decoder.stages.3.convs.1.norm.bias shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.stages.3.convs.1.all_modules.0.bias shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.1.weight shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.1.bias shape torch.Size([64])
decoder.stages.4.convs.0.conv.weight shape torch.Size([32, 64, 3, 3, 3])
decoder.stages.4.convs.0.conv.bias shape torch.Size([32])
decoder.stages.4.convs.0.norm.weight shape torch.Size([32])
decoder.stages.4.convs.0.norm.bias shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.0.weight shape torch.Size([32, 64, 3, 3, 3])
decoder.stages.4.convs.0.all_modules.0.bias shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.1.weight shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.1.bias shape torch.Size([32])
decoder.stages.4.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.stages.4.convs.1.conv.bias shape torch.Size([32])
decoder.stages.4.convs.1.norm.weight shape torch.Size([32])
decoder.stages.4.convs.1.norm.bias shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.stages.4.convs.1.all_modules.0.bias shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.1.weight shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.1.bias shape torch.Size([32])
decoder.transpconvs.0.weight shape torch.Size([320, 320, 1, 2, 2])
decoder.transpconvs.0.bias shape torch.Size([320])
decoder.transpconvs.1.weight shape torch.Size([320, 256, 2, 2, 2])
decoder.transpconvs.1.bias shape torch.Size([256])
decoder.transpconvs.2.weight shape torch.Size([256, 128, 2, 2, 2])
decoder.transpconvs.2.bias shape torch.Size([128])
decoder.transpconvs.3.weight shape torch.Size([128, 64, 2, 2, 2])
decoder.transpconvs.3.bias shape torch.Size([64])
decoder.transpconvs.4.weight shape torch.Size([64, 32, 2, 2, 2])
decoder.transpconvs.4.bias shape torch.Size([32])
################### Done ###################
2024-08-12 15:52:52.513411: do_dummy_2d_data_aug: True
2024-08-12 15:52:52.530088: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset302_Calcium_OCTv2/splits_final_5.json
2024-08-12 15:52:52.547478: The split file contains 3 splits.
2024-08-12 15:52:52.549135: Desired fold for training: 0
2024-08-12 15:52:52.550421: This split has 3 training and 2 validation cases.
2024-08-12 15:52:52.551723: WARNING: Some validation cases are also in the training set. Please check the splits.json or ignore if this is intentional.
using pin_memory on device 0
using pin_memory on device 0

This is the configuration used by this training:
Configuration name: 3d_32x160x128_b10
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 10, 'patch_size': [32, 160, 128], 'median_image_size_in_voxels': [375.0, 498.0, 498.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'inherits_from': '3d_fullres'} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset302_Calcium_OCTv2', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.4977976381778717, 'mean': 0.13332499563694, 'median': 0.08871842920780182, 'min': 0.0, 'percentile_00_5': 0.014754901640117168, 'percentile_99_5': 0.4977976381778717, 'std': 0.12022686749696732}}} 

2024-08-12 15:52:55.281284: unpacking dataset...
2024-08-12 15:52:59.606716: unpacking done...
2024-08-12 15:52:59.663070: Unable to plot network architecture: nnUNet_compile is enabled!
2024-08-12 15:52:59.712675: 
2024-08-12 15:52:59.714530: Epoch 0
2024-08-12 15:52:59.716061: Current learning rate: 0.01
2024-08-12 15:57:39.467273: Validation loss improved from 1000.00000 to -0.27430! Patience: 0/50
2024-08-12 15:57:39.468787: train_loss -0.1862
2024-08-12 15:57:39.470391: val_loss -0.2743
2024-08-12 15:57:39.472027: Pseudo dice [0.5897]
2024-08-12 15:57:39.473305: Epoch time: 279.76 s
2024-08-12 15:57:39.474785: Yayy! New best EMA pseudo Dice: 0.5897
2024-08-12 15:57:41.411940: 
2024-08-12 15:57:41.413399: Epoch 1
2024-08-12 15:57:41.414580: Current learning rate: 0.00999
2024-08-12 16:03:14.958012: Validation loss did not improve from -0.27430. Patience: 1/50
2024-08-12 16:03:14.959331: train_loss -0.4054
2024-08-12 16:03:14.960447: val_loss -0.248
2024-08-12 16:03:14.961485: Pseudo dice [0.5773]
2024-08-12 16:03:14.962563: Epoch time: 333.55 s
2024-08-12 16:03:16.324223: 
2024-08-12 16:03:16.325739: Epoch 2
2024-08-12 16:03:16.327308: Current learning rate: 0.00998
2024-08-12 16:10:14.246998: Validation loss improved from -0.27430 to -0.37572! Patience: 1/50
2024-08-12 16:10:14.249217: train_loss -0.4897
2024-08-12 16:10:14.250314: val_loss -0.3757
2024-08-12 16:10:14.251337: Pseudo dice [0.6666]
2024-08-12 16:10:14.252328: Epoch time: 417.93 s
2024-08-12 16:10:14.253253: Yayy! New best EMA pseudo Dice: 0.5963
2024-08-12 16:10:16.063939: 
2024-08-12 16:10:16.065541: Epoch 3
2024-08-12 16:10:16.067302: Current learning rate: 0.00997
2024-08-12 16:17:45.739180: Validation loss improved from -0.37572 to -0.41586! Patience: 0/50
2024-08-12 16:17:45.740536: train_loss -0.5322
2024-08-12 16:17:45.741812: val_loss -0.4159
2024-08-12 16:17:45.743021: Pseudo dice [0.6699]
2024-08-12 16:17:45.744228: Epoch time: 449.68 s
2024-08-12 16:17:45.745335: Yayy! New best EMA pseudo Dice: 0.6037
2024-08-12 16:17:47.547633: 
2024-08-12 16:17:47.549006: Epoch 4
2024-08-12 16:17:47.550128: Current learning rate: 0.00996
2024-08-12 16:23:26.497398: Validation loss did not improve from -0.41586. Patience: 1/50
2024-08-12 16:23:26.498756: train_loss -0.5492
2024-08-12 16:23:26.499904: val_loss -0.3958
2024-08-12 16:23:26.501022: Pseudo dice [0.6594]
2024-08-12 16:23:26.502095: Epoch time: 338.95 s
2024-08-12 16:23:27.298759: Yayy! New best EMA pseudo Dice: 0.6092
2024-08-12 16:23:29.178056: 
2024-08-12 16:23:29.183134: Epoch 5
2024-08-12 16:23:29.184932: Current learning rate: 0.00995
2024-08-12 16:31:03.697943: Validation loss improved from -0.41586 to -0.41589! Patience: 1/50
2024-08-12 16:31:03.699410: train_loss -0.5625
2024-08-12 16:31:03.700873: val_loss -0.4159
2024-08-12 16:31:03.702272: Pseudo dice [0.6795]
2024-08-12 16:31:03.703617: Epoch time: 454.52 s
2024-08-12 16:31:03.704955: Yayy! New best EMA pseudo Dice: 0.6163
2024-08-12 16:31:05.564700: 
2024-08-12 16:31:05.566120: Epoch 6
2024-08-12 16:31:05.567411: Current learning rate: 0.00995
2024-08-12 16:38:24.204939: Validation loss did not improve from -0.41589. Patience: 1/50
2024-08-12 16:38:24.206370: train_loss -0.5789
2024-08-12 16:38:24.207736: val_loss -0.4117
2024-08-12 16:38:24.209125: Pseudo dice [0.667]
2024-08-12 16:38:24.210292: Epoch time: 438.64 s
2024-08-12 16:38:24.211469: Yayy! New best EMA pseudo Dice: 0.6213
2024-08-12 16:38:26.070714: 
2024-08-12 16:38:26.072028: Epoch 7
2024-08-12 16:38:26.073168: Current learning rate: 0.00994
2024-08-12 16:44:47.200105: Validation loss improved from -0.41589 to -0.42329! Patience: 1/50
2024-08-12 16:44:47.201402: train_loss -0.5859
2024-08-12 16:44:47.202497: val_loss -0.4233
2024-08-12 16:44:47.203507: Pseudo dice [0.6814]
2024-08-12 16:44:47.204598: Epoch time: 381.13 s
2024-08-12 16:44:47.205587: Yayy! New best EMA pseudo Dice: 0.6273
2024-08-12 16:44:49.122845: 
2024-08-12 16:44:49.124253: Epoch 8
2024-08-12 16:44:49.125348: Current learning rate: 0.00993
2024-08-12 16:51:44.563523: Validation loss improved from -0.42329 to -0.44898! Patience: 0/50
2024-08-12 16:51:44.565186: train_loss -0.609
2024-08-12 16:51:44.566504: val_loss -0.449
2024-08-12 16:51:44.567688: Pseudo dice [0.6914]
2024-08-12 16:51:44.568837: Epoch time: 415.44 s
2024-08-12 16:51:44.569970: Yayy! New best EMA pseudo Dice: 0.6337
2024-08-12 16:51:46.876408: 
2024-08-12 16:51:46.878151: Epoch 9
2024-08-12 16:51:46.879565: Current learning rate: 0.00992
2024-08-12 16:58:03.526928: Validation loss did not improve from -0.44898. Patience: 1/50
2024-08-12 16:58:03.539370: train_loss -0.6164
2024-08-12 16:58:03.540554: val_loss -0.3803
2024-08-12 16:58:03.541674: Pseudo dice [0.6624]
2024-08-12 16:58:03.542810: Epoch time: 376.66 s
2024-08-12 16:58:04.062464: Yayy! New best EMA pseudo Dice: 0.6366
2024-08-12 16:58:05.883739: 
2024-08-12 16:58:05.885498: Epoch 10
2024-08-12 16:58:05.887153: Current learning rate: 0.00991
2024-08-12 17:05:22.952247: Validation loss did not improve from -0.44898. Patience: 2/50
2024-08-12 17:05:22.954115: train_loss -0.6208
2024-08-12 17:05:22.956144: val_loss -0.3514
2024-08-12 17:05:22.957199: Pseudo dice [0.6619]
2024-08-12 17:05:22.958342: Epoch time: 437.07 s
2024-08-12 17:05:22.959307: Yayy! New best EMA pseudo Dice: 0.6391
2024-08-12 17:05:24.848789: 
2024-08-12 17:05:24.850249: Epoch 11
2024-08-12 17:05:24.851494: Current learning rate: 0.0099
2024-08-12 17:12:45.680517: Validation loss did not improve from -0.44898. Patience: 3/50
2024-08-12 17:12:45.681892: train_loss -0.6291
2024-08-12 17:12:45.683699: val_loss -0.3902
2024-08-12 17:12:45.685281: Pseudo dice [0.6589]
2024-08-12 17:12:45.686570: Epoch time: 440.84 s
2024-08-12 17:12:45.688024: Yayy! New best EMA pseudo Dice: 0.6411
2024-08-12 17:12:47.445490: 
2024-08-12 17:12:47.446800: Epoch 12
2024-08-12 17:12:47.447799: Current learning rate: 0.00989
2024-08-12 17:19:52.189008: Validation loss did not improve from -0.44898. Patience: 4/50
2024-08-12 17:19:52.190472: train_loss -0.6418
2024-08-12 17:19:52.191678: val_loss -0.4225
2024-08-12 17:19:52.192787: Pseudo dice [0.6749]
2024-08-12 17:19:52.193896: Epoch time: 424.75 s
2024-08-12 17:19:52.195127: Yayy! New best EMA pseudo Dice: 0.6445
2024-08-12 17:19:53.970548: 
2024-08-12 17:19:53.972339: Epoch 13
2024-08-12 17:19:53.973757: Current learning rate: 0.00988
2024-08-12 17:26:57.295843: Validation loss did not improve from -0.44898. Patience: 5/50
2024-08-12 17:26:57.297176: train_loss -0.6553
2024-08-12 17:26:57.298530: val_loss -0.4062
2024-08-12 17:26:57.299875: Pseudo dice [0.6812]
2024-08-12 17:26:57.301167: Epoch time: 423.33 s
2024-08-12 17:26:57.302508: Yayy! New best EMA pseudo Dice: 0.6482
2024-08-12 17:26:59.098060: 
2024-08-12 17:26:59.099803: Epoch 14
2024-08-12 17:26:59.101144: Current learning rate: 0.00987
2024-08-12 17:34:15.286533: Validation loss did not improve from -0.44898. Patience: 6/50
2024-08-12 17:34:15.287775: train_loss -0.6599
2024-08-12 17:34:15.289087: val_loss -0.4119
2024-08-12 17:34:15.290451: Pseudo dice [0.6789]
2024-08-12 17:34:15.291920: Epoch time: 436.19 s
2024-08-12 17:34:15.669343: Yayy! New best EMA pseudo Dice: 0.6512
2024-08-12 17:34:17.452960: 
2024-08-12 17:34:17.454782: Epoch 15
2024-08-12 17:34:17.455949: Current learning rate: 0.00986
2024-08-12 17:41:24.426681: Validation loss did not improve from -0.44898. Patience: 7/50
2024-08-12 17:41:24.428419: train_loss -0.664
2024-08-12 17:41:24.429879: val_loss -0.4445
2024-08-12 17:41:24.431399: Pseudo dice [0.6955]
2024-08-12 17:41:24.432979: Epoch time: 426.98 s
2024-08-12 17:41:24.434748: Yayy! New best EMA pseudo Dice: 0.6557
2024-08-12 17:41:26.403137: 
2024-08-12 17:41:26.405300: Epoch 16
2024-08-12 17:41:26.406796: Current learning rate: 0.00986
2024-08-12 17:47:16.626660: Validation loss did not improve from -0.44898. Patience: 8/50
2024-08-12 17:47:16.628290: train_loss -0.6671
2024-08-12 17:47:16.629488: val_loss -0.3951
2024-08-12 17:47:16.630646: Pseudo dice [0.6734]
2024-08-12 17:47:16.631870: Epoch time: 350.23 s
2024-08-12 17:47:16.632901: Yayy! New best EMA pseudo Dice: 0.6574
2024-08-12 17:47:18.495920: 
2024-08-12 17:47:18.497921: Epoch 17
2024-08-12 17:47:18.499500: Current learning rate: 0.00985
2024-08-12 17:54:18.752521: Validation loss did not improve from -0.44898. Patience: 9/50
2024-08-12 17:54:18.754265: train_loss -0.6666
2024-08-12 17:54:18.756565: val_loss -0.4187
2024-08-12 17:54:18.758641: Pseudo dice [0.6937]
2024-08-12 17:54:18.760096: Epoch time: 420.26 s
2024-08-12 17:54:18.761477: Yayy! New best EMA pseudo Dice: 0.6611
2024-08-12 17:54:20.681234: 
2024-08-12 17:54:20.683126: Epoch 18
2024-08-12 17:54:20.684705: Current learning rate: 0.00984
2024-08-12 18:01:20.284053: Validation loss did not improve from -0.44898. Patience: 10/50
2024-08-12 18:01:20.285668: train_loss -0.6783
2024-08-12 18:01:20.286971: val_loss -0.3796
2024-08-12 18:01:20.288207: Pseudo dice [0.6784]
2024-08-12 18:01:20.289355: Epoch time: 419.61 s
2024-08-12 18:01:20.290447: Yayy! New best EMA pseudo Dice: 0.6628
2024-08-12 18:01:22.181025: 
2024-08-12 18:01:22.182619: Epoch 19
2024-08-12 18:01:22.184050: Current learning rate: 0.00983
2024-08-12 18:07:42.045367: Validation loss did not improve from -0.44898. Patience: 11/50
2024-08-12 18:07:42.048063: train_loss -0.6884
2024-08-12 18:07:42.050723: val_loss -0.3778
2024-08-12 18:07:42.052355: Pseudo dice [0.6574]
2024-08-12 18:07:42.053870: Epoch time: 379.87 s
2024-08-12 18:07:45.874214: 
2024-08-12 18:07:45.875885: Epoch 20
2024-08-12 18:07:45.876920: Current learning rate: 0.00982
2024-08-12 18:15:26.396351: Validation loss improved from -0.44898 to -0.46362! Patience: 11/50
2024-08-12 18:15:26.397866: train_loss -0.6938
2024-08-12 18:15:26.399733: val_loss -0.4636
2024-08-12 18:15:26.401361: Pseudo dice [0.7059]
2024-08-12 18:15:26.403188: Epoch time: 460.52 s
2024-08-12 18:15:26.404406: Yayy! New best EMA pseudo Dice: 0.6666
2024-08-12 18:15:28.261798: 
2024-08-12 18:15:28.263367: Epoch 21
2024-08-12 18:15:28.264709: Current learning rate: 0.00981
2024-08-12 18:22:58.037408: Validation loss did not improve from -0.46362. Patience: 1/50
2024-08-12 18:22:58.039062: train_loss -0.7087
2024-08-12 18:22:58.040551: val_loss -0.4196
2024-08-12 18:22:58.041777: Pseudo dice [0.691]
2024-08-12 18:22:58.042921: Epoch time: 449.78 s
2024-08-12 18:22:58.043890: Yayy! New best EMA pseudo Dice: 0.6691
2024-08-12 18:22:59.886035: 
2024-08-12 18:22:59.887826: Epoch 22
2024-08-12 18:22:59.889132: Current learning rate: 0.0098
2024-08-12 18:31:26.498820: Validation loss did not improve from -0.46362. Patience: 2/50
2024-08-12 18:31:26.500460: train_loss -0.7016
2024-08-12 18:31:26.501813: val_loss -0.4384
2024-08-12 18:31:26.503072: Pseudo dice [0.6976]
2024-08-12 18:31:26.506484: Epoch time: 506.62 s
2024-08-12 18:31:26.508314: Yayy! New best EMA pseudo Dice: 0.6719
2024-08-12 18:31:28.327183: 
2024-08-12 18:31:28.328797: Epoch 23
2024-08-12 18:31:28.330013: Current learning rate: 0.00979
2024-08-12 18:39:38.046277: Validation loss did not improve from -0.46362. Patience: 3/50
2024-08-12 18:39:38.047837: train_loss -0.7036
2024-08-12 18:39:38.049052: val_loss -0.3812
2024-08-12 18:39:38.050283: Pseudo dice [0.6777]
2024-08-12 18:39:38.051567: Epoch time: 489.72 s
2024-08-12 18:39:38.052640: Yayy! New best EMA pseudo Dice: 0.6725
2024-08-12 18:39:39.797890: 
2024-08-12 18:39:39.799586: Epoch 24
2024-08-12 18:39:39.800676: Current learning rate: 0.00978
2024-08-12 18:48:06.116868: Validation loss did not improve from -0.46362. Patience: 4/50
2024-08-12 18:48:06.118346: train_loss -0.7045
2024-08-12 18:48:06.120345: val_loss -0.4484
2024-08-12 18:48:06.121742: Pseudo dice [0.7052]
2024-08-12 18:48:06.123543: Epoch time: 506.32 s
2024-08-12 18:48:06.506855: Yayy! New best EMA pseudo Dice: 0.6758
2024-08-12 18:48:08.399335: 
2024-08-12 18:48:08.400894: Epoch 25
2024-08-12 18:48:08.402009: Current learning rate: 0.00977
2024-08-12 18:56:36.571959: Validation loss did not improve from -0.46362. Patience: 5/50
2024-08-12 18:56:36.573411: train_loss -0.716
2024-08-12 18:56:36.574822: val_loss -0.4585
2024-08-12 18:56:36.576094: Pseudo dice [0.7102]
2024-08-12 18:56:36.577250: Epoch time: 508.18 s
2024-08-12 18:56:36.578327: Yayy! New best EMA pseudo Dice: 0.6792
2024-08-12 18:56:38.365162: 
2024-08-12 18:56:38.366778: Epoch 26
2024-08-12 18:56:38.367897: Current learning rate: 0.00977
2024-08-12 19:05:28.117642: Validation loss did not improve from -0.46362. Patience: 6/50
2024-08-12 19:05:28.118995: train_loss -0.7214
2024-08-12 19:05:28.120273: val_loss -0.3777
2024-08-12 19:05:28.121570: Pseudo dice [0.6727]
2024-08-12 19:05:28.122874: Epoch time: 529.76 s
2024-08-12 19:05:29.531806: 
2024-08-12 19:05:29.533759: Epoch 27
2024-08-12 19:05:29.535156: Current learning rate: 0.00976
2024-08-12 19:13:29.650845: Validation loss did not improve from -0.46362. Patience: 7/50
2024-08-12 19:13:29.654717: train_loss -0.7189
2024-08-12 19:13:29.692360: val_loss -0.4228
2024-08-12 19:13:29.694866: Pseudo dice [0.6986]
2024-08-12 19:13:29.699346: Epoch time: 480.12 s
2024-08-12 19:13:29.701432: Yayy! New best EMA pseudo Dice: 0.6806
2024-08-12 19:13:31.718755: 
2024-08-12 19:13:31.721267: Epoch 28
2024-08-12 19:13:31.722557: Current learning rate: 0.00975
2024-08-12 19:19:37.891130: Validation loss did not improve from -0.46362. Patience: 8/50
2024-08-12 19:19:37.892747: train_loss -0.729
2024-08-12 19:19:37.893969: val_loss -0.3681
2024-08-12 19:19:37.895121: Pseudo dice [0.6707]
2024-08-12 19:19:37.896486: Epoch time: 366.18 s
2024-08-12 19:19:39.366102: 
2024-08-12 19:19:39.368425: Epoch 29
2024-08-12 19:19:39.369912: Current learning rate: 0.00974
2024-08-12 19:28:24.805333: Validation loss did not improve from -0.46362. Patience: 9/50
2024-08-12 19:28:24.806976: train_loss -0.7321
2024-08-12 19:28:24.808271: val_loss -0.4034
2024-08-12 19:28:24.809516: Pseudo dice [0.6751]
2024-08-12 19:28:24.810746: Epoch time: 525.44 s
2024-08-12 19:28:26.712509: 
2024-08-12 19:28:26.714578: Epoch 30
2024-08-12 19:28:26.716316: Current learning rate: 0.00973
2024-08-12 19:35:36.030729: Validation loss did not improve from -0.46362. Patience: 10/50
2024-08-12 19:35:36.032296: train_loss -0.7356
2024-08-12 19:35:36.033659: val_loss -0.3877
2024-08-12 19:35:36.034748: Pseudo dice [0.6619]
2024-08-12 19:35:36.035888: Epoch time: 429.32 s
2024-08-12 19:35:37.441917: 
2024-08-12 19:35:37.443805: Epoch 31
2024-08-12 19:35:37.445233: Current learning rate: 0.00972
2024-08-12 19:43:54.195921: Validation loss did not improve from -0.46362. Patience: 11/50
2024-08-12 19:43:54.197515: train_loss -0.7372
2024-08-12 19:43:54.198971: val_loss -0.3858
2024-08-12 19:43:54.200372: Pseudo dice [0.6894]
2024-08-12 19:43:54.201880: Epoch time: 496.76 s
2024-08-12 19:43:56.087296: 
2024-08-12 19:43:56.089365: Epoch 32
2024-08-12 19:43:56.090737: Current learning rate: 0.00971
2024-08-12 19:49:44.497545: Validation loss did not improve from -0.46362. Patience: 12/50
2024-08-12 19:49:44.499597: train_loss -0.7407
2024-08-12 19:49:44.502595: val_loss -0.4074
2024-08-12 19:49:44.504895: Pseudo dice [0.6762]
2024-08-12 19:49:44.506797: Epoch time: 348.41 s
2024-08-12 19:49:45.912394: 
2024-08-12 19:49:45.913928: Epoch 33
2024-08-12 19:49:45.915266: Current learning rate: 0.0097
2024-08-12 19:56:14.944319: Validation loss did not improve from -0.46362. Patience: 13/50
2024-08-12 19:56:14.945576: train_loss -0.7405
2024-08-12 19:56:14.947406: val_loss -0.3034
2024-08-12 19:56:14.948750: Pseudo dice [0.647]
2024-08-12 19:56:14.949852: Epoch time: 389.04 s
2024-08-12 19:56:16.434224: 
2024-08-12 19:56:16.436255: Epoch 34
2024-08-12 19:56:16.437490: Current learning rate: 0.00969
2024-08-12 20:03:39.179952: Validation loss did not improve from -0.46362. Patience: 14/50
2024-08-12 20:03:39.181147: train_loss -0.7409
2024-08-12 20:03:39.182307: val_loss -0.3801
2024-08-12 20:03:39.183591: Pseudo dice [0.6659]
2024-08-12 20:03:39.184850: Epoch time: 442.75 s
2024-08-12 20:03:41.081713: 
2024-08-12 20:03:41.083530: Epoch 35
2024-08-12 20:03:41.084898: Current learning rate: 0.00968
2024-08-12 20:10:41.474968: Validation loss did not improve from -0.46362. Patience: 15/50
2024-08-12 20:10:41.476277: train_loss -0.7471
2024-08-12 20:10:41.477623: val_loss -0.4129
2024-08-12 20:10:41.478951: Pseudo dice [0.6966]
2024-08-12 20:10:41.480192: Epoch time: 420.4 s
2024-08-12 20:10:42.945663: 
2024-08-12 20:10:42.947688: Epoch 36
2024-08-12 20:10:42.949006: Current learning rate: 0.00968
2024-08-12 20:18:36.775109: Validation loss did not improve from -0.46362. Patience: 16/50
2024-08-12 20:18:36.777970: train_loss -0.75
2024-08-12 20:18:36.779516: val_loss -0.3909
2024-08-12 20:18:36.780794: Pseudo dice [0.6753]
2024-08-12 20:18:36.781936: Epoch time: 473.83 s
2024-08-12 20:18:38.244614: 
2024-08-12 20:18:38.246411: Epoch 37
2024-08-12 20:18:38.247592: Current learning rate: 0.00967
2024-08-12 20:24:37.993053: Validation loss did not improve from -0.46362. Patience: 17/50
2024-08-12 20:24:37.994533: train_loss -0.7504
2024-08-12 20:24:37.995969: val_loss -0.406
2024-08-12 20:24:37.997098: Pseudo dice [0.6869]
2024-08-12 20:24:37.998308: Epoch time: 359.75 s
2024-08-12 20:24:39.430927: 
2024-08-12 20:24:39.432422: Epoch 38
2024-08-12 20:24:39.433585: Current learning rate: 0.00966
2024-08-12 20:28:54.849870: Validation loss did not improve from -0.46362. Patience: 18/50
2024-08-12 20:28:54.851497: train_loss -0.7573
2024-08-12 20:28:54.853059: val_loss -0.424
2024-08-12 20:28:54.854558: Pseudo dice [0.6958]
2024-08-12 20:28:54.855710: Epoch time: 255.42 s
2024-08-12 20:28:56.353063: 
2024-08-12 20:28:56.354944: Epoch 39
2024-08-12 20:28:56.356629: Current learning rate: 0.00965
2024-08-12 20:30:37.931005: Validation loss improved from -0.46362 to -0.49507! Patience: 18/50
2024-08-12 20:30:37.932494: train_loss -0.7582
2024-08-12 20:30:37.933635: val_loss -0.4951
2024-08-12 20:30:37.934633: Pseudo dice [0.7325]
2024-08-12 20:30:37.935640: Epoch time: 101.58 s
2024-08-12 20:30:38.422163: Yayy! New best EMA pseudo Dice: 0.6846
2024-08-12 20:30:40.378238: 
2024-08-12 20:30:40.380229: Epoch 40
2024-08-12 20:30:40.381449: Current learning rate: 0.00964
2024-08-12 20:34:36.787528: Validation loss did not improve from -0.49507. Patience: 1/50
2024-08-12 20:34:36.789184: train_loss -0.7634
2024-08-12 20:34:36.790781: val_loss -0.4076
2024-08-12 20:34:36.791845: Pseudo dice [0.6859]
2024-08-12 20:34:36.792938: Epoch time: 236.41 s
2024-08-12 20:34:36.793949: Yayy! New best EMA pseudo Dice: 0.6847
2024-08-12 20:34:38.968267: 
2024-08-12 20:34:38.969887: Epoch 41
2024-08-12 20:34:38.971008: Current learning rate: 0.00963
2024-08-12 20:38:59.679054: Validation loss did not improve from -0.49507. Patience: 2/50
2024-08-12 20:38:59.681133: train_loss -0.7677
2024-08-12 20:38:59.682727: val_loss -0.3606
2024-08-12 20:38:59.690735: Pseudo dice [0.6708]
2024-08-12 20:38:59.692301: Epoch time: 260.71 s
2024-08-12 20:39:01.113125: 
2024-08-12 20:39:01.116476: Epoch 42
2024-08-12 20:39:01.118400: Current learning rate: 0.00962
2024-08-12 20:41:30.900117: Validation loss did not improve from -0.49507. Patience: 3/50
2024-08-12 20:41:30.901209: train_loss -0.7635
2024-08-12 20:41:30.902241: val_loss -0.3639
2024-08-12 20:41:30.903185: Pseudo dice [0.6754]
2024-08-12 20:41:30.904213: Epoch time: 149.79 s
2024-08-12 20:41:35.426736: 
2024-08-12 20:41:35.428087: Epoch 43
2024-08-12 20:41:35.429065: Current learning rate: 0.00961
2024-08-12 20:46:28.244703: Validation loss did not improve from -0.49507. Patience: 4/50
2024-08-12 20:46:28.246162: train_loss -0.7668
2024-08-12 20:46:28.247370: val_loss -0.3942
2024-08-12 20:46:28.248472: Pseudo dice [0.6779]
2024-08-12 20:46:28.249928: Epoch time: 292.82 s
2024-08-12 20:46:29.636989: 
2024-08-12 20:46:29.639528: Epoch 44
2024-08-12 20:46:29.641714: Current learning rate: 0.0096
2024-08-12 20:48:21.721377: Validation loss did not improve from -0.49507. Patience: 5/50
2024-08-12 20:48:21.722774: train_loss -0.7663
2024-08-12 20:48:21.724087: val_loss -0.4359
2024-08-12 20:48:21.725330: Pseudo dice [0.6939]
2024-08-12 20:48:21.726636: Epoch time: 112.09 s
2024-08-12 20:48:23.602783: 
2024-08-12 20:48:23.605572: Epoch 45
2024-08-12 20:48:23.607431: Current learning rate: 0.00959
2024-08-12 20:52:15.362981: Validation loss did not improve from -0.49507. Patience: 6/50
2024-08-12 20:52:15.364174: train_loss -0.7664
2024-08-12 20:52:15.365453: val_loss -0.3228
2024-08-12 20:52:15.366528: Pseudo dice [0.6516]
2024-08-12 20:52:15.367604: Epoch time: 231.76 s
2024-08-12 20:52:16.764078: 
2024-08-12 20:52:16.765452: Epoch 46
2024-08-12 20:52:16.766745: Current learning rate: 0.00959
2024-08-12 20:56:19.422534: Validation loss did not improve from -0.49507. Patience: 7/50
2024-08-12 20:56:19.423976: train_loss -0.7713
2024-08-12 20:56:19.425305: val_loss -0.466
2024-08-12 20:56:19.426684: Pseudo dice [0.7181]
2024-08-12 20:56:19.428334: Epoch time: 242.66 s
2024-08-12 20:56:20.829770: 
2024-08-12 20:56:20.832275: Epoch 47
2024-08-12 20:56:20.834345: Current learning rate: 0.00958
2024-08-12 20:58:54.641365: Validation loss did not improve from -0.49507. Patience: 8/50
2024-08-12 20:58:54.642789: train_loss -0.7751
2024-08-12 20:58:54.644221: val_loss -0.4455
2024-08-12 20:58:54.645536: Pseudo dice [0.7056]
2024-08-12 20:58:54.646773: Epoch time: 153.81 s
2024-08-12 20:58:54.647845: Yayy! New best EMA pseudo Dice: 0.6861
2024-08-12 20:58:56.422932: 
2024-08-12 20:58:56.424659: Epoch 48
2024-08-12 20:58:56.425863: Current learning rate: 0.00957
2024-08-12 21:03:50.266934: Validation loss did not improve from -0.49507. Patience: 9/50
2024-08-12 21:03:50.268164: train_loss -0.7761
2024-08-12 21:03:50.269608: val_loss -0.4054
2024-08-12 21:03:50.270829: Pseudo dice [0.715]
2024-08-12 21:03:50.271990: Epoch time: 293.85 s
2024-08-12 21:03:50.273036: Yayy! New best EMA pseudo Dice: 0.689
2024-08-12 21:03:52.084435: 
2024-08-12 21:03:52.087740: Epoch 49
2024-08-12 21:03:52.089168: Current learning rate: 0.00956
2024-08-12 21:05:45.615536: Validation loss did not improve from -0.49507. Patience: 10/50
2024-08-12 21:05:45.616956: train_loss -0.7785
2024-08-12 21:05:45.618482: val_loss -0.425
2024-08-12 21:05:45.619929: Pseudo dice [0.6998]
2024-08-12 21:05:45.621212: Epoch time: 113.53 s
2024-08-12 21:05:46.029547: Yayy! New best EMA pseudo Dice: 0.69
2024-08-12 21:05:47.893891: 
2024-08-12 21:05:47.895398: Epoch 50
2024-08-12 21:05:47.896574: Current learning rate: 0.00955
2024-08-12 21:09:55.440200: Validation loss did not improve from -0.49507. Patience: 11/50
2024-08-12 21:09:55.441602: train_loss -0.7808
2024-08-12 21:09:55.442937: val_loss -0.375
2024-08-12 21:09:55.444153: Pseudo dice [0.6753]
2024-08-12 21:09:55.445274: Epoch time: 247.55 s
2024-08-12 21:09:56.877803: 
2024-08-12 21:09:56.880301: Epoch 51
2024-08-12 21:09:56.881788: Current learning rate: 0.00954
2024-08-12 21:14:12.597322: Validation loss did not improve from -0.49507. Patience: 12/50
2024-08-12 21:14:12.598762: train_loss -0.7821
2024-08-12 21:14:12.600198: val_loss -0.2876
2024-08-12 21:14:12.601499: Pseudo dice [0.63]
2024-08-12 21:14:12.602852: Epoch time: 255.72 s
2024-08-12 21:14:14.164695: 
2024-08-12 21:14:14.166121: Epoch 52
2024-08-12 21:14:14.167347: Current learning rate: 0.00953
2024-08-12 21:16:16.470976: Validation loss did not improve from -0.49507. Patience: 13/50
2024-08-12 21:16:16.472243: train_loss -0.7787
2024-08-12 21:16:16.473481: val_loss -0.4443
2024-08-12 21:16:16.474756: Pseudo dice [0.7165]
2024-08-12 21:16:16.475948: Epoch time: 122.31 s
2024-08-12 21:16:17.973981: 
2024-08-12 21:16:17.976396: Epoch 53
2024-08-12 21:16:17.978824: Current learning rate: 0.00952
2024-08-12 21:20:41.426409: Validation loss improved from -0.49507 to -0.49552! Patience: 13/50
2024-08-12 21:20:41.428974: train_loss -0.7828
2024-08-12 21:20:41.430326: val_loss -0.4955
2024-08-12 21:20:41.431661: Pseudo dice [0.735]
2024-08-12 21:20:41.432774: Epoch time: 263.46 s
2024-08-12 21:20:41.433829: Yayy! New best EMA pseudo Dice: 0.691
2024-08-12 21:20:43.435895: 
2024-08-12 21:20:43.437359: Epoch 54
2024-08-12 21:20:43.438630: Current learning rate: 0.00951
2024-08-12 21:24:15.085630: Validation loss did not improve from -0.49552. Patience: 1/50
2024-08-12 21:24:15.087958: train_loss -0.7872
2024-08-12 21:24:15.090989: val_loss -0.3509
2024-08-12 21:24:15.092513: Pseudo dice [0.6731]
2024-08-12 21:24:15.094240: Epoch time: 211.65 s
2024-08-12 21:24:17.771540: 
2024-08-12 21:24:17.773283: Epoch 55
2024-08-12 21:24:17.774601: Current learning rate: 0.0095
2024-08-12 21:27:51.368463: Validation loss did not improve from -0.49552. Patience: 2/50
2024-08-12 21:27:51.369674: train_loss -0.7824
2024-08-12 21:27:51.370853: val_loss -0.3703
2024-08-12 21:27:51.371952: Pseudo dice [0.6746]
2024-08-12 21:27:51.373436: Epoch time: 213.6 s
2024-08-12 21:27:52.856184: 
2024-08-12 21:27:52.857840: Epoch 56
2024-08-12 21:27:52.859254: Current learning rate: 0.00949
2024-08-12 21:29:29.808031: Validation loss did not improve from -0.49552. Patience: 3/50
2024-08-12 21:29:29.810217: train_loss -0.7866
2024-08-12 21:29:29.812575: val_loss -0.3623
2024-08-12 21:29:29.814520: Pseudo dice [0.6732]
2024-08-12 21:29:29.815999: Epoch time: 96.96 s
2024-08-12 21:29:31.452522: 
2024-08-12 21:29:31.454232: Epoch 57
2024-08-12 21:29:31.455564: Current learning rate: 0.00949
2024-08-12 21:31:42.620554: Validation loss did not improve from -0.49552. Patience: 4/50
2024-08-12 21:31:42.622295: train_loss -0.7918
2024-08-12 21:31:42.624041: val_loss -0.4251
2024-08-12 21:31:42.625454: Pseudo dice [0.7062]
2024-08-12 21:31:42.626926: Epoch time: 131.17 s
2024-08-12 21:31:44.065799: 
2024-08-12 21:31:44.067531: Epoch 58
2024-08-12 21:31:44.068785: Current learning rate: 0.00948
2024-08-12 21:33:52.646344: Validation loss did not improve from -0.49552. Patience: 5/50
2024-08-12 21:33:52.647911: train_loss -0.7931
2024-08-12 21:33:52.649483: val_loss -0.4516
2024-08-12 21:33:52.650792: Pseudo dice [0.7285]
2024-08-12 21:33:52.651864: Epoch time: 128.58 s
2024-08-12 21:33:52.653218: Yayy! New best EMA pseudo Dice: 0.6923
2024-08-12 21:33:54.485475: 
2024-08-12 21:33:54.487289: Epoch 59
2024-08-12 21:33:54.488534: Current learning rate: 0.00947
2024-08-12 21:35:36.720204: Validation loss did not improve from -0.49552. Patience: 6/50
2024-08-12 21:35:36.721722: train_loss -0.7899
2024-08-12 21:35:36.723082: val_loss -0.444
2024-08-12 21:35:36.724204: Pseudo dice [0.7339]
2024-08-12 21:35:36.725311: Epoch time: 102.24 s
2024-08-12 21:35:37.140525: Yayy! New best EMA pseudo Dice: 0.6965
2024-08-12 21:35:39.002761: 
2024-08-12 21:35:39.004024: Epoch 60
2024-08-12 21:35:39.005040: Current learning rate: 0.00946
2024-08-12 21:38:12.824797: Validation loss did not improve from -0.49552. Patience: 7/50
2024-08-12 21:38:12.826190: train_loss -0.786
2024-08-12 21:38:12.827380: val_loss -0.4429
2024-08-12 21:38:12.828546: Pseudo dice [0.7095]
2024-08-12 21:38:12.829747: Epoch time: 153.83 s
2024-08-12 21:38:12.830787: Yayy! New best EMA pseudo Dice: 0.6978
2024-08-12 21:38:14.718138: 
2024-08-12 21:38:14.720003: Epoch 61
2024-08-12 21:38:14.721343: Current learning rate: 0.00945
2024-08-12 21:39:51.591975: Validation loss did not improve from -0.49552. Patience: 8/50
2024-08-12 21:39:51.593229: train_loss -0.7918
2024-08-12 21:39:51.594570: val_loss -0.34
2024-08-12 21:39:51.595894: Pseudo dice [0.6647]
2024-08-12 21:39:51.597017: Epoch time: 96.88 s
2024-08-12 21:39:53.130582: 
2024-08-12 21:39:53.131888: Epoch 62
2024-08-12 21:39:53.133170: Current learning rate: 0.00944
2024-08-12 21:41:47.898378: Validation loss did not improve from -0.49552. Patience: 9/50
2024-08-12 21:41:47.899860: train_loss -0.7952
2024-08-12 21:41:47.901266: val_loss -0.3485
2024-08-12 21:41:47.902506: Pseudo dice [0.6623]
2024-08-12 21:41:47.903780: Epoch time: 114.77 s
2024-08-12 21:41:49.376774: 
2024-08-12 21:41:49.378298: Epoch 63
2024-08-12 21:41:49.379369: Current learning rate: 0.00943
2024-08-12 21:44:11.542670: Validation loss did not improve from -0.49552. Patience: 10/50
2024-08-12 21:44:11.544137: train_loss -0.7984
2024-08-12 21:44:11.545316: val_loss -0.4364
2024-08-12 21:44:11.546499: Pseudo dice [0.7108]
2024-08-12 21:44:11.548077: Epoch time: 142.17 s
2024-08-12 21:44:13.083261: 
2024-08-12 21:44:13.084920: Epoch 64
2024-08-12 21:44:13.086001: Current learning rate: 0.00942
2024-08-12 21:45:49.948396: Validation loss did not improve from -0.49552. Patience: 11/50
2024-08-12 21:45:49.949656: train_loss -0.7967
2024-08-12 21:45:49.950902: val_loss -0.4555
2024-08-12 21:45:49.952203: Pseudo dice [0.7248]
2024-08-12 21:45:49.953359: Epoch time: 96.87 s
2024-08-12 21:45:51.798612: 
2024-08-12 21:45:51.800296: Epoch 65
2024-08-12 21:45:51.801364: Current learning rate: 0.00941
2024-08-12 21:47:59.755740: Validation loss did not improve from -0.49552. Patience: 12/50
2024-08-12 21:47:59.757288: train_loss -0.7967
2024-08-12 21:47:59.758445: val_loss -0.3877
2024-08-12 21:47:59.759467: Pseudo dice [0.7]
2024-08-12 21:47:59.760768: Epoch time: 127.96 s
2024-08-12 21:48:01.865740: 
2024-08-12 21:48:01.867337: Epoch 66
2024-08-12 21:48:01.868461: Current learning rate: 0.0094
2024-08-12 21:50:05.279958: Validation loss did not improve from -0.49552. Patience: 13/50
2024-08-12 21:50:05.281183: train_loss -0.7985
2024-08-12 21:50:05.282328: val_loss -0.4308
2024-08-12 21:50:05.283301: Pseudo dice [0.7064]
2024-08-12 21:50:05.284287: Epoch time: 123.42 s
2024-08-12 21:50:06.744715: 
2024-08-12 21:50:06.746367: Epoch 67
2024-08-12 21:50:06.747521: Current learning rate: 0.00939
2024-08-12 21:51:44.616460: Validation loss did not improve from -0.49552. Patience: 14/50
2024-08-12 21:51:44.617736: train_loss -0.7973
2024-08-12 21:51:44.619131: val_loss -0.3307
2024-08-12 21:51:44.620534: Pseudo dice [0.6571]
2024-08-12 21:51:44.621726: Epoch time: 97.87 s
2024-08-12 21:51:46.171556: 
2024-08-12 21:51:46.172833: Epoch 68
2024-08-12 21:51:46.173844: Current learning rate: 0.00939
2024-08-12 21:54:11.706150: Validation loss did not improve from -0.49552. Patience: 15/50
2024-08-12 21:54:11.707781: train_loss -0.7971
2024-08-12 21:54:11.764114: val_loss -0.3647
2024-08-12 21:54:11.765502: Pseudo dice [0.6856]
2024-08-12 21:54:11.766703: Epoch time: 145.54 s
2024-08-12 21:54:13.239065: 
2024-08-12 21:54:13.240469: Epoch 69
2024-08-12 21:54:13.241536: Current learning rate: 0.00938
2024-08-12 21:56:03.289541: Validation loss did not improve from -0.49552. Patience: 16/50
2024-08-12 21:56:03.291193: train_loss -0.7975
2024-08-12 21:56:03.295084: val_loss -0.4274
2024-08-12 21:56:03.296382: Pseudo dice [0.7141]
2024-08-12 21:56:03.297631: Epoch time: 110.05 s
2024-08-12 21:56:05.212668: 
2024-08-12 21:56:05.214701: Epoch 70
2024-08-12 21:56:05.215975: Current learning rate: 0.00937
2024-08-12 21:57:47.166668: Validation loss did not improve from -0.49552. Patience: 17/50
2024-08-12 21:57:47.168559: train_loss -0.7991
2024-08-12 21:57:47.170570: val_loss -0.434
2024-08-12 21:57:47.171843: Pseudo dice [0.714]
2024-08-12 21:57:47.173189: Epoch time: 101.96 s
2024-08-12 21:57:48.777970: 
2024-08-12 21:57:48.779371: Epoch 71
2024-08-12 21:57:48.780765: Current learning rate: 0.00936
2024-08-12 22:00:15.341210: Validation loss did not improve from -0.49552. Patience: 18/50
2024-08-12 22:00:15.342849: train_loss -0.807
2024-08-12 22:00:15.344709: val_loss -0.4633
2024-08-12 22:00:15.345954: Pseudo dice [0.7313]
2024-08-12 22:00:15.347353: Epoch time: 146.57 s
2024-08-12 22:00:15.348714: Yayy! New best EMA pseudo Dice: 0.7003
2024-08-12 22:00:17.348713: 
2024-08-12 22:00:17.351134: Epoch 72
2024-08-12 22:00:17.352914: Current learning rate: 0.00935
2024-08-12 22:01:59.772112: Validation loss did not improve from -0.49552. Patience: 19/50
2024-08-12 22:01:59.773242: train_loss -0.8074
2024-08-12 22:01:59.774312: val_loss -0.3304
2024-08-12 22:01:59.775267: Pseudo dice [0.6761]
2024-08-12 22:01:59.776310: Epoch time: 102.43 s
2024-08-12 22:02:01.293710: 
2024-08-12 22:02:01.295226: Epoch 73
2024-08-12 22:02:01.296266: Current learning rate: 0.00934
2024-08-12 22:03:49.377036: Validation loss did not improve from -0.49552. Patience: 20/50
2024-08-12 22:03:49.378406: train_loss -0.8092
2024-08-12 22:03:49.379567: val_loss -0.4873
2024-08-12 22:03:49.380526: Pseudo dice [0.7397]
2024-08-12 22:03:49.381585: Epoch time: 108.09 s
2024-08-12 22:03:49.382671: Yayy! New best EMA pseudo Dice: 0.702
2024-08-12 22:03:51.266879: 
2024-08-12 22:03:51.268429: Epoch 74
2024-08-12 22:03:51.269619: Current learning rate: 0.00933
2024-08-12 22:06:24.268359: Validation loss did not improve from -0.49552. Patience: 21/50
2024-08-12 22:06:24.269919: train_loss -0.8099
2024-08-12 22:06:24.299780: val_loss -0.4003
2024-08-12 22:06:24.300828: Pseudo dice [0.6981]
2024-08-12 22:06:24.301818: Epoch time: 153.0 s
2024-08-12 22:06:26.231339: 
2024-08-12 22:06:26.233032: Epoch 75
2024-08-12 22:06:26.234251: Current learning rate: 0.00932
2024-08-12 22:08:03.416394: Validation loss did not improve from -0.49552. Patience: 22/50
2024-08-12 22:08:03.417828: train_loss -0.8078
2024-08-12 22:08:03.418946: val_loss -0.2977
2024-08-12 22:08:03.419893: Pseudo dice [0.6435]
2024-08-12 22:08:03.420899: Epoch time: 97.19 s
2024-08-12 22:08:04.914881: 
2024-08-12 22:08:04.916272: Epoch 76
2024-08-12 22:08:04.917503: Current learning rate: 0.00931
2024-08-12 22:10:18.052707: Validation loss did not improve from -0.49552. Patience: 23/50
2024-08-12 22:10:18.054227: train_loss -0.8038
2024-08-12 22:10:18.055480: val_loss -0.3952
2024-08-12 22:10:18.056595: Pseudo dice [0.6889]
2024-08-12 22:10:18.057597: Epoch time: 133.14 s
2024-08-12 22:10:19.977962: 
2024-08-12 22:10:19.979346: Epoch 77
2024-08-12 22:10:19.980516: Current learning rate: 0.0093
2024-08-12 22:12:24.912848: Validation loss did not improve from -0.49552. Patience: 24/50
2024-08-12 22:12:24.914018: train_loss -0.8097
2024-08-12 22:12:24.915266: val_loss -0.449
2024-08-12 22:12:24.916301: Pseudo dice [0.7392]
2024-08-12 22:12:24.917412: Epoch time: 124.94 s
2024-08-12 22:12:26.420829: 
2024-08-12 22:12:26.422507: Epoch 78
2024-08-12 22:12:26.423634: Current learning rate: 0.0093
2024-08-12 22:14:17.216544: Validation loss did not improve from -0.49552. Patience: 25/50
2024-08-12 22:14:17.218559: train_loss -0.8083
2024-08-12 22:14:17.224344: val_loss -0.4082
2024-08-12 22:14:17.231331: Pseudo dice [0.7101]
2024-08-12 22:14:17.233500: Epoch time: 110.8 s
2024-08-12 22:14:18.806052: 
2024-08-12 22:14:18.808321: Epoch 79
2024-08-12 22:14:18.809584: Current learning rate: 0.00929
2024-08-12 22:16:39.975924: Validation loss did not improve from -0.49552. Patience: 26/50
2024-08-12 22:16:39.977649: train_loss -0.8111
2024-08-12 22:16:39.979389: val_loss -0.4393
2024-08-12 22:16:39.980749: Pseudo dice [0.7249]
2024-08-12 22:16:39.982182: Epoch time: 141.18 s
2024-08-12 22:16:40.406272: Yayy! New best EMA pseudo Dice: 0.703
2024-08-12 22:16:42.412633: 
2024-08-12 22:16:42.414532: Epoch 80
2024-08-12 22:16:42.415829: Current learning rate: 0.00928
2024-08-12 22:18:38.996941: Validation loss did not improve from -0.49552. Patience: 27/50
2024-08-12 22:18:38.998053: train_loss -0.8129
2024-08-12 22:18:38.999093: val_loss -0.412
2024-08-12 22:18:39.000080: Pseudo dice [0.7175]
2024-08-12 22:18:39.001151: Epoch time: 116.59 s
2024-08-12 22:18:39.002077: Yayy! New best EMA pseudo Dice: 0.7045
2024-08-12 22:18:40.950946: 
2024-08-12 22:18:40.952491: Epoch 81
2024-08-12 22:18:40.953693: Current learning rate: 0.00927
2024-08-12 22:20:22.123406: Validation loss did not improve from -0.49552. Patience: 28/50
2024-08-12 22:20:22.124988: train_loss -0.8131
2024-08-12 22:20:22.126631: val_loss -0.4219
2024-08-12 22:20:22.128182: Pseudo dice [0.7053]
2024-08-12 22:20:22.129738: Epoch time: 101.18 s
2024-08-12 22:20:22.131245: Yayy! New best EMA pseudo Dice: 0.7046
2024-08-12 22:20:24.049711: 
2024-08-12 22:20:24.051395: Epoch 82
2024-08-12 22:20:24.052681: Current learning rate: 0.00926
2024-08-12 22:22:56.195613: Validation loss did not improve from -0.49552. Patience: 29/50
2024-08-12 22:22:56.196685: train_loss -0.8133
2024-08-12 22:22:56.197922: val_loss -0.4233
2024-08-12 22:22:56.199005: Pseudo dice [0.7179]
2024-08-12 22:22:56.200152: Epoch time: 152.15 s
2024-08-12 22:22:56.201321: Yayy! New best EMA pseudo Dice: 0.7059
2024-08-12 22:22:58.089319: 
2024-08-12 22:22:58.091062: Epoch 83
2024-08-12 22:22:58.092409: Current learning rate: 0.00925
2024-08-12 22:24:38.397592: Validation loss did not improve from -0.49552. Patience: 30/50
2024-08-12 22:24:38.409723: train_loss -0.8148
2024-08-12 22:24:38.410914: val_loss -0.41
2024-08-12 22:24:38.412186: Pseudo dice [0.7144]
2024-08-12 22:24:38.413330: Epoch time: 100.32 s
2024-08-12 22:24:38.414456: Yayy! New best EMA pseudo Dice: 0.7067
2024-08-12 22:24:40.501606: 
2024-08-12 22:24:40.503084: Epoch 84
2024-08-12 22:24:40.504156: Current learning rate: 0.00924
2024-08-12 22:26:33.326019: Validation loss did not improve from -0.49552. Patience: 31/50
2024-08-12 22:26:33.327500: train_loss -0.8122
2024-08-12 22:26:33.328778: val_loss -0.3686
2024-08-12 22:26:33.329891: Pseudo dice [0.6896]
2024-08-12 22:26:33.331144: Epoch time: 112.83 s
2024-08-12 22:26:35.120267: 
2024-08-12 22:26:35.121806: Epoch 85
2024-08-12 22:26:35.123089: Current learning rate: 0.00923
2024-08-12 22:28:55.039316: Validation loss did not improve from -0.49552. Patience: 32/50
2024-08-12 22:28:55.040965: train_loss -0.8145
2024-08-12 22:28:55.042209: val_loss -0.3675
2024-08-12 22:28:55.043224: Pseudo dice [0.7001]
2024-08-12 22:28:55.044410: Epoch time: 139.92 s
2024-08-12 22:28:56.483677: 
2024-08-12 22:28:56.485189: Epoch 86
2024-08-12 22:28:56.486281: Current learning rate: 0.00922
2024-08-12 22:30:33.694291: Validation loss did not improve from -0.49552. Patience: 33/50
2024-08-12 22:30:33.695691: train_loss -0.8149
2024-08-12 22:30:33.697415: val_loss -0.3805
2024-08-12 22:30:33.698881: Pseudo dice [0.6949]
2024-08-12 22:30:33.700238: Epoch time: 97.21 s
2024-08-12 22:30:35.190489: 
2024-08-12 22:30:35.192110: Epoch 87
2024-08-12 22:30:35.202698: Current learning rate: 0.00921
2024-08-12 22:32:27.764309: Validation loss did not improve from -0.49552. Patience: 34/50
2024-08-12 22:32:27.765623: train_loss -0.8155
2024-08-12 22:32:27.766779: val_loss -0.3614
2024-08-12 22:32:27.767858: Pseudo dice [0.6802]
2024-08-12 22:32:27.768884: Epoch time: 112.58 s
2024-08-12 22:32:30.957788: 
2024-08-12 22:32:30.960073: Epoch 88
2024-08-12 22:32:30.961995: Current learning rate: 0.0092
2024-08-12 22:34:30.856873: Validation loss did not improve from -0.49552. Patience: 35/50
2024-08-12 22:34:30.858675: train_loss -0.8208
2024-08-12 22:34:30.860242: val_loss -0.3709
2024-08-12 22:34:30.862038: Pseudo dice [0.6996]
2024-08-12 22:34:30.863575: Epoch time: 119.9 s
2024-08-12 22:34:32.964506: 
2024-08-12 22:34:32.966150: Epoch 89
2024-08-12 22:34:32.967321: Current learning rate: 0.0092
2024-08-12 22:36:09.570576: Validation loss did not improve from -0.49552. Patience: 36/50
2024-08-12 22:36:09.572164: train_loss -0.8203
2024-08-12 22:36:09.573524: val_loss -0.4549
2024-08-12 22:36:09.574909: Pseudo dice [0.7295]
2024-08-12 22:36:09.576207: Epoch time: 96.61 s
2024-08-12 22:36:11.476758: 
2024-08-12 22:36:11.478537: Epoch 90
2024-08-12 22:36:11.480150: Current learning rate: 0.00919
2024-08-12 22:37:59.115387: Validation loss did not improve from -0.49552. Patience: 37/50
2024-08-12 22:37:59.116833: train_loss -0.8132
2024-08-12 22:37:59.118859: val_loss -0.4476
2024-08-12 22:37:59.120596: Pseudo dice [0.7304]
2024-08-12 22:37:59.122241: Epoch time: 107.64 s
2024-08-12 22:38:00.580162: 
2024-08-12 22:38:00.581839: Epoch 91
2024-08-12 22:38:00.583372: Current learning rate: 0.00918
2024-08-12 22:40:04.279856: Validation loss did not improve from -0.49552. Patience: 38/50
2024-08-12 22:40:04.281297: train_loss -0.816
2024-08-12 22:40:04.282760: val_loss -0.3436
2024-08-12 22:40:04.284023: Pseudo dice [0.7038]
2024-08-12 22:40:04.285819: Epoch time: 123.7 s
2024-08-12 22:40:05.843032: 
2024-08-12 22:40:05.844294: Epoch 92
2024-08-12 22:40:05.845595: Current learning rate: 0.00917
2024-08-12 22:41:46.786341: Validation loss did not improve from -0.49552. Patience: 39/50
2024-08-12 22:41:46.787691: train_loss -0.8206
2024-08-12 22:41:46.789171: val_loss -0.3042
2024-08-12 22:41:46.790437: Pseudo dice [0.669]
2024-08-12 22:41:46.791682: Epoch time: 100.95 s
2024-08-12 22:41:48.197106: 
2024-08-12 22:41:48.198989: Epoch 93
2024-08-12 22:41:48.200083: Current learning rate: 0.00916
2024-08-12 22:43:24.888158: Validation loss did not improve from -0.49552. Patience: 40/50
2024-08-12 22:43:24.889292: train_loss -0.8212
2024-08-12 22:43:24.890512: val_loss -0.3804
2024-08-12 22:43:24.891578: Pseudo dice [0.6935]
2024-08-12 22:43:24.893068: Epoch time: 96.69 s
2024-08-12 22:43:26.369058: 
2024-08-12 22:43:26.370402: Epoch 94
2024-08-12 22:43:26.371507: Current learning rate: 0.00915
2024-08-12 22:45:26.641659: Validation loss did not improve from -0.49552. Patience: 41/50
2024-08-12 22:45:26.643194: train_loss -0.8241
2024-08-12 22:45:26.644581: val_loss -0.4324
2024-08-12 22:45:26.645962: Pseudo dice [0.7184]
2024-08-12 22:45:26.647390: Epoch time: 120.28 s
2024-08-12 22:45:28.537413: 
2024-08-12 22:45:28.538904: Epoch 95
2024-08-12 22:45:28.540022: Current learning rate: 0.00914
2024-08-12 22:47:14.311404: Validation loss did not improve from -0.49552. Patience: 42/50
2024-08-12 22:47:14.312796: train_loss -0.8232
2024-08-12 22:47:14.314224: val_loss -0.3885
2024-08-12 22:47:14.315707: Pseudo dice [0.7099]
2024-08-12 22:47:14.317343: Epoch time: 105.78 s
2024-08-12 22:47:15.728822: 
2024-08-12 22:47:15.730191: Epoch 96
2024-08-12 22:47:15.731308: Current learning rate: 0.00913
2024-08-12 22:48:52.899685: Validation loss did not improve from -0.49552. Patience: 43/50
2024-08-12 22:48:52.900860: train_loss -0.8273
2024-08-12 22:48:52.901997: val_loss -0.3995
2024-08-12 22:48:52.902950: Pseudo dice [0.7079]
2024-08-12 22:48:52.903882: Epoch time: 97.17 s
2024-08-12 22:48:54.351896: 
2024-08-12 22:48:54.354818: Epoch 97
2024-08-12 22:48:54.356517: Current learning rate: 0.00912
2024-08-12 22:50:49.238266: Validation loss did not improve from -0.49552. Patience: 44/50
2024-08-12 22:50:49.239893: train_loss -0.8275
2024-08-12 22:50:49.241010: val_loss -0.3907
2024-08-12 22:50:49.242038: Pseudo dice [0.7103]
2024-08-12 22:50:49.243086: Epoch time: 114.89 s
2024-08-12 22:50:50.689886: 
2024-08-12 22:50:50.692555: Epoch 98
2024-08-12 22:50:50.694283: Current learning rate: 0.00911
2024-08-12 22:52:39.982819: Validation loss did not improve from -0.49552. Patience: 45/50
2024-08-12 22:52:39.984993: train_loss -0.8273
2024-08-12 22:52:39.986278: val_loss -0.416
2024-08-12 22:52:39.987291: Pseudo dice [0.7185]
2024-08-12 22:52:39.988232: Epoch time: 109.3 s
2024-08-12 22:52:41.420557: 
2024-08-12 22:52:41.422161: Epoch 99
2024-08-12 22:52:41.423574: Current learning rate: 0.0091
2024-08-12 22:54:17.474601: Validation loss did not improve from -0.49552. Patience: 46/50
2024-08-12 22:54:17.475782: train_loss -0.8237
2024-08-12 22:54:17.476945: val_loss -0.3824
2024-08-12 22:54:17.477886: Pseudo dice [0.7068]
2024-08-12 22:54:17.478864: Epoch time: 96.06 s
2024-08-12 22:54:19.812965: 
2024-08-12 22:54:19.814365: Epoch 100
2024-08-12 22:54:19.815383: Current learning rate: 0.0091
2024-08-12 22:55:56.133465: Validation loss did not improve from -0.49552. Patience: 47/50
2024-08-12 22:55:56.134712: train_loss -0.8271
2024-08-12 22:55:56.135846: val_loss -0.3873
2024-08-12 22:55:56.136814: Pseudo dice [0.7095]
2024-08-12 22:55:56.137845: Epoch time: 96.32 s
2024-08-12 22:55:57.598338: 
2024-08-12 22:55:57.599990: Epoch 101
2024-08-12 22:55:57.601203: Current learning rate: 0.00909
2024-08-12 22:57:34.075993: Validation loss did not improve from -0.49552. Patience: 48/50
2024-08-12 22:57:34.077554: train_loss -0.8278
2024-08-12 22:57:34.078894: val_loss -0.3378
2024-08-12 22:57:34.080154: Pseudo dice [0.6977]
2024-08-12 22:57:34.081224: Epoch time: 96.48 s
2024-08-12 22:57:35.523296: 
2024-08-12 22:57:35.524880: Epoch 102
2024-08-12 22:57:35.526090: Current learning rate: 0.00908
2024-08-12 22:59:10.937967: Validation loss did not improve from -0.49552. Patience: 49/50
2024-08-12 22:59:10.939581: train_loss -0.8282
2024-08-12 22:59:10.940918: val_loss -0.3814
2024-08-12 22:59:10.942055: Pseudo dice [0.7044]
2024-08-12 22:59:10.943154: Epoch time: 95.42 s
2024-08-12 22:59:12.459469: 
2024-08-12 22:59:12.461269: Epoch 103
2024-08-12 22:59:12.462514: Current learning rate: 0.00907
2024-08-12 23:00:48.516522: Validation loss did not improve from -0.49552. Patience: 50/50
2024-08-12 23:00:48.517844: train_loss -0.8271
2024-08-12 23:00:48.519172: val_loss -0.3245
2024-08-12 23:00:48.520297: Pseudo dice [0.6764]
2024-08-12 23:00:48.521435: Epoch time: 96.06 s
2024-08-12 23:00:49.961084: Patience reached. Stopping training.
2024-08-12 23:00:50.479147: Training done.
2024-08-12 23:00:50.835620: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset302_Calcium_OCTv2/splits_final_5.json
2024-08-12 23:00:50.863410: The split file contains 3 splits.
2024-08-12 23:00:50.864887: Desired fold for training: 0
2024-08-12 23:00:50.866117: This split has 3 training and 2 validation cases.
2024-08-12 23:00:50.867182: WARNING: Some validation cases are also in the training set. Please check the splits.json or ignore if this is intentional.
2024-08-12 23:00:50.868245: predicting 701-013
2024-08-12 23:00:50.890266: 701-013, shape torch.Size([1, 375, 498, 498]), rank 0
2024-08-12 23:02:46.705704: predicting 704-003
2024-08-12 23:02:46.840388: 704-003, shape torch.Size([1, 375, 498, 498]), rank 0
2024-08-12 23:04:38.246731: Validation complete
2024-08-12 23:04:38.247648: Mean Validation Dice:  0.6714796243056376
wandb: 
wandb: Run history:
wandb:            ema_fg_dice ▁▁▃▃▄▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇██████████
wandb:   epoch_end_timestamps ▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████
wandb: epoch_start_timestamps ▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████
wandb:                    lrs ████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:           mean_fg_dice ▁▅▅▅▄▅▆▅▆▅▅▅▆▅▅█▅▆▆▅▇▅▇▇▇▆▅██▆▇▆▆▅█▅▇▇▇▅
wandb:           train_losses █▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_losses █▅▄▃▆▄▃▅▃▅▅▄▄▅▄▁▅▃▃▅▃▅▂▃▃▃▅▂▁▄▃▃▅▅▂▇▄▄▄▆
wandb: 
wandb: Run summary:
wandb:            ema_fg_dice 0.70271
wandb:   epoch_end_timestamps 1723518048.51767
wandb: epoch_start_timestamps 1723517952.45774
wandb:                    lrs 0.00907
wandb:           mean_fg_dice 0.67635
wandb:           train_losses -0.82707
wandb:             val_losses -0.3245
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset302_Calcium_OCTv2/nnUNetTrainerScaleAnalysis5__nnUNetPlans__3d_32x160x128_b10/fold_0/wandb/offline-run-20240812_155249-kep8xtuf
wandb: Find logs at: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset302_Calcium_OCTv2/nnUNetTrainerScaleAnalysis5__nnUNetPlans__3d_32x160x128_b10/fold_0/wandb/offline-run-20240812_155249-kep8xtuf/logs
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f202cd1bdf0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f202a163d00>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f202cc35130>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f202010e580>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f1ff4131430>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f20201137c0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 2 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 2 cases that I would like to predict

Predicting 101-045:
perform_everything_on_device: True
  0%|          | 0/966 [00:00<?, ?it/s]  0%|          | 1/966 [00:01<23:46,  1.48s/it]  0%|          | 3/966 [00:01<07:14,  2.22it/s]  0%|          | 4/966 [00:01<05:23,  2.97it/s]  1%|          | 5/966 [00:01<04:14,  3.78it/s]  1%|          | 6/966 [00:02<03:28,  4.60it/s]  1%|          | 7/966 [00:02<02:58,  5.37it/s]  1%|          | 8/966 [00:02<02:38,  6.05it/s]  1%|          | 9/966 [00:02<02:24,  6.62it/s]  1%|          | 10/966 [00:02<02:15,  7.07it/s]  1%|          | 11/966 [00:02<02:08,  7.42it/s]  1%|          | 12/966 [00:02<02:04,  7.69it/s]  1%|▏         | 13/966 [00:02<02:00,  7.88it/s]  1%|▏         | 14/966 [00:02<01:58,  8.03it/s]  2%|▏         | 15/966 [00:03<01:56,  8.13it/s]  2%|▏         | 16/966 [00:03<01:55,  8.21it/s]  2%|▏         | 17/966 [00:03<01:54,  8.26it/s]  2%|▏         | 18/966 [00:03<01:54,  8.30it/s]  2%|▏         | 19/966 [00:03<01:53,  8.32it/s]  2%|▏         | 20/966 [00:03<01:53,  8.34it/s]  2%|▏         | 21/966 [00:03<01:53,  8.36it/s]  2%|▏         | 22/966 [00:03<01:52,  8.36it/s]  2%|▏         | 23/966 [00:04<01:52,  8.36it/s]  2%|▏         | 24/966 [00:04<01:52,  8.36it/s]  3%|▎         | 25/966 [00:04<01:52,  8.37it/s]  3%|▎         | 26/966 [00:04<01:52,  8.38it/s]  3%|▎         | 27/966 [00:04<01:52,  8.38it/s]  3%|▎         | 28/966 [00:04<01:51,  8.38it/s]  3%|▎         | 29/966 [00:04<01:51,  8.39it/s]  3%|▎         | 30/966 [00:04<01:51,  8.39it/s]  3%|▎         | 31/966 [00:04<01:51,  8.38it/s]  3%|▎         | 32/966 [00:05<01:51,  8.38it/s]  3%|▎         | 33/966 [00:05<01:51,  8.38it/s]  4%|▎         | 34/966 [00:05<01:51,  8.39it/s]  4%|▎         | 35/966 [00:05<01:51,  8.38it/s]  4%|▎         | 36/966 [00:05<01:50,  8.39it/s]  4%|▍         | 37/966 [00:05<01:50,  8.39it/s]  4%|▍         | 38/966 [00:05<01:50,  8.40it/s]  4%|▍         | 39/966 [00:05<01:50,  8.39it/s]  4%|▍         | 40/966 [00:06<01:50,  8.39it/s]  4%|▍         | 41/966 [00:06<01:50,  8.39it/s]  4%|▍         | 42/966 [00:06<01:50,  8.39it/s]  4%|▍         | 43/966 [00:06<01:49,  8.40it/s]  5%|▍         | 44/966 [00:06<01:49,  8.40it/s]  5%|▍         | 45/966 [00:06<01:49,  8.41it/s]  5%|▍         | 46/966 [00:06<01:49,  8.40it/s]  5%|▍         | 47/966 [00:06<01:49,  8.41it/s]  5%|▍         | 48/966 [00:07<01:49,  8.39it/s]  5%|▌         | 49/966 [00:07<01:49,  8.39it/s]  5%|▌         | 50/966 [00:07<01:49,  8.39it/s]  5%|▌         | 51/966 [00:07<01:49,  8.39it/s]  5%|▌         | 52/966 [00:07<01:48,  8.39it/s]  5%|▌         | 53/966 [00:07<01:48,  8.38it/s]  6%|▌         | 54/966 [00:07<01:48,  8.38it/s]  6%|▌         | 55/966 [00:07<01:48,  8.37it/s]  6%|▌         | 56/966 [00:07<01:48,  8.37it/s]  6%|▌         | 57/966 [00:08<01:48,  8.38it/s]  6%|▌         | 58/966 [00:08<01:48,  8.38it/s]  6%|▌         | 59/966 [00:08<01:48,  8.38it/s]  6%|▌         | 60/966 [00:08<01:48,  8.37it/s]  6%|▋         | 61/966 [00:08<01:48,  8.37it/s]  6%|▋         | 62/966 [00:08<01:48,  8.37it/s]  7%|▋         | 63/966 [00:08<01:47,  8.38it/s]  7%|▋         | 64/966 [00:08<01:47,  8.38it/s]  7%|▋         | 65/966 [00:09<01:47,  8.37it/s]  7%|▋         | 66/966 [00:09<01:47,  8.37it/s]  7%|▋         | 67/966 [00:09<01:47,  8.37it/s]  7%|▋         | 68/966 [00:09<01:47,  8.38it/s]  7%|▋         | 69/966 [00:09<01:47,  8.38it/s]  7%|▋         | 70/966 [00:09<01:47,  8.37it/s]  7%|▋         | 71/966 [00:09<01:46,  8.37it/s]  7%|▋         | 72/966 [00:09<01:46,  8.38it/s]  8%|▊         | 73/966 [00:10<01:46,  8.39it/s]  8%|▊         | 74/966 [00:10<01:46,  8.38it/s]  8%|▊         | 75/966 [00:10<01:46,  8.38it/s]  8%|▊         | 76/966 [00:10<01:46,  8.39it/s]  8%|▊         | 77/966 [00:10<01:46,  8.38it/s]  8%|▊         | 78/966 [00:10<01:45,  8.38it/s]  8%|▊         | 79/966 [00:10<01:45,  8.40it/s]  8%|▊         | 80/966 [00:10<01:45,  8.39it/s]  8%|▊         | 81/966 [00:10<01:45,  8.39it/s]  8%|▊         | 82/966 [00:11<01:45,  8.38it/s]  9%|▊         | 83/966 [00:11<01:45,  8.38it/s]  9%|▊         | 84/966 [00:11<01:45,  8.39it/s]  9%|▉         | 85/966 [00:11<01:44,  8.41it/s]  9%|▉         | 86/966 [00:11<01:44,  8.41it/s]  9%|▉         | 87/966 [00:11<01:44,  8.40it/s]  9%|▉         | 88/966 [00:11<01:44,  8.40it/s]  9%|▉         | 89/966 [00:11<01:44,  8.40it/s]  9%|▉         | 90/966 [00:12<01:44,  8.40it/s]  9%|▉         | 91/966 [00:12<01:44,  8.41it/s] 10%|▉         | 92/966 [00:12<01:43,  8.42it/s] 10%|▉         | 93/966 [00:12<01:43,  8.41it/s] 10%|▉         | 94/966 [00:12<01:44,  8.38it/s] 10%|▉         | 95/966 [00:12<01:43,  8.39it/s] 10%|▉         | 96/966 [00:12<01:43,  8.38it/s] 10%|█         | 97/966 [00:12<01:43,  8.37it/s] 10%|█         | 98/966 [00:12<01:43,  8.37it/s] 10%|█         | 99/966 [00:13<01:43,  8.36it/s] 10%|█         | 100/966 [00:13<01:43,  8.36it/s] 10%|█         | 101/966 [00:13<01:43,  8.37it/s] 11%|█         | 102/966 [00:13<01:43,  8.36it/s] 11%|█         | 103/966 [00:13<01:43,  8.37it/s] 11%|█         | 104/966 [00:13<01:43,  8.37it/s] 11%|█         | 105/966 [00:13<01:43,  8.36it/s] 11%|█         | 106/966 [00:13<01:42,  8.35it/s] 11%|█         | 107/966 [00:14<01:42,  8.36it/s] 11%|█         | 108/966 [00:14<01:42,  8.38it/s] 11%|█▏        | 109/966 [00:14<01:42,  8.37it/s] 11%|█▏        | 110/966 [00:14<01:42,  8.37it/s] 11%|█▏        | 111/966 [00:14<01:42,  8.37it/s] 12%|█▏        | 112/966 [00:14<01:42,  8.37it/s] 12%|█▏        | 113/966 [00:14<01:42,  8.36it/s] 12%|█▏        | 114/966 [00:14<01:41,  8.36it/s] 12%|█▏        | 115/966 [00:15<01:41,  8.36it/s] 12%|█▏        | 116/966 [00:15<01:41,  8.36it/s] 12%|█▏        | 117/966 [00:15<01:41,  8.35it/s] 12%|█▏        | 118/966 [00:15<01:41,  8.35it/s] 12%|█▏        | 119/966 [00:15<01:41,  8.35it/s] 12%|█▏        | 120/966 [00:15<01:41,  8.36it/s] 13%|█▎        | 121/966 [00:15<01:41,  8.36it/s] 13%|█▎        | 122/966 [00:15<01:40,  8.37it/s] 13%|█▎        | 123/966 [00:15<01:40,  8.37it/s] 13%|█▎        | 124/966 [00:16<01:40,  8.37it/s] 13%|█▎        | 125/966 [00:16<01:40,  8.37it/s] 13%|█▎        | 126/966 [00:16<01:40,  8.36it/s] 13%|█▎        | 127/966 [00:16<01:40,  8.38it/s] 13%|█▎        | 128/966 [00:16<01:39,  8.41it/s] 13%|█▎        | 129/966 [00:16<01:39,  8.39it/s] 13%|█▎        | 130/966 [00:16<01:39,  8.39it/s] 14%|█▎        | 131/966 [00:16<01:39,  8.37it/s] 14%|█▎        | 132/966 [00:17<01:39,  8.37it/s] 14%|█▍        | 133/966 [00:17<01:39,  8.39it/s] 14%|█▍        | 134/966 [00:17<01:39,  8.39it/s] 14%|█▍        | 135/966 [00:17<01:39,  8.39it/s] 14%|█▍        | 136/966 [00:17<01:39,  8.38it/s] 14%|█▍        | 137/966 [00:17<01:38,  8.38it/s] 14%|█▍        | 138/966 [00:17<01:38,  8.39it/s] 14%|█▍        | 139/966 [00:17<01:38,  8.37it/s] 14%|█▍        | 140/966 [00:18<01:38,  8.38it/s] 15%|█▍        | 141/966 [00:18<01:38,  8.38it/s] 15%|█▍        | 142/966 [00:18<01:38,  8.39it/s] 15%|█▍        | 143/966 [00:18<01:38,  8.37it/s] 15%|█▍        | 144/966 [00:18<01:38,  8.36it/s] 15%|█▌        | 145/966 [00:18<01:38,  8.36it/s] 15%|█▌        | 146/966 [00:18<01:38,  8.36it/s] 15%|█▌        | 147/966 [00:18<01:38,  8.35it/s] 15%|█▌        | 148/966 [00:18<01:37,  8.36it/s] 15%|█▌        | 149/966 [00:19<01:37,  8.37it/s] 16%|█▌        | 150/966 [00:19<01:37,  8.36it/s] 16%|█▌        | 151/966 [00:19<01:37,  8.36it/s] 16%|█▌        | 152/966 [00:19<01:37,  8.35it/s] 16%|█▌        | 153/966 [00:19<01:37,  8.36it/s] 16%|█▌        | 154/966 [00:19<01:37,  8.36it/s] 16%|█▌        | 155/966 [00:19<01:36,  8.36it/s] 16%|█▌        | 156/966 [00:19<01:36,  8.36it/s] 16%|█▋        | 157/966 [00:20<01:36,  8.35it/s] 16%|█▋        | 158/966 [00:20<01:36,  8.36it/s] 16%|█▋        | 159/966 [00:20<01:36,  8.37it/s] 17%|█▋        | 160/966 [00:20<01:36,  8.37it/s] 17%|█▋        | 161/966 [00:20<01:36,  8.36it/s] 17%|█▋        | 162/966 [00:20<01:36,  8.35it/s] 17%|█▋        | 163/966 [00:20<01:36,  8.36it/s] 17%|█▋        | 164/966 [00:20<01:35,  8.38it/s] 17%|█▋        | 165/966 [00:20<01:35,  8.37it/s] 17%|█▋        | 166/966 [00:21<01:35,  8.37it/s] 17%|█▋        | 167/966 [00:21<01:35,  8.36it/s] 17%|█▋        | 168/966 [00:21<01:35,  8.38it/s] 17%|█▋        | 169/966 [00:21<01:34,  8.39it/s] 18%|█▊        | 170/966 [00:21<01:34,  8.39it/s] 18%|█▊        | 171/966 [00:21<01:34,  8.37it/s] 18%|█▊        | 172/966 [00:21<01:34,  8.37it/s] 18%|█▊        | 173/966 [00:21<01:34,  8.37it/s] 18%|█▊        | 174/966 [00:22<01:34,  8.39it/s] 18%|█▊        | 175/966 [00:22<01:34,  8.39it/s] 18%|█▊        | 176/966 [00:22<01:34,  8.38it/s] 18%|█▊        | 177/966 [00:22<01:34,  8.37it/s] 18%|█▊        | 178/966 [00:22<01:34,  8.38it/s] 19%|█▊        | 179/966 [00:22<01:33,  8.38it/s] 19%|█▊        | 180/966 [00:22<01:33,  8.39it/s] 19%|█▊        | 181/966 [00:22<01:33,  8.39it/s] 19%|█▉        | 182/966 [00:23<01:33,  8.38it/s] 19%|█▉        | 183/966 [00:23<01:33,  8.37it/s] 19%|█▉        | 184/966 [00:23<01:33,  8.37it/s] 19%|█▉        | 185/966 [00:23<01:33,  8.37it/s] 19%|█▉        | 186/966 [00:23<01:33,  8.36it/s] 19%|█▉        | 187/966 [00:23<01:33,  8.35it/s] 19%|█▉        | 188/966 [00:23<01:33,  8.34it/s] 20%|█▉        | 189/966 [00:23<01:33,  8.35it/s] 20%|█▉        | 190/966 [00:23<01:32,  8.36it/s] 20%|█▉        | 191/966 [00:24<01:32,  8.36it/s] 20%|█▉        | 192/966 [00:24<01:32,  8.36it/s] 20%|█▉        | 193/966 [00:24<01:32,  8.36it/s] 20%|██        | 194/966 [00:24<01:32,  8.35it/s] 20%|██        | 195/966 [00:24<01:32,  8.34it/s] 20%|██        | 196/966 [00:24<01:32,  8.35it/s] 20%|██        | 197/966 [00:24<01:32,  8.35it/s] 20%|██        | 198/966 [00:24<01:31,  8.35it/s] 21%|██        | 199/966 [00:25<01:31,  8.36it/s] 21%|██        | 200/966 [00:25<01:31,  8.37it/s] 21%|██        | 201/966 [00:25<01:31,  8.37it/s] 21%|██        | 202/966 [00:25<01:31,  8.36it/s] 21%|██        | 203/966 [00:25<01:31,  8.36it/s] 21%|██        | 204/966 [00:25<01:31,  8.35it/s] 21%|██        | 205/966 [00:25<01:30,  8.38it/s] 21%|██▏       | 206/966 [00:25<01:30,  8.38it/s] 21%|██▏       | 207/966 [00:26<01:30,  8.37it/s] 22%|██▏       | 208/966 [00:26<01:30,  8.36it/s] 22%|██▏       | 209/966 [00:26<01:30,  8.36it/s] 22%|██▏       | 210/966 [00:26<01:30,  8.37it/s] 22%|██▏       | 211/966 [00:26<01:30,  8.38it/s] 22%|██▏       | 212/966 [00:26<01:29,  8.40it/s] 22%|██▏       | 213/966 [00:26<01:29,  8.39it/s] 22%|██▏       | 214/966 [00:26<01:29,  8.38it/s] 22%|██▏       | 215/966 [00:26<01:29,  8.37it/s] 22%|██▏       | 216/966 [00:27<01:29,  8.37it/s] 22%|██▏       | 217/966 [00:27<01:29,  8.37it/s] 23%|██▎       | 218/966 [00:27<01:29,  8.39it/s] 23%|██▎       | 219/966 [00:27<01:29,  8.38it/s] 23%|██▎       | 220/966 [00:27<01:29,  8.37it/s] 23%|██▎       | 221/966 [00:27<01:29,  8.36it/s] 23%|██▎       | 222/966 [00:27<01:28,  8.37it/s] 23%|██▎       | 223/966 [00:27<01:28,  8.36it/s] 23%|██▎       | 224/966 [00:28<01:28,  8.36it/s] 23%|██▎       | 225/966 [00:28<01:28,  8.36it/s] 23%|██▎       | 226/966 [00:28<01:28,  8.36it/s] 23%|██▎       | 227/966 [00:28<01:28,  8.35it/s] 24%|██▎       | 228/966 [00:28<01:28,  8.35it/s] 24%|██▎       | 229/966 [00:28<01:28,  8.36it/s] 24%|██▍       | 230/966 [00:28<01:28,  8.35it/s] 24%|██▍       | 231/966 [00:28<01:28,  8.34it/s] 24%|██▍       | 232/966 [00:29<01:28,  8.34it/s] 24%|██▍       | 233/966 [00:29<01:27,  8.35it/s] 24%|██▍       | 234/966 [00:29<01:27,  8.35it/s] 24%|██▍       | 235/966 [00:29<01:27,  8.37it/s] 24%|██▍       | 236/966 [00:29<01:27,  8.37it/s] 25%|██▍       | 237/966 [00:29<01:27,  8.36it/s] 25%|██▍       | 238/966 [00:29<01:26,  8.37it/s] 25%|██▍       | 239/966 [00:29<01:26,  8.36it/s] 25%|██▍       | 240/966 [00:29<01:26,  8.37it/s] 25%|██▍       | 241/966 [00:30<01:26,  8.37it/s] 25%|██▌       | 242/966 [00:30<01:26,  8.37it/s] 25%|██▌       | 243/966 [00:30<01:26,  8.36it/s] 25%|██▌       | 244/966 [00:30<01:26,  8.37it/s] 25%|██▌       | 245/966 [00:30<01:26,  8.37it/s] 25%|██▌       | 246/966 [00:30<01:26,  8.37it/s] 26%|██▌       | 247/966 [00:30<01:25,  8.37it/s] 26%|██▌       | 248/966 [00:30<01:25,  8.37it/s] 26%|██▌       | 249/966 [00:31<01:25,  8.37it/s] 26%|██▌       | 250/966 [00:31<01:25,  8.37it/s] 26%|██▌       | 251/966 [00:31<01:25,  8.38it/s] 26%|██▌       | 252/966 [00:31<01:25,  8.37it/s] 26%|██▌       | 253/966 [00:31<01:25,  8.36it/s] 26%|██▋       | 254/966 [00:31<01:25,  8.37it/s] 26%|██▋       | 255/966 [00:31<01:24,  8.37it/s] 27%|██▋       | 256/966 [00:31<01:24,  8.38it/s] 27%|██▋       | 257/966 [00:31<01:24,  8.38it/s] 27%|██▋       | 258/966 [00:32<01:24,  8.37it/s] 27%|██▋       | 259/966 [00:32<01:24,  8.38it/s] 27%|██▋       | 260/966 [00:32<01:24,  8.38it/s] 27%|██▋       | 261/966 [00:32<01:24,  8.39it/s] 27%|██▋       | 262/966 [00:32<01:24,  8.37it/s] 27%|██▋       | 263/966 [00:32<01:24,  8.37it/s] 27%|██▋       | 264/966 [00:32<01:23,  8.36it/s] 27%|██▋       | 265/966 [00:32<01:23,  8.35it/s] 28%|██▊       | 266/966 [00:33<01:23,  8.35it/s] 28%|██▊       | 267/966 [00:33<01:23,  8.36it/s] 28%|██▊       | 268/966 [00:33<01:23,  8.35it/s] 28%|██▊       | 269/966 [00:33<01:23,  8.34it/s] 28%|██▊       | 270/966 [00:33<01:23,  8.35it/s] 28%|██▊       | 271/966 [00:33<01:23,  8.34it/s] 28%|██▊       | 272/966 [00:33<01:23,  8.34it/s] 28%|██▊       | 273/966 [00:33<01:22,  8.36it/s] 28%|██▊       | 274/966 [00:34<01:22,  8.35it/s] 28%|██▊       | 275/966 [00:34<01:22,  8.34it/s] 29%|██▊       | 276/966 [00:34<01:22,  8.36it/s] 29%|██▊       | 277/966 [00:34<01:22,  8.36it/s] 29%|██▉       | 278/966 [00:34<01:22,  8.36it/s] 29%|██▉       | 279/966 [00:34<01:22,  8.35it/s] 29%|██▉       | 280/966 [00:34<01:22,  8.36it/s] 29%|██▉       | 281/966 [00:34<01:22,  8.35it/s] 29%|██▉       | 282/966 [00:34<01:21,  8.35it/s] 29%|██▉       | 283/966 [00:35<01:21,  8.37it/s] 29%|██▉       | 284/966 [00:35<01:21,  8.36it/s] 30%|██▉       | 285/966 [00:35<01:21,  8.35it/s] 30%|██▉       | 286/966 [00:35<01:21,  8.36it/s] 30%|██▉       | 287/966 [00:35<01:21,  8.35it/s] 30%|██▉       | 288/966 [00:35<01:21,  8.36it/s] 30%|██▉       | 289/966 [00:35<01:20,  8.38it/s] 30%|███       | 290/966 [00:35<01:20,  8.36it/s] 30%|███       | 291/966 [00:36<01:20,  8.36it/s] 30%|███       | 292/966 [00:36<01:20,  8.35it/s] 30%|███       | 293/966 [00:36<01:20,  8.35it/s] 30%|███       | 294/966 [00:36<01:20,  8.35it/s] 31%|███       | 295/966 [00:36<01:20,  8.36it/s] 31%|███       | 296/966 [00:36<01:19,  8.39it/s] 31%|███       | 297/966 [00:36<01:19,  8.38it/s] 31%|███       | 298/966 [00:36<01:19,  8.37it/s] 31%|███       | 299/966 [00:37<01:19,  8.36it/s] 31%|███       | 300/966 [00:37<01:19,  8.37it/s] 31%|███       | 301/966 [00:37<01:19,  8.36it/s] 31%|███▏      | 302/966 [00:37<01:19,  8.36it/s] 31%|███▏      | 303/966 [00:37<01:19,  8.35it/s] 31%|███▏      | 304/966 [00:37<01:19,  8.35it/s] 32%|███▏      | 305/966 [00:37<01:19,  8.35it/s] 32%|███▏      | 306/966 [00:37<01:19,  8.34it/s] 32%|███▏      | 307/966 [00:37<01:18,  8.35it/s] 32%|███▏      | 308/966 [00:38<01:18,  8.34it/s] 32%|███▏      | 309/966 [00:38<01:18,  8.34it/s] 32%|███▏      | 310/966 [00:38<01:18,  8.34it/s] 32%|███▏      | 311/966 [00:38<01:18,  8.35it/s] 32%|███▏      | 312/966 [00:38<01:18,  8.34it/s] 32%|███▏      | 313/966 [00:38<01:18,  8.33it/s] 33%|███▎      | 314/966 [00:38<01:18,  8.33it/s] 33%|███▎      | 315/966 [00:38<01:18,  8.34it/s] 33%|███▎      | 316/966 [00:39<01:17,  8.34it/s] 33%|███▎      | 317/966 [00:39<01:17,  8.36it/s] 33%|███▎      | 318/966 [00:39<01:17,  8.35it/s] 33%|███▎      | 319/966 [00:39<01:17,  8.35it/s] 33%|███▎      | 320/966 [00:39<01:17,  8.34it/s] 33%|███▎      | 321/966 [00:39<01:17,  8.33it/s] 33%|███▎      | 322/966 [00:39<01:17,  8.34it/s] 33%|███▎      | 323/966 [00:39<01:17,  8.34it/s] 34%|███▎      | 324/966 [00:40<01:16,  8.36it/s] 34%|███▎      | 325/966 [00:40<01:16,  8.35it/s] 34%|███▎      | 326/966 [00:40<01:16,  8.34it/s] 34%|███▍      | 327/966 [00:40<01:16,  8.35it/s] 34%|███▍      | 328/966 [00:40<01:16,  8.35it/s] 34%|███▍      | 329/966 [00:40<01:16,  8.34it/s] 34%|███▍      | 330/966 [00:40<01:16,  8.35it/s] 34%|███▍      | 331/966 [00:40<01:15,  8.38it/s] 34%|███▍      | 332/966 [00:40<01:15,  8.37it/s] 34%|███▍      | 333/966 [00:41<01:15,  8.35it/s] 35%|███▍      | 334/966 [00:41<01:15,  8.34it/s] 35%|███▍      | 335/966 [00:41<01:15,  8.34it/s] 35%|███▍      | 336/966 [00:41<01:15,  8.35it/s] 35%|███▍      | 337/966 [00:41<01:15,  8.37it/s] 35%|███▍      | 338/966 [00:41<01:14,  8.37it/s] 35%|███▌      | 339/966 [00:41<01:14,  8.38it/s] 35%|███▌      | 340/966 [00:41<01:14,  8.37it/s] 35%|███▌      | 341/966 [00:42<01:14,  8.37it/s] 35%|███▌      | 342/966 [00:42<01:14,  8.36it/s] 36%|███▌      | 343/966 [00:42<01:14,  8.36it/s] 36%|███▌      | 344/966 [00:42<01:14,  8.36it/s] 36%|███▌      | 345/966 [00:42<01:14,  8.36it/s] 36%|███▌      | 346/966 [00:42<01:14,  8.35it/s] 36%|███▌      | 347/966 [00:42<01:14,  8.36it/s] 36%|███▌      | 348/966 [00:42<01:14,  8.35it/s] 36%|███▌      | 349/966 [00:43<01:13,  8.35it/s] 36%|███▌      | 350/966 [00:43<01:13,  8.35it/s] 36%|███▋      | 351/966 [00:43<01:13,  8.36it/s] 36%|███▋      | 352/966 [00:43<01:13,  8.35it/s] 37%|███▋      | 353/966 [00:43<01:13,  8.35it/s] 37%|███▋      | 354/966 [00:43<01:13,  8.34it/s] 37%|███▋      | 355/966 [00:43<01:13,  8.35it/s] 37%|███▋      | 356/966 [00:43<01:13,  8.34it/s] 37%|███▋      | 357/966 [00:43<01:13,  8.34it/s] 37%|███▋      | 358/966 [00:44<01:12,  8.34it/s] 37%|███▋      | 359/966 [00:44<01:12,  8.35it/s] 37%|███▋      | 360/966 [00:44<01:12,  8.35it/s] 37%|███▋      | 361/966 [00:44<01:12,  8.35it/s] 37%|███▋      | 362/966 [00:44<01:12,  8.35it/s] 38%|███▊      | 363/966 [00:44<01:12,  8.36it/s] 38%|███▊      | 364/966 [00:44<01:12,  8.35it/s] 38%|███▊      | 365/966 [00:44<01:11,  8.35it/s] 38%|███▊      | 366/966 [00:45<01:11,  8.35it/s] 38%|███▊      | 367/966 [00:45<01:11,  8.35it/s] 38%|███▊      | 368/966 [00:45<01:11,  8.34it/s] 38%|███▊      | 369/966 [00:45<01:11,  8.34it/s] 38%|███▊      | 370/966 [00:45<01:11,  8.35it/s] 38%|███▊      | 371/966 [00:45<01:11,  8.35it/s] 39%|███▊      | 372/966 [00:45<01:11,  8.35it/s] 39%|███▊      | 373/966 [00:45<01:10,  8.36it/s] 39%|███▊      | 374/966 [00:45<01:10,  8.36it/s] 39%|███▉      | 375/966 [00:46<01:10,  8.37it/s] 39%|███▉      | 376/966 [00:46<01:10,  8.36it/s] 39%|███▉      | 377/966 [00:46<01:10,  8.34it/s] 39%|███▉      | 378/966 [00:46<01:10,  8.36it/s] 39%|███▉      | 379/966 [00:46<01:10,  8.36it/s] 39%|███▉      | 380/966 [00:46<01:10,  8.36it/s] 39%|███▉      | 381/966 [00:46<01:09,  8.36it/s] 40%|███▉      | 382/966 [00:46<01:09,  8.36it/s] 40%|███▉      | 383/966 [00:47<01:09,  8.36it/s] 40%|███▉      | 384/966 [00:47<01:09,  8.35it/s] 40%|███▉      | 385/966 [00:47<01:09,  8.35it/s] 40%|███▉      | 386/966 [00:47<01:09,  8.36it/s] 40%|████      | 387/966 [00:47<01:09,  8.36it/s] 40%|████      | 388/966 [00:47<01:09,  8.35it/s] 40%|████      | 389/966 [00:47<01:09,  8.34it/s] 40%|████      | 390/966 [00:47<01:09,  8.35it/s] 40%|████      | 391/966 [00:48<01:08,  8.36it/s] 41%|████      | 392/966 [00:48<01:08,  8.35it/s] 41%|████      | 393/966 [00:48<01:08,  8.34it/s] 41%|████      | 394/966 [00:48<01:08,  8.34it/s] 41%|████      | 395/966 [00:48<01:08,  8.34it/s] 41%|████      | 396/966 [00:48<01:08,  8.33it/s] 41%|████      | 397/966 [00:48<01:08,  8.34it/s] 41%|████      | 398/966 [00:48<01:08,  8.34it/s] 41%|████▏     | 399/966 [00:48<01:07,  8.34it/s] 41%|████▏     | 400/966 [00:49<01:07,  8.34it/s] 42%|████▏     | 401/966 [00:49<01:07,  8.34it/s] 42%|████▏     | 402/966 [00:49<01:07,  8.35it/s] 42%|████▏     | 403/966 [00:49<01:07,  8.34it/s] 42%|████▏     | 404/966 [00:49<01:07,  8.33it/s] 42%|████▏     | 405/966 [00:49<01:07,  8.34it/s] 42%|████▏     | 406/966 [00:49<01:07,  8.33it/s] 42%|████▏     | 407/966 [00:49<01:07,  8.34it/s] 42%|████▏     | 408/966 [00:50<01:06,  8.34it/s] 42%|████▏     | 409/966 [00:50<01:06,  8.34it/s] 42%|████▏     | 410/966 [00:50<01:06,  8.34it/s] 43%|████▎     | 411/966 [00:50<01:06,  8.34it/s] 43%|████▎     | 412/966 [00:50<01:06,  8.35it/s] 43%|████▎     | 413/966 [00:50<01:06,  8.35it/s] 43%|████▎     | 414/966 [00:50<01:06,  8.36it/s] 43%|████▎     | 415/966 [00:50<01:05,  8.36it/s] 43%|████▎     | 416/966 [00:51<01:05,  8.37it/s] 43%|████▎     | 417/966 [00:51<01:05,  8.36it/s] 43%|████▎     | 418/966 [00:51<01:05,  8.34it/s] 43%|████▎     | 419/966 [00:51<01:05,  8.34it/s] 43%|████▎     | 420/966 [00:51<01:05,  8.33it/s] 44%|████▎     | 421/966 [00:51<01:05,  8.34it/s] 44%|████▎     | 422/966 [00:51<01:05,  8.37it/s] 44%|████▍     | 423/966 [00:51<01:04,  8.37it/s] 44%|████▍     | 424/966 [00:51<01:04,  8.37it/s] 44%|████▍     | 425/966 [00:52<01:04,  8.37it/s] 44%|████▍     | 426/966 [00:52<01:04,  8.36it/s] 44%|████▍     | 427/966 [00:52<01:04,  8.35it/s] 44%|████▍     | 428/966 [00:52<01:04,  8.35it/s] 44%|████▍     | 429/966 [00:52<01:04,  8.36it/s] 45%|████▍     | 430/966 [00:52<01:04,  8.35it/s] 45%|████▍     | 431/966 [00:52<01:04,  8.35it/s] 45%|████▍     | 432/966 [00:52<01:04,  8.34it/s] 45%|████▍     | 433/966 [00:53<01:03,  8.34it/s] 45%|████▍     | 434/966 [00:53<01:03,  8.33it/s] 45%|████▌     | 435/966 [00:53<01:03,  8.33it/s] 45%|████▌     | 436/966 [00:53<01:03,  8.34it/s] 45%|████▌     | 437/966 [00:53<01:03,  8.34it/s] 45%|████▌     | 438/966 [00:53<01:03,  8.34it/s] 45%|████▌     | 439/966 [00:53<01:03,  8.34it/s] 46%|████▌     | 440/966 [00:53<01:03,  8.33it/s] 46%|████▌     | 441/966 [00:54<01:02,  8.34it/s] 46%|████▌     | 442/966 [00:54<01:02,  8.34it/s] 46%|████▌     | 443/966 [00:54<01:02,  8.35it/s] 46%|████▌     | 444/966 [00:54<01:02,  8.35it/s] 46%|████▌     | 445/966 [00:54<01:02,  8.35it/s] 46%|████▌     | 446/966 [00:54<01:02,  8.36it/s] 46%|████▋     | 447/966 [00:54<01:02,  8.35it/s] 46%|████▋     | 448/966 [00:54<01:02,  8.35it/s] 46%|████▋     | 449/966 [00:54<01:01,  8.34it/s] 47%|████▋     | 450/966 [00:55<01:01,  8.35it/s] 47%|████▋     | 451/966 [00:55<01:01,  8.35it/s] 47%|████▋     | 452/966 [00:55<01:01,  8.35it/s] 47%|████▋     | 453/966 [00:55<01:01,  8.35it/s] 47%|████▋     | 454/966 [00:55<01:01,  8.34it/s] 47%|████▋     | 455/966 [00:55<01:01,  8.35it/s] 47%|████▋     | 456/966 [00:55<01:01,  8.36it/s] 47%|████▋     | 457/966 [00:55<01:00,  8.36it/s] 47%|████▋     | 458/966 [00:56<01:00,  8.35it/s] 48%|████▊     | 459/966 [00:56<01:00,  8.34it/s] 48%|████▊     | 460/966 [00:56<01:00,  8.33it/s] 48%|████▊     | 461/966 [00:56<01:00,  8.33it/s] 48%|████▊     | 462/966 [00:56<01:00,  8.35it/s] 48%|████▊     | 463/966 [00:56<01:00,  8.35it/s] 48%|████▊     | 464/966 [00:56<01:00,  8.36it/s] 48%|████▊     | 465/966 [00:56<00:59,  8.36it/s] 48%|████▊     | 466/966 [00:57<00:59,  8.36it/s] 48%|████▊     | 467/966 [00:57<00:59,  8.36it/s] 48%|████▊     | 468/966 [00:57<00:59,  8.35it/s] 49%|████▊     | 469/966 [00:57<00:59,  8.35it/s] 49%|████▊     | 470/966 [00:57<00:59,  8.36it/s] 49%|████▉     | 471/966 [00:57<00:59,  8.36it/s] 49%|████▉     | 472/966 [00:57<00:59,  8.36it/s] 49%|████▉     | 473/966 [00:57<00:59,  8.35it/s] 49%|████▉     | 474/966 [00:57<00:58,  8.34it/s] 49%|████▉     | 475/966 [00:58<00:58,  8.34it/s] 49%|████▉     | 476/966 [00:58<00:58,  8.36it/s] 49%|████▉     | 477/966 [00:58<00:58,  8.35it/s] 49%|████▉     | 478/966 [00:58<00:58,  8.35it/s] 50%|████▉     | 479/966 [00:58<00:58,  8.35it/s] 50%|████▉     | 480/966 [00:58<00:58,  8.36it/s] 50%|████▉     | 481/966 [00:58<00:57,  8.36it/s] 50%|████▉     | 482/966 [00:58<00:57,  8.35it/s] 50%|█████     | 483/966 [00:59<00:57,  8.34it/s] 50%|█████     | 484/966 [00:59<00:57,  8.34it/s] 50%|█████     | 485/966 [00:59<00:57,  8.34it/s] 50%|█████     | 486/966 [00:59<00:57,  8.35it/s] 50%|█████     | 487/966 [00:59<00:57,  8.33it/s] 51%|█████     | 488/966 [00:59<00:57,  8.33it/s] 51%|█████     | 489/966 [00:59<00:57,  8.32it/s] 51%|█████     | 490/966 [00:59<00:57,  8.33it/s] 51%|█████     | 491/966 [01:00<00:56,  8.34it/s] 51%|█████     | 492/966 [01:00<00:56,  8.34it/s] 51%|█████     | 493/966 [01:00<00:56,  8.34it/s] 51%|█████     | 494/966 [01:00<00:56,  8.34it/s] 51%|█████     | 495/966 [01:00<00:56,  8.33it/s] 51%|█████▏    | 496/966 [01:00<00:56,  8.34it/s] 51%|█████▏    | 497/966 [01:00<00:56,  8.34it/s] 52%|█████▏    | 498/966 [01:00<00:56,  8.34it/s] 52%|█████▏    | 499/966 [01:00<00:55,  8.37it/s] 52%|█████▏    | 500/966 [01:01<00:55,  8.35it/s] 52%|█████▏    | 501/966 [01:01<00:55,  8.35it/s] 52%|█████▏    | 502/966 [01:01<00:55,  8.35it/s] 52%|█████▏    | 503/966 [01:01<00:55,  8.34it/s] 52%|█████▏    | 504/966 [01:01<00:55,  8.35it/s] 52%|█████▏    | 505/966 [01:01<00:55,  8.36it/s] 52%|█████▏    | 506/966 [01:01<00:54,  8.37it/s] 52%|█████▏    | 507/966 [01:01<00:54,  8.36it/s] 53%|█████▎    | 508/966 [01:02<00:54,  8.35it/s] 53%|█████▎    | 509/966 [01:02<00:54,  8.34it/s] 53%|█████▎    | 510/966 [01:02<00:54,  8.33it/s] 53%|█████▎    | 511/966 [01:02<00:54,  8.34it/s] 53%|█████▎    | 512/966 [01:02<00:54,  8.35it/s] 53%|█████▎    | 513/966 [01:02<00:54,  8.35it/s] 53%|█████▎    | 514/966 [01:02<00:54,  8.34it/s] 53%|█████▎    | 515/966 [01:02<00:54,  8.34it/s] 53%|█████▎    | 516/966 [01:03<00:53,  8.34it/s] 54%|█████▎    | 517/966 [01:03<00:53,  8.34it/s] 54%|█████▎    | 518/966 [01:03<00:53,  8.34it/s] 54%|█████▎    | 519/966 [01:03<00:53,  8.34it/s] 54%|█████▍    | 520/966 [01:03<00:53,  8.34it/s] 54%|█████▍    | 521/966 [01:03<00:53,  8.35it/s] 54%|█████▍    | 522/966 [01:03<00:53,  8.35it/s] 54%|█████▍    | 523/966 [01:03<00:53,  8.34it/s] 54%|█████▍    | 524/966 [01:03<00:52,  8.34it/s] 54%|█████▍    | 525/966 [01:04<00:52,  8.34it/s] 54%|█████▍    | 526/966 [01:04<00:52,  8.34it/s] 55%|█████▍    | 527/966 [01:04<00:52,  8.35it/s] 55%|█████▍    | 528/966 [01:04<00:52,  8.34it/s] 55%|█████▍    | 529/966 [01:04<00:52,  8.33it/s] 55%|█████▍    | 530/966 [01:04<00:52,  8.33it/s] 55%|█████▍    | 531/966 [01:04<00:52,  8.33it/s] 55%|█████▌    | 532/966 [01:04<00:52,  8.33it/s] 55%|█████▌    | 533/966 [01:05<00:51,  8.34it/s] 55%|█████▌    | 534/966 [01:05<00:51,  8.35it/s] 55%|█████▌    | 535/966 [01:05<00:51,  8.36it/s] 55%|█████▌    | 536/966 [01:05<00:51,  8.35it/s] 56%|█████▌    | 537/966 [01:05<00:51,  8.34it/s] 56%|█████▌    | 538/966 [01:05<00:51,  8.35it/s] 56%|█████▌    | 539/966 [01:05<00:51,  8.34it/s] 56%|█████▌    | 540/966 [01:05<00:51,  8.34it/s] 56%|█████▌    | 541/966 [01:06<00:50,  8.37it/s] 56%|█████▌    | 542/966 [01:06<00:50,  8.37it/s] 56%|█████▌    | 543/966 [01:06<00:50,  8.37it/s] 56%|█████▋    | 544/966 [01:06<00:50,  8.35it/s] 56%|█████▋    | 545/966 [01:06<00:50,  8.34it/s] 57%|█████▋    | 546/966 [01:06<00:50,  8.35it/s] 57%|█████▋    | 547/966 [01:06<00:50,  8.35it/s] 57%|█████▋    | 548/966 [01:06<00:49,  8.36it/s] 57%|█████▋    | 549/966 [01:06<00:49,  8.35it/s] 57%|█████▋    | 550/966 [01:07<00:49,  8.35it/s] 57%|█████▋    | 551/966 [01:07<00:49,  8.35it/s] 57%|█████▋    | 552/966 [01:07<00:49,  8.34it/s] 57%|█████▋    | 553/966 [01:07<00:49,  8.34it/s] 57%|█████▋    | 554/966 [01:07<00:49,  8.36it/s] 57%|█████▋    | 555/966 [01:07<00:49,  8.36it/s] 58%|█████▊    | 556/966 [01:07<00:49,  8.34it/s] 58%|█████▊    | 557/966 [01:07<00:48,  8.35it/s] 58%|█████▊    | 558/966 [01:08<00:48,  8.35it/s] 58%|█████▊    | 559/966 [01:08<00:48,  8.34it/s] 58%|█████▊    | 560/966 [01:08<00:48,  8.35it/s] 58%|█████▊    | 561/966 [01:08<00:48,  8.34it/s] 58%|█████▊    | 562/966 [01:08<00:48,  8.33it/s] 58%|█████▊    | 563/966 [01:08<00:48,  8.32it/s] 58%|█████▊    | 564/966 [01:08<00:48,  8.33it/s] 58%|█████▊    | 565/966 [01:08<00:48,  8.33it/s] 59%|█████▊    | 566/966 [01:08<00:47,  8.34it/s] 59%|█████▊    | 567/966 [01:09<00:47,  8.33it/s] 59%|█████▉    | 568/966 [01:09<00:47,  8.34it/s] 59%|█████▉    | 569/966 [01:09<00:47,  8.34it/s] 59%|█████▉    | 570/966 [01:09<00:47,  8.34it/s] 59%|█████▉    | 571/966 [01:09<00:47,  8.33it/s] 59%|█████▉    | 572/966 [01:09<00:47,  8.32it/s] 59%|█████▉    | 573/966 [01:09<00:47,  8.33it/s] 59%|█████▉    | 574/966 [01:09<00:47,  8.33it/s] 60%|█████▉    | 575/966 [01:10<00:46,  8.34it/s] 60%|█████▉    | 576/966 [01:10<00:46,  8.35it/s] 60%|█████▉    | 577/966 [01:10<00:46,  8.34it/s] 60%|█████▉    | 578/966 [01:10<00:46,  8.33it/s] 60%|█████▉    | 579/966 [01:10<00:46,  8.33it/s] 60%|██████    | 580/966 [01:10<00:46,  8.33it/s] 60%|██████    | 581/966 [01:10<00:46,  8.34it/s] 60%|██████    | 582/966 [01:10<00:46,  8.33it/s] 60%|██████    | 583/966 [01:11<00:45,  8.34it/s] 60%|██████    | 584/966 [01:11<00:45,  8.34it/s] 61%|██████    | 585/966 [01:11<00:45,  8.34it/s] 61%|██████    | 586/966 [01:11<00:45,  8.35it/s] 61%|██████    | 587/966 [01:11<00:45,  8.35it/s] 61%|██████    | 588/966 [01:11<00:45,  8.35it/s] 61%|██████    | 589/966 [01:11<00:45,  8.36it/s] 61%|██████    | 590/966 [01:11<00:44,  8.36it/s] 61%|██████    | 591/966 [01:11<00:44,  8.36it/s] 61%|██████▏   | 592/966 [01:12<00:44,  8.35it/s] 61%|██████▏   | 593/966 [01:12<00:44,  8.35it/s] 61%|██████▏   | 594/966 [01:12<00:44,  8.34it/s] 62%|██████▏   | 595/966 [01:12<00:44,  8.34it/s] 62%|██████▏   | 596/966 [01:12<00:44,  8.35it/s] 62%|██████▏   | 597/966 [01:12<00:44,  8.35it/s] 62%|██████▏   | 598/966 [01:12<00:44,  8.36it/s] 62%|██████▏   | 599/966 [01:12<00:43,  8.36it/s] 62%|██████▏   | 600/966 [01:13<00:43,  8.36it/s] 62%|██████▏   | 601/966 [01:13<00:43,  8.34it/s] 62%|██████▏   | 602/966 [01:13<00:43,  8.34it/s] 62%|██████▏   | 603/966 [01:13<00:43,  8.34it/s] 63%|██████▎   | 604/966 [01:13<00:43,  8.33it/s] 63%|██████▎   | 605/966 [01:13<00:43,  8.34it/s] 63%|██████▎   | 606/966 [01:13<00:43,  8.34it/s] 63%|██████▎   | 607/966 [01:13<00:43,  8.33it/s] 63%|██████▎   | 608/966 [01:14<00:43,  8.32it/s] 63%|██████▎   | 609/966 [01:14<00:42,  8.33it/s] 63%|██████▎   | 610/966 [01:14<00:42,  8.34it/s] 63%|██████▎   | 611/966 [01:14<00:42,  8.34it/s] 63%|██████▎   | 612/966 [01:14<00:42,  8.34it/s] 63%|██████▎   | 613/966 [01:14<00:42,  8.33it/s] 64%|██████▎   | 614/966 [01:14<00:42,  8.33it/s] 64%|██████▎   | 615/966 [01:14<00:42,  8.33it/s] 64%|██████▍   | 616/966 [01:14<00:42,  8.33it/s] 64%|██████▍   | 617/966 [01:15<00:41,  8.33it/s] 64%|██████▍   | 618/966 [01:15<00:41,  8.34it/s] 64%|██████▍   | 619/966 [01:15<00:41,  8.34it/s] 64%|██████▍   | 620/966 [01:15<00:41,  8.33it/s] 64%|██████▍   | 621/966 [01:15<00:41,  8.33it/s] 64%|██████▍   | 622/966 [01:15<00:41,  8.34it/s] 64%|██████▍   | 623/966 [01:15<00:41,  8.34it/s] 65%|██████▍   | 624/966 [01:15<00:40,  8.35it/s] 65%|██████▍   | 625/966 [01:16<00:40,  8.35it/s] 65%|██████▍   | 626/966 [01:16<00:40,  8.34it/s] 65%|██████▍   | 627/966 [01:16<00:40,  8.35it/s] 65%|██████▌   | 628/966 [01:16<00:40,  8.34it/s] 65%|██████▌   | 629/966 [01:16<00:40,  8.33it/s] 65%|██████▌   | 630/966 [01:16<00:40,  8.33it/s] 65%|██████▌   | 631/966 [01:16<00:40,  8.35it/s] 65%|██████▌   | 632/966 [01:16<00:39,  8.36it/s] 66%|██████▌   | 633/966 [01:17<00:39,  8.36it/s] 66%|██████▌   | 634/966 [01:17<00:39,  8.35it/s] 66%|██████▌   | 635/966 [01:17<00:39,  8.34it/s] 66%|██████▌   | 636/966 [01:17<00:39,  8.33it/s] 66%|██████▌   | 637/966 [01:17<00:39,  8.35it/s] 66%|██████▌   | 638/966 [01:17<00:39,  8.34it/s] 66%|██████▌   | 639/966 [01:17<00:39,  8.34it/s] 66%|██████▋   | 640/966 [01:17<00:39,  8.35it/s] 66%|██████▋   | 641/966 [01:17<00:38,  8.35it/s] 66%|██████▋   | 642/966 [01:18<00:38,  8.34it/s] 67%|██████▋   | 643/966 [01:18<00:38,  8.33it/s] 67%|██████▋   | 644/966 [01:18<00:38,  8.33it/s] 67%|██████▋   | 645/966 [01:18<00:38,  8.34it/s] 67%|██████▋   | 646/966 [01:18<00:38,  8.33it/s] 67%|██████▋   | 647/966 [01:18<00:38,  8.32it/s] 67%|██████▋   | 648/966 [01:18<00:38,  8.33it/s] 67%|██████▋   | 649/966 [01:18<00:38,  8.34it/s] 67%|██████▋   | 650/966 [01:19<00:37,  8.33it/s] 67%|██████▋   | 651/966 [01:19<00:37,  8.32it/s] 67%|██████▋   | 652/966 [01:19<00:37,  8.32it/s] 68%|██████▊   | 653/966 [01:19<00:37,  8.32it/s] 68%|██████▊   | 654/966 [01:19<00:37,  8.33it/s] 68%|██████▊   | 655/966 [01:19<00:37,  8.33it/s] 68%|██████▊   | 656/966 [01:19<00:37,  8.34it/s] 68%|██████▊   | 657/966 [01:19<00:37,  8.33it/s] 68%|██████▊   | 658/966 [01:20<00:37,  8.31it/s] 68%|██████▊   | 659/966 [01:20<00:36,  8.31it/s] 68%|██████▊   | 660/966 [01:20<00:36,  8.33it/s] 68%|██████▊   | 661/966 [01:20<00:36,  8.33it/s] 69%|██████▊   | 662/966 [01:20<00:36,  8.35it/s] 69%|██████▊   | 663/966 [01:20<00:36,  8.34it/s] 69%|██████▊   | 664/966 [01:20<00:36,  8.33it/s] 69%|██████▉   | 665/966 [01:20<00:36,  8.33it/s] 69%|██████▉   | 666/966 [01:20<00:36,  8.33it/s] 69%|██████▉   | 667/966 [01:21<00:35,  8.33it/s] 69%|██████▉   | 668/966 [01:21<00:35,  8.34it/s] 69%|██████▉   | 669/966 [01:21<00:35,  8.34it/s] 69%|██████▉   | 670/966 [01:21<00:35,  8.34it/s] 69%|██████▉   | 671/966 [01:21<00:35,  8.33it/s] 70%|██████▉   | 672/966 [01:21<00:35,  8.33it/s] 70%|██████▉   | 673/966 [01:21<00:35,  8.35it/s] 70%|██████▉   | 674/966 [01:21<00:34,  8.37it/s] 70%|██████▉   | 675/966 [01:22<00:34,  8.36it/s] 70%|██████▉   | 676/966 [01:22<00:34,  8.35it/s] 70%|███████   | 677/966 [01:22<00:34,  8.33it/s] 70%|███████   | 678/966 [01:22<00:34,  8.32it/s] 70%|███████   | 679/966 [01:22<00:34,  8.34it/s] 70%|███████   | 680/966 [01:22<00:34,  8.34it/s] 70%|███████   | 681/966 [01:22<00:34,  8.34it/s] 71%|███████   | 682/966 [01:22<00:34,  8.35it/s] 71%|███████   | 683/966 [01:23<00:33,  8.35it/s] 71%|███████   | 684/966 [01:23<00:33,  8.34it/s] 71%|███████   | 685/966 [01:23<00:33,  8.32it/s] 71%|███████   | 686/966 [01:23<00:33,  8.31it/s] 71%|███████   | 687/966 [01:23<00:33,  8.32it/s] 71%|███████   | 688/966 [01:23<00:33,  8.32it/s] 71%|███████▏  | 689/966 [01:23<00:33,  8.33it/s] 71%|███████▏  | 690/966 [01:23<00:33,  8.33it/s] 72%|███████▏  | 691/966 [01:23<00:32,  8.33it/s] 72%|███████▏  | 692/966 [01:24<00:32,  8.33it/s] 72%|███████▏  | 693/966 [01:24<00:32,  8.33it/s] 72%|███████▏  | 694/966 [01:24<00:32,  8.32it/s] 72%|███████▏  | 695/966 [01:24<00:32,  8.32it/s] 72%|███████▏  | 696/966 [01:24<00:32,  8.32it/s] 72%|███████▏  | 697/966 [01:24<00:32,  8.32it/s] 72%|███████▏  | 698/966 [01:24<00:32,  8.32it/s] 72%|███████▏  | 699/966 [01:24<00:32,  8.32it/s] 72%|███████▏  | 700/966 [01:25<00:31,  8.33it/s] 73%|███████▎  | 701/966 [01:25<00:31,  8.33it/s] 73%|███████▎  | 702/966 [01:25<00:31,  8.34it/s] 73%|███████▎  | 703/966 [01:25<00:31,  8.33it/s] 73%|███████▎  | 704/966 [01:25<00:31,  8.33it/s] 73%|███████▎  | 705/966 [01:25<00:31,  8.33it/s] 73%|███████▎  | 706/966 [01:25<00:31,  8.33it/s] 73%|███████▎  | 707/966 [01:25<00:31,  8.33it/s] 73%|███████▎  | 708/966 [01:26<00:30,  8.34it/s] 73%|███████▎  | 709/966 [01:26<00:30,  8.36it/s] 73%|███████▎  | 710/966 [01:26<00:30,  8.35it/s] 74%|███████▎  | 711/966 [01:26<00:30,  8.34it/s] 74%|███████▎  | 712/966 [01:26<00:30,  8.33it/s] 74%|███████▍  | 713/966 [01:26<00:30,  8.33it/s] 74%|███████▍  | 714/966 [01:26<00:30,  8.34it/s] 74%|███████▍  | 715/966 [01:26<00:30,  8.35it/s] 74%|███████▍  | 716/966 [01:26<00:29,  8.35it/s] 74%|███████▍  | 717/966 [01:27<00:29,  8.34it/s] 74%|███████▍  | 718/966 [01:27<00:29,  8.34it/s] 74%|███████▍  | 719/966 [01:27<00:29,  8.33it/s] 75%|███████▍  | 720/966 [01:27<00:29,  8.33it/s] 75%|███████▍  | 721/966 [01:27<00:29,  8.35it/s] 75%|███████▍  | 722/966 [01:27<00:29,  8.35it/s] 75%|███████▍  | 723/966 [01:27<00:29,  8.34it/s] 75%|███████▍  | 724/966 [01:27<00:29,  8.34it/s] 75%|███████▌  | 725/966 [01:28<00:28,  8.34it/s] 75%|███████▌  | 726/966 [01:28<00:28,  8.34it/s] 75%|███████▌  | 727/966 [01:28<00:28,  8.34it/s] 75%|███████▌  | 728/966 [01:28<00:28,  8.33it/s] 75%|███████▌  | 729/966 [01:28<00:28,  8.32it/s] 76%|███████▌  | 730/966 [01:28<00:28,  8.32it/s] 76%|███████▌  | 731/966 [01:28<00:28,  8.33it/s] 76%|███████▌  | 732/966 [01:28<00:28,  8.32it/s] 76%|███████▌  | 733/966 [01:29<00:28,  8.32it/s] 76%|███████▌  | 734/966 [01:29<00:27,  8.30it/s] 76%|███████▌  | 735/966 [01:29<00:27,  8.31it/s] 76%|███████▌  | 736/966 [01:29<00:27,  8.30it/s] 76%|███████▋  | 737/966 [01:29<00:27,  8.31it/s] 76%|███████▋  | 738/966 [01:29<00:27,  8.32it/s] 77%|███████▋  | 739/966 [01:29<00:27,  8.33it/s] 77%|███████▋  | 740/966 [01:29<00:27,  8.34it/s] 77%|███████▋  | 741/966 [01:29<00:27,  8.33it/s] 77%|███████▋  | 742/966 [01:30<00:26,  8.32it/s] 77%|███████▋  | 743/966 [01:30<00:26,  8.32it/s] 77%|███████▋  | 744/966 [01:30<00:26,  8.32it/s] 77%|███████▋  | 745/966 [01:30<00:26,  8.33it/s] 77%|███████▋  | 746/966 [01:30<00:26,  8.32it/s] 77%|███████▋  | 747/966 [01:30<00:26,  8.33it/s] 77%|███████▋  | 748/966 [01:30<00:26,  8.33it/s] 78%|███████▊  | 749/966 [01:30<00:26,  8.32it/s] 78%|███████▊  | 750/966 [01:31<00:25,  8.32it/s] 78%|███████▊  | 751/966 [01:31<00:25,  8.34it/s] 78%|███████▊  | 752/966 [01:31<00:25,  8.34it/s] 78%|███████▊  | 753/966 [01:31<00:25,  8.34it/s] 78%|███████▊  | 754/966 [01:31<00:25,  8.34it/s] 78%|███████▊  | 755/966 [01:31<00:25,  8.33it/s] 78%|███████▊  | 756/966 [01:31<00:25,  8.34it/s] 78%|███████▊  | 757/966 [01:31<00:25,  8.34it/s] 78%|███████▊  | 758/966 [01:32<00:24,  8.34it/s] 79%|███████▊  | 759/966 [01:32<00:24,  8.34it/s] 79%|███████▊  | 760/966 [01:32<00:24,  8.35it/s] 79%|███████▉  | 761/966 [01:32<00:24,  8.35it/s] 79%|███████▉  | 762/966 [01:32<00:24,  8.36it/s] 79%|███████▉  | 763/966 [01:32<00:24,  8.34it/s] 79%|███████▉  | 764/966 [01:32<00:24,  8.34it/s] 79%|███████▉  | 765/966 [01:32<00:24,  8.35it/s] 79%|███████▉  | 766/966 [01:32<00:23,  8.34it/s] 79%|███████▉  | 767/966 [01:33<00:23,  8.33it/s] 80%|███████▉  | 768/966 [01:33<00:23,  8.33it/s] 80%|███████▉  | 769/966 [01:33<00:23,  8.34it/s] 80%|███████▉  | 770/966 [01:33<00:23,  8.33it/s] 80%|███████▉  | 771/966 [01:33<00:23,  8.33it/s] 80%|███████▉  | 772/966 [01:33<00:23,  8.32it/s] 80%|████████  | 773/966 [01:33<00:23,  8.32it/s] 80%|████████  | 774/966 [01:33<00:23,  8.32it/s] 80%|████████  | 775/966 [01:34<00:22,  8.31it/s] 80%|████████  | 776/966 [01:34<00:22,  8.32it/s] 80%|████████  | 777/966 [01:34<00:22,  8.32it/s] 81%|████████  | 778/966 [01:34<00:22,  8.32it/s] 81%|████████  | 779/966 [01:34<00:22,  8.31it/s] 81%|████████  | 780/966 [01:34<00:22,  8.31it/s] 81%|████████  | 781/966 [01:34<00:22,  8.31it/s] 81%|████████  | 782/966 [01:34<00:22,  8.31it/s] 81%|████████  | 783/966 [01:35<00:21,  8.32it/s] 81%|████████  | 784/966 [01:35<00:21,  8.33it/s] 81%|████████▏ | 785/966 [01:35<00:21,  8.34it/s] 81%|████████▏ | 786/966 [01:35<00:21,  8.32it/s] 81%|████████▏ | 787/966 [01:35<00:21,  8.32it/s] 82%|████████▏ | 788/966 [01:35<00:21,  8.33it/s] 82%|████████▏ | 789/966 [01:35<00:21,  8.32it/s] 82%|████████▏ | 790/966 [01:35<00:21,  8.33it/s] 82%|████████▏ | 791/966 [01:35<00:21,  8.32it/s] 82%|████████▏ | 792/966 [01:36<00:20,  8.33it/s] 82%|████████▏ | 793/966 [01:36<00:20,  8.33it/s] 82%|████████▏ | 794/966 [01:36<00:20,  8.34it/s] 82%|████████▏ | 795/966 [01:36<00:20,  8.33it/s] 82%|████████▏ | 796/966 [01:36<00:20,  8.33it/s] 83%|████████▎ | 797/966 [01:36<00:20,  8.32it/s] 83%|████████▎ | 798/966 [01:36<00:20,  8.33it/s] 83%|████████▎ | 799/966 [01:36<00:20,  8.35it/s] 83%|████████▎ | 800/966 [01:37<00:19,  8.34it/s] 83%|████████▎ | 801/966 [01:37<00:19,  8.33it/s] 83%|████████▎ | 802/966 [01:37<00:19,  8.33it/s] 83%|████████▎ | 803/966 [01:37<00:19,  8.33it/s] 83%|████████▎ | 804/966 [01:37<00:19,  8.33it/s] 83%|████████▎ | 805/966 [01:37<00:19,  8.34it/s] 83%|████████▎ | 806/966 [01:37<00:19,  8.35it/s] 84%|████████▎ | 807/966 [01:37<00:19,  8.36it/s] 84%|████████▎ | 808/966 [01:38<00:18,  8.34it/s] 84%|████████▎ | 809/966 [01:38<00:18,  8.33it/s] 84%|████████▍ | 810/966 [01:38<00:18,  8.32it/s] 84%|████████▍ | 811/966 [01:38<00:18,  8.33it/s] 84%|████████▍ | 812/966 [01:38<00:18,  8.33it/s] 84%|████████▍ | 813/966 [01:38<00:18,  8.33it/s] 84%|████████▍ | 814/966 [01:38<00:18,  8.33it/s] 84%|████████▍ | 815/966 [01:38<00:18,  8.33it/s] 84%|████████▍ | 816/966 [01:38<00:18,  8.32it/s] 85%|████████▍ | 817/966 [01:39<00:17,  8.31it/s] 85%|████████▍ | 818/966 [01:39<00:17,  8.32it/s] 85%|████████▍ | 819/966 [01:39<00:17,  8.32it/s] 85%|████████▍ | 820/966 [01:39<00:17,  8.32it/s] 85%|████████▍ | 821/966 [01:39<00:17,  8.33it/s] 85%|████████▌ | 822/966 [01:39<00:17,  8.33it/s] 85%|████████▌ | 823/966 [01:39<00:17,  8.34it/s] 85%|████████▌ | 824/966 [01:39<00:17,  8.33it/s] 85%|████████▌ | 825/966 [01:40<00:16,  8.31it/s] 86%|████████▌ | 826/966 [01:40<00:16,  8.30it/s] 86%|████████▌ | 827/966 [01:40<00:16,  8.30it/s] 86%|████████▌ | 828/966 [01:40<00:16,  8.32it/s] 86%|████████▌ | 829/966 [01:40<00:16,  8.32it/s] 86%|████████▌ | 830/966 [01:40<00:16,  8.33it/s] 86%|████████▌ | 831/966 [01:40<00:16,  8.33it/s] 86%|████████▌ | 832/966 [01:40<00:16,  8.33it/s] 86%|████████▌ | 833/966 [01:41<00:15,  8.33it/s] 86%|████████▋ | 834/966 [01:41<00:15,  8.33it/s] 86%|████████▋ | 835/966 [01:41<00:15,  8.33it/s] 87%|████████▋ | 836/966 [01:41<00:15,  8.34it/s] 87%|████████▋ | 837/966 [01:41<00:15,  8.33it/s] 87%|████████▋ | 838/966 [01:41<00:15,  8.33it/s] 87%|████████▋ | 839/966 [01:41<00:15,  8.35it/s] 87%|████████▋ | 840/966 [01:41<00:15,  8.34it/s] 87%|████████▋ | 841/966 [01:41<00:14,  8.33it/s] 87%|████████▋ | 842/966 [01:42<00:14,  8.34it/s] 87%|████████▋ | 843/966 [01:42<00:14,  8.33it/s] 87%|████████▋ | 844/966 [01:42<00:14,  8.33it/s] 87%|████████▋ | 845/966 [01:42<00:14,  8.33it/s] 88%|████████▊ | 846/966 [01:42<00:14,  8.34it/s] 88%|████████▊ | 847/966 [01:42<00:14,  8.34it/s] 88%|████████▊ | 848/966 [01:42<00:14,  8.35it/s] 88%|████████▊ | 849/966 [01:42<00:14,  8.34it/s] 88%|████████▊ | 850/966 [01:43<00:13,  8.34it/s] 88%|████████▊ | 851/966 [01:43<00:13,  8.34it/s] 88%|████████▊ | 852/966 [01:43<00:13,  8.32it/s] 88%|████████▊ | 853/966 [01:43<00:13,  8.32it/s] 88%|████████▊ | 854/966 [01:43<00:13,  8.32it/s] 89%|████████▊ | 855/966 [01:43<00:13,  8.33it/s] 89%|████████▊ | 856/966 [01:43<00:13,  8.33it/s] 89%|████████▊ | 857/966 [01:43<00:13,  8.32it/s] 89%|████████▉ | 858/966 [01:44<00:12,  8.33it/s] 89%|████████▉ | 859/966 [01:44<00:12,  8.33it/s] 89%|████████▉ | 860/966 [01:44<00:12,  8.32it/s] 89%|████████▉ | 861/966 [01:44<00:12,  8.31it/s] 89%|████████▉ | 862/966 [01:44<00:12,  8.30it/s] 89%|████████▉ | 863/966 [01:44<00:12,  8.32it/s] 89%|████████▉ | 864/966 [01:44<00:12,  8.32it/s] 90%|████████▉ | 865/966 [01:44<00:12,  8.32it/s] 90%|████████▉ | 866/966 [01:45<00:12,  8.31it/s] 90%|████████▉ | 867/966 [01:45<00:11,  8.32it/s] 90%|████████▉ | 868/966 [01:45<00:11,  8.33it/s] 90%|████████▉ | 869/966 [01:45<00:11,  8.32it/s] 90%|█████████ | 870/966 [01:45<00:11,  8.32it/s] 90%|█████████ | 871/966 [01:45<00:11,  8.32it/s] 90%|█████████ | 872/966 [01:45<00:11,  8.32it/s] 90%|█████████ | 873/966 [01:45<00:11,  8.33it/s] 90%|█████████ | 874/966 [01:45<00:11,  8.32it/s] 91%|█████████ | 875/966 [01:46<00:10,  8.30it/s] 91%|█████████ | 876/966 [01:46<00:10,  8.31it/s] 91%|█████████ | 877/966 [01:46<00:10,  8.33it/s] 91%|█████████ | 878/966 [01:46<00:10,  8.33it/s] 91%|█████████ | 879/966 [01:46<00:10,  8.33it/s] 91%|█████████ | 880/966 [01:46<00:10,  8.32it/s] 91%|█████████ | 881/966 [01:46<00:10,  8.33it/s] 91%|█████████▏| 882/966 [01:46<00:10,  8.33it/s] 91%|█████████▏| 883/966 [01:47<00:09,  8.33it/s] 92%|█████████▏| 884/966 [01:47<00:09,  8.34it/s] 92%|█████████▏| 885/966 [01:47<00:09,  8.34it/s] 92%|█████████▏| 886/966 [01:47<00:09,  8.33it/s] 92%|█████████▏| 887/966 [01:47<00:09,  8.33it/s] 92%|█████████▏| 888/966 [01:47<00:09,  8.33it/s] 92%|█████████▏| 889/966 [01:47<00:09,  8.33it/s] 92%|█████████▏| 890/966 [01:47<00:09,  8.35it/s] 92%|█████████▏| 891/966 [01:48<00:08,  8.35it/s] 92%|█████████▏| 892/966 [01:48<00:08,  8.35it/s] 92%|█████████▏| 893/966 [01:48<00:08,  8.34it/s] 93%|█████████▎| 894/966 [01:48<00:08,  8.33it/s] 93%|█████████▎| 895/966 [01:48<00:08,  8.33it/s] 93%|█████████▎| 896/966 [01:48<00:08,  8.32it/s] 93%|█████████▎| 897/966 [01:48<00:08,  8.32it/s] 93%|█████████▎| 898/966 [01:48<00:08,  8.30it/s] 93%|█████████▎| 899/966 [01:48<00:08,  8.30it/s] 93%|█████████▎| 900/966 [01:49<00:07,  8.31it/s] 93%|█████████▎| 901/966 [01:49<00:07,  8.32it/s] 93%|█████████▎| 902/966 [01:49<00:07,  8.32it/s] 93%|█████████▎| 903/966 [01:49<00:07,  8.32it/s] 94%|█████████▎| 904/966 [01:49<00:07,  8.31it/s] 94%|█████████▎| 905/966 [01:49<00:07,  8.31it/s] 94%|█████████▍| 906/966 [01:49<00:07,  8.31it/s] 94%|█████████▍| 907/966 [01:49<00:07,  8.31it/s] 94%|█████████▍| 908/966 [01:50<00:06,  8.31it/s] 94%|█████████▍| 909/966 [01:50<00:06,  8.30it/s] 94%|█████████▍| 910/966 [01:50<00:06,  8.30it/s] 94%|█████████▍| 911/966 [01:50<00:06,  8.31it/s] 94%|█████████▍| 912/966 [01:50<00:06,  8.30it/s] 95%|█████████▍| 913/966 [01:50<00:06,  8.31it/s] 95%|█████████▍| 914/966 [01:50<00:06,  8.31it/s] 95%|█████████▍| 915/966 [01:50<00:06,  8.32it/s] 95%|█████████▍| 916/966 [01:51<00:06,  8.32it/s] 95%|█████████▍| 917/966 [01:51<00:05,  8.32it/s] 95%|█████████▌| 918/966 [01:51<00:05,  8.32it/s] 95%|█████████▌| 919/966 [01:51<00:05,  8.33it/s] 95%|█████████▌| 920/966 [01:51<00:05,  8.34it/s] 95%|█████████▌| 921/966 [01:51<00:05,  8.33it/s] 95%|█████████▌| 922/966 [01:51<00:05,  8.32it/s] 96%|█████████▌| 923/966 [01:51<00:05,  8.33it/s] 96%|█████████▌| 924/966 [01:51<00:05,  8.34it/s] 96%|█████████▌| 925/966 [01:52<00:04,  8.33it/s] 96%|█████████▌| 926/966 [01:52<00:04,  8.34it/s] 96%|█████████▌| 927/966 [01:52<00:04,  8.35it/s] 96%|█████████▌| 928/966 [01:52<00:04,  8.34it/s] 96%|█████████▌| 929/966 [01:52<00:04,  8.33it/s] 96%|█████████▋| 930/966 [01:52<00:04,  8.32it/s] 96%|█████████▋| 931/966 [01:52<00:04,  8.33it/s] 96%|█████████▋| 932/966 [01:52<00:04,  8.33it/s] 97%|█████████▋| 933/966 [01:53<00:03,  8.35it/s] 97%|█████████▋| 934/966 [01:53<00:03,  8.33it/s] 97%|█████████▋| 935/966 [01:53<00:03,  8.32it/s] 97%|█████████▋| 936/966 [01:53<00:03,  8.32it/s] 97%|█████████▋| 937/966 [01:53<00:03,  8.32it/s] 97%|█████████▋| 938/966 [01:53<00:03,  8.32it/s] 97%|█████████▋| 939/966 [01:53<00:03,  8.32it/s] 97%|█████████▋| 940/966 [01:53<00:03,  8.32it/s] 97%|█████████▋| 941/966 [01:54<00:03,  8.32it/s] 98%|█████████▊| 942/966 [01:54<00:02,  8.33it/s] 98%|█████████▊| 943/966 [01:54<00:02,  8.32it/s] 98%|█████████▊| 944/966 [01:54<00:02,  8.32it/s] 98%|█████████▊| 945/966 [01:54<00:02,  8.32it/s] 98%|█████████▊| 946/966 [01:54<00:02,  8.32it/s] 98%|█████████▊| 947/966 [01:54<00:02,  8.32it/s] 98%|█████████▊| 948/966 [01:54<00:02,  8.31it/s] 98%|█████████▊| 949/966 [01:54<00:02,  8.31it/s] 98%|█████████▊| 950/966 [01:55<00:01,  8.31it/s] 98%|█████████▊| 951/966 [01:55<00:01,  8.32it/s] 99%|█████████▊| 952/966 [01:55<00:01,  8.32it/s] 99%|█████████▊| 953/966 [01:55<00:01,  8.33it/s] 99%|█████████▉| 954/966 [01:55<00:01,  8.31it/s] 99%|█████████▉| 955/966 [01:55<00:01,  8.31it/s] 99%|█████████▉| 956/966 [01:55<00:01,  8.31it/s] 99%|█████████▉| 957/966 [01:55<00:01,  8.32it/s] 99%|█████████▉| 958/966 [01:56<00:00,  8.32it/s] 99%|█████████▉| 959/966 [01:56<00:00,  8.32it/s] 99%|█████████▉| 960/966 [01:56<00:00,  8.33it/s] 99%|█████████▉| 961/966 [01:56<00:00,  8.33it/s]100%|█████████▉| 962/966 [01:56<00:00,  8.33it/s]100%|█████████▉| 963/966 [01:56<00:00,  8.32it/s]100%|█████████▉| 964/966 [01:56<00:00,  8.32it/s]100%|█████████▉| 965/966 [01:56<00:00,  8.32it/s]100%|██████████| 966/966 [01:57<00:00,  8.33it/s]100%|██████████| 966/966 [01:57<00:00,  8.26it/s]
sending off prediction to background worker for resampling and export
done with 101-045

Predicting 706-005:
perform_everything_on_device: True
  0%|          | 0/966 [00:00<?, ?it/s]  0%|          | 2/966 [00:00<01:27, 11.05it/s]  0%|          | 4/966 [00:00<01:43,  9.28it/s]  1%|          | 5/966 [00:00<01:47,  8.98it/s]  1%|          | 6/966 [00:00<01:49,  8.77it/s]  1%|          | 7/966 [00:00<01:51,  8.64it/s]  1%|          | 8/966 [00:00<01:52,  8.55it/s]  1%|          | 9/966 [00:01<01:52,  8.48it/s]  1%|          | 10/966 [00:01<01:53,  8.44it/s]  1%|          | 11/966 [00:01<01:53,  8.41it/s]  1%|          | 12/966 [00:01<01:53,  8.38it/s]  1%|▏         | 13/966 [00:01<01:53,  8.37it/s]  1%|▏         | 14/966 [00:01<01:53,  8.36it/s]  2%|▏         | 15/966 [00:01<01:53,  8.35it/s]  2%|▏         | 16/966 [00:01<01:53,  8.33it/s]  2%|▏         | 17/966 [00:01<01:53,  8.34it/s]  2%|▏         | 18/966 [00:02<01:53,  8.34it/s]  2%|▏         | 19/966 [00:02<01:53,  8.33it/s]  2%|▏         | 20/966 [00:02<01:53,  8.33it/s]  2%|▏         | 21/966 [00:02<01:53,  8.33it/s]  2%|▏         | 22/966 [00:02<01:53,  8.33it/s]  2%|▏         | 23/966 [00:02<01:53,  8.33it/s]  2%|▏         | 24/966 [00:02<01:53,  8.32it/s]  3%|▎         | 25/966 [00:02<01:53,  8.31it/s]  3%|▎         | 26/966 [00:03<01:53,  8.31it/s]  3%|▎         | 27/966 [00:03<01:53,  8.31it/s]  3%|▎         | 28/966 [00:03<01:52,  8.32it/s]  3%|▎         | 29/966 [00:03<01:52,  8.33it/s]  3%|▎         | 30/966 [00:03<01:52,  8.32it/s]  3%|▎         | 31/966 [00:03<01:52,  8.32it/s]  3%|▎         | 32/966 [00:03<01:52,  8.31it/s]  3%|▎         | 33/966 [00:03<01:52,  8.32it/s]  4%|▎         | 34/966 [00:04<01:52,  8.32it/s]  4%|▎         | 35/966 [00:04<01:52,  8.31it/s]  4%|▎         | 36/966 [00:04<01:51,  8.32it/s]  4%|▍         | 37/966 [00:04<01:51,  8.33it/s]  4%|▍         | 38/966 [00:04<01:51,  8.35it/s]  4%|▍         | 39/966 [00:04<01:51,  8.34it/s]  4%|▍         | 40/966 [00:04<01:51,  8.34it/s]  4%|▍         | 41/966 [00:04<01:50,  8.34it/s]  4%|▍         | 42/966 [00:04<01:50,  8.35it/s]  4%|▍         | 43/966 [00:05<01:50,  8.36it/s]  5%|▍         | 44/966 [00:05<01:50,  8.37it/s]  5%|▍         | 45/966 [00:05<01:50,  8.35it/s]  5%|▍         | 46/966 [00:05<01:50,  8.34it/s]  5%|▍         | 47/966 [00:05<01:50,  8.33it/s]  5%|▍         | 48/966 [00:05<01:50,  8.34it/s]  5%|▌         | 49/966 [00:05<01:49,  8.35it/s]  5%|▌         | 50/966 [00:05<01:49,  8.35it/s]  5%|▌         | 51/966 [00:06<01:49,  8.35it/s]  5%|▌         | 52/966 [00:06<01:49,  8.35it/s]  5%|▌         | 53/966 [00:06<01:49,  8.34it/s]  6%|▌         | 54/966 [00:06<01:49,  8.32it/s]  6%|▌         | 55/966 [00:06<01:49,  8.33it/s]  6%|▌         | 56/966 [00:06<01:49,  8.34it/s]  6%|▌         | 57/966 [00:06<01:49,  8.33it/s]  6%|▌         | 58/966 [00:06<01:49,  8.32it/s]  6%|▌         | 59/966 [00:07<01:49,  8.32it/s]  6%|▌         | 60/966 [00:07<01:48,  8.33it/s]  6%|▋         | 61/966 [00:07<01:48,  8.32it/s]  6%|▋         | 62/966 [00:07<01:48,  8.33it/s]  7%|▋         | 63/966 [00:07<01:48,  8.33it/s]  7%|▋         | 64/966 [00:07<01:48,  8.33it/s]  7%|▋         | 65/966 [00:07<01:48,  8.32it/s]  7%|▋         | 66/966 [00:07<01:48,  8.32it/s]  7%|▋         | 67/966 [00:07<01:48,  8.31it/s]  7%|▋         | 68/966 [00:08<01:48,  8.31it/s]  7%|▋         | 69/966 [00:08<01:47,  8.31it/s]  7%|▋         | 70/966 [00:08<01:47,  8.31it/s]  7%|▋         | 71/966 [00:08<01:47,  8.30it/s]  7%|▋         | 72/966 [00:08<01:47,  8.31it/s]  8%|▊         | 73/966 [00:08<01:47,  8.31it/s]  8%|▊         | 74/966 [00:08<01:47,  8.32it/s]  8%|▊         | 75/966 [00:08<01:47,  8.32it/s]  8%|▊         | 76/966 [00:09<01:46,  8.32it/s]  8%|▊         | 77/966 [00:09<01:46,  8.33it/s]  8%|▊         | 78/966 [00:09<01:46,  8.34it/s]  8%|▊         | 79/966 [00:09<01:46,  8.34it/s]  8%|▊         | 80/966 [00:09<01:46,  8.33it/s]  8%|▊         | 81/966 [00:09<01:46,  8.33it/s]  8%|▊         | 82/966 [00:09<01:46,  8.34it/s]  9%|▊         | 83/966 [00:09<01:45,  8.33it/s]  9%|▊         | 84/966 [00:10<01:45,  8.34it/s]  9%|▉         | 85/966 [00:10<01:45,  8.35it/s]  9%|▉         | 86/966 [00:10<01:45,  8.35it/s]  9%|▉         | 87/966 [00:10<01:45,  8.33it/s]  9%|▉         | 88/966 [00:10<01:45,  8.34it/s]  9%|▉         | 89/966 [00:10<01:45,  8.33it/s]  9%|▉         | 90/966 [00:10<01:45,  8.33it/s]  9%|▉         | 91/966 [00:10<01:44,  8.34it/s] 10%|▉         | 92/966 [00:10<01:44,  8.34it/s] 10%|▉         | 93/966 [00:11<01:44,  8.35it/s] 10%|▉         | 94/966 [00:11<01:44,  8.34it/s] 10%|▉         | 95/966 [00:11<01:44,  8.33it/s] 10%|▉         | 96/966 [00:11<01:44,  8.34it/s] 10%|█         | 97/966 [00:11<01:44,  8.33it/s] 10%|█         | 98/966 [00:11<01:44,  8.33it/s] 10%|█         | 99/966 [00:11<01:43,  8.34it/s] 10%|█         | 100/966 [00:11<01:43,  8.33it/s] 10%|█         | 101/966 [00:12<01:43,  8.32it/s] 11%|█         | 102/966 [00:12<01:43,  8.33it/s] 11%|█         | 103/966 [00:12<01:43,  8.32it/s] 11%|█         | 104/966 [00:12<01:43,  8.32it/s] 11%|█         | 105/966 [00:12<01:43,  8.32it/s] 11%|█         | 106/966 [00:12<01:43,  8.31it/s] 11%|█         | 107/966 [00:12<01:43,  8.31it/s] 11%|█         | 108/966 [00:12<01:43,  8.31it/s] 11%|█▏        | 109/966 [00:13<01:43,  8.31it/s] 11%|█▏        | 110/966 [00:13<01:43,  8.31it/s] 11%|█▏        | 111/966 [00:13<01:42,  8.31it/s] 12%|█▏        | 112/966 [00:13<01:42,  8.33it/s] 12%|█▏        | 113/966 [00:13<01:42,  8.31it/s] 12%|█▏        | 114/966 [00:13<01:42,  8.32it/s] 12%|█▏        | 115/966 [00:13<01:42,  8.31it/s] 12%|█▏        | 116/966 [00:13<01:42,  8.31it/s] 12%|█▏        | 117/966 [00:13<01:42,  8.31it/s] 12%|█▏        | 118/966 [00:14<01:42,  8.30it/s] 12%|█▏        | 119/966 [00:14<01:42,  8.30it/s] 12%|█▏        | 120/966 [00:14<01:41,  8.31it/s] 13%|█▎        | 121/966 [00:14<01:41,  8.34it/s] 13%|█▎        | 122/966 [00:14<01:41,  8.34it/s] 13%|█▎        | 123/966 [00:14<01:41,  8.34it/s] 13%|█▎        | 124/966 [00:14<01:41,  8.33it/s] 13%|█▎        | 125/966 [00:14<01:40,  8.34it/s] 13%|█▎        | 126/966 [00:15<01:40,  8.35it/s] 13%|█▎        | 127/966 [00:15<01:40,  8.34it/s] 13%|█▎        | 128/966 [00:15<01:40,  8.35it/s] 13%|█▎        | 129/966 [00:15<01:40,  8.34it/s] 13%|█▎        | 130/966 [00:15<01:40,  8.34it/s] 14%|█▎        | 131/966 [00:15<01:40,  8.33it/s] 14%|█▎        | 132/966 [00:15<01:40,  8.32it/s] 14%|█▍        | 133/966 [00:15<01:40,  8.33it/s] 14%|█▍        | 134/966 [00:16<01:39,  8.33it/s] 14%|█▍        | 135/966 [00:16<01:39,  8.33it/s] 14%|█▍        | 136/966 [00:16<01:39,  8.33it/s] 14%|█▍        | 137/966 [00:16<01:39,  8.34it/s] 14%|█▍        | 138/966 [00:16<01:39,  8.34it/s] 14%|█▍        | 139/966 [00:16<01:39,  8.33it/s] 14%|█▍        | 140/966 [00:16<01:39,  8.34it/s] 15%|█▍        | 141/966 [00:16<01:39,  8.33it/s] 15%|█▍        | 142/966 [00:16<01:38,  8.33it/s] 15%|█▍        | 143/966 [00:17<01:38,  8.33it/s] 15%|█▍        | 144/966 [00:17<01:38,  8.32it/s] 15%|█▌        | 145/966 [00:17<01:38,  8.32it/s] 15%|█▌        | 146/966 [00:17<01:38,  8.32it/s] 15%|█▌        | 147/966 [00:17<01:38,  8.32it/s] 15%|█▌        | 148/966 [00:17<01:38,  8.31it/s] 15%|█▌        | 149/966 [00:17<01:38,  8.30it/s] 16%|█▌        | 150/966 [00:17<01:38,  8.30it/s] 16%|█▌        | 151/966 [00:18<01:38,  8.30it/s] 16%|█▌        | 152/966 [00:18<01:37,  8.31it/s] 16%|█▌        | 153/966 [00:18<01:37,  8.31it/s] 16%|█▌        | 154/966 [00:18<01:37,  8.32it/s] 16%|█▌        | 155/966 [00:18<01:37,  8.33it/s] 16%|█▌        | 156/966 [00:18<01:37,  8.32it/s] 16%|█▋        | 157/966 [00:18<01:37,  8.31it/s] 16%|█▋        | 158/966 [00:18<01:37,  8.31it/s] 16%|█▋        | 159/966 [00:19<01:37,  8.31it/s] 17%|█▋        | 160/966 [00:19<01:36,  8.32it/s] 17%|█▋        | 161/966 [00:19<01:36,  8.33it/s] 17%|█▋        | 162/966 [00:19<01:36,  8.32it/s] 17%|█▋        | 163/966 [00:19<01:36,  8.33it/s] 17%|█▋        | 164/966 [00:19<01:36,  8.34it/s] 17%|█▋        | 165/966 [00:19<01:36,  8.34it/s] 17%|█▋        | 166/966 [00:19<01:35,  8.33it/s] 17%|█▋        | 167/966 [00:19<01:35,  8.33it/s] 17%|█▋        | 168/966 [00:20<01:35,  8.33it/s] 17%|█▋        | 169/966 [00:20<01:35,  8.34it/s] 18%|█▊        | 170/966 [00:20<01:35,  8.35it/s] 18%|█▊        | 171/966 [00:20<01:35,  8.34it/s] 18%|█▊        | 172/966 [00:20<01:35,  8.33it/s] 18%|█▊        | 173/966 [00:20<01:35,  8.32it/s] 18%|█▊        | 174/966 [00:20<01:35,  8.33it/s] 18%|█▊        | 175/966 [00:20<01:34,  8.34it/s] 18%|█▊        | 176/966 [00:21<01:34,  8.35it/s] 18%|█▊        | 177/966 [00:21<01:34,  8.34it/s] 18%|█▊        | 178/966 [00:21<01:34,  8.33it/s] 19%|█▊        | 179/966 [00:21<01:34,  8.32it/s] 19%|█▊        | 180/966 [00:21<01:34,  8.32it/s] 19%|█▊        | 181/966 [00:21<01:34,  8.33it/s] 19%|█▉        | 182/966 [00:21<01:34,  8.33it/s] 19%|█▉        | 183/966 [00:21<01:34,  8.33it/s] 19%|█▉        | 184/966 [00:22<01:33,  8.33it/s] 19%|█▉        | 185/966 [00:22<01:33,  8.32it/s] 19%|█▉        | 186/966 [00:22<01:33,  8.32it/s] 19%|█▉        | 187/966 [00:22<01:33,  8.32it/s] 19%|█▉        | 188/966 [00:22<01:33,  8.31it/s] 20%|█▉        | 189/966 [00:22<01:33,  8.31it/s] 20%|█▉        | 190/966 [00:22<01:33,  8.31it/s] 20%|█▉        | 191/966 [00:22<01:33,  8.31it/s] 20%|█▉        | 192/966 [00:22<01:33,  8.30it/s] 20%|█▉        | 193/966 [00:23<01:33,  8.29it/s] 20%|██        | 194/966 [00:23<01:32,  8.30it/s] 20%|██        | 195/966 [00:23<01:32,  8.30it/s] 20%|██        | 196/966 [00:23<01:32,  8.30it/s] 20%|██        | 197/966 [00:23<01:32,  8.30it/s] 20%|██        | 198/966 [00:23<01:32,  8.31it/s] 21%|██        | 199/966 [00:23<01:32,  8.32it/s] 21%|██        | 200/966 [00:23<01:32,  8.32it/s] 21%|██        | 201/966 [00:24<01:31,  8.32it/s] 21%|██        | 202/966 [00:24<01:31,  8.32it/s] 21%|██        | 203/966 [00:24<01:31,  8.33it/s] 21%|██        | 204/966 [00:24<01:31,  8.32it/s] 21%|██        | 205/966 [00:24<01:31,  8.32it/s] 21%|██▏       | 206/966 [00:24<01:31,  8.32it/s] 21%|██▏       | 207/966 [00:24<01:31,  8.33it/s] 22%|██▏       | 208/966 [00:24<01:31,  8.33it/s] 22%|██▏       | 209/966 [00:25<01:30,  8.33it/s] 22%|██▏       | 210/966 [00:25<01:30,  8.33it/s] 22%|██▏       | 211/966 [00:25<01:30,  8.35it/s] 22%|██▏       | 212/966 [00:25<01:30,  8.35it/s] 22%|██▏       | 213/966 [00:25<01:30,  8.35it/s] 22%|██▏       | 214/966 [00:25<01:30,  8.33it/s] 22%|██▏       | 215/966 [00:25<01:30,  8.34it/s] 22%|██▏       | 216/966 [00:25<01:29,  8.34it/s] 22%|██▏       | 217/966 [00:26<01:29,  8.34it/s] 23%|██▎       | 218/966 [00:26<01:29,  8.33it/s] 23%|██▎       | 219/966 [00:26<01:29,  8.32it/s] 23%|██▎       | 220/966 [00:26<01:29,  8.32it/s] 23%|██▎       | 221/966 [00:26<01:29,  8.33it/s] 23%|██▎       | 222/966 [00:26<01:29,  8.33it/s] 23%|██▎       | 223/966 [00:26<01:29,  8.34it/s] 23%|██▎       | 224/966 [00:26<01:29,  8.34it/s] 23%|██▎       | 225/966 [00:26<01:29,  8.32it/s] 23%|██▎       | 226/966 [00:27<01:29,  8.31it/s] 23%|██▎       | 227/966 [00:27<01:29,  8.30it/s] 24%|██▎       | 228/966 [00:27<01:28,  8.31it/s] 24%|██▎       | 229/966 [00:27<01:28,  8.31it/s] 24%|██▍       | 230/966 [00:27<01:28,  8.31it/s] 24%|██▍       | 231/966 [00:27<01:28,  8.31it/s] 24%|██▍       | 232/966 [00:27<01:28,  8.33it/s] 24%|██▍       | 233/966 [00:27<01:28,  8.32it/s] 24%|██▍       | 234/966 [00:28<01:28,  8.31it/s] 24%|██▍       | 235/966 [00:28<01:28,  8.30it/s] 24%|██▍       | 236/966 [00:28<01:27,  8.30it/s] 25%|██▍       | 237/966 [00:28<01:27,  8.31it/s] 25%|██▍       | 238/966 [00:28<01:27,  8.31it/s] 25%|██▍       | 239/966 [00:28<01:27,  8.31it/s] 25%|██▍       | 240/966 [00:28<01:27,  8.32it/s] 25%|██▍       | 241/966 [00:28<01:27,  8.33it/s] 25%|██▌       | 242/966 [00:29<01:27,  8.32it/s] 25%|██▌       | 243/966 [00:29<01:27,  8.30it/s] 25%|██▌       | 244/966 [00:29<01:27,  8.30it/s] 25%|██▌       | 245/966 [00:29<01:26,  8.31it/s] 25%|██▌       | 246/966 [00:29<01:26,  8.32it/s] 26%|██▌       | 247/966 [00:29<01:26,  8.33it/s] 26%|██▌       | 248/966 [00:29<01:26,  8.33it/s] 26%|██▌       | 249/966 [00:29<01:26,  8.33it/s] 26%|██▌       | 250/966 [00:29<01:25,  8.34it/s] 26%|██▌       | 251/966 [00:30<01:25,  8.34it/s] 26%|██▌       | 252/966 [00:30<01:25,  8.32it/s] 26%|██▌       | 253/966 [00:30<01:25,  8.33it/s] 26%|██▋       | 254/966 [00:30<01:25,  8.33it/s] 26%|██▋       | 255/966 [00:30<01:25,  8.33it/s] 27%|██▋       | 256/966 [00:30<01:25,  8.34it/s] 27%|██▋       | 257/966 [00:30<01:25,  8.34it/s] 27%|██▋       | 258/966 [00:30<01:24,  8.35it/s] 27%|██▋       | 259/966 [00:31<01:24,  8.34it/s] 27%|██▋       | 260/966 [00:31<01:24,  8.33it/s] 27%|██▋       | 261/966 [00:31<01:24,  8.33it/s] 27%|██▋       | 262/966 [00:31<01:24,  8.32it/s] 27%|██▋       | 263/966 [00:31<01:24,  8.32it/s] 27%|██▋       | 264/966 [00:31<01:24,  8.31it/s] 27%|██▋       | 265/966 [00:31<01:24,  8.32it/s] 28%|██▊       | 266/966 [00:31<01:24,  8.33it/s] 28%|██▊       | 267/966 [00:32<01:23,  8.33it/s] 28%|██▊       | 268/966 [00:32<01:24,  8.30it/s] 28%|██▊       | 269/966 [00:32<01:23,  8.30it/s] 28%|██▊       | 270/966 [00:32<01:23,  8.30it/s] 28%|██▊       | 271/966 [00:32<01:23,  8.30it/s] 28%|██▊       | 272/966 [00:32<01:23,  8.31it/s] 28%|██▊       | 273/966 [00:32<01:23,  8.31it/s] 28%|██▊       | 274/966 [00:32<01:23,  8.32it/s] 28%|██▊       | 275/966 [00:32<01:23,  8.32it/s] 29%|██▊       | 276/966 [00:33<01:22,  8.32it/s] 29%|██▊       | 277/966 [00:33<01:22,  8.31it/s] 29%|██▉       | 278/966 [00:33<01:22,  8.31it/s] 29%|██▉       | 279/966 [00:33<01:22,  8.31it/s] 29%|██▉       | 280/966 [00:33<01:22,  8.30it/s] 29%|██▉       | 281/966 [00:33<01:22,  8.30it/s] 29%|██▉       | 282/966 [00:33<01:22,  8.30it/s] 29%|██▉       | 283/966 [00:33<01:22,  8.31it/s] 29%|██▉       | 284/966 [00:34<01:22,  8.31it/s] 30%|██▉       | 285/966 [00:34<01:21,  8.32it/s] 30%|██▉       | 286/966 [00:34<01:21,  8.32it/s] 30%|██▉       | 287/966 [00:34<01:21,  8.31it/s] 30%|██▉       | 288/966 [00:34<01:21,  8.31it/s] 30%|██▉       | 289/966 [00:34<01:21,  8.31it/s] 30%|███       | 290/966 [00:34<01:21,  8.31it/s] 30%|███       | 291/966 [00:34<01:21,  8.32it/s] 30%|███       | 292/966 [00:35<01:20,  8.32it/s] 30%|███       | 293/966 [00:35<01:20,  8.33it/s] 30%|███       | 294/966 [00:35<01:20,  8.34it/s] 31%|███       | 295/966 [00:35<01:20,  8.35it/s] 31%|███       | 296/966 [00:35<01:20,  8.35it/s] 31%|███       | 297/966 [00:35<01:20,  8.34it/s] 31%|███       | 298/966 [00:35<01:20,  8.33it/s] 31%|███       | 299/966 [00:35<01:20,  8.33it/s] 31%|███       | 300/966 [00:35<01:19,  8.33it/s] 31%|███       | 301/966 [00:36<01:19,  8.34it/s] 31%|███▏      | 302/966 [00:36<01:19,  8.34it/s] 31%|███▏      | 303/966 [00:36<01:19,  8.33it/s] 31%|███▏      | 304/966 [00:36<01:19,  8.33it/s] 32%|███▏      | 305/966 [00:36<01:19,  8.31it/s] 32%|███▏      | 306/966 [00:36<01:19,  8.31it/s] 32%|███▏      | 307/966 [00:36<01:19,  8.31it/s] 32%|███▏      | 308/966 [00:36<01:19,  8.31it/s] 32%|███▏      | 309/966 [00:37<01:19,  8.31it/s] 32%|███▏      | 310/966 [00:37<01:18,  8.31it/s] 32%|███▏      | 311/966 [00:37<01:18,  8.32it/s] 32%|███▏      | 312/966 [00:37<01:18,  8.32it/s] 32%|███▏      | 313/966 [00:37<01:18,  8.32it/s] 33%|███▎      | 314/966 [00:37<01:18,  8.31it/s] 33%|███▎      | 315/966 [00:37<01:18,  8.31it/s] 33%|███▎      | 316/966 [00:37<01:18,  8.29it/s] 33%|███▎      | 317/966 [00:38<01:18,  8.29it/s] 33%|███▎      | 318/966 [00:38<01:18,  8.30it/s] 33%|███▎      | 319/966 [00:38<01:17,  8.31it/s] 33%|███▎      | 320/966 [00:38<01:17,  8.31it/s] 33%|███▎      | 321/966 [00:38<01:17,  8.31it/s] 33%|███▎      | 322/966 [00:38<01:17,  8.30it/s] 33%|███▎      | 323/966 [00:38<01:17,  8.30it/s] 34%|███▎      | 324/966 [00:38<01:17,  8.31it/s] 34%|███▎      | 325/966 [00:38<01:17,  8.30it/s] 34%|███▎      | 326/966 [00:39<01:17,  8.31it/s] 34%|███▍      | 327/966 [00:39<01:16,  8.30it/s] 34%|███▍      | 328/966 [00:39<01:16,  8.31it/s] 34%|███▍      | 329/966 [00:39<01:16,  8.31it/s] 34%|███▍      | 330/966 [00:39<01:16,  8.33it/s] 34%|███▍      | 331/966 [00:39<01:16,  8.34it/s] 34%|███▍      | 332/966 [00:39<01:16,  8.33it/s] 34%|███▍      | 333/966 [00:39<01:16,  8.32it/s] 35%|███▍      | 334/966 [00:40<01:15,  8.32it/s] 35%|███▍      | 335/966 [00:40<01:15,  8.31it/s] 35%|███▍      | 336/966 [00:40<01:15,  8.31it/s] 35%|███▍      | 337/966 [00:40<01:15,  8.32it/s] 35%|███▍      | 338/966 [00:40<01:15,  8.33it/s] 35%|███▌      | 339/966 [00:40<01:15,  8.34it/s] 35%|███▌      | 340/966 [00:40<01:15,  8.34it/s] 35%|███▌      | 341/966 [00:40<01:14,  8.35it/s] 35%|███▌      | 342/966 [00:41<01:14,  8.35it/s] 36%|███▌      | 343/966 [00:41<01:14,  8.34it/s] 36%|███▌      | 344/966 [00:41<01:14,  8.33it/s] 36%|███▌      | 345/966 [00:41<01:14,  8.33it/s] 36%|███▌      | 346/966 [00:41<01:14,  8.33it/s] 36%|███▌      | 347/966 [00:41<01:14,  8.34it/s] 36%|███▌      | 348/966 [00:41<01:14,  8.34it/s] 36%|███▌      | 349/966 [00:41<01:14,  8.34it/s] 36%|███▌      | 350/966 [00:41<01:13,  8.34it/s] 36%|███▋      | 351/966 [00:42<01:13,  8.34it/s] 36%|███▋      | 352/966 [00:42<01:13,  8.31it/s] 37%|███▋      | 353/966 [00:42<01:13,  8.31it/s] 37%|███▋      | 354/966 [00:42<01:13,  8.31it/s] 37%|███▋      | 355/966 [00:42<01:13,  8.32it/s] 37%|███▋      | 356/966 [00:42<01:13,  8.33it/s] 37%|███▋      | 357/966 [00:42<01:13,  8.31it/s] 37%|███▋      | 358/966 [00:42<01:13,  8.31it/s] 37%|███▋      | 359/966 [00:43<01:12,  8.32it/s] 37%|███▋      | 360/966 [00:43<01:12,  8.31it/s] 37%|███▋      | 361/966 [00:43<01:12,  8.31it/s] 37%|███▋      | 362/966 [00:43<01:12,  8.31it/s] 38%|███▊      | 363/966 [00:43<01:12,  8.32it/s] 38%|███▊      | 364/966 [00:43<01:12,  8.32it/s] 38%|███▊      | 365/966 [00:43<01:12,  8.31it/s] 38%|███▊      | 366/966 [00:43<01:12,  8.32it/s] 38%|███▊      | 367/966 [00:44<01:11,  8.33it/s] 38%|███▊      | 368/966 [00:44<01:11,  8.32it/s] 38%|███▊      | 369/966 [00:44<01:11,  8.32it/s] 38%|███▊      | 370/966 [00:44<01:11,  8.32it/s] 38%|███▊      | 371/966 [00:44<01:11,  8.33it/s] 39%|███▊      | 372/966 [00:44<01:11,  8.34it/s] 39%|███▊      | 373/966 [00:44<01:11,  8.34it/s] 39%|███▊      | 374/966 [00:44<01:11,  8.33it/s] 39%|███▉      | 375/966 [00:44<01:10,  8.34it/s] 39%|███▉      | 376/966 [00:45<01:10,  8.34it/s] 39%|███▉      | 377/966 [00:45<01:10,  8.34it/s] 39%|███▉      | 378/966 [00:45<01:10,  8.34it/s] 39%|███▉      | 379/966 [00:45<01:10,  8.35it/s] 39%|███▉      | 380/966 [00:45<01:10,  8.36it/s] 39%|███▉      | 381/966 [00:45<01:10,  8.35it/s] 40%|███▉      | 382/966 [00:45<01:10,  8.33it/s] 40%|███▉      | 383/966 [00:45<01:10,  8.33it/s] 40%|███▉      | 384/966 [00:46<01:09,  8.33it/s] 40%|███▉      | 385/966 [00:46<01:09,  8.34it/s] 40%|███▉      | 386/966 [00:46<01:09,  8.35it/s] 40%|████      | 387/966 [00:46<01:09,  8.34it/s] 40%|████      | 388/966 [00:46<01:09,  8.34it/s] 40%|████      | 389/966 [00:46<01:09,  8.33it/s] 40%|████      | 390/966 [00:46<01:09,  8.33it/s] 40%|████      | 391/966 [00:46<01:09,  8.32it/s] 41%|████      | 392/966 [00:47<01:08,  8.33it/s] 41%|████      | 393/966 [00:47<01:08,  8.32it/s] 41%|████      | 394/966 [00:47<01:08,  8.32it/s] 41%|████      | 395/966 [00:47<01:08,  8.32it/s] 41%|████      | 396/966 [00:47<01:08,  8.31it/s] 41%|████      | 397/966 [00:47<01:08,  8.30it/s] 41%|████      | 398/966 [00:47<01:08,  8.31it/s] 41%|████▏     | 399/966 [00:47<01:08,  8.31it/s] 41%|████▏     | 400/966 [00:47<01:08,  8.31it/s] 42%|████▏     | 401/966 [00:48<01:07,  8.31it/s] 42%|████▏     | 402/966 [00:48<01:07,  8.31it/s] 42%|████▏     | 403/966 [00:48<01:07,  8.30it/s] 42%|████▏     | 404/966 [00:48<01:07,  8.30it/s] 42%|████▏     | 405/966 [00:48<01:07,  8.31it/s] 42%|████▏     | 406/966 [00:48<01:07,  8.32it/s] 42%|████▏     | 407/966 [00:48<01:07,  8.32it/s] 42%|████▏     | 408/966 [00:48<01:06,  8.33it/s] 42%|████▏     | 409/966 [00:49<01:06,  8.32it/s] 42%|████▏     | 410/966 [00:49<01:06,  8.31it/s] 43%|████▎     | 411/966 [00:49<01:06,  8.31it/s] 43%|████▎     | 412/966 [00:49<01:06,  8.32it/s] 43%|████▎     | 413/966 [00:49<01:06,  8.32it/s] 43%|████▎     | 414/966 [00:49<01:06,  8.32it/s] 43%|████▎     | 415/966 [00:49<01:06,  8.34it/s] 43%|████▎     | 416/966 [00:49<01:06,  8.33it/s] 43%|████▎     | 417/966 [00:50<01:05,  8.34it/s] 43%|████▎     | 418/966 [00:50<01:05,  8.34it/s] 43%|████▎     | 419/966 [00:50<01:05,  8.35it/s] 43%|████▎     | 420/966 [00:50<01:05,  8.35it/s] 44%|████▎     | 421/966 [00:50<01:05,  8.34it/s] 44%|████▎     | 422/966 [00:50<01:05,  8.35it/s] 44%|████▍     | 423/966 [00:50<01:05,  8.35it/s] 44%|████▍     | 424/966 [00:50<01:04,  8.35it/s] 44%|████▍     | 425/966 [00:50<01:04,  8.35it/s] 44%|████▍     | 426/966 [00:51<01:04,  8.33it/s] 44%|████▍     | 427/966 [00:51<01:04,  8.33it/s] 44%|████▍     | 428/966 [00:51<01:04,  8.34it/s] 44%|████▍     | 429/966 [00:51<01:04,  8.34it/s] 45%|████▍     | 430/966 [00:51<01:04,  8.33it/s] 45%|████▍     | 431/966 [00:51<01:04,  8.32it/s] 45%|████▍     | 432/966 [00:51<01:04,  8.31it/s] 45%|████▍     | 433/966 [00:51<01:04,  8.32it/s] 45%|████▍     | 434/966 [00:52<01:03,  8.32it/s] 45%|████▌     | 435/966 [00:52<01:03,  8.33it/s] 45%|████▌     | 436/966 [00:52<01:03,  8.34it/s] 45%|████▌     | 437/966 [00:52<01:03,  8.35it/s] 45%|████▌     | 438/966 [00:52<01:03,  8.33it/s] 45%|████▌     | 439/966 [00:52<01:03,  8.33it/s] 46%|████▌     | 440/966 [00:52<01:03,  8.32it/s] 46%|████▌     | 441/966 [00:52<01:03,  8.32it/s] 46%|████▌     | 442/966 [00:53<01:02,  8.33it/s] 46%|████▌     | 443/966 [00:53<01:02,  8.33it/s] 46%|████▌     | 444/966 [00:53<01:02,  8.33it/s] 46%|████▌     | 445/966 [00:53<01:02,  8.33it/s] 46%|████▌     | 446/966 [00:53<01:02,  8.32it/s] 46%|████▋     | 447/966 [00:53<01:02,  8.33it/s] 46%|████▋     | 448/966 [00:53<01:02,  8.32it/s] 46%|████▋     | 449/966 [00:53<01:02,  8.31it/s] 47%|████▋     | 450/966 [00:53<01:02,  8.32it/s] 47%|████▋     | 451/966 [00:54<01:01,  8.32it/s] 47%|████▋     | 452/966 [00:54<01:01,  8.33it/s] 47%|████▋     | 453/966 [00:54<01:01,  8.32it/s] 47%|████▋     | 454/966 [00:54<01:01,  8.32it/s] 47%|████▋     | 455/966 [00:54<01:01,  8.33it/s] 47%|████▋     | 456/966 [00:54<01:01,  8.34it/s] 47%|████▋     | 457/966 [00:54<01:01,  8.33it/s] 47%|████▋     | 458/966 [00:54<01:00,  8.34it/s] 48%|████▊     | 459/966 [00:55<01:00,  8.34it/s] 48%|████▊     | 460/966 [00:55<01:00,  8.34it/s] 48%|████▊     | 461/966 [00:55<01:00,  8.33it/s] 48%|████▊     | 462/966 [00:55<01:00,  8.34it/s] 48%|████▊     | 463/966 [00:55<01:00,  8.35it/s] 48%|████▊     | 464/966 [00:55<01:00,  8.36it/s] 48%|████▊     | 465/966 [00:55<01:00,  8.33it/s] 48%|████▊     | 466/966 [00:55<01:00,  8.32it/s] 48%|████▊     | 467/966 [00:56<00:59,  8.33it/s] 48%|████▊     | 468/966 [00:56<00:59,  8.34it/s] 49%|████▊     | 469/966 [00:56<00:59,  8.35it/s] 49%|████▊     | 470/966 [00:56<00:59,  8.35it/s] 49%|████▉     | 471/966 [00:56<00:59,  8.35it/s] 49%|████▉     | 472/966 [00:56<00:59,  8.34it/s] 49%|████▉     | 473/966 [00:56<00:59,  8.32it/s] 49%|████▉     | 474/966 [00:56<00:59,  8.31it/s] 49%|████▉     | 475/966 [00:56<00:58,  8.32it/s] 49%|████▉     | 476/966 [00:57<00:58,  8.33it/s] 49%|████▉     | 477/966 [00:57<00:58,  8.33it/s] 49%|████▉     | 478/966 [00:57<00:58,  8.32it/s] 50%|████▉     | 479/966 [00:57<00:58,  8.33it/s] 50%|████▉     | 480/966 [00:57<00:58,  8.32it/s] 50%|████▉     | 481/966 [00:57<00:58,  8.31it/s] 50%|████▉     | 482/966 [00:57<00:58,  8.31it/s] 50%|█████     | 483/966 [00:57<00:58,  8.30it/s] 50%|█████     | 484/966 [00:58<00:58,  8.30it/s] 50%|█████     | 485/966 [00:58<00:57,  8.31it/s] 50%|█████     | 486/966 [00:58<00:57,  8.31it/s] 50%|█████     | 487/966 [00:58<00:57,  8.31it/s] 51%|█████     | 488/966 [00:58<00:57,  8.31it/s] 51%|█████     | 489/966 [00:58<00:57,  8.31it/s] 51%|█████     | 490/966 [00:58<00:57,  8.32it/s] 51%|█████     | 491/966 [00:58<00:57,  8.31it/s] 51%|█████     | 492/966 [00:59<00:57,  8.31it/s] 51%|█████     | 493/966 [00:59<00:56,  8.31it/s] 51%|█████     | 494/966 [00:59<00:56,  8.32it/s] 51%|█████     | 495/966 [00:59<00:56,  8.32it/s] 51%|█████▏    | 496/966 [00:59<00:56,  8.33it/s] 51%|█████▏    | 497/966 [00:59<00:56,  8.33it/s] 52%|█████▏    | 498/966 [00:59<00:56,  8.34it/s] 52%|█████▏    | 499/966 [00:59<00:55,  8.34it/s] 52%|█████▏    | 500/966 [01:00<00:55,  8.34it/s] 52%|█████▏    | 501/966 [01:00<00:55,  8.35it/s] 52%|█████▏    | 502/966 [01:00<00:55,  8.34it/s] 52%|█████▏    | 503/966 [01:00<00:55,  8.32it/s] 52%|█████▏    | 504/966 [01:00<00:55,  8.33it/s] 52%|█████▏    | 505/966 [01:00<00:55,  8.34it/s] 52%|█████▏    | 506/966 [01:00<00:55,  8.35it/s] 52%|█████▏    | 507/966 [01:00<00:55,  8.34it/s] 53%|█████▎    | 508/966 [01:00<00:54,  8.34it/s] 53%|█████▎    | 509/966 [01:01<00:54,  8.34it/s] 53%|█████▎    | 510/966 [01:01<00:54,  8.34it/s] 53%|█████▎    | 511/966 [01:01<00:54,  8.34it/s] 53%|█████▎    | 512/966 [01:01<00:54,  8.34it/s] 53%|█████▎    | 513/966 [01:01<00:54,  8.33it/s] 53%|█████▎    | 514/966 [01:01<00:54,  8.34it/s] 53%|█████▎    | 515/966 [01:01<00:54,  8.33it/s] 53%|█████▎    | 516/966 [01:01<00:54,  8.32it/s] 54%|█████▎    | 517/966 [01:02<00:53,  8.32it/s] 54%|█████▎    | 518/966 [01:02<00:53,  8.33it/s] 54%|█████▎    | 519/966 [01:02<00:53,  8.32it/s] 54%|█████▍    | 520/966 [01:02<00:53,  8.32it/s] 54%|█████▍    | 521/966 [01:02<00:53,  8.32it/s] 54%|█████▍    | 522/966 [01:02<00:53,  8.32it/s] 54%|█████▍    | 523/966 [01:02<00:53,  8.32it/s] 54%|█████▍    | 524/966 [01:02<00:53,  8.32it/s] 54%|█████▍    | 525/966 [01:03<00:53,  8.31it/s] 54%|█████▍    | 526/966 [01:03<00:53,  8.30it/s] 55%|█████▍    | 527/966 [01:03<00:52,  8.31it/s] 55%|█████▍    | 528/966 [01:03<00:52,  8.32it/s] 55%|█████▍    | 529/966 [01:03<00:52,  8.32it/s] 55%|█████▍    | 530/966 [01:03<00:52,  8.32it/s] 55%|█████▍    | 531/966 [01:03<00:52,  8.32it/s] 55%|█████▌    | 532/966 [01:03<00:52,  8.32it/s] 55%|█████▌    | 533/966 [01:03<00:52,  8.31it/s] 55%|█████▌    | 534/966 [01:04<00:52,  8.31it/s] 55%|█████▌    | 535/966 [01:04<00:51,  8.31it/s] 55%|█████▌    | 536/966 [01:04<00:51,  8.31it/s] 56%|█████▌    | 537/966 [01:04<00:51,  8.32it/s] 56%|█████▌    | 538/966 [01:04<00:51,  8.31it/s] 56%|█████▌    | 539/966 [01:04<00:51,  8.32it/s] 56%|█████▌    | 540/966 [01:04<00:51,  8.34it/s] 56%|█████▌    | 541/966 [01:04<00:50,  8.34it/s] 56%|█████▌    | 542/966 [01:05<00:50,  8.33it/s] 56%|█████▌    | 543/966 [01:05<00:50,  8.34it/s] 56%|█████▋    | 544/966 [01:05<00:50,  8.33it/s] 56%|█████▋    | 545/966 [01:05<00:50,  8.32it/s] 57%|█████▋    | 546/966 [01:05<00:50,  8.33it/s] 57%|█████▋    | 547/966 [01:05<00:50,  8.34it/s] 57%|█████▋    | 548/966 [01:05<00:50,  8.34it/s] 57%|█████▋    | 549/966 [01:05<00:49,  8.34it/s] 57%|█████▋    | 550/966 [01:06<00:49,  8.34it/s] 57%|█████▋    | 551/966 [01:06<00:49,  8.34it/s] 57%|█████▋    | 552/966 [01:06<00:49,  8.34it/s] 57%|█████▋    | 553/966 [01:06<00:49,  8.34it/s] 57%|█████▋    | 554/966 [01:06<00:49,  8.35it/s] 57%|█████▋    | 555/966 [01:06<00:49,  8.36it/s] 58%|█████▊    | 556/966 [01:06<00:49,  8.35it/s] 58%|█████▊    | 557/966 [01:06<00:49,  8.34it/s] 58%|█████▊    | 558/966 [01:06<00:49,  8.32it/s] 58%|█████▊    | 559/966 [01:07<00:48,  8.33it/s] 58%|█████▊    | 560/966 [01:07<00:48,  8.33it/s] 58%|█████▊    | 561/966 [01:07<00:48,  8.32it/s] 58%|█████▊    | 562/966 [01:07<00:48,  8.31it/s] 58%|█████▊    | 563/966 [01:07<00:48,  8.31it/s] 58%|█████▊    | 564/966 [01:07<00:48,  8.31it/s] 58%|█████▊    | 565/966 [01:07<00:48,  8.32it/s] 59%|█████▊    | 566/966 [01:07<00:48,  8.31it/s] 59%|█████▊    | 567/966 [01:08<00:47,  8.32it/s] 59%|█████▉    | 568/966 [01:08<00:47,  8.32it/s] 59%|█████▉    | 569/966 [01:08<00:47,  8.33it/s] 59%|█████▉    | 570/966 [01:08<00:47,  8.30it/s] 59%|█████▉    | 571/966 [01:08<00:47,  8.30it/s] 59%|█████▉    | 572/966 [01:08<00:47,  8.30it/s] 59%|█████▉    | 573/966 [01:08<00:47,  8.32it/s] 59%|█████▉    | 574/966 [01:08<00:47,  8.32it/s] 60%|█████▉    | 575/966 [01:09<00:46,  8.32it/s] 60%|█████▉    | 576/966 [01:09<00:46,  8.32it/s] 60%|█████▉    | 577/966 [01:09<00:46,  8.33it/s] 60%|█████▉    | 578/966 [01:09<00:46,  8.32it/s] 60%|█████▉    | 579/966 [01:09<00:46,  8.32it/s] 60%|██████    | 580/966 [01:09<00:46,  8.32it/s] 60%|██████    | 581/966 [01:09<00:46,  8.33it/s] 60%|██████    | 582/966 [01:09<00:46,  8.33it/s] 60%|██████    | 583/966 [01:09<00:45,  8.33it/s] 60%|██████    | 584/966 [01:10<00:45,  8.34it/s] 61%|██████    | 585/966 [01:10<00:45,  8.33it/s] 61%|██████    | 586/966 [01:10<00:45,  8.33it/s] 61%|██████    | 587/966 [01:10<00:45,  8.32it/s] 61%|██████    | 588/966 [01:10<00:45,  8.34it/s] 61%|██████    | 589/966 [01:10<00:45,  8.34it/s] 61%|██████    | 590/966 [01:10<00:45,  8.35it/s] 61%|██████    | 591/966 [01:10<00:44,  8.35it/s] 61%|██████▏   | 592/966 [01:11<00:44,  8.35it/s] 61%|██████▏   | 593/966 [01:11<00:44,  8.35it/s] 61%|██████▏   | 594/966 [01:11<00:44,  8.34it/s] 62%|██████▏   | 595/966 [01:11<00:44,  8.34it/s] 62%|██████▏   | 596/966 [01:11<00:44,  8.35it/s] 62%|██████▏   | 597/966 [01:11<00:44,  8.35it/s] 62%|██████▏   | 598/966 [01:11<00:44,  8.34it/s] 62%|██████▏   | 599/966 [01:11<00:44,  8.34it/s] 62%|██████▏   | 600/966 [01:12<00:43,  8.33it/s] 62%|██████▏   | 601/966 [01:12<00:43,  8.33it/s] 62%|██████▏   | 602/966 [01:12<00:43,  8.32it/s] 62%|██████▏   | 603/966 [01:12<00:43,  8.32it/s] 63%|██████▎   | 604/966 [01:12<00:43,  8.32it/s] 63%|██████▎   | 605/966 [01:12<00:43,  8.31it/s] 63%|██████▎   | 606/966 [01:12<00:43,  8.31it/s] 63%|██████▎   | 607/966 [01:12<00:43,  8.30it/s] 63%|██████▎   | 608/966 [01:12<00:43,  8.30it/s] 63%|██████▎   | 609/966 [01:13<00:42,  8.30it/s] 63%|██████▎   | 610/966 [01:13<00:42,  8.30it/s] 63%|██████▎   | 611/966 [01:13<00:42,  8.31it/s] 63%|██████▎   | 612/966 [01:13<00:42,  8.32it/s] 63%|██████▎   | 613/966 [01:13<00:42,  8.32it/s] 64%|██████▎   | 614/966 [01:13<00:42,  8.32it/s] 64%|██████▎   | 615/966 [01:13<00:42,  8.32it/s] 64%|██████▍   | 616/966 [01:13<00:42,  8.31it/s] 64%|██████▍   | 617/966 [01:14<00:42,  8.31it/s] 64%|██████▍   | 618/966 [01:14<00:41,  8.31it/s] 64%|██████▍   | 619/966 [01:14<00:41,  8.31it/s] 64%|██████▍   | 620/966 [01:14<00:41,  8.32it/s] 64%|██████▍   | 621/966 [01:14<00:41,  8.32it/s] 64%|██████▍   | 622/966 [01:14<00:41,  8.31it/s] 64%|██████▍   | 623/966 [01:14<00:41,  8.32it/s] 65%|██████▍   | 624/966 [01:14<00:41,  8.33it/s] 65%|██████▍   | 625/966 [01:15<00:40,  8.33it/s] 65%|██████▍   | 626/966 [01:15<00:40,  8.34it/s] 65%|██████▍   | 627/966 [01:15<00:40,  8.34it/s] 65%|██████▌   | 628/966 [01:15<00:40,  8.33it/s] 65%|██████▌   | 629/966 [01:15<00:40,  8.32it/s] 65%|██████▌   | 630/966 [01:15<00:40,  8.32it/s] 65%|██████▌   | 631/966 [01:15<00:40,  8.34it/s] 65%|██████▌   | 632/966 [01:15<00:40,  8.34it/s] 66%|██████▌   | 633/966 [01:15<00:39,  8.34it/s] 66%|██████▌   | 634/966 [01:16<00:39,  8.34it/s] 66%|██████▌   | 635/966 [01:16<00:39,  8.34it/s] 66%|██████▌   | 636/966 [01:16<00:39,  8.34it/s] 66%|██████▌   | 637/966 [01:16<00:39,  8.33it/s] 66%|██████▌   | 638/966 [01:16<00:39,  8.34it/s] 66%|██████▌   | 639/966 [01:16<00:39,  8.34it/s] 66%|██████▋   | 640/966 [01:16<00:39,  8.33it/s] 66%|██████▋   | 641/966 [01:16<00:39,  8.33it/s] 66%|██████▋   | 642/966 [01:17<00:38,  8.33it/s] 67%|██████▋   | 643/966 [01:17<00:38,  8.32it/s] 67%|██████▋   | 644/966 [01:17<00:38,  8.31it/s] 67%|██████▋   | 645/966 [01:17<00:38,  8.31it/s] 67%|██████▋   | 646/966 [01:17<00:38,  8.32it/s] 67%|██████▋   | 647/966 [01:17<00:38,  8.32it/s] 67%|██████▋   | 648/966 [01:17<00:38,  8.33it/s] 67%|██████▋   | 649/966 [01:17<00:38,  8.33it/s] 67%|██████▋   | 650/966 [01:18<00:37,  8.32it/s] 67%|██████▋   | 651/966 [01:18<00:37,  8.31it/s] 67%|██████▋   | 652/966 [01:18<00:37,  8.30it/s] 68%|██████▊   | 653/966 [01:18<00:37,  8.30it/s] 68%|██████▊   | 654/966 [01:18<00:37,  8.30it/s] 68%|██████▊   | 655/966 [01:18<00:37,  8.31it/s] 68%|██████▊   | 656/966 [01:18<00:37,  8.32it/s] 68%|██████▊   | 657/966 [01:18<00:37,  8.32it/s] 68%|██████▊   | 658/966 [01:18<00:37,  8.32it/s] 68%|██████▊   | 659/966 [01:19<00:36,  8.32it/s] 68%|██████▊   | 660/966 [01:19<00:36,  8.32it/s] 68%|██████▊   | 661/966 [01:19<00:36,  8.31it/s] 69%|██████▊   | 662/966 [01:19<00:36,  8.30it/s] 69%|██████▊   | 663/966 [01:19<00:36,  8.30it/s] 69%|██████▊   | 664/966 [01:19<00:36,  8.30it/s] 69%|██████▉   | 665/966 [01:19<00:36,  8.31it/s] 69%|██████▉   | 666/966 [01:19<00:36,  8.32it/s] 69%|██████▉   | 667/966 [01:20<00:35,  8.34it/s] 69%|██████▉   | 668/966 [01:20<00:35,  8.35it/s] 69%|██████▉   | 669/966 [01:20<00:35,  8.33it/s] 69%|██████▉   | 670/966 [01:20<00:35,  8.32it/s] 69%|██████▉   | 671/966 [01:20<00:35,  8.31it/s] 70%|██████▉   | 672/966 [01:20<00:35,  8.31it/s] 70%|██████▉   | 673/966 [01:20<00:35,  8.32it/s] 70%|██████▉   | 674/966 [01:20<00:35,  8.33it/s] 70%|██████▉   | 675/966 [01:21<00:34,  8.33it/s] 70%|██████▉   | 676/966 [01:21<00:34,  8.34it/s] 70%|███████   | 677/966 [01:21<00:34,  8.34it/s] 70%|███████   | 678/966 [01:21<00:34,  8.34it/s] 70%|███████   | 679/966 [01:21<00:34,  8.34it/s] 70%|███████   | 680/966 [01:21<00:34,  8.34it/s] 70%|███████   | 681/966 [01:21<00:34,  8.34it/s] 71%|███████   | 682/966 [01:21<00:34,  8.33it/s] 71%|███████   | 683/966 [01:21<00:34,  8.32it/s] 71%|███████   | 684/966 [01:22<00:33,  8.32it/s] 71%|███████   | 685/966 [01:22<00:33,  8.32it/s] 71%|███████   | 686/966 [01:22<00:33,  8.32it/s] 71%|███████   | 687/966 [01:22<00:33,  8.33it/s] 71%|███████   | 688/966 [01:22<00:33,  8.34it/s] 71%|███████▏  | 689/966 [01:22<00:33,  8.34it/s] 71%|███████▏  | 690/966 [01:22<00:33,  8.32it/s] 72%|███████▏  | 691/966 [01:22<00:33,  8.32it/s] 72%|███████▏  | 692/966 [01:23<00:32,  8.32it/s] 72%|███████▏  | 693/966 [01:23<00:32,  8.32it/s] 72%|███████▏  | 694/966 [01:23<00:32,  8.31it/s] 72%|███████▏  | 695/966 [01:23<00:32,  8.32it/s] 72%|███████▏  | 696/966 [01:23<00:32,  8.32it/s] 72%|███████▏  | 697/966 [01:23<00:32,  8.33it/s] 72%|███████▏  | 698/966 [01:23<00:32,  8.32it/s] 72%|███████▏  | 699/966 [01:23<00:32,  8.32it/s] 72%|███████▏  | 700/966 [01:24<00:32,  8.31it/s] 73%|███████▎  | 701/966 [01:24<00:31,  8.30it/s] 73%|███████▎  | 702/966 [01:24<00:31,  8.30it/s] 73%|███████▎  | 703/966 [01:24<00:31,  8.32it/s] 73%|███████▎  | 704/966 [01:24<00:31,  8.32it/s] 73%|███████▎  | 705/966 [01:24<00:31,  8.33it/s] 73%|███████▎  | 706/966 [01:24<00:31,  8.33it/s] 73%|███████▎  | 707/966 [01:24<00:31,  8.32it/s] 73%|███████▎  | 708/966 [01:24<00:31,  8.32it/s] 73%|███████▎  | 709/966 [01:25<00:30,  8.33it/s] 73%|███████▎  | 710/966 [01:25<00:30,  8.34it/s] 74%|███████▎  | 711/966 [01:25<00:30,  8.34it/s] 74%|███████▎  | 712/966 [01:25<00:30,  8.33it/s] 74%|███████▍  | 713/966 [01:25<00:30,  8.33it/s] 74%|███████▍  | 714/966 [01:25<00:30,  8.33it/s] 74%|███████▍  | 715/966 [01:25<00:30,  8.34it/s] 74%|███████▍  | 716/966 [01:25<00:29,  8.34it/s] 74%|███████▍  | 717/966 [01:26<00:29,  8.34it/s] 74%|███████▍  | 718/966 [01:26<00:29,  8.34it/s] 74%|███████▍  | 719/966 [01:26<00:29,  8.32it/s] 75%|███████▍  | 720/966 [01:26<00:29,  8.33it/s] 75%|███████▍  | 721/966 [01:26<00:29,  8.33it/s] 75%|███████▍  | 722/966 [01:26<00:29,  8.34it/s] 75%|███████▍  | 723/966 [01:26<00:29,  8.33it/s] 75%|███████▍  | 724/966 [01:26<00:29,  8.34it/s] 75%|███████▌  | 725/966 [01:27<00:28,  8.33it/s] 75%|███████▌  | 726/966 [01:27<00:28,  8.33it/s] 75%|███████▌  | 727/966 [01:27<00:28,  8.31it/s] 75%|███████▌  | 728/966 [01:27<00:28,  8.32it/s] 75%|███████▌  | 729/966 [01:27<00:28,  8.32it/s] 76%|███████▌  | 730/966 [01:27<00:28,  8.32it/s] 76%|███████▌  | 731/966 [01:27<00:28,  8.32it/s] 76%|███████▌  | 732/966 [01:27<00:28,  8.32it/s] 76%|███████▌  | 733/966 [01:27<00:27,  8.33it/s] 76%|███████▌  | 734/966 [01:28<00:27,  8.32it/s] 76%|███████▌  | 735/966 [01:28<00:27,  8.32it/s] 76%|███████▌  | 736/966 [01:28<00:27,  8.32it/s] 76%|███████▋  | 737/966 [01:28<00:27,  8.31it/s] 76%|███████▋  | 738/966 [01:28<00:27,  8.32it/s] 77%|███████▋  | 739/966 [01:28<00:27,  8.32it/s] 77%|███████▋  | 740/966 [01:28<00:27,  8.32it/s] 77%|███████▋  | 741/966 [01:28<00:27,  8.32it/s] 77%|███████▋  | 742/966 [01:29<00:26,  8.32it/s] 77%|███████▋  | 743/966 [01:29<00:26,  8.32it/s] 77%|███████▋  | 744/966 [01:29<00:26,  8.32it/s] 77%|███████▋  | 745/966 [01:29<00:26,  8.31it/s] 77%|███████▋  | 746/966 [01:29<00:26,  8.31it/s] 77%|███████▋  | 747/966 [01:29<00:26,  8.32it/s] 77%|███████▋  | 748/966 [01:29<00:26,  8.32it/s] 78%|███████▊  | 749/966 [01:29<00:26,  8.31it/s] 78%|███████▊  | 750/966 [01:30<00:25,  8.31it/s] 78%|███████▊  | 751/966 [01:30<00:25,  8.33it/s] 78%|███████▊  | 752/966 [01:30<00:25,  8.34it/s] 78%|███████▊  | 753/966 [01:30<00:25,  8.34it/s] 78%|███████▊  | 754/966 [01:30<00:25,  8.34it/s] 78%|███████▊  | 755/966 [01:30<00:25,  8.32it/s] 78%|███████▊  | 756/966 [01:30<00:25,  8.34it/s] 78%|███████▊  | 757/966 [01:30<00:25,  8.34it/s] 78%|███████▊  | 758/966 [01:30<00:24,  8.34it/s] 79%|███████▊  | 759/966 [01:31<00:24,  8.34it/s] 79%|███████▊  | 760/966 [01:31<00:24,  8.34it/s] 79%|███████▉  | 761/966 [01:31<00:24,  8.32it/s] 79%|███████▉  | 762/966 [01:31<00:24,  8.33it/s] 79%|███████▉  | 763/966 [01:31<00:24,  8.34it/s] 79%|███████▉  | 764/966 [01:31<00:24,  8.34it/s] 79%|███████▉  | 765/966 [01:31<00:24,  8.35it/s] 79%|███████▉  | 766/966 [01:31<00:23,  8.34it/s] 79%|███████▉  | 767/966 [01:32<00:23,  8.32it/s] 80%|███████▉  | 768/966 [01:32<00:23,  8.32it/s] 80%|███████▉  | 769/966 [01:32<00:23,  8.33it/s] 80%|███████▉  | 770/966 [01:32<00:23,  8.33it/s] 80%|███████▉  | 771/966 [01:32<00:23,  8.33it/s] 80%|███████▉  | 772/966 [01:32<00:23,  8.33it/s] 80%|████████  | 773/966 [01:32<00:23,  8.33it/s] 80%|████████  | 774/966 [01:32<00:23,  8.32it/s] 80%|████████  | 775/966 [01:33<00:22,  8.31it/s] 80%|████████  | 776/966 [01:33<00:22,  8.30it/s] 80%|████████  | 777/966 [01:33<00:22,  8.32it/s] 81%|████████  | 778/966 [01:33<00:22,  8.32it/s] 81%|████████  | 779/966 [01:33<00:22,  8.32it/s] 81%|████████  | 780/966 [01:33<00:22,  8.32it/s] 81%|████████  | 781/966 [01:33<00:22,  8.33it/s] 81%|████████  | 782/966 [01:33<00:22,  8.32it/s] 81%|████████  | 783/966 [01:33<00:22,  8.30it/s] 81%|████████  | 784/966 [01:34<00:21,  8.28it/s] 81%|████████▏ | 785/966 [01:34<00:21,  8.29it/s] 81%|████████▏ | 786/966 [01:34<00:21,  8.30it/s] 81%|████████▏ | 787/966 [01:34<00:21,  8.31it/s] 82%|████████▏ | 788/966 [01:34<00:21,  8.32it/s] 82%|████████▏ | 789/966 [01:34<00:21,  8.34it/s] 82%|████████▏ | 790/966 [01:34<00:21,  8.34it/s] 82%|████████▏ | 791/966 [01:34<00:20,  8.34it/s] 82%|████████▏ | 792/966 [01:35<00:20,  8.32it/s] 82%|████████▏ | 793/966 [01:35<00:20,  8.32it/s] 82%|████████▏ | 794/966 [01:35<00:20,  8.33it/s] 82%|████████▏ | 795/966 [01:35<00:20,  8.32it/s] 82%|████████▏ | 796/966 [01:35<00:20,  8.33it/s] 83%|████████▎ | 797/966 [01:35<00:20,  8.33it/s] 83%|████████▎ | 798/966 [01:35<00:20,  8.34it/s] 83%|████████▎ | 799/966 [01:35<00:20,  8.34it/s] 83%|████████▎ | 800/966 [01:36<00:19,  8.35it/s] 83%|████████▎ | 801/966 [01:36<00:19,  8.35it/s] 83%|████████▎ | 802/966 [01:36<00:19,  8.35it/s] 83%|████████▎ | 803/966 [01:36<00:19,  8.34it/s] 83%|████████▎ | 804/966 [01:36<00:19,  8.34it/s] 83%|████████▎ | 805/966 [01:36<00:19,  8.36it/s] 83%|████████▎ | 806/966 [01:36<00:19,  8.35it/s] 84%|████████▎ | 807/966 [01:36<00:19,  8.34it/s] 84%|████████▎ | 808/966 [01:36<00:18,  8.34it/s] 84%|████████▎ | 809/966 [01:37<00:18,  8.34it/s] 84%|████████▍ | 810/966 [01:37<00:18,  8.34it/s] 84%|████████▍ | 811/966 [01:37<00:18,  8.32it/s] 84%|████████▍ | 812/966 [01:37<00:18,  8.31it/s] 84%|████████▍ | 813/966 [01:37<00:18,  8.31it/s] 84%|████████▍ | 814/966 [01:37<00:18,  8.30it/s] 84%|████████▍ | 815/966 [01:37<00:18,  8.31it/s] 84%|████████▍ | 816/966 [01:37<00:18,  8.32it/s] 85%|████████▍ | 817/966 [01:38<00:17,  8.32it/s] 85%|████████▍ | 818/966 [01:38<00:17,  8.33it/s] 85%|████████▍ | 819/966 [01:38<00:17,  8.32it/s] 85%|████████▍ | 820/966 [01:38<00:17,  8.32it/s] 85%|████████▍ | 821/966 [01:38<00:17,  8.30it/s] 85%|████████▌ | 822/966 [01:38<00:17,  8.30it/s] 85%|████████▌ | 823/966 [01:38<00:17,  8.30it/s] 85%|████████▌ | 824/966 [01:38<00:17,  8.31it/s] 85%|████████▌ | 825/966 [01:39<00:16,  8.32it/s] 86%|████████▌ | 826/966 [01:39<00:16,  8.33it/s] 86%|████████▌ | 827/966 [01:39<00:16,  8.33it/s] 86%|████████▌ | 828/966 [01:39<00:16,  8.33it/s] 86%|████████▌ | 829/966 [01:39<00:16,  8.32it/s] 86%|████████▌ | 830/966 [01:39<00:16,  8.31it/s] 86%|████████▌ | 831/966 [01:39<00:16,  8.30it/s] 86%|████████▌ | 832/966 [01:39<00:16,  8.30it/s] 86%|████████▌ | 833/966 [01:40<00:15,  8.32it/s] 86%|████████▋ | 834/966 [01:40<00:15,  8.32it/s] 86%|████████▋ | 835/966 [01:40<00:15,  8.34it/s] 87%|████████▋ | 836/966 [01:40<00:15,  8.34it/s] 87%|████████▋ | 837/966 [01:40<00:15,  8.34it/s] 87%|████████▋ | 838/966 [01:40<00:15,  8.33it/s] 87%|████████▋ | 839/966 [01:40<00:15,  8.32it/s] 87%|████████▋ | 840/966 [01:40<00:15,  8.32it/s] 87%|████████▋ | 841/966 [01:40<00:15,  8.33it/s] 87%|████████▋ | 842/966 [01:41<00:14,  8.33it/s] 87%|████████▋ | 843/966 [01:41<00:14,  8.34it/s] 87%|████████▋ | 844/966 [01:41<00:14,  8.34it/s] 87%|████████▋ | 845/966 [01:41<00:14,  8.35it/s] 88%|████████▊ | 846/966 [01:41<00:14,  8.34it/s] 88%|████████▊ | 847/966 [01:41<00:14,  8.33it/s] 88%|████████▊ | 848/966 [01:41<00:14,  8.33it/s] 88%|████████▊ | 849/966 [01:41<00:14,  8.33it/s] 88%|████████▊ | 850/966 [01:42<00:13,  8.32it/s] 88%|████████▊ | 851/966 [01:42<00:13,  8.33it/s] 88%|████████▊ | 852/966 [01:42<00:13,  8.33it/s] 88%|████████▊ | 853/966 [01:42<00:13,  8.33it/s] 88%|████████▊ | 854/966 [01:42<00:13,  8.33it/s] 89%|████████▊ | 855/966 [01:42<00:13,  8.33it/s] 89%|████████▊ | 856/966 [01:42<00:13,  8.32it/s] 89%|████████▊ | 857/966 [01:42<00:13,  8.31it/s] 89%|████████▉ | 858/966 [01:43<00:12,  8.31it/s] 89%|████████▉ | 859/966 [01:43<00:12,  8.32it/s] 89%|████████▉ | 860/966 [01:43<00:12,  8.32it/s] 89%|████████▉ | 861/966 [01:43<00:12,  8.32it/s] 89%|████████▉ | 862/966 [01:43<00:12,  8.32it/s] 89%|████████▉ | 863/966 [01:43<00:12,  8.31it/s] 89%|████████▉ | 864/966 [01:43<00:12,  8.30it/s] 90%|████████▉ | 865/966 [01:43<00:12,  8.30it/s] 90%|████████▉ | 866/966 [01:43<00:12,  8.29it/s] 90%|████████▉ | 867/966 [01:44<00:11,  8.30it/s] 90%|████████▉ | 868/966 [01:44<00:11,  8.31it/s] 90%|████████▉ | 869/966 [01:44<00:11,  8.32it/s] 90%|█████████ | 870/966 [01:44<00:11,  8.30it/s] 90%|█████████ | 871/966 [01:44<00:11,  8.30it/s] 90%|█████████ | 872/966 [01:44<00:11,  8.31it/s] 90%|█████████ | 873/966 [01:44<00:11,  8.30it/s] 90%|█████████ | 874/966 [01:44<00:11,  8.31it/s] 91%|█████████ | 875/966 [01:45<00:10,  8.30it/s] 91%|█████████ | 876/966 [01:45<00:10,  8.32it/s] 91%|█████████ | 877/966 [01:45<00:10,  8.33it/s] 91%|█████████ | 878/966 [01:45<00:10,  8.33it/s] 91%|█████████ | 879/966 [01:45<00:10,  8.33it/s] 91%|█████████ | 880/966 [01:45<00:10,  8.33it/s] 91%|█████████ | 881/966 [01:45<00:10,  8.33it/s] 91%|█████████▏| 882/966 [01:45<00:10,  8.33it/s] 91%|█████████▏| 883/966 [01:46<00:09,  8.34it/s] 92%|█████████▏| 884/966 [01:46<00:09,  8.34it/s] 92%|█████████▏| 885/966 [01:46<00:09,  8.34it/s] 92%|█████████▏| 886/966 [01:46<00:09,  8.33it/s] 92%|█████████▏| 887/966 [01:46<00:09,  8.33it/s] 92%|█████████▏| 888/966 [01:46<00:09,  8.33it/s] 92%|█████████▏| 889/966 [01:46<00:09,  8.34it/s] 92%|█████████▏| 890/966 [01:46<00:09,  8.34it/s] 92%|█████████▏| 891/966 [01:46<00:08,  8.34it/s] 92%|█████████▏| 892/966 [01:47<00:08,  8.33it/s] 92%|█████████▏| 893/966 [01:47<00:08,  8.33it/s] 93%|█████████▎| 894/966 [01:47<00:08,  8.32it/s] 93%|█████████▎| 895/966 [01:47<00:08,  8.33it/s] 93%|█████████▎| 896/966 [01:47<00:08,  8.33it/s] 93%|█████████▎| 897/966 [01:47<00:08,  8.32it/s] 93%|█████████▎| 898/966 [01:47<00:08,  8.32it/s] 93%|█████████▎| 899/966 [01:47<00:08,  8.32it/s] 93%|█████████▎| 900/966 [01:48<00:07,  8.32it/s] 93%|█████████▎| 901/966 [01:48<00:07,  8.32it/s] 93%|█████████▎| 902/966 [01:48<00:07,  8.30it/s] 93%|█████████▎| 903/966 [01:48<00:07,  8.31it/s] 94%|█████████▎| 904/966 [01:48<00:07,  8.31it/s] 94%|█████████▎| 905/966 [01:48<00:07,  8.31it/s] 94%|█████████▍| 906/966 [01:48<00:07,  8.33it/s] 94%|█████████▍| 907/966 [01:48<00:07,  8.33it/s] 94%|█████████▍| 908/966 [01:49<00:06,  8.32it/s] 94%|█████████▍| 909/966 [01:49<00:06,  8.32it/s] 94%|█████████▍| 910/966 [01:49<00:06,  8.30it/s] 94%|█████████▍| 911/966 [01:49<00:06,  8.30it/s] 94%|█████████▍| 912/966 [01:49<00:06,  8.30it/s] 95%|█████████▍| 913/966 [01:49<00:06,  8.30it/s] 95%|█████████▍| 914/966 [01:49<00:06,  8.31it/s] 95%|█████████▍| 915/966 [01:49<00:06,  8.32it/s] 95%|█████████▍| 916/966 [01:49<00:06,  8.33it/s] 95%|█████████▍| 917/966 [01:50<00:05,  8.34it/s] 95%|█████████▌| 918/966 [01:50<00:05,  8.33it/s] 95%|█████████▌| 919/966 [01:50<00:05,  8.32it/s] 95%|█████████▌| 920/966 [01:50<00:05,  8.32it/s] 95%|█████████▌| 921/966 [01:50<00:05,  8.32it/s] 95%|█████████▌| 922/966 [01:50<00:05,  8.33it/s] 96%|█████████▌| 923/966 [01:50<00:05,  8.33it/s] 96%|█████████▌| 924/966 [01:50<00:05,  8.35it/s] 96%|█████████▌| 925/966 [01:51<00:04,  8.35it/s] 96%|█████████▌| 926/966 [01:51<00:04,  8.35it/s] 96%|█████████▌| 927/966 [01:51<00:04,  8.34it/s] 96%|█████████▌| 928/966 [01:51<00:04,  8.32it/s] 96%|█████████▌| 929/966 [01:51<00:04,  8.32it/s] 96%|█████████▋| 930/966 [01:51<00:04,  8.33it/s] 96%|█████████▋| 931/966 [01:51<00:04,  8.33it/s] 96%|█████████▋| 932/966 [01:51<00:04,  8.34it/s] 97%|█████████▋| 933/966 [01:52<00:03,  8.33it/s] 97%|█████████▋| 934/966 [01:52<00:03,  8.33it/s] 97%|█████████▋| 935/966 [01:52<00:03,  8.34it/s] 97%|█████████▋| 936/966 [01:52<00:03,  8.33it/s] 97%|█████████▋| 937/966 [01:52<00:03,  8.33it/s] 97%|█████████▋| 938/966 [01:52<00:03,  8.32it/s] 97%|█████████▋| 939/966 [01:52<00:03,  8.31it/s] 97%|█████████▋| 940/966 [01:52<00:03,  8.31it/s] 97%|█████████▋| 941/966 [01:52<00:03,  8.32it/s] 98%|█████████▊| 942/966 [01:53<00:02,  8.32it/s] 98%|█████████▊| 943/966 [01:53<00:02,  8.32it/s] 98%|█████████▊| 944/966 [01:53<00:02,  8.32it/s] 98%|█████████▊| 945/966 [01:53<00:02,  8.32it/s] 98%|█████████▊| 946/966 [01:53<00:02,  8.31it/s] 98%|█████████▊| 947/966 [01:53<00:02,  8.30it/s] 98%|█████████▊| 948/966 [01:53<00:02,  8.29it/s] 98%|█████████▊| 949/966 [01:53<00:02,  8.31it/s] 98%|█████████▊| 950/966 [01:54<00:01,  8.31it/s] 98%|█████████▊| 951/966 [01:54<00:01,  8.32it/s] 99%|█████████▊| 952/966 [01:54<00:01,  8.33it/s] 99%|█████████▊| 953/966 [01:54<00:01,  8.33it/s] 99%|█████████▉| 954/966 [01:54<00:01,  8.32it/s] 99%|█████████▉| 955/966 [01:54<00:01,  8.31it/s] 99%|█████████▉| 956/966 [01:54<00:01,  8.30it/s] 99%|█████████▉| 957/966 [01:54<00:01,  8.29it/s] 99%|█████████▉| 958/966 [01:55<00:00,  8.31it/s] 99%|█████████▉| 959/966 [01:55<00:00,  8.31it/s] 99%|█████████▉| 960/966 [01:55<00:00,  8.33it/s] 99%|█████████▉| 961/966 [01:55<00:00,  8.34it/s]100%|█████████▉| 962/966 [01:55<00:00,  8.34it/s]100%|█████████▉| 963/966 [01:55<00:00,  8.33it/s]100%|█████████▉| 964/966 [01:55<00:00,  8.31it/s]100%|█████████▉| 965/966 [01:55<00:00,  8.31it/s]100%|██████████| 966/966 [01:55<00:00,  8.33it/s]100%|██████████| 966/966 [01:55<00:00,  8.33it/s]
sending off prediction to background worker for resampling and export
done with 706-005
Renaming /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset302_Calcium_OCTv2/nnUNetTrainerScaleAnalysis5__nnUNetPlans__3d_32x160x128_b10/fold_0 to /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset302_Calcium_OCTv2/nnUNetTrainerScaleAnalysis5__nnUNetPlans__3d_32x160x128_b10/fold_0_Genesis
Completed FOLD 0 CONFIG 3d_32x160x128_b10 TRAINER nnUNetTrainerScaleAnalysis5 Genesis
Begin training and evaluating FOLD 1 CONFIG 3d_32x160x128_b10 TRAINER nnUNetTrainerScaleAnalysis5 Genesis
wandb: Tracking run with wandb version 0.16.6
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2024-08-12 23:10:32.411235: Using 8 processes for validation.
2024-08-12 23:10:32.429109: Using 12 processes for data augmentation.
2024-08-12 23:10:33.428874: Using torch.compile...
/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
################### Loading pretrained weights from file  /home/gridsan/nchutisilp/datasets/ModelGenesisOutputs/ModelGenesisNNUNetPretrainingV2_noNorm_correct_orientation/Converted_nnUNet_Genesis_OCT_Best.pt ###################
Below is the list of overlapping blocks in pretrained model and nnUNet architecture:
encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])
encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])
encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])
encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])
encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])
encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])
encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])
encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])
encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])
encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])
encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])
encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])
encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])
encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])
encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])
encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])
encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])
encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])
encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])
encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])
encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])
encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])
encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])
encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])
encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])
encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])
encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])
decoder.encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])
decoder.encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])
decoder.encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])
decoder.encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])
decoder.encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])
decoder.encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])
decoder.encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])
decoder.encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])
decoder.encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])
decoder.encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])
decoder.encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])
decoder.encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])
decoder.encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])
decoder.encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.stages.0.convs.0.conv.weight shape torch.Size([320, 640, 3, 3, 3])
decoder.stages.0.convs.0.conv.bias shape torch.Size([320])
decoder.stages.0.convs.0.norm.weight shape torch.Size([320])
decoder.stages.0.convs.0.norm.bias shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.0.weight shape torch.Size([320, 640, 3, 3, 3])
decoder.stages.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.stages.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.stages.0.convs.1.conv.bias shape torch.Size([320])
decoder.stages.0.convs.1.norm.weight shape torch.Size([320])
decoder.stages.0.convs.1.norm.bias shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.stages.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.stages.1.convs.0.conv.weight shape torch.Size([256, 512, 3, 3, 3])
decoder.stages.1.convs.0.conv.bias shape torch.Size([256])
decoder.stages.1.convs.0.norm.weight shape torch.Size([256])
decoder.stages.1.convs.0.norm.bias shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.0.weight shape torch.Size([256, 512, 3, 3, 3])
decoder.stages.1.convs.0.all_modules.0.bias shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.1.weight shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.1.bias shape torch.Size([256])
decoder.stages.1.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.stages.1.convs.1.conv.bias shape torch.Size([256])
decoder.stages.1.convs.1.norm.weight shape torch.Size([256])
decoder.stages.1.convs.1.norm.bias shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.stages.1.convs.1.all_modules.0.bias shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.1.weight shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.1.bias shape torch.Size([256])
decoder.stages.2.convs.0.conv.weight shape torch.Size([128, 256, 3, 3, 3])
decoder.stages.2.convs.0.conv.bias shape torch.Size([128])
decoder.stages.2.convs.0.norm.weight shape torch.Size([128])
decoder.stages.2.convs.0.norm.bias shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.0.weight shape torch.Size([128, 256, 3, 3, 3])
decoder.stages.2.convs.0.all_modules.0.bias shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.1.weight shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.1.bias shape torch.Size([128])
decoder.stages.2.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.stages.2.convs.1.conv.bias shape torch.Size([128])
decoder.stages.2.convs.1.norm.weight shape torch.Size([128])
decoder.stages.2.convs.1.norm.bias shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.stages.2.convs.1.all_modules.0.bias shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.1.weight shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.1.bias shape torch.Size([128])
decoder.stages.3.convs.0.conv.weight shape torch.Size([64, 128, 3, 3, 3])
decoder.stages.3.convs.0.conv.bias shape torch.Size([64])
decoder.stages.3.convs.0.norm.weight shape torch.Size([64])
decoder.stages.3.convs.0.norm.bias shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.0.weight shape torch.Size([64, 128, 3, 3, 3])
decoder.stages.3.convs.0.all_modules.0.bias shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.1.weight shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.1.bias shape torch.Size([64])
decoder.stages.3.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.stages.3.convs.1.conv.bias shape torch.Size([64])
decoder.stages.3.convs.1.norm.weight shape torch.Size([64])
decoder.stages.3.convs.1.norm.bias shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.stages.3.convs.1.all_modules.0.bias shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.1.weight shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.1.bias shape torch.Size([64])
decoder.stages.4.convs.0.conv.weight shape torch.Size([32, 64, 3, 3, 3])
decoder.stages.4.convs.0.conv.bias shape torch.Size([32])
decoder.stages.4.convs.0.norm.weight shape torch.Size([32])
decoder.stages.4.convs.0.norm.bias shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.0.weight shape torch.Size([32, 64, 3, 3, 3])
decoder.stages.4.convs.0.all_modules.0.bias shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.1.weight shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.1.bias shape torch.Size([32])
decoder.stages.4.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.stages.4.convs.1.conv.bias shape torch.Size([32])
decoder.stages.4.convs.1.norm.weight shape torch.Size([32])
decoder.stages.4.convs.1.norm.bias shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.stages.4.convs.1.all_modules.0.bias shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.1.weight shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.1.bias shape torch.Size([32])
decoder.transpconvs.0.weight shape torch.Size([320, 320, 1, 2, 2])
decoder.transpconvs.0.bias shape torch.Size([320])
decoder.transpconvs.1.weight shape torch.Size([320, 256, 2, 2, 2])
decoder.transpconvs.1.bias shape torch.Size([256])
decoder.transpconvs.2.weight shape torch.Size([256, 128, 2, 2, 2])
decoder.transpconvs.2.bias shape torch.Size([128])
decoder.transpconvs.3.weight shape torch.Size([128, 64, 2, 2, 2])
decoder.transpconvs.3.bias shape torch.Size([64])
decoder.transpconvs.4.weight shape torch.Size([64, 32, 2, 2, 2])
decoder.transpconvs.4.bias shape torch.Size([32])
################### Done ###################
2024-08-12 23:10:46.841996: do_dummy_2d_data_aug: True
2024-08-12 23:10:46.844066: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset302_Calcium_OCTv2/splits_final_5.json
2024-08-12 23:10:46.846797: The split file contains 3 splits.
2024-08-12 23:10:46.848041: Desired fold for training: 1
2024-08-12 23:10:46.849930: This split has 3 training and 2 validation cases.
using pin_memory on device 0
using pin_memory on device 0

This is the configuration used by this training:
Configuration name: 3d_32x160x128_b10
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 10, 'patch_size': [32, 160, 128], 'median_image_size_in_voxels': [375.0, 498.0, 498.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'inherits_from': '3d_fullres'} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset302_Calcium_OCTv2', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.4977976381778717, 'mean': 0.13332499563694, 'median': 0.08871842920780182, 'min': 0.0, 'percentile_00_5': 0.014754901640117168, 'percentile_99_5': 0.4977976381778717, 'std': 0.12022686749696732}}} 

2024-08-12 23:11:06.538080: unpacking dataset...
