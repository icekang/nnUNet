/home/gridsan/nchutisilp/.conda/envs/nnunet/bin/python
wandb: Tracking run with wandb version 0.16.6
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2024-05-09 13:45:08.086992: do_dummy_2d_data_aug: True
2024-05-09 13:45:08.091391: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset302_Calcium_OCTv2/splits_final.json
2024-05-09 13:45:08.093922: The split file contains 3 splits.
2024-05-09 13:45:08.095712: Desired fold for training: 0
2024-05-09 13:45:08.096679: This split has 4 training and 2 validation cases.
using pin_memory on device 0
using pin_memory on device 0
2024-05-09 13:45:13.662627: Using torch.compile...
/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "

This is the configuration used by this training:
Configuration name: 3d_32x512x512_b2
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [32, 512, 512], 'median_image_size_in_voxels': [375.0, 498.0, 498.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'inherits_from': '3d_fullres'} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset302_Calcium_OCTv2', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.4977976381778717, 'mean': 0.13332499563694, 'median': 0.08871842920780182, 'min': 0.0, 'percentile_00_5': 0.014754901640117168, 'percentile_99_5': 0.4977976381778717, 'std': 0.12022686749696732}}} 

2024-05-09 13:45:16.055261: unpacking dataset...
2024-05-09 13:45:22.052684: unpacking done...
2024-05-09 13:45:22.065674: Unable to plot network architecture: nnUNet_compile is enabled!
2024-05-09 13:45:22.162305: 
2024-05-09 13:45:22.163897: Epoch 0
2024-05-09 13:45:22.165676: Current learning rate: 0.01
2024-05-09 13:50:49.668402: Validation loss improved from 1000.00000 to -0.24175! Patience: 0/50
2024-05-09 13:50:49.670068: train_loss -0.2179
2024-05-09 13:50:49.671553: val_loss -0.2418
2024-05-09 13:50:49.672787: Pseudo dice [0.4479]
2024-05-09 13:50:49.673832: Epoch time: 327.51 s
2024-05-09 13:50:49.674918: Yayy! New best EMA pseudo Dice: 0.4479
2024-05-09 13:50:51.315379: 
2024-05-09 13:50:51.316904: Epoch 1
2024-05-09 13:50:51.318315: Current learning rate: 0.00999
2024-05-09 13:54:49.697477: Validation loss improved from -0.24175 to -0.28950! Patience: 0/50
2024-05-09 13:54:49.699481: train_loss -0.342
2024-05-09 13:54:49.700675: val_loss -0.2895
2024-05-09 13:54:49.701668: Pseudo dice [0.496]
2024-05-09 13:54:49.702641: Epoch time: 238.39 s
2024-05-09 13:54:49.703511: Yayy! New best EMA pseudo Dice: 0.4527
2024-05-09 13:54:51.727258: 
2024-05-09 13:54:51.728410: Epoch 2
2024-05-09 13:54:51.729312: Current learning rate: 0.00998
2024-05-09 13:58:47.872816: Validation loss improved from -0.28950 to -0.30169! Patience: 0/50
2024-05-09 13:58:47.876321: train_loss -0.3688
2024-05-09 13:58:47.877950: val_loss -0.3017
2024-05-09 13:58:47.879309: Pseudo dice [0.4969]
2024-05-09 13:58:47.880881: Epoch time: 236.15 s
2024-05-09 13:58:47.882090: Yayy! New best EMA pseudo Dice: 0.4571
2024-05-09 13:58:49.736957: 
2024-05-09 13:58:49.738404: Epoch 3
2024-05-09 13:58:49.739652: Current learning rate: 0.00997
2024-05-09 14:02:45.353371: Validation loss did not improve from -0.30169. Patience: 1/50
2024-05-09 14:02:45.354837: train_loss -0.3951
2024-05-09 14:02:45.356039: val_loss -0.297
2024-05-09 14:02:45.357281: Pseudo dice [0.4818]
2024-05-09 14:02:45.358458: Epoch time: 235.62 s
2024-05-09 14:02:45.359728: Yayy! New best EMA pseudo Dice: 0.4596
2024-05-09 14:02:47.124000: 
2024-05-09 14:02:47.125275: Epoch 4
2024-05-09 14:02:47.126242: Current learning rate: 0.00996
2024-05-09 14:07:12.298123: Validation loss improved from -0.30169 to -0.35468! Patience: 1/50
2024-05-09 14:07:12.299443: train_loss -0.4071
2024-05-09 14:07:12.300504: val_loss -0.3547
2024-05-09 14:07:12.301497: Pseudo dice [0.5237]
2024-05-09 14:07:12.302398: Epoch time: 265.18 s
2024-05-09 14:07:12.786467: Yayy! New best EMA pseudo Dice: 0.466
2024-05-09 14:07:14.615628: 
2024-05-09 14:07:14.617521: Epoch 5
2024-05-09 14:07:14.618645: Current learning rate: 0.00995
2024-05-09 14:11:15.469381: Validation loss did not improve from -0.35468. Patience: 1/50
2024-05-09 14:11:15.470667: train_loss -0.4297
2024-05-09 14:11:15.471718: val_loss -0.3338
2024-05-09 14:11:15.472849: Pseudo dice [0.5299]
2024-05-09 14:11:15.473800: Epoch time: 240.86 s
2024-05-09 14:11:15.475222: Yayy! New best EMA pseudo Dice: 0.4724
2024-05-09 14:11:17.120834: 
2024-05-09 14:11:17.122556: Epoch 6
2024-05-09 14:11:17.123911: Current learning rate: 0.00995
2024-05-09 14:15:24.293329: Validation loss improved from -0.35468 to -0.36920! Patience: 1/50
2024-05-09 14:15:24.294671: train_loss -0.455
2024-05-09 14:15:24.295918: val_loss -0.3692
2024-05-09 14:15:24.296973: Pseudo dice [0.543]
2024-05-09 14:15:24.298070: Epoch time: 247.17 s
2024-05-09 14:15:24.299073: Yayy! New best EMA pseudo Dice: 0.4794
2024-05-09 14:15:26.037212: 
2024-05-09 14:15:26.038761: Epoch 7
2024-05-09 14:15:26.040131: Current learning rate: 0.00994
2024-05-09 14:19:43.949715: Validation loss improved from -0.36920 to -0.40093! Patience: 0/50
2024-05-09 14:19:43.951120: train_loss -0.4824
2024-05-09 14:19:43.952282: val_loss -0.4009
2024-05-09 14:19:43.953401: Pseudo dice [0.5777]
2024-05-09 14:19:43.954393: Epoch time: 257.92 s
2024-05-09 14:19:43.955308: Yayy! New best EMA pseudo Dice: 0.4893
2024-05-09 14:19:46.431820: 
2024-05-09 14:19:46.433288: Epoch 8
2024-05-09 14:19:46.434334: Current learning rate: 0.00993
2024-05-09 14:24:08.397819: Validation loss did not improve from -0.40093. Patience: 1/50
2024-05-09 14:24:08.399237: train_loss -0.479
2024-05-09 14:24:08.400296: val_loss -0.376
2024-05-09 14:24:08.401250: Pseudo dice [0.5571]
2024-05-09 14:24:08.402199: Epoch time: 261.97 s
2024-05-09 14:24:08.403131: Yayy! New best EMA pseudo Dice: 0.496
2024-05-09 14:24:11.258930: 
2024-05-09 14:24:11.260197: Epoch 9
2024-05-09 14:24:11.261137: Current learning rate: 0.00992
2024-05-09 14:28:08.669971: Validation loss improved from -0.40093 to -0.44259! Patience: 1/50
2024-05-09 14:28:08.671349: train_loss -0.5158
2024-05-09 14:28:08.672507: val_loss -0.4426
2024-05-09 14:28:08.673526: Pseudo dice [0.6154]
2024-05-09 14:28:08.674687: Epoch time: 237.41 s
2024-05-09 14:28:09.061420: Yayy! New best EMA pseudo Dice: 0.508
2024-05-09 14:28:10.954945: 
2024-05-09 14:28:10.956331: Epoch 10
2024-05-09 14:28:10.957495: Current learning rate: 0.00991
2024-05-09 14:32:16.563698: Validation loss did not improve from -0.44259. Patience: 1/50
2024-05-09 14:32:16.564851: train_loss -0.5287
2024-05-09 14:32:16.565908: val_loss -0.4294
2024-05-09 14:32:16.566849: Pseudo dice [0.5969]
2024-05-09 14:32:16.567766: Epoch time: 245.61 s
2024-05-09 14:32:16.568666: Yayy! New best EMA pseudo Dice: 0.5169
2024-05-09 14:32:18.374774: 
2024-05-09 14:32:18.376332: Epoch 11
2024-05-09 14:32:18.377393: Current learning rate: 0.0099
2024-05-09 14:36:28.251297: Validation loss improved from -0.44259 to -0.50407! Patience: 1/50
2024-05-09 14:36:28.252533: train_loss -0.5594
2024-05-09 14:36:28.253966: val_loss -0.5041
2024-05-09 14:36:28.255214: Pseudo dice [0.6385]
2024-05-09 14:36:28.256567: Epoch time: 249.88 s
2024-05-09 14:36:28.257625: Yayy! New best EMA pseudo Dice: 0.529
2024-05-09 14:36:30.022932: 
2024-05-09 14:36:30.024806: Epoch 12
2024-05-09 14:36:30.026386: Current learning rate: 0.00989
2024-05-09 14:40:36.744003: Validation loss did not improve from -0.50407. Patience: 1/50
2024-05-09 14:40:36.745335: train_loss -0.5758
2024-05-09 14:40:36.746447: val_loss -0.4835
2024-05-09 14:40:36.747592: Pseudo dice [0.6397]
2024-05-09 14:40:36.748533: Epoch time: 246.72 s
2024-05-09 14:40:36.749454: Yayy! New best EMA pseudo Dice: 0.5401
2024-05-09 14:40:38.509784: 
2024-05-09 14:40:38.511660: Epoch 13
2024-05-09 14:40:38.513018: Current learning rate: 0.00988
2024-05-09 14:44:44.594616: Validation loss did not improve from -0.50407. Patience: 2/50
2024-05-09 14:44:44.596070: train_loss -0.573
2024-05-09 14:44:44.597232: val_loss -0.4112
2024-05-09 14:44:44.598492: Pseudo dice [0.5909]
2024-05-09 14:44:44.599479: Epoch time: 246.09 s
2024-05-09 14:44:44.600501: Yayy! New best EMA pseudo Dice: 0.5452
2024-05-09 14:44:46.404959: 
2024-05-09 14:44:46.407049: Epoch 14
2024-05-09 14:44:46.408190: Current learning rate: 0.00987
2024-05-09 14:48:49.804469: Validation loss did not improve from -0.50407. Patience: 3/50
2024-05-09 14:48:49.805893: train_loss -0.5936
2024-05-09 14:48:49.806976: val_loss -0.4773
2024-05-09 14:48:49.807983: Pseudo dice [0.6441]
2024-05-09 14:48:49.808989: Epoch time: 243.4 s
2024-05-09 14:48:50.210121: Yayy! New best EMA pseudo Dice: 0.5551
2024-05-09 14:48:51.991875: 
2024-05-09 14:48:51.993526: Epoch 15
2024-05-09 14:48:51.994653: Current learning rate: 0.00986
2024-05-09 14:53:00.109882: Validation loss did not improve from -0.50407. Patience: 4/50
2024-05-09 14:53:00.111273: train_loss -0.5789
2024-05-09 14:53:00.112455: val_loss -0.4934
2024-05-09 14:53:00.113531: Pseudo dice [0.6472]
2024-05-09 14:53:00.114556: Epoch time: 248.12 s
2024-05-09 14:53:00.115635: Yayy! New best EMA pseudo Dice: 0.5643
2024-05-09 14:53:03.188245: 
2024-05-09 14:53:03.189867: Epoch 16
2024-05-09 14:53:03.191057: Current learning rate: 0.00986
2024-05-09 14:57:06.763031: Validation loss improved from -0.50407 to -0.50566! Patience: 4/50
2024-05-09 14:57:06.765305: train_loss -0.5984
2024-05-09 14:57:06.767189: val_loss -0.5057
2024-05-09 14:57:06.768353: Pseudo dice [0.6408]
2024-05-09 14:57:06.769502: Epoch time: 243.58 s
2024-05-09 14:57:06.770410: Yayy! New best EMA pseudo Dice: 0.5719
2024-05-09 14:57:08.631302: 
2024-05-09 14:57:08.632907: Epoch 17
2024-05-09 14:57:08.633998: Current learning rate: 0.00985
2024-05-09 15:01:05.088628: Validation loss improved from -0.50566 to -0.52162! Patience: 0/50
2024-05-09 15:01:05.090055: train_loss -0.6226
2024-05-09 15:01:05.091352: val_loss -0.5216
2024-05-09 15:01:05.092427: Pseudo dice [0.6546]
2024-05-09 15:01:05.093642: Epoch time: 236.46 s
2024-05-09 15:01:05.094727: Yayy! New best EMA pseudo Dice: 0.5802
2024-05-09 15:01:06.893960: 
2024-05-09 15:01:06.896073: Epoch 18
2024-05-09 15:01:06.897423: Current learning rate: 0.00984
2024-05-09 15:05:00.702182: Validation loss improved from -0.52162 to -0.53517! Patience: 0/50
2024-05-09 15:05:00.703487: train_loss -0.6233
2024-05-09 15:05:00.704619: val_loss -0.5352
2024-05-09 15:05:00.705572: Pseudo dice [0.6645]
2024-05-09 15:05:00.706476: Epoch time: 233.81 s
2024-05-09 15:05:00.707385: Yayy! New best EMA pseudo Dice: 0.5886
2024-05-09 15:05:03.017012: 
2024-05-09 15:05:03.018254: Epoch 19
2024-05-09 15:05:03.019220: Current learning rate: 0.00983
2024-05-09 15:08:55.106810: Validation loss did not improve from -0.53517. Patience: 1/50
2024-05-09 15:08:55.108243: train_loss -0.6385
2024-05-09 15:08:55.109442: val_loss -0.4905
2024-05-09 15:08:55.110577: Pseudo dice [0.6425]
2024-05-09 15:08:55.111566: Epoch time: 232.09 s
2024-05-09 15:08:55.447215: Yayy! New best EMA pseudo Dice: 0.594
2024-05-09 15:08:57.213187: 
2024-05-09 15:08:57.214727: Epoch 20
2024-05-09 15:08:57.215769: Current learning rate: 0.00982
2024-05-09 15:12:52.306278: Validation loss did not improve from -0.53517. Patience: 2/50
2024-05-09 15:12:52.307791: train_loss -0.636
2024-05-09 15:12:52.308986: val_loss -0.5328
2024-05-09 15:12:52.310296: Pseudo dice [0.6653]
2024-05-09 15:12:52.311512: Epoch time: 235.1 s
2024-05-09 15:12:52.312604: Yayy! New best EMA pseudo Dice: 0.6011
2024-05-09 15:12:54.117708: 
2024-05-09 15:12:54.119023: Epoch 21
2024-05-09 15:12:54.120183: Current learning rate: 0.00981
2024-05-09 15:17:01.262817: Validation loss did not improve from -0.53517. Patience: 3/50
2024-05-09 15:17:01.264094: train_loss -0.648
2024-05-09 15:17:01.265407: val_loss -0.4648
2024-05-09 15:17:01.266485: Pseudo dice [0.6307]
2024-05-09 15:17:01.267424: Epoch time: 247.15 s
2024-05-09 15:17:01.268237: Yayy! New best EMA pseudo Dice: 0.6041
2024-05-09 15:17:02.947406: 
2024-05-09 15:17:02.948810: Epoch 22
2024-05-09 15:17:02.949996: Current learning rate: 0.0098
2024-05-09 15:21:11.600257: Validation loss did not improve from -0.53517. Patience: 4/50
2024-05-09 15:21:11.601817: train_loss -0.6647
2024-05-09 15:21:11.603343: val_loss -0.5351
2024-05-09 15:21:11.604490: Pseudo dice [0.6651]
2024-05-09 15:21:11.606036: Epoch time: 248.66 s
2024-05-09 15:21:11.607081: Yayy! New best EMA pseudo Dice: 0.6102
2024-05-09 15:21:13.399252: 
2024-05-09 15:21:13.400707: Epoch 23
2024-05-09 15:21:13.401791: Current learning rate: 0.00979
2024-05-09 15:25:18.836138: Validation loss improved from -0.53517 to -0.54266! Patience: 4/50
2024-05-09 15:25:18.837209: train_loss -0.6424
2024-05-09 15:25:18.838226: val_loss -0.5427
2024-05-09 15:25:18.839436: Pseudo dice [0.6732]
2024-05-09 15:25:18.840522: Epoch time: 245.44 s
2024-05-09 15:25:18.841670: Yayy! New best EMA pseudo Dice: 0.6165
2024-05-09 15:25:20.515991: 
2024-05-09 15:25:20.517131: Epoch 24
2024-05-09 15:25:20.518090: Current learning rate: 0.00978
2024-05-09 15:29:29.553184: Validation loss did not improve from -0.54266. Patience: 1/50
2024-05-09 15:29:29.554595: train_loss -0.6442
2024-05-09 15:29:29.555804: val_loss -0.5176
2024-05-09 15:29:29.556766: Pseudo dice [0.6455]
2024-05-09 15:29:29.557719: Epoch time: 249.04 s
2024-05-09 15:29:29.945095: Yayy! New best EMA pseudo Dice: 0.6194
2024-05-09 15:29:31.651199: 
2024-05-09 15:29:31.652510: Epoch 25
2024-05-09 15:29:31.653624: Current learning rate: 0.00977
2024-05-09 15:33:40.955643: Validation loss did not improve from -0.54266. Patience: 2/50
2024-05-09 15:33:40.956904: train_loss -0.65
2024-05-09 15:33:40.958083: val_loss -0.5019
2024-05-09 15:33:40.959075: Pseudo dice [0.6509]
2024-05-09 15:33:40.960354: Epoch time: 249.31 s
2024-05-09 15:33:40.961366: Yayy! New best EMA pseudo Dice: 0.6226
2024-05-09 15:33:42.696600: 
2024-05-09 15:33:42.697931: Epoch 26
2024-05-09 15:33:42.698998: Current learning rate: 0.00977
2024-05-09 15:37:49.114611: Validation loss did not improve from -0.54266. Patience: 3/50
2024-05-09 15:37:49.115954: train_loss -0.667
2024-05-09 15:37:49.117027: val_loss -0.5408
2024-05-09 15:37:49.117987: Pseudo dice [0.6667]
2024-05-09 15:37:49.119041: Epoch time: 246.42 s
2024-05-09 15:37:49.119995: Yayy! New best EMA pseudo Dice: 0.627
2024-05-09 15:37:50.868385: 
2024-05-09 15:37:50.870157: Epoch 27
2024-05-09 15:37:50.871279: Current learning rate: 0.00976
2024-05-09 15:41:57.495241: Validation loss did not improve from -0.54266. Patience: 4/50
2024-05-09 15:41:57.496596: train_loss -0.665
2024-05-09 15:41:57.497699: val_loss -0.5405
2024-05-09 15:41:57.498711: Pseudo dice [0.6775]
2024-05-09 15:41:57.499869: Epoch time: 246.63 s
2024-05-09 15:41:57.500909: Yayy! New best EMA pseudo Dice: 0.632
2024-05-09 15:41:59.254432: 
2024-05-09 15:41:59.256060: Epoch 28
2024-05-09 15:41:59.257063: Current learning rate: 0.00975
2024-05-09 15:46:07.657038: Validation loss did not improve from -0.54266. Patience: 5/50
2024-05-09 15:46:07.658344: train_loss -0.6671
2024-05-09 15:46:07.659508: val_loss -0.5355
2024-05-09 15:46:07.660552: Pseudo dice [0.6757]
2024-05-09 15:46:07.661967: Epoch time: 248.41 s
2024-05-09 15:46:07.663132: Yayy! New best EMA pseudo Dice: 0.6364
2024-05-09 15:46:09.382734: 
2024-05-09 15:46:09.384055: Epoch 29
2024-05-09 15:46:09.385167: Current learning rate: 0.00974
2024-05-09 15:50:15.335622: Validation loss did not improve from -0.54266. Patience: 6/50
2024-05-09 15:50:15.336746: train_loss -0.6816
2024-05-09 15:50:15.337833: val_loss -0.5425
2024-05-09 15:50:15.338835: Pseudo dice [0.6802]
2024-05-09 15:50:15.339870: Epoch time: 245.96 s
2024-05-09 15:50:15.748934: Yayy! New best EMA pseudo Dice: 0.6408
2024-05-09 15:50:17.469869: 
2024-05-09 15:50:17.471096: Epoch 30
2024-05-09 15:50:17.472038: Current learning rate: 0.00973
2024-05-09 15:54:24.169583: Validation loss improved from -0.54266 to -0.56792! Patience: 6/50
2024-05-09 15:54:24.170889: train_loss -0.6832
2024-05-09 15:54:24.172035: val_loss -0.5679
2024-05-09 15:54:24.172999: Pseudo dice [0.6982]
2024-05-09 15:54:24.174035: Epoch time: 246.7 s
2024-05-09 15:54:24.174903: Yayy! New best EMA pseudo Dice: 0.6465
2024-05-09 15:54:26.340093: 
2024-05-09 15:54:26.341273: Epoch 31
2024-05-09 15:54:26.342213: Current learning rate: 0.00972
2024-05-09 15:58:36.559769: Validation loss did not improve from -0.56792. Patience: 1/50
2024-05-09 15:58:36.562078: train_loss -0.6939
2024-05-09 15:58:36.599919: val_loss -0.5185
2024-05-09 15:58:36.601648: Pseudo dice [0.6601]
2024-05-09 15:58:36.603402: Epoch time: 250.22 s
2024-05-09 15:58:36.604604: Yayy! New best EMA pseudo Dice: 0.6479
2024-05-09 15:58:38.912568: 
2024-05-09 15:58:38.914452: Epoch 32
2024-05-09 15:58:38.915626: Current learning rate: 0.00971
2024-05-09 16:02:49.874680: Validation loss did not improve from -0.56792. Patience: 2/50
2024-05-09 16:02:49.876821: train_loss -0.6825
2024-05-09 16:02:49.878022: val_loss -0.5269
2024-05-09 16:02:49.879161: Pseudo dice [0.67]
2024-05-09 16:02:49.880082: Epoch time: 250.96 s
2024-05-09 16:02:49.881001: Yayy! New best EMA pseudo Dice: 0.6501
2024-05-09 16:02:51.722243: 
2024-05-09 16:02:51.723598: Epoch 33
2024-05-09 16:02:51.724801: Current learning rate: 0.0097
2024-05-09 16:06:59.689316: Validation loss did not improve from -0.56792. Patience: 3/50
2024-05-09 16:06:59.690530: train_loss -0.6896
2024-05-09 16:06:59.692886: val_loss -0.5264
2024-05-09 16:06:59.694094: Pseudo dice [0.6673]
2024-05-09 16:06:59.695115: Epoch time: 247.97 s
2024-05-09 16:06:59.696223: Yayy! New best EMA pseudo Dice: 0.6518
2024-05-09 16:07:01.529705: 
2024-05-09 16:07:01.531125: Epoch 34
2024-05-09 16:07:01.532274: Current learning rate: 0.00969
2024-05-09 16:11:17.064496: Validation loss did not improve from -0.56792. Patience: 4/50
2024-05-09 16:11:17.066101: train_loss -0.6989
2024-05-09 16:11:17.067235: val_loss -0.5349
2024-05-09 16:11:17.068159: Pseudo dice [0.6751]
2024-05-09 16:11:17.069111: Epoch time: 255.54 s
2024-05-09 16:11:17.449450: Yayy! New best EMA pseudo Dice: 0.6541
2024-05-09 16:11:19.215719: 
2024-05-09 16:11:19.217630: Epoch 35
2024-05-09 16:11:19.218826: Current learning rate: 0.00968
2024-05-09 16:15:33.435813: Validation loss did not improve from -0.56792. Patience: 5/50
2024-05-09 16:15:33.437020: train_loss -0.68
2024-05-09 16:15:33.438373: val_loss -0.523
2024-05-09 16:15:33.439389: Pseudo dice [0.6712]
2024-05-09 16:15:33.440428: Epoch time: 254.22 s
2024-05-09 16:15:33.441394: Yayy! New best EMA pseudo Dice: 0.6558
2024-05-09 16:15:35.257214: 
2024-05-09 16:15:35.258568: Epoch 36
2024-05-09 16:15:35.259595: Current learning rate: 0.00968
2024-05-09 16:19:44.559310: Validation loss did not improve from -0.56792. Patience: 6/50
2024-05-09 16:19:44.560464: train_loss -0.7017
2024-05-09 16:19:44.561667: val_loss -0.4917
2024-05-09 16:19:44.562780: Pseudo dice [0.6499]
2024-05-09 16:19:44.563829: Epoch time: 249.3 s
2024-05-09 16:19:45.940799: 
2024-05-09 16:19:45.942042: Epoch 37
2024-05-09 16:19:45.943076: Current learning rate: 0.00967
2024-05-09 16:23:56.813688: Validation loss did not improve from -0.56792. Patience: 7/50
2024-05-09 16:23:56.815587: train_loss -0.6971
2024-05-09 16:23:56.816623: val_loss -0.4868
2024-05-09 16:23:56.817671: Pseudo dice [0.6428]
2024-05-09 16:23:56.818800: Epoch time: 250.88 s
2024-05-09 16:23:58.255761: 
2024-05-09 16:23:58.257004: Epoch 38
2024-05-09 16:23:58.257980: Current learning rate: 0.00966
2024-05-09 16:28:06.359875: Validation loss did not improve from -0.56792. Patience: 8/50
2024-05-09 16:28:06.361120: train_loss -0.6883
2024-05-09 16:28:06.362544: val_loss -0.4579
2024-05-09 16:28:06.363785: Pseudo dice [0.6204]
2024-05-09 16:28:06.365005: Epoch time: 248.11 s
2024-05-09 16:28:07.760323: 
2024-05-09 16:28:07.761995: Epoch 39
2024-05-09 16:28:07.763349: Current learning rate: 0.00965
2024-05-09 16:32:18.759509: Validation loss did not improve from -0.56792. Patience: 9/50
2024-05-09 16:32:18.760822: train_loss -0.6864
2024-05-09 16:32:18.762085: val_loss -0.5521
2024-05-09 16:32:18.763050: Pseudo dice [0.6825]
2024-05-09 16:32:18.764207: Epoch time: 251.0 s
2024-05-09 16:32:20.562647: 
2024-05-09 16:32:20.564399: Epoch 40
2024-05-09 16:32:20.566273: Current learning rate: 0.00964
2024-05-09 16:36:33.984422: Validation loss did not improve from -0.56792. Patience: 10/50
2024-05-09 16:36:33.985728: train_loss -0.6969
2024-05-09 16:36:33.986874: val_loss -0.5275
2024-05-09 16:36:33.988139: Pseudo dice [0.6578]
2024-05-09 16:36:33.989187: Epoch time: 253.42 s
2024-05-09 16:36:35.407636: 
2024-05-09 16:36:35.409301: Epoch 41
2024-05-09 16:36:35.410434: Current learning rate: 0.00963
2024-05-09 16:40:43.546657: Validation loss did not improve from -0.56792. Patience: 11/50
2024-05-09 16:40:43.547786: train_loss -0.7033
2024-05-09 16:40:43.548985: val_loss -0.535
2024-05-09 16:40:43.550029: Pseudo dice [0.6575]
2024-05-09 16:40:43.551026: Epoch time: 248.14 s
2024-05-09 16:40:45.668903: 
2024-05-09 16:40:45.670538: Epoch 42
2024-05-09 16:40:45.671887: Current learning rate: 0.00962
2024-05-09 16:44:55.140095: Validation loss did not improve from -0.56792. Patience: 12/50
2024-05-09 16:44:55.141161: train_loss -0.7144
2024-05-09 16:44:55.142136: val_loss -0.5423
2024-05-09 16:44:55.143081: Pseudo dice [0.6774]
2024-05-09 16:44:55.144058: Epoch time: 249.47 s
2024-05-09 16:44:55.144975: Yayy! New best EMA pseudo Dice: 0.6568
2024-05-09 16:44:56.878803: 
2024-05-09 16:44:56.880207: Epoch 43
2024-05-09 16:44:56.881340: Current learning rate: 0.00961
2024-05-09 16:49:07.259639: Validation loss did not improve from -0.56792. Patience: 13/50
2024-05-09 16:49:07.260981: train_loss -0.7151
2024-05-09 16:49:07.262197: val_loss -0.5563
2024-05-09 16:49:07.263487: Pseudo dice [0.6854]
2024-05-09 16:49:07.264614: Epoch time: 250.38 s
2024-05-09 16:49:07.265582: Yayy! New best EMA pseudo Dice: 0.6597
2024-05-09 16:49:09.019412: 
2024-05-09 16:49:09.021127: Epoch 44
2024-05-09 16:49:09.022272: Current learning rate: 0.0096
2024-05-09 16:53:17.989749: Validation loss did not improve from -0.56792. Patience: 14/50
2024-05-09 16:53:17.991251: train_loss -0.7148
2024-05-09 16:53:17.992455: val_loss -0.5572
2024-05-09 16:53:17.993592: Pseudo dice [0.6814]
2024-05-09 16:53:17.994703: Epoch time: 248.97 s
2024-05-09 16:53:18.394930: Yayy! New best EMA pseudo Dice: 0.6619
2024-05-09 16:53:20.138747: 
2024-05-09 16:53:20.139981: Epoch 45
2024-05-09 16:53:20.141266: Current learning rate: 0.00959
2024-05-09 16:57:28.872329: Validation loss did not improve from -0.56792. Patience: 15/50
2024-05-09 16:57:28.873564: train_loss -0.7133
2024-05-09 16:57:28.874584: val_loss -0.4931
2024-05-09 16:57:28.875499: Pseudo dice [0.6398]
2024-05-09 16:57:28.876412: Epoch time: 248.74 s
2024-05-09 16:57:30.195567: 
2024-05-09 16:57:30.196976: Epoch 46
2024-05-09 16:57:30.197928: Current learning rate: 0.00959
2024-05-09 17:01:37.873610: Validation loss did not improve from -0.56792. Patience: 16/50
2024-05-09 17:01:37.875271: train_loss -0.6964
2024-05-09 17:01:37.877173: val_loss -0.5441
2024-05-09 17:01:37.878508: Pseudo dice [0.6697]
2024-05-09 17:01:37.879619: Epoch time: 247.68 s
2024-05-09 17:01:39.247299: 
2024-05-09 17:01:39.248778: Epoch 47
2024-05-09 17:01:39.249767: Current learning rate: 0.00958
2024-05-09 17:05:50.271724: Validation loss did not improve from -0.56792. Patience: 17/50
2024-05-09 17:05:50.274704: train_loss -0.7217
2024-05-09 17:05:50.276020: val_loss -0.5333
2024-05-09 17:05:50.277039: Pseudo dice [0.6611]
2024-05-09 17:05:50.278060: Epoch time: 251.03 s
2024-05-09 17:05:51.877456: 
2024-05-09 17:05:51.879061: Epoch 48
2024-05-09 17:05:51.880084: Current learning rate: 0.00957
2024-05-09 17:10:02.578028: Validation loss did not improve from -0.56792. Patience: 18/50
2024-05-09 17:10:02.579899: train_loss -0.7281
2024-05-09 17:10:02.581263: val_loss -0.5406
2024-05-09 17:10:02.582211: Pseudo dice [0.6742]
2024-05-09 17:10:02.583154: Epoch time: 250.7 s
2024-05-09 17:10:02.584221: Yayy! New best EMA pseudo Dice: 0.662
2024-05-09 17:10:04.305386: 
2024-05-09 17:10:04.306862: Epoch 49
2024-05-09 17:10:04.307956: Current learning rate: 0.00956
2024-05-09 17:14:13.874089: Validation loss did not improve from -0.56792. Patience: 19/50
2024-05-09 17:14:13.875517: train_loss -0.7308
2024-05-09 17:14:13.876780: val_loss -0.5327
2024-05-09 17:14:13.878536: Pseudo dice [0.6633]
2024-05-09 17:14:13.879797: Epoch time: 249.57 s
2024-05-09 17:14:14.235911: Yayy! New best EMA pseudo Dice: 0.6622
2024-05-09 17:14:15.945381: 
2024-05-09 17:14:15.946913: Epoch 50
2024-05-09 17:14:15.948122: Current learning rate: 0.00955
2024-05-09 17:18:26.860056: Validation loss did not improve from -0.56792. Patience: 20/50
2024-05-09 17:18:26.861405: train_loss -0.7301
2024-05-09 17:18:26.862509: val_loss -0.5525
2024-05-09 17:18:26.863581: Pseudo dice [0.6937]
2024-05-09 17:18:26.864780: Epoch time: 250.92 s
2024-05-09 17:18:26.865940: Yayy! New best EMA pseudo Dice: 0.6653
2024-05-09 17:18:28.590279: 
2024-05-09 17:18:28.591813: Epoch 51
2024-05-09 17:18:28.592967: Current learning rate: 0.00954
2024-05-09 17:22:40.402923: Validation loss did not improve from -0.56792. Patience: 21/50
2024-05-09 17:22:40.404409: train_loss -0.7223
2024-05-09 17:22:40.405903: val_loss -0.5242
2024-05-09 17:22:40.407213: Pseudo dice [0.6789]
2024-05-09 17:22:40.408977: Epoch time: 251.82 s
2024-05-09 17:22:40.410372: Yayy! New best EMA pseudo Dice: 0.6667
2024-05-09 17:22:42.188069: 
2024-05-09 17:22:42.189763: Epoch 52
2024-05-09 17:22:42.191141: Current learning rate: 0.00953
2024-05-09 17:26:51.121076: Validation loss did not improve from -0.56792. Patience: 22/50
2024-05-09 17:26:51.122228: train_loss -0.7351
2024-05-09 17:26:51.123350: val_loss -0.5502
2024-05-09 17:26:51.124431: Pseudo dice [0.6816]
2024-05-09 17:26:51.125414: Epoch time: 248.94 s
2024-05-09 17:26:51.126419: Yayy! New best EMA pseudo Dice: 0.6682
2024-05-09 17:26:52.883066: 
2024-05-09 17:26:52.884540: Epoch 53
2024-05-09 17:26:52.885601: Current learning rate: 0.00952
2024-05-09 17:31:05.211723: Validation loss did not improve from -0.56792. Patience: 23/50
2024-05-09 17:31:05.213236: train_loss -0.7426
2024-05-09 17:31:05.214494: val_loss -0.5238
2024-05-09 17:31:05.216049: Pseudo dice [0.6737]
2024-05-09 17:31:05.217144: Epoch time: 252.33 s
2024-05-09 17:31:05.218174: Yayy! New best EMA pseudo Dice: 0.6687
2024-05-09 17:31:07.532624: 
2024-05-09 17:31:07.534591: Epoch 54
2024-05-09 17:31:07.535652: Current learning rate: 0.00951
2024-05-09 17:35:17.781497: Validation loss did not improve from -0.56792. Patience: 24/50
2024-05-09 17:35:17.782635: train_loss -0.7408
2024-05-09 17:35:17.783708: val_loss -0.5561
2024-05-09 17:35:17.784686: Pseudo dice [0.6948]
2024-05-09 17:35:17.785631: Epoch time: 250.25 s
2024-05-09 17:35:18.188066: Yayy! New best EMA pseudo Dice: 0.6713
2024-05-09 17:35:19.930447: 
2024-05-09 17:35:19.931681: Epoch 55
2024-05-09 17:35:19.932729: Current learning rate: 0.0095
2024-05-09 17:39:28.792727: Validation loss improved from -0.56792 to -0.57757! Patience: 24/50
2024-05-09 17:39:28.793925: train_loss -0.7394
2024-05-09 17:39:28.795070: val_loss -0.5776
2024-05-09 17:39:28.796049: Pseudo dice [0.6943]
2024-05-09 17:39:28.797144: Epoch time: 248.86 s
2024-05-09 17:39:28.798044: Yayy! New best EMA pseudo Dice: 0.6736
2024-05-09 17:39:30.559290: 
2024-05-09 17:39:30.560483: Epoch 56
2024-05-09 17:39:30.561453: Current learning rate: 0.00949
2024-05-09 17:43:43.862979: Validation loss did not improve from -0.57757. Patience: 1/50
2024-05-09 17:43:43.864308: train_loss -0.7369
2024-05-09 17:43:43.865421: val_loss -0.4818
2024-05-09 17:43:43.866456: Pseudo dice [0.6336]
2024-05-09 17:43:43.867546: Epoch time: 253.31 s
2024-05-09 17:43:45.210462: 
2024-05-09 17:43:45.211795: Epoch 57
2024-05-09 17:43:45.212765: Current learning rate: 0.00949
2024-05-09 17:47:51.687107: Validation loss did not improve from -0.57757. Patience: 2/50
2024-05-09 17:47:51.688523: train_loss -0.7345
2024-05-09 17:47:51.690003: val_loss -0.5197
2024-05-09 17:47:51.691202: Pseudo dice [0.6805]
2024-05-09 17:47:51.692243: Epoch time: 246.48 s
2024-05-09 17:47:53.065720: 
2024-05-09 17:47:53.066933: Epoch 58
2024-05-09 17:47:53.068380: Current learning rate: 0.00948
2024-05-09 17:52:00.940071: Validation loss did not improve from -0.57757. Patience: 3/50
2024-05-09 17:52:00.941261: train_loss -0.7243
2024-05-09 17:52:00.942405: val_loss -0.5478
2024-05-09 17:52:00.943479: Pseudo dice [0.6876]
2024-05-09 17:52:00.944430: Epoch time: 247.88 s
2024-05-09 17:52:02.302076: 
2024-05-09 17:52:02.303542: Epoch 59
2024-05-09 17:52:02.304456: Current learning rate: 0.00947
2024-05-09 17:56:11.696993: Validation loss did not improve from -0.57757. Patience: 4/50
2024-05-09 17:56:11.699417: train_loss -0.7332
2024-05-09 17:56:11.701012: val_loss -0.5594
2024-05-09 17:56:11.702073: Pseudo dice [0.6945]
2024-05-09 17:56:11.703197: Epoch time: 249.4 s
2024-05-09 17:56:12.139930: Yayy! New best EMA pseudo Dice: 0.6746
2024-05-09 17:56:13.830311: 
2024-05-09 17:56:13.831861: Epoch 60
2024-05-09 17:56:13.832943: Current learning rate: 0.00946
2024-05-09 18:00:29.168537: Validation loss did not improve from -0.57757. Patience: 5/50
2024-05-09 18:00:29.169915: train_loss -0.738
2024-05-09 18:00:29.171036: val_loss -0.5142
2024-05-09 18:00:29.172062: Pseudo dice [0.6639]
2024-05-09 18:00:29.173015: Epoch time: 255.34 s
2024-05-09 18:00:30.529663: 
2024-05-09 18:00:30.530855: Epoch 61
2024-05-09 18:00:30.531906: Current learning rate: 0.00945
2024-05-09 18:04:43.001823: Validation loss did not improve from -0.57757. Patience: 6/50
2024-05-09 18:04:43.003297: train_loss -0.751
2024-05-09 18:04:43.004485: val_loss -0.5692
2024-05-09 18:04:43.005548: Pseudo dice [0.688]
2024-05-09 18:04:43.006646: Epoch time: 252.48 s
2024-05-09 18:04:43.007547: Yayy! New best EMA pseudo Dice: 0.675
2024-05-09 18:04:44.757996: 
2024-05-09 18:04:44.759609: Epoch 62
2024-05-09 18:04:44.760548: Current learning rate: 0.00944
2024-05-09 18:08:57.695246: Validation loss did not improve from -0.57757. Patience: 7/50
2024-05-09 18:08:57.697181: train_loss -0.7515
2024-05-09 18:08:57.699395: val_loss -0.5651
2024-05-09 18:08:57.700490: Pseudo dice [0.6939]
2024-05-09 18:08:57.702115: Epoch time: 252.94 s
2024-05-09 18:08:57.703155: Yayy! New best EMA pseudo Dice: 0.6769
2024-05-09 18:08:59.432351: 
2024-05-09 18:08:59.434249: Epoch 63
2024-05-09 18:08:59.435263: Current learning rate: 0.00943
2024-05-09 18:13:11.845278: Validation loss improved from -0.57757 to -0.58676! Patience: 7/50
2024-05-09 18:13:11.847028: train_loss -0.7519
2024-05-09 18:13:11.848288: val_loss -0.5868
2024-05-09 18:13:11.849288: Pseudo dice [0.7107]
2024-05-09 18:13:11.850243: Epoch time: 252.42 s
2024-05-09 18:13:11.851261: Yayy! New best EMA pseudo Dice: 0.6803
2024-05-09 18:13:14.085454: 
2024-05-09 18:13:14.087039: Epoch 64
2024-05-09 18:13:14.088112: Current learning rate: 0.00942
2024-05-09 18:17:24.457808: Validation loss did not improve from -0.58676. Patience: 1/50
2024-05-09 18:17:24.459330: train_loss -0.7486
2024-05-09 18:17:24.460498: val_loss -0.5624
2024-05-09 18:17:24.461514: Pseudo dice [0.693]
2024-05-09 18:17:24.462662: Epoch time: 250.37 s
2024-05-09 18:17:24.814334: Yayy! New best EMA pseudo Dice: 0.6815
2024-05-09 18:17:27.169629: 
2024-05-09 18:17:27.171243: Epoch 65
2024-05-09 18:17:27.172447: Current learning rate: 0.00941
2024-05-09 18:21:38.170648: Validation loss did not improve from -0.58676. Patience: 2/50
2024-05-09 18:21:38.171864: train_loss -0.7623
2024-05-09 18:21:38.172831: val_loss -0.5473
2024-05-09 18:21:38.173821: Pseudo dice [0.6933]
2024-05-09 18:21:38.174822: Epoch time: 251.0 s
2024-05-09 18:21:38.175811: Yayy! New best EMA pseudo Dice: 0.6827
2024-05-09 18:21:40.097553: 
2024-05-09 18:21:40.098927: Epoch 66
2024-05-09 18:21:40.100018: Current learning rate: 0.0094
2024-05-09 18:25:49.991789: Validation loss did not improve from -0.58676. Patience: 3/50
2024-05-09 18:25:49.993047: train_loss -0.7657
2024-05-09 18:25:49.994504: val_loss -0.5456
2024-05-09 18:25:49.995750: Pseudo dice [0.6838]
2024-05-09 18:25:49.996948: Epoch time: 249.9 s
2024-05-09 18:25:49.998193: Yayy! New best EMA pseudo Dice: 0.6828
2024-05-09 18:25:51.759218: 
2024-05-09 18:25:51.760812: Epoch 67
2024-05-09 18:25:51.762111: Current learning rate: 0.00939
2024-05-09 18:30:02.198041: Validation loss did not improve from -0.58676. Patience: 4/50
2024-05-09 18:30:02.199378: train_loss -0.7688
2024-05-09 18:30:02.200720: val_loss -0.5509
2024-05-09 18:30:02.201696: Pseudo dice [0.6915]
2024-05-09 18:30:02.202736: Epoch time: 250.44 s
2024-05-09 18:30:02.203607: Yayy! New best EMA pseudo Dice: 0.6837
2024-05-09 18:30:04.003375: 
2024-05-09 18:30:04.005092: Epoch 68
2024-05-09 18:30:04.006102: Current learning rate: 0.00939
2024-05-09 18:34:15.203076: Validation loss did not improve from -0.58676. Patience: 5/50
2024-05-09 18:34:15.204353: train_loss -0.7755
2024-05-09 18:34:15.205391: val_loss -0.5589
2024-05-09 18:34:15.206350: Pseudo dice [0.6961]
2024-05-09 18:34:15.207316: Epoch time: 251.2 s
2024-05-09 18:34:15.208462: Yayy! New best EMA pseudo Dice: 0.6849
2024-05-09 18:34:16.996251: 
2024-05-09 18:34:16.997629: Epoch 69
2024-05-09 18:34:16.999018: Current learning rate: 0.00938
2024-05-09 18:38:27.194741: Validation loss did not improve from -0.58676. Patience: 6/50
2024-05-09 18:38:27.196795: train_loss -0.7632
2024-05-09 18:38:27.197960: val_loss -0.553
2024-05-09 18:38:27.199056: Pseudo dice [0.6736]
2024-05-09 18:38:27.200293: Epoch time: 250.2 s
2024-05-09 18:38:29.016483: 
2024-05-09 18:38:29.017909: Epoch 70
2024-05-09 18:38:29.019082: Current learning rate: 0.00937
2024-05-09 18:42:39.073929: Validation loss did not improve from -0.58676. Patience: 7/50
2024-05-09 18:42:39.075130: train_loss -0.7575
2024-05-09 18:42:39.076336: val_loss -0.5832
2024-05-09 18:42:39.077611: Pseudo dice [0.7052]
2024-05-09 18:42:39.078844: Epoch time: 250.06 s
2024-05-09 18:42:39.079971: Yayy! New best EMA pseudo Dice: 0.6859
2024-05-09 18:42:40.864244: 
2024-05-09 18:42:40.865616: Epoch 71
2024-05-09 18:42:40.866787: Current learning rate: 0.00936
2024-05-09 18:46:52.671519: Validation loss did not improve from -0.58676. Patience: 8/50
2024-05-09 18:46:52.672770: train_loss -0.7707
2024-05-09 18:46:52.674093: val_loss -0.5805
2024-05-09 18:46:52.675195: Pseudo dice [0.7179]
2024-05-09 18:46:52.676212: Epoch time: 251.81 s
2024-05-09 18:46:52.677394: Yayy! New best EMA pseudo Dice: 0.6891
2024-05-09 18:46:54.463118: 
2024-05-09 18:46:54.464305: Epoch 72
2024-05-09 18:46:54.465384: Current learning rate: 0.00935
2024-05-09 18:51:07.213826: Validation loss did not improve from -0.58676. Patience: 9/50
2024-05-09 18:51:07.215314: train_loss -0.756
2024-05-09 18:51:07.216587: val_loss -0.5701
2024-05-09 18:51:07.217883: Pseudo dice [0.6921]
2024-05-09 18:51:07.219001: Epoch time: 252.75 s
2024-05-09 18:51:07.220089: Yayy! New best EMA pseudo Dice: 0.6894
2024-05-09 18:51:09.037545: 
2024-05-09 18:51:09.039172: Epoch 73
2024-05-09 18:51:09.040296: Current learning rate: 0.00934
2024-05-09 18:55:23.351284: Validation loss did not improve from -0.58676. Patience: 10/50
2024-05-09 18:55:23.352560: train_loss -0.7465
2024-05-09 18:55:23.353768: val_loss -0.5749
2024-05-09 18:55:23.354696: Pseudo dice [0.7033]
2024-05-09 18:55:23.355736: Epoch time: 254.32 s
2024-05-09 18:55:23.356804: Yayy! New best EMA pseudo Dice: 0.6908
2024-05-09 18:55:25.138645: 
2024-05-09 18:55:25.139888: Epoch 74
2024-05-09 18:55:25.140927: Current learning rate: 0.00933
2024-05-09 18:59:37.658162: Validation loss did not improve from -0.58676. Patience: 11/50
2024-05-09 18:59:37.659472: train_loss -0.758
2024-05-09 18:59:37.660689: val_loss -0.5529
2024-05-09 18:59:37.661875: Pseudo dice [0.695]
2024-05-09 18:59:37.663187: Epoch time: 252.52 s
2024-05-09 18:59:38.069865: Yayy! New best EMA pseudo Dice: 0.6912
2024-05-09 18:59:39.882842: 
2024-05-09 18:59:39.884501: Epoch 75
2024-05-09 18:59:39.885633: Current learning rate: 0.00932
2024-05-09 19:03:53.790218: Validation loss did not improve from -0.58676. Patience: 12/50
2024-05-09 19:03:53.791525: train_loss -0.7601
2024-05-09 19:03:53.792859: val_loss -0.5451
2024-05-09 19:03:53.794061: Pseudo dice [0.6825]
2024-05-09 19:03:53.795404: Epoch time: 253.91 s
2024-05-09 19:03:55.679522: 
2024-05-09 19:03:55.681081: Epoch 76
2024-05-09 19:03:55.682286: Current learning rate: 0.00931
2024-05-09 19:08:06.503483: Validation loss did not improve from -0.58676. Patience: 13/50
2024-05-09 19:08:06.504945: train_loss -0.7587
2024-05-09 19:08:06.506522: val_loss -0.5866
2024-05-09 19:08:06.507638: Pseudo dice [0.7143]
2024-05-09 19:08:06.508583: Epoch time: 250.83 s
2024-05-09 19:08:06.509470: Yayy! New best EMA pseudo Dice: 0.6927
2024-05-09 19:08:08.334666: 
2024-05-09 19:08:08.335915: Epoch 77
2024-05-09 19:08:08.336856: Current learning rate: 0.0093
2024-05-09 19:12:11.156131: Validation loss improved from -0.58676 to -0.60634! Patience: 13/50
2024-05-09 19:12:11.158049: train_loss -0.7605
2024-05-09 19:12:11.159708: val_loss -0.6063
2024-05-09 19:12:11.160708: Pseudo dice [0.7305]
2024-05-09 19:12:11.161869: Epoch time: 242.82 s
2024-05-09 19:12:11.162818: Yayy! New best EMA pseudo Dice: 0.6965
2024-05-09 19:12:12.982152: 
2024-05-09 19:12:12.983636: Epoch 78
2024-05-09 19:12:12.984640: Current learning rate: 0.0093
2024-05-09 19:16:17.964441: Validation loss did not improve from -0.60634. Patience: 1/50
2024-05-09 19:16:17.966230: train_loss -0.773
2024-05-09 19:16:17.967569: val_loss -0.5606
2024-05-09 19:16:17.968918: Pseudo dice [0.6909]
2024-05-09 19:16:17.970243: Epoch time: 244.99 s
2024-05-09 19:16:19.707866: 
2024-05-09 19:16:19.709390: Epoch 79
2024-05-09 19:16:19.710585: Current learning rate: 0.00929
2024-05-09 19:20:14.797049: Validation loss did not improve from -0.60634. Patience: 2/50
2024-05-09 19:20:14.798629: train_loss -0.7769
2024-05-09 19:20:14.800432: val_loss -0.59
2024-05-09 19:20:14.801557: Pseudo dice [0.7074]
2024-05-09 19:20:14.802571: Epoch time: 235.09 s
2024-05-09 19:20:15.209421: Yayy! New best EMA pseudo Dice: 0.6971
2024-05-09 19:20:16.864891: 
2024-05-09 19:20:16.867745: Epoch 80
2024-05-09 19:20:16.869108: Current learning rate: 0.00928
2024-05-09 19:24:30.369683: Validation loss did not improve from -0.60634. Patience: 3/50
2024-05-09 19:24:30.370901: train_loss -0.7604
2024-05-09 19:24:30.372264: val_loss -0.5582
2024-05-09 19:24:30.373460: Pseudo dice [0.693]
2024-05-09 19:24:30.374728: Epoch time: 253.51 s
2024-05-09 19:24:31.803982: 
2024-05-09 19:24:31.805609: Epoch 81
2024-05-09 19:24:31.806844: Current learning rate: 0.00927
2024-05-09 19:28:48.090302: Validation loss did not improve from -0.60634. Patience: 4/50
2024-05-09 19:28:48.091826: train_loss -0.7691
2024-05-09 19:28:48.093304: val_loss -0.5826
2024-05-09 19:28:48.094355: Pseudo dice [0.6977]
2024-05-09 19:28:48.095706: Epoch time: 256.29 s
2024-05-09 19:28:49.523987: 
2024-05-09 19:28:49.525312: Epoch 82
2024-05-09 19:28:49.526287: Current learning rate: 0.00926
2024-05-09 19:33:01.801557: Validation loss did not improve from -0.60634. Patience: 5/50
2024-05-09 19:33:01.802904: train_loss -0.7687
2024-05-09 19:33:01.804111: val_loss -0.5756
2024-05-09 19:33:01.805274: Pseudo dice [0.7011]
2024-05-09 19:33:01.806432: Epoch time: 252.28 s
2024-05-09 19:33:01.807377: Yayy! New best EMA pseudo Dice: 0.6972
2024-05-09 19:33:03.566513: 
2024-05-09 19:33:03.567806: Epoch 83
2024-05-09 19:33:03.568811: Current learning rate: 0.00925
2024-05-09 19:37:14.307690: Validation loss did not improve from -0.60634. Patience: 6/50
2024-05-09 19:37:14.308937: train_loss -0.7673
2024-05-09 19:37:14.310090: val_loss -0.5451
2024-05-09 19:37:14.311137: Pseudo dice [0.6908]
2024-05-09 19:37:14.312071: Epoch time: 250.74 s
2024-05-09 19:37:15.649715: 
2024-05-09 19:37:15.651582: Epoch 84
2024-05-09 19:37:15.653191: Current learning rate: 0.00924
2024-05-09 19:41:20.410799: Validation loss did not improve from -0.60634. Patience: 7/50
2024-05-09 19:41:20.412106: train_loss -0.7839
2024-05-09 19:41:20.413118: val_loss -0.5945
2024-05-09 19:41:20.414099: Pseudo dice [0.7195]
2024-05-09 19:41:20.415094: Epoch time: 244.76 s
2024-05-09 19:41:21.246500: Yayy! New best EMA pseudo Dice: 0.6989
2024-05-09 19:41:23.105407: 
2024-05-09 19:41:23.106715: Epoch 85
2024-05-09 19:41:23.107639: Current learning rate: 0.00923
2024-05-09 19:45:26.560313: Validation loss did not improve from -0.60634. Patience: 8/50
2024-05-09 19:45:26.561512: train_loss -0.7698
2024-05-09 19:45:26.562679: val_loss -0.5631
2024-05-09 19:45:26.563664: Pseudo dice [0.693]
2024-05-09 19:45:26.564741: Epoch time: 243.46 s
2024-05-09 19:45:27.963467: 
2024-05-09 19:45:27.964714: Epoch 86
2024-05-09 19:45:27.965843: Current learning rate: 0.00922
2024-05-09 19:49:20.527735: Validation loss did not improve from -0.60634. Patience: 9/50
2024-05-09 19:49:20.529004: train_loss -0.7805
2024-05-09 19:49:20.530078: val_loss -0.5436
2024-05-09 19:49:20.531054: Pseudo dice [0.6749]
2024-05-09 19:49:20.532196: Epoch time: 232.57 s
2024-05-09 19:49:21.756061: 
2024-05-09 19:49:21.757793: Epoch 87
2024-05-09 19:49:21.758870: Current learning rate: 0.00921
2024-05-09 19:53:16.629617: Validation loss did not improve from -0.60634. Patience: 10/50
2024-05-09 19:53:16.631019: train_loss -0.7772
2024-05-09 19:53:16.632248: val_loss -0.5814
2024-05-09 19:53:16.633335: Pseudo dice [0.7061]
2024-05-09 19:53:16.634349: Epoch time: 234.88 s
2024-05-09 19:53:18.831270: 
2024-05-09 19:53:18.833441: Epoch 88
2024-05-09 19:53:18.834453: Current learning rate: 0.0092
2024-05-09 19:57:20.667542: Validation loss did not improve from -0.60634. Patience: 11/50
2024-05-09 19:57:20.668857: train_loss -0.7813
2024-05-09 19:57:20.669870: val_loss -0.565
2024-05-09 19:57:20.670922: Pseudo dice [0.6982]
2024-05-09 19:57:20.671868: Epoch time: 241.84 s
2024-05-09 19:57:22.010472: 
2024-05-09 19:57:22.011812: Epoch 89
2024-05-09 19:57:22.012920: Current learning rate: 0.0092
2024-05-09 20:01:27.156541: Validation loss did not improve from -0.60634. Patience: 12/50
2024-05-09 20:01:27.157768: train_loss -0.781
2024-05-09 20:01:27.159087: val_loss -0.5919
2024-05-09 20:01:27.160218: Pseudo dice [0.7143]
2024-05-09 20:01:27.161363: Epoch time: 245.15 s
2024-05-09 20:01:28.877613: 
2024-05-09 20:01:28.878956: Epoch 90
2024-05-09 20:01:28.880375: Current learning rate: 0.00919
2024-05-09 20:05:43.307880: Validation loss did not improve from -0.60634. Patience: 13/50
2024-05-09 20:05:43.309218: train_loss -0.7855
2024-05-09 20:05:43.310837: val_loss -0.5734
2024-05-09 20:05:43.312553: Pseudo dice [0.7017]
2024-05-09 20:05:43.313678: Epoch time: 254.43 s
2024-05-09 20:05:43.314636: Yayy! New best EMA pseudo Dice: 0.6991
2024-05-09 20:05:45.075403: 
2024-05-09 20:05:45.076708: Epoch 91
2024-05-09 20:05:45.077856: Current learning rate: 0.00918
2024-05-09 20:09:55.145804: Validation loss did not improve from -0.60634. Patience: 14/50
2024-05-09 20:09:55.147578: train_loss -0.7844
2024-05-09 20:09:55.148538: val_loss -0.5688
2024-05-09 20:09:55.149615: Pseudo dice [0.6995]
2024-05-09 20:09:55.150753: Epoch time: 250.07 s
2024-05-09 20:09:55.151816: Yayy! New best EMA pseudo Dice: 0.6991
2024-05-09 20:09:56.851444: 
2024-05-09 20:09:56.852890: Epoch 92
2024-05-09 20:09:56.853960: Current learning rate: 0.00917
2024-05-09 20:13:59.493607: Validation loss did not improve from -0.60634. Patience: 15/50
2024-05-09 20:13:59.494848: train_loss -0.7928
2024-05-09 20:13:59.496040: val_loss -0.551
2024-05-09 20:13:59.496975: Pseudo dice [0.688]
2024-05-09 20:13:59.498038: Epoch time: 242.64 s
2024-05-09 20:14:00.821067: 
2024-05-09 20:14:00.822541: Epoch 93
2024-05-09 20:14:00.823686: Current learning rate: 0.00916
2024-05-09 20:18:04.638312: Validation loss did not improve from -0.60634. Patience: 16/50
2024-05-09 20:18:04.640099: train_loss -0.7851
2024-05-09 20:18:04.642351: val_loss -0.5431
2024-05-09 20:18:04.643612: Pseudo dice [0.6837]
2024-05-09 20:18:04.644984: Epoch time: 243.82 s
2024-05-09 20:18:05.978476: 
2024-05-09 20:18:05.980037: Epoch 94
2024-05-09 20:18:05.981210: Current learning rate: 0.00915
2024-05-09 20:22:21.132771: Validation loss did not improve from -0.60634. Patience: 17/50
2024-05-09 20:22:21.134686: train_loss -0.785
2024-05-09 20:22:21.135924: val_loss -0.5878
2024-05-09 20:22:21.136961: Pseudo dice [0.7242]
2024-05-09 20:22:21.138052: Epoch time: 255.16 s
2024-05-09 20:22:22.096965: Yayy! New best EMA pseudo Dice: 0.6994
2024-05-09 20:22:24.164490: 
2024-05-09 20:22:24.165724: Epoch 95
2024-05-09 20:22:24.166753: Current learning rate: 0.00914
2024-05-09 20:26:39.554931: Validation loss did not improve from -0.60634. Patience: 18/50
2024-05-09 20:26:39.556139: train_loss -0.7848
2024-05-09 20:26:39.557125: val_loss -0.5627
2024-05-09 20:26:39.558002: Pseudo dice [0.6901]
2024-05-09 20:26:39.558988: Epoch time: 255.39 s
2024-05-09 20:26:40.874249: 
2024-05-09 20:26:40.875570: Epoch 96
2024-05-09 20:26:40.876679: Current learning rate: 0.00913
2024-05-09 20:30:46.748902: Validation loss did not improve from -0.60634. Patience: 19/50
2024-05-09 20:30:46.750175: train_loss -0.796
2024-05-09 20:30:46.751408: val_loss -0.5159
2024-05-09 20:30:46.752506: Pseudo dice [0.6588]
2024-05-09 20:30:46.753571: Epoch time: 245.88 s
2024-05-09 20:30:48.154689: 
2024-05-09 20:30:48.156631: Epoch 97
2024-05-09 20:30:48.157898: Current learning rate: 0.00912
2024-05-09 20:34:47.920236: Validation loss did not improve from -0.60634. Patience: 20/50
2024-05-09 20:34:47.921454: train_loss -0.7977
2024-05-09 20:34:47.922510: val_loss -0.5968
2024-05-09 20:34:47.923398: Pseudo dice [0.7174]
2024-05-09 20:34:47.924336: Epoch time: 239.77 s
2024-05-09 20:34:49.318423: 
2024-05-09 20:34:49.319658: Epoch 98
2024-05-09 20:34:49.320736: Current learning rate: 0.00911
2024-05-09 20:38:50.418921: Validation loss did not improve from -0.60634. Patience: 21/50
2024-05-09 20:38:50.420083: train_loss -0.798
2024-05-09 20:38:50.421050: val_loss -0.6007
2024-05-09 20:38:50.421993: Pseudo dice [0.7318]
2024-05-09 20:38:50.423105: Epoch time: 241.1 s
2024-05-09 20:38:50.424003: Yayy! New best EMA pseudo Dice: 0.7003
2024-05-09 20:38:53.713912: 
2024-05-09 20:38:53.715360: Epoch 99
2024-05-09 20:38:53.716513: Current learning rate: 0.0091
2024-05-09 20:43:01.972008: Validation loss did not improve from -0.60634. Patience: 22/50
2024-05-09 20:43:01.973418: train_loss -0.7891
2024-05-09 20:43:01.975172: val_loss -0.5739
2024-05-09 20:43:01.976329: Pseudo dice [0.7019]
2024-05-09 20:43:01.977556: Epoch time: 248.26 s
2024-05-09 20:43:02.363850: Yayy! New best EMA pseudo Dice: 0.7004
2024-05-09 20:43:04.093120: 
2024-05-09 20:43:04.094552: Epoch 100
2024-05-09 20:43:04.095538: Current learning rate: 0.0091
2024-05-09 20:47:05.765665: Validation loss did not improve from -0.60634. Patience: 23/50
2024-05-09 20:47:05.767267: train_loss -0.7874
2024-05-09 20:47:05.768294: val_loss -0.5511
2024-05-09 20:47:05.769271: Pseudo dice [0.6959]
2024-05-09 20:47:05.770184: Epoch time: 241.67 s
2024-05-09 20:47:07.194002: 
2024-05-09 20:47:07.195212: Epoch 101
2024-05-09 20:47:07.196261: Current learning rate: 0.00909
2024-05-09 20:51:01.257295: Validation loss did not improve from -0.60634. Patience: 24/50
2024-05-09 20:51:01.258430: train_loss -0.7868
2024-05-09 20:51:01.259660: val_loss -0.571
2024-05-09 20:51:01.260914: Pseudo dice [0.7137]
2024-05-09 20:51:01.262142: Epoch time: 234.07 s
2024-05-09 20:51:01.263145: Yayy! New best EMA pseudo Dice: 0.7014
2024-05-09 20:51:02.853852: 
2024-05-09 20:51:02.855457: Epoch 102
2024-05-09 20:51:02.856717: Current learning rate: 0.00908
2024-05-09 20:55:05.673230: Validation loss improved from -0.60634 to -0.61249! Patience: 24/50
2024-05-09 20:55:05.674452: train_loss -0.8032
2024-05-09 20:55:05.675684: val_loss -0.6125
2024-05-09 20:55:05.676763: Pseudo dice [0.7302]
2024-05-09 20:55:05.677868: Epoch time: 242.82 s
2024-05-09 20:55:05.678887: Yayy! New best EMA pseudo Dice: 0.7042
2024-05-09 20:55:07.449446: 
2024-05-09 20:55:07.451580: Epoch 103
2024-05-09 20:55:07.452798: Current learning rate: 0.00907
2024-05-09 20:59:10.799368: Validation loss did not improve from -0.61249. Patience: 1/50
2024-05-09 20:59:10.800739: train_loss -0.7929
2024-05-09 20:59:10.802310: val_loss -0.5404
2024-05-09 20:59:10.803447: Pseudo dice [0.6813]
2024-05-09 20:59:10.804582: Epoch time: 243.35 s
2024-05-09 20:59:12.154627: 
2024-05-09 20:59:12.156144: Epoch 104
2024-05-09 20:59:12.157478: Current learning rate: 0.00906
2024-05-09 21:03:18.954648: Validation loss did not improve from -0.61249. Patience: 2/50
2024-05-09 21:03:18.955928: train_loss -0.7703
2024-05-09 21:03:18.957237: val_loss -0.5369
2024-05-09 21:03:18.958542: Pseudo dice [0.6872]
2024-05-09 21:03:18.959643: Epoch time: 246.8 s
2024-05-09 21:03:20.765998: 
2024-05-09 21:03:20.767877: Epoch 105
2024-05-09 21:03:20.769013: Current learning rate: 0.00905
2024-05-09 21:07:38.341600: Validation loss did not improve from -0.61249. Patience: 3/50
2024-05-09 21:07:38.342715: train_loss -0.7871
2024-05-09 21:07:38.343939: val_loss -0.5889
2024-05-09 21:07:38.345107: Pseudo dice [0.7155]
2024-05-09 21:07:38.346080: Epoch time: 257.58 s
2024-05-09 21:07:39.700626: 
2024-05-09 21:07:39.701960: Epoch 106
2024-05-09 21:07:39.703245: Current learning rate: 0.00904
2024-05-09 21:11:44.816678: Validation loss did not improve from -0.61249. Patience: 4/50
2024-05-09 21:11:44.818019: train_loss -0.7849
2024-05-09 21:11:44.820405: val_loss -0.5511
2024-05-09 21:11:44.821456: Pseudo dice [0.6816]
2024-05-09 21:11:44.822432: Epoch time: 245.12 s
2024-05-09 21:11:46.168827: 
2024-05-09 21:11:46.169947: Epoch 107
2024-05-09 21:11:46.171336: Current learning rate: 0.00903
2024-05-09 21:15:51.705600: Validation loss did not improve from -0.61249. Patience: 5/50
2024-05-09 21:15:51.706795: train_loss -0.7959
2024-05-09 21:15:51.708088: val_loss -0.5925
2024-05-09 21:15:51.709014: Pseudo dice [0.7202]
2024-05-09 21:15:51.710171: Epoch time: 245.54 s
2024-05-09 21:15:53.058976: 
2024-05-09 21:15:53.060099: Epoch 108
2024-05-09 21:15:53.061131: Current learning rate: 0.00902
2024-05-09 21:20:01.449307: Validation loss did not improve from -0.61249. Patience: 6/50
2024-05-09 21:20:01.450941: train_loss -0.7964
2024-05-09 21:20:01.452111: val_loss -0.5635
2024-05-09 21:20:01.453216: Pseudo dice [0.7132]
2024-05-09 21:20:01.454156: Epoch time: 248.39 s
2024-05-09 21:20:02.828478: 
2024-05-09 21:20:02.829656: Epoch 109
2024-05-09 21:20:02.830655: Current learning rate: 0.00901
2024-05-09 21:24:21.726909: Validation loss did not improve from -0.61249. Patience: 7/50
2024-05-09 21:24:21.729690: train_loss -0.8036
2024-05-09 21:24:21.731805: val_loss -0.5839
2024-05-09 21:24:21.733012: Pseudo dice [0.725]
2024-05-09 21:24:21.734091: Epoch time: 258.9 s
2024-05-09 21:24:22.314291: Yayy! New best EMA pseudo Dice: 0.7053
2024-05-09 21:24:24.056375: 
2024-05-09 21:24:24.057578: Epoch 110
2024-05-09 21:24:24.058460: Current learning rate: 0.009
2024-05-09 21:28:33.933421: Validation loss did not improve from -0.61249. Patience: 8/50
2024-05-09 21:28:33.935232: train_loss -0.8059
2024-05-09 21:28:33.936290: val_loss -0.6039
2024-05-09 21:28:33.937229: Pseudo dice [0.7202]
2024-05-09 21:28:33.938172: Epoch time: 249.88 s
2024-05-09 21:28:33.939147: Yayy! New best EMA pseudo Dice: 0.7068
2024-05-09 21:28:36.307797: 
2024-05-09 21:28:36.309670: Epoch 111
2024-05-09 21:28:36.310727: Current learning rate: 0.009
2024-05-09 21:32:38.726573: Validation loss did not improve from -0.61249. Patience: 9/50
2024-05-09 21:32:38.727715: train_loss -0.7935
2024-05-09 21:32:38.728803: val_loss -0.5522
2024-05-09 21:32:38.729738: Pseudo dice [0.6898]
2024-05-09 21:32:38.730703: Epoch time: 242.42 s
2024-05-09 21:32:40.084475: 
2024-05-09 21:32:40.085575: Epoch 112
2024-05-09 21:32:40.086485: Current learning rate: 0.00899
2024-05-09 21:36:46.123176: Validation loss did not improve from -0.61249. Patience: 10/50
2024-05-09 21:36:46.124382: train_loss -0.7956
2024-05-09 21:36:46.125553: val_loss -0.5798
2024-05-09 21:36:46.126612: Pseudo dice [0.7055]
2024-05-09 21:36:46.127796: Epoch time: 246.04 s
2024-05-09 21:36:47.489177: 
2024-05-09 21:36:47.490530: Epoch 113
2024-05-09 21:36:47.491491: Current learning rate: 0.00898
2024-05-09 21:40:47.944701: Validation loss did not improve from -0.61249. Patience: 11/50
2024-05-09 21:40:47.945924: train_loss -0.8032
2024-05-09 21:40:47.946959: val_loss -0.5548
2024-05-09 21:40:47.948070: Pseudo dice [0.7061]
2024-05-09 21:40:47.949163: Epoch time: 240.46 s
2024-05-09 21:40:49.317262: 
2024-05-09 21:40:49.318457: Epoch 114
2024-05-09 21:40:49.319419: Current learning rate: 0.00897
2024-05-09 21:45:05.623688: Validation loss did not improve from -0.61249. Patience: 12/50
2024-05-09 21:45:05.624794: train_loss -0.787
2024-05-09 21:45:05.626173: val_loss -0.5533
2024-05-09 21:45:05.627508: Pseudo dice [0.6985]
2024-05-09 21:45:05.628867: Epoch time: 256.31 s
2024-05-09 21:45:07.345814: 
2024-05-09 21:45:07.347131: Epoch 115
2024-05-09 21:45:07.348168: Current learning rate: 0.00896
2024-05-09 21:49:19.134341: Validation loss did not improve from -0.61249. Patience: 13/50
2024-05-09 21:49:19.135530: train_loss -0.7844
2024-05-09 21:49:19.136689: val_loss -0.6077
2024-05-09 21:49:19.137619: Pseudo dice [0.7158]
2024-05-09 21:49:19.138760: Epoch time: 251.79 s
2024-05-09 21:49:20.520090: 
2024-05-09 21:49:20.521548: Epoch 116
2024-05-09 21:49:20.522580: Current learning rate: 0.00895
2024-05-09 21:53:22.392229: Validation loss did not improve from -0.61249. Patience: 14/50
2024-05-09 21:53:22.393853: train_loss -0.8037
2024-05-09 21:53:22.395463: val_loss -0.5571
2024-05-09 21:53:22.397113: Pseudo dice [0.6978]
2024-05-09 21:53:22.398300: Epoch time: 241.87 s
2024-05-09 21:53:23.940418: 
2024-05-09 21:53:23.941901: Epoch 117
2024-05-09 21:53:23.943314: Current learning rate: 0.00894
2024-05-09 21:57:30.028366: Validation loss did not improve from -0.61249. Patience: 15/50
2024-05-09 21:57:30.029639: train_loss -0.808
2024-05-09 21:57:30.030730: val_loss -0.607
2024-05-09 21:57:30.031635: Pseudo dice [0.7261]
2024-05-09 21:57:30.032701: Epoch time: 246.09 s
2024-05-09 21:57:30.033755: Yayy! New best EMA pseudo Dice: 0.707
2024-05-09 21:57:31.871030: 
2024-05-09 21:57:31.872383: Epoch 118
2024-05-09 21:57:31.873343: Current learning rate: 0.00893
2024-05-09 22:01:43.150012: Validation loss did not improve from -0.61249. Patience: 16/50
2024-05-09 22:01:43.151145: train_loss -0.8131
2024-05-09 22:01:43.152205: val_loss -0.5561
2024-05-09 22:01:43.153143: Pseudo dice [0.693]
2024-05-09 22:01:43.154103: Epoch time: 251.28 s
2024-05-09 22:01:44.560774: 
2024-05-09 22:01:44.561918: Epoch 119
2024-05-09 22:01:44.562794: Current learning rate: 0.00892
2024-05-09 22:06:03.504128: Validation loss did not improve from -0.61249. Patience: 17/50
2024-05-09 22:06:03.505273: train_loss -0.8106
2024-05-09 22:06:03.506631: val_loss -0.5586
2024-05-09 22:06:03.507617: Pseudo dice [0.6894]
2024-05-09 22:06:03.508894: Epoch time: 258.95 s
2024-05-09 22:06:05.741931: 
2024-05-09 22:06:05.742995: Epoch 120
2024-05-09 22:06:05.743980: Current learning rate: 0.00891
2024-05-09 22:10:18.817654: Validation loss did not improve from -0.61249. Patience: 18/50
2024-05-09 22:10:18.818825: train_loss -0.8161
2024-05-09 22:10:18.819891: val_loss -0.6045
2024-05-09 22:10:18.820835: Pseudo dice [0.7271]
2024-05-09 22:10:18.821864: Epoch time: 253.08 s
2024-05-09 22:10:20.195201: 
2024-05-09 22:10:20.196411: Epoch 121
2024-05-09 22:10:20.197380: Current learning rate: 0.0089
2024-05-09 22:14:35.202430: Validation loss did not improve from -0.61249. Patience: 19/50
2024-05-09 22:14:35.203636: train_loss -0.8136
2024-05-09 22:14:35.204783: val_loss -0.5684
2024-05-09 22:14:35.205786: Pseudo dice [0.7111]
2024-05-09 22:14:35.206770: Epoch time: 255.01 s
2024-05-09 22:14:36.586857: 
2024-05-09 22:14:36.588196: Epoch 122
2024-05-09 22:14:36.589363: Current learning rate: 0.00889
2024-05-09 22:18:46.608135: Validation loss did not improve from -0.61249. Patience: 20/50
2024-05-09 22:18:46.609348: train_loss -0.8106
2024-05-09 22:18:46.610590: val_loss -0.5999
2024-05-09 22:18:46.611573: Pseudo dice [0.7168]
2024-05-09 22:18:46.613353: Epoch time: 250.02 s
2024-05-09 22:18:46.614439: Yayy! New best EMA pseudo Dice: 0.7078
2024-05-09 22:18:49.377994: 
2024-05-09 22:18:49.379569: Epoch 123
2024-05-09 22:18:49.380561: Current learning rate: 0.00889
2024-05-09 22:22:57.970676: Validation loss did not improve from -0.61249. Patience: 21/50
2024-05-09 22:22:57.971869: train_loss -0.8109
2024-05-09 22:22:57.972979: val_loss -0.5872
2024-05-09 22:22:57.974054: Pseudo dice [0.7194]
2024-05-09 22:22:57.975065: Epoch time: 248.6 s
2024-05-09 22:22:57.976009: Yayy! New best EMA pseudo Dice: 0.7089
2024-05-09 22:22:59.748196: 
2024-05-09 22:22:59.749490: Epoch 124
2024-05-09 22:22:59.750522: Current learning rate: 0.00888
2024-05-09 22:27:02.806014: Validation loss did not improve from -0.61249. Patience: 22/50
2024-05-09 22:27:02.807449: train_loss -0.8187
2024-05-09 22:27:02.809007: val_loss -0.5846
2024-05-09 22:27:02.809952: Pseudo dice [0.7208]
2024-05-09 22:27:02.811013: Epoch time: 243.06 s
2024-05-09 22:27:03.178169: Yayy! New best EMA pseudo Dice: 0.7101
2024-05-09 22:27:04.977730: 
2024-05-09 22:27:04.979056: Epoch 125
2024-05-09 22:27:04.980160: Current learning rate: 0.00887
2024-05-09 22:31:11.712392: Validation loss did not improve from -0.61249. Patience: 23/50
2024-05-09 22:31:11.715027: train_loss -0.8156
2024-05-09 22:31:11.716213: val_loss -0.5431
2024-05-09 22:31:11.717191: Pseudo dice [0.6879]
2024-05-09 22:31:11.718201: Epoch time: 246.74 s
2024-05-09 22:31:13.116271: 
2024-05-09 22:31:13.117411: Epoch 126
2024-05-09 22:31:13.118425: Current learning rate: 0.00886
2024-05-09 22:35:16.586912: Validation loss did not improve from -0.61249. Patience: 24/50
2024-05-09 22:35:16.590291: train_loss -0.8096
2024-05-09 22:35:16.591574: val_loss -0.5294
2024-05-09 22:35:16.592668: Pseudo dice [0.6865]
2024-05-09 22:35:16.594327: Epoch time: 243.48 s
2024-05-09 22:35:17.998247: 
2024-05-09 22:35:17.999684: Epoch 127
2024-05-09 22:35:18.000712: Current learning rate: 0.00885
2024-05-09 22:39:21.808956: Validation loss did not improve from -0.61249. Patience: 25/50
2024-05-09 22:39:21.810214: train_loss -0.8139
2024-05-09 22:39:21.811292: val_loss -0.5658
2024-05-09 22:39:21.812188: Pseudo dice [0.7077]
2024-05-09 22:39:21.813263: Epoch time: 243.81 s
2024-05-09 22:39:23.211249: 
2024-05-09 22:39:23.212392: Epoch 128
2024-05-09 22:39:23.213545: Current learning rate: 0.00884
2024-05-09 22:43:28.266574: Validation loss did not improve from -0.61249. Patience: 26/50
2024-05-09 22:43:28.268391: train_loss -0.8137
2024-05-09 22:43:28.269576: val_loss -0.5768
2024-05-09 22:43:28.270745: Pseudo dice [0.7103]
2024-05-09 22:43:28.271752: Epoch time: 245.06 s
2024-05-09 22:43:29.649952: 
2024-05-09 22:43:29.651207: Epoch 129
2024-05-09 22:43:29.652194: Current learning rate: 0.00883
2024-05-09 22:47:39.364042: Validation loss improved from -0.61249 to -0.61262! Patience: 26/50
2024-05-09 22:47:39.365295: train_loss -0.8152
2024-05-09 22:47:39.366639: val_loss -0.6126
2024-05-09 22:47:39.367887: Pseudo dice [0.7352]
2024-05-09 22:47:39.369240: Epoch time: 249.72 s
2024-05-09 22:47:41.285558: 
2024-05-09 22:47:41.287353: Epoch 130
2024-05-09 22:47:41.288622: Current learning rate: 0.00882
2024-05-09 22:51:44.550315: Validation loss did not improve from -0.61262. Patience: 1/50
2024-05-09 22:51:44.551748: train_loss -0.8179
2024-05-09 22:51:44.552904: val_loss -0.5841
2024-05-09 22:51:44.553906: Pseudo dice [0.7004]
2024-05-09 22:51:44.554881: Epoch time: 243.27 s
2024-05-09 22:51:45.945163: 
2024-05-09 22:51:45.946432: Epoch 131
2024-05-09 22:51:45.947385: Current learning rate: 0.00881
2024-05-09 22:55:49.127199: Validation loss did not improve from -0.61262. Patience: 2/50
2024-05-09 22:55:49.128347: train_loss -0.8157
2024-05-09 22:55:49.129605: val_loss -0.5768
2024-05-09 22:55:49.130728: Pseudo dice [0.7188]
2024-05-09 22:55:49.131903: Epoch time: 243.18 s
2024-05-09 22:55:50.554764: 
2024-05-09 22:55:50.556147: Epoch 132
2024-05-09 22:55:50.557466: Current learning rate: 0.0088
2024-05-09 22:59:49.758109: Validation loss improved from -0.61262 to -0.61390! Patience: 2/50
2024-05-09 22:59:49.759418: train_loss -0.799
2024-05-09 22:59:49.760746: val_loss -0.6139
2024-05-09 22:59:49.761777: Pseudo dice [0.7322]
2024-05-09 22:59:49.762949: Epoch time: 239.21 s
2024-05-09 22:59:49.763860: Yayy! New best EMA pseudo Dice: 0.7117
2024-05-09 22:59:51.663734: 
2024-05-09 22:59:51.665191: Epoch 133
2024-05-09 22:59:51.666340: Current learning rate: 0.00879
2024-05-09 23:03:55.405276: Validation loss did not improve from -0.61390. Patience: 1/50
2024-05-09 23:03:55.406622: train_loss -0.812
2024-05-09 23:03:55.407936: val_loss -0.5505
2024-05-09 23:03:55.409746: Pseudo dice [0.6803]
2024-05-09 23:03:55.410909: Epoch time: 243.74 s
2024-05-09 23:03:57.147573: 
2024-05-09 23:03:57.148748: Epoch 134
2024-05-09 23:03:57.149751: Current learning rate: 0.00879
2024-05-09 23:07:56.829469: Validation loss did not improve from -0.61390. Patience: 2/50
2024-05-09 23:07:56.830673: train_loss -0.8172
2024-05-09 23:07:56.831855: val_loss -0.592
2024-05-09 23:07:56.832752: Pseudo dice [0.7177]
2024-05-09 23:07:56.833742: Epoch time: 239.68 s
2024-05-09 23:07:58.677785: 
2024-05-09 23:07:58.679059: Epoch 135
2024-05-09 23:07:58.679984: Current learning rate: 0.00878
2024-05-09 23:11:52.650055: Validation loss did not improve from -0.61390. Patience: 3/50
2024-05-09 23:11:52.651624: train_loss -0.8141
2024-05-09 23:11:52.653475: val_loss -0.5644
2024-05-09 23:11:52.654741: Pseudo dice [0.7136]
2024-05-09 23:11:52.656123: Epoch time: 233.98 s
2024-05-09 23:11:54.043576: 
2024-05-09 23:11:54.045266: Epoch 136
2024-05-09 23:11:54.046653: Current learning rate: 0.00877
2024-05-09 23:15:53.219639: Validation loss did not improve from -0.61390. Patience: 4/50
2024-05-09 23:15:53.220920: train_loss -0.8172
2024-05-09 23:15:53.222166: val_loss -0.5571
2024-05-09 23:15:53.223152: Pseudo dice [0.6971]
2024-05-09 23:15:53.224610: Epoch time: 239.18 s
2024-05-09 23:15:54.546052: 
2024-05-09 23:15:54.547705: Epoch 137
2024-05-09 23:15:54.549027: Current learning rate: 0.00876
2024-05-09 23:19:57.382877: Validation loss did not improve from -0.61390. Patience: 5/50
2024-05-09 23:19:57.383967: train_loss -0.8194
2024-05-09 23:19:57.384990: val_loss -0.5775
2024-05-09 23:19:57.386143: Pseudo dice [0.6968]
2024-05-09 23:19:57.387102: Epoch time: 242.84 s
2024-05-09 23:19:58.796934: 
2024-05-09 23:19:58.798647: Epoch 138
2024-05-09 23:19:58.799696: Current learning rate: 0.00875
2024-05-09 23:23:59.523336: Validation loss did not improve from -0.61390. Patience: 6/50
2024-05-09 23:23:59.524624: train_loss -0.8211
2024-05-09 23:23:59.525738: val_loss -0.565
2024-05-09 23:23:59.526740: Pseudo dice [0.7037]
2024-05-09 23:23:59.527787: Epoch time: 240.73 s
2024-05-09 23:24:00.930538: 
2024-05-09 23:24:00.932082: Epoch 139
2024-05-09 23:24:00.933378: Current learning rate: 0.00874
2024-05-09 23:27:57.845075: Validation loss did not improve from -0.61390. Patience: 7/50
2024-05-09 23:27:57.846323: train_loss -0.8233
2024-05-09 23:27:57.847661: val_loss -0.5758
2024-05-09 23:27:57.848670: Pseudo dice [0.7125]
2024-05-09 23:27:57.849722: Epoch time: 236.92 s
2024-05-09 23:27:59.648397: 
2024-05-09 23:27:59.649831: Epoch 140
2024-05-09 23:27:59.651461: Current learning rate: 0.00873
2024-05-09 23:32:02.955826: Validation loss did not improve from -0.61390. Patience: 8/50
2024-05-09 23:32:02.957247: train_loss -0.806
2024-05-09 23:32:02.959374: val_loss -0.5858
2024-05-09 23:32:02.960574: Pseudo dice [0.7189]
2024-05-09 23:32:02.961838: Epoch time: 243.31 s
2024-05-09 23:32:04.446405: 
2024-05-09 23:32:04.886548: Epoch 141
2024-05-09 23:32:04.888034: Current learning rate: 0.00872
2024-05-09 23:36:06.513755: Validation loss did not improve from -0.61390. Patience: 9/50
2024-05-09 23:36:06.551900: train_loss -0.8151
2024-05-09 23:36:06.553279: val_loss -0.5238
2024-05-09 23:36:06.554513: Pseudo dice [0.676]
2024-05-09 23:36:06.555805: Epoch time: 242.11 s
2024-05-09 23:36:08.200997: 
2024-05-09 23:36:08.202693: Epoch 142
2024-05-09 23:36:08.203853: Current learning rate: 0.00871
2024-05-09 23:40:09.625426: Validation loss improved from -0.61390 to -0.62667! Patience: 9/50
2024-05-09 23:40:09.626866: train_loss -0.8167
2024-05-09 23:40:09.627956: val_loss -0.6267
2024-05-09 23:40:09.629007: Pseudo dice [0.7366]
2024-05-09 23:40:09.629971: Epoch time: 241.43 s
2024-05-09 23:40:11.049008: 
2024-05-09 23:40:11.050897: Epoch 143
2024-05-09 23:40:11.051971: Current learning rate: 0.0087
2024-05-09 23:44:13.787530: Validation loss did not improve from -0.62667. Patience: 1/50
2024-05-09 23:44:13.789119: train_loss -0.8223
2024-05-09 23:44:13.790594: val_loss -0.5692
2024-05-09 23:44:13.791902: Pseudo dice [0.7081]
2024-05-09 23:44:13.793297: Epoch time: 242.74 s
2024-05-09 23:44:15.258100: 
2024-05-09 23:44:15.260180: Epoch 144
2024-05-09 23:44:15.261338: Current learning rate: 0.00869
2024-05-09 23:48:23.363714: Validation loss did not improve from -0.62667. Patience: 2/50
2024-05-09 23:48:23.365067: train_loss -0.8236
2024-05-09 23:48:23.366429: val_loss -0.5898
2024-05-09 23:48:23.367496: Pseudo dice [0.7286]
2024-05-09 23:48:23.368688: Epoch time: 248.11 s
2024-05-09 23:48:25.218908: 
2024-05-09 23:48:25.220759: Epoch 145
2024-05-09 23:48:25.222177: Current learning rate: 0.00868
2024-05-09 23:52:24.348271: Validation loss did not improve from -0.62667. Patience: 3/50
2024-05-09 23:52:24.349664: train_loss -0.8251
2024-05-09 23:52:24.350705: val_loss -0.5875
2024-05-09 23:52:24.351794: Pseudo dice [0.724]
2024-05-09 23:52:24.352906: Epoch time: 239.13 s
2024-05-09 23:52:24.353796: Yayy! New best EMA pseudo Dice: 0.7119
2024-05-09 23:52:26.527005: 
2024-05-09 23:52:26.528605: Epoch 146
2024-05-09 23:52:26.529592: Current learning rate: 0.00868
2024-05-09 23:56:27.570290: Validation loss did not improve from -0.62667. Patience: 4/50
2024-05-09 23:56:27.571568: train_loss -0.8256
2024-05-09 23:56:27.573204: val_loss -0.5731
2024-05-09 23:56:27.574337: Pseudo dice [0.7193]
2024-05-09 23:56:27.575423: Epoch time: 241.05 s
2024-05-09 23:56:27.576827: Yayy! New best EMA pseudo Dice: 0.7126
2024-05-09 23:56:29.455508: 
2024-05-09 23:56:29.457344: Epoch 147
2024-05-09 23:56:29.458390: Current learning rate: 0.00867
2024-05-10 00:00:32.694436: Validation loss did not improve from -0.62667. Patience: 5/50
2024-05-10 00:00:32.696062: train_loss -0.8284
2024-05-10 00:00:32.697126: val_loss -0.6088
2024-05-10 00:00:32.698124: Pseudo dice [0.7304]
2024-05-10 00:00:32.699222: Epoch time: 243.24 s
2024-05-10 00:00:32.700246: Yayy! New best EMA pseudo Dice: 0.7144
2024-05-10 00:00:34.502771: 
2024-05-10 00:00:34.504385: Epoch 148
2024-05-10 00:00:34.505551: Current learning rate: 0.00866
2024-05-10 00:04:35.965332: Validation loss did not improve from -0.62667. Patience: 6/50
2024-05-10 00:04:35.967469: train_loss -0.8243
2024-05-10 00:04:35.968634: val_loss -0.5622
2024-05-10 00:04:35.969639: Pseudo dice [0.6977]
2024-05-10 00:04:35.970750: Epoch time: 241.47 s
2024-05-10 00:04:37.423480: 
2024-05-10 00:04:37.424723: Epoch 149
2024-05-10 00:04:37.425757: Current learning rate: 0.00865
2024-05-10 00:08:40.334004: Validation loss did not improve from -0.62667. Patience: 7/50
2024-05-10 00:08:40.335312: train_loss -0.8144
2024-05-10 00:08:40.336605: val_loss -0.528
2024-05-10 00:08:40.337594: Pseudo dice [0.6887]
2024-05-10 00:08:40.338632: Epoch time: 242.91 s
2024-05-10 00:08:42.332286: 
2024-05-10 00:08:42.333802: Epoch 150
2024-05-10 00:08:42.335127: Current learning rate: 0.00864
2024-05-10 00:12:47.610362: Validation loss did not improve from -0.62667. Patience: 8/50
2024-05-10 00:12:47.611708: train_loss -0.8206
2024-05-10 00:12:47.612736: val_loss -0.5268
2024-05-10 00:12:47.613812: Pseudo dice [0.6819]
2024-05-10 00:12:47.614785: Epoch time: 245.28 s
2024-05-10 00:12:49.042984: 
2024-05-10 00:12:49.044287: Epoch 151
2024-05-10 00:12:49.045183: Current learning rate: 0.00863
2024-05-10 00:16:53.921645: Validation loss did not improve from -0.62667. Patience: 9/50
2024-05-10 00:16:53.922787: train_loss -0.8259
2024-05-10 00:16:53.923893: val_loss -0.6128
2024-05-10 00:16:53.924916: Pseudo dice [0.7303]
2024-05-10 00:16:53.926001: Epoch time: 244.88 s
2024-05-10 00:16:55.348003: 
2024-05-10 00:16:55.349580: Epoch 152
2024-05-10 00:16:55.350681: Current learning rate: 0.00862
2024-05-10 00:20:50.386901: Validation loss did not improve from -0.62667. Patience: 10/50
2024-05-10 00:20:50.388684: train_loss -0.827
2024-05-10 00:20:50.389934: val_loss -0.5476
2024-05-10 00:20:50.390920: Pseudo dice [0.6901]
2024-05-10 00:20:50.391874: Epoch time: 235.04 s
2024-05-10 00:20:51.808666: 
2024-05-10 00:20:51.810184: Epoch 153
2024-05-10 00:20:51.811351: Current learning rate: 0.00861
2024-05-10 00:24:49.161797: Validation loss did not improve from -0.62667. Patience: 11/50
2024-05-10 00:24:49.163374: train_loss -0.8321
2024-05-10 00:24:49.164748: val_loss -0.5816
2024-05-10 00:24:49.165943: Pseudo dice [0.7108]
2024-05-10 00:24:49.167312: Epoch time: 237.36 s
2024-05-10 00:24:50.530977: 
2024-05-10 00:24:50.532413: Epoch 154
2024-05-10 00:24:50.533698: Current learning rate: 0.0086
2024-05-10 00:28:48.376465: Validation loss did not improve from -0.62667. Patience: 12/50
2024-05-10 00:28:48.377785: train_loss -0.8327
2024-05-10 00:28:48.378893: val_loss -0.6012
2024-05-10 00:28:48.379855: Pseudo dice [0.7293]
2024-05-10 00:28:48.380892: Epoch time: 237.85 s
2024-05-10 00:28:50.204722: 
2024-05-10 00:28:50.206280: Epoch 155
2024-05-10 00:28:50.207396: Current learning rate: 0.00859
2024-05-10 00:32:51.443619: Validation loss did not improve from -0.62667. Patience: 13/50
2024-05-10 00:32:51.445002: train_loss -0.8331
2024-05-10 00:32:51.446337: val_loss -0.581
2024-05-10 00:32:51.447564: Pseudo dice [0.707]
2024-05-10 00:32:51.448904: Epoch time: 241.24 s
2024-05-10 00:32:53.562747: 
2024-05-10 00:32:53.564305: Epoch 156
2024-05-10 00:32:53.565674: Current learning rate: 0.00858
2024-05-10 00:36:54.663180: Validation loss did not improve from -0.62667. Patience: 14/50
2024-05-10 00:36:54.664431: train_loss -0.8337
2024-05-10 00:36:54.666449: val_loss -0.5668
2024-05-10 00:36:54.667514: Pseudo dice [0.7033]
2024-05-10 00:36:54.668854: Epoch time: 241.1 s
2024-05-10 00:36:56.144938: 
2024-05-10 00:36:56.146812: Epoch 157
2024-05-10 00:36:56.148064: Current learning rate: 0.00858
2024-05-10 00:40:56.625085: Validation loss did not improve from -0.62667. Patience: 15/50
2024-05-10 00:40:56.627240: train_loss -0.8291
2024-05-10 00:40:56.628343: val_loss -0.6185
2024-05-10 00:40:56.629674: Pseudo dice [0.7345]
2024-05-10 00:40:56.630852: Epoch time: 240.48 s
2024-05-10 00:40:58.080608: 
2024-05-10 00:40:58.081949: Epoch 158
2024-05-10 00:40:58.083055: Current learning rate: 0.00857
2024-05-10 00:45:02.645709: Validation loss did not improve from -0.62667. Patience: 16/50
2024-05-10 00:45:02.647105: train_loss -0.8295
2024-05-10 00:45:02.648520: val_loss -0.5715
2024-05-10 00:45:02.649518: Pseudo dice [0.7036]
2024-05-10 00:45:02.650669: Epoch time: 244.57 s
2024-05-10 00:45:04.103121: 
2024-05-10 00:45:04.104696: Epoch 159
2024-05-10 00:45:04.105738: Current learning rate: 0.00856
2024-05-10 00:49:02.827631: Validation loss did not improve from -0.62667. Patience: 17/50
2024-05-10 00:49:02.828934: train_loss -0.8303
2024-05-10 00:49:02.830238: val_loss -0.6094
2024-05-10 00:49:02.831135: Pseudo dice [0.7372]
2024-05-10 00:49:02.832061: Epoch time: 238.73 s
2024-05-10 00:49:04.722480: 
2024-05-10 00:49:04.723752: Epoch 160
2024-05-10 00:49:04.724674: Current learning rate: 0.00855
2024-05-10 00:53:04.220834: Validation loss did not improve from -0.62667. Patience: 18/50
2024-05-10 00:53:04.221946: train_loss -0.8292
2024-05-10 00:53:04.223376: val_loss -0.582
2024-05-10 00:53:04.224591: Pseudo dice [0.7149]
2024-05-10 00:53:04.225680: Epoch time: 239.5 s
2024-05-10 00:53:05.654958: 
2024-05-10 00:53:05.656275: Epoch 161
2024-05-10 00:53:05.657307: Current learning rate: 0.00854
2024-05-10 00:57:04.649446: Validation loss did not improve from -0.62667. Patience: 19/50
2024-05-10 00:57:04.650681: train_loss -0.8312
2024-05-10 00:57:04.651624: val_loss -0.5729
2024-05-10 00:57:04.652492: Pseudo dice [0.701]
2024-05-10 00:57:04.653405: Epoch time: 239.0 s
2024-05-10 00:57:06.111620: 
2024-05-10 00:57:06.112734: Epoch 162
2024-05-10 00:57:06.113663: Current learning rate: 0.00853
2024-05-10 01:01:09.558742: Validation loss did not improve from -0.62667. Patience: 20/50
2024-05-10 01:01:09.559838: train_loss -0.8359
2024-05-10 01:01:09.560839: val_loss -0.5774
2024-05-10 01:01:09.563217: Pseudo dice [0.7202]
2024-05-10 01:01:09.564251: Epoch time: 243.45 s
2024-05-10 01:01:11.064323: 
2024-05-10 01:01:11.065522: Epoch 163
2024-05-10 01:01:11.066750: Current learning rate: 0.00852
2024-05-10 01:05:08.762539: Validation loss did not improve from -0.62667. Patience: 21/50
2024-05-10 01:05:08.763620: train_loss -0.8351
2024-05-10 01:05:08.764679: val_loss -0.6064
2024-05-10 01:05:08.765684: Pseudo dice [0.7245]
2024-05-10 01:05:08.766656: Epoch time: 237.7 s
2024-05-10 01:05:10.206248: 
2024-05-10 01:05:10.207565: Epoch 164
2024-05-10 01:05:10.208578: Current learning rate: 0.00851
2024-05-10 01:09:13.564707: Validation loss did not improve from -0.62667. Patience: 22/50
2024-05-10 01:09:13.566448: train_loss -0.8349
2024-05-10 01:09:13.567813: val_loss -0.5536
2024-05-10 01:09:13.568900: Pseudo dice [0.7047]
2024-05-10 01:09:13.570086: Epoch time: 243.36 s
2024-05-10 01:09:15.377493: 
2024-05-10 01:09:15.378810: Epoch 165
2024-05-10 01:09:15.379783: Current learning rate: 0.0085
2024-05-10 01:13:22.338812: Validation loss did not improve from -0.62667. Patience: 23/50
2024-05-10 01:13:22.340085: train_loss -0.8346
2024-05-10 01:13:22.341217: val_loss -0.5723
2024-05-10 01:13:22.342276: Pseudo dice [0.7078]
2024-05-10 01:13:22.343235: Epoch time: 246.96 s
2024-05-10 01:13:23.751978: 
2024-05-10 01:13:23.753175: Epoch 166
2024-05-10 01:13:23.754341: Current learning rate: 0.00849
2024-05-10 01:17:29.508044: Validation loss did not improve from -0.62667. Patience: 24/50
2024-05-10 01:17:29.509461: train_loss -0.8341
2024-05-10 01:17:29.510549: val_loss -0.5871
2024-05-10 01:17:29.511530: Pseudo dice [0.723]
2024-05-10 01:17:29.512629: Epoch time: 245.76 s
2024-05-10 01:17:30.916296: 
2024-05-10 01:17:30.917518: Epoch 167
2024-05-10 01:17:30.918509: Current learning rate: 0.00848
2024-05-10 01:21:34.892660: Validation loss did not improve from -0.62667. Patience: 25/50
2024-05-10 01:21:34.894070: train_loss -0.8387
2024-05-10 01:21:34.895346: val_loss -0.5883
2024-05-10 01:21:34.896492: Pseudo dice [0.7214]
2024-05-10 01:21:34.897721: Epoch time: 243.98 s
2024-05-10 01:21:34.898800: Yayy! New best EMA pseudo Dice: 0.7146
2024-05-10 01:21:37.864537: 
2024-05-10 01:21:37.866618: Epoch 168
2024-05-10 01:21:37.867778: Current learning rate: 0.00847
2024-05-10 01:25:42.574518: Validation loss did not improve from -0.62667. Patience: 26/50
2024-05-10 01:25:42.575637: train_loss -0.8385
2024-05-10 01:25:42.576607: val_loss -0.5903
2024-05-10 01:25:42.577533: Pseudo dice [0.7211]
2024-05-10 01:25:42.578458: Epoch time: 244.71 s
2024-05-10 01:25:42.579423: Yayy! New best EMA pseudo Dice: 0.7152
2024-05-10 01:25:44.390751: 
2024-05-10 01:25:44.392537: Epoch 169
2024-05-10 01:25:44.393519: Current learning rate: 0.00847
2024-05-10 01:29:41.289995: Validation loss did not improve from -0.62667. Patience: 27/50
2024-05-10 01:29:41.292227: train_loss -0.8335
2024-05-10 01:29:41.293701: val_loss -0.6052
2024-05-10 01:29:41.294932: Pseudo dice [0.7359]
2024-05-10 01:29:41.296327: Epoch time: 236.9 s
2024-05-10 01:29:41.781204: Yayy! New best EMA pseudo Dice: 0.7173
2024-05-10 01:29:43.663821: 
2024-05-10 01:29:43.665746: Epoch 170
2024-05-10 01:29:43.667008: Current learning rate: 0.00846
2024-05-10 01:33:39.946794: Validation loss did not improve from -0.62667. Patience: 28/50
2024-05-10 01:33:39.948615: train_loss -0.8319
2024-05-10 01:33:39.950212: val_loss -0.5643
2024-05-10 01:33:39.951331: Pseudo dice [0.7037]
2024-05-10 01:33:39.952449: Epoch time: 236.29 s
2024-05-10 01:33:41.270296: 
2024-05-10 01:33:41.272588: Epoch 171
2024-05-10 01:33:41.274087: Current learning rate: 0.00845
2024-05-10 01:37:39.794441: Validation loss did not improve from -0.62667. Patience: 29/50
2024-05-10 01:37:39.795738: train_loss -0.8335
2024-05-10 01:37:39.796852: val_loss -0.5888
2024-05-10 01:37:39.797822: Pseudo dice [0.715]
2024-05-10 01:37:39.798782: Epoch time: 238.53 s
2024-05-10 01:37:41.148532: 
2024-05-10 01:37:41.150547: Epoch 172
2024-05-10 01:37:41.152119: Current learning rate: 0.00844
2024-05-10 01:41:42.230983: Validation loss did not improve from -0.62667. Patience: 30/50
2024-05-10 01:41:42.233318: train_loss -0.8213
2024-05-10 01:41:42.235250: val_loss -0.5521
2024-05-10 01:41:42.236935: Pseudo dice [0.701]
2024-05-10 01:41:42.238398: Epoch time: 241.09 s
2024-05-10 01:41:43.646174: 
2024-05-10 01:41:43.648052: Epoch 173
2024-05-10 01:41:43.649103: Current learning rate: 0.00843
2024-05-10 01:45:44.352225: Validation loss did not improve from -0.62667. Patience: 31/50
2024-05-10 01:45:44.353925: train_loss -0.8294
2024-05-10 01:45:44.355208: val_loss -0.5886
2024-05-10 01:45:44.357051: Pseudo dice [0.7122]
2024-05-10 01:45:44.358666: Epoch time: 240.71 s
2024-05-10 01:45:45.735074: 
2024-05-10 01:45:45.736994: Epoch 174
2024-05-10 01:45:45.738403: Current learning rate: 0.00842
2024-05-10 01:49:48.026574: Validation loss did not improve from -0.62667. Patience: 32/50
2024-05-10 01:49:48.028593: train_loss -0.8324
2024-05-10 01:49:48.029630: val_loss -0.5897
2024-05-10 01:49:48.030879: Pseudo dice [0.7198]
2024-05-10 01:49:48.031837: Epoch time: 242.29 s
2024-05-10 01:49:49.950404: 
2024-05-10 01:49:49.952149: Epoch 175
2024-05-10 01:49:49.953126: Current learning rate: 0.00841
2024-05-10 01:53:48.859433: Validation loss did not improve from -0.62667. Patience: 33/50
2024-05-10 01:53:48.860605: train_loss -0.8402
2024-05-10 01:53:48.861709: val_loss -0.616
2024-05-10 01:53:48.862650: Pseudo dice [0.7359]
2024-05-10 01:53:48.863717: Epoch time: 238.91 s
2024-05-10 01:53:50.292715: 
2024-05-10 01:53:50.294603: Epoch 176
2024-05-10 01:53:50.295553: Current learning rate: 0.0084
2024-05-10 01:57:50.493196: Validation loss did not improve from -0.62667. Patience: 34/50
2024-05-10 01:57:50.494463: train_loss -0.838
2024-05-10 01:57:50.495645: val_loss -0.5872
2024-05-10 01:57:50.497071: Pseudo dice [0.7187]
2024-05-10 01:57:50.498430: Epoch time: 240.2 s
2024-05-10 01:57:51.923076: 
2024-05-10 01:57:51.924847: Epoch 177
2024-05-10 01:57:51.925921: Current learning rate: 0.00839
2024-05-10 02:01:50.964811: Validation loss did not improve from -0.62667. Patience: 35/50
2024-05-10 02:01:50.966420: train_loss -0.8365
2024-05-10 02:01:50.967646: val_loss -0.5922
2024-05-10 02:01:50.968668: Pseudo dice [0.7227]
2024-05-10 02:01:50.969694: Epoch time: 239.04 s
2024-05-10 02:01:50.970545: Yayy! New best EMA pseudo Dice: 0.7176
2024-05-10 02:01:52.717871: 
2024-05-10 02:01:52.719909: Epoch 178
2024-05-10 02:01:52.720809: Current learning rate: 0.00838
2024-05-10 02:05:56.104574: Validation loss did not improve from -0.62667. Patience: 36/50
2024-05-10 02:05:56.105904: train_loss -0.8356
2024-05-10 02:05:56.107048: val_loss -0.5845
2024-05-10 02:05:56.108150: Pseudo dice [0.7233]
2024-05-10 02:05:56.109262: Epoch time: 243.39 s
2024-05-10 02:05:56.110251: Yayy! New best EMA pseudo Dice: 0.7182
2024-05-10 02:05:58.560540: 
2024-05-10 02:05:58.562353: Epoch 179
2024-05-10 02:05:58.563534: Current learning rate: 0.00837
2024-05-10 02:10:02.445768: Validation loss did not improve from -0.62667. Patience: 37/50
2024-05-10 02:10:02.447002: train_loss -0.8375
2024-05-10 02:10:02.448105: val_loss -0.608
2024-05-10 02:10:02.449205: Pseudo dice [0.7334]
2024-05-10 02:10:02.450221: Epoch time: 243.89 s
2024-05-10 02:10:02.838511: Yayy! New best EMA pseudo Dice: 0.7197
2024-05-10 02:10:04.633848: 
2024-05-10 02:10:04.635346: Epoch 180
2024-05-10 02:10:04.636240: Current learning rate: 0.00836
2024-05-10 02:14:06.002147: Validation loss did not improve from -0.62667. Patience: 38/50
2024-05-10 02:14:06.003714: train_loss -0.8421
2024-05-10 02:14:06.005183: val_loss -0.5889
2024-05-10 02:14:06.006250: Pseudo dice [0.7203]
2024-05-10 02:14:06.007195: Epoch time: 241.37 s
2024-05-10 02:14:06.008241: Yayy! New best EMA pseudo Dice: 0.7198
2024-05-10 02:14:07.841268: 
2024-05-10 02:14:07.842986: Epoch 181
2024-05-10 02:14:07.844178: Current learning rate: 0.00836
2024-05-10 02:18:07.215364: Validation loss did not improve from -0.62667. Patience: 39/50
2024-05-10 02:18:07.217005: train_loss -0.8412
2024-05-10 02:18:07.218472: val_loss -0.5657
2024-05-10 02:18:07.219631: Pseudo dice [0.704]
2024-05-10 02:18:07.220772: Epoch time: 239.38 s
2024-05-10 02:18:08.678178: 
2024-05-10 02:18:08.680004: Epoch 182
2024-05-10 02:18:08.681431: Current learning rate: 0.00835
2024-05-10 02:22:11.680643: Validation loss did not improve from -0.62667. Patience: 40/50
2024-05-10 02:22:11.681768: train_loss -0.8407
2024-05-10 02:22:11.682976: val_loss -0.575
2024-05-10 02:22:11.684087: Pseudo dice [0.7081]
2024-05-10 02:22:11.685157: Epoch time: 243.0 s
2024-05-10 02:22:13.135191: 
2024-05-10 02:22:13.137171: Epoch 183
2024-05-10 02:22:13.138280: Current learning rate: 0.00834
2024-05-10 02:26:14.840857: Validation loss did not improve from -0.62667. Patience: 41/50
2024-05-10 02:26:14.842000: train_loss -0.8328
2024-05-10 02:26:14.843095: val_loss -0.5811
2024-05-10 02:26:14.844042: Pseudo dice [0.7159]
2024-05-10 02:26:14.845046: Epoch time: 241.71 s
2024-05-10 02:26:16.277011: 
2024-05-10 02:26:16.278547: Epoch 184
2024-05-10 02:26:16.279520: Current learning rate: 0.00833
2024-05-10 02:30:15.446872: Validation loss did not improve from -0.62667. Patience: 42/50
2024-05-10 02:30:15.447986: train_loss -0.8273
2024-05-10 02:30:15.449138: val_loss -0.599
2024-05-10 02:30:15.450204: Pseudo dice [0.7164]
2024-05-10 02:30:15.451155: Epoch time: 239.17 s
2024-05-10 02:30:17.312410: 
2024-05-10 02:30:17.314264: Epoch 185
2024-05-10 02:30:17.315333: Current learning rate: 0.00832
2024-05-10 02:34:15.579783: Validation loss did not improve from -0.62667. Patience: 43/50
2024-05-10 02:34:15.581027: train_loss -0.8303
2024-05-10 02:34:15.582168: val_loss -0.5596
2024-05-10 02:34:15.583139: Pseudo dice [0.7059]
2024-05-10 02:34:15.584077: Epoch time: 238.27 s
2024-05-10 02:34:17.008606: 
2024-05-10 02:34:17.010509: Epoch 186
2024-05-10 02:34:17.011723: Current learning rate: 0.00831
2024-05-10 02:38:20.382954: Validation loss did not improve from -0.62667. Patience: 44/50
2024-05-10 02:38:20.384481: train_loss -0.8393
2024-05-10 02:38:20.385673: val_loss -0.6128
2024-05-10 02:38:20.386951: Pseudo dice [0.7385]
2024-05-10 02:38:20.388026: Epoch time: 243.38 s
2024-05-10 02:38:21.798577: 
2024-05-10 02:38:21.800089: Epoch 187
2024-05-10 02:38:21.801191: Current learning rate: 0.0083
2024-05-10 02:42:16.694405: Validation loss did not improve from -0.62667. Patience: 45/50
2024-05-10 02:42:16.695825: train_loss -0.8436
2024-05-10 02:42:16.697250: val_loss -0.6198
2024-05-10 02:42:16.698501: Pseudo dice [0.7401]
2024-05-10 02:42:16.699807: Epoch time: 234.9 s
2024-05-10 02:42:16.700868: Yayy! New best EMA pseudo Dice: 0.7203
2024-05-10 02:42:18.519952: 
2024-05-10 02:42:18.522149: Epoch 188
2024-05-10 02:42:18.523247: Current learning rate: 0.00829
2024-05-10 02:46:15.366302: Validation loss did not improve from -0.62667. Patience: 46/50
2024-05-10 02:46:15.367376: train_loss -0.8404
2024-05-10 02:46:15.369025: val_loss -0.6045
2024-05-10 02:46:15.370102: Pseudo dice [0.7356]
2024-05-10 02:46:15.371124: Epoch time: 236.85 s
2024-05-10 02:46:15.372064: Yayy! New best EMA pseudo Dice: 0.7219
2024-05-10 02:46:18.718569: 
2024-05-10 02:46:18.720575: Epoch 189
2024-05-10 02:46:18.721787: Current learning rate: 0.00828
2024-05-10 02:50:23.661707: Validation loss did not improve from -0.62667. Patience: 47/50
2024-05-10 02:50:23.663766: train_loss -0.842
2024-05-10 02:50:23.664809: val_loss -0.6053
2024-05-10 02:50:23.665754: Pseudo dice [0.7334]
2024-05-10 02:50:23.666710: Epoch time: 244.95 s
2024-05-10 02:50:24.084596: Yayy! New best EMA pseudo Dice: 0.723
2024-05-10 02:50:25.962105: 
2024-05-10 02:50:25.964609: Epoch 190
2024-05-10 02:50:25.965642: Current learning rate: 0.00827
2024-05-10 02:54:26.865473: Validation loss did not improve from -0.62667. Patience: 48/50
2024-05-10 02:54:26.867787: train_loss -0.8406
2024-05-10 02:54:26.869086: val_loss -0.5559
2024-05-10 02:54:26.870357: Pseudo dice [0.6945]
2024-05-10 02:54:26.871544: Epoch time: 240.91 s
2024-05-10 02:54:28.317878: 
2024-05-10 02:54:28.320476: Epoch 191
2024-05-10 02:54:28.321897: Current learning rate: 0.00826
2024-05-10 02:58:32.130619: Validation loss did not improve from -0.62667. Patience: 49/50
2024-05-10 02:58:32.131766: train_loss -0.8406
2024-05-10 02:58:32.132765: val_loss -0.5823
2024-05-10 02:58:32.133804: Pseudo dice [0.718]
2024-05-10 02:58:32.134725: Epoch time: 243.82 s
2024-05-10 02:58:33.618124: 
2024-05-10 02:58:33.619884: Epoch 192
2024-05-10 02:58:33.621118: Current learning rate: 0.00825
2024-05-10 03:02:39.454268: Validation loss did not improve from -0.62667. Patience: 50/50
2024-05-10 03:02:39.455436: train_loss -0.8396
2024-05-10 03:02:39.456597: val_loss -0.5803
2024-05-10 03:02:39.457616: Pseudo dice [0.7131]
2024-05-10 03:02:39.458606: Epoch time: 245.84 s
2024-05-10 03:02:40.909106: Patience reached. Stopping training.
2024-05-10 03:02:41.417183: Training done.
2024-05-10 03:02:42.018772: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset302_Calcium_OCTv2/splits_final.json
2024-05-10 03:02:42.025863: The split file contains 3 splits.
2024-05-10 03:02:42.027051: Desired fold for training: 0
2024-05-10 03:02:42.028174: This split has 4 training and 2 validation cases.
2024-05-10 03:02:42.029329: predicting 101-019
2024-05-10 03:02:42.146888: 101-019, shape torch.Size([1, 375, 498, 498]), rank 0
2024-05-10 03:03:51.992865: predicting 704-003
2024-05-10 03:03:52.008708: 704-003, shape torch.Size([1, 375, 498, 498]), rank 0
2024-05-10 03:06:05.962448: Validation complete
2024-05-10 03:06:05.963995: Mean Validation Dice:  0.7077061870131518
wandb: 
wandb: Run history:
wandb:            ema_fg_dice ▁▂▂▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████████
wandb:   epoch_end_timestamps ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███
wandb: epoch_start_timestamps ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███
wandb:                    lrs ███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:           mean_fg_dice ▁▂▄▅▅▆▆▆▆▇▆▆▇▇▆▇█▇▇▆▇▆█▇█▇▇█▇▆██▇▇▇▇█▇▇█
wandb:           train_losses █▇▆▅▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_losses █▇▅▄▄▃▃▃▂▂▃▃▂▂▂▂▁▃▂▃▁▃▂▂▁▂▂▂▂▃▁▁▂▂▂▂▁▂▂▁
wandb: 
wandb: Run summary:
wandb:            ema_fg_dice 0.71926
wandb:   epoch_end_timestamps 1715324559.45529
wandb: epoch_start_timestamps 1715324313.61649
wandb:                    lrs 0.00825
wandb:           mean_fg_dice 0.71313
wandb:           train_losses -0.83962
wandb:             val_losses -0.58025
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset302_Calcium_OCTv2/nnUNetTrainer__nnUNetPlans__3d_32x512x512_b2/fold_0/wandb/offline-run-20240509_134506-0bhztrkg
wandb: Find logs at: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset302_Calcium_OCTv2/nnUNetTrainer__nnUNetPlans__3d_32x512x512_b2/fold_0/wandb/offline-run-20240509_134506-0bhztrkg/logs
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f5bcb4efe80>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f5bfb4651f0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f5b4776a370>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f5bc8c2eeb0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f5bf3c82610>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f5bfde27160>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
FOLD 0 CONFIG 3d_32x512x512_b2 TRAINER nnUNetTrainer

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 2 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 2 cases that I would like to predict

Predicting 101-045:
perform_everything_on_device: True
  0%|          | 0/23 [00:00<?, ?it/s]  4%|▍         | 1/23 [00:44<16:17, 44.44s/it]  9%|▊         | 2/23 [00:45<06:42, 19.17s/it] 13%|█▎        | 3/23 [00:47<03:41, 11.09s/it] 17%|█▋        | 4/23 [00:48<02:18,  7.29s/it] 22%|██▏       | 5/23 [00:50<01:33,  5.20s/it] 26%|██▌       | 6/23 [00:51<01:06,  3.93s/it] 30%|███       | 7/23 [00:53<00:50,  3.13s/it] 35%|███▍      | 8/23 [00:54<00:39,  2.60s/it] 39%|███▉      | 9/23 [00:56<00:31,  2.25s/it] 43%|████▎     | 10/23 [00:57<00:26,  2.01s/it] 48%|████▊     | 11/23 [00:59<00:22,  1.85s/it] 52%|█████▏    | 12/23 [01:00<00:19,  1.74s/it] 57%|█████▋    | 13/23 [01:02<00:16,  1.66s/it] 61%|██████    | 14/23 [01:03<00:14,  1.60s/it] 65%|██████▌   | 15/23 [01:05<00:12,  1.57s/it] 70%|██████▉   | 16/23 [01:06<00:10,  1.54s/it] 74%|███████▍  | 17/23 [01:08<00:09,  1.52s/it] 78%|███████▊  | 18/23 [01:09<00:07,  1.51s/it] 83%|████████▎ | 19/23 [01:11<00:06,  1.50s/it] 87%|████████▋ | 20/23 [01:12<00:04,  1.50s/it] 91%|█████████▏| 21/23 [01:13<00:02,  1.49s/it] 96%|█████████▌| 22/23 [01:15<00:01,  1.49s/it]100%|██████████| 23/23 [01:16<00:00,  1.49s/it]100%|██████████| 23/23 [01:16<00:00,  3.35s/it]
sending off prediction to background worker for resampling and export
done with 101-045

Predicting 706-005:
perform_everything_on_device: True
  0%|          | 0/23 [00:00<?, ?it/s]  4%|▍         | 1/23 [00:00<00:17,  1.26it/s]  9%|▊         | 2/23 [00:02<00:25,  1.20s/it] 13%|█▎        | 3/23 [00:03<00:26,  1.33s/it] 17%|█▋        | 4/23 [00:05<00:26,  1.39s/it] 22%|██▏       | 5/23 [00:06<00:25,  1.42s/it] 26%|██▌       | 6/23 [00:08<00:24,  1.45s/it] 30%|███       | 7/23 [00:09<00:23,  1.46s/it] 35%|███▍      | 8/23 [00:11<00:22,  1.47s/it] 39%|███▉      | 9/23 [00:12<00:20,  1.47s/it] 43%|████▎     | 10/23 [00:14<00:19,  1.48s/it] 48%|████▊     | 11/23 [00:15<00:17,  1.48s/it] 52%|█████▏    | 12/23 [00:17<00:16,  1.48s/it] 57%|█████▋    | 13/23 [00:18<00:14,  1.48s/it] 61%|██████    | 14/23 [00:20<00:13,  1.49s/it] 65%|██████▌   | 15/23 [00:21<00:11,  1.48s/it] 70%|██████▉   | 16/23 [00:23<00:10,  1.49s/it] 74%|███████▍  | 17/23 [00:24<00:08,  1.49s/it] 78%|███████▊  | 18/23 [00:26<00:07,  1.49s/it] 83%|████████▎ | 19/23 [00:27<00:05,  1.49s/it] 87%|████████▋ | 20/23 [00:29<00:04,  1.49s/it] 91%|█████████▏| 21/23 [00:30<00:02,  1.49s/it] 96%|█████████▌| 22/23 [00:32<00:01,  1.49s/it]100%|██████████| 23/23 [00:33<00:00,  1.49s/it]100%|██████████| 23/23 [00:33<00:00,  1.46s/it]
sending off prediction to background worker for resampling and export
done with 706-005
Completed FOLD 0 CONFIG 3d_32x512x512_b2 TRAINER nnUNetTrainer
