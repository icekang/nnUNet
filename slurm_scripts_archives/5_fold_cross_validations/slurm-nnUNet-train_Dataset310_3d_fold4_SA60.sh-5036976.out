/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/bin/python
Starting training with CONFIG=3d_32x160x128_b10, DATASET_ID=310, TRAINER=nnUNetTrainerScaleAnalysis60
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:169: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2025-10-06 03:16:37.198215: do_dummy_2d_data_aug: True
2025-10-06 03:16:37.198593: Using splits from existing split file: /nfs/erelab001/shared/Computational_Group/Naravich/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset310_nnInteractive_Calcium_OCT_CrossValidation/splits_final_60.json
2025-10-06 03:16:37.198917: The split file contains 5 splits.
2025-10-06 03:16:37.199032: Desired fold for training: 4
2025-10-06 03:16:37.199131: This split has 4 training and 4 validation cases.
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
using pin_memory on device 0
using pin_memory on device 0
2025-10-06 03:16:42.048862: Using torch.compile...

This is the configuration used by this training:
Configuration name: 3d_32x160x128_b10
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 10, 'patch_size': [32, 160, 128], 'median_image_size_in_voxels': [375.0, 498.0, 498.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'inherits_from': '3d_fullres'} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset310_nnInteractive_Calcium_OCT_CrossValidation', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.4977976381778717, 'mean': 0.1394134759902954, 'median': 0.09849607944488525, 'min': 0.0, 'percentile_00_5': 0.015305490233004093, 'percentile_99_5': 0.4977976381778717, 'std': 0.121165432035923}}} 

2025-10-06 03:16:43.525491: unpacking dataset...
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:7095: UserWarning: 
Online softmax is disabled on the fly since Inductor decides to
split the reduction. Cut an issue to PyTorch if this is an
important use case and you want to speed it up with online
softmax.

  warnings.warn(
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:7095: UserWarning: 
Online softmax is disabled on the fly since Inductor decides to
split the reduction. Cut an issue to PyTorch if this is an
important use case and you want to speed it up with online
softmax.

  warnings.warn(
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:7095: UserWarning: 
Online softmax is disabled on the fly since Inductor decides to
split the reduction. Cut an issue to PyTorch if this is an
important use case and you want to speed it up with online
softmax.

  warnings.warn(
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:7095: UserWarning: 
Online softmax is disabled on the fly since Inductor decides to
split the reduction. Cut an issue to PyTorch if this is an
important use case and you want to speed it up with online
softmax.

  warnings.warn(
2025-10-06 03:16:47.865056: unpacking done...
2025-10-06 03:16:47.867014: Unable to plot network architecture: nnUNet_compile is enabled!
2025-10-06 03:16:47.872057: 
2025-10-06 03:16:47.872277: Epoch 0
2025-10-06 03:16:47.872469: Current learning rate: 0.01
2025-10-06 03:18:09.935558: Validation loss improved from 1000.00000 to -0.16104! Patience: 0/50
2025-10-06 03:18:09.936220: train_loss -0.1253
2025-10-06 03:18:09.936428: val_loss -0.161
2025-10-06 03:18:09.936600: Pseudo dice [np.float32(0.5263)]
2025-10-06 03:18:09.936747: Epoch time: 82.06 s
2025-10-06 03:18:09.936874: Yayy! New best EMA pseudo Dice: 0.5263000130653381
2025-10-06 03:18:10.975169: 
2025-10-06 03:18:10.975497: Epoch 1
2025-10-06 03:18:10.975695: Current learning rate: 0.00994
2025-10-06 03:18:57.289474: Validation loss improved from -0.16104 to -0.21686! Patience: 0/50
2025-10-06 03:18:57.289966: train_loss -0.2665
2025-10-06 03:18:57.290156: val_loss -0.2169
2025-10-06 03:18:57.290267: Pseudo dice [np.float32(0.5527)]
2025-10-06 03:18:57.290414: Epoch time: 46.32 s
2025-10-06 03:18:57.290523: Yayy! New best EMA pseudo Dice: 0.5289999842643738
2025-10-06 03:18:58.365921: 
2025-10-06 03:18:58.366210: Epoch 2
2025-10-06 03:18:58.366399: Current learning rate: 0.00988
2025-10-06 03:19:44.757526: Validation loss did not improve from -0.21686. Patience: 1/50
2025-10-06 03:19:44.758056: train_loss -0.2976
2025-10-06 03:19:44.758247: val_loss -0.1908
2025-10-06 03:19:44.758387: Pseudo dice [np.float32(0.5406)]
2025-10-06 03:19:44.758513: Epoch time: 46.39 s
2025-10-06 03:19:44.758629: Yayy! New best EMA pseudo Dice: 0.5300999879837036
2025-10-06 03:19:45.859544: 
2025-10-06 03:19:45.859873: Epoch 3
2025-10-06 03:19:45.860111: Current learning rate: 0.00982
2025-10-06 03:20:32.301353: Validation loss improved from -0.21686 to -0.25709! Patience: 1/50
2025-10-06 03:20:32.301843: train_loss -0.3232
2025-10-06 03:20:32.301987: val_loss -0.2571
2025-10-06 03:20:32.302115: Pseudo dice [np.float32(0.5729)]
2025-10-06 03:20:32.302248: Epoch time: 46.44 s
2025-10-06 03:20:32.302361: Yayy! New best EMA pseudo Dice: 0.5343999862670898
2025-10-06 03:20:33.417398: 
2025-10-06 03:20:33.417759: Epoch 4
2025-10-06 03:20:33.417994: Current learning rate: 0.00976
2025-10-06 03:21:19.860780: Validation loss improved from -0.25709 to -0.28650! Patience: 0/50
2025-10-06 03:21:19.861286: train_loss -0.3552
2025-10-06 03:21:19.861470: val_loss -0.2865
2025-10-06 03:21:19.861589: Pseudo dice [np.float32(0.6013)]
2025-10-06 03:21:19.861754: Epoch time: 46.44 s
2025-10-06 03:21:20.243352: Yayy! New best EMA pseudo Dice: 0.541100025177002
2025-10-06 03:21:21.323889: 
2025-10-06 03:21:21.324229: Epoch 5
2025-10-06 03:21:21.324426: Current learning rate: 0.0097
2025-10-06 03:22:07.713123: Validation loss improved from -0.28650 to -0.30396! Patience: 0/50
2025-10-06 03:22:07.713569: train_loss -0.3669
2025-10-06 03:22:07.713750: val_loss -0.304
2025-10-06 03:22:07.713912: Pseudo dice [np.float32(0.6081)]
2025-10-06 03:22:07.714084: Epoch time: 46.39 s
2025-10-06 03:22:07.714255: Yayy! New best EMA pseudo Dice: 0.5478000044822693
2025-10-06 03:22:08.818201: 
2025-10-06 03:22:08.818451: Epoch 6
2025-10-06 03:22:08.818651: Current learning rate: 0.00964
2025-10-06 03:22:55.204948: Validation loss did not improve from -0.30396. Patience: 1/50
2025-10-06 03:22:55.205662: train_loss -0.3972
2025-10-06 03:22:55.205971: val_loss -0.201
2025-10-06 03:22:55.206124: Pseudo dice [np.float32(0.5826)]
2025-10-06 03:22:55.206405: Epoch time: 46.39 s
2025-10-06 03:22:55.206591: Yayy! New best EMA pseudo Dice: 0.5512999892234802
2025-10-06 03:22:56.319794: 
2025-10-06 03:22:56.320063: Epoch 7
2025-10-06 03:22:56.320385: Current learning rate: 0.00958
2025-10-06 03:23:42.763944: Validation loss improved from -0.30396 to -0.31622! Patience: 1/50
2025-10-06 03:23:42.764385: train_loss -0.4132
2025-10-06 03:23:42.764531: val_loss -0.3162
2025-10-06 03:23:42.764647: Pseudo dice [np.float32(0.5985)]
2025-10-06 03:23:42.764848: Epoch time: 46.45 s
2025-10-06 03:23:42.765084: Yayy! New best EMA pseudo Dice: 0.5559999942779541
2025-10-06 03:23:43.887785: 
2025-10-06 03:23:43.888166: Epoch 8
2025-10-06 03:23:43.888441: Current learning rate: 0.00952
2025-10-06 03:24:30.380439: Validation loss improved from -0.31622 to -0.37215! Patience: 0/50
2025-10-06 03:24:30.381130: train_loss -0.4245
2025-10-06 03:24:30.381306: val_loss -0.3722
2025-10-06 03:24:30.381454: Pseudo dice [np.float32(0.6449)]
2025-10-06 03:24:30.381613: Epoch time: 46.49 s
2025-10-06 03:24:30.381762: Yayy! New best EMA pseudo Dice: 0.5648999810218811
2025-10-06 03:24:31.492318: 
2025-10-06 03:24:31.492568: Epoch 9
2025-10-06 03:24:31.492765: Current learning rate: 0.00946
2025-10-06 03:25:18.002299: Validation loss did not improve from -0.37215. Patience: 1/50
2025-10-06 03:25:18.002832: train_loss -0.4365
2025-10-06 03:25:18.002985: val_loss -0.3583
2025-10-06 03:25:18.003129: Pseudo dice [np.float32(0.6379)]
2025-10-06 03:25:18.003287: Epoch time: 46.51 s
2025-10-06 03:25:18.429201: Yayy! New best EMA pseudo Dice: 0.5722000002861023
2025-10-06 03:25:19.502141: 
2025-10-06 03:25:19.502416: Epoch 10
2025-10-06 03:25:19.502589: Current learning rate: 0.0094
2025-10-06 03:26:05.956813: Validation loss did not improve from -0.37215. Patience: 2/50
2025-10-06 03:26:05.957601: train_loss -0.4573
2025-10-06 03:26:05.957754: val_loss -0.3224
2025-10-06 03:26:05.957894: Pseudo dice [np.float32(0.6177)]
2025-10-06 03:26:05.958033: Epoch time: 46.46 s
2025-10-06 03:26:05.958149: Yayy! New best EMA pseudo Dice: 0.5767999887466431
2025-10-06 03:26:07.057791: 
2025-10-06 03:26:07.058182: Epoch 11
2025-10-06 03:26:07.058396: Current learning rate: 0.00934
2025-10-06 03:26:53.468094: Validation loss did not improve from -0.37215. Patience: 3/50
2025-10-06 03:26:53.468630: train_loss -0.4699
2025-10-06 03:26:53.468791: val_loss -0.3652
2025-10-06 03:26:53.468943: Pseudo dice [np.float32(0.648)]
2025-10-06 03:26:53.469199: Epoch time: 46.41 s
2025-10-06 03:26:53.469343: Yayy! New best EMA pseudo Dice: 0.583899974822998
2025-10-06 03:26:54.556386: 
2025-10-06 03:26:54.556737: Epoch 12
2025-10-06 03:26:54.557021: Current learning rate: 0.00928
2025-10-06 03:27:40.918012: Validation loss did not improve from -0.37215. Patience: 4/50
2025-10-06 03:27:40.918721: train_loss -0.4569
2025-10-06 03:27:40.918900: val_loss -0.3595
2025-10-06 03:27:40.919081: Pseudo dice [np.float32(0.6363)]
2025-10-06 03:27:40.919296: Epoch time: 46.36 s
2025-10-06 03:27:40.919509: Yayy! New best EMA pseudo Dice: 0.5891000032424927
2025-10-06 03:27:42.570443: 
2025-10-06 03:27:42.570813: Epoch 13
2025-10-06 03:27:42.570994: Current learning rate: 0.00922
2025-10-06 03:28:29.061815: Validation loss improved from -0.37215 to -0.38479! Patience: 4/50
2025-10-06 03:28:29.062349: train_loss -0.4892
2025-10-06 03:28:29.062551: val_loss -0.3848
2025-10-06 03:28:29.062678: Pseudo dice [np.float32(0.6444)]
2025-10-06 03:28:29.062837: Epoch time: 46.49 s
2025-10-06 03:28:29.062979: Yayy! New best EMA pseudo Dice: 0.5946000218391418
2025-10-06 03:28:30.179998: 
2025-10-06 03:28:30.180375: Epoch 14
2025-10-06 03:28:30.180563: Current learning rate: 0.00916
2025-10-06 03:29:16.659103: Validation loss did not improve from -0.38479. Patience: 1/50
2025-10-06 03:29:16.659847: train_loss -0.4982
2025-10-06 03:29:16.660021: val_loss -0.3801
2025-10-06 03:29:16.660176: Pseudo dice [np.float32(0.6408)]
2025-10-06 03:29:16.660359: Epoch time: 46.48 s
2025-10-06 03:29:17.123108: Yayy! New best EMA pseudo Dice: 0.5993000268936157
2025-10-06 03:29:18.235375: 
2025-10-06 03:29:18.235686: Epoch 15
2025-10-06 03:29:18.235940: Current learning rate: 0.0091
2025-10-06 03:30:04.713024: Validation loss did not improve from -0.38479. Patience: 2/50
2025-10-06 03:30:04.713398: train_loss -0.5082
2025-10-06 03:30:04.713569: val_loss -0.3588
2025-10-06 03:30:04.713718: Pseudo dice [np.float32(0.6415)]
2025-10-06 03:30:04.713858: Epoch time: 46.48 s
2025-10-06 03:30:04.713985: Yayy! New best EMA pseudo Dice: 0.6035000085830688
2025-10-06 03:30:05.837938: 
2025-10-06 03:30:05.838295: Epoch 16
2025-10-06 03:30:05.838535: Current learning rate: 0.00903
2025-10-06 03:30:52.259974: Validation loss did not improve from -0.38479. Patience: 3/50
2025-10-06 03:30:52.260662: train_loss -0.5157
2025-10-06 03:30:52.260844: val_loss -0.3195
2025-10-06 03:30:52.260972: Pseudo dice [np.float32(0.5984)]
2025-10-06 03:30:52.261108: Epoch time: 46.42 s
2025-10-06 03:30:52.920079: 
2025-10-06 03:30:52.920413: Epoch 17
2025-10-06 03:30:52.920612: Current learning rate: 0.00897
2025-10-06 03:31:39.358377: Validation loss did not improve from -0.38479. Patience: 4/50
2025-10-06 03:31:39.358989: train_loss -0.5065
2025-10-06 03:31:39.359161: val_loss -0.3843
2025-10-06 03:31:39.359287: Pseudo dice [np.float32(0.6413)]
2025-10-06 03:31:39.359488: Epoch time: 46.44 s
2025-10-06 03:31:39.359627: Yayy! New best EMA pseudo Dice: 0.6068000197410583
2025-10-06 03:31:40.478787: 
2025-10-06 03:31:40.479139: Epoch 18
2025-10-06 03:31:40.479361: Current learning rate: 0.00891
2025-10-06 03:32:26.947815: Validation loss did not improve from -0.38479. Patience: 5/50
2025-10-06 03:32:26.948787: train_loss -0.5249
2025-10-06 03:32:26.949072: val_loss -0.3664
2025-10-06 03:32:26.949269: Pseudo dice [np.float32(0.6433)]
2025-10-06 03:32:26.949572: Epoch time: 46.47 s
2025-10-06 03:32:26.949795: Yayy! New best EMA pseudo Dice: 0.6104999780654907
2025-10-06 03:32:28.058489: 
2025-10-06 03:32:28.058872: Epoch 19
2025-10-06 03:32:28.059061: Current learning rate: 0.00885
2025-10-06 03:33:14.526716: Validation loss improved from -0.38479 to -0.39977! Patience: 5/50
2025-10-06 03:33:14.527448: train_loss -0.5232
2025-10-06 03:33:14.527725: val_loss -0.3998
2025-10-06 03:33:14.527902: Pseudo dice [np.float32(0.663)]
2025-10-06 03:33:14.528144: Epoch time: 46.47 s
2025-10-06 03:33:14.972705: Yayy! New best EMA pseudo Dice: 0.6157000064849854
2025-10-06 03:33:16.109069: 
2025-10-06 03:33:16.109444: Epoch 20
2025-10-06 03:33:16.109701: Current learning rate: 0.00879
2025-10-06 03:34:02.583074: Validation loss did not improve from -0.39977. Patience: 1/50
2025-10-06 03:34:02.583778: train_loss -0.5435
2025-10-06 03:34:02.583937: val_loss -0.3719
2025-10-06 03:34:02.584073: Pseudo dice [np.float32(0.6486)]
2025-10-06 03:34:02.584339: Epoch time: 46.48 s
2025-10-06 03:34:02.584497: Yayy! New best EMA pseudo Dice: 0.6190000176429749
2025-10-06 03:34:03.709561: 
2025-10-06 03:34:03.709989: Epoch 21
2025-10-06 03:34:03.710237: Current learning rate: 0.00873
2025-10-06 03:34:50.285716: Validation loss improved from -0.39977 to -0.41165! Patience: 1/50
2025-10-06 03:34:50.286248: train_loss -0.5468
2025-10-06 03:34:50.286500: val_loss -0.4117
2025-10-06 03:34:50.286702: Pseudo dice [np.float32(0.681)]
2025-10-06 03:34:50.286917: Epoch time: 46.58 s
2025-10-06 03:34:50.287134: Yayy! New best EMA pseudo Dice: 0.6251999735832214
2025-10-06 03:34:51.371669: 
2025-10-06 03:34:51.372002: Epoch 22
2025-10-06 03:34:51.372219: Current learning rate: 0.00867
2025-10-06 03:35:37.852448: Validation loss did not improve from -0.41165. Patience: 1/50
2025-10-06 03:35:37.853255: train_loss -0.551
2025-10-06 03:35:37.853481: val_loss -0.381
2025-10-06 03:35:37.853705: Pseudo dice [np.float32(0.6514)]
2025-10-06 03:35:37.853919: Epoch time: 46.48 s
2025-10-06 03:35:37.854131: Yayy! New best EMA pseudo Dice: 0.6277999877929688
2025-10-06 03:35:38.937230: 
2025-10-06 03:35:38.937595: Epoch 23
2025-10-06 03:35:38.937785: Current learning rate: 0.00861
2025-10-06 03:36:25.426091: Validation loss improved from -0.41165 to -0.42527! Patience: 1/50
2025-10-06 03:36:25.426643: train_loss -0.5561
2025-10-06 03:36:25.426879: val_loss -0.4253
2025-10-06 03:36:25.427024: Pseudo dice [np.float32(0.6722)]
2025-10-06 03:36:25.427207: Epoch time: 46.49 s
2025-10-06 03:36:25.427362: Yayy! New best EMA pseudo Dice: 0.6323000192642212
2025-10-06 03:36:26.546486: 
2025-10-06 03:36:26.546883: Epoch 24
2025-10-06 03:36:26.547158: Current learning rate: 0.00855
2025-10-06 03:37:13.110623: Validation loss did not improve from -0.42527. Patience: 1/50
2025-10-06 03:37:13.111156: train_loss -0.5563
2025-10-06 03:37:13.111403: val_loss -0.4197
2025-10-06 03:37:13.111589: Pseudo dice [np.float32(0.6836)]
2025-10-06 03:37:13.111753: Epoch time: 46.57 s
2025-10-06 03:37:13.581080: Yayy! New best EMA pseudo Dice: 0.6373999714851379
2025-10-06 03:37:14.691343: 
2025-10-06 03:37:14.691767: Epoch 25
2025-10-06 03:37:14.692039: Current learning rate: 0.00849
2025-10-06 03:38:01.151812: Validation loss did not improve from -0.42527. Patience: 2/50
2025-10-06 03:38:01.152554: train_loss -0.5503
2025-10-06 03:38:01.152812: val_loss -0.4173
2025-10-06 03:38:01.152936: Pseudo dice [np.float32(0.6617)]
2025-10-06 03:38:01.153094: Epoch time: 46.46 s
2025-10-06 03:38:01.153298: Yayy! New best EMA pseudo Dice: 0.6398000121116638
2025-10-06 03:38:02.259233: 
2025-10-06 03:38:02.259479: Epoch 26
2025-10-06 03:38:02.259650: Current learning rate: 0.00843
2025-10-06 03:38:48.741493: Validation loss improved from -0.42527 to -0.43410! Patience: 2/50
2025-10-06 03:38:48.742074: train_loss -0.5647
2025-10-06 03:38:48.742237: val_loss -0.4341
2025-10-06 03:38:48.742378: Pseudo dice [np.float32(0.6816)]
2025-10-06 03:38:48.742541: Epoch time: 46.48 s
2025-10-06 03:38:48.742731: Yayy! New best EMA pseudo Dice: 0.6439999938011169
2025-10-06 03:38:49.854166: 
2025-10-06 03:38:49.854450: Epoch 27
2025-10-06 03:38:49.854622: Current learning rate: 0.00836
2025-10-06 03:39:36.216618: Validation loss did not improve from -0.43410. Patience: 1/50
2025-10-06 03:39:36.217291: train_loss -0.5773
2025-10-06 03:39:36.217595: val_loss -0.39
2025-10-06 03:39:36.217840: Pseudo dice [np.float32(0.667)]
2025-10-06 03:39:36.218026: Epoch time: 46.36 s
2025-10-06 03:39:36.218191: Yayy! New best EMA pseudo Dice: 0.6463000178337097
2025-10-06 03:39:37.877457: 
2025-10-06 03:39:37.877746: Epoch 28
2025-10-06 03:39:37.878015: Current learning rate: 0.0083
2025-10-06 03:40:24.367440: Validation loss did not improve from -0.43410. Patience: 2/50
2025-10-06 03:40:24.368300: train_loss -0.5792
2025-10-06 03:40:24.368567: val_loss -0.3686
2025-10-06 03:40:24.368770: Pseudo dice [np.float32(0.6482)]
2025-10-06 03:40:24.368966: Epoch time: 46.49 s
2025-10-06 03:40:24.369122: Yayy! New best EMA pseudo Dice: 0.6464999914169312
2025-10-06 03:40:25.473292: 
2025-10-06 03:40:25.473670: Epoch 29
2025-10-06 03:40:25.473881: Current learning rate: 0.00824
2025-10-06 03:41:11.868125: Validation loss did not improve from -0.43410. Patience: 3/50
2025-10-06 03:41:11.868507: train_loss -0.5825
2025-10-06 03:41:11.868726: val_loss -0.4079
2025-10-06 03:41:11.868872: Pseudo dice [np.float32(0.6707)]
2025-10-06 03:41:11.869019: Epoch time: 46.4 s
2025-10-06 03:41:12.329442: Yayy! New best EMA pseudo Dice: 0.6488999724388123
2025-10-06 03:41:13.453155: 
2025-10-06 03:41:13.453423: Epoch 30
2025-10-06 03:41:13.453665: Current learning rate: 0.00818
2025-10-06 03:41:59.897142: Validation loss did not improve from -0.43410. Patience: 4/50
2025-10-06 03:41:59.897761: train_loss -0.5881
2025-10-06 03:41:59.897916: val_loss -0.3851
2025-10-06 03:41:59.898032: Pseudo dice [np.float32(0.6574)]
2025-10-06 03:41:59.898161: Epoch time: 46.45 s
2025-10-06 03:41:59.898338: Yayy! New best EMA pseudo Dice: 0.6498000025749207
2025-10-06 03:42:01.002190: 
2025-10-06 03:42:01.002530: Epoch 31
2025-10-06 03:42:01.002749: Current learning rate: 0.00812
2025-10-06 03:42:47.370190: Validation loss did not improve from -0.43410. Patience: 5/50
2025-10-06 03:42:47.370852: train_loss -0.5951
2025-10-06 03:42:47.371047: val_loss -0.4065
2025-10-06 03:42:47.371204: Pseudo dice [np.float32(0.6701)]
2025-10-06 03:42:47.371360: Epoch time: 46.37 s
2025-10-06 03:42:47.371477: Yayy! New best EMA pseudo Dice: 0.6517999768257141
2025-10-06 03:42:48.482386: 
2025-10-06 03:42:48.482630: Epoch 32
2025-10-06 03:42:48.482895: Current learning rate: 0.00806
2025-10-06 03:43:34.819798: Validation loss did not improve from -0.43410. Patience: 6/50
2025-10-06 03:43:34.820478: train_loss -0.5937
2025-10-06 03:43:34.820656: val_loss -0.4162
2025-10-06 03:43:34.820814: Pseudo dice [np.float32(0.6741)]
2025-10-06 03:43:34.820982: Epoch time: 46.34 s
2025-10-06 03:43:34.821106: Yayy! New best EMA pseudo Dice: 0.6539999842643738
2025-10-06 03:43:35.916669: 
2025-10-06 03:43:35.916995: Epoch 33
2025-10-06 03:43:35.917233: Current learning rate: 0.008
2025-10-06 03:44:22.240291: Validation loss did not improve from -0.43410. Patience: 7/50
2025-10-06 03:44:22.240864: train_loss -0.6022
2025-10-06 03:44:22.241051: val_loss -0.4233
2025-10-06 03:44:22.241195: Pseudo dice [np.float32(0.675)]
2025-10-06 03:44:22.241340: Epoch time: 46.32 s
2025-10-06 03:44:22.241445: Yayy! New best EMA pseudo Dice: 0.6560999751091003
2025-10-06 03:44:23.359885: 
2025-10-06 03:44:23.360213: Epoch 34
2025-10-06 03:44:23.360410: Current learning rate: 0.00793
2025-10-06 03:45:09.770334: Validation loss did not improve from -0.43410. Patience: 8/50
2025-10-06 03:45:09.771255: train_loss -0.6046
2025-10-06 03:45:09.771450: val_loss -0.4062
2025-10-06 03:45:09.771591: Pseudo dice [np.float32(0.6776)]
2025-10-06 03:45:09.771811: Epoch time: 46.41 s
2025-10-06 03:45:10.210605: Yayy! New best EMA pseudo Dice: 0.65829998254776
2025-10-06 03:45:11.316243: 
2025-10-06 03:45:11.316605: Epoch 35
2025-10-06 03:45:11.316826: Current learning rate: 0.00787
2025-10-06 03:45:57.780651: Validation loss did not improve from -0.43410. Patience: 9/50
2025-10-06 03:45:57.781113: train_loss -0.599
2025-10-06 03:45:57.781278: val_loss -0.4084
2025-10-06 03:45:57.781441: Pseudo dice [np.float32(0.6784)]
2025-10-06 03:45:57.781596: Epoch time: 46.47 s
2025-10-06 03:45:57.781730: Yayy! New best EMA pseudo Dice: 0.6603000164031982
2025-10-06 03:45:58.901568: 
2025-10-06 03:45:58.901877: Epoch 36
2025-10-06 03:45:58.902054: Current learning rate: 0.00781
2025-10-06 03:46:45.330217: Validation loss did not improve from -0.43410. Patience: 10/50
2025-10-06 03:46:45.330781: train_loss -0.6165
2025-10-06 03:46:45.330963: val_loss -0.4329
2025-10-06 03:46:45.331098: Pseudo dice [np.float32(0.6909)]
2025-10-06 03:46:45.331240: Epoch time: 46.43 s
2025-10-06 03:46:45.331348: Yayy! New best EMA pseudo Dice: 0.6632999777793884
2025-10-06 03:46:46.441444: 
2025-10-06 03:46:46.441697: Epoch 37
2025-10-06 03:46:46.441883: Current learning rate: 0.00775
2025-10-06 03:47:32.854990: Validation loss did not improve from -0.43410. Patience: 11/50
2025-10-06 03:47:32.855607: train_loss -0.6162
2025-10-06 03:47:32.855885: val_loss -0.4262
2025-10-06 03:47:32.856175: Pseudo dice [np.float32(0.6721)]
2025-10-06 03:47:32.856424: Epoch time: 46.41 s
2025-10-06 03:47:32.856544: Yayy! New best EMA pseudo Dice: 0.6642000079154968
2025-10-06 03:47:33.964679: 
2025-10-06 03:47:33.965039: Epoch 38
2025-10-06 03:47:33.965255: Current learning rate: 0.00769
2025-10-06 03:48:20.421950: Validation loss did not improve from -0.43410. Patience: 12/50
2025-10-06 03:48:20.422409: train_loss -0.6269
2025-10-06 03:48:20.422560: val_loss -0.4151
2025-10-06 03:48:20.422717: Pseudo dice [np.float32(0.6649)]
2025-10-06 03:48:20.422869: Epoch time: 46.46 s
2025-10-06 03:48:20.423019: Yayy! New best EMA pseudo Dice: 0.6643000245094299
2025-10-06 03:48:21.514458: 
2025-10-06 03:48:21.514760: Epoch 39
2025-10-06 03:48:21.514979: Current learning rate: 0.00763
2025-10-06 03:49:08.056896: Validation loss did not improve from -0.43410. Patience: 13/50
2025-10-06 03:49:08.057401: train_loss -0.6313
2025-10-06 03:49:08.057592: val_loss -0.4193
2025-10-06 03:49:08.057743: Pseudo dice [np.float32(0.6764)]
2025-10-06 03:49:08.057923: Epoch time: 46.54 s
2025-10-06 03:49:08.499739: Yayy! New best EMA pseudo Dice: 0.6654999852180481
2025-10-06 03:49:09.606723: 
2025-10-06 03:49:09.607043: Epoch 40
2025-10-06 03:49:09.607291: Current learning rate: 0.00756
2025-10-06 03:49:56.044385: Validation loss improved from -0.43410 to -0.44415! Patience: 13/50
2025-10-06 03:49:56.045220: train_loss -0.6318
2025-10-06 03:49:56.045471: val_loss -0.4442
2025-10-06 03:49:56.045757: Pseudo dice [np.float32(0.7027)]
2025-10-06 03:49:56.046011: Epoch time: 46.44 s
2025-10-06 03:49:56.046318: Yayy! New best EMA pseudo Dice: 0.6692000031471252
2025-10-06 03:49:57.172079: 
2025-10-06 03:49:57.172503: Epoch 41
2025-10-06 03:49:57.172791: Current learning rate: 0.0075
2025-10-06 03:50:43.562350: Validation loss improved from -0.44415 to -0.45515! Patience: 0/50
2025-10-06 03:50:43.562944: train_loss -0.6376
2025-10-06 03:50:43.563212: val_loss -0.4551
2025-10-06 03:50:43.563416: Pseudo dice [np.float32(0.6971)]
2025-10-06 03:50:43.563656: Epoch time: 46.39 s
2025-10-06 03:50:43.563852: Yayy! New best EMA pseudo Dice: 0.671999990940094
2025-10-06 03:50:44.656187: 
2025-10-06 03:50:44.656532: Epoch 42
2025-10-06 03:50:44.656697: Current learning rate: 0.00744
2025-10-06 03:51:30.997301: Validation loss did not improve from -0.45515. Patience: 1/50
2025-10-06 03:51:30.997918: train_loss -0.6462
2025-10-06 03:51:30.998063: val_loss -0.4273
2025-10-06 03:51:30.998191: Pseudo dice [np.float32(0.6874)]
2025-10-06 03:51:30.998323: Epoch time: 46.34 s
2025-10-06 03:51:30.998433: Yayy! New best EMA pseudo Dice: 0.6735000014305115
2025-10-06 03:51:32.640072: 
2025-10-06 03:51:32.640391: Epoch 43
2025-10-06 03:51:32.640568: Current learning rate: 0.00738
2025-10-06 03:52:18.974515: Validation loss did not improve from -0.45515. Patience: 2/50
2025-10-06 03:52:18.975201: train_loss -0.6426
2025-10-06 03:52:18.975418: val_loss -0.3737
2025-10-06 03:52:18.975628: Pseudo dice [np.float32(0.6474)]
2025-10-06 03:52:18.975832: Epoch time: 46.34 s
2025-10-06 03:52:19.618467: 
2025-10-06 03:52:19.618819: Epoch 44
2025-10-06 03:52:19.619040: Current learning rate: 0.00732
2025-10-06 03:53:06.195906: Validation loss did not improve from -0.45515. Patience: 3/50
2025-10-06 03:53:06.196476: train_loss -0.647
2025-10-06 03:53:06.196627: val_loss -0.4236
2025-10-06 03:53:06.196754: Pseudo dice [np.float32(0.6864)]
2025-10-06 03:53:06.196934: Epoch time: 46.58 s
2025-10-06 03:53:07.297810: 
2025-10-06 03:53:07.298080: Epoch 45
2025-10-06 03:53:07.298257: Current learning rate: 0.00725
2025-10-06 03:53:53.882406: Validation loss did not improve from -0.45515. Patience: 4/50
2025-10-06 03:53:53.882928: train_loss -0.6635
2025-10-06 03:53:53.883095: val_loss -0.4424
2025-10-06 03:53:53.883212: Pseudo dice [np.float32(0.6799)]
2025-10-06 03:53:53.883382: Epoch time: 46.59 s
2025-10-06 03:53:54.536719: 
2025-10-06 03:53:54.537119: Epoch 46
2025-10-06 03:53:54.537421: Current learning rate: 0.00719
2025-10-06 03:54:41.065767: Validation loss did not improve from -0.45515. Patience: 5/50
2025-10-06 03:54:41.066447: train_loss -0.6642
2025-10-06 03:54:41.066623: val_loss -0.4486
2025-10-06 03:54:41.066810: Pseudo dice [np.float32(0.6895)]
2025-10-06 03:54:41.066983: Epoch time: 46.53 s
2025-10-06 03:54:41.067135: Yayy! New best EMA pseudo Dice: 0.6747999787330627
2025-10-06 03:54:42.178037: 
2025-10-06 03:54:42.178315: Epoch 47
2025-10-06 03:54:42.178543: Current learning rate: 0.00713
2025-10-06 03:55:28.577062: Validation loss did not improve from -0.45515. Patience: 6/50
2025-10-06 03:55:28.577484: train_loss -0.6714
2025-10-06 03:55:28.577645: val_loss -0.4195
2025-10-06 03:55:28.577807: Pseudo dice [np.float32(0.6744)]
2025-10-06 03:55:28.578011: Epoch time: 46.4 s
2025-10-06 03:55:29.236074: 
2025-10-06 03:55:29.236348: Epoch 48
2025-10-06 03:55:29.236541: Current learning rate: 0.00707
2025-10-06 03:56:15.696562: Validation loss did not improve from -0.45515. Patience: 7/50
2025-10-06 03:56:15.697435: train_loss -0.6735
2025-10-06 03:56:15.697773: val_loss -0.4334
2025-10-06 03:56:15.697971: Pseudo dice [np.float32(0.6888)]
2025-10-06 03:56:15.698210: Epoch time: 46.46 s
2025-10-06 03:56:15.698451: Yayy! New best EMA pseudo Dice: 0.6761999726295471
2025-10-06 03:56:16.835534: 
2025-10-06 03:56:16.835920: Epoch 49
2025-10-06 03:56:16.836133: Current learning rate: 0.007
2025-10-06 03:57:03.285270: Validation loss did not improve from -0.45515. Patience: 8/50
2025-10-06 03:57:03.285912: train_loss -0.6799
2025-10-06 03:57:03.286086: val_loss -0.4218
2025-10-06 03:57:03.286268: Pseudo dice [np.float32(0.686)]
2025-10-06 03:57:03.286466: Epoch time: 46.45 s
2025-10-06 03:57:03.745260: Yayy! New best EMA pseudo Dice: 0.6772000193595886
2025-10-06 03:57:04.878634: 
2025-10-06 03:57:04.878990: Epoch 50
2025-10-06 03:57:04.879189: Current learning rate: 0.00694
2025-10-06 03:57:51.366840: Validation loss did not improve from -0.45515. Patience: 9/50
2025-10-06 03:57:51.367431: train_loss -0.6772
2025-10-06 03:57:51.367632: val_loss -0.412
2025-10-06 03:57:51.367775: Pseudo dice [np.float32(0.6812)]
2025-10-06 03:57:51.367909: Epoch time: 46.49 s
2025-10-06 03:57:51.368038: Yayy! New best EMA pseudo Dice: 0.6776000261306763
2025-10-06 03:57:52.503784: 
2025-10-06 03:57:52.504153: Epoch 51
2025-10-06 03:57:52.504338: Current learning rate: 0.00688
2025-10-06 03:58:38.937527: Validation loss did not improve from -0.45515. Patience: 10/50
2025-10-06 03:58:38.938071: train_loss -0.672
2025-10-06 03:58:38.938226: val_loss -0.4286
2025-10-06 03:58:38.938414: Pseudo dice [np.float32(0.6838)]
2025-10-06 03:58:38.938665: Epoch time: 46.43 s
2025-10-06 03:58:38.938843: Yayy! New best EMA pseudo Dice: 0.6782000064849854
2025-10-06 03:58:40.039499: 
2025-10-06 03:58:40.039818: Epoch 52
2025-10-06 03:58:40.040077: Current learning rate: 0.00682
2025-10-06 03:59:26.371481: Validation loss did not improve from -0.45515. Patience: 11/50
2025-10-06 03:59:26.372151: train_loss -0.6755
2025-10-06 03:59:26.372297: val_loss -0.4079
2025-10-06 03:59:26.372428: Pseudo dice [np.float32(0.6725)]
2025-10-06 03:59:26.372561: Epoch time: 46.33 s
2025-10-06 03:59:27.024974: 
2025-10-06 03:59:27.025321: Epoch 53
2025-10-06 03:59:27.025516: Current learning rate: 0.00675
2025-10-06 04:00:13.446611: Validation loss did not improve from -0.45515. Patience: 12/50
2025-10-06 04:00:13.447116: train_loss -0.6805
2025-10-06 04:00:13.447318: val_loss -0.4218
2025-10-06 04:00:13.447456: Pseudo dice [np.float32(0.6954)]
2025-10-06 04:00:13.447592: Epoch time: 46.42 s
2025-10-06 04:00:13.447703: Yayy! New best EMA pseudo Dice: 0.6794000267982483
2025-10-06 04:00:14.563623: 
2025-10-06 04:00:14.563957: Epoch 54
2025-10-06 04:00:14.564180: Current learning rate: 0.00669
2025-10-06 04:01:01.048754: Validation loss did not improve from -0.45515. Patience: 13/50
2025-10-06 04:01:01.049444: train_loss -0.6882
2025-10-06 04:01:01.049627: val_loss -0.4325
2025-10-06 04:01:01.049797: Pseudo dice [np.float32(0.6995)]
2025-10-06 04:01:01.049934: Epoch time: 46.49 s
2025-10-06 04:01:01.526067: Yayy! New best EMA pseudo Dice: 0.6814000010490417
2025-10-06 04:01:02.628558: 
2025-10-06 04:01:02.628965: Epoch 55
2025-10-06 04:01:02.629311: Current learning rate: 0.00663
2025-10-06 04:01:49.068269: Validation loss did not improve from -0.45515. Patience: 14/50
2025-10-06 04:01:49.068903: train_loss -0.6842
2025-10-06 04:01:49.069120: val_loss -0.4112
2025-10-06 04:01:49.069284: Pseudo dice [np.float32(0.6828)]
2025-10-06 04:01:49.069438: Epoch time: 46.44 s
2025-10-06 04:01:49.069573: Yayy! New best EMA pseudo Dice: 0.6815999746322632
2025-10-06 04:01:50.187966: 
2025-10-06 04:01:50.188287: Epoch 56
2025-10-06 04:01:50.188515: Current learning rate: 0.00657
2025-10-06 04:02:36.608571: Validation loss did not improve from -0.45515. Patience: 15/50
2025-10-06 04:02:36.609180: train_loss -0.6938
2025-10-06 04:02:36.609337: val_loss -0.4079
2025-10-06 04:02:36.609492: Pseudo dice [np.float32(0.6812)]
2025-10-06 04:02:36.609632: Epoch time: 46.42 s
2025-10-06 04:02:37.278823: 
2025-10-06 04:02:37.279192: Epoch 57
2025-10-06 04:02:37.279387: Current learning rate: 0.0065
2025-10-06 04:03:23.672008: Validation loss did not improve from -0.45515. Patience: 16/50
2025-10-06 04:03:23.672446: train_loss -0.7021
2025-10-06 04:03:23.672690: val_loss -0.4323
2025-10-06 04:03:23.672856: Pseudo dice [np.float32(0.6848)]
2025-10-06 04:03:23.673045: Epoch time: 46.39 s
2025-10-06 04:03:23.673215: Yayy! New best EMA pseudo Dice: 0.6819000244140625
2025-10-06 04:03:24.804544: 
2025-10-06 04:03:24.804786: Epoch 58
2025-10-06 04:03:24.804983: Current learning rate: 0.00644
2025-10-06 04:04:11.228618: Validation loss did not improve from -0.45515. Patience: 17/50
2025-10-06 04:04:11.229211: train_loss -0.7116
2025-10-06 04:04:11.229388: val_loss -0.4129
2025-10-06 04:04:11.229568: Pseudo dice [np.float32(0.6766)]
2025-10-06 04:04:11.229737: Epoch time: 46.43 s
2025-10-06 04:04:12.454689: 
2025-10-06 04:04:12.455039: Epoch 59
2025-10-06 04:04:12.455401: Current learning rate: 0.00638
2025-10-06 04:04:58.928972: Validation loss did not improve from -0.45515. Patience: 18/50
2025-10-06 04:04:58.929499: train_loss -0.7079
2025-10-06 04:04:58.929663: val_loss -0.4111
2025-10-06 04:04:58.929787: Pseudo dice [np.float32(0.6873)]
2025-10-06 04:04:58.929916: Epoch time: 46.48 s
2025-10-06 04:04:59.387135: Yayy! New best EMA pseudo Dice: 0.6819000244140625
2025-10-06 04:05:00.500093: 
2025-10-06 04:05:00.500344: Epoch 60
2025-10-06 04:05:00.500527: Current learning rate: 0.00631
2025-10-06 04:05:47.002525: Validation loss did not improve from -0.45515. Patience: 19/50
2025-10-06 04:05:47.003172: train_loss -0.7141
2025-10-06 04:05:47.003398: val_loss -0.4251
2025-10-06 04:05:47.003517: Pseudo dice [np.float32(0.6805)]
2025-10-06 04:05:47.003644: Epoch time: 46.5 s
2025-10-06 04:05:47.679721: 
2025-10-06 04:05:47.680092: Epoch 61
2025-10-06 04:05:47.680268: Current learning rate: 0.00625
2025-10-06 04:06:34.221740: Validation loss did not improve from -0.45515. Patience: 20/50
2025-10-06 04:06:34.222372: train_loss -0.7146
2025-10-06 04:06:34.222646: val_loss -0.4492
2025-10-06 04:06:34.222919: Pseudo dice [np.float32(0.7066)]
2025-10-06 04:06:34.223123: Epoch time: 46.54 s
2025-10-06 04:06:34.223311: Yayy! New best EMA pseudo Dice: 0.6843000054359436
2025-10-06 04:06:35.356833: 
2025-10-06 04:06:35.357181: Epoch 62
2025-10-06 04:06:35.357369: Current learning rate: 0.00619
2025-10-06 04:07:21.814874: Validation loss did not improve from -0.45515. Patience: 21/50
2025-10-06 04:07:21.815464: train_loss -0.7131
2025-10-06 04:07:21.815598: val_loss -0.4264
2025-10-06 04:07:21.815818: Pseudo dice [np.float32(0.6857)]
2025-10-06 04:07:21.815976: Epoch time: 46.46 s
2025-10-06 04:07:21.816123: Yayy! New best EMA pseudo Dice: 0.6844000220298767
2025-10-06 04:07:22.929646: 
2025-10-06 04:07:22.929925: Epoch 63
2025-10-06 04:07:22.930144: Current learning rate: 0.00612
2025-10-06 04:08:09.379858: Validation loss did not improve from -0.45515. Patience: 22/50
2025-10-06 04:08:09.380460: train_loss -0.7208
2025-10-06 04:08:09.380881: val_loss -0.4194
2025-10-06 04:08:09.381177: Pseudo dice [np.float32(0.6786)]
2025-10-06 04:08:09.381456: Epoch time: 46.45 s
2025-10-06 04:08:10.063827: 
2025-10-06 04:08:10.064137: Epoch 64
2025-10-06 04:08:10.064332: Current learning rate: 0.00606
2025-10-06 04:08:56.610243: Validation loss did not improve from -0.45515. Patience: 23/50
2025-10-06 04:08:56.610847: train_loss -0.7248
2025-10-06 04:08:56.611010: val_loss -0.4428
2025-10-06 04:08:56.611136: Pseudo dice [np.float32(0.6953)]
2025-10-06 04:08:56.611324: Epoch time: 46.55 s
2025-10-06 04:08:57.048039: Yayy! New best EMA pseudo Dice: 0.6850000023841858
2025-10-06 04:08:58.157243: 
2025-10-06 04:08:58.157570: Epoch 65
2025-10-06 04:08:58.157750: Current learning rate: 0.006
2025-10-06 04:09:44.658629: Validation loss did not improve from -0.45515. Patience: 24/50
2025-10-06 04:09:44.659171: train_loss -0.7292
2025-10-06 04:09:44.659372: val_loss -0.4227
2025-10-06 04:09:44.659544: Pseudo dice [np.float32(0.681)]
2025-10-06 04:09:44.659738: Epoch time: 46.5 s
2025-10-06 04:09:45.338525: 
2025-10-06 04:09:45.338894: Epoch 66
2025-10-06 04:09:45.339171: Current learning rate: 0.00593
2025-10-06 04:10:31.859206: Validation loss did not improve from -0.45515. Patience: 25/50
2025-10-06 04:10:31.859871: train_loss -0.731
2025-10-06 04:10:31.860213: val_loss -0.4073
2025-10-06 04:10:31.860463: Pseudo dice [np.float32(0.6865)]
2025-10-06 04:10:31.860717: Epoch time: 46.52 s
2025-10-06 04:10:32.537214: 
2025-10-06 04:10:32.537480: Epoch 67
2025-10-06 04:10:32.537675: Current learning rate: 0.00587
2025-10-06 04:11:18.996365: Validation loss did not improve from -0.45515. Patience: 26/50
2025-10-06 04:11:18.996990: train_loss -0.7299
2025-10-06 04:11:18.997197: val_loss -0.402
2025-10-06 04:11:18.997346: Pseudo dice [np.float32(0.6793)]
2025-10-06 04:11:18.997490: Epoch time: 46.46 s
2025-10-06 04:11:19.669203: 
2025-10-06 04:11:19.669549: Epoch 68
2025-10-06 04:11:19.669725: Current learning rate: 0.00581
2025-10-06 04:12:06.121491: Validation loss did not improve from -0.45515. Patience: 27/50
2025-10-06 04:12:06.122065: train_loss -0.7296
2025-10-06 04:12:06.122205: val_loss -0.4062
2025-10-06 04:12:06.122380: Pseudo dice [np.float32(0.6682)]
2025-10-06 04:12:06.122542: Epoch time: 46.45 s
2025-10-06 04:12:06.792823: 
2025-10-06 04:12:06.793059: Epoch 69
2025-10-06 04:12:06.793279: Current learning rate: 0.00574
2025-10-06 04:12:53.300269: Validation loss did not improve from -0.45515. Patience: 28/50
2025-10-06 04:12:53.300768: train_loss -0.7296
2025-10-06 04:12:53.300939: val_loss -0.427
2025-10-06 04:12:53.301108: Pseudo dice [np.float32(0.6916)]
2025-10-06 04:12:53.301251: Epoch time: 46.51 s
2025-10-06 04:12:54.429494: 
2025-10-06 04:12:54.429878: Epoch 70
2025-10-06 04:12:54.430102: Current learning rate: 0.00568
2025-10-06 04:13:41.008057: Validation loss did not improve from -0.45515. Patience: 29/50
2025-10-06 04:13:41.008781: train_loss -0.7339
2025-10-06 04:13:41.008958: val_loss -0.4252
2025-10-06 04:13:41.009156: Pseudo dice [np.float32(0.6909)]
2025-10-06 04:13:41.009304: Epoch time: 46.58 s
2025-10-06 04:13:41.684451: 
2025-10-06 04:13:41.684780: Epoch 71
2025-10-06 04:13:41.685005: Current learning rate: 0.00562
2025-10-06 04:14:28.217701: Validation loss did not improve from -0.45515. Patience: 30/50
2025-10-06 04:14:28.218304: train_loss -0.7457
2025-10-06 04:14:28.218474: val_loss -0.452
2025-10-06 04:14:28.218644: Pseudo dice [np.float32(0.7007)]
2025-10-06 04:14:28.218784: Epoch time: 46.53 s
2025-10-06 04:14:28.218931: Yayy! New best EMA pseudo Dice: 0.6858999729156494
2025-10-06 04:14:29.327234: 
2025-10-06 04:14:29.327595: Epoch 72
2025-10-06 04:14:29.327809: Current learning rate: 0.00555
2025-10-06 04:15:15.825592: Validation loss did not improve from -0.45515. Patience: 31/50
2025-10-06 04:15:15.826287: train_loss -0.7509
2025-10-06 04:15:15.826520: val_loss -0.4092
2025-10-06 04:15:15.826743: Pseudo dice [np.float32(0.6883)]
2025-10-06 04:15:15.826955: Epoch time: 46.5 s
2025-10-06 04:15:15.827146: Yayy! New best EMA pseudo Dice: 0.6861000061035156
2025-10-06 04:15:17.476023: 
2025-10-06 04:15:17.476472: Epoch 73
2025-10-06 04:15:17.476731: Current learning rate: 0.00549
2025-10-06 04:16:03.947869: Validation loss did not improve from -0.45515. Patience: 32/50
2025-10-06 04:16:03.948392: train_loss -0.7428
2025-10-06 04:16:03.948572: val_loss -0.3939
2025-10-06 04:16:03.948746: Pseudo dice [np.float32(0.6732)]
2025-10-06 04:16:03.948903: Epoch time: 46.47 s
2025-10-06 04:16:04.617631: 
2025-10-06 04:16:04.617999: Epoch 74
2025-10-06 04:16:04.618258: Current learning rate: 0.00542
2025-10-06 04:16:51.161809: Validation loss did not improve from -0.45515. Patience: 33/50
2025-10-06 04:16:51.162441: train_loss -0.7497
2025-10-06 04:16:51.162610: val_loss -0.4142
2025-10-06 04:16:51.162758: Pseudo dice [np.float32(0.6947)]
2025-10-06 04:16:51.162920: Epoch time: 46.55 s
2025-10-06 04:16:52.290863: 
2025-10-06 04:16:52.291239: Epoch 75
2025-10-06 04:16:52.291457: Current learning rate: 0.00536
2025-10-06 04:17:38.861620: Validation loss did not improve from -0.45515. Patience: 34/50
2025-10-06 04:17:38.862100: train_loss -0.75
2025-10-06 04:17:38.862321: val_loss -0.4221
2025-10-06 04:17:38.862491: Pseudo dice [np.float32(0.6881)]
2025-10-06 04:17:38.862656: Epoch time: 46.57 s
2025-10-06 04:17:39.538543: 
2025-10-06 04:17:39.538803: Epoch 76
2025-10-06 04:17:39.538998: Current learning rate: 0.00529
2025-10-06 04:18:26.072798: Validation loss did not improve from -0.45515. Patience: 35/50
2025-10-06 04:18:26.073753: train_loss -0.7496
2025-10-06 04:18:26.074078: val_loss -0.4201
2025-10-06 04:18:26.074268: Pseudo dice [np.float32(0.6847)]
2025-10-06 04:18:26.074434: Epoch time: 46.54 s
2025-10-06 04:18:26.761222: 
2025-10-06 04:18:26.761582: Epoch 77
2025-10-06 04:18:26.761770: Current learning rate: 0.00523
2025-10-06 04:19:13.246720: Validation loss did not improve from -0.45515. Patience: 36/50
2025-10-06 04:19:13.247100: train_loss -0.757
2025-10-06 04:19:13.247254: val_loss -0.4374
2025-10-06 04:19:13.247408: Pseudo dice [np.float32(0.6959)]
2025-10-06 04:19:13.247559: Epoch time: 46.49 s
2025-10-06 04:19:13.247673: Yayy! New best EMA pseudo Dice: 0.6869000196456909
2025-10-06 04:19:14.390375: 
2025-10-06 04:19:14.390747: Epoch 78
2025-10-06 04:19:14.390956: Current learning rate: 0.00517
2025-10-06 04:20:00.833687: Validation loss did not improve from -0.45515. Patience: 37/50
2025-10-06 04:20:00.834157: train_loss -0.7558
2025-10-06 04:20:00.834310: val_loss -0.4127
2025-10-06 04:20:00.834440: Pseudo dice [np.float32(0.6956)]
2025-10-06 04:20:00.834612: Epoch time: 46.44 s
2025-10-06 04:20:00.834747: Yayy! New best EMA pseudo Dice: 0.6877999901771545
2025-10-06 04:20:01.937405: 
2025-10-06 04:20:01.937729: Epoch 79
2025-10-06 04:20:01.937913: Current learning rate: 0.0051
2025-10-06 04:20:48.446716: Validation loss did not improve from -0.45515. Patience: 38/50
2025-10-06 04:20:48.447485: train_loss -0.762
2025-10-06 04:20:48.447812: val_loss -0.3753
2025-10-06 04:20:48.448052: Pseudo dice [np.float32(0.6677)]
2025-10-06 04:20:48.448253: Epoch time: 46.51 s
2025-10-06 04:20:49.593257: 
2025-10-06 04:20:49.593623: Epoch 80
2025-10-06 04:20:49.593876: Current learning rate: 0.00504
2025-10-06 04:21:36.058727: Validation loss did not improve from -0.45515. Patience: 39/50
2025-10-06 04:21:36.059196: train_loss -0.7709
2025-10-06 04:21:36.059382: val_loss -0.3862
2025-10-06 04:21:36.059516: Pseudo dice [np.float32(0.6796)]
2025-10-06 04:21:36.059668: Epoch time: 46.47 s
2025-10-06 04:21:36.745857: 
2025-10-06 04:21:36.746238: Epoch 81
2025-10-06 04:21:36.746458: Current learning rate: 0.00497
2025-10-06 04:22:23.262365: Validation loss did not improve from -0.45515. Patience: 40/50
2025-10-06 04:22:23.262744: train_loss -0.763
2025-10-06 04:22:23.262949: val_loss -0.3852
2025-10-06 04:22:23.263101: Pseudo dice [np.float32(0.6811)]
2025-10-06 04:22:23.263239: Epoch time: 46.52 s
2025-10-06 04:22:23.949898: 
2025-10-06 04:22:23.950250: Epoch 82
2025-10-06 04:22:23.950500: Current learning rate: 0.00491
2025-10-06 04:23:10.378129: Validation loss did not improve from -0.45515. Patience: 41/50
2025-10-06 04:23:10.378749: train_loss -0.766
2025-10-06 04:23:10.378953: val_loss -0.4361
2025-10-06 04:23:10.379075: Pseudo dice [np.float32(0.6877)]
2025-10-06 04:23:10.379214: Epoch time: 46.43 s
2025-10-06 04:23:11.043950: 
2025-10-06 04:23:11.044281: Epoch 83
2025-10-06 04:23:11.044475: Current learning rate: 0.00484
2025-10-06 04:23:57.348288: Validation loss did not improve from -0.45515. Patience: 42/50
2025-10-06 04:23:57.348721: train_loss -0.7712
2025-10-06 04:23:57.348942: val_loss -0.406
2025-10-06 04:23:57.349093: Pseudo dice [np.float32(0.6918)]
2025-10-06 04:23:57.349305: Epoch time: 46.31 s
2025-10-06 04:23:58.002141: 
2025-10-06 04:23:58.002438: Epoch 84
2025-10-06 04:23:58.002638: Current learning rate: 0.00478
2025-10-06 04:24:44.453081: Validation loss did not improve from -0.45515. Patience: 43/50
2025-10-06 04:24:44.453799: train_loss -0.7632
2025-10-06 04:24:44.454076: val_loss -0.4339
2025-10-06 04:24:44.454313: Pseudo dice [np.float32(0.6991)]
2025-10-06 04:24:44.454623: Epoch time: 46.45 s
2025-10-06 04:24:45.550246: 
2025-10-06 04:24:45.550691: Epoch 85
2025-10-06 04:24:45.550990: Current learning rate: 0.00471
2025-10-06 04:25:32.126355: Validation loss did not improve from -0.45515. Patience: 44/50
2025-10-06 04:25:32.126896: train_loss -0.7718
2025-10-06 04:25:32.127135: val_loss -0.3808
2025-10-06 04:25:32.127409: Pseudo dice [np.float32(0.6596)]
2025-10-06 04:25:32.127634: Epoch time: 46.58 s
2025-10-06 04:25:32.787975: 
2025-10-06 04:25:32.788361: Epoch 86
2025-10-06 04:25:32.788582: Current learning rate: 0.00465
2025-10-06 04:26:19.279716: Validation loss did not improve from -0.45515. Patience: 45/50
2025-10-06 04:26:19.280537: train_loss -0.7753
2025-10-06 04:26:19.280797: val_loss -0.4437
2025-10-06 04:26:19.280978: Pseudo dice [np.float32(0.7013)]
2025-10-06 04:26:19.281181: Epoch time: 46.49 s
2025-10-06 04:26:19.934887: 
2025-10-06 04:26:19.935138: Epoch 87
2025-10-06 04:26:19.935383: Current learning rate: 0.00458
2025-10-06 04:27:06.277014: Validation loss did not improve from -0.45515. Patience: 46/50
2025-10-06 04:27:06.277440: train_loss -0.7762
2025-10-06 04:27:06.277582: val_loss -0.4273
2025-10-06 04:27:06.277716: Pseudo dice [np.float32(0.6961)]
2025-10-06 04:27:06.277845: Epoch time: 46.34 s
2025-10-06 04:27:06.937757: 
2025-10-06 04:27:06.938002: Epoch 88
2025-10-06 04:27:06.938183: Current learning rate: 0.00452
2025-10-06 04:27:53.374856: Validation loss did not improve from -0.45515. Patience: 47/50
2025-10-06 04:27:53.375463: train_loss -0.7816
2025-10-06 04:27:53.375606: val_loss -0.4143
2025-10-06 04:27:53.375776: Pseudo dice [np.float32(0.6964)]
2025-10-06 04:27:53.375961: Epoch time: 46.44 s
2025-10-06 04:27:53.376125: Yayy! New best EMA pseudo Dice: 0.6880000233650208
2025-10-06 04:27:55.114227: 
2025-10-06 04:27:55.114612: Epoch 89
2025-10-06 04:27:55.114900: Current learning rate: 0.00445
2025-10-06 04:28:41.589400: Validation loss did not improve from -0.45515. Patience: 48/50
2025-10-06 04:28:41.590032: train_loss -0.7882
2025-10-06 04:28:41.590292: val_loss -0.4299
2025-10-06 04:28:41.590485: Pseudo dice [np.float32(0.6887)]
2025-10-06 04:28:41.590679: Epoch time: 46.48 s
2025-10-06 04:28:42.164781: Yayy! New best EMA pseudo Dice: 0.6880000233650208
2025-10-06 04:28:43.393297: 
2025-10-06 04:28:43.393704: Epoch 90
2025-10-06 04:28:43.393932: Current learning rate: 0.00438
2025-10-06 04:29:29.903277: Validation loss did not improve from -0.45515. Patience: 49/50
2025-10-06 04:29:29.903918: train_loss -0.7888
2025-10-06 04:29:29.904146: val_loss -0.4042
2025-10-06 04:29:29.904338: Pseudo dice [np.float32(0.6892)]
2025-10-06 04:29:29.904555: Epoch time: 46.51 s
2025-10-06 04:29:29.904713: Yayy! New best EMA pseudo Dice: 0.6881999969482422
2025-10-06 04:29:31.044751: 
2025-10-06 04:29:31.045107: Epoch 91
2025-10-06 04:29:31.045285: Current learning rate: 0.00432
2025-10-06 04:30:17.531268: Validation loss did not improve from -0.45515. Patience: 50/50
2025-10-06 04:30:17.531782: train_loss -0.7805
2025-10-06 04:30:17.531988: val_loss -0.4192
2025-10-06 04:30:17.532173: Pseudo dice [np.float32(0.6844)]
2025-10-06 04:30:17.532344: Epoch time: 46.49 s
2025-10-06 04:30:18.183866: 
2025-10-06 04:30:18.184207: Epoch 92
2025-10-06 04:30:18.184393: Current learning rate: 0.00425
2025-10-06 04:31:04.601992: Validation loss did not improve from -0.45515. Patience: 51/50
2025-10-06 04:31:04.602474: train_loss -0.7802
2025-10-06 04:31:04.602641: val_loss -0.4096
2025-10-06 04:31:04.602857: Pseudo dice [np.float32(0.6935)]
2025-10-06 04:31:04.603006: Epoch time: 46.42 s
2025-10-06 04:31:04.603126: Yayy! New best EMA pseudo Dice: 0.6883999705314636
2025-10-06 04:31:05.710599: 
2025-10-06 04:31:05.710934: Epoch 93
2025-10-06 04:31:05.711203: Current learning rate: 0.00419
2025-10-06 04:31:52.175002: Validation loss did not improve from -0.45515. Patience: 52/50
2025-10-06 04:31:52.175452: train_loss -0.793
2025-10-06 04:31:52.175640: val_loss -0.4242
2025-10-06 04:31:52.175808: Pseudo dice [np.float32(0.6924)]
2025-10-06 04:31:52.175978: Epoch time: 46.47 s
2025-10-06 04:31:52.176111: Yayy! New best EMA pseudo Dice: 0.6887999773025513
2025-10-06 04:31:53.291342: 
2025-10-06 04:31:53.291710: Epoch 94
2025-10-06 04:31:53.291937: Current learning rate: 0.00412
2025-10-06 04:32:39.811419: Validation loss did not improve from -0.45515. Patience: 53/50
2025-10-06 04:32:39.811977: train_loss -0.7934
2025-10-06 04:32:39.812134: val_loss -0.4057
2025-10-06 04:32:39.812258: Pseudo dice [np.float32(0.6894)]
2025-10-06 04:32:39.812396: Epoch time: 46.52 s
2025-10-06 04:32:40.249294: Yayy! New best EMA pseudo Dice: 0.6887999773025513
2025-10-06 04:32:41.337789: 
2025-10-06 04:32:41.338076: Epoch 95
2025-10-06 04:32:41.338281: Current learning rate: 0.00405
2025-10-06 04:33:27.915119: Validation loss did not improve from -0.45515. Patience: 54/50
2025-10-06 04:33:27.915581: train_loss -0.7965
2025-10-06 04:33:27.915765: val_loss -0.3953
2025-10-06 04:33:27.915904: Pseudo dice [np.float32(0.6853)]
2025-10-06 04:33:27.916055: Epoch time: 46.58 s
2025-10-06 04:33:28.573960: 
2025-10-06 04:33:28.574212: Epoch 96
2025-10-06 04:33:28.574392: Current learning rate: 0.00399
2025-10-06 04:34:15.111640: Validation loss did not improve from -0.45515. Patience: 55/50
2025-10-06 04:34:15.112208: train_loss -0.7918
2025-10-06 04:34:15.112348: val_loss -0.4353
2025-10-06 04:34:15.112464: Pseudo dice [np.float32(0.6986)]
2025-10-06 04:34:15.112591: Epoch time: 46.54 s
2025-10-06 04:34:15.112732: Yayy! New best EMA pseudo Dice: 0.6894999742507935
2025-10-06 04:34:16.216194: 
2025-10-06 04:34:16.216538: Epoch 97
2025-10-06 04:34:16.216748: Current learning rate: 0.00392
2025-10-06 04:35:02.652891: Validation loss did not improve from -0.45515. Patience: 56/50
2025-10-06 04:35:02.653327: train_loss -0.7989
2025-10-06 04:35:02.653476: val_loss -0.4125
2025-10-06 04:35:02.653597: Pseudo dice [np.float32(0.7001)]
2025-10-06 04:35:02.653723: Epoch time: 46.44 s
2025-10-06 04:35:02.653841: Yayy! New best EMA pseudo Dice: 0.690500020980835
2025-10-06 04:35:03.757123: 
2025-10-06 04:35:03.757485: Epoch 98
2025-10-06 04:35:03.757689: Current learning rate: 0.00385
2025-10-06 04:35:50.277238: Validation loss did not improve from -0.45515. Patience: 57/50
2025-10-06 04:35:50.277731: train_loss -0.8039
2025-10-06 04:35:50.277886: val_loss -0.3593
2025-10-06 04:35:50.278090: Pseudo dice [np.float32(0.659)]
2025-10-06 04:35:50.278224: Epoch time: 46.52 s
2025-10-06 04:35:50.942573: 
2025-10-06 04:35:50.942925: Epoch 99
2025-10-06 04:35:50.943191: Current learning rate: 0.00379
2025-10-06 04:36:37.373052: Validation loss did not improve from -0.45515. Patience: 58/50
2025-10-06 04:36:37.373413: train_loss -0.7873
2025-10-06 04:36:37.373594: val_loss -0.3721
2025-10-06 04:36:37.373747: Pseudo dice [np.float32(0.6734)]
2025-10-06 04:36:37.373914: Epoch time: 46.43 s
2025-10-06 04:36:38.478267: 
2025-10-06 04:36:38.478657: Epoch 100
2025-10-06 04:36:38.478901: Current learning rate: 0.00372
2025-10-06 04:37:24.999196: Validation loss did not improve from -0.45515. Patience: 59/50
2025-10-06 04:37:24.999932: train_loss -0.7999
2025-10-06 04:37:25.000253: val_loss -0.3808
2025-10-06 04:37:25.000506: Pseudo dice [np.float32(0.6951)]
2025-10-06 04:37:25.000789: Epoch time: 46.52 s
2025-10-06 04:37:25.678533: 
2025-10-06 04:37:25.678897: Epoch 101
2025-10-06 04:37:25.679104: Current learning rate: 0.00365
2025-10-06 04:38:12.114686: Validation loss did not improve from -0.45515. Patience: 60/50
2025-10-06 04:38:12.115142: train_loss -0.7977
2025-10-06 04:38:12.115306: val_loss -0.3832
2025-10-06 04:38:12.115432: Pseudo dice [np.float32(0.673)]
2025-10-06 04:38:12.115587: Epoch time: 46.44 s
2025-10-06 04:38:12.779836: 
2025-10-06 04:38:12.780199: Epoch 102
2025-10-06 04:38:12.780410: Current learning rate: 0.00359
2025-10-06 04:38:59.111913: Validation loss did not improve from -0.45515. Patience: 61/50
2025-10-06 04:38:59.112467: train_loss -0.8026
2025-10-06 04:38:59.112630: val_loss -0.3827
2025-10-06 04:38:59.112750: Pseudo dice [np.float32(0.6841)]
2025-10-06 04:38:59.112886: Epoch time: 46.33 s
2025-10-06 04:38:59.773073: 
2025-10-06 04:38:59.773449: Epoch 103
2025-10-06 04:38:59.773653: Current learning rate: 0.00352
2025-10-06 04:39:46.232784: Validation loss did not improve from -0.45515. Patience: 62/50
2025-10-06 04:39:46.233290: train_loss -0.8034
2025-10-06 04:39:46.233441: val_loss -0.4314
2025-10-06 04:39:46.233568: Pseudo dice [np.float32(0.693)]
2025-10-06 04:39:46.233702: Epoch time: 46.46 s
2025-10-06 04:39:47.463792: 
2025-10-06 04:39:47.464176: Epoch 104
2025-10-06 04:39:47.464393: Current learning rate: 0.00345
2025-10-06 04:40:33.973866: Validation loss did not improve from -0.45515. Patience: 63/50
2025-10-06 04:40:33.974605: train_loss -0.8092
2025-10-06 04:40:33.974812: val_loss -0.4359
2025-10-06 04:40:33.974977: Pseudo dice [np.float32(0.7141)]
2025-10-06 04:40:33.975138: Epoch time: 46.51 s
2025-10-06 04:40:35.107838: 
2025-10-06 04:40:35.108286: Epoch 105
2025-10-06 04:40:35.108658: Current learning rate: 0.00338
2025-10-06 04:41:21.658657: Validation loss did not improve from -0.45515. Patience: 64/50
2025-10-06 04:41:21.659155: train_loss -0.8129
2025-10-06 04:41:21.659309: val_loss -0.3687
2025-10-06 04:41:21.659468: Pseudo dice [np.float32(0.6811)]
2025-10-06 04:41:21.659609: Epoch time: 46.55 s
2025-10-06 04:41:22.331122: 
2025-10-06 04:41:22.331385: Epoch 106
2025-10-06 04:41:22.331582: Current learning rate: 0.00332
2025-10-06 04:42:08.789148: Validation loss did not improve from -0.45515. Patience: 65/50
2025-10-06 04:42:08.789716: train_loss -0.807
2025-10-06 04:42:08.789879: val_loss -0.4063
2025-10-06 04:42:08.790072: Pseudo dice [np.float32(0.6896)]
2025-10-06 04:42:08.790271: Epoch time: 46.46 s
2025-10-06 04:42:09.468118: 
2025-10-06 04:42:09.468435: Epoch 107
2025-10-06 04:42:09.468638: Current learning rate: 0.00325
2025-10-06 04:42:55.913358: Validation loss did not improve from -0.45515. Patience: 66/50
2025-10-06 04:42:55.913967: train_loss -0.8099
2025-10-06 04:42:55.914264: val_loss -0.3942
2025-10-06 04:42:55.914481: Pseudo dice [np.float32(0.6744)]
2025-10-06 04:42:55.914710: Epoch time: 46.45 s
2025-10-06 04:42:56.590970: 
2025-10-06 04:42:56.591277: Epoch 108
2025-10-06 04:42:56.591469: Current learning rate: 0.00318
2025-10-06 04:43:43.024575: Validation loss did not improve from -0.45515. Patience: 67/50
2025-10-06 04:43:43.025135: train_loss -0.8137
2025-10-06 04:43:43.025320: val_loss -0.3649
2025-10-06 04:43:43.025440: Pseudo dice [np.float32(0.688)]
2025-10-06 04:43:43.025579: Epoch time: 46.43 s
2025-10-06 04:43:43.690446: 
2025-10-06 04:43:43.690802: Epoch 109
2025-10-06 04:43:43.690991: Current learning rate: 0.00311
2025-10-06 04:44:30.149284: Validation loss did not improve from -0.45515. Patience: 68/50
2025-10-06 04:44:30.149834: train_loss -0.8173
2025-10-06 04:44:30.150025: val_loss -0.4119
2025-10-06 04:44:30.150182: Pseudo dice [np.float32(0.6923)]
2025-10-06 04:44:30.150343: Epoch time: 46.46 s
2025-10-06 04:44:31.256742: 
2025-10-06 04:44:31.256984: Epoch 110
2025-10-06 04:44:31.257174: Current learning rate: 0.00304
2025-10-06 04:45:17.835153: Validation loss did not improve from -0.45515. Patience: 69/50
2025-10-06 04:45:17.835755: train_loss -0.8146
2025-10-06 04:45:17.835955: val_loss -0.3989
2025-10-06 04:45:17.836114: Pseudo dice [np.float32(0.688)]
2025-10-06 04:45:17.836290: Epoch time: 46.58 s
2025-10-06 04:45:18.502718: 
2025-10-06 04:45:18.503138: Epoch 111
2025-10-06 04:45:18.503368: Current learning rate: 0.00297
2025-10-06 04:46:04.946215: Validation loss did not improve from -0.45515. Patience: 70/50
2025-10-06 04:46:04.946719: train_loss -0.8212
2025-10-06 04:46:04.946904: val_loss -0.4074
2025-10-06 04:46:04.947089: Pseudo dice [np.float32(0.6824)]
2025-10-06 04:46:04.947269: Epoch time: 46.44 s
2025-10-06 04:46:05.621666: 
2025-10-06 04:46:05.622086: Epoch 112
2025-10-06 04:46:05.622377: Current learning rate: 0.00291
2025-10-06 04:46:52.031758: Validation loss did not improve from -0.45515. Patience: 71/50
2025-10-06 04:46:52.032678: train_loss -0.8158
2025-10-06 04:46:52.033092: val_loss -0.3848
2025-10-06 04:46:52.033396: Pseudo dice [np.float32(0.6803)]
2025-10-06 04:46:52.033727: Epoch time: 46.41 s
2025-10-06 04:46:52.702809: 
2025-10-06 04:46:52.703152: Epoch 113
2025-10-06 04:46:52.703345: Current learning rate: 0.00284
2025-10-06 04:47:39.174203: Validation loss did not improve from -0.45515. Patience: 72/50
2025-10-06 04:47:39.174697: train_loss -0.8172
2025-10-06 04:47:39.174850: val_loss -0.411
2025-10-06 04:47:39.175017: Pseudo dice [np.float32(0.7007)]
2025-10-06 04:47:39.175198: Epoch time: 46.47 s
2025-10-06 04:47:39.835415: 
2025-10-06 04:47:39.835703: Epoch 114
2025-10-06 04:47:39.835892: Current learning rate: 0.00277
2025-10-06 04:48:26.325032: Validation loss did not improve from -0.45515. Patience: 73/50
2025-10-06 04:48:26.325593: train_loss -0.8198
2025-10-06 04:48:26.325739: val_loss -0.4191
2025-10-06 04:48:26.325871: Pseudo dice [np.float32(0.7002)]
2025-10-06 04:48:26.326032: Epoch time: 46.49 s
2025-10-06 04:48:27.440518: 
2025-10-06 04:48:27.440875: Epoch 115
2025-10-06 04:48:27.441149: Current learning rate: 0.0027
2025-10-06 04:49:13.957126: Validation loss did not improve from -0.45515. Patience: 74/50
2025-10-06 04:49:13.957762: train_loss -0.8267
2025-10-06 04:49:13.958006: val_loss -0.3736
2025-10-06 04:49:13.958302: Pseudo dice [np.float32(0.6796)]
2025-10-06 04:49:13.958522: Epoch time: 46.52 s
2025-10-06 04:49:14.654258: 
2025-10-06 04:49:14.654639: Epoch 116
2025-10-06 04:49:14.654862: Current learning rate: 0.00263
2025-10-06 04:50:01.235578: Validation loss did not improve from -0.45515. Patience: 75/50
2025-10-06 04:50:01.236187: train_loss -0.825
2025-10-06 04:50:01.236474: val_loss -0.3807
2025-10-06 04:50:01.236773: Pseudo dice [np.float32(0.6863)]
2025-10-06 04:50:01.237101: Epoch time: 46.58 s
2025-10-06 04:50:01.915389: 
2025-10-06 04:50:01.915602: Epoch 117
2025-10-06 04:50:01.915774: Current learning rate: 0.00256
2025-10-06 04:50:48.384535: Validation loss did not improve from -0.45515. Patience: 76/50
2025-10-06 04:50:48.385104: train_loss -0.8306
2025-10-06 04:50:48.385324: val_loss -0.445
2025-10-06 04:50:48.385489: Pseudo dice [np.float32(0.7156)]
2025-10-06 04:50:48.385676: Epoch time: 46.47 s
2025-10-06 04:50:48.385854: Yayy! New best EMA pseudo Dice: 0.6906999945640564
2025-10-06 04:50:49.505290: 
2025-10-06 04:50:49.505631: Epoch 118
2025-10-06 04:50:49.505878: Current learning rate: 0.00249
2025-10-06 04:51:35.955790: Validation loss did not improve from -0.45515. Patience: 77/50
2025-10-06 04:51:35.956293: train_loss -0.8292
2025-10-06 04:51:35.956450: val_loss -0.4266
2025-10-06 04:51:35.956585: Pseudo dice [np.float32(0.7005)]
2025-10-06 04:51:35.956783: Epoch time: 46.45 s
2025-10-06 04:51:35.956966: Yayy! New best EMA pseudo Dice: 0.6916999816894531
2025-10-06 04:51:37.076945: 
2025-10-06 04:51:37.077168: Epoch 119
2025-10-06 04:51:37.077337: Current learning rate: 0.00242
2025-10-06 04:52:23.578599: Validation loss did not improve from -0.45515. Patience: 78/50
2025-10-06 04:52:23.579249: train_loss -0.8285
2025-10-06 04:52:23.579435: val_loss -0.3933
2025-10-06 04:52:23.579558: Pseudo dice [np.float32(0.6927)]
2025-10-06 04:52:23.579705: Epoch time: 46.5 s
2025-10-06 04:52:24.629672: Yayy! New best EMA pseudo Dice: 0.6917999982833862
2025-10-06 04:52:25.754787: 
2025-10-06 04:52:25.755168: Epoch 120
2025-10-06 04:52:25.755353: Current learning rate: 0.00235
2025-10-06 04:53:12.352184: Validation loss did not improve from -0.45515. Patience: 79/50
2025-10-06 04:53:12.352768: train_loss -0.8246
2025-10-06 04:53:12.352971: val_loss -0.3894
2025-10-06 04:53:12.353093: Pseudo dice [np.float32(0.6924)]
2025-10-06 04:53:12.353277: Epoch time: 46.6 s
2025-10-06 04:53:12.353406: Yayy! New best EMA pseudo Dice: 0.6919000148773193
2025-10-06 04:53:13.478477: 
2025-10-06 04:53:13.478831: Epoch 121
2025-10-06 04:53:13.479035: Current learning rate: 0.00228
2025-10-06 04:53:59.946861: Validation loss did not improve from -0.45515. Patience: 80/50
2025-10-06 04:53:59.947473: train_loss -0.8333
2025-10-06 04:53:59.947631: val_loss -0.424
2025-10-06 04:53:59.947836: Pseudo dice [np.float32(0.6978)]
2025-10-06 04:53:59.948092: Epoch time: 46.47 s
2025-10-06 04:53:59.948247: Yayy! New best EMA pseudo Dice: 0.6924999952316284
2025-10-06 04:54:01.086238: 
2025-10-06 04:54:01.086670: Epoch 122
2025-10-06 04:54:01.086969: Current learning rate: 0.00221
2025-10-06 04:54:47.440228: Validation loss did not improve from -0.45515. Patience: 81/50
2025-10-06 04:54:47.440668: train_loss -0.834
2025-10-06 04:54:47.440829: val_loss -0.4072
2025-10-06 04:54:47.440984: Pseudo dice [np.float32(0.6874)]
2025-10-06 04:54:47.441119: Epoch time: 46.36 s
2025-10-06 04:54:48.120261: 
2025-10-06 04:54:48.120639: Epoch 123
2025-10-06 04:54:48.120826: Current learning rate: 0.00214
2025-10-06 04:55:34.528652: Validation loss did not improve from -0.45515. Patience: 82/50
2025-10-06 04:55:34.529349: train_loss -0.8355
2025-10-06 04:55:34.529538: val_loss -0.3848
2025-10-06 04:55:34.529763: Pseudo dice [np.float32(0.6795)]
2025-10-06 04:55:34.530352: Epoch time: 46.41 s
2025-10-06 04:55:35.215828: 
2025-10-06 04:55:35.216088: Epoch 124
2025-10-06 04:55:35.216316: Current learning rate: 0.00207
2025-10-06 04:56:21.743204: Validation loss did not improve from -0.45515. Patience: 83/50
2025-10-06 04:56:21.743819: train_loss -0.8341
2025-10-06 04:56:21.744072: val_loss -0.4231
2025-10-06 04:56:21.744214: Pseudo dice [np.float32(0.7024)]
2025-10-06 04:56:21.744439: Epoch time: 46.53 s
2025-10-06 04:56:22.886003: 
2025-10-06 04:56:22.886246: Epoch 125
2025-10-06 04:56:22.886440: Current learning rate: 0.00199
2025-10-06 04:57:09.478060: Validation loss did not improve from -0.45515. Patience: 84/50
2025-10-06 04:57:09.478628: train_loss -0.8345
2025-10-06 04:57:09.478844: val_loss -0.3863
2025-10-06 04:57:09.478990: Pseudo dice [np.float32(0.7005)]
2025-10-06 04:57:09.479194: Epoch time: 46.59 s
2025-10-06 04:57:09.479376: Yayy! New best EMA pseudo Dice: 0.6927000284194946
2025-10-06 04:57:10.615707: 
2025-10-06 04:57:10.616021: Epoch 126
2025-10-06 04:57:10.616194: Current learning rate: 0.00192
2025-10-06 04:57:57.192564: Validation loss did not improve from -0.45515. Patience: 85/50
2025-10-06 04:57:57.193190: train_loss -0.8376
2025-10-06 04:57:57.193333: val_loss -0.4506
2025-10-06 04:57:57.193471: Pseudo dice [np.float32(0.7132)]
2025-10-06 04:57:57.193671: Epoch time: 46.58 s
2025-10-06 04:57:57.193830: Yayy! New best EMA pseudo Dice: 0.6948000192642212
2025-10-06 04:57:58.334215: 
2025-10-06 04:57:58.334480: Epoch 127
2025-10-06 04:57:58.334673: Current learning rate: 0.00185
2025-10-06 04:58:44.800547: Validation loss did not improve from -0.45515. Patience: 86/50
2025-10-06 04:58:44.801054: train_loss -0.8389
2025-10-06 04:58:44.801246: val_loss -0.4222
2025-10-06 04:58:44.801393: Pseudo dice [np.float32(0.6976)]
2025-10-06 04:58:44.801551: Epoch time: 46.47 s
2025-10-06 04:58:44.801692: Yayy! New best EMA pseudo Dice: 0.6951000094413757
2025-10-06 04:58:45.970464: 
2025-10-06 04:58:45.970795: Epoch 128
2025-10-06 04:58:45.971003: Current learning rate: 0.00178
2025-10-06 04:59:32.483027: Validation loss did not improve from -0.45515. Patience: 87/50
2025-10-06 04:59:32.483860: train_loss -0.8394
2025-10-06 04:59:32.484303: val_loss -0.4179
2025-10-06 04:59:32.484642: Pseudo dice [np.float32(0.6901)]
2025-10-06 04:59:32.484960: Epoch time: 46.51 s
2025-10-06 04:59:33.172371: 
2025-10-06 04:59:33.172798: Epoch 129
2025-10-06 04:59:33.173095: Current learning rate: 0.0017
2025-10-06 05:00:19.516042: Validation loss did not improve from -0.45515. Patience: 88/50
2025-10-06 05:00:19.516837: train_loss -0.842
2025-10-06 05:00:19.517244: val_loss -0.4225
2025-10-06 05:00:19.517630: Pseudo dice [np.float32(0.7077)]
2025-10-06 05:00:19.517973: Epoch time: 46.35 s
2025-10-06 05:00:19.964051: Yayy! New best EMA pseudo Dice: 0.695900022983551
2025-10-06 05:00:21.098439: 
2025-10-06 05:00:21.098794: Epoch 130
2025-10-06 05:00:21.099031: Current learning rate: 0.00163
2025-10-06 05:01:07.567237: Validation loss did not improve from -0.45515. Patience: 89/50
2025-10-06 05:01:07.567856: train_loss -0.8412
2025-10-06 05:01:07.568047: val_loss -0.3957
2025-10-06 05:01:07.568219: Pseudo dice [np.float32(0.6856)]
2025-10-06 05:01:07.568413: Epoch time: 46.47 s
2025-10-06 05:01:08.237502: 
2025-10-06 05:01:08.237808: Epoch 131
2025-10-06 05:01:08.238065: Current learning rate: 0.00156
2025-10-06 05:01:54.908629: Validation loss did not improve from -0.45515. Patience: 90/50
2025-10-06 05:01:54.909256: train_loss -0.842
2025-10-06 05:01:54.909427: val_loss -0.4049
2025-10-06 05:01:54.909548: Pseudo dice [np.float32(0.699)]
2025-10-06 05:01:54.909688: Epoch time: 46.67 s
2025-10-06 05:01:55.580640: 
2025-10-06 05:01:55.581012: Epoch 132
2025-10-06 05:01:55.581215: Current learning rate: 0.00148
2025-10-06 05:02:42.132798: Validation loss did not improve from -0.45515. Patience: 91/50
2025-10-06 05:02:42.133334: train_loss -0.846
2025-10-06 05:02:42.133494: val_loss -0.3952
2025-10-06 05:02:42.133607: Pseudo dice [np.float32(0.6975)]
2025-10-06 05:02:42.133771: Epoch time: 46.55 s
2025-10-06 05:02:42.800526: 
2025-10-06 05:02:42.800866: Epoch 133
2025-10-06 05:02:42.801067: Current learning rate: 0.00141
2025-10-06 05:03:29.402207: Validation loss did not improve from -0.45515. Patience: 92/50
2025-10-06 05:03:29.402786: train_loss -0.8424
2025-10-06 05:03:29.402942: val_loss -0.3952
2025-10-06 05:03:29.403077: Pseudo dice [np.float32(0.698)]
2025-10-06 05:03:29.403203: Epoch time: 46.6 s
2025-10-06 05:03:30.648205: 
2025-10-06 05:03:30.648591: Epoch 134
2025-10-06 05:03:30.648794: Current learning rate: 0.00133
2025-10-06 05:04:17.136211: Validation loss did not improve from -0.45515. Patience: 93/50
2025-10-06 05:04:17.136826: train_loss -0.8469
2025-10-06 05:04:17.136998: val_loss -0.3535
2025-10-06 05:04:17.137135: Pseudo dice [np.float32(0.6816)]
2025-10-06 05:04:17.137287: Epoch time: 46.49 s
2025-10-06 05:04:18.308104: 
2025-10-06 05:04:18.308401: Epoch 135
2025-10-06 05:04:18.308565: Current learning rate: 0.00126
2025-10-06 05:05:04.871760: Validation loss did not improve from -0.45515. Patience: 94/50
2025-10-06 05:05:04.872435: train_loss -0.8465
2025-10-06 05:05:04.872614: val_loss -0.3921
2025-10-06 05:05:04.872795: Pseudo dice [np.float32(0.6945)]
2025-10-06 05:05:04.873080: Epoch time: 46.57 s
2025-10-06 05:05:05.549618: 
2025-10-06 05:05:05.549986: Epoch 136
2025-10-06 05:05:05.550210: Current learning rate: 0.00118
2025-10-06 05:05:52.051150: Validation loss did not improve from -0.45515. Patience: 95/50
2025-10-06 05:05:52.051728: train_loss -0.8464
2025-10-06 05:05:52.051893: val_loss -0.4108
2025-10-06 05:05:52.052020: Pseudo dice [np.float32(0.7064)]
2025-10-06 05:05:52.052178: Epoch time: 46.5 s
2025-10-06 05:05:52.730892: 
2025-10-06 05:05:52.731214: Epoch 137
2025-10-06 05:05:52.731421: Current learning rate: 0.00111
2025-10-06 05:06:39.162910: Validation loss did not improve from -0.45515. Patience: 96/50
2025-10-06 05:06:39.163460: train_loss -0.8501
2025-10-06 05:06:39.163611: val_loss -0.4194
2025-10-06 05:06:39.163745: Pseudo dice [np.float32(0.706)]
2025-10-06 05:06:39.163903: Epoch time: 46.43 s
2025-10-06 05:06:39.164052: Yayy! New best EMA pseudo Dice: 0.6966000199317932
2025-10-06 05:06:40.305266: 
2025-10-06 05:06:40.305701: Epoch 138
2025-10-06 05:06:40.306002: Current learning rate: 0.00103
2025-10-06 05:07:26.733794: Validation loss did not improve from -0.45515. Patience: 97/50
2025-10-06 05:07:26.734413: train_loss -0.8514
2025-10-06 05:07:26.734650: val_loss -0.4058
2025-10-06 05:07:26.734806: Pseudo dice [np.float32(0.6952)]
2025-10-06 05:07:26.734968: Epoch time: 46.43 s
2025-10-06 05:07:27.418612: 
2025-10-06 05:07:27.418918: Epoch 139
2025-10-06 05:07:27.419095: Current learning rate: 0.00095
2025-10-06 05:08:13.915471: Validation loss did not improve from -0.45515. Patience: 98/50
2025-10-06 05:08:13.916122: train_loss -0.8517
2025-10-06 05:08:13.916270: val_loss -0.3796
2025-10-06 05:08:13.916391: Pseudo dice [np.float32(0.689)]
2025-10-06 05:08:13.916526: Epoch time: 46.5 s
2025-10-06 05:08:15.046424: 
2025-10-06 05:08:15.046774: Epoch 140
2025-10-06 05:08:15.047029: Current learning rate: 0.00087
2025-10-06 05:09:01.535050: Validation loss did not improve from -0.45515. Patience: 99/50
2025-10-06 05:09:01.535630: train_loss -0.8491
2025-10-06 05:09:01.535869: val_loss -0.406
2025-10-06 05:09:01.536003: Pseudo dice [np.float32(0.6841)]
2025-10-06 05:09:01.536159: Epoch time: 46.49 s
2025-10-06 05:09:02.221533: 
2025-10-06 05:09:02.221890: Epoch 141
2025-10-06 05:09:02.222059: Current learning rate: 0.00079
2025-10-06 05:09:48.719898: Validation loss did not improve from -0.45515. Patience: 100/50
2025-10-06 05:09:48.720452: train_loss -0.8504
2025-10-06 05:09:48.720625: val_loss -0.4304
2025-10-06 05:09:48.720747: Pseudo dice [np.float32(0.7054)]
2025-10-06 05:09:48.720904: Epoch time: 46.5 s
2025-10-06 05:09:49.405724: 
2025-10-06 05:09:49.406102: Epoch 142
2025-10-06 05:09:49.406297: Current learning rate: 0.00071
2025-10-06 05:10:35.914168: Validation loss did not improve from -0.45515. Patience: 101/50
2025-10-06 05:10:35.914979: train_loss -0.8535
2025-10-06 05:10:35.915145: val_loss -0.4291
2025-10-06 05:10:35.915329: Pseudo dice [np.float32(0.709)]
2025-10-06 05:10:35.915531: Epoch time: 46.51 s
2025-10-06 05:10:35.915711: Yayy! New best EMA pseudo Dice: 0.6970000267028809
2025-10-06 05:10:37.043746: 
2025-10-06 05:10:37.044064: Epoch 143
2025-10-06 05:10:37.044243: Current learning rate: 0.00063
2025-10-06 05:11:23.457029: Validation loss did not improve from -0.45515. Patience: 102/50
2025-10-06 05:11:23.457563: train_loss -0.8532
2025-10-06 05:11:23.457700: val_loss -0.3715
2025-10-06 05:11:23.457828: Pseudo dice [np.float32(0.6954)]
2025-10-06 05:11:23.457963: Epoch time: 46.41 s
2025-10-06 05:11:24.130541: 
2025-10-06 05:11:24.130763: Epoch 144
2025-10-06 05:11:24.130927: Current learning rate: 0.00055
2025-10-06 05:12:10.650237: Validation loss did not improve from -0.45515. Patience: 103/50
2025-10-06 05:12:10.650822: train_loss -0.8553
2025-10-06 05:12:10.650999: val_loss -0.4093
2025-10-06 05:12:10.651119: Pseudo dice [np.float32(0.6913)]
2025-10-06 05:12:10.651250: Epoch time: 46.52 s
2025-10-06 05:12:11.791632: 
2025-10-06 05:12:11.791991: Epoch 145
2025-10-06 05:12:11.792171: Current learning rate: 0.00047
2025-10-06 05:12:58.278564: Validation loss did not improve from -0.45515. Patience: 104/50
2025-10-06 05:12:58.279010: train_loss -0.8563
2025-10-06 05:12:58.279216: val_loss -0.4126
2025-10-06 05:12:58.279364: Pseudo dice [np.float32(0.7018)]
2025-10-06 05:12:58.279513: Epoch time: 46.49 s
2025-10-06 05:12:58.962006: 
2025-10-06 05:12:58.962367: Epoch 146
2025-10-06 05:12:58.962622: Current learning rate: 0.00038
2025-10-06 05:13:45.407118: Validation loss did not improve from -0.45515. Patience: 105/50
2025-10-06 05:13:45.407886: train_loss -0.8574
2025-10-06 05:13:45.408189: val_loss -0.3791
2025-10-06 05:13:45.408594: Pseudo dice [np.float32(0.6872)]
2025-10-06 05:13:45.408913: Epoch time: 46.45 s
2025-10-06 05:13:46.089764: 
2025-10-06 05:13:46.090177: Epoch 147
2025-10-06 05:13:46.090476: Current learning rate: 0.0003
2025-10-06 05:14:32.510202: Validation loss did not improve from -0.45515. Patience: 106/50
2025-10-06 05:14:32.510721: train_loss -0.8561
2025-10-06 05:14:32.510891: val_loss -0.3955
2025-10-06 05:14:32.511018: Pseudo dice [np.float32(0.7008)]
2025-10-06 05:14:32.511168: Epoch time: 46.42 s
2025-10-06 05:14:33.195001: 
2025-10-06 05:14:33.195294: Epoch 148
2025-10-06 05:14:33.195504: Current learning rate: 0.00021
2025-10-06 05:15:19.624378: Validation loss did not improve from -0.45515. Patience: 107/50
2025-10-06 05:15:19.625029: train_loss -0.8573
2025-10-06 05:15:19.625248: val_loss -0.422
2025-10-06 05:15:19.625432: Pseudo dice [np.float32(0.7051)]
2025-10-06 05:15:19.625581: Epoch time: 46.43 s
2025-10-06 05:15:19.625703: Yayy! New best EMA pseudo Dice: 0.6972000002861023
2025-10-06 05:15:21.354433: 
2025-10-06 05:15:21.354803: Epoch 149
2025-10-06 05:15:21.354986: Current learning rate: 0.00011
2025-10-06 05:16:07.863079: Validation loss did not improve from -0.45515. Patience: 108/50
2025-10-06 05:16:07.863693: train_loss -0.8546
2025-10-06 05:16:07.863845: val_loss -0.3598
2025-10-06 05:16:07.863972: Pseudo dice [np.float32(0.6886)]
2025-10-06 05:16:07.864168: Epoch time: 46.51 s
2025-10-06 05:16:09.038526: Training done.
2025-10-06 05:16:09.050730: Using splits from existing split file: /nfs/erelab001/shared/Computational_Group/Naravich/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset310_nnInteractive_Calcium_OCT_CrossValidation/splits_final_60.json
2025-10-06 05:16:09.051045: The split file contains 5 splits.
2025-10-06 05:16:09.051147: Desired fold for training: 4
2025-10-06 05:16:09.051239: This split has 4 training and 4 validation cases.
2025-10-06 05:16:09.051419: predicting 101-044
2025-10-06 05:16:09.053784: 101-044, shape torch.Size([1, 404, 498, 498]), rank 0
2025-10-06 05:16:59.937241: predicting 101-045
2025-10-06 05:16:59.952406: 101-045, shape torch.Size([1, 375, 498, 498]), rank 0
2025-10-06 05:17:34.288163: predicting 401-004
2025-10-06 05:17:34.301651: 401-004, shape torch.Size([1, 375, 498, 498]), rank 0
2025-10-06 05:18:09.058166: predicting 706-005
2025-10-06 05:18:09.069643: 706-005, shape torch.Size([1, 375, 498, 498]), rank 0
2025-10-06 05:18:57.202879: Validation complete
2025-10-06 05:18:57.203109: Mean Validation Dice:  0.6859949512626722
Finished training fold 4 saving to /nfs/erelab001/shared/Computational_Group/Naravich/datasets/nnUNet_Datasets/nnUNet_results/Dataset310_nnInteractive_Calcium_OCT_CrossValidation/nnUNetTrainerScaleAnalysis60__nnUNetPlans__3d_32x160x128_b10/fold_4_No_Pretrained
