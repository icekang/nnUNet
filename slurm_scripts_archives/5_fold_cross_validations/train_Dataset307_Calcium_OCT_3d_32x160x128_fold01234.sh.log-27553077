/home/gridsan/nchutisilp/.conda/envs/nnunet/bin/python

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2024-12-05 12:35:56.694748: do_dummy_2d_data_aug: True
2024-12-05 12:35:56.759376: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset307_Sohee_Calcium_OCT_CrossValidation/splits_final.json
2024-12-05 12:35:56.768746: The split file contains 5 splits.
2024-12-05 12:35:56.770450: Desired fold for training: 4
2024-12-05 12:35:56.771716: This split has 7 training and 1 validation cases.

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2024-12-05 12:35:56.694800: do_dummy_2d_data_aug: True
2024-12-05 12:35:56.759412: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset307_Sohee_Calcium_OCT_CrossValidation/splits_final.json
2024-12-05 12:35:56.768162: The split file contains 5 splits.
2024-12-05 12:35:56.770505: Desired fold for training: 2
2024-12-05 12:35:56.771689: This split has 6 training and 2 validation cases.
using pin_memory on device 0
using pin_memory on device 0
using pin_memory on device 0
2024-12-05 12:36:10.744249: Using torch.compile...
using pin_memory on device 0
2024-12-05 12:36:11.637058: Using torch.compile...
/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "

This is the configuration used by this training:
Configuration name: 3d_32x160x128_b10
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 10, 'patch_size': [32, 160, 128], 'median_image_size_in_voxels': [375.0, 498.0, 498.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'inherits_from': '3d_fullres'} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset307_Sohee_Calcium_OCT_CrossValidation', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.4977976381778717, 'mean': 0.13507525622844696, 'median': 0.09599608182907104, 'min': 0.0, 'percentile_00_5': 0.014754901640117168, 'percentile_99_5': 0.4977976381778717, 'std': 0.12025152146816254}}} 

2024-12-05 12:36:23.206275: unpacking dataset...

This is the configuration used by this training:
Configuration name: 3d_32x160x128_b10
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 10, 'patch_size': [32, 160, 128], 'median_image_size_in_voxels': [375.0, 498.0, 498.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'inherits_from': '3d_fullres'} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset307_Sohee_Calcium_OCT_CrossValidation', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.4977976381778717, 'mean': 0.13507525622844696, 'median': 0.09599608182907104, 'min': 0.0, 'percentile_00_5': 0.014754901640117168, 'percentile_99_5': 0.4977976381778717, 'std': 0.12025152146816254}}} 

2024-12-05 12:36:23.206404: unpacking dataset...
2024-12-05 12:36:28.882593: unpacking done...
2024-12-05 12:36:28.992651: Unable to plot network architecture: nnUNet_compile is enabled!
2024-12-05 12:36:29.364830: 
2024-12-05 12:36:29.365775: Epoch 0
2024-12-05 12:36:29.366592: Current learning rate: 0.01
2024-12-05 12:40:01.536582: Validation loss improved from 1000.00000 to -0.22348! Patience: 0/50
2024-12-05 12:40:01.568393: train_loss -0.0557
2024-12-05 12:40:01.572549: val_loss -0.2235
2024-12-05 12:40:01.573403: Pseudo dice [0.5602]
2024-12-05 12:40:01.574286: Epoch time: 212.17 s
2024-12-05 12:40:01.575045: Yayy! New best EMA pseudo Dice: 0.5602
2024-12-05 12:40:04.391269: 
2024-12-05 12:40:04.392909: Epoch 1
2024-12-05 12:40:04.394191: Current learning rate: 0.00999
2024-12-05 12:41:31.477031: Validation loss improved from -0.22348 to -0.27344! Patience: 0/50
2024-12-05 12:41:31.478106: train_loss -0.2166
2024-12-05 12:41:31.478903: val_loss -0.2734
2024-12-05 12:41:31.479482: Pseudo dice [0.5816]
2024-12-05 12:41:31.480196: Epoch time: 87.09 s
2024-12-05 12:41:31.480797: Yayy! New best EMA pseudo Dice: 0.5623
2024-12-05 12:41:33.051353: 
2024-12-05 12:41:33.052689: Epoch 2
2024-12-05 12:41:33.053380: Current learning rate: 0.00998
2024-12-05 12:42:59.893599: Validation loss improved from -0.27344 to -0.29172! Patience: 0/50
2024-12-05 12:42:59.894633: train_loss -0.2664
2024-12-05 12:42:59.895455: val_loss -0.2917
2024-12-05 12:42:59.896250: Pseudo dice [0.6078]
2024-12-05 12:42:59.896968: Epoch time: 86.84 s
2024-12-05 12:42:59.897740: Yayy! New best EMA pseudo Dice: 0.5669
2024-12-05 12:43:01.607454: 
2024-12-05 12:43:01.608834: Epoch 3
2024-12-05 12:43:01.609570: Current learning rate: 0.00997
2024-12-05 12:44:28.038242: Validation loss did not improve from -0.29172. Patience: 1/50
2024-12-05 12:44:28.039243: train_loss -0.3077
2024-12-05 12:44:28.040099: val_loss -0.2332
2024-12-05 12:44:28.040869: Pseudo dice [0.5891]
2024-12-05 12:44:28.041527: Epoch time: 86.43 s
2024-12-05 12:44:28.042165: Yayy! New best EMA pseudo Dice: 0.5691
2024-12-05 12:44:29.629169: 
2024-12-05 12:44:29.630605: Epoch 4
2024-12-05 12:44:29.631319: Current learning rate: 0.00996
2024-12-05 12:45:55.960662: Validation loss improved from -0.29172 to -0.34985! Patience: 1/50
2024-12-05 12:45:55.961863: train_loss -0.3342
2024-12-05 12:45:55.962957: val_loss -0.3498
2024-12-05 12:45:55.963845: Pseudo dice [0.6303]
2024-12-05 12:45:55.964534: Epoch time: 86.33 s
2024-12-05 12:45:56.289418: Yayy! New best EMA pseudo Dice: 0.5752
2024-12-05 12:45:58.021600: 
2024-12-05 12:45:58.023378: Epoch 5
2024-12-05 12:45:58.024187: Current learning rate: 0.00995
2024-12-05 12:47:24.373741: Validation loss did not improve from -0.34985. Patience: 1/50
2024-12-05 12:47:24.376113: train_loss -0.3704
2024-12-05 12:47:24.377363: val_loss -0.347
2024-12-05 12:47:24.378030: Pseudo dice [0.6442]
2024-12-05 12:47:24.378942: Epoch time: 86.36 s
2024-12-05 12:47:24.379606: Yayy! New best EMA pseudo Dice: 0.5821
2024-12-05 12:47:25.999710: 
2024-12-05 12:47:26.001580: Epoch 6
2024-12-05 12:47:26.002529: Current learning rate: 0.00995
2024-12-05 12:48:52.210024: Validation loss did not improve from -0.34985. Patience: 2/50
2024-12-05 12:48:52.211097: train_loss -0.3969
2024-12-05 12:48:52.212052: val_loss -0.3039
2024-12-05 12:48:52.212981: Pseudo dice [0.6293]
2024-12-05 12:48:52.213876: Epoch time: 86.21 s
2024-12-05 12:48:52.214648: Yayy! New best EMA pseudo Dice: 0.5868
2024-12-05 12:48:53.926766: 
2024-12-05 12:48:53.928243: Epoch 7
2024-12-05 12:48:53.929206: Current learning rate: 0.00994
2024-12-05 12:50:20.118975: Validation loss improved from -0.34985 to -0.39486! Patience: 2/50
2024-12-05 12:50:20.120139: train_loss -0.4125
2024-12-05 12:50:20.121160: val_loss -0.3949
2024-12-05 12:50:20.121917: Pseudo dice [0.6608]
2024-12-05 12:50:20.122608: Epoch time: 86.2 s
2024-12-05 12:50:20.123350: Yayy! New best EMA pseudo Dice: 0.5942
2024-12-05 12:50:22.545200: 
2024-12-05 12:50:22.547022: Epoch 8
2024-12-05 12:50:22.547786: Current learning rate: 0.00993
2024-12-05 12:51:48.973085: Validation loss did not improve from -0.39486. Patience: 1/50
2024-12-05 12:51:48.974150: train_loss -0.4202
2024-12-05 12:51:48.975154: val_loss -0.378
2024-12-05 12:51:48.975842: Pseudo dice [0.6404]
2024-12-05 12:51:48.976730: Epoch time: 86.43 s
2024-12-05 12:51:48.977513: Yayy! New best EMA pseudo Dice: 0.5989
2024-12-05 12:51:50.631665: 
2024-12-05 12:51:50.633149: Epoch 9
2024-12-05 12:51:50.633982: Current learning rate: 0.00992
2024-12-05 12:53:17.212179: Validation loss did not improve from -0.39486. Patience: 2/50
2024-12-05 12:53:17.214144: train_loss -0.452
2024-12-05 12:53:17.221544: val_loss -0.3502
2024-12-05 12:53:17.222475: Pseudo dice [0.6358]
2024-12-05 12:53:17.223231: Epoch time: 86.58 s
2024-12-05 12:53:17.613835: Yayy! New best EMA pseudo Dice: 0.6026
2024-12-05 12:53:19.197842: 
2024-12-05 12:53:19.199380: Epoch 10
2024-12-05 12:53:19.200120: Current learning rate: 0.00991
2024-12-05 12:54:45.688698: Validation loss improved from -0.39486 to -0.41257! Patience: 2/50
2024-12-05 12:54:45.690636: train_loss -0.4517
2024-12-05 12:54:45.691597: val_loss -0.4126
2024-12-05 12:54:45.692528: Pseudo dice [0.6639]
2024-12-05 12:54:45.693509: Epoch time: 86.49 s
2024-12-05 12:54:45.694261: Yayy! New best EMA pseudo Dice: 0.6087
2024-12-05 12:54:47.302309: 
2024-12-05 12:54:47.303857: Epoch 11
2024-12-05 12:54:47.304544: Current learning rate: 0.0099
2024-12-05 12:56:13.679734: Validation loss did not improve from -0.41257. Patience: 1/50
2024-12-05 12:56:13.680795: train_loss -0.4602
2024-12-05 12:56:13.681838: val_loss -0.389
2024-12-05 12:56:13.682742: Pseudo dice [0.6663]
2024-12-05 12:56:13.683670: Epoch time: 86.38 s
2024-12-05 12:56:13.684483: Yayy! New best EMA pseudo Dice: 0.6144
2024-12-05 12:56:15.309261: 
2024-12-05 12:56:15.311225: Epoch 12
2024-12-05 12:56:15.312258: Current learning rate: 0.00989
2024-12-05 12:57:41.606775: Validation loss improved from -0.41257 to -0.44373! Patience: 1/50
2024-12-05 12:57:41.607857: train_loss -0.4641
2024-12-05 12:57:41.609053: val_loss -0.4437
2024-12-05 12:57:41.610349: Pseudo dice [0.6842]
2024-12-05 12:57:41.611440: Epoch time: 86.3 s
2024-12-05 12:57:41.612525: Yayy! New best EMA pseudo Dice: 0.6214
2024-12-05 12:57:43.272401: 
2024-12-05 12:57:43.274438: Epoch 13
2024-12-05 12:57:43.275481: Current learning rate: 0.00988
2024-12-05 12:59:09.777534: Validation loss did not improve from -0.44373. Patience: 1/50
2024-12-05 12:59:09.778728: train_loss -0.4717
2024-12-05 12:59:09.779565: val_loss -0.4005
2024-12-05 12:59:09.780363: Pseudo dice [0.6699]
2024-12-05 12:59:09.781138: Epoch time: 86.51 s
2024-12-05 12:59:09.781854: Yayy! New best EMA pseudo Dice: 0.6263
2024-12-05 12:59:11.456129: 
2024-12-05 12:59:11.458073: Epoch 14
2024-12-05 12:59:11.458841: Current learning rate: 0.00987
2024-12-05 13:00:37.890694: Validation loss improved from -0.44373 to -0.47411! Patience: 1/50
2024-12-05 13:00:37.892000: train_loss -0.4882
2024-12-05 13:00:37.893112: val_loss -0.4741
2024-12-05 13:00:37.893821: Pseudo dice [0.7018]
2024-12-05 13:00:37.894495: Epoch time: 86.44 s
2024-12-05 13:00:38.295429: Yayy! New best EMA pseudo Dice: 0.6338
2024-12-05 13:00:40.037258: 
2024-12-05 13:00:40.038897: Epoch 15
2024-12-05 13:00:40.039771: Current learning rate: 0.00986
2024-12-05 13:02:06.465019: Validation loss did not improve from -0.47411. Patience: 1/50
2024-12-05 13:02:06.467161: train_loss -0.496
2024-12-05 13:02:06.468156: val_loss -0.3893
2024-12-05 13:02:06.468936: Pseudo dice [0.654]
2024-12-05 13:02:06.469710: Epoch time: 86.43 s
2024-12-05 13:02:06.470419: Yayy! New best EMA pseudo Dice: 0.6358
2024-12-05 13:02:08.136607: 
2024-12-05 13:02:08.138095: Epoch 16
2024-12-05 13:02:08.139018: Current learning rate: 0.00986
2024-12-05 13:03:34.639760: Validation loss did not improve from -0.47411. Patience: 2/50
2024-12-05 13:03:34.640857: train_loss -0.5076
2024-12-05 13:03:34.641761: val_loss -0.4042
2024-12-05 13:03:34.642735: Pseudo dice [0.6621]
2024-12-05 13:03:34.643497: Epoch time: 86.51 s
2024-12-05 13:03:34.644274: Yayy! New best EMA pseudo Dice: 0.6385
2024-12-05 13:03:36.362034: 
2024-12-05 13:03:36.363287: Epoch 17
2024-12-05 13:03:36.364193: Current learning rate: 0.00985
2024-12-05 13:05:03.095263: Validation loss did not improve from -0.47411. Patience: 3/50
2024-12-05 13:05:03.096677: train_loss -0.4976
2024-12-05 13:05:03.097784: val_loss -0.4661
2024-12-05 13:05:03.098518: Pseudo dice [0.6956]
2024-12-05 13:05:03.099229: Epoch time: 86.74 s
2024-12-05 13:05:03.099995: Yayy! New best EMA pseudo Dice: 0.6442
2024-12-05 13:05:04.820309: 
2024-12-05 13:05:04.822002: Epoch 18
2024-12-05 13:05:04.822961: Current learning rate: 0.00984
2024-12-05 13:06:31.329737: Validation loss did not improve from -0.47411. Patience: 4/50
2024-12-05 13:06:31.330857: train_loss -0.5145
2024-12-05 13:06:31.332034: val_loss -0.4112
2024-12-05 13:06:31.332740: Pseudo dice [0.678]
2024-12-05 13:06:31.333589: Epoch time: 86.51 s
2024-12-05 13:06:31.334322: Yayy! New best EMA pseudo Dice: 0.6476
2024-12-05 13:06:33.635346: 
2024-12-05 13:06:33.636867: Epoch 19
2024-12-05 13:06:33.637502: Current learning rate: 0.00983
2024-12-05 13:08:00.029682: Validation loss did not improve from -0.47411. Patience: 5/50
2024-12-05 13:08:00.030641: train_loss -0.5286
2024-12-05 13:08:00.031540: val_loss -0.4014
2024-12-05 13:08:00.032387: Pseudo dice [0.6677]
2024-12-05 13:08:00.033329: Epoch time: 86.4 s
2024-12-05 13:08:00.415295: Yayy! New best EMA pseudo Dice: 0.6496
2024-12-05 13:08:02.077953: 
2024-12-05 13:08:02.079712: Epoch 20
2024-12-05 13:08:02.080719: Current learning rate: 0.00982
2024-12-05 13:09:28.664357: Validation loss did not improve from -0.47411. Patience: 6/50
2024-12-05 13:09:28.665752: train_loss -0.522
2024-12-05 13:09:28.667196: val_loss -0.404
2024-12-05 13:09:28.668188: Pseudo dice [0.667]
2024-12-05 13:09:28.668879: Epoch time: 86.59 s
2024-12-05 13:09:28.669692: Yayy! New best EMA pseudo Dice: 0.6513
2024-12-05 13:09:30.338220: 
2024-12-05 13:09:30.339345: Epoch 21
2024-12-05 13:09:30.340056: Current learning rate: 0.00981
2024-12-05 13:10:56.888074: Validation loss did not improve from -0.47411. Patience: 7/50
2024-12-05 13:10:56.888992: train_loss -0.5388
2024-12-05 13:10:56.889738: val_loss -0.4099
2024-12-05 13:10:56.890552: Pseudo dice [0.6808]
2024-12-05 13:10:56.891265: Epoch time: 86.55 s
2024-12-05 13:10:56.892024: Yayy! New best EMA pseudo Dice: 0.6543
2024-12-05 13:10:58.506867: 
2024-12-05 13:10:58.508794: Epoch 22
2024-12-05 13:10:58.509902: Current learning rate: 0.0098
2024-12-05 13:12:25.045078: Validation loss did not improve from -0.47411. Patience: 8/50
2024-12-05 13:12:25.046365: train_loss -0.5355
2024-12-05 13:12:25.047307: val_loss -0.4624
2024-12-05 13:12:25.048067: Pseudo dice [0.6943]
2024-12-05 13:12:25.048756: Epoch time: 86.54 s
2024-12-05 13:12:25.049364: Yayy! New best EMA pseudo Dice: 0.6583
2024-12-05 13:12:26.698564: 
2024-12-05 13:12:26.699997: Epoch 23
2024-12-05 13:12:26.700651: Current learning rate: 0.00979
2024-12-05 13:13:53.179105: Validation loss did not improve from -0.47411. Patience: 9/50
2024-12-05 13:13:53.180239: train_loss -0.5481
2024-12-05 13:13:53.181120: val_loss -0.4488
2024-12-05 13:13:53.181942: Pseudo dice [0.7022]
2024-12-05 13:13:53.182606: Epoch time: 86.48 s
2024-12-05 13:13:53.183305: Yayy! New best EMA pseudo Dice: 0.6627
2024-12-05 13:13:54.767477: 
2024-12-05 13:13:54.768664: Epoch 24
2024-12-05 13:13:54.769335: Current learning rate: 0.00978
2024-12-05 13:15:21.363849: Validation loss did not improve from -0.47411. Patience: 10/50
2024-12-05 13:15:21.366227: train_loss -0.5586
2024-12-05 13:15:21.368963: val_loss -0.4637
2024-12-05 13:15:21.370003: Pseudo dice [0.7003]
2024-12-05 13:15:21.370991: Epoch time: 86.6 s
2024-12-05 13:15:21.763894: Yayy! New best EMA pseudo Dice: 0.6664
2024-12-05 13:15:23.399712: 
2024-12-05 13:15:23.401285: Epoch 25
2024-12-05 13:15:23.402365: Current learning rate: 0.00977
2024-12-05 13:16:49.893024: Validation loss did not improve from -0.47411. Patience: 11/50
2024-12-05 13:16:49.894248: train_loss -0.5516
2024-12-05 13:16:49.895065: val_loss -0.4663
2024-12-05 13:16:49.895810: Pseudo dice [0.6986]
2024-12-05 13:16:49.896441: Epoch time: 86.5 s
2024-12-05 13:16:49.897141: Yayy! New best EMA pseudo Dice: 0.6696
2024-12-05 13:16:51.525769: 
2024-12-05 13:16:51.527347: Epoch 26
2024-12-05 13:16:51.528204: Current learning rate: 0.00977
2024-12-05 13:18:18.008038: Validation loss did not improve from -0.47411. Patience: 12/50
2024-12-05 13:18:18.009231: train_loss -0.5522
2024-12-05 13:18:18.010164: val_loss -0.459
2024-12-05 13:18:18.010876: Pseudo dice [0.6867]
2024-12-05 13:18:18.011615: Epoch time: 86.48 s
2024-12-05 13:18:18.012390: Yayy! New best EMA pseudo Dice: 0.6713
2024-12-05 13:18:19.680362: 
2024-12-05 13:18:19.681965: Epoch 27
2024-12-05 13:18:19.682723: Current learning rate: 0.00976
2024-12-05 13:19:46.123966: Validation loss did not improve from -0.47411. Patience: 13/50
2024-12-05 13:19:46.125202: train_loss -0.5584
2024-12-05 13:19:46.126063: val_loss -0.4138
2024-12-05 13:19:46.126904: Pseudo dice [0.6662]
2024-12-05 13:19:46.127625: Epoch time: 86.45 s
2024-12-05 13:19:47.420937: 
2024-12-05 13:19:47.422413: Epoch 28
2024-12-05 13:19:47.423309: Current learning rate: 0.00975
2024-12-05 13:21:13.844435: Validation loss did not improve from -0.47411. Patience: 14/50
2024-12-05 13:21:13.845612: train_loss -0.5581
2024-12-05 13:21:13.846317: val_loss -0.4573
2024-12-05 13:21:13.846928: Pseudo dice [0.6937]
2024-12-05 13:21:13.847570: Epoch time: 86.43 s
2024-12-05 13:21:13.848290: Yayy! New best EMA pseudo Dice: 0.6731
2024-12-05 13:21:15.919508: 
2024-12-05 13:21:15.920720: Epoch 29
2024-12-05 13:21:15.921401: Current learning rate: 0.00974
2024-12-05 13:22:42.391291: Validation loss did not improve from -0.47411. Patience: 15/50
2024-12-05 13:22:42.392663: train_loss -0.563
2024-12-05 13:22:42.393522: val_loss -0.4627
2024-12-05 13:22:42.394519: Pseudo dice [0.703]
2024-12-05 13:22:42.395504: Epoch time: 86.47 s
2024-12-05 13:22:42.775676: Yayy! New best EMA pseudo Dice: 0.6761
2024-12-05 13:22:44.429585: 
2024-12-05 13:22:44.431188: Epoch 30
2024-12-05 13:22:44.432355: Current learning rate: 0.00973
2024-12-05 13:24:10.816867: Validation loss improved from -0.47411 to -0.47677! Patience: 15/50
2024-12-05 13:24:10.818085: train_loss -0.5602
2024-12-05 13:24:10.818923: val_loss -0.4768
2024-12-05 13:24:10.819646: Pseudo dice [0.7081]
2024-12-05 13:24:10.820339: Epoch time: 86.39 s
2024-12-05 13:24:10.820960: Yayy! New best EMA pseudo Dice: 0.6793
2024-12-05 13:24:12.464502: 
2024-12-05 13:24:12.466481: Epoch 31
2024-12-05 13:24:12.467314: Current learning rate: 0.00972
2024-12-05 13:25:38.996552: Validation loss did not improve from -0.47677. Patience: 1/50
2024-12-05 13:25:38.997792: train_loss -0.577
2024-12-05 13:25:38.998758: val_loss -0.4576
2024-12-05 13:25:38.999638: Pseudo dice [0.6883]
2024-12-05 13:25:39.000288: Epoch time: 86.53 s
2024-12-05 13:25:39.001010: Yayy! New best EMA pseudo Dice: 0.6802
2024-12-05 13:25:40.674427: 
2024-12-05 13:25:40.676040: Epoch 32
2024-12-05 13:25:40.677050: Current learning rate: 0.00971
2024-12-05 13:27:07.232318: Validation loss did not improve from -0.47677. Patience: 2/50
2024-12-05 13:27:07.233299: train_loss -0.5713
2024-12-05 13:27:07.234179: val_loss -0.4731
2024-12-05 13:27:07.235112: Pseudo dice [0.701]
2024-12-05 13:27:07.236016: Epoch time: 86.56 s
2024-12-05 13:27:07.236906: Yayy! New best EMA pseudo Dice: 0.6823
2024-12-05 13:27:08.927013: 
2024-12-05 13:27:08.928515: Epoch 33
2024-12-05 13:27:08.929233: Current learning rate: 0.0097
2024-12-05 13:28:35.487638: Validation loss did not improve from -0.47677. Patience: 3/50
2024-12-05 13:28:35.488939: train_loss -0.5858
2024-12-05 13:28:35.490177: val_loss -0.4309
2024-12-05 13:28:35.491067: Pseudo dice [0.6932]
2024-12-05 13:28:35.491762: Epoch time: 86.56 s
2024-12-05 13:28:35.492466: Yayy! New best EMA pseudo Dice: 0.6834
2024-12-05 13:28:37.199613: 
2024-12-05 13:28:37.201169: Epoch 34
2024-12-05 13:28:37.202091: Current learning rate: 0.00969
2024-12-05 13:30:03.803064: Validation loss did not improve from -0.47677. Patience: 4/50
2024-12-05 13:30:03.804106: train_loss -0.5882
2024-12-05 13:30:03.805274: val_loss -0.4752
2024-12-05 13:30:03.806062: Pseudo dice [0.7019]
2024-12-05 13:30:03.806743: Epoch time: 86.61 s
2024-12-05 13:30:04.198474: Yayy! New best EMA pseudo Dice: 0.6852
2024-12-05 13:30:05.914383: 
2024-12-05 13:30:05.915656: Epoch 35
2024-12-05 13:30:05.916384: Current learning rate: 0.00968
2024-12-05 13:31:32.415164: Validation loss improved from -0.47677 to -0.49260! Patience: 4/50
2024-12-05 13:31:32.416493: train_loss -0.5853
2024-12-05 13:31:32.417332: val_loss -0.4926
2024-12-05 13:31:32.418055: Pseudo dice [0.7156]
2024-12-05 13:31:32.418811: Epoch time: 86.5 s
2024-12-05 13:31:32.419485: Yayy! New best EMA pseudo Dice: 0.6883
2024-12-05 13:31:34.114499: 
2024-12-05 13:31:34.115840: Epoch 36
2024-12-05 13:31:34.116611: Current learning rate: 0.00968
2024-12-05 13:33:00.599871: Validation loss did not improve from -0.49260. Patience: 1/50
2024-12-05 13:33:00.600963: train_loss -0.604
2024-12-05 13:33:00.601918: val_loss -0.4591
2024-12-05 13:33:00.602602: Pseudo dice [0.6894]
2024-12-05 13:33:00.603310: Epoch time: 86.49 s
2024-12-05 13:33:00.603991: Yayy! New best EMA pseudo Dice: 0.6884
2024-12-05 13:33:02.334163: 
2024-12-05 13:33:02.335400: Epoch 37
2024-12-05 13:33:02.336185: Current learning rate: 0.00967
2024-12-05 13:34:29.138335: Validation loss did not improve from -0.49260. Patience: 2/50
2024-12-05 13:34:29.139664: train_loss -0.5996
2024-12-05 13:34:29.140334: val_loss -0.444
2024-12-05 13:34:29.140966: Pseudo dice [0.6939]
2024-12-05 13:34:29.141588: Epoch time: 86.81 s
2024-12-05 13:34:29.142148: Yayy! New best EMA pseudo Dice: 0.6889
2024-12-05 13:34:30.853562: 
2024-12-05 13:34:30.854994: Epoch 38
2024-12-05 13:34:30.855928: Current learning rate: 0.00966
2024-12-05 13:35:57.573040: Validation loss did not improve from -0.49260. Patience: 3/50
2024-12-05 13:35:57.574383: train_loss -0.5888
2024-12-05 13:35:57.575727: val_loss -0.4875
2024-12-05 13:35:57.576739: Pseudo dice [0.711]
2024-12-05 13:35:57.577729: Epoch time: 86.72 s
2024-12-05 13:35:57.578659: Yayy! New best EMA pseudo Dice: 0.6911
2024-12-05 13:35:59.780064: 
2024-12-05 13:35:59.781618: Epoch 39
2024-12-05 13:35:59.782506: Current learning rate: 0.00965
2024-12-05 13:37:26.214612: Validation loss did not improve from -0.49260. Patience: 4/50
2024-12-05 13:37:26.216275: train_loss -0.6021
2024-12-05 13:37:26.217288: val_loss -0.4904
2024-12-05 13:37:26.218047: Pseudo dice [0.7115]
2024-12-05 13:37:26.218715: Epoch time: 86.44 s
2024-12-05 13:37:26.794873: Yayy! New best EMA pseudo Dice: 0.6932
2024-12-05 13:37:28.465543: 
2024-12-05 13:37:28.467204: Epoch 40
2024-12-05 13:37:28.468119: Current learning rate: 0.00964
2024-12-05 13:38:54.865890: Validation loss did not improve from -0.49260. Patience: 5/50
2024-12-05 13:38:54.867332: train_loss -0.606
2024-12-05 13:38:54.868573: val_loss -0.4726
2024-12-05 13:38:54.869508: Pseudo dice [0.7125]
2024-12-05 13:38:54.870409: Epoch time: 86.4 s
2024-12-05 13:38:54.871150: Yayy! New best EMA pseudo Dice: 0.6951
2024-12-05 13:38:56.621529: 
2024-12-05 13:38:56.623411: Epoch 41
2024-12-05 13:38:56.624323: Current learning rate: 0.00963
2024-12-05 13:40:23.263119: Validation loss did not improve from -0.49260. Patience: 6/50
2024-12-05 13:40:23.264378: train_loss -0.601
2024-12-05 13:40:23.265429: val_loss -0.4721
2024-12-05 13:40:23.266330: Pseudo dice [0.7]
2024-12-05 13:40:23.267152: Epoch time: 86.64 s
2024-12-05 13:40:23.267851: Yayy! New best EMA pseudo Dice: 0.6956
2024-12-05 13:40:24.874346: 
2024-12-05 13:40:24.876141: Epoch 42
2024-12-05 13:40:24.877053: Current learning rate: 0.00962
2024-12-05 13:41:51.810396: Validation loss did not improve from -0.49260. Patience: 7/50
2024-12-05 13:41:51.811492: train_loss -0.6103
2024-12-05 13:41:51.812377: val_loss -0.4662
2024-12-05 13:41:51.813062: Pseudo dice [0.6977]
2024-12-05 13:41:51.813680: Epoch time: 86.94 s
2024-12-05 13:41:51.814529: Yayy! New best EMA pseudo Dice: 0.6958
2024-12-05 13:41:53.494819: 
2024-12-05 13:41:53.496589: Epoch 43
2024-12-05 13:41:53.497580: Current learning rate: 0.00961
2024-12-05 13:43:20.082295: Validation loss did not improve from -0.49260. Patience: 8/50
2024-12-05 13:43:20.099664: train_loss -0.6098
2024-12-05 13:43:20.100916: val_loss -0.468
2024-12-05 13:43:20.101735: Pseudo dice [0.7057]
2024-12-05 13:43:20.102683: Epoch time: 86.61 s
2024-12-05 13:43:20.103708: Yayy! New best EMA pseudo Dice: 0.6968
2024-12-05 13:43:21.902419: 
2024-12-05 13:43:21.903949: Epoch 44
2024-12-05 13:43:21.904799: Current learning rate: 0.0096
2024-12-05 13:44:48.311420: Validation loss did not improve from -0.49260. Patience: 9/50
2024-12-05 13:44:48.312691: train_loss -0.608
2024-12-05 13:44:48.314020: val_loss -0.462
2024-12-05 13:44:48.315063: Pseudo dice [0.7006]
2024-12-05 13:44:48.316002: Epoch time: 86.41 s
2024-12-05 13:44:48.748205: Yayy! New best EMA pseudo Dice: 0.6972
2024-12-05 13:44:50.475105: 
2024-12-05 13:44:50.476520: Epoch 45
2024-12-05 13:44:50.477401: Current learning rate: 0.00959
2024-12-05 13:46:17.222128: Validation loss improved from -0.49260 to -0.51113! Patience: 9/50
2024-12-05 13:46:17.223305: train_loss -0.6174
2024-12-05 13:46:17.225327: val_loss -0.5111
2024-12-05 13:46:17.226212: Pseudo dice [0.731]
2024-12-05 13:46:17.227259: Epoch time: 86.75 s
2024-12-05 13:46:17.228114: Yayy! New best EMA pseudo Dice: 0.7006
2024-12-05 13:46:18.883519: 
2024-12-05 13:46:18.885121: Epoch 46
2024-12-05 13:46:18.886105: Current learning rate: 0.00959
2024-12-05 13:47:45.497035: Validation loss did not improve from -0.51113. Patience: 1/50
2024-12-05 13:47:45.498486: train_loss -0.6158
2024-12-05 13:47:45.499668: val_loss -0.4635
2024-12-05 13:47:45.500372: Pseudo dice [0.6946]
2024-12-05 13:47:45.501053: Epoch time: 86.62 s
2024-12-05 13:47:46.739211: 
2024-12-05 13:47:46.740686: Epoch 47
2024-12-05 13:47:46.741510: Current learning rate: 0.00958
2024-12-05 13:49:13.202857: Validation loss did not improve from -0.51113. Patience: 2/50
2024-12-05 13:49:13.204211: train_loss -0.6261
2024-12-05 13:49:13.205053: val_loss -0.457
2024-12-05 13:49:13.205891: Pseudo dice [0.7022]
2024-12-05 13:49:13.206571: Epoch time: 86.47 s
2024-12-05 13:49:14.451918: 
2024-12-05 13:49:14.453520: Epoch 48
2024-12-05 13:49:14.454206: Current learning rate: 0.00957
2024-12-05 13:50:40.890539: Validation loss did not improve from -0.51113. Patience: 3/50
2024-12-05 13:50:40.891684: train_loss -0.618
2024-12-05 13:50:40.892547: val_loss -0.455
2024-12-05 13:50:40.893201: Pseudo dice [0.6943]
2024-12-05 13:50:40.893968: Epoch time: 86.44 s
2024-12-05 13:50:42.155011: 
2024-12-05 13:50:42.156715: Epoch 49
2024-12-05 13:50:42.157406: Current learning rate: 0.00956
2024-12-05 13:52:08.642193: Validation loss did not improve from -0.51113. Patience: 4/50
2024-12-05 13:52:08.643264: train_loss -0.6088
2024-12-05 13:52:08.644298: val_loss -0.4873
2024-12-05 13:52:08.645095: Pseudo dice [0.722]
2024-12-05 13:52:08.646057: Epoch time: 86.49 s
2024-12-05 13:52:09.029383: Yayy! New best EMA pseudo Dice: 0.7018
2024-12-05 13:52:11.094959: 
2024-12-05 13:52:11.096916: Epoch 50
2024-12-05 13:52:11.097694: Current learning rate: 0.00955
2024-12-05 13:53:37.980237: Validation loss did not improve from -0.51113. Patience: 5/50
2024-12-05 13:53:37.981545: train_loss -0.6335
2024-12-05 13:53:37.982550: val_loss -0.4862
2024-12-05 13:53:37.983308: Pseudo dice [0.709]
2024-12-05 13:53:37.984102: Epoch time: 86.89 s
2024-12-05 13:53:37.984796: Yayy! New best EMA pseudo Dice: 0.7026
2024-12-05 13:53:39.592007: 
2024-12-05 13:53:39.593362: Epoch 51
2024-12-05 13:53:39.594175: Current learning rate: 0.00954
2024-12-05 13:55:06.383663: Validation loss improved from -0.51113 to -0.51933! Patience: 5/50
2024-12-05 13:55:06.384869: train_loss -0.6258
2024-12-05 13:55:06.386174: val_loss -0.5193
2024-12-05 13:55:06.386912: Pseudo dice [0.7278]
2024-12-05 13:55:06.387914: Epoch time: 86.79 s
2024-12-05 13:55:06.388833: Yayy! New best EMA pseudo Dice: 0.7051
2024-12-05 13:55:07.992795: 
2024-12-05 13:55:07.994093: Epoch 52
2024-12-05 13:55:07.994786: Current learning rate: 0.00953
2024-12-05 13:56:34.900916: Validation loss did not improve from -0.51933. Patience: 1/50
2024-12-05 13:56:34.902231: train_loss -0.6396
2024-12-05 13:56:34.903099: val_loss -0.4818
2024-12-05 13:56:34.903892: Pseudo dice [0.7158]
2024-12-05 13:56:34.904742: Epoch time: 86.91 s
2024-12-05 13:56:34.905623: Yayy! New best EMA pseudo Dice: 0.7061
2024-12-05 13:56:36.543699: 
2024-12-05 13:56:36.544853: Epoch 53
2024-12-05 13:56:36.545612: Current learning rate: 0.00952
2024-12-05 13:58:03.074263: Validation loss did not improve from -0.51933. Patience: 2/50
2024-12-05 13:58:03.075651: train_loss -0.6283
2024-12-05 13:58:03.076568: val_loss -0.4877
2024-12-05 13:58:03.077466: Pseudo dice [0.7085]
2024-12-05 13:58:03.078143: Epoch time: 86.53 s
2024-12-05 13:58:03.078812: Yayy! New best EMA pseudo Dice: 0.7064
2024-12-05 13:58:04.673568: 
2024-12-05 13:58:04.675201: Epoch 54
2024-12-05 13:58:04.676077: Current learning rate: 0.00951
2024-12-05 13:59:31.377788: Validation loss did not improve from -0.51933. Patience: 3/50
2024-12-05 13:59:31.379013: train_loss -0.6376
2024-12-05 13:59:31.379996: val_loss -0.5108
2024-12-05 13:59:31.380633: Pseudo dice [0.7332]
2024-12-05 13:59:31.381263: Epoch time: 86.71 s
2024-12-05 13:59:31.811691: Yayy! New best EMA pseudo Dice: 0.7091
2024-12-05 13:59:33.427537: 
2024-12-05 13:59:33.429180: Epoch 55
2024-12-05 13:59:33.429888: Current learning rate: 0.0095
2024-12-05 14:01:00.110426: Validation loss did not improve from -0.51933. Patience: 4/50
2024-12-05 14:01:00.111351: train_loss -0.6397
2024-12-05 14:01:00.112266: val_loss -0.4968
2024-12-05 14:01:00.113206: Pseudo dice [0.7254]
2024-12-05 14:01:00.114046: Epoch time: 86.68 s
2024-12-05 14:01:00.115073: Yayy! New best EMA pseudo Dice: 0.7107
2024-12-05 14:01:01.719468: 
2024-12-05 14:01:01.721222: Epoch 56
2024-12-05 14:01:01.722695: Current learning rate: 0.00949
2024-12-05 14:02:28.422744: Validation loss did not improve from -0.51933. Patience: 5/50
2024-12-05 14:02:28.424070: train_loss -0.6427
2024-12-05 14:02:28.424862: val_loss -0.5053
2024-12-05 14:02:28.425588: Pseudo dice [0.7219]
2024-12-05 14:02:28.426329: Epoch time: 86.71 s
2024-12-05 14:02:28.426994: Yayy! New best EMA pseudo Dice: 0.7118
2024-12-05 14:02:30.090817: 
2024-12-05 14:02:30.092291: Epoch 57
2024-12-05 14:02:30.093115: Current learning rate: 0.00949
2024-12-05 14:03:56.805961: Validation loss did not improve from -0.51933. Patience: 6/50
2024-12-05 14:03:56.807347: train_loss -0.6475
2024-12-05 14:03:56.808225: val_loss -0.4817
2024-12-05 14:03:56.809009: Pseudo dice [0.707]
2024-12-05 14:03:56.809876: Epoch time: 86.72 s
2024-12-05 14:03:58.119263: 
2024-12-05 14:03:58.120915: Epoch 58
2024-12-05 14:03:58.121599: Current learning rate: 0.00948
2024-12-05 14:05:24.771019: Validation loss did not improve from -0.51933. Patience: 7/50
2024-12-05 14:05:24.772098: train_loss -0.6511
2024-12-05 14:05:24.773273: val_loss -0.4559
2024-12-05 14:05:24.774186: Pseudo dice [0.712]
2024-12-05 14:05:24.774914: Epoch time: 86.65 s
2024-12-05 14:05:26.040948: 
2024-12-05 14:05:26.042550: Epoch 59
2024-12-05 14:05:26.043409: Current learning rate: 0.00947
2024-12-05 14:06:52.880066: Validation loss did not improve from -0.51933. Patience: 8/50
2024-12-05 14:06:52.880849: train_loss -0.6525
2024-12-05 14:06:52.881691: val_loss -0.4607
2024-12-05 14:06:52.882603: Pseudo dice [0.7088]
2024-12-05 14:06:52.883326: Epoch time: 86.84 s
2024-12-05 14:06:54.568508: 
2024-12-05 14:06:54.570091: Epoch 60
2024-12-05 14:06:54.570868: Current learning rate: 0.00946
2024-12-05 14:08:21.453949: Validation loss did not improve from -0.51933. Patience: 9/50
2024-12-05 14:08:21.455085: train_loss -0.6554
2024-12-05 14:08:21.455942: val_loss -0.5085
2024-12-05 14:08:21.456590: Pseudo dice [0.7237]
2024-12-05 14:08:21.457230: Epoch time: 86.89 s
2024-12-05 14:08:21.457882: Yayy! New best EMA pseudo Dice: 0.7124
2024-12-05 14:08:23.443003: 
2024-12-05 14:08:23.444382: Epoch 61
2024-12-05 14:08:23.445074: Current learning rate: 0.00945
2024-12-05 14:09:49.963579: Validation loss did not improve from -0.51933. Patience: 10/50
2024-12-05 14:09:49.964783: train_loss -0.6564
2024-12-05 14:09:49.965624: val_loss -0.5152
2024-12-05 14:09:49.966262: Pseudo dice [0.7362]
2024-12-05 14:09:49.966840: Epoch time: 86.52 s
2024-12-05 14:09:49.967486: Yayy! New best EMA pseudo Dice: 0.7148
2024-12-05 14:09:51.610748: 
2024-12-05 14:09:51.612413: Epoch 62
2024-12-05 14:09:51.613186: Current learning rate: 0.00944
2024-12-05 14:11:18.674334: Validation loss did not improve from -0.51933. Patience: 11/50
2024-12-05 14:11:18.675339: train_loss -0.6538
2024-12-05 14:11:18.676178: val_loss -0.4785
2024-12-05 14:11:18.676932: Pseudo dice [0.7067]
2024-12-05 14:11:18.677713: Epoch time: 87.07 s
2024-12-05 14:11:19.986455: 
2024-12-05 14:11:19.988186: Epoch 63
2024-12-05 14:11:19.989151: Current learning rate: 0.00943
2024-12-05 14:12:46.891052: Validation loss did not improve from -0.51933. Patience: 12/50
2024-12-05 14:12:46.892339: train_loss -0.659
2024-12-05 14:12:46.893465: val_loss -0.5006
2024-12-05 14:12:46.894332: Pseudo dice [0.7244]
2024-12-05 14:12:46.895118: Epoch time: 86.91 s
2024-12-05 14:12:46.895780: Yayy! New best EMA pseudo Dice: 0.715
2024-12-05 14:12:48.603666: 
2024-12-05 14:12:48.605570: Epoch 64
2024-12-05 14:12:48.606574: Current learning rate: 0.00942
2024-12-05 14:14:15.126198: Validation loss did not improve from -0.51933. Patience: 13/50
2024-12-05 14:14:15.127448: train_loss -0.6544
2024-12-05 14:14:15.128319: val_loss -0.4848
2024-12-05 14:14:15.128906: Pseudo dice [0.7186]
2024-12-05 14:14:15.129680: Epoch time: 86.52 s
2024-12-05 14:14:15.525233: Yayy! New best EMA pseudo Dice: 0.7154
2024-12-05 14:14:17.180359: 
2024-12-05 14:14:17.182010: Epoch 65
2024-12-05 14:14:17.183053: Current learning rate: 0.00941
2024-12-05 14:15:44.378708: Validation loss did not improve from -0.51933. Patience: 14/50
2024-12-05 14:15:44.379725: train_loss -0.6467
2024-12-05 14:15:44.380781: val_loss -0.509
2024-12-05 14:15:44.381583: Pseudo dice [0.7228]
2024-12-05 14:15:44.382355: Epoch time: 87.2 s
2024-12-05 14:15:44.383089: Yayy! New best EMA pseudo Dice: 0.7161
2024-12-05 14:15:46.038659: 
2024-12-05 14:15:46.040353: Epoch 66
2024-12-05 14:15:46.041103: Current learning rate: 0.0094
2024-12-05 14:17:12.869195: Validation loss did not improve from -0.51933. Patience: 15/50
2024-12-05 14:17:12.870322: train_loss -0.6606
2024-12-05 14:17:12.871307: val_loss -0.458
2024-12-05 14:17:12.871954: Pseudo dice [0.6935]
2024-12-05 14:17:12.872640: Epoch time: 86.83 s
2024-12-05 14:17:14.197091: 
2024-12-05 14:17:14.198420: Epoch 67
2024-12-05 14:17:14.199300: Current learning rate: 0.00939
2024-12-05 14:18:40.819308: Validation loss did not improve from -0.51933. Patience: 16/50
2024-12-05 14:18:40.820460: train_loss -0.6621
2024-12-05 14:18:40.821516: val_loss -0.4719
2024-12-05 14:18:40.822249: Pseudo dice [0.7086]
2024-12-05 14:18:40.822966: Epoch time: 86.62 s
2024-12-05 14:18:42.155210: 
2024-12-05 14:18:42.156857: Epoch 68
2024-12-05 14:18:42.157635: Current learning rate: 0.00939
2024-12-05 14:20:08.852626: Validation loss did not improve from -0.51933. Patience: 17/50
2024-12-05 14:20:08.853671: train_loss -0.6683
2024-12-05 14:20:08.854811: val_loss -0.4358
2024-12-05 14:20:08.855563: Pseudo dice [0.6967]
2024-12-05 14:20:08.856337: Epoch time: 86.7 s
2024-12-05 14:20:10.221487: 
2024-12-05 14:20:10.223037: Epoch 69
2024-12-05 14:20:10.223734: Current learning rate: 0.00938
2024-12-05 14:21:36.992003: Validation loss did not improve from -0.51933. Patience: 18/50
2024-12-05 14:21:36.993136: train_loss -0.6577
2024-12-05 14:21:36.994137: val_loss -0.4419
2024-12-05 14:21:36.994879: Pseudo dice [0.7028]
2024-12-05 14:21:36.995637: Epoch time: 86.77 s
2024-12-05 14:21:38.680898: 
2024-12-05 14:21:38.682542: Epoch 70
2024-12-05 14:21:38.683654: Current learning rate: 0.00937
2024-12-05 14:23:04.942553: Validation loss did not improve from -0.51933. Patience: 19/50
2024-12-05 14:23:04.943531: train_loss -0.6595
2024-12-05 14:23:04.944581: val_loss -0.4979
2024-12-05 14:23:04.945377: Pseudo dice [0.7189]
2024-12-05 14:23:04.946158: Epoch time: 86.26 s
2024-12-05 14:23:06.655008: 
2024-12-05 14:23:06.656542: Epoch 71
2024-12-05 14:23:06.657359: Current learning rate: 0.00936
2024-12-05 14:24:33.525318: Validation loss did not improve from -0.51933. Patience: 20/50
2024-12-05 14:24:33.526294: train_loss -0.6658
2024-12-05 14:24:33.527433: val_loss -0.4849
2024-12-05 14:24:33.528241: Pseudo dice [0.7176]
2024-12-05 14:24:33.528910: Epoch time: 86.87 s
2024-12-05 14:24:34.831070: 
2024-12-05 14:24:34.833083: Epoch 72
2024-12-05 14:24:34.833940: Current learning rate: 0.00935
2024-12-05 14:26:01.601998: Validation loss did not improve from -0.51933. Patience: 21/50
2024-12-05 14:26:01.603053: train_loss -0.6684
2024-12-05 14:26:01.603790: val_loss -0.4907
2024-12-05 14:26:01.604533: Pseudo dice [0.7268]
2024-12-05 14:26:01.605268: Epoch time: 86.77 s
2024-12-05 14:26:02.928086: 
2024-12-05 14:26:02.929510: Epoch 73
2024-12-05 14:26:02.930171: Current learning rate: 0.00934
2024-12-05 14:27:29.689602: Validation loss did not improve from -0.51933. Patience: 22/50
2024-12-05 14:27:29.690669: train_loss -0.6752
2024-12-05 14:27:29.691598: val_loss -0.4729
2024-12-05 14:27:29.692377: Pseudo dice [0.7093]
2024-12-05 14:27:29.693061: Epoch time: 86.76 s
2024-12-05 14:27:31.067536: 
2024-12-05 14:27:31.069188: Epoch 74
2024-12-05 14:27:31.070229: Current learning rate: 0.00933
2024-12-05 14:28:57.525863: Validation loss did not improve from -0.51933. Patience: 23/50
2024-12-05 14:28:57.526666: train_loss -0.6851
2024-12-05 14:28:57.527500: val_loss -0.4503
2024-12-05 14:28:57.528201: Pseudo dice [0.6981]
2024-12-05 14:28:57.528893: Epoch time: 86.46 s
2024-12-05 14:28:59.204927: 
2024-12-05 14:28:59.206295: Epoch 75
2024-12-05 14:28:59.207167: Current learning rate: 0.00932
2024-12-05 14:30:25.616071: Validation loss improved from -0.51933 to -0.52454! Patience: 23/50
2024-12-05 14:30:25.616821: train_loss -0.6762
2024-12-05 14:30:25.617809: val_loss -0.5245
2024-12-05 14:30:25.618811: Pseudo dice [0.7331]
2024-12-05 14:30:25.619748: Epoch time: 86.41 s
2024-12-05 14:30:26.912683: 
2024-12-05 14:30:26.914113: Epoch 76
2024-12-05 14:30:26.914934: Current learning rate: 0.00931
2024-12-05 14:31:53.599971: Validation loss did not improve from -0.52454. Patience: 1/50
2024-12-05 14:31:53.600863: train_loss -0.6848
2024-12-05 14:31:53.601915: val_loss -0.4722
2024-12-05 14:31:53.602857: Pseudo dice [0.7155]
2024-12-05 14:31:53.603601: Epoch time: 86.69 s
2024-12-05 14:31:54.911240: 
2024-12-05 14:31:54.912707: Epoch 77
2024-12-05 14:31:54.913487: Current learning rate: 0.0093
2024-12-05 14:33:21.556366: Validation loss did not improve from -0.52454. Patience: 2/50
2024-12-05 14:33:21.557334: train_loss -0.6753
2024-12-05 14:33:21.558253: val_loss -0.4968
2024-12-05 14:33:21.559055: Pseudo dice [0.7113]
2024-12-05 14:33:21.559982: Epoch time: 86.65 s
2024-12-05 14:33:22.881797: 
2024-12-05 14:33:22.883464: Epoch 78
2024-12-05 14:33:22.884342: Current learning rate: 0.0093
2024-12-05 14:34:49.534272: Validation loss did not improve from -0.52454. Patience: 3/50
2024-12-05 14:34:49.535424: train_loss -0.6833
2024-12-05 14:34:49.536494: val_loss -0.496
2024-12-05 14:34:49.537209: Pseudo dice [0.7115]
2024-12-05 14:34:49.537973: Epoch time: 86.65 s
2024-12-05 14:34:50.915578: 
2024-12-05 14:34:50.916904: Epoch 79
2024-12-05 14:34:50.917812: Current learning rate: 0.00929
2024-12-05 14:36:17.751337: Validation loss did not improve from -0.52454. Patience: 4/50
2024-12-05 14:36:17.752288: train_loss -0.6781
2024-12-05 14:36:17.753469: val_loss -0.5007
2024-12-05 14:36:17.754305: Pseudo dice [0.7222]
2024-12-05 14:36:17.754996: Epoch time: 86.84 s
2024-12-05 14:36:19.483292: 
2024-12-05 14:36:19.484589: Epoch 80
2024-12-05 14:36:19.485401: Current learning rate: 0.00928
2024-12-05 14:37:45.925098: Validation loss did not improve from -0.52454. Patience: 5/50
2024-12-05 14:37:45.926156: train_loss -0.6834
2024-12-05 14:37:45.927160: val_loss -0.495
2024-12-05 14:37:45.927951: Pseudo dice [0.7168]
2024-12-05 14:37:45.928596: Epoch time: 86.44 s
2024-12-05 14:37:48.044438: 
2024-12-05 14:37:48.045902: Epoch 81
2024-12-05 14:37:48.046836: Current learning rate: 0.00927
2024-12-05 14:39:14.673623: Validation loss did not improve from -0.52454. Patience: 6/50
2024-12-05 14:39:14.674952: train_loss -0.6873
2024-12-05 14:39:14.675941: val_loss -0.5065
2024-12-05 14:39:14.676664: Pseudo dice [0.716]
2024-12-05 14:39:14.677439: Epoch time: 86.63 s
2024-12-05 14:39:16.027203: 
2024-12-05 14:39:16.028766: Epoch 82
2024-12-05 14:39:16.029403: Current learning rate: 0.00926
2024-12-05 14:40:42.647453: Validation loss did not improve from -0.52454. Patience: 7/50
2024-12-05 14:40:42.648721: train_loss -0.6821
2024-12-05 14:40:42.649642: val_loss -0.5141
2024-12-05 14:40:42.650326: Pseudo dice [0.7238]
2024-12-05 14:40:42.650952: Epoch time: 86.62 s
2024-12-05 14:40:43.913266: 
2024-12-05 14:40:43.915094: Epoch 83
2024-12-05 14:40:43.915856: Current learning rate: 0.00925
2024-12-05 14:42:10.735432: Validation loss did not improve from -0.52454. Patience: 8/50
2024-12-05 14:42:10.744000: train_loss -0.6884
2024-12-05 14:42:10.745451: val_loss -0.4859
2024-12-05 14:42:10.746166: Pseudo dice [0.7152]
2024-12-05 14:42:10.747068: Epoch time: 86.83 s
2024-12-05 14:42:12.091715: 
2024-12-05 14:42:12.093366: Epoch 84
2024-12-05 14:42:12.094250: Current learning rate: 0.00924
2024-12-05 14:43:38.893415: Validation loss did not improve from -0.52454. Patience: 9/50
2024-12-05 14:43:38.894414: train_loss -0.6828
2024-12-05 14:43:38.895317: val_loss -0.4494
2024-12-05 14:43:38.896219: Pseudo dice [0.6986]
2024-12-05 14:43:38.897002: Epoch time: 86.8 s
2024-12-05 14:43:40.536918: 
2024-12-05 14:43:40.538326: Epoch 85
2024-12-05 14:43:40.539094: Current learning rate: 0.00923
2024-12-05 14:45:07.303308: Validation loss did not improve from -0.52454. Patience: 10/50
2024-12-05 14:45:07.304537: train_loss -0.685
2024-12-05 14:45:07.305459: val_loss -0.4801
2024-12-05 14:45:07.306283: Pseudo dice [0.7139]
2024-12-05 14:45:07.307089: Epoch time: 86.77 s
2024-12-05 14:45:08.684929: 
2024-12-05 14:45:08.686434: Epoch 86
2024-12-05 14:45:08.687151: Current learning rate: 0.00922
2024-12-05 14:46:37.340392: Validation loss did not improve from -0.52454. Patience: 11/50
2024-12-05 14:46:37.342876: train_loss -0.6908
2024-12-05 14:46:37.343927: val_loss -0.4875
2024-12-05 14:46:37.344585: Pseudo dice [0.7135]
2024-12-05 14:46:37.345251: Epoch time: 88.66 s
2024-12-05 14:46:38.602003: 
2024-12-05 14:46:38.603019: Epoch 87
2024-12-05 14:46:38.603905: Current learning rate: 0.00921
2024-12-05 14:48:05.602579: Validation loss did not improve from -0.52454. Patience: 12/50
2024-12-05 14:48:05.603721: train_loss -0.684
2024-12-05 14:48:05.604600: val_loss -0.4872
2024-12-05 14:48:05.605237: Pseudo dice [0.7134]
2024-12-05 14:48:05.605988: Epoch time: 87.0 s
2024-12-05 14:48:06.886490: 
2024-12-05 14:48:06.887955: Epoch 88
2024-12-05 14:48:06.888765: Current learning rate: 0.0092
2024-12-05 14:49:33.454395: Validation loss did not improve from -0.52454. Patience: 13/50
2024-12-05 14:49:33.456457: train_loss -0.6845
2024-12-05 14:49:33.457527: val_loss -0.4946
2024-12-05 14:49:33.458572: Pseudo dice [0.7248]
2024-12-05 14:49:33.459387: Epoch time: 86.57 s
2024-12-05 14:49:34.706439: 
2024-12-05 14:49:34.708309: Epoch 89
2024-12-05 14:49:34.709455: Current learning rate: 0.0092
2024-12-05 14:51:01.137671: Validation loss did not improve from -0.52454. Patience: 14/50
2024-12-05 14:51:01.138771: train_loss -0.6765
2024-12-05 14:51:01.139721: val_loss -0.5036
2024-12-05 14:51:01.140503: Pseudo dice [0.7148]
2024-12-05 14:51:01.141503: Epoch time: 86.43 s
2024-12-05 14:51:02.813528: 
2024-12-05 14:51:02.815181: Epoch 90
2024-12-05 14:51:02.816127: Current learning rate: 0.00919
2024-12-05 14:52:29.549876: Validation loss did not improve from -0.52454. Patience: 15/50
2024-12-05 14:52:29.550725: train_loss -0.689
2024-12-05 14:52:29.551598: val_loss -0.4801
2024-12-05 14:52:29.552458: Pseudo dice [0.7039]
2024-12-05 14:52:29.553385: Epoch time: 86.74 s
2024-12-05 14:52:30.818460: 
2024-12-05 14:52:30.819731: Epoch 91
2024-12-05 14:52:30.820528: Current learning rate: 0.00918
2024-12-05 14:53:57.381291: Validation loss did not improve from -0.52454. Patience: 16/50
2024-12-05 14:53:57.382273: train_loss -0.6877
2024-12-05 14:53:57.383142: val_loss -0.5081
2024-12-05 14:53:57.384124: Pseudo dice [0.7296]
2024-12-05 14:53:57.384799: Epoch time: 86.57 s
2024-12-05 14:54:00.530249: 
2024-12-05 14:54:00.531405: Epoch 92
2024-12-05 14:54:00.532117: Current learning rate: 0.00917
2024-12-05 14:55:26.887118: Validation loss did not improve from -0.52454. Patience: 17/50
2024-12-05 14:55:26.888100: train_loss -0.6956
2024-12-05 14:55:26.888994: val_loss -0.5196
2024-12-05 14:55:26.889664: Pseudo dice [0.7323]
2024-12-05 14:55:26.890431: Epoch time: 86.36 s
2024-12-05 14:55:26.891042: Yayy! New best EMA pseudo Dice: 0.7171
2024-12-05 14:55:28.498770: 
2024-12-05 14:55:28.500142: Epoch 93
2024-12-05 14:55:28.500862: Current learning rate: 0.00916
2024-12-05 14:56:55.051991: Validation loss did not improve from -0.52454. Patience: 18/50
2024-12-05 14:56:55.053237: train_loss -0.6949
2024-12-05 14:56:55.054000: val_loss -0.4788
2024-12-05 14:56:55.054693: Pseudo dice [0.7131]
2024-12-05 14:56:55.055371: Epoch time: 86.56 s
2024-12-05 14:56:56.309415: 
2024-12-05 14:56:56.310811: Epoch 94
2024-12-05 14:56:56.311511: Current learning rate: 0.00915
2024-12-05 14:58:23.051076: Validation loss did not improve from -0.52454. Patience: 19/50
2024-12-05 14:58:23.052264: train_loss -0.6938
2024-12-05 14:58:23.053247: val_loss -0.5032
2024-12-05 14:58:23.054013: Pseudo dice [0.7222]
2024-12-05 14:58:23.054800: Epoch time: 86.74 s
2024-12-05 14:58:23.422361: Yayy! New best EMA pseudo Dice: 0.7172
2024-12-05 14:58:25.015125: 
2024-12-05 14:58:25.016623: Epoch 95
2024-12-05 14:58:25.017354: Current learning rate: 0.00914
2024-12-05 14:59:51.521879: Validation loss did not improve from -0.52454. Patience: 20/50
2024-12-05 14:59:51.523181: train_loss -0.6948
2024-12-05 14:59:51.523998: val_loss -0.4976
2024-12-05 14:59:51.524760: Pseudo dice [0.7257]
2024-12-05 14:59:51.525376: Epoch time: 86.51 s
2024-12-05 14:59:51.526021: Yayy! New best EMA pseudo Dice: 0.7181
2024-12-05 14:59:53.113443: 
2024-12-05 14:59:53.114814: Epoch 96
2024-12-05 14:59:53.115576: Current learning rate: 0.00913
2024-12-05 15:01:19.623719: Validation loss did not improve from -0.52454. Patience: 21/50
2024-12-05 15:01:19.625279: train_loss -0.6904
2024-12-05 15:01:19.626270: val_loss -0.5007
2024-12-05 15:01:19.626968: Pseudo dice [0.7316]
2024-12-05 15:01:19.627661: Epoch time: 86.51 s
2024-12-05 15:01:19.628293: Yayy! New best EMA pseudo Dice: 0.7194
2024-12-05 15:01:21.218465: 
2024-12-05 15:01:21.219877: Epoch 97
2024-12-05 15:01:21.220575: Current learning rate: 0.00912
2024-12-05 15:02:47.749223: Validation loss did not improve from -0.52454. Patience: 22/50
2024-12-05 15:02:47.750356: train_loss -0.692
2024-12-05 15:02:47.751368: val_loss -0.4724
2024-12-05 15:02:47.752141: Pseudo dice [0.7]
2024-12-05 15:02:47.752785: Epoch time: 86.53 s
2024-12-05 15:02:49.040568: 
2024-12-05 15:02:49.041928: Epoch 98
2024-12-05 15:02:49.042638: Current learning rate: 0.00911
2024-12-05 15:04:15.745474: Validation loss did not improve from -0.52454. Patience: 23/50
2024-12-05 15:04:15.746523: train_loss -0.6882
2024-12-05 15:04:15.747612: val_loss -0.4759
2024-12-05 15:04:15.748421: Pseudo dice [0.712]
2024-12-05 15:04:15.749178: Epoch time: 86.71 s
2024-12-05 15:04:16.976050: 
2024-12-05 15:04:16.977661: Epoch 99
2024-12-05 15:04:16.978635: Current learning rate: 0.0091
2024-12-05 15:05:43.586842: Validation loss did not improve from -0.52454. Patience: 24/50
2024-12-05 15:05:43.588217: train_loss -0.6986
2024-12-05 15:05:43.589452: val_loss -0.504
2024-12-05 15:05:43.590107: Pseudo dice [0.7336]
2024-12-05 15:05:43.590765: Epoch time: 86.61 s
2024-12-05 15:05:45.174938: 
2024-12-05 15:05:45.176695: Epoch 100
2024-12-05 15:05:45.177506: Current learning rate: 0.0091
2024-12-05 15:07:11.872111: Validation loss did not improve from -0.52454. Patience: 25/50
2024-12-05 15:07:11.873136: train_loss -0.6954
2024-12-05 15:07:11.874126: val_loss -0.5152
2024-12-05 15:07:11.874841: Pseudo dice [0.7315]
2024-12-05 15:07:11.875491: Epoch time: 86.7 s
2024-12-05 15:07:11.876116: Yayy! New best EMA pseudo Dice: 0.7199
2024-12-05 15:07:13.464875: 
2024-12-05 15:07:13.467009: Epoch 101
2024-12-05 15:07:13.467764: Current learning rate: 0.00909
2024-12-05 15:08:39.940667: Validation loss did not improve from -0.52454. Patience: 26/50
2024-12-05 15:08:39.941762: train_loss -0.7031
2024-12-05 15:08:39.942751: val_loss -0.4397
2024-12-05 15:08:39.943526: Pseudo dice [0.6984]
2024-12-05 15:08:39.944385: Epoch time: 86.48 s
2024-12-05 15:08:41.187870: 
2024-12-05 15:08:41.189070: Epoch 102
2024-12-05 15:08:41.189917: Current learning rate: 0.00908
2024-12-05 15:10:07.781489: Validation loss did not improve from -0.52454. Patience: 27/50
2024-12-05 15:10:07.782619: train_loss -0.7053
2024-12-05 15:10:07.783507: val_loss -0.4693
2024-12-05 15:10:07.784256: Pseudo dice [0.7184]
2024-12-05 15:10:07.784935: Epoch time: 86.6 s
2024-12-05 15:10:09.013726: 
2024-12-05 15:10:09.015267: Epoch 103
2024-12-05 15:10:09.016182: Current learning rate: 0.00907
2024-12-05 15:11:35.979271: Validation loss did not improve from -0.52454. Patience: 28/50
2024-12-05 15:11:35.980478: train_loss -0.6994
2024-12-05 15:11:35.981427: val_loss -0.4752
2024-12-05 15:11:35.982226: Pseudo dice [0.6926]
2024-12-05 15:11:35.983027: Epoch time: 86.97 s
2024-12-05 15:11:37.268746: 
2024-12-05 15:11:37.270376: Epoch 104
2024-12-05 15:11:37.271235: Current learning rate: 0.00906
2024-12-05 15:13:03.858210: Validation loss did not improve from -0.52454. Patience: 29/50
2024-12-05 15:13:03.859452: train_loss -0.7022
2024-12-05 15:13:03.860360: val_loss -0.4981
2024-12-05 15:13:03.861115: Pseudo dice [0.7238]
2024-12-05 15:13:03.861937: Epoch time: 86.59 s
2024-12-05 15:13:05.454868: 
2024-12-05 15:13:05.456771: Epoch 105
2024-12-05 15:13:05.457487: Current learning rate: 0.00905
2024-12-05 15:14:31.867178: Validation loss did not improve from -0.52454. Patience: 30/50
2024-12-05 15:14:31.868391: train_loss -0.6949
2024-12-05 15:14:31.869248: val_loss -0.4805
2024-12-05 15:14:31.870182: Pseudo dice [0.712]
2024-12-05 15:14:31.871228: Epoch time: 86.41 s
2024-12-05 15:14:33.150468: 
2024-12-05 15:14:33.152100: Epoch 106
2024-12-05 15:14:33.153027: Current learning rate: 0.00904
2024-12-05 15:15:59.668811: Validation loss did not improve from -0.52454. Patience: 31/50
2024-12-05 15:15:59.670132: train_loss -0.6863
2024-12-05 15:15:59.671352: val_loss -0.4917
2024-12-05 15:15:59.672390: Pseudo dice [0.7187]
2024-12-05 15:15:59.673432: Epoch time: 86.52 s
2024-12-05 15:16:00.975630: 
2024-12-05 15:16:00.977461: Epoch 107
2024-12-05 15:16:00.978531: Current learning rate: 0.00903
2024-12-05 15:17:27.421435: Validation loss did not improve from -0.52454. Patience: 32/50
2024-12-05 15:17:27.422583: train_loss -0.6977
2024-12-05 15:17:27.423523: val_loss -0.4597
2024-12-05 15:17:27.424381: Pseudo dice [0.7116]
2024-12-05 15:17:27.425096: Epoch time: 86.45 s
2024-12-05 15:17:28.694906: 
2024-12-05 15:17:28.695979: Epoch 108
2024-12-05 15:17:28.696644: Current learning rate: 0.00902
2024-12-05 15:18:55.112848: Validation loss did not improve from -0.52454. Patience: 33/50
2024-12-05 15:18:55.114156: train_loss -0.7053
2024-12-05 15:18:55.115060: val_loss -0.5089
2024-12-05 15:18:55.115962: Pseudo dice [0.7254]
2024-12-05 15:18:55.116736: Epoch time: 86.42 s
2024-12-05 15:18:56.365401: 
2024-12-05 15:18:56.367003: Epoch 109
2024-12-05 15:18:56.367772: Current learning rate: 0.00901
2024-12-05 15:20:22.910190: Validation loss did not improve from -0.52454. Patience: 34/50
2024-12-05 15:20:22.911434: train_loss -0.7056
2024-12-05 15:20:22.912640: val_loss -0.4987
2024-12-05 15:20:22.913640: Pseudo dice [0.7257]
2024-12-05 15:20:22.914585: Epoch time: 86.55 s
2024-12-05 15:20:24.544051: 
2024-12-05 15:20:24.545542: Epoch 110
2024-12-05 15:20:24.546564: Current learning rate: 0.009
2024-12-05 15:21:51.162158: Validation loss did not improve from -0.52454. Patience: 35/50
2024-12-05 15:21:51.163280: train_loss -0.7126
2024-12-05 15:21:51.164289: val_loss -0.4996
2024-12-05 15:21:51.165180: Pseudo dice [0.7284]
2024-12-05 15:21:51.165976: Epoch time: 86.62 s
2024-12-05 15:21:52.485700: 
2024-12-05 15:21:52.487536: Epoch 111
2024-12-05 15:21:52.488395: Current learning rate: 0.009
2024-12-05 15:23:18.915288: Validation loss did not improve from -0.52454. Patience: 36/50
2024-12-05 15:23:18.916651: train_loss -0.7117
2024-12-05 15:23:18.917783: val_loss -0.4843
2024-12-05 15:23:18.918746: Pseudo dice [0.7227]
2024-12-05 15:23:18.919715: Epoch time: 86.43 s
2024-12-05 15:23:20.203718: 
2024-12-05 15:23:20.205375: Epoch 112
2024-12-05 15:23:20.206151: Current learning rate: 0.00899
2024-12-05 15:24:46.698716: Validation loss did not improve from -0.52454. Patience: 37/50
2024-12-05 15:24:46.699616: train_loss -0.7142
2024-12-05 15:24:46.700649: val_loss -0.5079
2024-12-05 15:24:46.701506: Pseudo dice [0.7239]
2024-12-05 15:24:46.702535: Epoch time: 86.5 s
2024-12-05 15:24:47.925004: 
2024-12-05 15:24:47.926492: Epoch 113
2024-12-05 15:24:47.927265: Current learning rate: 0.00898
2024-12-05 15:26:14.318895: Validation loss did not improve from -0.52454. Patience: 38/50
2024-12-05 15:26:14.319959: train_loss -0.7182
2024-12-05 15:26:14.320878: val_loss -0.5077
2024-12-05 15:26:14.321637: Pseudo dice [0.7212]
2024-12-05 15:26:14.322386: Epoch time: 86.4 s
2024-12-05 15:26:15.983117: 
2024-12-05 15:26:15.984953: Epoch 114
2024-12-05 15:26:15.985919: Current learning rate: 0.00897
2024-12-05 15:27:42.464229: Validation loss did not improve from -0.52454. Patience: 39/50
2024-12-05 15:27:42.465260: train_loss -0.7115
2024-12-05 15:27:42.466145: val_loss -0.5055
2024-12-05 15:27:42.466921: Pseudo dice [0.7259]
2024-12-05 15:27:42.467607: Epoch time: 86.48 s
2024-12-05 15:27:42.825425: Yayy! New best EMA pseudo Dice: 0.7203
2024-12-05 15:27:44.448191: 
2024-12-05 15:27:44.449677: Epoch 115
2024-12-05 15:27:44.450440: Current learning rate: 0.00896
2024-12-05 15:29:11.055076: Validation loss did not improve from -0.52454. Patience: 40/50
2024-12-05 15:29:11.056123: train_loss -0.7089
2024-12-05 15:29:11.057086: val_loss -0.4627
2024-12-05 15:29:11.057984: Pseudo dice [0.7052]
2024-12-05 15:29:11.058698: Epoch time: 86.61 s
2024-12-05 15:29:12.307545: 
2024-12-05 15:29:12.309169: Epoch 116
2024-12-05 15:29:12.309983: Current learning rate: 0.00895
2024-12-05 15:30:38.531193: Validation loss improved from -0.52454 to -0.52795! Patience: 40/50
2024-12-05 15:30:38.532278: train_loss -0.7151
2024-12-05 15:30:38.533132: val_loss -0.5279
2024-12-05 15:30:38.533941: Pseudo dice [0.7332]
2024-12-05 15:30:38.534534: Epoch time: 86.23 s
2024-12-05 15:30:39.782602: 
2024-12-05 15:30:39.784244: Epoch 117
2024-12-05 15:30:39.785042: Current learning rate: 0.00894
2024-12-05 15:32:06.170099: Validation loss did not improve from -0.52795. Patience: 1/50
2024-12-05 15:32:06.170986: train_loss -0.7192
2024-12-05 15:32:06.171758: val_loss -0.5259
2024-12-05 15:32:06.172542: Pseudo dice [0.7401]
2024-12-05 15:32:06.173223: Epoch time: 86.39 s
2024-12-05 15:32:06.173863: Yayy! New best EMA pseudo Dice: 0.7222
2024-12-05 15:32:07.796758: 
2024-12-05 15:32:07.798032: Epoch 118
2024-12-05 15:32:07.799158: Current learning rate: 0.00893
2024-12-05 15:33:34.104299: Validation loss did not improve from -0.52795. Patience: 2/50
2024-12-05 15:33:34.105382: train_loss -0.7194
2024-12-05 15:33:34.106400: val_loss -0.4709
2024-12-05 15:33:34.107145: Pseudo dice [0.7105]
2024-12-05 15:33:34.107805: Epoch time: 86.31 s
2024-12-05 15:33:35.429632: 
2024-12-05 15:33:35.431334: Epoch 119
2024-12-05 15:33:35.432244: Current learning rate: 0.00892
2024-12-05 15:35:01.894521: Validation loss did not improve from -0.52795. Patience: 3/50
2024-12-05 15:35:01.895495: train_loss -0.715
2024-12-05 15:35:01.896494: val_loss -0.5104
2024-12-05 15:35:01.897232: Pseudo dice [0.7291]
2024-12-05 15:35:01.897920: Epoch time: 86.47 s
2024-12-05 15:35:03.527804: 
2024-12-05 15:35:03.529112: Epoch 120
2024-12-05 15:35:03.529783: Current learning rate: 0.00891
2024-12-05 15:36:29.970335: Validation loss did not improve from -0.52795. Patience: 4/50
2024-12-05 15:36:29.971420: train_loss -0.7204
2024-12-05 15:36:29.972389: val_loss -0.4872
2024-12-05 15:36:29.973191: Pseudo dice [0.7223]
2024-12-05 15:36:29.973908: Epoch time: 86.44 s
2024-12-05 15:36:31.309993: 
2024-12-05 15:36:31.311338: Epoch 121
2024-12-05 15:36:31.312038: Current learning rate: 0.0089
2024-12-05 15:37:57.943785: Validation loss did not improve from -0.52795. Patience: 5/50
2024-12-05 15:37:57.945172: train_loss -0.7234
2024-12-05 15:37:57.946216: val_loss -0.5109
2024-12-05 15:37:57.946955: Pseudo dice [0.7312]
2024-12-05 15:37:57.947608: Epoch time: 86.64 s
2024-12-05 15:37:57.948316: Yayy! New best EMA pseudo Dice: 0.7228
2024-12-05 15:37:59.630461: 
2024-12-05 15:37:59.631973: Epoch 122
2024-12-05 15:37:59.632891: Current learning rate: 0.00889
2024-12-05 15:39:26.274753: Validation loss did not improve from -0.52795. Patience: 6/50
2024-12-05 15:39:26.275792: train_loss -0.7259
2024-12-05 15:39:26.276563: val_loss -0.5004
2024-12-05 15:39:26.277311: Pseudo dice [0.7239]
2024-12-05 15:39:26.277935: Epoch time: 86.65 s
2024-12-05 15:39:26.278726: Yayy! New best EMA pseudo Dice: 0.7229
2024-12-05 15:39:27.877738: 
2024-12-05 15:39:27.878942: Epoch 123
2024-12-05 15:39:27.879735: Current learning rate: 0.00889
2024-12-05 15:40:54.547817: Validation loss did not improve from -0.52795. Patience: 7/50
2024-12-05 15:40:54.548831: train_loss -0.7212
2024-12-05 15:40:54.549827: val_loss -0.4931
2024-12-05 15:40:54.550495: Pseudo dice [0.7206]
2024-12-05 15:40:54.551202: Epoch time: 86.67 s
2024-12-05 15:40:55.880074: 
2024-12-05 15:40:55.881175: Epoch 124
2024-12-05 15:40:55.881943: Current learning rate: 0.00888
2024-12-05 15:42:22.070628: Validation loss did not improve from -0.52795. Patience: 8/50
2024-12-05 15:42:22.071976: train_loss -0.7235
2024-12-05 15:42:22.073071: val_loss -0.4726
2024-12-05 15:42:22.074022: Pseudo dice [0.7148]
2024-12-05 15:42:22.074991: Epoch time: 86.19 s
2024-12-05 15:42:24.064492: 
2024-12-05 15:42:24.066077: Epoch 125
2024-12-05 15:42:24.066911: Current learning rate: 0.00887
2024-12-05 15:43:50.584277: Validation loss did not improve from -0.52795. Patience: 9/50
2024-12-05 15:43:50.585608: train_loss -0.7216
2024-12-05 15:43:50.586358: val_loss -0.5079
2024-12-05 15:43:50.587045: Pseudo dice [0.734]
2024-12-05 15:43:50.587879: Epoch time: 86.52 s
2024-12-05 15:43:50.588648: Yayy! New best EMA pseudo Dice: 0.7231
2024-12-05 15:43:52.165625: 
2024-12-05 15:43:52.167080: Epoch 126
2024-12-05 15:43:52.168155: Current learning rate: 0.00886
2024-12-05 15:45:18.578577: Validation loss did not improve from -0.52795. Patience: 10/50
2024-12-05 15:45:18.579634: train_loss -0.732
2024-12-05 15:45:18.580544: val_loss -0.4846
2024-12-05 15:45:18.581362: Pseudo dice [0.7216]
2024-12-05 15:45:18.582232: Epoch time: 86.42 s
2024-12-05 15:45:19.818723: 
2024-12-05 15:45:19.820386: Epoch 127
2024-12-05 15:45:19.821213: Current learning rate: 0.00885
2024-12-05 15:46:46.510343: Validation loss did not improve from -0.52795. Patience: 11/50
2024-12-05 15:46:46.511223: train_loss -0.7145
2024-12-05 15:46:46.512070: val_loss -0.5272
2024-12-05 15:46:46.512753: Pseudo dice [0.7399]
2024-12-05 15:46:46.513459: Epoch time: 86.69 s
2024-12-05 15:46:46.514248: Yayy! New best EMA pseudo Dice: 0.7247
2024-12-05 15:46:48.221033: 
2024-12-05 15:46:48.222682: Epoch 128
2024-12-05 15:46:48.223338: Current learning rate: 0.00884
2024-12-05 15:48:14.666381: Validation loss did not improve from -0.52795. Patience: 12/50
2024-12-05 15:48:14.667440: train_loss -0.7257
2024-12-05 15:48:14.668426: val_loss -0.506
2024-12-05 15:48:14.669199: Pseudo dice [0.7288]
2024-12-05 15:48:14.669924: Epoch time: 86.45 s
2024-12-05 15:48:14.670649: Yayy! New best EMA pseudo Dice: 0.7251
2024-12-05 15:48:16.369319: 
2024-12-05 15:48:16.370386: Epoch 129
2024-12-05 15:48:16.371204: Current learning rate: 0.00883
2024-12-05 15:49:42.810430: Validation loss did not improve from -0.52795. Patience: 13/50
2024-12-05 15:49:42.811453: train_loss -0.7172
2024-12-05 15:49:42.812666: val_loss -0.4773
2024-12-05 15:49:42.813900: Pseudo dice [0.6969]
2024-12-05 15:49:42.814886: Epoch time: 86.44 s
2024-12-05 15:49:44.455637: 
2024-12-05 15:49:44.457222: Epoch 130
2024-12-05 15:49:44.458601: Current learning rate: 0.00882
2024-12-05 15:51:10.952907: Validation loss did not improve from -0.52795. Patience: 14/50
2024-12-05 15:51:10.955155: train_loss -0.7166
2024-12-05 15:51:10.957103: val_loss -0.4863
2024-12-05 15:51:10.958230: Pseudo dice [0.7169]
2024-12-05 15:51:10.959686: Epoch time: 86.5 s
2024-12-05 15:51:12.308408: 
2024-12-05 15:51:12.310175: Epoch 131
2024-12-05 15:51:12.311170: Current learning rate: 0.00881
2024-12-05 15:52:38.712386: Validation loss did not improve from -0.52795. Patience: 15/50
2024-12-05 15:52:38.713807: train_loss -0.7193
2024-12-05 15:52:38.714724: val_loss -0.4652
2024-12-05 15:52:38.715371: Pseudo dice [0.7019]
2024-12-05 15:52:38.716018: Epoch time: 86.41 s
2024-12-05 15:52:40.037216: 
2024-12-05 15:52:40.038674: Epoch 132
2024-12-05 15:52:40.039354: Current learning rate: 0.0088
2024-12-05 15:54:06.504328: Validation loss did not improve from -0.52795. Patience: 16/50
2024-12-05 15:54:06.505908: train_loss -0.7203
2024-12-05 15:54:06.506768: val_loss -0.4595
2024-12-05 15:54:06.507551: Pseudo dice [0.6975]
2024-12-05 15:54:06.508325: Epoch time: 86.47 s
2024-12-05 15:54:07.863872: 
2024-12-05 15:54:07.865661: Epoch 133
2024-12-05 15:54:07.866547: Current learning rate: 0.00879
2024-12-05 15:55:34.208954: Validation loss did not improve from -0.52795. Patience: 17/50
2024-12-05 15:55:34.209981: train_loss -0.7208
2024-12-05 15:55:34.210981: val_loss -0.4474
2024-12-05 15:55:34.212045: Pseudo dice [0.7089]
2024-12-05 15:55:34.212876: Epoch time: 86.35 s
2024-12-05 15:55:35.509624: 
2024-12-05 15:55:35.511001: Epoch 134
2024-12-05 15:55:35.511850: Current learning rate: 0.00879
2024-12-05 15:57:01.861944: Validation loss did not improve from -0.52795. Patience: 18/50
2024-12-05 15:57:01.863026: train_loss -0.7291
2024-12-05 15:57:01.864092: val_loss -0.4575
2024-12-05 15:57:01.865000: Pseudo dice [0.7147]
2024-12-05 15:57:01.865858: Epoch time: 86.35 s
2024-12-05 15:57:04.311142: 
2024-12-05 15:57:04.312629: Epoch 135
2024-12-05 15:57:04.313754: Current learning rate: 0.00878
2024-12-05 15:58:30.702986: Validation loss did not improve from -0.52795. Patience: 19/50
2024-12-05 15:58:30.704181: train_loss -0.7258
2024-12-05 15:58:30.705240: val_loss -0.4685
2024-12-05 15:58:30.706017: Pseudo dice [0.7159]
2024-12-05 15:58:30.706757: Epoch time: 86.39 s
2024-12-05 15:58:32.090809: 
2024-12-05 15:58:32.092542: Epoch 136
2024-12-05 15:58:32.093315: Current learning rate: 0.00877
2024-12-05 15:59:58.325930: Validation loss did not improve from -0.52795. Patience: 20/50
2024-12-05 15:59:58.327078: train_loss -0.7239
2024-12-05 15:59:58.328029: val_loss -0.5168
2024-12-05 15:59:58.328713: Pseudo dice [0.7341]
2024-12-05 15:59:58.329449: Epoch time: 86.24 s
2024-12-05 15:59:59.675973: 
2024-12-05 15:59:59.677824: Epoch 137
2024-12-05 15:59:59.678816: Current learning rate: 0.00876
2024-12-05 16:01:26.050171: Validation loss improved from -0.52795 to -0.53026! Patience: 20/50
2024-12-05 16:01:26.051048: train_loss -0.7367
2024-12-05 16:01:26.051738: val_loss -0.5303
2024-12-05 16:01:26.052365: Pseudo dice [0.75]
2024-12-05 16:01:26.053130: Epoch time: 86.38 s
2024-12-05 16:01:27.346678: 
2024-12-05 16:01:27.348232: Epoch 138
2024-12-05 16:01:27.349017: Current learning rate: 0.00875
2024-12-05 16:02:53.665403: Validation loss did not improve from -0.53026. Patience: 1/50
2024-12-05 16:02:53.666465: train_loss -0.7328
2024-12-05 16:02:53.667295: val_loss -0.5147
2024-12-05 16:02:53.668130: Pseudo dice [0.7315]
2024-12-05 16:02:53.668904: Epoch time: 86.32 s
2024-12-05 16:02:55.006900: 
2024-12-05 16:02:55.008430: Epoch 139
2024-12-05 16:02:55.009180: Current learning rate: 0.00874
2024-12-05 16:04:21.142606: Validation loss did not improve from -0.53026. Patience: 2/50
2024-12-05 16:04:21.143966: train_loss -0.7193
2024-12-05 16:04:21.144842: val_loss -0.506
2024-12-05 16:04:21.145479: Pseudo dice [0.722]
2024-12-05 16:04:21.146212: Epoch time: 86.14 s
2024-12-05 16:04:22.835496: 
2024-12-05 16:04:22.837128: Epoch 140
2024-12-05 16:04:22.837807: Current learning rate: 0.00873
2024-12-05 16:05:49.192158: Validation loss did not improve from -0.53026. Patience: 3/50
2024-12-05 16:05:49.193241: train_loss -0.7255
2024-12-05 16:05:49.194218: val_loss -0.507
2024-12-05 16:05:49.194964: Pseudo dice [0.7314]
2024-12-05 16:05:49.195722: Epoch time: 86.36 s
2024-12-05 16:05:50.522236: 
2024-12-05 16:05:50.523534: Epoch 141
2024-12-05 16:05:50.524391: Current learning rate: 0.00872
2024-12-05 16:07:16.688818: Validation loss did not improve from -0.53026. Patience: 4/50
2024-12-05 16:07:16.690118: train_loss -0.7328
2024-12-05 16:07:16.691115: val_loss -0.5074
2024-12-05 16:07:16.692068: Pseudo dice [0.7166]
2024-12-05 16:07:16.693005: Epoch time: 86.17 s
2024-12-05 16:07:17.998902: 
2024-12-05 16:07:18.000554: Epoch 142
2024-12-05 16:07:18.001549: Current learning rate: 0.00871
2024-12-05 16:08:44.235405: Validation loss did not improve from -0.53026. Patience: 5/50
2024-12-05 16:08:44.236613: train_loss -0.7329
2024-12-05 16:08:44.237568: val_loss -0.4902
2024-12-05 16:08:44.238227: Pseudo dice [0.7179]
2024-12-05 16:08:44.239112: Epoch time: 86.24 s
2024-12-05 16:08:45.544890: 
2024-12-05 16:08:45.546527: Epoch 143
2024-12-05 16:08:45.547234: Current learning rate: 0.0087
2024-12-05 16:10:11.834798: Validation loss did not improve from -0.53026. Patience: 6/50
2024-12-05 16:10:11.835850: train_loss -0.7327
2024-12-05 16:10:11.836690: val_loss -0.4899
2024-12-05 16:10:11.837495: Pseudo dice [0.723]
2024-12-05 16:10:11.838116: Epoch time: 86.29 s
2024-12-05 16:10:13.166727: 
2024-12-05 16:10:13.168671: Epoch 144
2024-12-05 16:10:13.169509: Current learning rate: 0.00869
2024-12-05 16:11:39.609581: Validation loss did not improve from -0.53026. Patience: 7/50
2024-12-05 16:11:39.610410: train_loss -0.7358
2024-12-05 16:11:39.611355: val_loss -0.5237
2024-12-05 16:11:39.612052: Pseudo dice [0.7271]
2024-12-05 16:11:39.612827: Epoch time: 86.44 s
2024-12-05 16:11:41.255481: 
2024-12-05 16:11:41.257201: Epoch 145
2024-12-05 16:11:41.258245: Current learning rate: 0.00868
2024-12-05 16:13:07.922551: Validation loss did not improve from -0.53026. Patience: 8/50
2024-12-05 16:13:07.923643: train_loss -0.7301
2024-12-05 16:13:07.924353: val_loss -0.4857
2024-12-05 16:13:07.925084: Pseudo dice [0.7173]
2024-12-05 16:13:07.925649: Epoch time: 86.67 s
2024-12-05 16:13:09.556861: 
2024-12-05 16:13:09.558404: Epoch 146
2024-12-05 16:13:09.559083: Current learning rate: 0.00868
2024-12-05 16:14:36.124297: Validation loss did not improve from -0.53026. Patience: 9/50
2024-12-05 16:14:36.125435: train_loss -0.7405
2024-12-05 16:14:36.126364: val_loss -0.4849
2024-12-05 16:14:36.127190: Pseudo dice [0.7114]
2024-12-05 16:14:36.127991: Epoch time: 86.57 s
2024-12-05 16:14:37.457324: 
2024-12-05 16:14:37.458240: Epoch 147
2024-12-05 16:14:37.458844: Current learning rate: 0.00867
2024-12-05 16:16:03.891405: Validation loss did not improve from -0.53026. Patience: 10/50
2024-12-05 16:16:03.892342: train_loss -0.732
2024-12-05 16:16:03.893191: val_loss -0.5039
2024-12-05 16:16:03.894151: Pseudo dice [0.7302]
2024-12-05 16:16:03.895047: Epoch time: 86.44 s
2024-12-05 16:16:05.207972: 
2024-12-05 16:16:05.209324: Epoch 148
2024-12-05 16:16:05.210156: Current learning rate: 0.00866
2024-12-05 16:17:31.584513: Validation loss did not improve from -0.53026. Patience: 11/50
2024-12-05 16:17:31.585445: train_loss -0.7352
2024-12-05 16:17:31.586403: val_loss -0.4941
2024-12-05 16:17:31.587343: Pseudo dice [0.7248]
2024-12-05 16:17:31.588239: Epoch time: 86.38 s
2024-12-05 16:17:32.879499: 
2024-12-05 16:17:32.880641: Epoch 149
2024-12-05 16:17:32.881537: Current learning rate: 0.00865
2024-12-05 16:18:59.278637: Validation loss did not improve from -0.53026. Patience: 12/50
2024-12-05 16:18:59.279868: train_loss -0.7392
2024-12-05 16:18:59.280650: val_loss -0.4787
2024-12-05 16:18:59.281409: Pseudo dice [0.7176]
2024-12-05 16:18:59.282410: Epoch time: 86.4 s
2024-12-05 16:19:00.926928: 
2024-12-05 16:19:00.927798: Epoch 150
2024-12-05 16:19:00.928549: Current learning rate: 0.00864
2024-12-05 16:20:27.334091: Validation loss did not improve from -0.53026. Patience: 13/50
2024-12-05 16:20:27.335347: train_loss -0.7436
2024-12-05 16:20:27.336229: val_loss -0.479
2024-12-05 16:20:27.337136: Pseudo dice [0.7215]
2024-12-05 16:20:27.337983: Epoch time: 86.41 s
2024-12-05 16:20:28.666451: 
2024-12-05 16:20:28.667641: Epoch 151
2024-12-05 16:20:28.668578: Current learning rate: 0.00863
2024-12-05 16:21:55.089119: Validation loss did not improve from -0.53026. Patience: 14/50
2024-12-05 16:21:55.090162: train_loss -0.7393
2024-12-05 16:21:55.090831: val_loss -0.5151
2024-12-05 16:21:55.091535: Pseudo dice [0.7338]
2024-12-05 16:21:55.092171: Epoch time: 86.42 s
2024-12-05 16:21:56.406978: 
2024-12-05 16:21:56.408472: Epoch 152
2024-12-05 16:21:56.409266: Current learning rate: 0.00862
2024-12-05 16:23:23.057603: Validation loss did not improve from -0.53026. Patience: 15/50
2024-12-05 16:23:23.058891: train_loss -0.7392
2024-12-05 16:23:23.059756: val_loss -0.4972
2024-12-05 16:23:23.060465: Pseudo dice [0.7182]
2024-12-05 16:23:23.061357: Epoch time: 86.65 s
2024-12-05 16:23:24.347566: 
2024-12-05 16:23:24.349071: Epoch 153
2024-12-05 16:23:24.349872: Current learning rate: 0.00861
2024-12-05 16:24:50.802560: Validation loss did not improve from -0.53026. Patience: 16/50
2024-12-05 16:24:50.803758: train_loss -0.7406
2024-12-05 16:24:50.804592: val_loss -0.4678
2024-12-05 16:24:50.805449: Pseudo dice [0.7066]
2024-12-05 16:24:50.806171: Epoch time: 86.46 s
2024-12-05 16:24:52.103749: 
2024-12-05 16:24:52.105127: Epoch 154
2024-12-05 16:24:52.105811: Current learning rate: 0.0086
2024-12-05 16:26:18.685749: Validation loss did not improve from -0.53026. Patience: 17/50
2024-12-05 16:26:18.686607: train_loss -0.7413
2024-12-05 16:26:18.687357: val_loss -0.4909
2024-12-05 16:26:18.688246: Pseudo dice [0.7137]
2024-12-05 16:26:18.689127: Epoch time: 86.58 s
2024-12-05 16:26:20.443702: 
2024-12-05 16:26:20.445050: Epoch 155
2024-12-05 16:26:20.446043: Current learning rate: 0.00859
2024-12-05 16:27:47.084363: Validation loss did not improve from -0.53026. Patience: 18/50
2024-12-05 16:27:47.085530: train_loss -0.7362
2024-12-05 16:27:47.086352: val_loss -0.5055
2024-12-05 16:27:47.087106: Pseudo dice [0.724]
2024-12-05 16:27:47.087790: Epoch time: 86.64 s
2024-12-05 16:27:48.749387: 
2024-12-05 16:27:48.750331: Epoch 156
2024-12-05 16:27:48.750981: Current learning rate: 0.00858
2024-12-05 16:29:15.127269: Validation loss did not improve from -0.53026. Patience: 19/50
2024-12-05 16:29:15.128120: train_loss -0.738
2024-12-05 16:29:15.129128: val_loss -0.4653
2024-12-05 16:29:15.130059: Pseudo dice [0.6939]
2024-12-05 16:29:15.130689: Epoch time: 86.38 s
2024-12-05 16:29:16.456051: 
2024-12-05 16:29:16.457203: Epoch 157
2024-12-05 16:29:16.457932: Current learning rate: 0.00858
2024-12-05 16:30:42.894970: Validation loss did not improve from -0.53026. Patience: 20/50
2024-12-05 16:30:42.896235: train_loss -0.7339
2024-12-05 16:30:42.897650: val_loss -0.5221
2024-12-05 16:30:42.898593: Pseudo dice [0.7352]
2024-12-05 16:30:42.899645: Epoch time: 86.44 s
2024-12-05 16:30:44.228878: 
2024-12-05 16:30:44.230264: Epoch 158
2024-12-05 16:30:44.231030: Current learning rate: 0.00857
2024-12-05 16:32:10.690700: Validation loss did not improve from -0.53026. Patience: 21/50
2024-12-05 16:32:10.691940: train_loss -0.7365
2024-12-05 16:32:10.692904: val_loss -0.471
2024-12-05 16:32:10.693727: Pseudo dice [0.7142]
2024-12-05 16:32:10.694380: Epoch time: 86.46 s
2024-12-05 16:32:12.023170: 
2024-12-05 16:32:12.024345: Epoch 159
2024-12-05 16:32:12.025100: Current learning rate: 0.00856
2024-12-05 16:33:38.554971: Validation loss did not improve from -0.53026. Patience: 22/50
2024-12-05 16:33:38.556132: train_loss -0.7409
2024-12-05 16:33:38.556975: val_loss -0.5171
2024-12-05 16:33:38.557743: Pseudo dice [0.7236]
2024-12-05 16:33:38.558506: Epoch time: 86.53 s
2024-12-05 16:33:40.218072: 
2024-12-05 16:33:40.218993: Epoch 160
2024-12-05 16:33:40.219781: Current learning rate: 0.00855
2024-12-05 16:35:06.553081: Validation loss did not improve from -0.53026. Patience: 23/50
2024-12-05 16:35:06.554102: train_loss -0.7455
2024-12-05 16:35:06.555005: val_loss -0.5247
2024-12-05 16:35:06.555655: Pseudo dice [0.7351]
2024-12-05 16:35:06.556371: Epoch time: 86.34 s
2024-12-05 16:35:07.889048: 
2024-12-05 16:35:07.890518: Epoch 161
2024-12-05 16:35:07.891184: Current learning rate: 0.00854
2024-12-05 16:36:34.371190: Validation loss did not improve from -0.53026. Patience: 24/50
2024-12-05 16:36:34.372275: train_loss -0.7431
2024-12-05 16:36:34.373392: val_loss -0.5095
2024-12-05 16:36:34.374316: Pseudo dice [0.7208]
2024-12-05 16:36:34.375283: Epoch time: 86.48 s
2024-12-05 16:36:35.696209: 
2024-12-05 16:36:35.697392: Epoch 162
2024-12-05 16:36:35.698501: Current learning rate: 0.00853
2024-12-05 16:38:02.210743: Validation loss did not improve from -0.53026. Patience: 25/50
2024-12-05 16:38:02.211786: train_loss -0.7433
2024-12-05 16:38:02.212514: val_loss -0.4693
2024-12-05 16:38:02.213152: Pseudo dice [0.711]
2024-12-05 16:38:02.213886: Epoch time: 86.52 s
2024-12-05 16:38:03.573572: 
2024-12-05 16:38:03.574954: Epoch 163
2024-12-05 16:38:03.575685: Current learning rate: 0.00852
2024-12-05 16:39:30.193576: Validation loss did not improve from -0.53026. Patience: 26/50
2024-12-05 16:39:30.194489: train_loss -0.7371
2024-12-05 16:39:30.195318: val_loss -0.48
2024-12-05 16:39:30.196089: Pseudo dice [0.7172]
2024-12-05 16:39:30.196996: Epoch time: 86.62 s
2024-12-05 16:39:31.593003: 
2024-12-05 16:39:31.594428: Epoch 164
2024-12-05 16:39:31.595556: Current learning rate: 0.00851
2024-12-05 16:40:58.187308: Validation loss did not improve from -0.53026. Patience: 27/50
2024-12-05 16:40:58.188475: train_loss -0.743
2024-12-05 16:40:58.189385: val_loss -0.4984
2024-12-05 16:40:58.190017: Pseudo dice [0.7196]
2024-12-05 16:40:58.190788: Epoch time: 86.6 s
2024-12-05 16:40:59.845837: 
2024-12-05 16:40:59.847654: Epoch 165
2024-12-05 16:40:59.848414: Current learning rate: 0.0085
2024-12-05 16:42:26.554189: Validation loss did not improve from -0.53026. Patience: 28/50
2024-12-05 16:42:26.555207: train_loss -0.7296
2024-12-05 16:42:26.556016: val_loss -0.4888
2024-12-05 16:42:26.556659: Pseudo dice [0.7144]
2024-12-05 16:42:26.557288: Epoch time: 86.71 s
2024-12-05 16:42:28.238585: 
2024-12-05 16:42:28.239891: Epoch 166
2024-12-05 16:42:28.240587: Current learning rate: 0.00849
2024-12-05 16:43:54.827743: Validation loss did not improve from -0.53026. Patience: 29/50
2024-12-05 16:43:54.828783: train_loss -0.7327
2024-12-05 16:43:54.829868: val_loss -0.4497
2024-12-05 16:43:54.830925: Pseudo dice [0.6967]
2024-12-05 16:43:54.831985: Epoch time: 86.59 s
2024-12-05 16:43:56.236228: 
2024-12-05 16:43:56.237648: Epoch 167
2024-12-05 16:43:56.238445: Current learning rate: 0.00848
2024-12-05 16:45:22.872957: Validation loss did not improve from -0.53026. Patience: 30/50
2024-12-05 16:45:22.874158: train_loss -0.7435
2024-12-05 16:45:22.875309: val_loss -0.499
2024-12-05 16:45:22.876193: Pseudo dice [0.7209]
2024-12-05 16:45:22.877095: Epoch time: 86.64 s
2024-12-05 16:45:24.191320: 
2024-12-05 16:45:24.193217: Epoch 168
2024-12-05 16:45:24.194394: Current learning rate: 0.00847
2024-12-05 16:46:51.171911: Validation loss did not improve from -0.53026. Patience: 31/50
2024-12-05 16:46:51.172988: train_loss -0.7396
2024-12-05 16:46:51.173959: val_loss -0.5124
2024-12-05 16:46:51.174738: Pseudo dice [0.728]
2024-12-05 16:46:51.175562: Epoch time: 86.98 s
2024-12-05 16:46:52.489364: 
2024-12-05 16:46:52.490945: Epoch 169
2024-12-05 16:46:52.492056: Current learning rate: 0.00847
2024-12-05 16:48:19.313088: Validation loss did not improve from -0.53026. Patience: 32/50
2024-12-05 16:48:19.314104: train_loss -0.7468
2024-12-05 16:48:19.315251: val_loss -0.5041
2024-12-05 16:48:19.316239: Pseudo dice [0.7287]
2024-12-05 16:48:19.317134: Epoch time: 86.83 s
2024-12-05 16:48:20.996164: 
2024-12-05 16:48:20.997756: Epoch 170
2024-12-05 16:48:20.998585: Current learning rate: 0.00846
2024-12-05 16:49:47.615132: Validation loss did not improve from -0.53026. Patience: 33/50
2024-12-05 16:49:47.616335: train_loss -0.7442
2024-12-05 16:49:47.617385: val_loss -0.4996
2024-12-05 16:49:47.618260: Pseudo dice [0.7144]
2024-12-05 16:49:47.618988: Epoch time: 86.62 s
2024-12-05 16:49:48.937522: 
2024-12-05 16:49:48.939259: Epoch 171
2024-12-05 16:49:48.940463: Current learning rate: 0.00845
2024-12-05 16:51:15.582222: Validation loss did not improve from -0.53026. Patience: 34/50
2024-12-05 16:51:15.583180: train_loss -0.7419
2024-12-05 16:51:15.584018: val_loss -0.4868
2024-12-05 16:51:15.584785: Pseudo dice [0.7231]
2024-12-05 16:51:15.585480: Epoch time: 86.65 s
2024-12-05 16:51:16.856035: 
2024-12-05 16:51:16.857481: Epoch 172
2024-12-05 16:51:16.858294: Current learning rate: 0.00844
2024-12-05 16:52:44.141474: Validation loss did not improve from -0.53026. Patience: 35/50
2024-12-05 16:52:44.142716: train_loss -0.7482
2024-12-05 16:52:44.143751: val_loss -0.4767
2024-12-05 16:52:44.144736: Pseudo dice [0.7166]
2024-12-05 16:52:44.145502: Epoch time: 87.29 s
2024-12-05 16:52:45.488451: 
2024-12-05 16:52:45.490092: Epoch 173
2024-12-05 16:52:45.490928: Current learning rate: 0.00843
2024-12-05 16:54:12.409224: Validation loss did not improve from -0.53026. Patience: 36/50
2024-12-05 16:54:12.410037: train_loss -0.7555
2024-12-05 16:54:12.411117: val_loss -0.5256
2024-12-05 16:54:12.412003: Pseudo dice [0.736]
2024-12-05 16:54:12.412876: Epoch time: 86.92 s
2024-12-05 16:54:13.722309: 
2024-12-05 16:54:13.723893: Epoch 174
2024-12-05 16:54:13.724781: Current learning rate: 0.00842
2024-12-05 16:55:40.316902: Validation loss did not improve from -0.53026. Patience: 37/50
2024-12-05 16:55:40.318111: train_loss -0.7548
2024-12-05 16:55:40.318869: val_loss -0.5016
2024-12-05 16:55:40.319566: Pseudo dice [0.7187]
2024-12-05 16:55:40.320275: Epoch time: 86.6 s
2024-12-05 16:55:41.992443: 
2024-12-05 16:55:41.993310: Epoch 175
2024-12-05 16:55:41.994006: Current learning rate: 0.00841
2024-12-05 16:57:09.561404: Validation loss did not improve from -0.53026. Patience: 38/50
2024-12-05 16:57:09.611935: train_loss -0.7516
2024-12-05 16:57:09.613859: val_loss -0.4774
2024-12-05 16:57:09.614861: Pseudo dice [0.7195]
2024-12-05 16:57:09.616187: Epoch time: 87.6 s
2024-12-05 16:57:12.486974: 
2024-12-05 16:57:12.488933: Epoch 176
2024-12-05 16:57:12.489848: Current learning rate: 0.0084
2024-12-05 16:58:39.139741: Validation loss did not improve from -0.53026. Patience: 39/50
2024-12-05 16:58:39.140644: train_loss -0.749
2024-12-05 16:58:39.141518: val_loss -0.5173
2024-12-05 16:58:39.142294: Pseudo dice [0.7349]
2024-12-05 16:58:39.142950: Epoch time: 86.65 s
2024-12-05 16:58:40.427212: 
2024-12-05 16:58:40.428828: Epoch 177
2024-12-05 16:58:40.429708: Current learning rate: 0.00839
2024-12-05 17:00:06.780300: Validation loss did not improve from -0.53026. Patience: 40/50
2024-12-05 17:00:06.781136: train_loss -0.7479
2024-12-05 17:00:06.782207: val_loss -0.5172
2024-12-05 17:00:06.782921: Pseudo dice [0.7321]
2024-12-05 17:00:06.783611: Epoch time: 86.35 s
2024-12-05 17:00:08.084417: 
2024-12-05 17:00:08.085838: Epoch 178
2024-12-05 17:00:08.086525: Current learning rate: 0.00838
2024-12-05 17:01:34.497420: Validation loss did not improve from -0.53026. Patience: 41/50
2024-12-05 17:01:34.498503: train_loss -0.7578
2024-12-05 17:01:34.499431: val_loss -0.5187
2024-12-05 17:01:34.500144: Pseudo dice [0.7358]
2024-12-05 17:01:34.500824: Epoch time: 86.42 s
2024-12-05 17:01:35.855556: 
2024-12-05 17:01:35.857069: Epoch 179
2024-12-05 17:01:35.857982: Current learning rate: 0.00837
2024-12-05 17:03:02.278988: Validation loss did not improve from -0.53026. Patience: 42/50
2024-12-05 17:03:02.279913: train_loss -0.7524
2024-12-05 17:03:02.280682: val_loss -0.4839
2024-12-05 17:03:02.281415: Pseudo dice [0.727]
2024-12-05 17:03:02.282061: Epoch time: 86.43 s
2024-12-05 17:03:04.014309: 
2024-12-05 17:03:04.015730: Epoch 180
2024-12-05 17:03:04.016406: Current learning rate: 0.00836
2024-12-05 17:04:30.346318: Validation loss did not improve from -0.53026. Patience: 43/50
2024-12-05 17:04:30.347471: train_loss -0.7553
2024-12-05 17:04:30.348351: val_loss -0.5015
2024-12-05 17:04:30.349024: Pseudo dice [0.7256]
2024-12-05 17:04:30.349744: Epoch time: 86.33 s
2024-12-05 17:04:31.653336: 
2024-12-05 17:04:31.654904: Epoch 181
2024-12-05 17:04:31.655854: Current learning rate: 0.00836
2024-12-05 17:05:58.046471: Validation loss did not improve from -0.53026. Patience: 44/50
2024-12-05 17:05:58.047465: train_loss -0.7545
2024-12-05 17:05:58.048365: val_loss -0.5001
2024-12-05 17:05:58.049323: Pseudo dice [0.7315]
2024-12-05 17:05:58.050271: Epoch time: 86.4 s
2024-12-05 17:05:58.051133: Yayy! New best EMA pseudo Dice: 0.7253
2024-12-05 17:05:59.725628: 
2024-12-05 17:05:59.727017: Epoch 182
2024-12-05 17:05:59.727823: Current learning rate: 0.00835
2024-12-05 17:07:26.567119: Validation loss did not improve from -0.53026. Patience: 45/50
2024-12-05 17:07:26.568251: train_loss -0.7596
2024-12-05 17:07:26.569165: val_loss -0.4908
2024-12-05 17:07:26.569921: Pseudo dice [0.7153]
2024-12-05 17:07:26.570574: Epoch time: 86.84 s
2024-12-05 17:07:27.859117: 
2024-12-05 17:07:27.860327: Epoch 183
2024-12-05 17:07:27.861039: Current learning rate: 0.00834
2024-12-05 17:08:54.404950: Validation loss did not improve from -0.53026. Patience: 46/50
2024-12-05 17:08:54.406085: train_loss -0.7551
2024-12-05 17:08:54.406994: val_loss -0.5073
2024-12-05 17:08:54.407702: Pseudo dice [0.744]
2024-12-05 17:08:54.408502: Epoch time: 86.55 s
2024-12-05 17:08:54.409327: Yayy! New best EMA pseudo Dice: 0.7263
2024-12-05 17:08:56.087061: 
2024-12-05 17:08:56.088525: Epoch 184
2024-12-05 17:08:56.089467: Current learning rate: 0.00833
2024-12-05 17:10:22.618288: Validation loss did not improve from -0.53026. Patience: 47/50
2024-12-05 17:10:22.619357: train_loss -0.7585
2024-12-05 17:10:22.620176: val_loss -0.4936
2024-12-05 17:10:22.620871: Pseudo dice [0.7203]
2024-12-05 17:10:22.621537: Epoch time: 86.53 s
2024-12-05 17:10:24.342477: 
2024-12-05 17:10:24.344123: Epoch 185
2024-12-05 17:10:24.345009: Current learning rate: 0.00832
2024-12-05 17:11:50.709266: Validation loss did not improve from -0.53026. Patience: 48/50
2024-12-05 17:11:50.710157: train_loss -0.7579
2024-12-05 17:11:50.710940: val_loss -0.4923
2024-12-05 17:11:50.711686: Pseudo dice [0.7232]
2024-12-05 17:11:50.712442: Epoch time: 86.37 s
2024-12-05 17:11:52.392885: 
2024-12-05 17:11:52.394559: Epoch 186
2024-12-05 17:11:52.395581: Current learning rate: 0.00831
2024-12-05 17:13:18.720631: Validation loss did not improve from -0.53026. Patience: 49/50
2024-12-05 17:13:18.721656: train_loss -0.7609
2024-12-05 17:13:18.722482: val_loss -0.5085
2024-12-05 17:13:18.723226: Pseudo dice [0.7385]
2024-12-05 17:13:18.724036: Epoch time: 86.33 s
2024-12-05 17:13:18.724748: Yayy! New best EMA pseudo Dice: 0.7267
2024-12-05 17:13:20.396590: 
2024-12-05 17:13:20.397878: Epoch 187
2024-12-05 17:13:20.398745: Current learning rate: 0.0083
2024-12-05 17:14:46.731424: Validation loss did not improve from -0.53026. Patience: 50/50
2024-12-05 17:14:46.732467: train_loss -0.7647
2024-12-05 17:14:46.733338: val_loss -0.5051
2024-12-05 17:14:46.734202: Pseudo dice [0.7271]
2024-12-05 17:14:46.734939: Epoch time: 86.34 s
2024-12-05 17:14:46.735623: Yayy! New best EMA pseudo Dice: 0.7268
2024-12-05 17:14:48.439135: Patience reached. Stopping training.
2024-12-05 17:14:48.858871: Training done.
2024-12-05 17:14:49.342643: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset307_Sohee_Calcium_OCT_CrossValidation/splits_final.json
2024-12-05 17:14:49.368137: The split file contains 5 splits.
2024-12-05 17:14:49.368871: Desired fold for training: 4
2024-12-05 17:14:49.369820: This split has 7 training and 1 validation cases.
2024-12-05 17:14:49.370665: predicting 101-045
2024-12-05 17:14:49.384354: 101-045, shape torch.Size([1, 375, 498, 498]), rank 0
2024-12-05 17:18:00.376323: Validation complete
2024-12-05 17:18:00.377063: Mean Validation Dice:  0.7299560955018082
