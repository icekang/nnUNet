/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/bin/python
Starting training with CONFIG=3d_32x160x128_b10, DATASET_ID=310, TRAINER=nnUNetTrainerScaleAnalysis40
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:169: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2025-10-05 21:06:07.725949: do_dummy_2d_data_aug: True
2025-10-05 21:06:07.726422: Using splits from existing split file: /nfs/erelab001/shared/Computational_Group/Naravich/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset310_nnInteractive_Calcium_OCT_CrossValidation/splits_final_40.json
2025-10-05 21:06:07.726823: The split file contains 5 splits.
2025-10-05 21:06:07.727001: Desired fold for training: 3
2025-10-05 21:06:07.727144: This split has 3 training and 6 validation cases.
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
using pin_memory on device 0
using pin_memory on device 0
2025-10-05 21:06:13.170231: Using torch.compile...

This is the configuration used by this training:
Configuration name: 3d_32x160x128_b10
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 10, 'patch_size': [32, 160, 128], 'median_image_size_in_voxels': [375.0, 498.0, 498.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'inherits_from': '3d_fullres'} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset310_nnInteractive_Calcium_OCT_CrossValidation', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.4977976381778717, 'mean': 0.1394134759902954, 'median': 0.09849607944488525, 'min': 0.0, 'percentile_00_5': 0.015305490233004093, 'percentile_99_5': 0.4977976381778717, 'std': 0.121165432035923}}} 

2025-10-05 21:06:14.677589: unpacking dataset...
2025-10-05 21:06:19.122526: unpacking done...
2025-10-05 21:06:19.124991: Unable to plot network architecture: nnUNet_compile is enabled!
2025-10-05 21:06:19.130217: 
2025-10-05 21:06:19.130492: Epoch 0
2025-10-05 21:06:19.130724: Current learning rate: 0.01
2025-10-05 21:07:11.596289: Validation loss improved from 1000.00000 to -0.07250! Patience: 0/50
2025-10-05 21:07:11.597018: train_loss -0.1505
2025-10-05 21:07:11.597224: val_loss -0.0725
2025-10-05 21:07:11.597366: Pseudo dice [np.float32(0.5136)]
2025-10-05 21:07:11.597518: Epoch time: 52.47 s
2025-10-05 21:07:11.597688: Yayy! New best EMA pseudo Dice: 0.5135999917984009
2025-10-05 21:07:12.807003: 
2025-10-05 21:07:12.807420: Epoch 1
2025-10-05 21:07:12.807645: Current learning rate: 0.00994
2025-10-05 21:07:58.970168: Validation loss improved from -0.07250 to -0.12273! Patience: 0/50
2025-10-05 21:07:58.970768: train_loss -0.2853
2025-10-05 21:07:58.970939: val_loss -0.1227
2025-10-05 21:07:58.971057: Pseudo dice [np.float32(0.5151)]
2025-10-05 21:07:58.971250: Epoch time: 46.16 s
2025-10-05 21:07:58.971391: Yayy! New best EMA pseudo Dice: 0.5138000249862671
2025-10-05 21:08:00.053507: 
2025-10-05 21:08:00.053821: Epoch 2
2025-10-05 21:08:00.054032: Current learning rate: 0.00988
2025-10-05 21:08:46.212388: Validation loss did not improve from -0.12273. Patience: 1/50
2025-10-05 21:08:46.213022: train_loss -0.3393
2025-10-05 21:08:46.213197: val_loss -0.1029
2025-10-05 21:08:46.213375: Pseudo dice [np.float32(0.5273)]
2025-10-05 21:08:46.213527: Epoch time: 46.16 s
2025-10-05 21:08:46.213652: Yayy! New best EMA pseudo Dice: 0.5151000022888184
2025-10-05 21:08:47.269670: 
2025-10-05 21:08:47.270053: Epoch 3
2025-10-05 21:08:47.270299: Current learning rate: 0.00982
2025-10-05 21:09:33.422492: Validation loss improved from -0.12273 to -0.15545! Patience: 1/50
2025-10-05 21:09:33.422975: train_loss -0.3898
2025-10-05 21:09:33.423119: val_loss -0.1554
2025-10-05 21:09:33.423274: Pseudo dice [np.float32(0.5559)]
2025-10-05 21:09:33.423418: Epoch time: 46.15 s
2025-10-05 21:09:33.423558: Yayy! New best EMA pseudo Dice: 0.5192000269889832
2025-10-05 21:09:34.524611: 
2025-10-05 21:09:34.524904: Epoch 4
2025-10-05 21:09:34.525116: Current learning rate: 0.00976
2025-10-05 21:10:20.745970: Validation loss improved from -0.15545 to -0.18882! Patience: 0/50
2025-10-05 21:10:20.746616: train_loss -0.4241
2025-10-05 21:10:20.746788: val_loss -0.1888
2025-10-05 21:10:20.746918: Pseudo dice [np.float32(0.5533)]
2025-10-05 21:10:20.747080: Epoch time: 46.22 s
2025-10-05 21:10:21.134305: Yayy! New best EMA pseudo Dice: 0.522599995136261
2025-10-05 21:10:22.234288: 
2025-10-05 21:10:22.234635: Epoch 5
2025-10-05 21:10:22.234852: Current learning rate: 0.0097
2025-10-05 21:11:08.535559: Validation loss improved from -0.18882 to -0.21757! Patience: 0/50
2025-10-05 21:11:08.536120: train_loss -0.4575
2025-10-05 21:11:08.536362: val_loss -0.2176
2025-10-05 21:11:08.536585: Pseudo dice [np.float32(0.5785)]
2025-10-05 21:11:08.536945: Epoch time: 46.3 s
2025-10-05 21:11:08.537126: Yayy! New best EMA pseudo Dice: 0.5281999707221985
2025-10-05 21:11:09.612768: 
2025-10-05 21:11:09.613167: Epoch 6
2025-10-05 21:11:09.613443: Current learning rate: 0.00964
2025-10-05 21:11:55.900560: Validation loss improved from -0.21757 to -0.23273! Patience: 0/50
2025-10-05 21:11:55.915900: train_loss -0.4775
2025-10-05 21:11:55.921804: val_loss -0.2327
2025-10-05 21:11:55.927575: Pseudo dice [np.float32(0.5835)]
2025-10-05 21:11:55.933825: Epoch time: 46.3 s
2025-10-05 21:11:55.940911: Yayy! New best EMA pseudo Dice: 0.5336999893188477
2025-10-05 21:11:57.051033: 
2025-10-05 21:11:57.051360: Epoch 7
2025-10-05 21:11:57.051572: Current learning rate: 0.00958
2025-10-05 21:12:43.245790: Validation loss improved from -0.23273 to -0.24606! Patience: 0/50
2025-10-05 21:12:43.246204: train_loss -0.5006
2025-10-05 21:12:43.246403: val_loss -0.2461
2025-10-05 21:12:43.246574: Pseudo dice [np.float32(0.6016)]
2025-10-05 21:12:43.246753: Epoch time: 46.2 s
2025-10-05 21:12:43.246916: Yayy! New best EMA pseudo Dice: 0.5404999852180481
2025-10-05 21:12:44.309902: 
2025-10-05 21:12:44.310247: Epoch 8
2025-10-05 21:12:44.310467: Current learning rate: 0.00952
2025-10-05 21:13:30.535768: Validation loss did not improve from -0.24606. Patience: 1/50
2025-10-05 21:13:30.536531: train_loss -0.5131
2025-10-05 21:13:30.536835: val_loss -0.2429
2025-10-05 21:13:30.537079: Pseudo dice [np.float32(0.6178)]
2025-10-05 21:13:30.537368: Epoch time: 46.23 s
2025-10-05 21:13:30.537576: Yayy! New best EMA pseudo Dice: 0.54830002784729
2025-10-05 21:13:31.609512: 
2025-10-05 21:13:31.609836: Epoch 9
2025-10-05 21:13:31.610082: Current learning rate: 0.00946
2025-10-05 21:14:17.879547: Validation loss improved from -0.24606 to -0.25409! Patience: 1/50
2025-10-05 21:14:17.879888: train_loss -0.5168
2025-10-05 21:14:17.880023: val_loss -0.2541
2025-10-05 21:14:17.880127: Pseudo dice [np.float32(0.6109)]
2025-10-05 21:14:17.880251: Epoch time: 46.27 s
2025-10-05 21:14:18.321673: Yayy! New best EMA pseudo Dice: 0.5544999837875366
2025-10-05 21:14:19.437471: 
2025-10-05 21:14:19.437753: Epoch 10
2025-10-05 21:14:19.437942: Current learning rate: 0.0094
2025-10-05 21:15:05.732683: Validation loss improved from -0.25409 to -0.28694! Patience: 0/50
2025-10-05 21:15:05.733313: train_loss -0.5271
2025-10-05 21:15:05.733511: val_loss -0.2869
2025-10-05 21:15:05.733656: Pseudo dice [np.float32(0.6378)]
2025-10-05 21:15:05.733827: Epoch time: 46.3 s
2025-10-05 21:15:05.733942: Yayy! New best EMA pseudo Dice: 0.5629000067710876
2025-10-05 21:15:06.863540: 
2025-10-05 21:15:06.864044: Epoch 11
2025-10-05 21:15:06.864262: Current learning rate: 0.00934
2025-10-05 21:15:53.298187: Validation loss did not improve from -0.28694. Patience: 1/50
2025-10-05 21:15:53.298687: train_loss -0.5457
2025-10-05 21:15:53.298858: val_loss -0.2744
2025-10-05 21:15:53.299008: Pseudo dice [np.float32(0.6158)]
2025-10-05 21:15:53.299160: Epoch time: 46.44 s
2025-10-05 21:15:53.299268: Yayy! New best EMA pseudo Dice: 0.5681999921798706
2025-10-05 21:15:54.770071: 
2025-10-05 21:15:54.770447: Epoch 12
2025-10-05 21:15:54.770663: Current learning rate: 0.00928
2025-10-05 21:16:41.054143: Validation loss did not improve from -0.28694. Patience: 2/50
2025-10-05 21:16:41.054729: train_loss -0.5545
2025-10-05 21:16:41.054895: val_loss -0.2134
2025-10-05 21:16:41.055023: Pseudo dice [np.float32(0.6166)]
2025-10-05 21:16:41.055171: Epoch time: 46.29 s
2025-10-05 21:16:41.055305: Yayy! New best EMA pseudo Dice: 0.5730000138282776
2025-10-05 21:16:42.145804: 
2025-10-05 21:16:42.146187: Epoch 13
2025-10-05 21:16:42.146420: Current learning rate: 0.00922
2025-10-05 21:17:28.339417: Validation loss did not improve from -0.28694. Patience: 3/50
2025-10-05 21:17:28.339944: train_loss -0.577
2025-10-05 21:17:28.340120: val_loss -0.2829
2025-10-05 21:17:28.340242: Pseudo dice [np.float32(0.6374)]
2025-10-05 21:17:28.340392: Epoch time: 46.19 s
2025-10-05 21:17:28.340523: Yayy! New best EMA pseudo Dice: 0.5794000029563904
2025-10-05 21:17:29.428837: 
2025-10-05 21:17:29.429171: Epoch 14
2025-10-05 21:17:29.429372: Current learning rate: 0.00916
2025-10-05 21:18:15.657025: Validation loss improved from -0.28694 to -0.28899! Patience: 3/50
2025-10-05 21:18:15.657920: train_loss -0.579
2025-10-05 21:18:15.658297: val_loss -0.289
2025-10-05 21:18:15.658529: Pseudo dice [np.float32(0.6324)]
2025-10-05 21:18:15.658723: Epoch time: 46.23 s
2025-10-05 21:18:16.103202: Yayy! New best EMA pseudo Dice: 0.5846999883651733
2025-10-05 21:18:17.184599: 
2025-10-05 21:18:17.185040: Epoch 15
2025-10-05 21:18:17.185280: Current learning rate: 0.0091
2025-10-05 21:19:03.525213: Validation loss improved from -0.28899 to -0.30134! Patience: 0/50
2025-10-05 21:19:03.525664: train_loss -0.5633
2025-10-05 21:19:03.525847: val_loss -0.3013
2025-10-05 21:19:03.526001: Pseudo dice [np.float32(0.6529)]
2025-10-05 21:19:03.526171: Epoch time: 46.34 s
2025-10-05 21:19:03.526343: Yayy! New best EMA pseudo Dice: 0.5916000008583069
2025-10-05 21:19:04.612700: 
2025-10-05 21:19:04.613106: Epoch 16
2025-10-05 21:19:04.613358: Current learning rate: 0.00903
2025-10-05 21:19:51.048971: Validation loss did not improve from -0.30134. Patience: 1/50
2025-10-05 21:19:51.049539: train_loss -0.5933
2025-10-05 21:19:51.049686: val_loss -0.2968
2025-10-05 21:19:51.049876: Pseudo dice [np.float32(0.6566)]
2025-10-05 21:19:51.050035: Epoch time: 46.44 s
2025-10-05 21:19:51.050172: Yayy! New best EMA pseudo Dice: 0.5981000065803528
2025-10-05 21:19:52.177270: 
2025-10-05 21:19:52.177679: Epoch 17
2025-10-05 21:19:52.178027: Current learning rate: 0.00897
2025-10-05 21:20:38.595080: Validation loss did not improve from -0.30134. Patience: 2/50
2025-10-05 21:20:38.595563: train_loss -0.6016
2025-10-05 21:20:38.595707: val_loss -0.2917
2025-10-05 21:20:38.595844: Pseudo dice [np.float32(0.6532)]
2025-10-05 21:20:38.596043: Epoch time: 46.42 s
2025-10-05 21:20:38.596219: Yayy! New best EMA pseudo Dice: 0.603600025177002
2025-10-05 21:20:39.670224: 
2025-10-05 21:20:39.670502: Epoch 18
2025-10-05 21:20:39.670698: Current learning rate: 0.00891
2025-10-05 21:21:26.011796: Validation loss did not improve from -0.30134. Patience: 3/50
2025-10-05 21:21:26.012317: train_loss -0.6102
2025-10-05 21:21:26.012466: val_loss -0.2839
2025-10-05 21:21:26.012593: Pseudo dice [np.float32(0.6344)]
2025-10-05 21:21:26.012721: Epoch time: 46.34 s
2025-10-05 21:21:26.012830: Yayy! New best EMA pseudo Dice: 0.6065999865531921
2025-10-05 21:21:27.097492: 
2025-10-05 21:21:27.097844: Epoch 19
2025-10-05 21:21:27.098058: Current learning rate: 0.00885
2025-10-05 21:22:13.314553: Validation loss did not improve from -0.30134. Patience: 4/50
2025-10-05 21:22:13.314990: train_loss -0.6208
2025-10-05 21:22:13.315145: val_loss -0.2784
2025-10-05 21:22:13.315330: Pseudo dice [np.float32(0.6211)]
2025-10-05 21:22:13.315586: Epoch time: 46.22 s
2025-10-05 21:22:13.779347: Yayy! New best EMA pseudo Dice: 0.6080999970436096
2025-10-05 21:22:14.844483: 
2025-10-05 21:22:14.844841: Epoch 20
2025-10-05 21:22:14.845035: Current learning rate: 0.00879
2025-10-05 21:23:01.249371: Validation loss did not improve from -0.30134. Patience: 5/50
2025-10-05 21:23:01.250020: train_loss -0.6384
2025-10-05 21:23:01.250235: val_loss -0.2714
2025-10-05 21:23:01.250369: Pseudo dice [np.float32(0.6411)]
2025-10-05 21:23:01.250507: Epoch time: 46.41 s
2025-10-05 21:23:01.250633: Yayy! New best EMA pseudo Dice: 0.6114000082015991
2025-10-05 21:23:02.380889: 
2025-10-05 21:23:02.381298: Epoch 21
2025-10-05 21:23:02.381546: Current learning rate: 0.00873
2025-10-05 21:23:48.745835: Validation loss did not improve from -0.30134. Patience: 6/50
2025-10-05 21:23:48.746456: train_loss -0.6407
2025-10-05 21:23:48.746783: val_loss -0.2825
2025-10-05 21:23:48.747106: Pseudo dice [np.float32(0.635)]
2025-10-05 21:23:48.747479: Epoch time: 46.37 s
2025-10-05 21:23:48.747746: Yayy! New best EMA pseudo Dice: 0.6137999892234802
2025-10-05 21:23:49.831773: 
2025-10-05 21:23:49.832142: Epoch 22
2025-10-05 21:23:49.832387: Current learning rate: 0.00867
2025-10-05 21:24:36.100304: Validation loss did not improve from -0.30134. Patience: 7/50
2025-10-05 21:24:36.101145: train_loss -0.6407
2025-10-05 21:24:36.101513: val_loss -0.2755
2025-10-05 21:24:36.101814: Pseudo dice [np.float32(0.6559)]
2025-10-05 21:24:36.102117: Epoch time: 46.27 s
2025-10-05 21:24:36.102351: Yayy! New best EMA pseudo Dice: 0.6179999709129333
2025-10-05 21:24:37.178101: 
2025-10-05 21:24:37.178371: Epoch 23
2025-10-05 21:24:37.178544: Current learning rate: 0.00861
2025-10-05 21:25:23.290128: Validation loss did not improve from -0.30134. Patience: 8/50
2025-10-05 21:25:23.290577: train_loss -0.6551
2025-10-05 21:25:23.290728: val_loss -0.2708
2025-10-05 21:25:23.290899: Pseudo dice [np.float32(0.6267)]
2025-10-05 21:25:23.291081: Epoch time: 46.11 s
2025-10-05 21:25:23.291198: Yayy! New best EMA pseudo Dice: 0.6187999844551086
2025-10-05 21:25:24.688649: 
2025-10-05 21:25:24.689005: Epoch 24
2025-10-05 21:25:24.689229: Current learning rate: 0.00855
2025-10-05 21:26:10.785935: Validation loss improved from -0.30134 to -0.30448! Patience: 8/50
2025-10-05 21:26:10.786513: train_loss -0.6611
2025-10-05 21:26:10.786685: val_loss -0.3045
2025-10-05 21:26:10.786846: Pseudo dice [np.float32(0.6385)]
2025-10-05 21:26:10.787003: Epoch time: 46.1 s
2025-10-05 21:26:11.237859: Yayy! New best EMA pseudo Dice: 0.6208000183105469
2025-10-05 21:26:12.322095: 
2025-10-05 21:26:12.322362: Epoch 25
2025-10-05 21:26:12.322537: Current learning rate: 0.00849
2025-10-05 21:26:58.438077: Validation loss did not improve from -0.30448. Patience: 1/50
2025-10-05 21:26:58.438635: train_loss -0.6699
2025-10-05 21:26:58.438781: val_loss -0.2901
2025-10-05 21:26:58.438967: Pseudo dice [np.float32(0.6356)]
2025-10-05 21:26:58.439168: Epoch time: 46.12 s
2025-10-05 21:26:58.439343: Yayy! New best EMA pseudo Dice: 0.6223000288009644
2025-10-05 21:26:59.531748: 
2025-10-05 21:26:59.532113: Epoch 26
2025-10-05 21:26:59.532377: Current learning rate: 0.00843
2025-10-05 21:27:45.734634: Validation loss did not improve from -0.30448. Patience: 2/50
2025-10-05 21:27:45.735252: train_loss -0.6719
2025-10-05 21:27:45.735409: val_loss -0.2704
2025-10-05 21:27:45.735544: Pseudo dice [np.float32(0.6313)]
2025-10-05 21:27:45.735701: Epoch time: 46.2 s
2025-10-05 21:27:45.735820: Yayy! New best EMA pseudo Dice: 0.623199999332428
2025-10-05 21:27:46.827006: 
2025-10-05 21:27:46.827343: Epoch 27
2025-10-05 21:27:46.827550: Current learning rate: 0.00836
2025-10-05 21:28:33.006106: Validation loss did not improve from -0.30448. Patience: 3/50
2025-10-05 21:28:33.006571: train_loss -0.6804
2025-10-05 21:28:33.006730: val_loss -0.2265
2025-10-05 21:28:33.006914: Pseudo dice [np.float32(0.6276)]
2025-10-05 21:28:33.007144: Epoch time: 46.18 s
2025-10-05 21:28:33.007263: Yayy! New best EMA pseudo Dice: 0.6236000061035156
2025-10-05 21:28:34.094646: 
2025-10-05 21:28:34.094945: Epoch 28
2025-10-05 21:28:34.095149: Current learning rate: 0.0083
2025-10-05 21:29:20.204699: Validation loss did not improve from -0.30448. Patience: 4/50
2025-10-05 21:29:20.205294: train_loss -0.6891
2025-10-05 21:29:20.205467: val_loss -0.2868
2025-10-05 21:29:20.205611: Pseudo dice [np.float32(0.6419)]
2025-10-05 21:29:20.205772: Epoch time: 46.11 s
2025-10-05 21:29:20.205894: Yayy! New best EMA pseudo Dice: 0.6254000067710876
2025-10-05 21:29:21.309151: 
2025-10-05 21:29:21.309589: Epoch 29
2025-10-05 21:29:21.309844: Current learning rate: 0.00824
2025-10-05 21:30:07.409691: Validation loss did not improve from -0.30448. Patience: 5/50
2025-10-05 21:30:07.410307: train_loss -0.6946
2025-10-05 21:30:07.410567: val_loss -0.2518
2025-10-05 21:30:07.410831: Pseudo dice [np.float32(0.6499)]
2025-10-05 21:30:07.411129: Epoch time: 46.1 s
2025-10-05 21:30:07.857839: Yayy! New best EMA pseudo Dice: 0.6279000043869019
2025-10-05 21:30:08.934721: 
2025-10-05 21:30:08.935161: Epoch 30
2025-10-05 21:30:08.935436: Current learning rate: 0.00818
2025-10-05 21:30:55.050030: Validation loss did not improve from -0.30448. Patience: 6/50
2025-10-05 21:30:55.050575: train_loss -0.6908
2025-10-05 21:30:55.050714: val_loss -0.2672
2025-10-05 21:30:55.050850: Pseudo dice [np.float32(0.6388)]
2025-10-05 21:30:55.051000: Epoch time: 46.12 s
2025-10-05 21:30:55.051114: Yayy! New best EMA pseudo Dice: 0.6290000081062317
2025-10-05 21:30:56.153789: 
2025-10-05 21:30:56.154146: Epoch 31
2025-10-05 21:30:56.154362: Current learning rate: 0.00812
2025-10-05 21:31:42.407573: Validation loss did not improve from -0.30448. Patience: 7/50
2025-10-05 21:31:42.408054: train_loss -0.7099
2025-10-05 21:31:42.408239: val_loss -0.2331
2025-10-05 21:31:42.408387: Pseudo dice [np.float32(0.6444)]
2025-10-05 21:31:42.408535: Epoch time: 46.26 s
2025-10-05 21:31:42.408665: Yayy! New best EMA pseudo Dice: 0.6305000185966492
2025-10-05 21:31:43.526658: 
2025-10-05 21:31:43.527081: Epoch 32
2025-10-05 21:31:43.527261: Current learning rate: 0.00806
2025-10-05 21:32:29.746395: Validation loss did not improve from -0.30448. Patience: 8/50
2025-10-05 21:32:29.746941: train_loss -0.7106
2025-10-05 21:32:29.747094: val_loss -0.2584
2025-10-05 21:32:29.747257: Pseudo dice [np.float32(0.639)]
2025-10-05 21:32:29.747406: Epoch time: 46.22 s
2025-10-05 21:32:29.747696: Yayy! New best EMA pseudo Dice: 0.6313999891281128
2025-10-05 21:32:30.848439: 
2025-10-05 21:32:30.848765: Epoch 33
2025-10-05 21:32:30.848949: Current learning rate: 0.008
2025-10-05 21:33:16.960831: Validation loss did not improve from -0.30448. Patience: 9/50
2025-10-05 21:33:16.961275: train_loss -0.7233
2025-10-05 21:33:16.961472: val_loss -0.2406
2025-10-05 21:33:16.961622: Pseudo dice [np.float32(0.6382)]
2025-10-05 21:33:16.961789: Epoch time: 46.11 s
2025-10-05 21:33:16.961900: Yayy! New best EMA pseudo Dice: 0.632099986076355
2025-10-05 21:33:18.047472: 
2025-10-05 21:33:18.047846: Epoch 34
2025-10-05 21:33:18.048089: Current learning rate: 0.00793
2025-10-05 21:34:04.106364: Validation loss did not improve from -0.30448. Patience: 10/50
2025-10-05 21:34:04.107034: train_loss -0.7197
2025-10-05 21:34:04.107172: val_loss -0.2664
2025-10-05 21:34:04.107359: Pseudo dice [np.float32(0.6172)]
2025-10-05 21:34:04.107595: Epoch time: 46.06 s
2025-10-05 21:34:05.534898: 
2025-10-05 21:34:05.535202: Epoch 35
2025-10-05 21:34:05.535375: Current learning rate: 0.00787
2025-10-05 21:34:51.656565: Validation loss did not improve from -0.30448. Patience: 11/50
2025-10-05 21:34:51.657152: train_loss -0.7344
2025-10-05 21:34:51.657349: val_loss -0.2693
2025-10-05 21:34:51.657547: Pseudo dice [np.float32(0.6367)]
2025-10-05 21:34:51.657779: Epoch time: 46.12 s
2025-10-05 21:34:52.306765: 
2025-10-05 21:34:52.307170: Epoch 36
2025-10-05 21:34:52.307415: Current learning rate: 0.00781
2025-10-05 21:35:38.512203: Validation loss did not improve from -0.30448. Patience: 12/50
2025-10-05 21:35:38.512866: train_loss -0.7414
2025-10-05 21:35:38.513011: val_loss -0.2751
2025-10-05 21:35:38.513130: Pseudo dice [np.float32(0.6473)]
2025-10-05 21:35:38.513297: Epoch time: 46.21 s
2025-10-05 21:35:38.513471: Yayy! New best EMA pseudo Dice: 0.6327999830245972
2025-10-05 21:35:39.610007: 
2025-10-05 21:35:39.610352: Epoch 37
2025-10-05 21:35:39.610600: Current learning rate: 0.00775
2025-10-05 21:36:25.793779: Validation loss did not improve from -0.30448. Patience: 13/50
2025-10-05 21:36:25.794360: train_loss -0.7544
2025-10-05 21:36:25.794506: val_loss -0.2264
2025-10-05 21:36:25.794713: Pseudo dice [np.float32(0.6368)]
2025-10-05 21:36:25.794873: Epoch time: 46.19 s
2025-10-05 21:36:25.795027: Yayy! New best EMA pseudo Dice: 0.6331999897956848
2025-10-05 21:36:26.867076: 
2025-10-05 21:36:26.867434: Epoch 38
2025-10-05 21:36:26.867669: Current learning rate: 0.00769
2025-10-05 21:37:12.978672: Validation loss did not improve from -0.30448. Patience: 14/50
2025-10-05 21:37:12.979258: train_loss -0.7432
2025-10-05 21:37:12.979404: val_loss -0.2311
2025-10-05 21:37:12.979546: Pseudo dice [np.float32(0.6455)]
2025-10-05 21:37:12.979692: Epoch time: 46.11 s
2025-10-05 21:37:12.979853: Yayy! New best EMA pseudo Dice: 0.6344000101089478
2025-10-05 21:37:14.072944: 
2025-10-05 21:37:14.073274: Epoch 39
2025-10-05 21:37:14.073479: Current learning rate: 0.00763
2025-10-05 21:38:00.177325: Validation loss did not improve from -0.30448. Patience: 15/50
2025-10-05 21:38:00.177776: train_loss -0.7442
2025-10-05 21:38:00.177998: val_loss -0.2836
2025-10-05 21:38:00.178153: Pseudo dice [np.float32(0.6487)]
2025-10-05 21:38:00.178290: Epoch time: 46.11 s
2025-10-05 21:38:00.609616: Yayy! New best EMA pseudo Dice: 0.6358000040054321
2025-10-05 21:38:01.676944: 
2025-10-05 21:38:01.677260: Epoch 40
2025-10-05 21:38:01.677485: Current learning rate: 0.00756
2025-10-05 21:38:47.869033: Validation loss did not improve from -0.30448. Patience: 16/50
2025-10-05 21:38:47.869914: train_loss -0.7563
2025-10-05 21:38:47.870140: val_loss -0.2549
2025-10-05 21:38:47.870332: Pseudo dice [np.float32(0.6373)]
2025-10-05 21:38:47.870580: Epoch time: 46.19 s
2025-10-05 21:38:47.870780: Yayy! New best EMA pseudo Dice: 0.6359999775886536
2025-10-05 21:38:48.973929: 
2025-10-05 21:38:48.974227: Epoch 41
2025-10-05 21:38:48.974441: Current learning rate: 0.0075
2025-10-05 21:39:35.200183: Validation loss did not improve from -0.30448. Patience: 17/50
2025-10-05 21:39:35.200680: train_loss -0.758
2025-10-05 21:39:35.200894: val_loss -0.2798
2025-10-05 21:39:35.201041: Pseudo dice [np.float32(0.6638)]
2025-10-05 21:39:35.201199: Epoch time: 46.23 s
2025-10-05 21:39:35.201335: Yayy! New best EMA pseudo Dice: 0.6388000249862671
2025-10-05 21:39:36.285225: 
2025-10-05 21:39:36.285527: Epoch 42
2025-10-05 21:39:36.285796: Current learning rate: 0.00744
2025-10-05 21:40:22.549363: Validation loss did not improve from -0.30448. Patience: 18/50
2025-10-05 21:40:22.550020: train_loss -0.7606
2025-10-05 21:40:22.550167: val_loss -0.229
2025-10-05 21:40:22.550372: Pseudo dice [np.float32(0.6272)]
2025-10-05 21:40:22.550619: Epoch time: 46.27 s
2025-10-05 21:40:23.171283: 
2025-10-05 21:40:23.171604: Epoch 43
2025-10-05 21:40:23.171874: Current learning rate: 0.00738
2025-10-05 21:41:09.360433: Validation loss did not improve from -0.30448. Patience: 19/50
2025-10-05 21:41:09.361064: train_loss -0.7772
2025-10-05 21:41:09.361291: val_loss -0.2249
2025-10-05 21:41:09.361414: Pseudo dice [np.float32(0.6418)]
2025-10-05 21:41:09.361556: Epoch time: 46.19 s
2025-10-05 21:41:09.980645: 
2025-10-05 21:41:09.980942: Epoch 44
2025-10-05 21:41:09.981110: Current learning rate: 0.00732
2025-10-05 21:41:56.172099: Validation loss did not improve from -0.30448. Patience: 20/50
2025-10-05 21:41:56.172787: train_loss -0.7736
2025-10-05 21:41:56.173009: val_loss -0.2234
2025-10-05 21:41:56.173208: Pseudo dice [np.float32(0.6433)]
2025-10-05 21:41:56.173408: Epoch time: 46.19 s
2025-10-05 21:41:57.242070: 
2025-10-05 21:41:57.242375: Epoch 45
2025-10-05 21:41:57.242548: Current learning rate: 0.00725
2025-10-05 21:42:43.481208: Validation loss did not improve from -0.30448. Patience: 21/50
2025-10-05 21:42:43.481708: train_loss -0.7715
2025-10-05 21:42:43.481912: val_loss -0.1815
2025-10-05 21:42:43.482077: Pseudo dice [np.float32(0.6119)]
2025-10-05 21:42:43.482230: Epoch time: 46.24 s
2025-10-05 21:42:44.109016: 
2025-10-05 21:42:44.109293: Epoch 46
2025-10-05 21:42:44.109487: Current learning rate: 0.00719
2025-10-05 21:43:30.403572: Validation loss did not improve from -0.30448. Patience: 22/50
2025-10-05 21:43:30.404298: train_loss -0.781
2025-10-05 21:43:30.404452: val_loss -0.2571
2025-10-05 21:43:30.404617: Pseudo dice [np.float32(0.6488)]
2025-10-05 21:43:30.404778: Epoch time: 46.3 s
2025-10-05 21:43:31.413131: 
2025-10-05 21:43:31.413474: Epoch 47
2025-10-05 21:43:31.413687: Current learning rate: 0.00713
2025-10-05 21:44:17.687615: Validation loss did not improve from -0.30448. Patience: 23/50
2025-10-05 21:44:17.688132: train_loss -0.7907
2025-10-05 21:44:17.688278: val_loss -0.2188
2025-10-05 21:44:17.688399: Pseudo dice [np.float32(0.6202)]
2025-10-05 21:44:17.688524: Epoch time: 46.28 s
2025-10-05 21:44:18.319809: 
2025-10-05 21:44:18.320182: Epoch 48
2025-10-05 21:44:18.320382: Current learning rate: 0.00707
2025-10-05 21:45:04.510402: Validation loss did not improve from -0.30448. Patience: 24/50
2025-10-05 21:45:04.511186: train_loss -0.7842
2025-10-05 21:45:04.511383: val_loss -0.2667
2025-10-05 21:45:04.511561: Pseudo dice [np.float32(0.6474)]
2025-10-05 21:45:04.511717: Epoch time: 46.19 s
2025-10-05 21:45:05.158405: 
2025-10-05 21:45:05.158657: Epoch 49
2025-10-05 21:45:05.158953: Current learning rate: 0.007
2025-10-05 21:45:51.243134: Validation loss did not improve from -0.30448. Patience: 25/50
2025-10-05 21:45:51.243673: train_loss -0.8001
2025-10-05 21:45:51.243827: val_loss -0.2264
2025-10-05 21:45:51.243995: Pseudo dice [np.float32(0.6526)]
2025-10-05 21:45:51.244178: Epoch time: 46.09 s
2025-10-05 21:45:52.335394: 
2025-10-05 21:45:52.335751: Epoch 50
2025-10-05 21:45:52.335983: Current learning rate: 0.00694
2025-10-05 21:46:38.439873: Validation loss did not improve from -0.30448. Patience: 26/50
2025-10-05 21:46:38.440573: train_loss -0.8036
2025-10-05 21:46:38.440869: val_loss -0.2021
2025-10-05 21:46:38.441115: Pseudo dice [np.float32(0.6387)]
2025-10-05 21:46:38.441360: Epoch time: 46.11 s
2025-10-05 21:46:39.071220: 
2025-10-05 21:46:39.071648: Epoch 51
2025-10-05 21:46:39.072155: Current learning rate: 0.00688
2025-10-05 21:47:25.249423: Validation loss did not improve from -0.30448. Patience: 27/50
2025-10-05 21:47:25.249934: train_loss -0.8013
2025-10-05 21:47:25.250103: val_loss -0.2392
2025-10-05 21:47:25.250225: Pseudo dice [np.float32(0.6556)]
2025-10-05 21:47:25.250366: Epoch time: 46.18 s
2025-10-05 21:47:25.250474: Yayy! New best EMA pseudo Dice: 0.6399999856948853
2025-10-05 21:47:26.338370: 
2025-10-05 21:47:26.338614: Epoch 52
2025-10-05 21:47:26.338814: Current learning rate: 0.00682
2025-10-05 21:48:12.508916: Validation loss did not improve from -0.30448. Patience: 28/50
2025-10-05 21:48:12.509541: train_loss -0.8054
2025-10-05 21:48:12.509742: val_loss -0.1984
2025-10-05 21:48:12.509893: Pseudo dice [np.float32(0.6379)]
2025-10-05 21:48:12.510022: Epoch time: 46.17 s
2025-10-05 21:48:13.150507: 
2025-10-05 21:48:13.150809: Epoch 53
2025-10-05 21:48:13.151054: Current learning rate: 0.00675
2025-10-05 21:48:59.301257: Validation loss did not improve from -0.30448. Patience: 29/50
2025-10-05 21:48:59.301725: train_loss -0.7991
2025-10-05 21:48:59.301922: val_loss -0.1964
2025-10-05 21:48:59.302035: Pseudo dice [np.float32(0.6367)]
2025-10-05 21:48:59.302157: Epoch time: 46.15 s
2025-10-05 21:48:59.923342: 
2025-10-05 21:48:59.923647: Epoch 54
2025-10-05 21:48:59.923872: Current learning rate: 0.00669
2025-10-05 21:49:46.070590: Validation loss did not improve from -0.30448. Patience: 30/50
2025-10-05 21:49:46.071161: train_loss -0.8113
2025-10-05 21:49:46.071334: val_loss -0.2139
2025-10-05 21:49:46.071502: Pseudo dice [np.float32(0.6529)]
2025-10-05 21:49:46.071656: Epoch time: 46.15 s
2025-10-05 21:49:46.531137: Yayy! New best EMA pseudo Dice: 0.6407999992370605
2025-10-05 21:49:47.609698: 
2025-10-05 21:49:47.610046: Epoch 55
2025-10-05 21:49:47.610261: Current learning rate: 0.00663
2025-10-05 21:50:33.703372: Validation loss did not improve from -0.30448. Patience: 31/50
2025-10-05 21:50:33.704088: train_loss -0.813
2025-10-05 21:50:33.704352: val_loss -0.2425
2025-10-05 21:50:33.704542: Pseudo dice [np.float32(0.6502)]
2025-10-05 21:50:33.704740: Epoch time: 46.1 s
2025-10-05 21:50:33.704906: Yayy! New best EMA pseudo Dice: 0.6417999863624573
2025-10-05 21:50:34.778728: 
2025-10-05 21:50:34.779100: Epoch 56
2025-10-05 21:50:34.779323: Current learning rate: 0.00657
2025-10-05 21:51:20.914881: Validation loss did not improve from -0.30448. Patience: 32/50
2025-10-05 21:51:20.915479: train_loss -0.8195
2025-10-05 21:51:20.915713: val_loss -0.2284
2025-10-05 21:51:20.915910: Pseudo dice [np.float32(0.6645)]
2025-10-05 21:51:20.916075: Epoch time: 46.14 s
2025-10-05 21:51:20.916221: Yayy! New best EMA pseudo Dice: 0.64410001039505
2025-10-05 21:51:21.996729: 
2025-10-05 21:51:21.997017: Epoch 57
2025-10-05 21:51:21.997216: Current learning rate: 0.0065
2025-10-05 21:52:08.184929: Validation loss did not improve from -0.30448. Patience: 33/50
2025-10-05 21:52:08.185390: train_loss -0.8191
2025-10-05 21:52:08.185586: val_loss -0.1783
2025-10-05 21:52:08.185789: Pseudo dice [np.float32(0.6193)]
2025-10-05 21:52:08.185950: Epoch time: 46.19 s
2025-10-05 21:52:09.178365: 
2025-10-05 21:52:09.178724: Epoch 58
2025-10-05 21:52:09.178977: Current learning rate: 0.00644
2025-10-05 21:52:55.334344: Validation loss did not improve from -0.30448. Patience: 34/50
2025-10-05 21:52:55.335004: train_loss -0.8197
2025-10-05 21:52:55.335162: val_loss -0.1401
2025-10-05 21:52:55.335303: Pseudo dice [np.float32(0.6315)]
2025-10-05 21:52:55.335476: Epoch time: 46.16 s
2025-10-05 21:52:55.977237: 
2025-10-05 21:52:55.977550: Epoch 59
2025-10-05 21:52:55.977796: Current learning rate: 0.00638
2025-10-05 21:53:42.093101: Validation loss did not improve from -0.30448. Patience: 35/50
2025-10-05 21:53:42.093574: train_loss -0.8261
2025-10-05 21:53:42.093715: val_loss -0.1625
2025-10-05 21:53:42.093859: Pseudo dice [np.float32(0.6356)]
2025-10-05 21:53:42.094030: Epoch time: 46.12 s
2025-10-05 21:53:43.196527: 
2025-10-05 21:53:43.196877: Epoch 60
2025-10-05 21:53:43.197137: Current learning rate: 0.00631
2025-10-05 21:54:29.359355: Validation loss did not improve from -0.30448. Patience: 36/50
2025-10-05 21:54:29.360080: train_loss -0.8266
2025-10-05 21:54:29.360219: val_loss -0.1829
2025-10-05 21:54:29.360415: Pseudo dice [np.float32(0.6379)]
2025-10-05 21:54:29.360643: Epoch time: 46.16 s
2025-10-05 21:54:30.007363: 
2025-10-05 21:54:30.007699: Epoch 61
2025-10-05 21:54:30.007943: Current learning rate: 0.00625
2025-10-05 21:55:16.185325: Validation loss did not improve from -0.30448. Patience: 37/50
2025-10-05 21:55:16.186105: train_loss -0.8316
2025-10-05 21:55:16.186352: val_loss -0.1959
2025-10-05 21:55:16.186606: Pseudo dice [np.float32(0.6533)]
2025-10-05 21:55:16.186784: Epoch time: 46.18 s
2025-10-05 21:55:16.826344: 
2025-10-05 21:55:16.826605: Epoch 62
2025-10-05 21:55:16.826833: Current learning rate: 0.00619
2025-10-05 21:56:03.042539: Validation loss did not improve from -0.30448. Patience: 38/50
2025-10-05 21:56:03.043129: train_loss -0.8336
2025-10-05 21:56:03.043269: val_loss -0.1954
2025-10-05 21:56:03.043378: Pseudo dice [np.float32(0.6373)]
2025-10-05 21:56:03.043505: Epoch time: 46.22 s
2025-10-05 21:56:03.694127: 
2025-10-05 21:56:03.694416: Epoch 63
2025-10-05 21:56:03.694608: Current learning rate: 0.00612
2025-10-05 21:56:49.839876: Validation loss did not improve from -0.30448. Patience: 39/50
2025-10-05 21:56:49.840345: train_loss -0.8338
2025-10-05 21:56:49.840533: val_loss -0.1941
2025-10-05 21:56:49.840680: Pseudo dice [np.float32(0.6416)]
2025-10-05 21:56:49.840820: Epoch time: 46.15 s
2025-10-05 21:56:50.487433: 
2025-10-05 21:56:50.487823: Epoch 64
2025-10-05 21:56:50.488037: Current learning rate: 0.00606
2025-10-05 21:57:36.587548: Validation loss did not improve from -0.30448. Patience: 40/50
2025-10-05 21:57:36.588114: train_loss -0.8411
2025-10-05 21:57:36.588341: val_loss -0.2051
2025-10-05 21:57:36.588457: Pseudo dice [np.float32(0.6531)]
2025-10-05 21:57:36.588617: Epoch time: 46.1 s
2025-10-05 21:57:37.675490: 
2025-10-05 21:57:37.675844: Epoch 65
2025-10-05 21:57:37.676079: Current learning rate: 0.006
2025-10-05 21:58:23.824720: Validation loss did not improve from -0.30448. Patience: 41/50
2025-10-05 21:58:23.825219: train_loss -0.8413
2025-10-05 21:58:23.825390: val_loss -0.1482
2025-10-05 21:58:23.825536: Pseudo dice [np.float32(0.6341)]
2025-10-05 21:58:23.825701: Epoch time: 46.15 s
2025-10-05 21:58:24.461125: 
2025-10-05 21:58:24.461495: Epoch 66
2025-10-05 21:58:24.461760: Current learning rate: 0.00593
2025-10-05 21:59:10.620964: Validation loss did not improve from -0.30448. Patience: 42/50
2025-10-05 21:59:10.621752: train_loss -0.8446
2025-10-05 21:59:10.622052: val_loss -0.1945
2025-10-05 21:59:10.622281: Pseudo dice [np.float32(0.6498)]
2025-10-05 21:59:10.622516: Epoch time: 46.16 s
2025-10-05 21:59:11.270559: 
2025-10-05 21:59:11.270941: Epoch 67
2025-10-05 21:59:11.271209: Current learning rate: 0.00587
2025-10-05 21:59:57.449201: Validation loss did not improve from -0.30448. Patience: 43/50
2025-10-05 21:59:57.449821: train_loss -0.8435
2025-10-05 21:59:57.450025: val_loss -0.1942
2025-10-05 21:59:57.450176: Pseudo dice [np.float32(0.6467)]
2025-10-05 21:59:57.450317: Epoch time: 46.18 s
2025-10-05 21:59:58.095393: 
2025-10-05 21:59:58.095746: Epoch 68
2025-10-05 21:59:58.095919: Current learning rate: 0.00581
2025-10-05 22:00:44.256984: Validation loss did not improve from -0.30448. Patience: 44/50
2025-10-05 22:00:44.257578: train_loss -0.8446
2025-10-05 22:00:44.257769: val_loss -0.1736
2025-10-05 22:00:44.257921: Pseudo dice [np.float32(0.6501)]
2025-10-05 22:00:44.258072: Epoch time: 46.16 s
2025-10-05 22:00:44.891051: 
2025-10-05 22:00:44.891418: Epoch 69
2025-10-05 22:00:44.891666: Current learning rate: 0.00574
2025-10-05 22:01:31.018890: Validation loss did not improve from -0.30448. Patience: 45/50
2025-10-05 22:01:31.019382: train_loss -0.8489
2025-10-05 22:01:31.019557: val_loss -0.131
2025-10-05 22:01:31.019676: Pseudo dice [np.float32(0.6416)]
2025-10-05 22:01:31.019838: Epoch time: 46.13 s
2025-10-05 22:01:32.481808: 
2025-10-05 22:01:32.482142: Epoch 70
2025-10-05 22:01:32.482339: Current learning rate: 0.00568
2025-10-05 22:02:18.588747: Validation loss did not improve from -0.30448. Patience: 46/50
2025-10-05 22:02:18.589421: train_loss -0.8514
2025-10-05 22:02:18.589581: val_loss -0.1329
2025-10-05 22:02:18.589713: Pseudo dice [np.float32(0.6416)]
2025-10-05 22:02:18.589873: Epoch time: 46.11 s
2025-10-05 22:02:19.223951: 
2025-10-05 22:02:19.224307: Epoch 71
2025-10-05 22:02:19.224507: Current learning rate: 0.00562
2025-10-05 22:03:05.405201: Validation loss did not improve from -0.30448. Patience: 47/50
2025-10-05 22:03:05.405756: train_loss -0.8532
2025-10-05 22:03:05.405976: val_loss -0.1402
2025-10-05 22:03:05.406199: Pseudo dice [np.float32(0.6446)]
2025-10-05 22:03:05.406468: Epoch time: 46.18 s
2025-10-05 22:03:06.070174: 
2025-10-05 22:03:06.070481: Epoch 72
2025-10-05 22:03:06.070653: Current learning rate: 0.00555
2025-10-05 22:03:52.239181: Validation loss did not improve from -0.30448. Patience: 48/50
2025-10-05 22:03:52.239853: train_loss -0.8539
2025-10-05 22:03:52.240021: val_loss -0.1811
2025-10-05 22:03:52.240240: Pseudo dice [np.float32(0.6475)]
2025-10-05 22:03:52.240396: Epoch time: 46.17 s
2025-10-05 22:03:52.895918: 
2025-10-05 22:03:52.896224: Epoch 73
2025-10-05 22:03:52.896418: Current learning rate: 0.00549
2025-10-05 22:04:39.013837: Validation loss did not improve from -0.30448. Patience: 49/50
2025-10-05 22:04:39.014336: train_loss -0.8551
2025-10-05 22:04:39.014509: val_loss -0.153
2025-10-05 22:04:39.014660: Pseudo dice [np.float32(0.657)]
2025-10-05 22:04:39.014795: Epoch time: 46.12 s
2025-10-05 22:04:39.014921: Yayy! New best EMA pseudo Dice: 0.6449999809265137
2025-10-05 22:04:40.091281: 
2025-10-05 22:04:40.091614: Epoch 74
2025-10-05 22:04:40.091797: Current learning rate: 0.00542
2025-10-05 22:05:26.127611: Validation loss did not improve from -0.30448. Patience: 50/50
2025-10-05 22:05:26.128144: train_loss -0.8602
2025-10-05 22:05:26.128296: val_loss -0.2117
2025-10-05 22:05:26.128498: Pseudo dice [np.float32(0.6575)]
2025-10-05 22:05:26.128690: Epoch time: 46.04 s
2025-10-05 22:05:26.579182: Yayy! New best EMA pseudo Dice: 0.6462000012397766
2025-10-05 22:05:27.649073: 
2025-10-05 22:05:27.649464: Epoch 75
2025-10-05 22:05:27.649760: Current learning rate: 0.00536
2025-10-05 22:06:13.709832: Validation loss did not improve from -0.30448. Patience: 51/50
2025-10-05 22:06:13.710304: train_loss -0.862
2025-10-05 22:06:13.710480: val_loss -0.1542
2025-10-05 22:06:13.710673: Pseudo dice [np.float32(0.6366)]
2025-10-05 22:06:13.710849: Epoch time: 46.06 s
2025-10-05 22:06:14.343616: 
2025-10-05 22:06:14.343952: Epoch 76
2025-10-05 22:06:14.344156: Current learning rate: 0.00529
2025-10-05 22:07:00.457377: Validation loss did not improve from -0.30448. Patience: 52/50
2025-10-05 22:07:00.458404: train_loss -0.8656
2025-10-05 22:07:00.458676: val_loss -0.1169
2025-10-05 22:07:00.458913: Pseudo dice [np.float32(0.6313)]
2025-10-05 22:07:00.459155: Epoch time: 46.12 s
2025-10-05 22:07:01.094698: 
2025-10-05 22:07:01.095113: Epoch 77
2025-10-05 22:07:01.095447: Current learning rate: 0.00523
2025-10-05 22:07:47.226604: Validation loss did not improve from -0.30448. Patience: 53/50
2025-10-05 22:07:47.227148: train_loss -0.8641
2025-10-05 22:07:47.227388: val_loss -0.1388
2025-10-05 22:07:47.227586: Pseudo dice [np.float32(0.6436)]
2025-10-05 22:07:47.227795: Epoch time: 46.13 s
2025-10-05 22:07:47.878759: 
2025-10-05 22:07:47.879148: Epoch 78
2025-10-05 22:07:47.879422: Current learning rate: 0.00517
2025-10-05 22:08:33.998534: Validation loss did not improve from -0.30448. Patience: 54/50
2025-10-05 22:08:33.999120: train_loss -0.8639
2025-10-05 22:08:33.999378: val_loss -0.1042
2025-10-05 22:08:33.999506: Pseudo dice [np.float32(0.6423)]
2025-10-05 22:08:33.999640: Epoch time: 46.12 s
2025-10-05 22:08:34.641942: 
2025-10-05 22:08:34.642295: Epoch 79
2025-10-05 22:08:34.642508: Current learning rate: 0.0051
2025-10-05 22:09:20.736574: Validation loss did not improve from -0.30448. Patience: 55/50
2025-10-05 22:09:20.737278: train_loss -0.8648
2025-10-05 22:09:20.737530: val_loss -0.154
2025-10-05 22:09:20.737675: Pseudo dice [np.float32(0.6409)]
2025-10-05 22:09:20.737821: Epoch time: 46.1 s
2025-10-05 22:09:21.831895: 
2025-10-05 22:09:21.832226: Epoch 80
2025-10-05 22:09:21.832393: Current learning rate: 0.00504
2025-10-05 22:10:07.960682: Validation loss did not improve from -0.30448. Patience: 56/50
2025-10-05 22:10:07.961220: train_loss -0.8641
2025-10-05 22:10:07.961358: val_loss -0.1067
2025-10-05 22:10:07.961468: Pseudo dice [np.float32(0.6325)]
2025-10-05 22:10:07.961590: Epoch time: 46.13 s
2025-10-05 22:10:08.975518: 
2025-10-05 22:10:08.975846: Epoch 81
2025-10-05 22:10:08.976024: Current learning rate: 0.00497
2025-10-05 22:10:55.112486: Validation loss did not improve from -0.30448. Patience: 57/50
2025-10-05 22:10:55.112963: train_loss -0.868
2025-10-05 22:10:55.113125: val_loss -0.1642
2025-10-05 22:10:55.113280: Pseudo dice [np.float32(0.6376)]
2025-10-05 22:10:55.113500: Epoch time: 46.14 s
2025-10-05 22:10:55.769095: 
2025-10-05 22:10:55.769412: Epoch 82
2025-10-05 22:10:55.769669: Current learning rate: 0.00491
2025-10-05 22:11:41.958695: Validation loss did not improve from -0.30448. Patience: 58/50
2025-10-05 22:11:41.959342: train_loss -0.8696
2025-10-05 22:11:41.959491: val_loss -0.1583
2025-10-05 22:11:41.959613: Pseudo dice [np.float32(0.6527)]
2025-10-05 22:11:41.959769: Epoch time: 46.19 s
2025-10-05 22:11:42.585546: 
2025-10-05 22:11:42.585962: Epoch 83
2025-10-05 22:11:42.586149: Current learning rate: 0.00484
2025-10-05 22:12:28.722455: Validation loss did not improve from -0.30448. Patience: 59/50
2025-10-05 22:12:28.722944: train_loss -0.8754
2025-10-05 22:12:28.723117: val_loss -0.1085
2025-10-05 22:12:28.723254: Pseudo dice [np.float32(0.6358)]
2025-10-05 22:12:28.723388: Epoch time: 46.14 s
2025-10-05 22:12:29.342903: 
2025-10-05 22:12:29.343241: Epoch 84
2025-10-05 22:12:29.343425: Current learning rate: 0.00478
2025-10-05 22:13:15.434930: Validation loss did not improve from -0.30448. Patience: 60/50
2025-10-05 22:13:15.435498: train_loss -0.8745
2025-10-05 22:13:15.435692: val_loss -0.1638
2025-10-05 22:13:15.435888: Pseudo dice [np.float32(0.6562)]
2025-10-05 22:13:15.436084: Epoch time: 46.09 s
2025-10-05 22:13:16.525500: 
2025-10-05 22:13:16.525853: Epoch 85
2025-10-05 22:13:16.526075: Current learning rate: 0.00471
2025-10-05 22:14:02.636578: Validation loss did not improve from -0.30448. Patience: 61/50
2025-10-05 22:14:02.637404: train_loss -0.8779
2025-10-05 22:14:02.637647: val_loss -0.1415
2025-10-05 22:14:02.637836: Pseudo dice [np.float32(0.6557)]
2025-10-05 22:14:02.637998: Epoch time: 46.11 s
2025-10-05 22:14:03.277687: 
2025-10-05 22:14:03.278051: Epoch 86
2025-10-05 22:14:03.278261: Current learning rate: 0.00465
2025-10-05 22:14:49.428084: Validation loss did not improve from -0.30448. Patience: 62/50
2025-10-05 22:14:49.428900: train_loss -0.8724
2025-10-05 22:14:49.429114: val_loss -0.1263
2025-10-05 22:14:49.429377: Pseudo dice [np.float32(0.6354)]
2025-10-05 22:14:49.429591: Epoch time: 46.15 s
2025-10-05 22:14:50.062132: 
2025-10-05 22:14:50.062462: Epoch 87
2025-10-05 22:14:50.062664: Current learning rate: 0.00458
2025-10-05 22:15:36.267193: Validation loss did not improve from -0.30448. Patience: 63/50
2025-10-05 22:15:36.267743: train_loss -0.8771
2025-10-05 22:15:36.267961: val_loss -0.1096
2025-10-05 22:15:36.268190: Pseudo dice [np.float32(0.6345)]
2025-10-05 22:15:36.268403: Epoch time: 46.21 s
2025-10-05 22:15:36.896666: 
2025-10-05 22:15:36.896974: Epoch 88
2025-10-05 22:15:36.897218: Current learning rate: 0.00452
2025-10-05 22:16:23.056682: Validation loss did not improve from -0.30448. Patience: 64/50
2025-10-05 22:16:23.057282: train_loss -0.8766
2025-10-05 22:16:23.057490: val_loss -0.1304
2025-10-05 22:16:23.057673: Pseudo dice [np.float32(0.6503)]
2025-10-05 22:16:23.057858: Epoch time: 46.16 s
2025-10-05 22:16:23.675685: 
2025-10-05 22:16:23.675961: Epoch 89
2025-10-05 22:16:23.676133: Current learning rate: 0.00445
2025-10-05 22:17:09.877354: Validation loss did not improve from -0.30448. Patience: 65/50
2025-10-05 22:17:09.878189: train_loss -0.88
2025-10-05 22:17:09.878560: val_loss -0.1566
2025-10-05 22:17:09.878770: Pseudo dice [np.float32(0.644)]
2025-10-05 22:17:09.878967: Epoch time: 46.2 s
2025-10-05 22:17:10.961921: 
2025-10-05 22:17:10.962290: Epoch 90
2025-10-05 22:17:10.962493: Current learning rate: 0.00438
2025-10-05 22:17:57.090370: Validation loss did not improve from -0.30448. Patience: 66/50
2025-10-05 22:17:57.090983: train_loss -0.8807
2025-10-05 22:17:57.091187: val_loss -0.1566
2025-10-05 22:17:57.091309: Pseudo dice [np.float32(0.6537)]
2025-10-05 22:17:57.091462: Epoch time: 46.13 s
2025-10-05 22:17:57.719810: 
2025-10-05 22:17:57.720070: Epoch 91
2025-10-05 22:17:57.720269: Current learning rate: 0.00432
2025-10-05 22:18:43.878343: Validation loss did not improve from -0.30448. Patience: 67/50
2025-10-05 22:18:43.878936: train_loss -0.8811
2025-10-05 22:18:43.879070: val_loss -0.12
2025-10-05 22:18:43.879230: Pseudo dice [np.float32(0.6409)]
2025-10-05 22:18:43.879360: Epoch time: 46.16 s
2025-10-05 22:18:44.505729: 
2025-10-05 22:18:44.506002: Epoch 92
2025-10-05 22:18:44.506174: Current learning rate: 0.00425
2025-10-05 22:19:30.683982: Validation loss did not improve from -0.30448. Patience: 68/50
2025-10-05 22:19:30.684588: train_loss -0.8813
2025-10-05 22:19:30.684763: val_loss -0.1084
2025-10-05 22:19:30.684904: Pseudo dice [np.float32(0.6358)]
2025-10-05 22:19:30.685122: Epoch time: 46.18 s
2025-10-05 22:19:31.682391: 
2025-10-05 22:19:31.682753: Epoch 93
2025-10-05 22:19:31.683010: Current learning rate: 0.00419
2025-10-05 22:20:17.791998: Validation loss did not improve from -0.30448. Patience: 69/50
2025-10-05 22:20:17.792521: train_loss -0.8817
2025-10-05 22:20:17.792706: val_loss -0.159
2025-10-05 22:20:17.792849: Pseudo dice [np.float32(0.6538)]
2025-10-05 22:20:17.793015: Epoch time: 46.11 s
2025-10-05 22:20:18.420911: 
2025-10-05 22:20:18.421235: Epoch 94
2025-10-05 22:20:18.421416: Current learning rate: 0.00412
2025-10-05 22:21:04.554152: Validation loss did not improve from -0.30448. Patience: 70/50
2025-10-05 22:21:04.555009: train_loss -0.885
2025-10-05 22:21:04.555227: val_loss -0.0802
2025-10-05 22:21:04.555420: Pseudo dice [np.float32(0.6399)]
2025-10-05 22:21:04.555629: Epoch time: 46.13 s
2025-10-05 22:21:05.641743: 
2025-10-05 22:21:05.642070: Epoch 95
2025-10-05 22:21:05.642279: Current learning rate: 0.00405
2025-10-05 22:21:51.725648: Validation loss did not improve from -0.30448. Patience: 71/50
2025-10-05 22:21:51.726191: train_loss -0.8854
2025-10-05 22:21:51.726485: val_loss -0.139
2025-10-05 22:21:51.726740: Pseudo dice [np.float32(0.6473)]
2025-10-05 22:21:51.727014: Epoch time: 46.09 s
2025-10-05 22:21:52.363928: 
2025-10-05 22:21:52.364279: Epoch 96
2025-10-05 22:21:52.364519: Current learning rate: 0.00399
2025-10-05 22:22:38.560221: Validation loss did not improve from -0.30448. Patience: 72/50
2025-10-05 22:22:38.560811: train_loss -0.8835
2025-10-05 22:22:38.561001: val_loss -0.1579
2025-10-05 22:22:38.561157: Pseudo dice [np.float32(0.6423)]
2025-10-05 22:22:38.561395: Epoch time: 46.2 s
2025-10-05 22:22:39.207379: 
2025-10-05 22:22:39.208002: Epoch 97
2025-10-05 22:22:39.208489: Current learning rate: 0.00392
2025-10-05 22:23:25.380095: Validation loss did not improve from -0.30448. Patience: 73/50
2025-10-05 22:23:25.380656: train_loss -0.8872
2025-10-05 22:23:25.380814: val_loss -0.1214
2025-10-05 22:23:25.380945: Pseudo dice [np.float32(0.6599)]
2025-10-05 22:23:25.381124: Epoch time: 46.17 s
2025-10-05 22:23:26.017831: 
2025-10-05 22:23:26.018156: Epoch 98
2025-10-05 22:23:26.018378: Current learning rate: 0.00385
2025-10-05 22:24:12.133072: Validation loss did not improve from -0.30448. Patience: 74/50
2025-10-05 22:24:12.133801: train_loss -0.8895
2025-10-05 22:24:12.134042: val_loss -0.1331
2025-10-05 22:24:12.134251: Pseudo dice [np.float32(0.6355)]
2025-10-05 22:24:12.134447: Epoch time: 46.12 s
2025-10-05 22:24:12.765393: 
2025-10-05 22:24:12.765774: Epoch 99
2025-10-05 22:24:12.766014: Current learning rate: 0.00379
2025-10-05 22:24:58.810026: Validation loss did not improve from -0.30448. Patience: 75/50
2025-10-05 22:24:58.810458: train_loss -0.8893
2025-10-05 22:24:58.810622: val_loss -0.1144
2025-10-05 22:24:58.810770: Pseudo dice [np.float32(0.6388)]
2025-10-05 22:24:58.810911: Epoch time: 46.05 s
2025-10-05 22:24:59.918054: 
2025-10-05 22:24:59.918441: Epoch 100
2025-10-05 22:24:59.918660: Current learning rate: 0.00372
2025-10-05 22:25:46.049900: Validation loss did not improve from -0.30448. Patience: 76/50
2025-10-05 22:25:46.050505: train_loss -0.8878
2025-10-05 22:25:46.050675: val_loss -0.1173
2025-10-05 22:25:46.050860: Pseudo dice [np.float32(0.6439)]
2025-10-05 22:25:46.051017: Epoch time: 46.13 s
2025-10-05 22:25:46.689559: 
2025-10-05 22:25:46.689951: Epoch 101
2025-10-05 22:25:46.690155: Current learning rate: 0.00365
2025-10-05 22:26:32.833597: Validation loss did not improve from -0.30448. Patience: 77/50
2025-10-05 22:26:32.834243: train_loss -0.8911
2025-10-05 22:26:32.834413: val_loss -0.1004
2025-10-05 22:26:32.834656: Pseudo dice [np.float32(0.62)]
2025-10-05 22:26:32.834820: Epoch time: 46.15 s
2025-10-05 22:26:33.462264: 
2025-10-05 22:26:33.462578: Epoch 102
2025-10-05 22:26:33.462758: Current learning rate: 0.00359
2025-10-05 22:27:19.602748: Validation loss did not improve from -0.30448. Patience: 78/50
2025-10-05 22:27:19.603327: train_loss -0.8902
2025-10-05 22:27:19.603490: val_loss -0.0907
2025-10-05 22:27:19.603683: Pseudo dice [np.float32(0.6529)]
2025-10-05 22:27:19.603863: Epoch time: 46.14 s
2025-10-05 22:27:20.229538: 
2025-10-05 22:27:20.229822: Epoch 103
2025-10-05 22:27:20.230090: Current learning rate: 0.00352
2025-10-05 22:28:06.248850: Validation loss did not improve from -0.30448. Patience: 79/50
2025-10-05 22:28:06.249600: train_loss -0.8959
2025-10-05 22:28:06.249855: val_loss -0.1281
2025-10-05 22:28:06.250098: Pseudo dice [np.float32(0.6586)]
2025-10-05 22:28:06.250382: Epoch time: 46.02 s
2025-10-05 22:28:06.880934: 
2025-10-05 22:28:06.881319: Epoch 104
2025-10-05 22:28:06.881584: Current learning rate: 0.00345
2025-10-05 22:28:52.918064: Validation loss did not improve from -0.30448. Patience: 80/50
2025-10-05 22:28:52.918845: train_loss -0.895
2025-10-05 22:28:52.919139: val_loss -0.0951
2025-10-05 22:28:52.919377: Pseudo dice [np.float32(0.6393)]
2025-10-05 22:28:52.919621: Epoch time: 46.04 s
2025-10-05 22:28:54.371402: 
2025-10-05 22:28:54.371795: Epoch 105
2025-10-05 22:28:54.371985: Current learning rate: 0.00338
2025-10-05 22:29:40.459033: Validation loss did not improve from -0.30448. Patience: 81/50
2025-10-05 22:29:40.459490: train_loss -0.8958
2025-10-05 22:29:40.459698: val_loss -0.1176
2025-10-05 22:29:40.459887: Pseudo dice [np.float32(0.6577)]
2025-10-05 22:29:40.460064: Epoch time: 46.09 s
2025-10-05 22:29:41.082514: 
2025-10-05 22:29:41.082887: Epoch 106
2025-10-05 22:29:41.083129: Current learning rate: 0.00332
2025-10-05 22:30:27.217052: Validation loss did not improve from -0.30448. Patience: 82/50
2025-10-05 22:30:27.217695: train_loss -0.8964
2025-10-05 22:30:27.217857: val_loss -0.0983
2025-10-05 22:30:27.217976: Pseudo dice [np.float32(0.6451)]
2025-10-05 22:30:27.218110: Epoch time: 46.14 s
2025-10-05 22:30:27.845730: 
2025-10-05 22:30:27.846113: Epoch 107
2025-10-05 22:30:27.846332: Current learning rate: 0.00325
2025-10-05 22:31:13.999964: Validation loss did not improve from -0.30448. Patience: 83/50
2025-10-05 22:31:14.000467: train_loss -0.8989
2025-10-05 22:31:14.000644: val_loss -0.0911
2025-10-05 22:31:14.000801: Pseudo dice [np.float32(0.6328)]
2025-10-05 22:31:14.000973: Epoch time: 46.16 s
2025-10-05 22:31:14.622951: 
2025-10-05 22:31:14.623280: Epoch 108
2025-10-05 22:31:14.623461: Current learning rate: 0.00318
2025-10-05 22:32:00.651766: Validation loss did not improve from -0.30448. Patience: 84/50
2025-10-05 22:32:00.652456: train_loss -0.8955
2025-10-05 22:32:00.652683: val_loss -0.0812
2025-10-05 22:32:00.652891: Pseudo dice [np.float32(0.6398)]
2025-10-05 22:32:00.653056: Epoch time: 46.03 s
2025-10-05 22:32:01.284318: 
2025-10-05 22:32:01.284874: Epoch 109
2025-10-05 22:32:01.285064: Current learning rate: 0.00311
2025-10-05 22:32:47.284343: Validation loss did not improve from -0.30448. Patience: 85/50
2025-10-05 22:32:47.285005: train_loss -0.8994
2025-10-05 22:32:47.285184: val_loss -0.1015
2025-10-05 22:32:47.285358: Pseudo dice [np.float32(0.6551)]
2025-10-05 22:32:47.285511: Epoch time: 46.0 s
2025-10-05 22:32:48.364792: 
2025-10-05 22:32:48.365085: Epoch 110
2025-10-05 22:32:48.365352: Current learning rate: 0.00304
2025-10-05 22:33:34.409316: Validation loss did not improve from -0.30448. Patience: 86/50
2025-10-05 22:33:34.409958: train_loss -0.8968
2025-10-05 22:33:34.410109: val_loss -0.0995
2025-10-05 22:33:34.410219: Pseudo dice [np.float32(0.6478)]
2025-10-05 22:33:34.410363: Epoch time: 46.05 s
2025-10-05 22:33:35.039604: 
2025-10-05 22:33:35.039879: Epoch 111
2025-10-05 22:33:35.040071: Current learning rate: 0.00297
2025-10-05 22:34:21.079472: Validation loss did not improve from -0.30448. Patience: 87/50
2025-10-05 22:34:21.079975: train_loss -0.8962
2025-10-05 22:34:21.080194: val_loss -0.0887
2025-10-05 22:34:21.080367: Pseudo dice [np.float32(0.6416)]
2025-10-05 22:34:21.080578: Epoch time: 46.04 s
2025-10-05 22:34:21.712145: 
2025-10-05 22:34:21.712421: Epoch 112
2025-10-05 22:34:21.712663: Current learning rate: 0.00291
2025-10-05 22:35:07.794762: Validation loss did not improve from -0.30448. Patience: 88/50
2025-10-05 22:35:07.795406: train_loss -0.898
2025-10-05 22:35:07.795550: val_loss -0.1452
2025-10-05 22:35:07.795682: Pseudo dice [np.float32(0.656)]
2025-10-05 22:35:07.795830: Epoch time: 46.08 s
2025-10-05 22:35:08.427490: 
2025-10-05 22:35:08.427858: Epoch 113
2025-10-05 22:35:08.428051: Current learning rate: 0.00284
2025-10-05 22:35:54.418869: Validation loss did not improve from -0.30448. Patience: 89/50
2025-10-05 22:35:54.419285: train_loss -0.8984
2025-10-05 22:35:54.419433: val_loss -0.0672
2025-10-05 22:35:54.419569: Pseudo dice [np.float32(0.6412)]
2025-10-05 22:35:54.419703: Epoch time: 45.99 s
2025-10-05 22:35:55.042979: 
2025-10-05 22:35:55.043273: Epoch 114
2025-10-05 22:35:55.043447: Current learning rate: 0.00277
2025-10-05 22:36:41.036914: Validation loss did not improve from -0.30448. Patience: 90/50
2025-10-05 22:36:41.037412: train_loss -0.9025
2025-10-05 22:36:41.037567: val_loss -0.0722
2025-10-05 22:36:41.037698: Pseudo dice [np.float32(0.64)]
2025-10-05 22:36:41.037919: Epoch time: 46.0 s
2025-10-05 22:36:42.115117: 
2025-10-05 22:36:42.115569: Epoch 115
2025-10-05 22:36:42.115992: Current learning rate: 0.0027
2025-10-05 22:37:28.187956: Validation loss did not improve from -0.30448. Patience: 91/50
2025-10-05 22:37:28.188459: train_loss -0.9021
2025-10-05 22:37:28.188651: val_loss -0.0689
2025-10-05 22:37:28.188797: Pseudo dice [np.float32(0.6354)]
2025-10-05 22:37:28.189065: Epoch time: 46.07 s
2025-10-05 22:37:28.822533: 
2025-10-05 22:37:28.822896: Epoch 116
2025-10-05 22:37:28.823106: Current learning rate: 0.00263
2025-10-05 22:38:14.885415: Validation loss did not improve from -0.30448. Patience: 92/50
2025-10-05 22:38:14.886089: train_loss -0.9026
2025-10-05 22:38:14.886412: val_loss -0.0782
2025-10-05 22:38:14.886614: Pseudo dice [np.float32(0.6607)]
2025-10-05 22:38:14.886766: Epoch time: 46.06 s
2025-10-05 22:38:15.883978: 
2025-10-05 22:38:15.884289: Epoch 117
2025-10-05 22:38:15.884514: Current learning rate: 0.00256
2025-10-05 22:39:01.997508: Validation loss did not improve from -0.30448. Patience: 93/50
2025-10-05 22:39:01.998021: train_loss -0.9025
2025-10-05 22:39:01.998252: val_loss -0.0942
2025-10-05 22:39:01.998445: Pseudo dice [np.float32(0.656)]
2025-10-05 22:39:01.998664: Epoch time: 46.11 s
2025-10-05 22:39:01.998916: Yayy! New best EMA pseudo Dice: 0.6466000080108643
2025-10-05 22:39:03.072578: 
2025-10-05 22:39:03.072988: Epoch 118
2025-10-05 22:39:03.073201: Current learning rate: 0.00249
2025-10-05 22:39:49.086525: Validation loss did not improve from -0.30448. Patience: 94/50
2025-10-05 22:39:49.087035: train_loss -0.9035
2025-10-05 22:39:49.087195: val_loss -0.0938
2025-10-05 22:39:49.087306: Pseudo dice [np.float32(0.6339)]
2025-10-05 22:39:49.087502: Epoch time: 46.02 s
2025-10-05 22:39:49.723465: 
2025-10-05 22:39:49.723820: Epoch 119
2025-10-05 22:39:49.724030: Current learning rate: 0.00242
2025-10-05 22:40:35.796048: Validation loss did not improve from -0.30448. Patience: 95/50
2025-10-05 22:40:35.796545: train_loss -0.9066
2025-10-05 22:40:35.796774: val_loss -0.0696
2025-10-05 22:40:35.797021: Pseudo dice [np.float32(0.6578)]
2025-10-05 22:40:35.797243: Epoch time: 46.07 s
2025-10-05 22:40:36.885689: 
2025-10-05 22:40:36.886014: Epoch 120
2025-10-05 22:40:36.886246: Current learning rate: 0.00235
2025-10-05 22:41:23.074092: Validation loss did not improve from -0.30448. Patience: 96/50
2025-10-05 22:41:23.074672: train_loss -0.9067
2025-10-05 22:41:23.074862: val_loss -0.119
2025-10-05 22:41:23.075078: Pseudo dice [np.float32(0.6556)]
2025-10-05 22:41:23.075275: Epoch time: 46.19 s
2025-10-05 22:41:23.075388: Yayy! New best EMA pseudo Dice: 0.6474999785423279
2025-10-05 22:41:24.160827: 
2025-10-05 22:41:24.161099: Epoch 121
2025-10-05 22:41:24.161319: Current learning rate: 0.00228
2025-10-05 22:42:10.284516: Validation loss did not improve from -0.30448. Patience: 97/50
2025-10-05 22:42:10.285078: train_loss -0.9055
2025-10-05 22:42:10.285239: val_loss -0.1085
2025-10-05 22:42:10.285376: Pseudo dice [np.float32(0.6571)]
2025-10-05 22:42:10.285532: Epoch time: 46.13 s
2025-10-05 22:42:10.285649: Yayy! New best EMA pseudo Dice: 0.6484000086784363
2025-10-05 22:42:11.354119: 
2025-10-05 22:42:11.354410: Epoch 122
2025-10-05 22:42:11.354592: Current learning rate: 0.00221
2025-10-05 22:42:57.477080: Validation loss did not improve from -0.30448. Patience: 98/50
2025-10-05 22:42:57.477569: train_loss -0.9081
2025-10-05 22:42:57.477709: val_loss -0.1059
2025-10-05 22:42:57.477918: Pseudo dice [np.float32(0.6533)]
2025-10-05 22:42:57.478100: Epoch time: 46.12 s
2025-10-05 22:42:57.478241: Yayy! New best EMA pseudo Dice: 0.6488999724388123
2025-10-05 22:42:58.549764: 
2025-10-05 22:42:58.550130: Epoch 123
2025-10-05 22:42:58.550344: Current learning rate: 0.00214
2025-10-05 22:43:44.625680: Validation loss did not improve from -0.30448. Patience: 99/50
2025-10-05 22:43:44.626255: train_loss -0.9073
2025-10-05 22:43:44.626469: val_loss -0.113
2025-10-05 22:43:44.626672: Pseudo dice [np.float32(0.6497)]
2025-10-05 22:43:44.626899: Epoch time: 46.08 s
2025-10-05 22:43:44.627084: Yayy! New best EMA pseudo Dice: 0.6489999890327454
2025-10-05 22:43:45.695175: 
2025-10-05 22:43:45.695565: Epoch 124
2025-10-05 22:43:45.695769: Current learning rate: 0.00207
2025-10-05 22:44:31.825138: Validation loss did not improve from -0.30448. Patience: 100/50
2025-10-05 22:44:31.826044: train_loss -0.9082
2025-10-05 22:44:31.826343: val_loss -0.0757
2025-10-05 22:44:31.826554: Pseudo dice [np.float32(0.639)]
2025-10-05 22:44:31.826804: Epoch time: 46.13 s
2025-10-05 22:44:32.901589: 
2025-10-05 22:44:32.901927: Epoch 125
2025-10-05 22:44:32.902150: Current learning rate: 0.00199
2025-10-05 22:45:19.144430: Validation loss did not improve from -0.30448. Patience: 101/50
2025-10-05 22:45:19.144881: train_loss -0.9083
2025-10-05 22:45:19.145030: val_loss -0.1035
2025-10-05 22:45:19.145180: Pseudo dice [np.float32(0.6445)]
2025-10-05 22:45:19.145370: Epoch time: 46.24 s
2025-10-05 22:45:19.786440: 
2025-10-05 22:45:19.786831: Epoch 126
2025-10-05 22:45:19.787130: Current learning rate: 0.00192
2025-10-05 22:46:05.963357: Validation loss did not improve from -0.30448. Patience: 102/50
2025-10-05 22:46:05.963926: train_loss -0.9093
2025-10-05 22:46:05.964133: val_loss -0.078
2025-10-05 22:46:05.964282: Pseudo dice [np.float32(0.6426)]
2025-10-05 22:46:05.964409: Epoch time: 46.18 s
2025-10-05 22:46:06.597178: 
2025-10-05 22:46:06.597522: Epoch 127
2025-10-05 22:46:06.597694: Current learning rate: 0.00185
2025-10-05 22:46:52.720166: Validation loss did not improve from -0.30448. Patience: 103/50
2025-10-05 22:46:52.720849: train_loss -0.9122
2025-10-05 22:46:52.721121: val_loss -0.0891
2025-10-05 22:46:52.721545: Pseudo dice [np.float32(0.6499)]
2025-10-05 22:46:52.721838: Epoch time: 46.12 s
2025-10-05 22:46:53.718795: 
2025-10-05 22:46:53.719163: Epoch 128
2025-10-05 22:46:53.719385: Current learning rate: 0.00178
2025-10-05 22:47:39.775516: Validation loss did not improve from -0.30448. Patience: 104/50
2025-10-05 22:47:39.776165: train_loss -0.9101
2025-10-05 22:47:39.776344: val_loss -0.0819
2025-10-05 22:47:39.776495: Pseudo dice [np.float32(0.647)]
2025-10-05 22:47:39.776628: Epoch time: 46.06 s
2025-10-05 22:47:40.407519: 
2025-10-05 22:47:40.407898: Epoch 129
2025-10-05 22:47:40.408139: Current learning rate: 0.0017
2025-10-05 22:48:26.546053: Validation loss did not improve from -0.30448. Patience: 105/50
2025-10-05 22:48:26.546634: train_loss -0.9101
2025-10-05 22:48:26.546953: val_loss -0.0752
2025-10-05 22:48:26.547156: Pseudo dice [np.float32(0.6552)]
2025-10-05 22:48:26.547334: Epoch time: 46.14 s
2025-10-05 22:48:27.634193: 
2025-10-05 22:48:27.634534: Epoch 130
2025-10-05 22:48:27.634743: Current learning rate: 0.00163
2025-10-05 22:49:13.850786: Validation loss did not improve from -0.30448. Patience: 106/50
2025-10-05 22:49:13.851392: train_loss -0.9099
2025-10-05 22:49:13.851533: val_loss -0.0828
2025-10-05 22:49:13.851640: Pseudo dice [np.float32(0.6559)]
2025-10-05 22:49:13.851777: Epoch time: 46.22 s
2025-10-05 22:49:14.487884: 
2025-10-05 22:49:14.488238: Epoch 131
2025-10-05 22:49:14.488451: Current learning rate: 0.00156
2025-10-05 22:50:00.627447: Validation loss did not improve from -0.30448. Patience: 107/50
2025-10-05 22:50:00.627904: train_loss -0.9111
2025-10-05 22:50:00.628134: val_loss -0.0843
2025-10-05 22:50:00.628330: Pseudo dice [np.float32(0.6644)]
2025-10-05 22:50:00.628537: Epoch time: 46.14 s
2025-10-05 22:50:00.628723: Yayy! New best EMA pseudo Dice: 0.6504999995231628
2025-10-05 22:50:01.699831: 
2025-10-05 22:50:01.700142: Epoch 132
2025-10-05 22:50:01.700318: Current learning rate: 0.00148
2025-10-05 22:50:47.774336: Validation loss did not improve from -0.30448. Patience: 108/50
2025-10-05 22:50:47.774826: train_loss -0.9116
2025-10-05 22:50:47.775013: val_loss -0.0908
2025-10-05 22:50:47.775132: Pseudo dice [np.float32(0.6473)]
2025-10-05 22:50:47.775268: Epoch time: 46.08 s
2025-10-05 22:50:48.397927: 
2025-10-05 22:50:48.398251: Epoch 133
2025-10-05 22:50:48.398454: Current learning rate: 0.00141
2025-10-05 22:51:34.461790: Validation loss did not improve from -0.30448. Patience: 109/50
2025-10-05 22:51:34.462402: train_loss -0.9133
2025-10-05 22:51:34.462541: val_loss -0.0812
2025-10-05 22:51:34.462746: Pseudo dice [np.float32(0.6585)]
2025-10-05 22:51:34.462929: Epoch time: 46.07 s
2025-10-05 22:51:34.463092: Yayy! New best EMA pseudo Dice: 0.6510000228881836
2025-10-05 22:51:35.544480: 
2025-10-05 22:51:35.544742: Epoch 134
2025-10-05 22:51:35.544963: Current learning rate: 0.00133
2025-10-05 22:52:21.631570: Validation loss did not improve from -0.30448. Patience: 110/50
2025-10-05 22:52:21.632176: train_loss -0.9136
2025-10-05 22:52:21.632377: val_loss -0.0957
2025-10-05 22:52:21.632519: Pseudo dice [np.float32(0.6467)]
2025-10-05 22:52:21.632733: Epoch time: 46.09 s
2025-10-05 22:52:22.724597: 
2025-10-05 22:52:22.724979: Epoch 135
2025-10-05 22:52:22.725368: Current learning rate: 0.00126
2025-10-05 22:53:08.817336: Validation loss did not improve from -0.30448. Patience: 111/50
2025-10-05 22:53:08.817823: train_loss -0.9137
2025-10-05 22:53:08.818034: val_loss -0.0538
2025-10-05 22:53:08.818252: Pseudo dice [np.float32(0.6346)]
2025-10-05 22:53:08.818468: Epoch time: 46.09 s
2025-10-05 22:53:09.451252: 
2025-10-05 22:53:09.451620: Epoch 136
2025-10-05 22:53:09.451895: Current learning rate: 0.00118
2025-10-05 22:53:55.543908: Validation loss did not improve from -0.30448. Patience: 112/50
2025-10-05 22:53:55.544508: train_loss -0.9157
2025-10-05 22:53:55.544663: val_loss -0.0799
2025-10-05 22:53:55.544786: Pseudo dice [np.float32(0.6525)]
2025-10-05 22:53:55.544941: Epoch time: 46.09 s
2025-10-05 22:53:56.179316: 
2025-10-05 22:53:56.179669: Epoch 137
2025-10-05 22:53:56.179859: Current learning rate: 0.00111
2025-10-05 22:54:42.299847: Validation loss did not improve from -0.30448. Patience: 113/50
2025-10-05 22:54:42.300350: train_loss -0.9148
2025-10-05 22:54:42.300498: val_loss -0.1032
2025-10-05 22:54:42.300610: Pseudo dice [np.float32(0.6614)]
2025-10-05 22:54:42.300777: Epoch time: 46.12 s
2025-10-05 22:54:42.931137: 
2025-10-05 22:54:42.931521: Epoch 138
2025-10-05 22:54:42.931794: Current learning rate: 0.00103
2025-10-05 22:55:29.027170: Validation loss did not improve from -0.30448. Patience: 114/50
2025-10-05 22:55:29.027704: train_loss -0.913
2025-10-05 22:55:29.027853: val_loss -0.0419
2025-10-05 22:55:29.028018: Pseudo dice [np.float32(0.6404)]
2025-10-05 22:55:29.028142: Epoch time: 46.1 s
2025-10-05 22:55:29.662729: 
2025-10-05 22:55:29.663069: Epoch 139
2025-10-05 22:55:29.663265: Current learning rate: 0.00095
2025-10-05 22:56:15.732089: Validation loss did not improve from -0.30448. Patience: 115/50
2025-10-05 22:56:15.732671: train_loss -0.9155
2025-10-05 22:56:15.732828: val_loss -0.0735
2025-10-05 22:56:15.732971: Pseudo dice [np.float32(0.6496)]
2025-10-05 22:56:15.733118: Epoch time: 46.07 s
2025-10-05 22:56:16.823910: 
2025-10-05 22:56:16.824194: Epoch 140
2025-10-05 22:56:16.824450: Current learning rate: 0.00087
2025-10-05 22:57:03.293438: Validation loss did not improve from -0.30448. Patience: 116/50
2025-10-05 22:57:03.294206: train_loss -0.9161
2025-10-05 22:57:03.294446: val_loss -0.0308
2025-10-05 22:57:03.294677: Pseudo dice [np.float32(0.645)]
2025-10-05 22:57:03.294921: Epoch time: 46.47 s
2025-10-05 22:57:03.935897: 
2025-10-05 22:57:03.936306: Epoch 141
2025-10-05 22:57:03.936595: Current learning rate: 0.00079
2025-10-05 22:57:50.052291: Validation loss did not improve from -0.30448. Patience: 117/50
2025-10-05 22:57:50.052832: train_loss -0.9165
2025-10-05 22:57:50.053031: val_loss -0.0483
2025-10-05 22:57:50.053183: Pseudo dice [np.float32(0.6432)]
2025-10-05 22:57:50.053367: Epoch time: 46.12 s
2025-10-05 22:57:50.687694: 
2025-10-05 22:57:50.688084: Epoch 142
2025-10-05 22:57:50.688293: Current learning rate: 0.00071
2025-10-05 22:58:36.815436: Validation loss did not improve from -0.30448. Patience: 118/50
2025-10-05 22:58:36.816226: train_loss -0.9167
2025-10-05 22:58:36.816445: val_loss -0.084
2025-10-05 22:58:36.816641: Pseudo dice [np.float32(0.6498)]
2025-10-05 22:58:36.816864: Epoch time: 46.13 s
2025-10-05 22:58:37.458854: 
2025-10-05 22:58:37.459227: Epoch 143
2025-10-05 22:58:37.459470: Current learning rate: 0.00063
2025-10-05 22:59:23.621016: Validation loss did not improve from -0.30448. Patience: 119/50
2025-10-05 22:59:23.621537: train_loss -0.9155
2025-10-05 22:59:23.621727: val_loss -0.0755
2025-10-05 22:59:23.621867: Pseudo dice [np.float32(0.6568)]
2025-10-05 22:59:23.622046: Epoch time: 46.16 s
2025-10-05 22:59:24.269374: 
2025-10-05 22:59:24.269774: Epoch 144
2025-10-05 22:59:24.269974: Current learning rate: 0.00055
2025-10-05 23:00:10.355863: Validation loss did not improve from -0.30448. Patience: 120/50
2025-10-05 23:00:10.356465: train_loss -0.918
2025-10-05 23:00:10.356606: val_loss -0.0863
2025-10-05 23:00:10.357016: Pseudo dice [np.float32(0.6383)]
2025-10-05 23:00:10.357186: Epoch time: 46.09 s
2025-10-05 23:00:11.449147: 
2025-10-05 23:00:11.449445: Epoch 145
2025-10-05 23:00:11.449808: Current learning rate: 0.00047
2025-10-05 23:00:57.583270: Validation loss did not improve from -0.30448. Patience: 121/50
2025-10-05 23:00:57.583847: train_loss -0.9213
2025-10-05 23:00:57.584053: val_loss -0.088
2025-10-05 23:00:57.584224: Pseudo dice [np.float32(0.6634)]
2025-10-05 23:00:57.584375: Epoch time: 46.14 s
2025-10-05 23:00:58.226732: 
2025-10-05 23:00:58.227143: Epoch 146
2025-10-05 23:00:58.227375: Current learning rate: 0.00038
2025-10-05 23:01:44.385290: Validation loss did not improve from -0.30448. Patience: 122/50
2025-10-05 23:01:44.385904: train_loss -0.919
2025-10-05 23:01:44.386058: val_loss -0.0238
2025-10-05 23:01:44.386169: Pseudo dice [np.float32(0.6413)]
2025-10-05 23:01:44.386314: Epoch time: 46.16 s
2025-10-05 23:01:45.038027: 
2025-10-05 23:01:45.038377: Epoch 147
2025-10-05 23:01:45.038589: Current learning rate: 0.0003
2025-10-05 23:02:31.176221: Validation loss did not improve from -0.30448. Patience: 123/50
2025-10-05 23:02:31.176749: train_loss -0.9194
2025-10-05 23:02:31.176899: val_loss -0.0368
2025-10-05 23:02:31.177012: Pseudo dice [np.float32(0.6419)]
2025-10-05 23:02:31.177148: Epoch time: 46.14 s
2025-10-05 23:02:31.812885: 
2025-10-05 23:02:31.813252: Epoch 148
2025-10-05 23:02:31.813480: Current learning rate: 0.00021
2025-10-05 23:03:17.940390: Validation loss did not improve from -0.30448. Patience: 124/50
2025-10-05 23:03:17.941087: train_loss -0.9174
2025-10-05 23:03:17.941249: val_loss -0.0806
2025-10-05 23:03:17.941381: Pseudo dice [np.float32(0.6443)]
2025-10-05 23:03:17.941523: Epoch time: 46.13 s
2025-10-05 23:03:18.577616: 
2025-10-05 23:03:18.577886: Epoch 149
2025-10-05 23:03:18.578110: Current learning rate: 0.00011
2025-10-05 23:04:04.623326: Validation loss did not improve from -0.30448. Patience: 125/50
2025-10-05 23:04:04.623848: train_loss -0.9194
2025-10-05 23:04:04.624054: val_loss -0.0893
2025-10-05 23:04:04.624303: Pseudo dice [np.float32(0.6554)]
2025-10-05 23:04:04.624536: Epoch time: 46.05 s
2025-10-05 23:04:05.820211: Training done.
2025-10-05 23:04:05.876308: Using splits from existing split file: /nfs/erelab001/shared/Computational_Group/Naravich/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset310_nnInteractive_Calcium_OCT_CrossValidation/splits_final_40.json
2025-10-05 23:04:05.876812: The split file contains 5 splits.
2025-10-05 23:04:05.877913: Desired fold for training: 3
2025-10-05 23:04:05.878371: This split has 3 training and 6 validation cases.
2025-10-05 23:04:05.878613: predicting 101-044
2025-10-05 23:04:05.881281: 101-044, shape torch.Size([1, 404, 498, 498]), rank 0
2025-10-05 23:04:47.398180: predicting 101-045
2025-10-05 23:04:47.410422: 101-045, shape torch.Size([1, 375, 498, 498]), rank 0
2025-10-05 23:05:21.573948: predicting 106-002
2025-10-05 23:05:21.588751: 106-002, shape torch.Size([1, 539, 498, 498]), rank 0
2025-10-05 23:06:10.309966: predicting 401-004
2025-10-05 23:06:10.328597: 401-004, shape torch.Size([1, 375, 498, 498]), rank 0
2025-10-05 23:06:44.596937: predicting 704-003
2025-10-05 23:06:44.610081: 704-003, shape torch.Size([1, 375, 498, 498]), rank 0
2025-10-05 23:07:18.897442: predicting 706-005
2025-10-05 23:07:18.911322: 706-005, shape torch.Size([1, 375, 498, 498]), rank 0
2025-10-05 23:08:06.855846: Validation complete
2025-10-05 23:08:06.856106: Mean Validation Dice:  0.613942966897756
Finished training fold 3 saving to /nfs/erelab001/shared/Computational_Group/Naravich/datasets/nnUNet_Datasets/nnUNet_results/Dataset310_nnInteractive_Calcium_OCT_CrossValidation/nnUNetTrainerScaleAnalysis40__nnUNetPlans__3d_32x160x128_b10/fold_3_No_Pretrained
