/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/bin/python
Starting training with CONFIG=3d_32x160x128_b10, DATASET_ID=310, TRAINER=nnUNetTrainerScaleAnalysis80
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:169: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2025-10-05 19:02:41.564787: do_dummy_2d_data_aug: True
2025-10-05 19:02:41.565137: Using splits from existing split file: /nfs/erelab001/shared/Computational_Group/Naravich/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset310_nnInteractive_Calcium_OCT_CrossValidation/splits_final_80.json
2025-10-05 19:02:41.565367: The split file contains 5 splits.
2025-10-05 19:02:41.565502: Desired fold for training: 2
2025-10-05 19:02:41.565631: This split has 6 training and 3 validation cases.
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
using pin_memory on device 0
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
using pin_memory on device 0
2025-10-05 19:02:45.873411: Using torch.compile...

This is the configuration used by this training:
Configuration name: 3d_32x160x128_b10
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 10, 'patch_size': [32, 160, 128], 'median_image_size_in_voxels': [375.0, 498.0, 498.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'inherits_from': '3d_fullres'} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset310_nnInteractive_Calcium_OCT_CrossValidation', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.4977976381778717, 'mean': 0.1394134759902954, 'median': 0.09849607944488525, 'min': 0.0, 'percentile_00_5': 0.015305490233004093, 'percentile_99_5': 0.4977976381778717, 'std': 0.121165432035923}}} 

2025-10-05 19:02:47.327307: unpacking dataset...
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:7095: UserWarning: 
Online softmax is disabled on the fly since Inductor decides to
split the reduction. Cut an issue to PyTorch if this is an
important use case and you want to speed it up with online
softmax.

  warnings.warn(
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:7095: UserWarning: 
Online softmax is disabled on the fly since Inductor decides to
split the reduction. Cut an issue to PyTorch if this is an
important use case and you want to speed it up with online
softmax.

  warnings.warn(
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:7095: UserWarning: 
Online softmax is disabled on the fly since Inductor decides to
split the reduction. Cut an issue to PyTorch if this is an
important use case and you want to speed it up with online
softmax.

  warnings.warn(
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:7095: UserWarning: 
Online softmax is disabled on the fly since Inductor decides to
split the reduction. Cut an issue to PyTorch if this is an
important use case and you want to speed it up with online
softmax.

  warnings.warn(
2025-10-05 19:02:51.833525: unpacking done...
2025-10-05 19:02:51.835965: Unable to plot network architecture: nnUNet_compile is enabled!
2025-10-05 19:02:51.840942: 
2025-10-05 19:02:51.841203: Epoch 0
2025-10-05 19:02:51.841438: Current learning rate: 0.01
2025-10-05 19:04:13.162251: Validation loss improved from 1000.00000 to -0.13475! Patience: 0/50
2025-10-05 19:04:13.162956: train_loss -0.1395
2025-10-05 19:04:13.163132: val_loss -0.1348
2025-10-05 19:04:13.163275: Pseudo dice [np.float32(0.5048)]
2025-10-05 19:04:13.163432: Epoch time: 81.32 s
2025-10-05 19:04:13.163613: Yayy! New best EMA pseudo Dice: 0.504800021648407
2025-10-05 19:04:14.127122: 
2025-10-05 19:04:14.127534: Epoch 1
2025-10-05 19:04:14.127844: Current learning rate: 0.00994
2025-10-05 19:05:00.251091: Validation loss improved from -0.13475 to -0.16669! Patience: 0/50
2025-10-05 19:05:00.251622: train_loss -0.2631
2025-10-05 19:05:00.251768: val_loss -0.1667
2025-10-05 19:05:00.251883: Pseudo dice [np.float32(0.5433)]
2025-10-05 19:05:00.252010: Epoch time: 46.13 s
2025-10-05 19:05:00.252165: Yayy! New best EMA pseudo Dice: 0.5087000131607056
2025-10-05 19:05:01.415335: 
2025-10-05 19:05:01.415708: Epoch 2
2025-10-05 19:05:01.415931: Current learning rate: 0.00988
2025-10-05 19:05:47.652039: Validation loss improved from -0.16669 to -0.17866! Patience: 0/50
2025-10-05 19:05:47.652664: train_loss -0.3096
2025-10-05 19:05:47.652847: val_loss -0.1787
2025-10-05 19:05:47.652963: Pseudo dice [np.float32(0.5387)]
2025-10-05 19:05:47.653103: Epoch time: 46.24 s
2025-10-05 19:05:47.653266: Yayy! New best EMA pseudo Dice: 0.5116999745368958
2025-10-05 19:05:48.794125: 
2025-10-05 19:05:48.794457: Epoch 3
2025-10-05 19:05:48.794910: Current learning rate: 0.00982
2025-10-05 19:06:35.168222: Validation loss improved from -0.17866 to -0.25954! Patience: 0/50
2025-10-05 19:06:35.168827: train_loss -0.3643
2025-10-05 19:06:35.168983: val_loss -0.2595
2025-10-05 19:06:35.169121: Pseudo dice [np.float32(0.5862)]
2025-10-05 19:06:35.169290: Epoch time: 46.38 s
2025-10-05 19:06:35.169421: Yayy! New best EMA pseudo Dice: 0.51910001039505
2025-10-05 19:06:36.285162: 
2025-10-05 19:06:36.285514: Epoch 4
2025-10-05 19:06:36.285712: Current learning rate: 0.00976
2025-10-05 19:07:22.638872: Validation loss did not improve from -0.25954. Patience: 1/50
2025-10-05 19:07:22.639636: train_loss -0.3967
2025-10-05 19:07:22.639949: val_loss -0.2267
2025-10-05 19:07:22.640182: Pseudo dice [np.float32(0.572)]
2025-10-05 19:07:22.640470: Epoch time: 46.36 s
2025-10-05 19:07:23.057406: Yayy! New best EMA pseudo Dice: 0.524399995803833
2025-10-05 19:07:24.199161: 
2025-10-05 19:07:24.199536: Epoch 5
2025-10-05 19:07:24.199790: Current learning rate: 0.0097
2025-10-05 19:08:10.525832: Validation loss did not improve from -0.25954. Patience: 2/50
2025-10-05 19:08:10.526343: train_loss -0.4444
2025-10-05 19:08:10.526566: val_loss -0.1851
2025-10-05 19:08:10.526825: Pseudo dice [np.float32(0.5625)]
2025-10-05 19:08:10.527030: Epoch time: 46.33 s
2025-10-05 19:08:10.527195: Yayy! New best EMA pseudo Dice: 0.5281999707221985
2025-10-05 19:08:11.689922: 
2025-10-05 19:08:11.690211: Epoch 6
2025-10-05 19:08:11.690412: Current learning rate: 0.00964
2025-10-05 19:08:57.955059: Validation loss did not improve from -0.25954. Patience: 3/50
2025-10-05 19:08:57.955893: train_loss -0.4448
2025-10-05 19:08:57.956084: val_loss -0.2103
2025-10-05 19:08:57.956290: Pseudo dice [np.float32(0.5698)]
2025-10-05 19:08:57.956486: Epoch time: 46.27 s
2025-10-05 19:08:57.956658: Yayy! New best EMA pseudo Dice: 0.5324000120162964
2025-10-05 19:08:59.082561: 
2025-10-05 19:08:59.083039: Epoch 7
2025-10-05 19:08:59.083421: Current learning rate: 0.00958
2025-10-05 19:09:45.258109: Validation loss improved from -0.25954 to -0.25997! Patience: 3/50
2025-10-05 19:09:45.258572: train_loss -0.4628
2025-10-05 19:09:45.258846: val_loss -0.26
2025-10-05 19:09:45.259068: Pseudo dice [np.float32(0.5636)]
2025-10-05 19:09:45.259264: Epoch time: 46.18 s
2025-10-05 19:09:45.259438: Yayy! New best EMA pseudo Dice: 0.5354999899864197
2025-10-05 19:09:46.415241: 
2025-10-05 19:09:46.415632: Epoch 8
2025-10-05 19:09:46.415865: Current learning rate: 0.00952
2025-10-05 19:10:32.692049: Validation loss improved from -0.25997 to -0.26021! Patience: 0/50
2025-10-05 19:10:32.692765: train_loss -0.4649
2025-10-05 19:10:32.692977: val_loss -0.2602
2025-10-05 19:10:32.693135: Pseudo dice [np.float32(0.5844)]
2025-10-05 19:10:32.693331: Epoch time: 46.28 s
2025-10-05 19:10:32.693502: Yayy! New best EMA pseudo Dice: 0.5404000282287598
2025-10-05 19:10:33.850080: 
2025-10-05 19:10:33.850498: Epoch 9
2025-10-05 19:10:33.850770: Current learning rate: 0.00946
2025-10-05 19:11:20.205276: Validation loss improved from -0.26021 to -0.27926! Patience: 0/50
2025-10-05 19:11:20.205813: train_loss -0.4849
2025-10-05 19:11:20.206025: val_loss -0.2793
2025-10-05 19:11:20.206201: Pseudo dice [np.float32(0.6007)]
2025-10-05 19:11:20.206392: Epoch time: 46.36 s
2025-10-05 19:11:20.705065: Yayy! New best EMA pseudo Dice: 0.5464000105857849
2025-10-05 19:11:21.826837: 
2025-10-05 19:11:21.827240: Epoch 10
2025-10-05 19:11:21.827473: Current learning rate: 0.0094
2025-10-05 19:12:08.091732: Validation loss improved from -0.27926 to -0.32337! Patience: 0/50
2025-10-05 19:12:08.092402: train_loss -0.4952
2025-10-05 19:12:08.092544: val_loss -0.3234
2025-10-05 19:12:08.092679: Pseudo dice [np.float32(0.6163)]
2025-10-05 19:12:08.092948: Epoch time: 46.27 s
2025-10-05 19:12:08.093143: Yayy! New best EMA pseudo Dice: 0.5533999800682068
2025-10-05 19:12:09.215523: 
2025-10-05 19:12:09.215889: Epoch 11
2025-10-05 19:12:09.216128: Current learning rate: 0.00934
2025-10-05 19:12:55.445433: Validation loss did not improve from -0.32337. Patience: 1/50
2025-10-05 19:12:55.445881: train_loss -0.5029
2025-10-05 19:12:55.446087: val_loss -0.2611
2025-10-05 19:12:55.446259: Pseudo dice [np.float32(0.5985)]
2025-10-05 19:12:55.446435: Epoch time: 46.23 s
2025-10-05 19:12:55.446674: Yayy! New best EMA pseudo Dice: 0.5579000115394592
2025-10-05 19:12:56.589039: 
2025-10-05 19:12:56.589560: Epoch 12
2025-10-05 19:12:56.590007: Current learning rate: 0.00928
2025-10-05 19:13:42.789811: Validation loss improved from -0.32337 to -0.34117! Patience: 1/50
2025-10-05 19:13:42.790463: train_loss -0.5083
2025-10-05 19:13:42.790632: val_loss -0.3412
2025-10-05 19:13:42.790814: Pseudo dice [np.float32(0.6347)]
2025-10-05 19:13:42.790996: Epoch time: 46.2 s
2025-10-05 19:13:42.791145: Yayy! New best EMA pseudo Dice: 0.5655999779701233
2025-10-05 19:13:44.505310: 
2025-10-05 19:13:44.505645: Epoch 13
2025-10-05 19:13:44.505934: Current learning rate: 0.00922
2025-10-05 19:14:30.842656: Validation loss did not improve from -0.34117. Patience: 1/50
2025-10-05 19:14:30.843081: train_loss -0.5235
2025-10-05 19:14:30.843260: val_loss -0.3233
2025-10-05 19:14:30.843386: Pseudo dice [np.float32(0.6176)]
2025-10-05 19:14:30.843560: Epoch time: 46.34 s
2025-10-05 19:14:30.843699: Yayy! New best EMA pseudo Dice: 0.5708000063896179
2025-10-05 19:14:31.971078: 
2025-10-05 19:14:31.971440: Epoch 14
2025-10-05 19:14:31.971665: Current learning rate: 0.00916
2025-10-05 19:15:18.296624: Validation loss did not improve from -0.34117. Patience: 2/50
2025-10-05 19:15:18.297310: train_loss -0.5264
2025-10-05 19:15:18.297547: val_loss -0.2313
2025-10-05 19:15:18.297679: Pseudo dice [np.float32(0.5907)]
2025-10-05 19:15:18.297826: Epoch time: 46.33 s
2025-10-05 19:15:18.760260: Yayy! New best EMA pseudo Dice: 0.5727999806404114
2025-10-05 19:15:19.854617: 
2025-10-05 19:15:19.854985: Epoch 15
2025-10-05 19:15:19.855219: Current learning rate: 0.0091
2025-10-05 19:16:06.095302: Validation loss improved from -0.34117 to -0.34458! Patience: 2/50
2025-10-05 19:16:06.095903: train_loss -0.5347
2025-10-05 19:16:06.096133: val_loss -0.3446
2025-10-05 19:16:06.096426: Pseudo dice [np.float32(0.6298)]
2025-10-05 19:16:06.096696: Epoch time: 46.24 s
2025-10-05 19:16:06.096887: Yayy! New best EMA pseudo Dice: 0.578499972820282
2025-10-05 19:16:07.210377: 
2025-10-05 19:16:07.210671: Epoch 16
2025-10-05 19:16:07.210936: Current learning rate: 0.00903
2025-10-05 19:16:53.462553: Validation loss improved from -0.34458 to -0.41142! Patience: 0/50
2025-10-05 19:16:53.463307: train_loss -0.5471
2025-10-05 19:16:53.463575: val_loss -0.4114
2025-10-05 19:16:53.463729: Pseudo dice [np.float32(0.6675)]
2025-10-05 19:16:53.463898: Epoch time: 46.25 s
2025-10-05 19:16:53.464115: Yayy! New best EMA pseudo Dice: 0.5874000191688538
2025-10-05 19:16:54.574660: 
2025-10-05 19:16:54.574970: Epoch 17
2025-10-05 19:16:54.575195: Current learning rate: 0.00897
2025-10-05 19:17:40.893595: Validation loss did not improve from -0.41142. Patience: 1/50
2025-10-05 19:17:40.894084: train_loss -0.5515
2025-10-05 19:17:40.894257: val_loss -0.3644
2025-10-05 19:17:40.894397: Pseudo dice [np.float32(0.6272)]
2025-10-05 19:17:40.894565: Epoch time: 46.32 s
2025-10-05 19:17:40.894699: Yayy! New best EMA pseudo Dice: 0.5914000272750854
2025-10-05 19:17:41.998028: 
2025-10-05 19:17:41.998366: Epoch 18
2025-10-05 19:17:41.998588: Current learning rate: 0.00891
2025-10-05 19:18:28.463518: Validation loss did not improve from -0.41142. Patience: 2/50
2025-10-05 19:18:28.464228: train_loss -0.5494
2025-10-05 19:18:28.464382: val_loss -0.3285
2025-10-05 19:18:28.464523: Pseudo dice [np.float32(0.6288)]
2025-10-05 19:18:28.464660: Epoch time: 46.47 s
2025-10-05 19:18:28.464787: Yayy! New best EMA pseudo Dice: 0.5950999855995178
2025-10-05 19:18:29.576195: 
2025-10-05 19:18:29.576634: Epoch 19
2025-10-05 19:18:29.576906: Current learning rate: 0.00885
2025-10-05 19:19:15.979309: Validation loss did not improve from -0.41142. Patience: 3/50
2025-10-05 19:19:15.979825: train_loss -0.5598
2025-10-05 19:19:15.979964: val_loss -0.316
2025-10-05 19:19:15.980076: Pseudo dice [np.float32(0.6271)]
2025-10-05 19:19:15.980256: Epoch time: 46.4 s
2025-10-05 19:19:16.416131: Yayy! New best EMA pseudo Dice: 0.5982999801635742
2025-10-05 19:19:17.508691: 
2025-10-05 19:19:17.509010: Epoch 20
2025-10-05 19:19:17.509181: Current learning rate: 0.00879
2025-10-05 19:20:03.796484: Validation loss did not improve from -0.41142. Patience: 4/50
2025-10-05 19:20:03.797243: train_loss -0.5812
2025-10-05 19:20:03.797448: val_loss -0.3643
2025-10-05 19:20:03.797683: Pseudo dice [np.float32(0.6399)]
2025-10-05 19:20:03.797932: Epoch time: 46.29 s
2025-10-05 19:20:03.798199: Yayy! New best EMA pseudo Dice: 0.6025000214576721
2025-10-05 19:20:04.899989: 
2025-10-05 19:20:04.900431: Epoch 21
2025-10-05 19:20:04.900738: Current learning rate: 0.00873
2025-10-05 19:20:51.192830: Validation loss did not improve from -0.41142. Patience: 5/50
2025-10-05 19:20:51.193253: train_loss -0.5811
2025-10-05 19:20:51.193405: val_loss -0.3525
2025-10-05 19:20:51.193592: Pseudo dice [np.float32(0.6403)]
2025-10-05 19:20:51.193753: Epoch time: 46.29 s
2025-10-05 19:20:51.193895: Yayy! New best EMA pseudo Dice: 0.6062999963760376
2025-10-05 19:20:52.298615: 
2025-10-05 19:20:52.298933: Epoch 22
2025-10-05 19:20:52.299156: Current learning rate: 0.00867
2025-10-05 19:21:38.619800: Validation loss did not improve from -0.41142. Patience: 6/50
2025-10-05 19:21:38.620464: train_loss -0.5774
2025-10-05 19:21:38.620602: val_loss -0.3323
2025-10-05 19:21:38.620739: Pseudo dice [np.float32(0.6299)]
2025-10-05 19:21:38.620947: Epoch time: 46.32 s
2025-10-05 19:21:38.621065: Yayy! New best EMA pseudo Dice: 0.6086000204086304
2025-10-05 19:21:39.715297: 
2025-10-05 19:21:39.715616: Epoch 23
2025-10-05 19:21:39.715812: Current learning rate: 0.00861
2025-10-05 19:22:26.104384: Validation loss did not improve from -0.41142. Patience: 7/50
2025-10-05 19:22:26.105081: train_loss -0.5843
2025-10-05 19:22:26.105388: val_loss -0.409
2025-10-05 19:22:26.105812: Pseudo dice [np.float32(0.6576)]
2025-10-05 19:22:26.106118: Epoch time: 46.39 s
2025-10-05 19:22:26.106375: Yayy! New best EMA pseudo Dice: 0.6134999990463257
2025-10-05 19:22:27.219722: 
2025-10-05 19:22:27.220150: Epoch 24
2025-10-05 19:22:27.220427: Current learning rate: 0.00855
2025-10-05 19:23:13.569745: Validation loss did not improve from -0.41142. Patience: 8/50
2025-10-05 19:23:13.570400: train_loss -0.5834
2025-10-05 19:23:13.570582: val_loss -0.3238
2025-10-05 19:23:13.570732: Pseudo dice [np.float32(0.6372)]
2025-10-05 19:23:13.570919: Epoch time: 46.35 s
2025-10-05 19:23:14.012428: Yayy! New best EMA pseudo Dice: 0.6158999800682068
2025-10-05 19:23:15.096987: 
2025-10-05 19:23:15.097353: Epoch 25
2025-10-05 19:23:15.097586: Current learning rate: 0.00849
2025-10-05 19:24:01.429592: Validation loss improved from -0.41142 to -0.42464! Patience: 8/50
2025-10-05 19:24:01.430065: train_loss -0.5977
2025-10-05 19:24:01.430208: val_loss -0.4246
2025-10-05 19:24:01.430320: Pseudo dice [np.float32(0.6717)]
2025-10-05 19:24:01.430484: Epoch time: 46.33 s
2025-10-05 19:24:01.430653: Yayy! New best EMA pseudo Dice: 0.6215000152587891
2025-10-05 19:24:02.507796: 
2025-10-05 19:24:02.508166: Epoch 26
2025-10-05 19:24:02.508348: Current learning rate: 0.00843
2025-10-05 19:24:48.725429: Validation loss did not improve from -0.42464. Patience: 1/50
2025-10-05 19:24:48.726021: train_loss -0.5818
2025-10-05 19:24:48.726155: val_loss -0.3652
2025-10-05 19:24:48.726263: Pseudo dice [np.float32(0.6465)]
2025-10-05 19:24:48.726390: Epoch time: 46.22 s
2025-10-05 19:24:48.726513: Yayy! New best EMA pseudo Dice: 0.6240000128746033
2025-10-05 19:24:50.352232: 
2025-10-05 19:24:50.352583: Epoch 27
2025-10-05 19:24:50.352805: Current learning rate: 0.00836
2025-10-05 19:25:36.710127: Validation loss did not improve from -0.42464. Patience: 2/50
2025-10-05 19:25:36.710541: train_loss -0.6089
2025-10-05 19:25:36.710726: val_loss -0.3516
2025-10-05 19:25:36.710884: Pseudo dice [np.float32(0.6468)]
2025-10-05 19:25:36.711085: Epoch time: 46.36 s
2025-10-05 19:25:36.711277: Yayy! New best EMA pseudo Dice: 0.6262999773025513
2025-10-05 19:25:37.850145: 
2025-10-05 19:25:37.850466: Epoch 28
2025-10-05 19:25:37.850657: Current learning rate: 0.0083
2025-10-05 19:26:24.235639: Validation loss did not improve from -0.42464. Patience: 3/50
2025-10-05 19:26:24.236199: train_loss -0.6165
2025-10-05 19:26:24.236333: val_loss -0.3987
2025-10-05 19:26:24.236459: Pseudo dice [np.float32(0.6687)]
2025-10-05 19:26:24.236623: Epoch time: 46.39 s
2025-10-05 19:26:24.236740: Yayy! New best EMA pseudo Dice: 0.6305000185966492
2025-10-05 19:26:25.353675: 
2025-10-05 19:26:25.354113: Epoch 29
2025-10-05 19:26:25.354392: Current learning rate: 0.00824
2025-10-05 19:27:11.761124: Validation loss did not improve from -0.42464. Patience: 4/50
2025-10-05 19:27:11.761638: train_loss -0.6117
2025-10-05 19:27:11.761805: val_loss -0.3783
2025-10-05 19:27:11.761938: Pseudo dice [np.float32(0.6503)]
2025-10-05 19:27:11.762084: Epoch time: 46.41 s
2025-10-05 19:27:12.222677: Yayy! New best EMA pseudo Dice: 0.6324999928474426
2025-10-05 19:27:13.417592: 
2025-10-05 19:27:13.417992: Epoch 30
2025-10-05 19:27:13.418331: Current learning rate: 0.00818
2025-10-05 19:27:59.748675: Validation loss did not improve from -0.42464. Patience: 5/50
2025-10-05 19:27:59.749342: train_loss -0.6179
2025-10-05 19:27:59.749523: val_loss -0.4079
2025-10-05 19:27:59.749710: Pseudo dice [np.float32(0.6635)]
2025-10-05 19:27:59.749888: Epoch time: 46.33 s
2025-10-05 19:27:59.750040: Yayy! New best EMA pseudo Dice: 0.6355999708175659
2025-10-05 19:28:00.844213: 
2025-10-05 19:28:00.844614: Epoch 31
2025-10-05 19:28:00.844893: Current learning rate: 0.00812
2025-10-05 19:28:47.145573: Validation loss did not improve from -0.42464. Patience: 6/50
2025-10-05 19:28:47.146005: train_loss -0.619
2025-10-05 19:28:47.146189: val_loss -0.3872
2025-10-05 19:28:47.146385: Pseudo dice [np.float32(0.6583)]
2025-10-05 19:28:47.146569: Epoch time: 46.3 s
2025-10-05 19:28:47.146725: Yayy! New best EMA pseudo Dice: 0.6378999948501587
2025-10-05 19:28:48.256981: 
2025-10-05 19:28:48.257264: Epoch 32
2025-10-05 19:28:48.257490: Current learning rate: 0.00806
2025-10-05 19:29:34.658015: Validation loss did not improve from -0.42464. Patience: 7/50
2025-10-05 19:29:34.658701: train_loss -0.6276
2025-10-05 19:29:34.658852: val_loss -0.3956
2025-10-05 19:29:34.658972: Pseudo dice [np.float32(0.6553)]
2025-10-05 19:29:34.659108: Epoch time: 46.4 s
2025-10-05 19:29:34.659401: Yayy! New best EMA pseudo Dice: 0.6395999789237976
2025-10-05 19:29:35.765813: 
2025-10-05 19:29:35.766238: Epoch 33
2025-10-05 19:29:35.766456: Current learning rate: 0.008
2025-10-05 19:30:22.160703: Validation loss did not improve from -0.42464. Patience: 8/50
2025-10-05 19:30:22.161190: train_loss -0.6363
2025-10-05 19:30:22.161410: val_loss -0.3751
2025-10-05 19:30:22.161528: Pseudo dice [np.float32(0.6433)]
2025-10-05 19:30:22.161657: Epoch time: 46.4 s
2025-10-05 19:30:22.161788: Yayy! New best EMA pseudo Dice: 0.6399999856948853
2025-10-05 19:30:23.290667: 
2025-10-05 19:30:23.290945: Epoch 34
2025-10-05 19:30:23.291151: Current learning rate: 0.00793
2025-10-05 19:31:09.620543: Validation loss improved from -0.42464 to -0.43488! Patience: 8/50
2025-10-05 19:31:09.621227: train_loss -0.6451
2025-10-05 19:31:09.621365: val_loss -0.4349
2025-10-05 19:31:09.621508: Pseudo dice [np.float32(0.6746)]
2025-10-05 19:31:09.621675: Epoch time: 46.33 s
2025-10-05 19:31:10.074461: Yayy! New best EMA pseudo Dice: 0.6434000134468079
2025-10-05 19:31:11.170201: 
2025-10-05 19:31:11.170603: Epoch 35
2025-10-05 19:31:11.170836: Current learning rate: 0.00787
2025-10-05 19:31:57.445189: Validation loss did not improve from -0.43488. Patience: 1/50
2025-10-05 19:31:57.445718: train_loss -0.6529
2025-10-05 19:31:57.445937: val_loss -0.4042
2025-10-05 19:31:57.446110: Pseudo dice [np.float32(0.6637)]
2025-10-05 19:31:57.446269: Epoch time: 46.28 s
2025-10-05 19:31:57.446425: Yayy! New best EMA pseudo Dice: 0.6455000042915344
2025-10-05 19:31:58.564553: 
2025-10-05 19:31:58.564878: Epoch 36
2025-10-05 19:31:58.565089: Current learning rate: 0.00781
2025-10-05 19:32:44.875374: Validation loss did not improve from -0.43488. Patience: 2/50
2025-10-05 19:32:44.876069: train_loss -0.649
2025-10-05 19:32:44.876235: val_loss -0.4129
2025-10-05 19:32:44.876376: Pseudo dice [np.float32(0.6719)]
2025-10-05 19:32:44.876509: Epoch time: 46.31 s
2025-10-05 19:32:44.876626: Yayy! New best EMA pseudo Dice: 0.6481000185012817
2025-10-05 19:32:45.986946: 
2025-10-05 19:32:45.987309: Epoch 37
2025-10-05 19:32:45.987568: Current learning rate: 0.00775
2025-10-05 19:33:32.511746: Validation loss did not improve from -0.43488. Patience: 3/50
2025-10-05 19:33:32.512290: train_loss -0.6489
2025-10-05 19:33:32.512460: val_loss -0.3947
2025-10-05 19:33:32.512577: Pseudo dice [np.float32(0.6563)]
2025-10-05 19:33:32.512752: Epoch time: 46.53 s
2025-10-05 19:33:32.512876: Yayy! New best EMA pseudo Dice: 0.6488999724388123
2025-10-05 19:33:33.622778: 
2025-10-05 19:33:33.623106: Epoch 38
2025-10-05 19:33:33.623330: Current learning rate: 0.00769
2025-10-05 19:34:20.074263: Validation loss did not improve from -0.43488. Patience: 4/50
2025-10-05 19:34:20.074823: train_loss -0.6496
2025-10-05 19:34:20.074975: val_loss -0.3711
2025-10-05 19:34:20.075113: Pseudo dice [np.float32(0.6542)]
2025-10-05 19:34:20.075269: Epoch time: 46.45 s
2025-10-05 19:34:20.075403: Yayy! New best EMA pseudo Dice: 0.6495000123977661
2025-10-05 19:34:21.190970: 
2025-10-05 19:34:21.191409: Epoch 39
2025-10-05 19:34:21.191663: Current learning rate: 0.00763
2025-10-05 19:35:07.493915: Validation loss did not improve from -0.43488. Patience: 5/50
2025-10-05 19:35:07.494375: train_loss -0.6433
2025-10-05 19:35:07.494540: val_loss -0.406
2025-10-05 19:35:07.494713: Pseudo dice [np.float32(0.6689)]
2025-10-05 19:35:07.494884: Epoch time: 46.3 s
2025-10-05 19:35:07.950683: Yayy! New best EMA pseudo Dice: 0.6514000296592712
2025-10-05 19:35:09.054987: 
2025-10-05 19:35:09.055381: Epoch 40
2025-10-05 19:35:09.055686: Current learning rate: 0.00756
2025-10-05 19:35:55.336805: Validation loss did not improve from -0.43488. Patience: 6/50
2025-10-05 19:35:55.337382: train_loss -0.66
2025-10-05 19:35:55.337593: val_loss -0.3841
2025-10-05 19:35:55.337748: Pseudo dice [np.float32(0.6613)]
2025-10-05 19:35:55.337917: Epoch time: 46.28 s
2025-10-05 19:35:55.338087: Yayy! New best EMA pseudo Dice: 0.652400016784668
2025-10-05 19:35:56.433472: 
2025-10-05 19:35:56.433824: Epoch 41
2025-10-05 19:35:56.434018: Current learning rate: 0.0075
2025-10-05 19:36:42.702311: Validation loss did not improve from -0.43488. Patience: 7/50
2025-10-05 19:36:42.702916: train_loss -0.6585
2025-10-05 19:36:42.703097: val_loss -0.4151
2025-10-05 19:36:42.703281: Pseudo dice [np.float32(0.6674)]
2025-10-05 19:36:42.703439: Epoch time: 46.27 s
2025-10-05 19:36:42.703574: Yayy! New best EMA pseudo Dice: 0.6539000272750854
2025-10-05 19:36:43.817950: 
2025-10-05 19:36:43.818199: Epoch 42
2025-10-05 19:36:43.818402: Current learning rate: 0.00744
2025-10-05 19:37:30.705200: Validation loss did not improve from -0.43488. Patience: 8/50
2025-10-05 19:37:30.705869: train_loss -0.6572
2025-10-05 19:37:30.706064: val_loss -0.381
2025-10-05 19:37:30.706187: Pseudo dice [np.float32(0.6679)]
2025-10-05 19:37:30.706315: Epoch time: 46.89 s
2025-10-05 19:37:30.706443: Yayy! New best EMA pseudo Dice: 0.6553000211715698
2025-10-05 19:37:31.801935: 
2025-10-05 19:37:31.802279: Epoch 43
2025-10-05 19:37:31.802463: Current learning rate: 0.00738
2025-10-05 19:38:18.207480: Validation loss did not improve from -0.43488. Patience: 9/50
2025-10-05 19:38:18.207999: train_loss -0.6743
2025-10-05 19:38:18.208186: val_loss -0.4072
2025-10-05 19:38:18.208370: Pseudo dice [np.float32(0.6703)]
2025-10-05 19:38:18.208517: Epoch time: 46.41 s
2025-10-05 19:38:18.208627: Yayy! New best EMA pseudo Dice: 0.6567999720573425
2025-10-05 19:38:19.322547: 
2025-10-05 19:38:19.322908: Epoch 44
2025-10-05 19:38:19.323112: Current learning rate: 0.00732
2025-10-05 19:39:05.708787: Validation loss did not improve from -0.43488. Patience: 10/50
2025-10-05 19:39:05.709512: train_loss -0.6804
2025-10-05 19:39:05.709677: val_loss -0.4132
2025-10-05 19:39:05.709846: Pseudo dice [np.float32(0.6748)]
2025-10-05 19:39:05.710004: Epoch time: 46.39 s
2025-10-05 19:39:06.173839: Yayy! New best EMA pseudo Dice: 0.6585999727249146
2025-10-05 19:39:07.252716: 
2025-10-05 19:39:07.252993: Epoch 45
2025-10-05 19:39:07.253182: Current learning rate: 0.00725
2025-10-05 19:39:53.586332: Validation loss did not improve from -0.43488. Patience: 11/50
2025-10-05 19:39:53.586768: train_loss -0.6764
2025-10-05 19:39:53.586973: val_loss -0.3815
2025-10-05 19:39:53.587171: Pseudo dice [np.float32(0.6504)]
2025-10-05 19:39:53.587348: Epoch time: 46.33 s
2025-10-05 19:39:54.217639: 
2025-10-05 19:39:54.217917: Epoch 46
2025-10-05 19:39:54.218138: Current learning rate: 0.00719
2025-10-05 19:40:40.564078: Validation loss did not improve from -0.43488. Patience: 12/50
2025-10-05 19:40:40.564841: train_loss -0.6756
2025-10-05 19:40:40.565101: val_loss -0.4029
2025-10-05 19:40:40.565236: Pseudo dice [np.float32(0.6765)]
2025-10-05 19:40:40.565392: Epoch time: 46.35 s
2025-10-05 19:40:40.565544: Yayy! New best EMA pseudo Dice: 0.659600019454956
2025-10-05 19:40:41.678395: 
2025-10-05 19:40:41.678738: Epoch 47
2025-10-05 19:40:41.678966: Current learning rate: 0.00713
2025-10-05 19:41:28.013582: Validation loss did not improve from -0.43488. Patience: 13/50
2025-10-05 19:41:28.014097: train_loss -0.6781
2025-10-05 19:41:28.014279: val_loss -0.3691
2025-10-05 19:41:28.014432: Pseudo dice [np.float32(0.665)]
2025-10-05 19:41:28.014575: Epoch time: 46.34 s
2025-10-05 19:41:28.014747: Yayy! New best EMA pseudo Dice: 0.6601999998092651
2025-10-05 19:41:29.130172: 
2025-10-05 19:41:29.130539: Epoch 48
2025-10-05 19:41:29.130739: Current learning rate: 0.00707
2025-10-05 19:42:15.521317: Validation loss did not improve from -0.43488. Patience: 14/50
2025-10-05 19:42:15.522051: train_loss -0.6866
2025-10-05 19:42:15.522217: val_loss -0.4131
2025-10-05 19:42:15.522385: Pseudo dice [np.float32(0.6794)]
2025-10-05 19:42:15.522528: Epoch time: 46.39 s
2025-10-05 19:42:15.522660: Yayy! New best EMA pseudo Dice: 0.6621000170707703
2025-10-05 19:42:16.662326: 
2025-10-05 19:42:16.662609: Epoch 49
2025-10-05 19:42:16.662855: Current learning rate: 0.007
2025-10-05 19:43:03.098355: Validation loss did not improve from -0.43488. Patience: 15/50
2025-10-05 19:43:03.098906: train_loss -0.6881
2025-10-05 19:43:03.099277: val_loss -0.3937
2025-10-05 19:43:03.099519: Pseudo dice [np.float32(0.6663)]
2025-10-05 19:43:03.099687: Epoch time: 46.44 s
2025-10-05 19:43:03.550305: Yayy! New best EMA pseudo Dice: 0.6625000238418579
2025-10-05 19:43:04.658862: 
2025-10-05 19:43:04.659214: Epoch 50
2025-10-05 19:43:04.659426: Current learning rate: 0.00694
2025-10-05 19:43:51.000234: Validation loss did not improve from -0.43488. Patience: 16/50
2025-10-05 19:43:51.000881: train_loss -0.6846
2025-10-05 19:43:51.001039: val_loss -0.3825
2025-10-05 19:43:51.001171: Pseudo dice [np.float32(0.6592)]
2025-10-05 19:43:51.001323: Epoch time: 46.34 s
2025-10-05 19:43:51.648017: 
2025-10-05 19:43:51.648365: Epoch 51
2025-10-05 19:43:51.648567: Current learning rate: 0.00688
2025-10-05 19:44:37.973445: Validation loss did not improve from -0.43488. Patience: 17/50
2025-10-05 19:44:37.973992: train_loss -0.6967
2025-10-05 19:44:37.974178: val_loss -0.417
2025-10-05 19:44:37.974322: Pseudo dice [np.float32(0.6821)]
2025-10-05 19:44:37.974476: Epoch time: 46.33 s
2025-10-05 19:44:37.974599: Yayy! New best EMA pseudo Dice: 0.6642000079154968
2025-10-05 19:44:39.090491: 
2025-10-05 19:44:39.091109: Epoch 52
2025-10-05 19:44:39.091352: Current learning rate: 0.00682
2025-10-05 19:45:25.444541: Validation loss did not improve from -0.43488. Patience: 18/50
2025-10-05 19:45:25.445232: train_loss -0.7107
2025-10-05 19:45:25.445370: val_loss -0.4325
2025-10-05 19:45:25.445555: Pseudo dice [np.float32(0.6967)]
2025-10-05 19:45:25.445723: Epoch time: 46.36 s
2025-10-05 19:45:25.445848: Yayy! New best EMA pseudo Dice: 0.6674000024795532
2025-10-05 19:45:26.562031: 
2025-10-05 19:45:26.562360: Epoch 53
2025-10-05 19:45:26.562577: Current learning rate: 0.00675
2025-10-05 19:46:12.882420: Validation loss did not improve from -0.43488. Patience: 19/50
2025-10-05 19:46:12.882933: train_loss -0.7073
2025-10-05 19:46:12.883089: val_loss -0.3855
2025-10-05 19:46:12.883206: Pseudo dice [np.float32(0.6653)]
2025-10-05 19:46:12.883378: Epoch time: 46.32 s
2025-10-05 19:46:13.538252: 
2025-10-05 19:46:13.538628: Epoch 54
2025-10-05 19:46:13.538897: Current learning rate: 0.00669
2025-10-05 19:46:59.909511: Validation loss did not improve from -0.43488. Patience: 20/50
2025-10-05 19:46:59.910143: train_loss -0.7014
2025-10-05 19:46:59.910312: val_loss -0.3829
2025-10-05 19:46:59.910456: Pseudo dice [np.float32(0.6592)]
2025-10-05 19:46:59.910584: Epoch time: 46.37 s
2025-10-05 19:47:01.019475: 
2025-10-05 19:47:01.019779: Epoch 55
2025-10-05 19:47:01.020028: Current learning rate: 0.00663
2025-10-05 19:47:47.326076: Validation loss did not improve from -0.43488. Patience: 21/50
2025-10-05 19:47:47.326532: train_loss -0.7145
2025-10-05 19:47:47.326688: val_loss -0.3669
2025-10-05 19:47:47.326829: Pseudo dice [np.float32(0.654)]
2025-10-05 19:47:47.326970: Epoch time: 46.31 s
2025-10-05 19:47:47.970964: 
2025-10-05 19:47:47.971269: Epoch 56
2025-10-05 19:47:47.971484: Current learning rate: 0.00657
2025-10-05 19:48:34.351717: Validation loss did not improve from -0.43488. Patience: 22/50
2025-10-05 19:48:34.352524: train_loss -0.7083
2025-10-05 19:48:34.352827: val_loss -0.3859
2025-10-05 19:48:34.353069: Pseudo dice [np.float32(0.677)]
2025-10-05 19:48:34.353292: Epoch time: 46.38 s
2025-10-05 19:48:35.031453: 
2025-10-05 19:48:35.031797: Epoch 57
2025-10-05 19:48:35.031987: Current learning rate: 0.0065
2025-10-05 19:49:21.419410: Validation loss did not improve from -0.43488. Patience: 23/50
2025-10-05 19:49:21.419946: train_loss -0.7125
2025-10-05 19:49:21.420158: val_loss -0.4338
2025-10-05 19:49:21.420326: Pseudo dice [np.float32(0.6898)]
2025-10-05 19:49:21.420528: Epoch time: 46.39 s
2025-10-05 19:49:21.420681: Yayy! New best EMA pseudo Dice: 0.6686999797821045
2025-10-05 19:49:23.102522: 
2025-10-05 19:49:23.102952: Epoch 58
2025-10-05 19:49:23.103180: Current learning rate: 0.00644
2025-10-05 19:50:09.568555: Validation loss did not improve from -0.43488. Patience: 24/50
2025-10-05 19:50:09.569213: train_loss -0.7114
2025-10-05 19:50:09.569387: val_loss -0.4149
2025-10-05 19:50:09.569570: Pseudo dice [np.float32(0.6731)]
2025-10-05 19:50:09.569746: Epoch time: 46.47 s
2025-10-05 19:50:09.569913: Yayy! New best EMA pseudo Dice: 0.6690999865531921
2025-10-05 19:50:10.726693: 
2025-10-05 19:50:10.726968: Epoch 59
2025-10-05 19:50:10.727154: Current learning rate: 0.00638
2025-10-05 19:50:57.166361: Validation loss did not improve from -0.43488. Patience: 25/50
2025-10-05 19:50:57.166862: train_loss -0.7161
2025-10-05 19:50:57.167007: val_loss -0.38
2025-10-05 19:50:57.167116: Pseudo dice [np.float32(0.6728)]
2025-10-05 19:50:57.167274: Epoch time: 46.44 s
2025-10-05 19:50:57.660044: Yayy! New best EMA pseudo Dice: 0.6694999933242798
2025-10-05 19:50:58.789258: 
2025-10-05 19:50:58.789628: Epoch 60
2025-10-05 19:50:58.789910: Current learning rate: 0.00631
2025-10-05 19:51:45.247871: Validation loss did not improve from -0.43488. Patience: 26/50
2025-10-05 19:51:45.248554: train_loss -0.7178
2025-10-05 19:51:45.248708: val_loss -0.3986
2025-10-05 19:51:45.248834: Pseudo dice [np.float32(0.675)]
2025-10-05 19:51:45.248995: Epoch time: 46.46 s
2025-10-05 19:51:45.249161: Yayy! New best EMA pseudo Dice: 0.6700999736785889
2025-10-05 19:51:46.397355: 
2025-10-05 19:51:46.397661: Epoch 61
2025-10-05 19:51:46.397863: Current learning rate: 0.00625
2025-10-05 19:52:32.794853: Validation loss did not improve from -0.43488. Patience: 27/50
2025-10-05 19:52:32.795291: train_loss -0.73
2025-10-05 19:52:32.795454: val_loss -0.4009
2025-10-05 19:52:32.795646: Pseudo dice [np.float32(0.6782)]
2025-10-05 19:52:32.795791: Epoch time: 46.4 s
2025-10-05 19:52:32.795901: Yayy! New best EMA pseudo Dice: 0.6708999872207642
2025-10-05 19:52:33.900960: 
2025-10-05 19:52:33.901217: Epoch 62
2025-10-05 19:52:33.901396: Current learning rate: 0.00619
2025-10-05 19:53:20.292541: Validation loss improved from -0.43488 to -0.43832! Patience: 27/50
2025-10-05 19:53:20.293185: train_loss -0.7265
2025-10-05 19:53:20.293326: val_loss -0.4383
2025-10-05 19:53:20.293472: Pseudo dice [np.float32(0.6905)]
2025-10-05 19:53:20.293659: Epoch time: 46.39 s
2025-10-05 19:53:20.293795: Yayy! New best EMA pseudo Dice: 0.6728000044822693
2025-10-05 19:53:21.408448: 
2025-10-05 19:53:21.408720: Epoch 63
2025-10-05 19:53:21.408962: Current learning rate: 0.00612
2025-10-05 19:54:07.818251: Validation loss improved from -0.43832 to -0.45172! Patience: 0/50
2025-10-05 19:54:07.818743: train_loss -0.7395
2025-10-05 19:54:07.818900: val_loss -0.4517
2025-10-05 19:54:07.819050: Pseudo dice [np.float32(0.6964)]
2025-10-05 19:54:07.819209: Epoch time: 46.41 s
2025-10-05 19:54:07.819340: Yayy! New best EMA pseudo Dice: 0.6751999855041504
2025-10-05 19:54:08.924136: 
2025-10-05 19:54:08.924542: Epoch 64
2025-10-05 19:54:08.924803: Current learning rate: 0.00606
2025-10-05 19:54:55.298645: Validation loss did not improve from -0.45172. Patience: 1/50
2025-10-05 19:54:55.299341: train_loss -0.7298
2025-10-05 19:54:55.299487: val_loss -0.4178
2025-10-05 19:54:55.299637: Pseudo dice [np.float32(0.6764)]
2025-10-05 19:54:55.299781: Epoch time: 46.38 s
2025-10-05 19:54:55.752860: Yayy! New best EMA pseudo Dice: 0.6753000020980835
2025-10-05 19:54:56.840496: 
2025-10-05 19:54:56.840872: Epoch 65
2025-10-05 19:54:56.841077: Current learning rate: 0.006
2025-10-05 19:55:43.191954: Validation loss did not improve from -0.45172. Patience: 2/50
2025-10-05 19:55:43.192529: train_loss -0.7312
2025-10-05 19:55:43.192744: val_loss -0.3914
2025-10-05 19:55:43.192874: Pseudo dice [np.float32(0.6767)]
2025-10-05 19:55:43.193036: Epoch time: 46.35 s
2025-10-05 19:55:43.193148: Yayy! New best EMA pseudo Dice: 0.6754999756813049
2025-10-05 19:55:44.317509: 
2025-10-05 19:55:44.317927: Epoch 66
2025-10-05 19:55:44.318231: Current learning rate: 0.00593
2025-10-05 19:56:30.731241: Validation loss did not improve from -0.45172. Patience: 3/50
2025-10-05 19:56:30.732120: train_loss -0.7295
2025-10-05 19:56:30.732382: val_loss -0.3554
2025-10-05 19:56:30.732644: Pseudo dice [np.float32(0.6528)]
2025-10-05 19:56:30.732949: Epoch time: 46.42 s
2025-10-05 19:56:31.402436: 
2025-10-05 19:56:31.402936: Epoch 67
2025-10-05 19:56:31.403155: Current learning rate: 0.00587
2025-10-05 19:57:17.804931: Validation loss did not improve from -0.45172. Patience: 4/50
2025-10-05 19:57:17.805343: train_loss -0.7297
2025-10-05 19:57:17.805509: val_loss -0.4016
2025-10-05 19:57:17.805694: Pseudo dice [np.float32(0.6779)]
2025-10-05 19:57:17.805849: Epoch time: 46.4 s
2025-10-05 19:57:18.493467: 
2025-10-05 19:57:18.493829: Epoch 68
2025-10-05 19:57:18.494040: Current learning rate: 0.00581
2025-10-05 19:58:04.866620: Validation loss did not improve from -0.45172. Patience: 5/50
2025-10-05 19:58:04.867280: train_loss -0.7372
2025-10-05 19:58:04.867465: val_loss -0.409
2025-10-05 19:58:04.867689: Pseudo dice [np.float32(0.6787)]
2025-10-05 19:58:04.867840: Epoch time: 46.37 s
2025-10-05 19:58:05.525126: 
2025-10-05 19:58:05.525461: Epoch 69
2025-10-05 19:58:05.525730: Current learning rate: 0.00574
2025-10-05 19:58:51.857229: Validation loss did not improve from -0.45172. Patience: 6/50
2025-10-05 19:58:51.857746: train_loss -0.7386
2025-10-05 19:58:51.857927: val_loss -0.3744
2025-10-05 19:58:51.858055: Pseudo dice [np.float32(0.6706)]
2025-10-05 19:58:51.858193: Epoch time: 46.33 s
2025-10-05 19:58:52.983720: 
2025-10-05 19:58:52.984020: Epoch 70
2025-10-05 19:58:52.984226: Current learning rate: 0.00568
2025-10-05 19:59:39.273074: Validation loss did not improve from -0.45172. Patience: 7/50
2025-10-05 19:59:39.273716: train_loss -0.7498
2025-10-05 19:59:39.273884: val_loss -0.4083
2025-10-05 19:59:39.274015: Pseudo dice [np.float32(0.6721)]
2025-10-05 19:59:39.274164: Epoch time: 46.29 s
2025-10-05 19:59:39.925971: 
2025-10-05 19:59:39.926462: Epoch 71
2025-10-05 19:59:39.926642: Current learning rate: 0.00562
2025-10-05 20:00:26.253651: Validation loss did not improve from -0.45172. Patience: 8/50
2025-10-05 20:00:26.254091: train_loss -0.7487
2025-10-05 20:00:26.254270: val_loss -0.4121
2025-10-05 20:00:26.254415: Pseudo dice [np.float32(0.6737)]
2025-10-05 20:00:26.254602: Epoch time: 46.33 s
2025-10-05 20:00:26.907912: 
2025-10-05 20:00:26.908207: Epoch 72
2025-10-05 20:00:26.908428: Current learning rate: 0.00555
2025-10-05 20:01:13.172509: Validation loss did not improve from -0.45172. Patience: 9/50
2025-10-05 20:01:13.173188: train_loss -0.7588
2025-10-05 20:01:13.173329: val_loss -0.438
2025-10-05 20:01:13.173477: Pseudo dice [np.float32(0.6978)]
2025-10-05 20:01:13.173637: Epoch time: 46.27 s
2025-10-05 20:01:13.173763: Yayy! New best EMA pseudo Dice: 0.6761000156402588
2025-10-05 20:01:14.832587: 
2025-10-05 20:01:14.832955: Epoch 73
2025-10-05 20:01:14.833198: Current learning rate: 0.00549
2025-10-05 20:02:01.173597: Validation loss did not improve from -0.45172. Patience: 10/50
2025-10-05 20:02:01.174063: train_loss -0.7546
2025-10-05 20:02:01.174253: val_loss -0.3388
2025-10-05 20:02:01.174410: Pseudo dice [np.float32(0.6567)]
2025-10-05 20:02:01.174589: Epoch time: 46.34 s
2025-10-05 20:02:01.841958: 
2025-10-05 20:02:01.842296: Epoch 74
2025-10-05 20:02:01.842520: Current learning rate: 0.00542
2025-10-05 20:02:48.109304: Validation loss did not improve from -0.45172. Patience: 11/50
2025-10-05 20:02:48.110047: train_loss -0.7603
2025-10-05 20:02:48.110214: val_loss -0.4041
2025-10-05 20:02:48.110355: Pseudo dice [np.float32(0.6773)]
2025-10-05 20:02:48.110496: Epoch time: 46.27 s
2025-10-05 20:02:49.216342: 
2025-10-05 20:02:49.216879: Epoch 75
2025-10-05 20:02:49.217125: Current learning rate: 0.00536
2025-10-05 20:03:35.511668: Validation loss did not improve from -0.45172. Patience: 12/50
2025-10-05 20:03:35.512141: train_loss -0.7629
2025-10-05 20:03:35.512311: val_loss -0.3807
2025-10-05 20:03:35.512450: Pseudo dice [np.float32(0.6749)]
2025-10-05 20:03:35.512662: Epoch time: 46.3 s
2025-10-05 20:03:36.171548: 
2025-10-05 20:03:36.171855: Epoch 76
2025-10-05 20:03:36.172044: Current learning rate: 0.00529
2025-10-05 20:04:22.468716: Validation loss did not improve from -0.45172. Patience: 13/50
2025-10-05 20:04:22.469360: train_loss -0.7652
2025-10-05 20:04:22.469570: val_loss -0.3712
2025-10-05 20:04:22.469714: Pseudo dice [np.float32(0.6665)]
2025-10-05 20:04:22.469866: Epoch time: 46.3 s
2025-10-05 20:04:23.122247: 
2025-10-05 20:04:23.122558: Epoch 77
2025-10-05 20:04:23.122772: Current learning rate: 0.00523
2025-10-05 20:05:09.403950: Validation loss did not improve from -0.45172. Patience: 14/50
2025-10-05 20:05:09.404440: train_loss -0.7668
2025-10-05 20:05:09.404586: val_loss -0.4142
2025-10-05 20:05:09.404699: Pseudo dice [np.float32(0.6818)]
2025-10-05 20:05:09.404840: Epoch time: 46.28 s
2025-10-05 20:05:10.078335: 
2025-10-05 20:05:10.078652: Epoch 78
2025-10-05 20:05:10.078880: Current learning rate: 0.00517
2025-10-05 20:05:56.406826: Validation loss did not improve from -0.45172. Patience: 15/50
2025-10-05 20:05:56.407601: train_loss -0.7706
2025-10-05 20:05:56.407758: val_loss -0.3873
2025-10-05 20:05:56.407873: Pseudo dice [np.float32(0.6751)]
2025-10-05 20:05:56.408030: Epoch time: 46.33 s
2025-10-05 20:05:57.084468: 
2025-10-05 20:05:57.084775: Epoch 79
2025-10-05 20:05:57.084984: Current learning rate: 0.0051
2025-10-05 20:06:43.664006: Validation loss did not improve from -0.45172. Patience: 16/50
2025-10-05 20:06:43.664536: train_loss -0.7725
2025-10-05 20:06:43.664695: val_loss -0.3599
2025-10-05 20:06:43.664843: Pseudo dice [np.float32(0.6589)]
2025-10-05 20:06:43.665070: Epoch time: 46.58 s
2025-10-05 20:06:44.820529: 
2025-10-05 20:06:44.820858: Epoch 80
2025-10-05 20:06:44.821066: Current learning rate: 0.00504
2025-10-05 20:07:31.383380: Validation loss did not improve from -0.45172. Patience: 17/50
2025-10-05 20:07:31.384008: train_loss -0.7743
2025-10-05 20:07:31.384223: val_loss -0.4041
2025-10-05 20:07:31.384374: Pseudo dice [np.float32(0.6821)]
2025-10-05 20:07:31.384546: Epoch time: 46.56 s
2025-10-05 20:07:32.111541: 
2025-10-05 20:07:32.111831: Epoch 81
2025-10-05 20:07:32.112024: Current learning rate: 0.00497
2025-10-05 20:08:18.605243: Validation loss did not improve from -0.45172. Patience: 18/50
2025-10-05 20:08:18.605700: train_loss -0.7783
2025-10-05 20:08:18.605913: val_loss -0.4037
2025-10-05 20:08:18.606138: Pseudo dice [np.float32(0.6841)]
2025-10-05 20:08:18.606318: Epoch time: 46.49 s
2025-10-05 20:08:19.273941: 
2025-10-05 20:08:19.274305: Epoch 82
2025-10-05 20:08:19.274566: Current learning rate: 0.00491
2025-10-05 20:09:05.726963: Validation loss improved from -0.45172 to -0.45533! Patience: 18/50
2025-10-05 20:09:05.727649: train_loss -0.7736
2025-10-05 20:09:05.727847: val_loss -0.4553
2025-10-05 20:09:05.727991: Pseudo dice [np.float32(0.7066)]
2025-10-05 20:09:05.728176: Epoch time: 46.45 s
2025-10-05 20:09:05.728330: Yayy! New best EMA pseudo Dice: 0.6780999898910522
2025-10-05 20:09:06.833520: 
2025-10-05 20:09:06.833861: Epoch 83
2025-10-05 20:09:06.834090: Current learning rate: 0.00484
2025-10-05 20:09:53.182321: Validation loss did not improve from -0.45533. Patience: 1/50
2025-10-05 20:09:53.182863: train_loss -0.7739
2025-10-05 20:09:53.183009: val_loss -0.4108
2025-10-05 20:09:53.183134: Pseudo dice [np.float32(0.6792)]
2025-10-05 20:09:53.183264: Epoch time: 46.35 s
2025-10-05 20:09:53.183431: Yayy! New best EMA pseudo Dice: 0.6782000064849854
2025-10-05 20:09:54.275285: 
2025-10-05 20:09:54.275543: Epoch 84
2025-10-05 20:09:54.275731: Current learning rate: 0.00478
2025-10-05 20:10:40.637319: Validation loss did not improve from -0.45533. Patience: 2/50
2025-10-05 20:10:40.637973: train_loss -0.7769
2025-10-05 20:10:40.638164: val_loss -0.424
2025-10-05 20:10:40.638341: Pseudo dice [np.float32(0.6932)]
2025-10-05 20:10:40.638500: Epoch time: 46.36 s
2025-10-05 20:10:41.091330: Yayy! New best EMA pseudo Dice: 0.6797000169754028
2025-10-05 20:10:42.200125: 
2025-10-05 20:10:42.200484: Epoch 85
2025-10-05 20:10:42.200700: Current learning rate: 0.00471
2025-10-05 20:11:28.494946: Validation loss did not improve from -0.45533. Patience: 3/50
2025-10-05 20:11:28.495547: train_loss -0.7814
2025-10-05 20:11:28.495831: val_loss -0.3982
2025-10-05 20:11:28.495974: Pseudo dice [np.float32(0.6782)]
2025-10-05 20:11:28.496224: Epoch time: 46.3 s
2025-10-05 20:11:29.143001: 
2025-10-05 20:11:29.143260: Epoch 86
2025-10-05 20:11:29.143542: Current learning rate: 0.00465
2025-10-05 20:12:15.490389: Validation loss did not improve from -0.45533. Patience: 4/50
2025-10-05 20:12:15.491027: train_loss -0.7814
2025-10-05 20:12:15.491276: val_loss -0.4007
2025-10-05 20:12:15.491410: Pseudo dice [np.float32(0.6907)]
2025-10-05 20:12:15.491543: Epoch time: 46.35 s
2025-10-05 20:12:15.491658: Yayy! New best EMA pseudo Dice: 0.6807000041007996
2025-10-05 20:12:16.610780: 
2025-10-05 20:12:16.611109: Epoch 87
2025-10-05 20:12:16.611311: Current learning rate: 0.00458
2025-10-05 20:13:03.067235: Validation loss did not improve from -0.45533. Patience: 5/50
2025-10-05 20:13:03.067730: train_loss -0.7857
2025-10-05 20:13:03.067884: val_loss -0.3838
2025-10-05 20:13:03.067999: Pseudo dice [np.float32(0.6729)]
2025-10-05 20:13:03.068158: Epoch time: 46.46 s
2025-10-05 20:13:04.273587: 
2025-10-05 20:13:04.273909: Epoch 88
2025-10-05 20:13:04.274117: Current learning rate: 0.00452
2025-10-05 20:13:50.659093: Validation loss did not improve from -0.45533. Patience: 6/50
2025-10-05 20:13:50.659760: train_loss -0.7934
2025-10-05 20:13:50.659927: val_loss -0.3882
2025-10-05 20:13:50.660093: Pseudo dice [np.float32(0.6922)]
2025-10-05 20:13:50.660339: Epoch time: 46.39 s
2025-10-05 20:13:50.660461: Yayy! New best EMA pseudo Dice: 0.6811000108718872
2025-10-05 20:13:51.770451: 
2025-10-05 20:13:51.770841: Epoch 89
2025-10-05 20:13:51.771052: Current learning rate: 0.00445
2025-10-05 20:14:38.106057: Validation loss did not improve from -0.45533. Patience: 7/50
2025-10-05 20:14:38.106574: train_loss -0.7914
2025-10-05 20:14:38.106730: val_loss -0.3622
2025-10-05 20:14:38.106874: Pseudo dice [np.float32(0.6811)]
2025-10-05 20:14:38.107015: Epoch time: 46.34 s
2025-10-05 20:14:39.231409: 
2025-10-05 20:14:39.231816: Epoch 90
2025-10-05 20:14:39.232075: Current learning rate: 0.00438
2025-10-05 20:15:25.669196: Validation loss did not improve from -0.45533. Patience: 8/50
2025-10-05 20:15:25.669825: train_loss -0.786
2025-10-05 20:15:25.669993: val_loss -0.3886
2025-10-05 20:15:25.670123: Pseudo dice [np.float32(0.6831)]
2025-10-05 20:15:25.670292: Epoch time: 46.44 s
2025-10-05 20:15:25.670433: Yayy! New best EMA pseudo Dice: 0.6812999844551086
2025-10-05 20:15:26.861025: 
2025-10-05 20:15:26.861329: Epoch 91
2025-10-05 20:15:26.861529: Current learning rate: 0.00432
2025-10-05 20:16:13.197584: Validation loss did not improve from -0.45533. Patience: 9/50
2025-10-05 20:16:13.198085: train_loss -0.7884
2025-10-05 20:16:13.198265: val_loss -0.3923
2025-10-05 20:16:13.198613: Pseudo dice [np.float32(0.6798)]
2025-10-05 20:16:13.198780: Epoch time: 46.34 s
2025-10-05 20:16:13.841923: 
2025-10-05 20:16:13.842287: Epoch 92
2025-10-05 20:16:13.842494: Current learning rate: 0.00425
2025-10-05 20:17:00.343762: Validation loss did not improve from -0.45533. Patience: 10/50
2025-10-05 20:17:00.344474: train_loss -0.7948
2025-10-05 20:17:00.344774: val_loss -0.4141
2025-10-05 20:17:00.345084: Pseudo dice [np.float32(0.6867)]
2025-10-05 20:17:00.345363: Epoch time: 46.5 s
2025-10-05 20:17:00.345557: Yayy! New best EMA pseudo Dice: 0.6816999912261963
2025-10-05 20:17:01.461514: 
2025-10-05 20:17:01.461827: Epoch 93
2025-10-05 20:17:01.462080: Current learning rate: 0.00419
2025-10-05 20:17:47.879055: Validation loss did not improve from -0.45533. Patience: 11/50
2025-10-05 20:17:47.879534: train_loss -0.7963
2025-10-05 20:17:47.879686: val_loss -0.4114
2025-10-05 20:17:47.879881: Pseudo dice [np.float32(0.6862)]
2025-10-05 20:17:47.880017: Epoch time: 46.42 s
2025-10-05 20:17:47.880139: Yayy! New best EMA pseudo Dice: 0.682200014591217
2025-10-05 20:17:49.043674: 
2025-10-05 20:17:49.044012: Epoch 94
2025-10-05 20:17:49.044245: Current learning rate: 0.00412
2025-10-05 20:18:35.575540: Validation loss did not improve from -0.45533. Patience: 12/50
2025-10-05 20:18:35.576230: train_loss -0.7951
2025-10-05 20:18:35.576412: val_loss -0.3695
2025-10-05 20:18:35.576549: Pseudo dice [np.float32(0.6765)]
2025-10-05 20:18:35.576695: Epoch time: 46.53 s
2025-10-05 20:18:36.686523: 
2025-10-05 20:18:36.686843: Epoch 95
2025-10-05 20:18:36.687031: Current learning rate: 0.00405
2025-10-05 20:19:23.092076: Validation loss did not improve from -0.45533. Patience: 13/50
2025-10-05 20:19:23.092609: train_loss -0.7992
2025-10-05 20:19:23.092779: val_loss -0.416
2025-10-05 20:19:23.092942: Pseudo dice [np.float32(0.6858)]
2025-10-05 20:19:23.093093: Epoch time: 46.41 s
2025-10-05 20:19:23.743469: 
2025-10-05 20:19:23.743768: Epoch 96
2025-10-05 20:19:23.743951: Current learning rate: 0.00399
2025-10-05 20:20:10.207323: Validation loss did not improve from -0.45533. Patience: 14/50
2025-10-05 20:20:10.207961: train_loss -0.7911
2025-10-05 20:20:10.208116: val_loss -0.3873
2025-10-05 20:20:10.208329: Pseudo dice [np.float32(0.6891)]
2025-10-05 20:20:10.208503: Epoch time: 46.47 s
2025-10-05 20:20:10.208615: Yayy! New best EMA pseudo Dice: 0.682699978351593
2025-10-05 20:20:11.339859: 
2025-10-05 20:20:11.340145: Epoch 97
2025-10-05 20:20:11.340368: Current learning rate: 0.00392
2025-10-05 20:20:57.745053: Validation loss did not improve from -0.45533. Patience: 15/50
2025-10-05 20:20:57.745557: train_loss -0.8028
2025-10-05 20:20:57.745701: val_loss -0.3895
2025-10-05 20:20:57.745825: Pseudo dice [np.float32(0.6798)]
2025-10-05 20:20:57.745979: Epoch time: 46.41 s
2025-10-05 20:20:58.405202: 
2025-10-05 20:20:58.405441: Epoch 98
2025-10-05 20:20:58.405618: Current learning rate: 0.00385
2025-10-05 20:21:44.996981: Validation loss did not improve from -0.45533. Patience: 16/50
2025-10-05 20:21:44.997613: train_loss -0.8013
2025-10-05 20:21:44.997763: val_loss -0.3828
2025-10-05 20:21:44.997950: Pseudo dice [np.float32(0.6766)]
2025-10-05 20:21:44.998079: Epoch time: 46.59 s
2025-10-05 20:21:45.649678: 
2025-10-05 20:21:45.650040: Epoch 99
2025-10-05 20:21:45.650270: Current learning rate: 0.00379
2025-10-05 20:22:32.157551: Validation loss did not improve from -0.45533. Patience: 17/50
2025-10-05 20:22:32.158058: train_loss -0.8076
2025-10-05 20:22:32.158248: val_loss -0.3737
2025-10-05 20:22:32.158418: Pseudo dice [np.float32(0.6737)]
2025-10-05 20:22:32.158589: Epoch time: 46.51 s
2025-10-05 20:22:33.284280: 
2025-10-05 20:22:33.284542: Epoch 100
2025-10-05 20:22:33.284770: Current learning rate: 0.00372
2025-10-05 20:23:19.652101: Validation loss did not improve from -0.45533. Patience: 18/50
2025-10-05 20:23:19.652764: train_loss -0.8138
2025-10-05 20:23:19.652960: val_loss -0.3631
2025-10-05 20:23:19.653135: Pseudo dice [np.float32(0.682)]
2025-10-05 20:23:19.653301: Epoch time: 46.37 s
2025-10-05 20:23:20.307447: 
2025-10-05 20:23:20.307761: Epoch 101
2025-10-05 20:23:20.307942: Current learning rate: 0.00365
2025-10-05 20:24:06.721105: Validation loss did not improve from -0.45533. Patience: 19/50
2025-10-05 20:24:06.721641: train_loss -0.8155
2025-10-05 20:24:06.721832: val_loss -0.3843
2025-10-05 20:24:06.722002: Pseudo dice [np.float32(0.683)]
2025-10-05 20:24:06.722139: Epoch time: 46.41 s
2025-10-05 20:24:07.369450: 
2025-10-05 20:24:07.369690: Epoch 102
2025-10-05 20:24:07.369899: Current learning rate: 0.00359
2025-10-05 20:24:53.700848: Validation loss did not improve from -0.45533. Patience: 20/50
2025-10-05 20:24:53.701495: train_loss -0.8118
2025-10-05 20:24:53.701698: val_loss -0.3706
2025-10-05 20:24:53.701856: Pseudo dice [np.float32(0.6761)]
2025-10-05 20:24:53.702034: Epoch time: 46.33 s
2025-10-05 20:24:54.351886: 
2025-10-05 20:24:54.352262: Epoch 103
2025-10-05 20:24:54.352477: Current learning rate: 0.00352
2025-10-05 20:25:40.746060: Validation loss did not improve from -0.45533. Patience: 21/50
2025-10-05 20:25:40.746471: train_loss -0.811
2025-10-05 20:25:40.746668: val_loss -0.3735
2025-10-05 20:25:40.746861: Pseudo dice [np.float32(0.6847)]
2025-10-05 20:25:40.747045: Epoch time: 46.4 s
2025-10-05 20:25:41.971318: 
2025-10-05 20:25:41.971609: Epoch 104
2025-10-05 20:25:41.971878: Current learning rate: 0.00345
2025-10-05 20:26:28.277383: Validation loss did not improve from -0.45533. Patience: 22/50
2025-10-05 20:26:28.278059: train_loss -0.8127
2025-10-05 20:26:28.278388: val_loss -0.4233
2025-10-05 20:26:28.278548: Pseudo dice [np.float32(0.7025)]
2025-10-05 20:26:28.278721: Epoch time: 46.31 s
2025-10-05 20:26:28.738465: Yayy! New best EMA pseudo Dice: 0.6833000183105469
2025-10-05 20:26:29.842937: 
2025-10-05 20:26:29.843305: Epoch 105
2025-10-05 20:26:29.843489: Current learning rate: 0.00338
2025-10-05 20:27:16.369170: Validation loss did not improve from -0.45533. Patience: 23/50
2025-10-05 20:27:16.369715: train_loss -0.8141
2025-10-05 20:27:16.369918: val_loss -0.3783
2025-10-05 20:27:16.370146: Pseudo dice [np.float32(0.677)]
2025-10-05 20:27:16.370409: Epoch time: 46.53 s
2025-10-05 20:27:17.039514: 
2025-10-05 20:27:17.039835: Epoch 106
2025-10-05 20:27:17.040074: Current learning rate: 0.00332
2025-10-05 20:28:03.540028: Validation loss did not improve from -0.45533. Patience: 24/50
2025-10-05 20:28:03.540743: train_loss -0.8132
2025-10-05 20:28:03.540916: val_loss -0.3892
2025-10-05 20:28:03.541055: Pseudo dice [np.float32(0.6835)]
2025-10-05 20:28:03.541186: Epoch time: 46.5 s
2025-10-05 20:28:04.204354: 
2025-10-05 20:28:04.204701: Epoch 107
2025-10-05 20:28:04.204971: Current learning rate: 0.00325
2025-10-05 20:28:50.520122: Validation loss did not improve from -0.45533. Patience: 25/50
2025-10-05 20:28:50.520622: train_loss -0.8192
2025-10-05 20:28:50.520809: val_loss -0.4101
2025-10-05 20:28:50.520922: Pseudo dice [np.float32(0.696)]
2025-10-05 20:28:50.521052: Epoch time: 46.32 s
2025-10-05 20:28:50.521166: Yayy! New best EMA pseudo Dice: 0.6840999722480774
2025-10-05 20:28:51.631986: 
2025-10-05 20:28:51.632325: Epoch 108
2025-10-05 20:28:51.632572: Current learning rate: 0.00318
2025-10-05 20:29:37.949311: Validation loss did not improve from -0.45533. Patience: 26/50
2025-10-05 20:29:37.949988: train_loss -0.8203
2025-10-05 20:29:37.950177: val_loss -0.4137
2025-10-05 20:29:37.950371: Pseudo dice [np.float32(0.6935)]
2025-10-05 20:29:37.950575: Epoch time: 46.32 s
2025-10-05 20:29:37.950707: Yayy! New best EMA pseudo Dice: 0.6850000023841858
2025-10-05 20:29:39.044796: 
2025-10-05 20:29:39.045180: Epoch 109
2025-10-05 20:29:39.045396: Current learning rate: 0.00311
2025-10-05 20:30:25.392872: Validation loss did not improve from -0.45533. Patience: 27/50
2025-10-05 20:30:25.393301: train_loss -0.8252
2025-10-05 20:30:25.393473: val_loss -0.4462
2025-10-05 20:30:25.393609: Pseudo dice [np.float32(0.7069)]
2025-10-05 20:30:25.393763: Epoch time: 46.35 s
2025-10-05 20:30:25.847810: Yayy! New best EMA pseudo Dice: 0.6872000098228455
2025-10-05 20:30:26.966101: 
2025-10-05 20:30:26.966547: Epoch 110
2025-10-05 20:30:26.966841: Current learning rate: 0.00304
2025-10-05 20:31:13.359616: Validation loss did not improve from -0.45533. Patience: 28/50
2025-10-05 20:31:13.360219: train_loss -0.8212
2025-10-05 20:31:13.360388: val_loss -0.3988
2025-10-05 20:31:13.360530: Pseudo dice [np.float32(0.6896)]
2025-10-05 20:31:13.360715: Epoch time: 46.39 s
2025-10-05 20:31:13.360866: Yayy! New best EMA pseudo Dice: 0.6873999834060669
2025-10-05 20:31:14.507654: 
2025-10-05 20:31:14.507992: Epoch 111
2025-10-05 20:31:14.508232: Current learning rate: 0.00297
2025-10-05 20:32:00.898168: Validation loss did not improve from -0.45533. Patience: 29/50
2025-10-05 20:32:00.898592: train_loss -0.8238
2025-10-05 20:32:00.898789: val_loss -0.3795
2025-10-05 20:32:00.898954: Pseudo dice [np.float32(0.682)]
2025-10-05 20:32:00.899113: Epoch time: 46.39 s
2025-10-05 20:32:01.556653: 
2025-10-05 20:32:01.556981: Epoch 112
2025-10-05 20:32:01.557277: Current learning rate: 0.00291
2025-10-05 20:32:47.905186: Validation loss did not improve from -0.45533. Patience: 30/50
2025-10-05 20:32:47.905796: train_loss -0.8261
2025-10-05 20:32:47.905945: val_loss -0.3701
2025-10-05 20:32:47.906082: Pseudo dice [np.float32(0.6766)]
2025-10-05 20:32:47.906207: Epoch time: 46.35 s
2025-10-05 20:32:48.564064: 
2025-10-05 20:32:48.564308: Epoch 113
2025-10-05 20:32:48.564492: Current learning rate: 0.00284
2025-10-05 20:33:34.964073: Validation loss did not improve from -0.45533. Patience: 31/50
2025-10-05 20:33:34.964560: train_loss -0.8298
2025-10-05 20:33:34.964724: val_loss -0.3765
2025-10-05 20:33:34.964844: Pseudo dice [np.float32(0.6775)]
2025-10-05 20:33:34.964983: Epoch time: 46.4 s
2025-10-05 20:33:35.625455: 
2025-10-05 20:33:35.625710: Epoch 114
2025-10-05 20:33:35.625903: Current learning rate: 0.00277
2025-10-05 20:34:22.061405: Validation loss did not improve from -0.45533. Patience: 32/50
2025-10-05 20:34:22.062138: train_loss -0.8294
2025-10-05 20:34:22.062294: val_loss -0.4263
2025-10-05 20:34:22.062425: Pseudo dice [np.float32(0.6989)]
2025-10-05 20:34:22.062571: Epoch time: 46.44 s
2025-10-05 20:34:23.189461: 
2025-10-05 20:34:23.189828: Epoch 115
2025-10-05 20:34:23.190010: Current learning rate: 0.0027
2025-10-05 20:35:09.680828: Validation loss did not improve from -0.45533. Patience: 33/50
2025-10-05 20:35:09.681276: train_loss -0.8309
2025-10-05 20:35:09.681468: val_loss -0.3513
2025-10-05 20:35:09.681611: Pseudo dice [np.float32(0.6819)]
2025-10-05 20:35:09.681775: Epoch time: 46.49 s
2025-10-05 20:35:10.346258: 
2025-10-05 20:35:10.346671: Epoch 116
2025-10-05 20:35:10.346936: Current learning rate: 0.00263
2025-10-05 20:35:56.774141: Validation loss did not improve from -0.45533. Patience: 34/50
2025-10-05 20:35:56.774824: train_loss -0.8282
2025-10-05 20:35:56.774961: val_loss -0.3553
2025-10-05 20:35:56.775207: Pseudo dice [np.float32(0.6832)]
2025-10-05 20:35:56.775396: Epoch time: 46.43 s
2025-10-05 20:35:57.435242: 
2025-10-05 20:35:57.435535: Epoch 117
2025-10-05 20:35:57.435776: Current learning rate: 0.00256
2025-10-05 20:36:43.835348: Validation loss did not improve from -0.45533. Patience: 35/50
2025-10-05 20:36:43.835864: train_loss -0.8319
2025-10-05 20:36:43.836049: val_loss -0.3522
2025-10-05 20:36:43.836200: Pseudo dice [np.float32(0.6762)]
2025-10-05 20:36:43.836371: Epoch time: 46.4 s
2025-10-05 20:36:44.499413: 
2025-10-05 20:36:44.499794: Epoch 118
2025-10-05 20:36:44.500022: Current learning rate: 0.00249
2025-10-05 20:37:30.794375: Validation loss did not improve from -0.45533. Patience: 36/50
2025-10-05 20:37:30.795096: train_loss -0.8377
2025-10-05 20:37:30.795251: val_loss -0.375
2025-10-05 20:37:30.795571: Pseudo dice [np.float32(0.6856)]
2025-10-05 20:37:30.795720: Epoch time: 46.3 s
2025-10-05 20:37:32.024658: 
2025-10-05 20:37:32.025041: Epoch 119
2025-10-05 20:37:32.025337: Current learning rate: 0.00242
2025-10-05 20:38:18.339965: Validation loss did not improve from -0.45533. Patience: 37/50
2025-10-05 20:38:18.340463: train_loss -0.8367
2025-10-05 20:38:18.340659: val_loss -0.3677
2025-10-05 20:38:18.340816: Pseudo dice [np.float32(0.6819)]
2025-10-05 20:38:18.340978: Epoch time: 46.32 s
2025-10-05 20:38:19.445528: 
2025-10-05 20:38:19.445878: Epoch 120
2025-10-05 20:38:19.446142: Current learning rate: 0.00235
2025-10-05 20:39:05.813431: Validation loss did not improve from -0.45533. Patience: 38/50
2025-10-05 20:39:05.814086: train_loss -0.8355
2025-10-05 20:39:05.814269: val_loss -0.3912
2025-10-05 20:39:05.814417: Pseudo dice [np.float32(0.6838)]
2025-10-05 20:39:05.814579: Epoch time: 46.37 s
2025-10-05 20:39:06.479755: 
2025-10-05 20:39:06.480018: Epoch 121
2025-10-05 20:39:06.480203: Current learning rate: 0.00228
2025-10-05 20:39:52.803888: Validation loss did not improve from -0.45533. Patience: 39/50
2025-10-05 20:39:52.804411: train_loss -0.8382
2025-10-05 20:39:52.804574: val_loss -0.395
2025-10-05 20:39:52.804698: Pseudo dice [np.float32(0.6912)]
2025-10-05 20:39:52.804847: Epoch time: 46.33 s
2025-10-05 20:39:53.479403: 
2025-10-05 20:39:53.479679: Epoch 122
2025-10-05 20:39:53.479886: Current learning rate: 0.00221
2025-10-05 20:40:39.781186: Validation loss did not improve from -0.45533. Patience: 40/50
2025-10-05 20:40:39.782062: train_loss -0.8379
2025-10-05 20:40:39.782361: val_loss -0.388
2025-10-05 20:40:39.782607: Pseudo dice [np.float32(0.6805)]
2025-10-05 20:40:39.782856: Epoch time: 46.3 s
2025-10-05 20:40:40.462827: 
2025-10-05 20:40:40.463148: Epoch 123
2025-10-05 20:40:40.463331: Current learning rate: 0.00214
2025-10-05 20:41:26.733917: Validation loss did not improve from -0.45533. Patience: 41/50
2025-10-05 20:41:26.734394: train_loss -0.8363
2025-10-05 20:41:26.734596: val_loss -0.4107
2025-10-05 20:41:26.734744: Pseudo dice [np.float32(0.7057)]
2025-10-05 20:41:26.734945: Epoch time: 46.27 s
2025-10-05 20:41:27.409424: 
2025-10-05 20:41:27.409673: Epoch 124
2025-10-05 20:41:27.409873: Current learning rate: 0.00207
2025-10-05 20:42:13.681707: Validation loss did not improve from -0.45533. Patience: 42/50
2025-10-05 20:42:13.682587: train_loss -0.8424
2025-10-05 20:42:13.682779: val_loss -0.3741
2025-10-05 20:42:13.682950: Pseudo dice [np.float32(0.6905)]
2025-10-05 20:42:13.683169: Epoch time: 46.27 s
2025-10-05 20:42:14.893272: 
2025-10-05 20:42:14.893611: Epoch 125
2025-10-05 20:42:14.893824: Current learning rate: 0.00199
2025-10-05 20:43:01.342243: Validation loss did not improve from -0.45533. Patience: 43/50
2025-10-05 20:43:01.342832: train_loss -0.8429
2025-10-05 20:43:01.343065: val_loss -0.368
2025-10-05 20:43:01.343204: Pseudo dice [np.float32(0.6914)]
2025-10-05 20:43:01.343405: Epoch time: 46.45 s
2025-10-05 20:43:01.343619: Yayy! New best EMA pseudo Dice: 0.6876000165939331
2025-10-05 20:43:02.475710: 
2025-10-05 20:43:02.475986: Epoch 126
2025-10-05 20:43:02.476173: Current learning rate: 0.00192
2025-10-05 20:43:48.936011: Validation loss did not improve from -0.45533. Patience: 44/50
2025-10-05 20:43:48.936648: train_loss -0.8426
2025-10-05 20:43:48.936859: val_loss -0.365
2025-10-05 20:43:48.937016: Pseudo dice [np.float32(0.6769)]
2025-10-05 20:43:48.937204: Epoch time: 46.46 s
2025-10-05 20:43:49.609045: 
2025-10-05 20:43:49.609310: Epoch 127
2025-10-05 20:43:49.609537: Current learning rate: 0.00185
2025-10-05 20:44:35.966486: Validation loss did not improve from -0.45533. Patience: 45/50
2025-10-05 20:44:35.967020: train_loss -0.8419
2025-10-05 20:44:35.967247: val_loss -0.4061
2025-10-05 20:44:35.967446: Pseudo dice [np.float32(0.7036)]
2025-10-05 20:44:35.967664: Epoch time: 46.36 s
2025-10-05 20:44:35.967868: Yayy! New best EMA pseudo Dice: 0.6881999969482422
2025-10-05 20:44:37.091494: 
2025-10-05 20:44:37.091852: Epoch 128
2025-10-05 20:44:37.092067: Current learning rate: 0.00178
2025-10-05 20:45:23.333148: Validation loss did not improve from -0.45533. Patience: 46/50
2025-10-05 20:45:23.333802: train_loss -0.8451
2025-10-05 20:45:23.333997: val_loss -0.3431
2025-10-05 20:45:23.334124: Pseudo dice [np.float32(0.6796)]
2025-10-05 20:45:23.334263: Epoch time: 46.24 s
2025-10-05 20:45:23.990346: 
2025-10-05 20:45:23.990743: Epoch 129
2025-10-05 20:45:23.991012: Current learning rate: 0.0017
2025-10-05 20:46:10.339785: Validation loss did not improve from -0.45533. Patience: 47/50
2025-10-05 20:46:10.340359: train_loss -0.8438
2025-10-05 20:46:10.340642: val_loss -0.3981
2025-10-05 20:46:10.340857: Pseudo dice [np.float32(0.6931)]
2025-10-05 20:46:10.341095: Epoch time: 46.35 s
2025-10-05 20:46:11.455606: 
2025-10-05 20:46:11.455899: Epoch 130
2025-10-05 20:46:11.456113: Current learning rate: 0.00163
2025-10-05 20:46:57.829504: Validation loss did not improve from -0.45533. Patience: 48/50
2025-10-05 20:46:57.830050: train_loss -0.842
2025-10-05 20:46:57.830227: val_loss -0.3978
2025-10-05 20:46:57.830370: Pseudo dice [np.float32(0.6991)]
2025-10-05 20:46:57.830538: Epoch time: 46.38 s
2025-10-05 20:46:57.830666: Yayy! New best EMA pseudo Dice: 0.6890000104904175
2025-10-05 20:46:58.956556: 
2025-10-05 20:46:58.956918: Epoch 131
2025-10-05 20:46:58.957216: Current learning rate: 0.00156
2025-10-05 20:47:45.301347: Validation loss did not improve from -0.45533. Patience: 49/50
2025-10-05 20:47:45.301769: train_loss -0.8454
2025-10-05 20:47:45.301910: val_loss -0.4024
2025-10-05 20:47:45.302056: Pseudo dice [np.float32(0.7078)]
2025-10-05 20:47:45.302200: Epoch time: 46.35 s
2025-10-05 20:47:45.302340: Yayy! New best EMA pseudo Dice: 0.6909000277519226
2025-10-05 20:47:46.433995: 
2025-10-05 20:47:46.434408: Epoch 132
2025-10-05 20:47:46.434608: Current learning rate: 0.00148
2025-10-05 20:48:32.790747: Validation loss did not improve from -0.45533. Patience: 50/50
2025-10-05 20:48:32.791558: train_loss -0.847
2025-10-05 20:48:32.791723: val_loss -0.3839
2025-10-05 20:48:32.791839: Pseudo dice [np.float32(0.6986)]
2025-10-05 20:48:32.791969: Epoch time: 46.36 s
2025-10-05 20:48:32.792114: Yayy! New best EMA pseudo Dice: 0.6916999816894531
2025-10-05 20:48:33.916040: 
2025-10-05 20:48:33.916308: Epoch 133
2025-10-05 20:48:33.916515: Current learning rate: 0.00141
2025-10-05 20:49:20.187426: Validation loss did not improve from -0.45533. Patience: 51/50
2025-10-05 20:49:20.187874: train_loss -0.8471
2025-10-05 20:49:20.188049: val_loss -0.392
2025-10-05 20:49:20.188266: Pseudo dice [np.float32(0.7026)]
2025-10-05 20:49:20.188423: Epoch time: 46.27 s
2025-10-05 20:49:20.188555: Yayy! New best EMA pseudo Dice: 0.692799985408783
2025-10-05 20:49:21.862525: 
2025-10-05 20:49:21.862895: Epoch 134
2025-10-05 20:49:21.863105: Current learning rate: 0.00133
2025-10-05 20:50:08.065478: Validation loss did not improve from -0.45533. Patience: 52/50
2025-10-05 20:50:08.066116: train_loss -0.8517
2025-10-05 20:50:08.066314: val_loss -0.3517
2025-10-05 20:50:08.066454: Pseudo dice [np.float32(0.6979)]
2025-10-05 20:50:08.066586: Epoch time: 46.2 s
2025-10-05 20:50:08.514569: Yayy! New best EMA pseudo Dice: 0.6933000087738037
2025-10-05 20:50:09.630121: 
2025-10-05 20:50:09.630478: Epoch 135
2025-10-05 20:50:09.630796: Current learning rate: 0.00126
2025-10-05 20:50:55.866700: Validation loss did not improve from -0.45533. Patience: 53/50
2025-10-05 20:50:55.867126: train_loss -0.8498
2025-10-05 20:50:55.867363: val_loss -0.4101
2025-10-05 20:50:55.867515: Pseudo dice [np.float32(0.6933)]
2025-10-05 20:50:55.867675: Epoch time: 46.24 s
2025-10-05 20:50:55.867800: Yayy! New best EMA pseudo Dice: 0.6933000087738037
2025-10-05 20:50:57.006955: 
2025-10-05 20:50:57.007349: Epoch 136
2025-10-05 20:50:57.007621: Current learning rate: 0.00118
2025-10-05 20:51:43.395836: Validation loss did not improve from -0.45533. Patience: 54/50
2025-10-05 20:51:43.396511: train_loss -0.853
2025-10-05 20:51:43.396655: val_loss -0.4032
2025-10-05 20:51:43.396773: Pseudo dice [np.float32(0.7033)]
2025-10-05 20:51:43.396958: Epoch time: 46.39 s
2025-10-05 20:51:43.397101: Yayy! New best EMA pseudo Dice: 0.6942999958992004
2025-10-05 20:51:44.542448: 
2025-10-05 20:51:44.542867: Epoch 137
2025-10-05 20:51:44.543150: Current learning rate: 0.00111
2025-10-05 20:52:30.780028: Validation loss did not improve from -0.45533. Patience: 55/50
2025-10-05 20:52:30.780722: train_loss -0.8549
2025-10-05 20:52:30.781095: val_loss -0.3615
2025-10-05 20:52:30.781301: Pseudo dice [np.float32(0.6814)]
2025-10-05 20:52:30.781541: Epoch time: 46.24 s
2025-10-05 20:52:31.448975: 
2025-10-05 20:52:31.449302: Epoch 138
2025-10-05 20:52:31.449502: Current learning rate: 0.00103
2025-10-05 20:53:17.589245: Validation loss did not improve from -0.45533. Patience: 56/50
2025-10-05 20:53:17.589966: train_loss -0.8577
2025-10-05 20:53:17.590276: val_loss -0.3724
2025-10-05 20:53:17.590526: Pseudo dice [np.float32(0.6844)]
2025-10-05 20:53:17.590831: Epoch time: 46.14 s
2025-10-05 20:53:18.258873: 
2025-10-05 20:53:18.259219: Epoch 139
2025-10-05 20:53:18.259489: Current learning rate: 0.00095
2025-10-05 20:54:04.351168: Validation loss did not improve from -0.45533. Patience: 57/50
2025-10-05 20:54:04.351695: train_loss -0.8527
2025-10-05 20:54:04.351860: val_loss -0.3614
2025-10-05 20:54:04.352055: Pseudo dice [np.float32(0.6916)]
2025-10-05 20:54:04.352214: Epoch time: 46.09 s
2025-10-05 20:54:05.455851: 
2025-10-05 20:54:05.456120: Epoch 140
2025-10-05 20:54:05.456300: Current learning rate: 0.00087
2025-10-05 20:54:51.648306: Validation loss did not improve from -0.45533. Patience: 58/50
2025-10-05 20:54:51.649019: train_loss -0.8553
2025-10-05 20:54:51.649202: val_loss -0.3664
2025-10-05 20:54:51.649335: Pseudo dice [np.float32(0.6861)]
2025-10-05 20:54:51.649496: Epoch time: 46.19 s
2025-10-05 20:54:52.327787: 
2025-10-05 20:54:52.328046: Epoch 141
2025-10-05 20:54:52.328228: Current learning rate: 0.00079
2025-10-05 20:55:38.597018: Validation loss did not improve from -0.45533. Patience: 59/50
2025-10-05 20:55:38.597524: train_loss -0.8563
2025-10-05 20:55:38.597714: val_loss -0.3977
2025-10-05 20:55:38.597851: Pseudo dice [np.float32(0.6958)]
2025-10-05 20:55:38.598023: Epoch time: 46.27 s
2025-10-05 20:55:39.262213: 
2025-10-05 20:55:39.262453: Epoch 142
2025-10-05 20:55:39.262633: Current learning rate: 0.00071
2025-10-05 20:56:25.492643: Validation loss did not improve from -0.45533. Patience: 60/50
2025-10-05 20:56:25.493278: train_loss -0.8572
2025-10-05 20:56:25.493446: val_loss -0.3918
2025-10-05 20:56:25.493608: Pseudo dice [np.float32(0.6936)]
2025-10-05 20:56:25.493747: Epoch time: 46.23 s
2025-10-05 20:56:26.158906: 
2025-10-05 20:56:26.159162: Epoch 143
2025-10-05 20:56:26.159339: Current learning rate: 0.00063
2025-10-05 20:57:12.331949: Validation loss did not improve from -0.45533. Patience: 61/50
2025-10-05 20:57:12.332396: train_loss -0.8556
2025-10-05 20:57:12.332531: val_loss -0.3682
2025-10-05 20:57:12.332653: Pseudo dice [np.float32(0.6909)]
2025-10-05 20:57:12.332795: Epoch time: 46.17 s
2025-10-05 20:57:12.990072: 
2025-10-05 20:57:12.990344: Epoch 144
2025-10-05 20:57:12.990530: Current learning rate: 0.00055
2025-10-05 20:57:59.067168: Validation loss did not improve from -0.45533. Patience: 62/50
2025-10-05 20:57:59.068051: train_loss -0.8576
2025-10-05 20:57:59.068285: val_loss -0.3542
2025-10-05 20:57:59.068476: Pseudo dice [np.float32(0.6793)]
2025-10-05 20:57:59.068710: Epoch time: 46.08 s
2025-10-05 20:58:00.167305: 
2025-10-05 20:58:00.167600: Epoch 145
2025-10-05 20:58:00.167871: Current learning rate: 0.00047
2025-10-05 20:58:46.375967: Validation loss did not improve from -0.45533. Patience: 63/50
2025-10-05 20:58:46.376421: train_loss -0.8615
2025-10-05 20:58:46.376572: val_loss -0.3873
2025-10-05 20:58:46.376763: Pseudo dice [np.float32(0.6995)]
2025-10-05 20:58:46.376934: Epoch time: 46.21 s
2025-10-05 20:58:47.045664: 
2025-10-05 20:58:47.046148: Epoch 146
2025-10-05 20:58:47.046354: Current learning rate: 0.00038
2025-10-05 20:59:33.347101: Validation loss did not improve from -0.45533. Patience: 64/50
2025-10-05 20:59:33.347717: train_loss -0.8566
2025-10-05 20:59:33.347888: val_loss -0.3875
2025-10-05 20:59:33.348044: Pseudo dice [np.float32(0.7005)]
2025-10-05 20:59:33.348184: Epoch time: 46.3 s
2025-10-05 20:59:34.013199: 
2025-10-05 20:59:34.013486: Epoch 147
2025-10-05 20:59:34.013677: Current learning rate: 0.0003
2025-10-05 21:00:20.232944: Validation loss did not improve from -0.45533. Patience: 65/50
2025-10-05 21:00:20.233449: train_loss -0.8602
2025-10-05 21:00:20.233633: val_loss -0.3838
2025-10-05 21:00:20.233787: Pseudo dice [np.float32(0.6995)]
2025-10-05 21:00:20.234008: Epoch time: 46.22 s
2025-10-05 21:00:21.428273: 
2025-10-05 21:00:21.428553: Epoch 148
2025-10-05 21:00:21.428763: Current learning rate: 0.00021
2025-10-05 21:01:07.657836: Validation loss did not improve from -0.45533. Patience: 66/50
2025-10-05 21:01:07.658426: train_loss -0.861
2025-10-05 21:01:07.658622: val_loss -0.3713
2025-10-05 21:01:07.658788: Pseudo dice [np.float32(0.6819)]
2025-10-05 21:01:07.658952: Epoch time: 46.23 s
2025-10-05 21:01:08.319120: 
2025-10-05 21:01:08.319482: Epoch 149
2025-10-05 21:01:08.319704: Current learning rate: 0.00011
2025-10-05 21:01:54.469444: Validation loss did not improve from -0.45533. Patience: 67/50
2025-10-05 21:01:54.469883: train_loss -0.8626
2025-10-05 21:01:54.470058: val_loss -0.3697
2025-10-05 21:01:54.470191: Pseudo dice [np.float32(0.6876)]
2025-10-05 21:01:54.470373: Epoch time: 46.15 s
2025-10-05 21:01:55.656647: Training done.
2025-10-05 21:01:55.671364: Using splits from existing split file: /nfs/erelab001/shared/Computational_Group/Naravich/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset310_nnInteractive_Calcium_OCT_CrossValidation/splits_final_80.json
2025-10-05 21:01:55.671753: The split file contains 5 splits.
2025-10-05 21:01:55.671911: Desired fold for training: 2
2025-10-05 21:01:55.672121: This split has 6 training and 3 validation cases.
2025-10-05 21:01:55.672400: predicting 101-045
2025-10-05 21:01:55.676950: 101-045, shape torch.Size([1, 375, 498, 498]), rank 0
2025-10-05 21:02:42.852647: predicting 401-004
2025-10-05 21:02:42.865865: 401-004, shape torch.Size([1, 375, 498, 498]), rank 0
2025-10-05 21:03:16.801237: predicting 704-003
2025-10-05 21:03:16.814456: 704-003, shape torch.Size([1, 375, 498, 498]), rank 0
2025-10-05 21:04:03.891719: Validation complete
2025-10-05 21:04:03.891958: Mean Validation Dice:  0.679247488212893
Finished training fold 2 saving to /nfs/erelab001/shared/Computational_Group/Naravich/datasets/nnUNet_Datasets/nnUNet_results/Dataset310_nnInteractive_Calcium_OCT_CrossValidation/nnUNetTrainerScaleAnalysis80__nnUNetPlans__3d_32x160x128_b10/fold_2_No_Pretrained
