/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/bin/python
Starting training with CONFIG=3d_32x160x128_b10, DATASET_ID=310, TRAINER=nnUNetTrainer
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:169: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2025-10-02 16:49:13.193333: do_dummy_2d_data_aug: True
2025-10-02 16:49:13.194113: Using splits from existing split file: /nfs/erelab001/shared/Computational_Group/Naravich/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset310_nnInteractive_Calcium_OCT_CrossValidation/splits_final.json
2025-10-02 16:49:13.194423: The split file contains 5 splits.
2025-10-02 16:49:13.194535: Desired fold for training: 1
2025-10-02 16:49:13.194646: This split has 6 training and 2 validation cases.
using pin_memory on device 0
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
using pin_memory on device 0
2025-10-02 16:50:00.158635: Using torch.compile...

This is the configuration used by this training:
Configuration name: 3d_32x160x128_b10
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 10, 'patch_size': [32, 160, 128], 'median_image_size_in_voxels': [375.0, 498.0, 498.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'inherits_from': '3d_fullres'} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset310_nnInteractive_Calcium_OCT_CrossValidation', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.4977976381778717, 'mean': 0.1394134759902954, 'median': 0.09849607944488525, 'min': 0.0, 'percentile_00_5': 0.015305490233004093, 'percentile_99_5': 0.4977976381778717, 'std': 0.121165432035923}}} 

2025-10-02 16:50:20.151971: unpacking dataset...
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:7095: UserWarning: 
Online softmax is disabled on the fly since Inductor decides to
split the reduction. Cut an issue to PyTorch if this is an
important use case and you want to speed it up with online
softmax.

  warnings.warn(
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:7095: UserWarning: 
Online softmax is disabled on the fly since Inductor decides to
split the reduction. Cut an issue to PyTorch if this is an
important use case and you want to speed it up with online
softmax.

  warnings.warn(
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:7095: UserWarning: 
Online softmax is disabled on the fly since Inductor decides to
split the reduction. Cut an issue to PyTorch if this is an
important use case and you want to speed it up with online
softmax.

  warnings.warn(
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:7095: UserWarning: 
Online softmax is disabled on the fly since Inductor decides to
split the reduction. Cut an issue to PyTorch if this is an
important use case and you want to speed it up with online
softmax.

  warnings.warn(
2025-10-02 16:50:24.690516: unpacking done...
2025-10-02 16:50:24.692938: Unable to plot network architecture: nnUNet_compile is enabled!
2025-10-02 16:50:24.699720: 
2025-10-02 16:50:24.699900: Epoch 0
2025-10-02 16:50:24.700197: Current learning rate: 0.01
2025-10-02 16:51:47.560030: Validation loss improved from 1000.00000 to -0.08502! Patience: 0/50
2025-10-02 16:51:47.560679: train_loss -0.149
2025-10-02 16:51:47.560868: val_loss -0.085
2025-10-02 16:51:47.561014: Pseudo dice [np.float32(0.4801)]
2025-10-02 16:51:47.561200: Epoch time: 82.86 s
2025-10-02 16:51:47.561333: Yayy! New best EMA pseudo Dice: 0.48010000586509705
2025-10-02 16:51:48.542953: 
2025-10-02 16:51:48.543267: Epoch 1
2025-10-02 16:51:48.543469: Current learning rate: 0.00994
2025-10-02 16:52:34.457210: Validation loss improved from -0.08502 to -0.13475! Patience: 0/50
2025-10-02 16:52:34.457595: train_loss -0.2606
2025-10-02 16:52:34.457749: val_loss -0.1348
2025-10-02 16:52:34.457884: Pseudo dice [np.float32(0.5068)]
2025-10-02 16:52:34.458024: Epoch time: 45.92 s
2025-10-02 16:52:34.458148: Yayy! New best EMA pseudo Dice: 0.482699990272522
2025-10-02 16:52:35.566269: 
2025-10-02 16:52:35.566552: Epoch 2
2025-10-02 16:52:35.566721: Current learning rate: 0.00988
2025-10-02 16:53:21.620771: Validation loss improved from -0.13475 to -0.15688! Patience: 0/50
2025-10-02 16:53:21.621595: train_loss -0.2969
2025-10-02 16:53:21.621817: val_loss -0.1569
2025-10-02 16:53:21.622571: Pseudo dice [np.float32(0.5008)]
2025-10-02 16:53:21.622710: Epoch time: 46.06 s
2025-10-02 16:53:21.622833: Yayy! New best EMA pseudo Dice: 0.484499990940094
2025-10-02 16:53:22.678119: 
2025-10-02 16:53:22.678409: Epoch 3
2025-10-02 16:53:22.678583: Current learning rate: 0.00982
2025-10-02 16:54:08.651143: Validation loss improved from -0.15688 to -0.18461! Patience: 0/50
2025-10-02 16:54:08.651894: train_loss -0.3168
2025-10-02 16:54:08.652544: val_loss -0.1846
2025-10-02 16:54:08.652712: Pseudo dice [np.float32(0.5473)]
2025-10-02 16:54:08.652858: Epoch time: 45.97 s
2025-10-02 16:54:08.652999: Yayy! New best EMA pseudo Dice: 0.49079999327659607
2025-10-02 16:54:09.703731: 
2025-10-02 16:54:09.704084: Epoch 4
2025-10-02 16:54:09.704394: Current learning rate: 0.00976
2025-10-02 16:54:55.762927: Validation loss improved from -0.18461 to -0.24252! Patience: 0/50
2025-10-02 16:54:55.763506: train_loss -0.3436
2025-10-02 16:54:55.763676: val_loss -0.2425
2025-10-02 16:54:55.763821: Pseudo dice [np.float32(0.558)]
2025-10-02 16:54:55.764054: Epoch time: 46.06 s
2025-10-02 16:54:56.141816: Yayy! New best EMA pseudo Dice: 0.4975000023841858
2025-10-02 16:54:57.223989: 
2025-10-02 16:54:57.224399: Epoch 5
2025-10-02 16:54:57.224742: Current learning rate: 0.0097
2025-10-02 16:55:43.244325: Validation loss did not improve from -0.24252. Patience: 1/50
2025-10-02 16:55:43.244791: train_loss -0.3836
2025-10-02 16:55:43.245005: val_loss -0.236
2025-10-02 16:55:43.245222: Pseudo dice [np.float32(0.5692)]
2025-10-02 16:55:43.245417: Epoch time: 46.02 s
2025-10-02 16:55:43.245584: Yayy! New best EMA pseudo Dice: 0.5047000050544739
2025-10-02 16:55:44.279864: 
2025-10-02 16:55:44.280272: Epoch 6
2025-10-02 16:55:44.280478: Current learning rate: 0.00964
2025-10-02 16:56:30.359658: Validation loss improved from -0.24252 to -0.28033! Patience: 1/50
2025-10-02 16:56:30.360243: train_loss -0.3966
2025-10-02 16:56:30.360418: val_loss -0.2803
2025-10-02 16:56:30.360546: Pseudo dice [np.float32(0.5905)]
2025-10-02 16:56:30.360673: Epoch time: 46.08 s
2025-10-02 16:56:30.360789: Yayy! New best EMA pseudo Dice: 0.5133000016212463
2025-10-02 16:56:31.412837: 
2025-10-02 16:56:31.413438: Epoch 7
2025-10-02 16:56:31.413913: Current learning rate: 0.00958
2025-10-02 16:57:17.475497: Validation loss did not improve from -0.28033. Patience: 1/50
2025-10-02 16:57:17.475958: train_loss -0.3883
2025-10-02 16:57:17.476146: val_loss -0.2736
2025-10-02 16:57:17.476321: Pseudo dice [np.float32(0.5847)]
2025-10-02 16:57:17.476481: Epoch time: 46.06 s
2025-10-02 16:57:17.476612: Yayy! New best EMA pseudo Dice: 0.5203999876976013
2025-10-02 16:57:18.594032: 
2025-10-02 16:57:18.594350: Epoch 8
2025-10-02 16:57:18.594660: Current learning rate: 0.00952
2025-10-02 16:58:04.710696: Validation loss improved from -0.28033 to -0.29303! Patience: 1/50
2025-10-02 16:58:04.711433: train_loss -0.4053
2025-10-02 16:58:04.711780: val_loss -0.293
2025-10-02 16:58:04.712065: Pseudo dice [np.float32(0.5933)]
2025-10-02 16:58:04.712321: Epoch time: 46.12 s
2025-10-02 16:58:04.712508: Yayy! New best EMA pseudo Dice: 0.5277000069618225
2025-10-02 16:58:05.809877: 
2025-10-02 16:58:05.810252: Epoch 9
2025-10-02 16:58:05.810510: Current learning rate: 0.00946
2025-10-02 16:58:51.975458: Validation loss improved from -0.29303 to -0.36127! Patience: 0/50
2025-10-02 16:58:51.976233: train_loss -0.4298
2025-10-02 16:58:51.976730: val_loss -0.3613
2025-10-02 16:58:51.977094: Pseudo dice [np.float32(0.6361)]
2025-10-02 16:58:51.977651: Epoch time: 46.17 s
2025-10-02 16:58:52.427427: Yayy! New best EMA pseudo Dice: 0.5386000275611877
2025-10-02 16:58:53.493175: 
2025-10-02 16:58:53.493485: Epoch 10
2025-10-02 16:58:53.493681: Current learning rate: 0.0094
2025-10-02 16:59:39.639756: Validation loss did not improve from -0.36127. Patience: 1/50
2025-10-02 16:59:39.641203: train_loss -0.4414
2025-10-02 16:59:39.641517: val_loss -0.3181
2025-10-02 16:59:39.641804: Pseudo dice [np.float32(0.6152)]
2025-10-02 16:59:39.642028: Epoch time: 46.15 s
2025-10-02 16:59:39.642277: Yayy! New best EMA pseudo Dice: 0.5461999773979187
2025-10-02 16:59:40.746814: 
2025-10-02 16:59:40.747108: Epoch 11
2025-10-02 16:59:40.747348: Current learning rate: 0.00934
2025-10-02 17:00:26.839144: Validation loss did not improve from -0.36127. Patience: 2/50
2025-10-02 17:00:26.839609: train_loss -0.4522
2025-10-02 17:00:26.839837: val_loss -0.3215
2025-10-02 17:00:26.840042: Pseudo dice [np.float32(0.6184)]
2025-10-02 17:00:26.840223: Epoch time: 46.09 s
2025-10-02 17:00:26.840343: Yayy! New best EMA pseudo Dice: 0.5533999800682068
2025-10-02 17:00:27.973358: 
2025-10-02 17:00:27.973811: Epoch 12
2025-10-02 17:00:27.974087: Current learning rate: 0.00928
2025-10-02 17:01:14.054838: Validation loss improved from -0.36127 to -0.37803! Patience: 2/50
2025-10-02 17:01:14.055488: train_loss -0.4556
2025-10-02 17:01:14.055677: val_loss -0.378
2025-10-02 17:01:14.055826: Pseudo dice [np.float32(0.6482)]
2025-10-02 17:01:14.055984: Epoch time: 46.08 s
2025-10-02 17:01:14.056141: Yayy! New best EMA pseudo Dice: 0.5629000067710876
2025-10-02 17:01:15.480593: 
2025-10-02 17:01:15.480863: Epoch 13
2025-10-02 17:01:15.481062: Current learning rate: 0.00922
2025-10-02 17:02:01.547303: Validation loss did not improve from -0.37803. Patience: 1/50
2025-10-02 17:02:01.547766: train_loss -0.478
2025-10-02 17:02:01.547935: val_loss -0.3447
2025-10-02 17:02:01.548135: Pseudo dice [np.float32(0.6307)]
2025-10-02 17:02:01.548302: Epoch time: 46.07 s
2025-10-02 17:02:01.548459: Yayy! New best EMA pseudo Dice: 0.5697000026702881
2025-10-02 17:02:02.635688: 
2025-10-02 17:02:02.635956: Epoch 14
2025-10-02 17:02:02.636176: Current learning rate: 0.00916
2025-10-02 17:02:48.710232: Validation loss did not improve from -0.37803. Patience: 2/50
2025-10-02 17:02:48.711041: train_loss -0.4778
2025-10-02 17:02:48.711317: val_loss -0.3403
2025-10-02 17:02:48.711614: Pseudo dice [np.float32(0.6319)]
2025-10-02 17:02:48.711882: Epoch time: 46.08 s
2025-10-02 17:02:49.133401: Yayy! New best EMA pseudo Dice: 0.5759000182151794
2025-10-02 17:02:50.174629: 
2025-10-02 17:02:50.174934: Epoch 15
2025-10-02 17:02:50.175155: Current learning rate: 0.0091
2025-10-02 17:03:36.244219: Validation loss did not improve from -0.37803. Patience: 3/50
2025-10-02 17:03:36.244832: train_loss -0.4862
2025-10-02 17:03:36.245131: val_loss -0.3338
2025-10-02 17:03:36.245429: Pseudo dice [np.float32(0.6288)]
2025-10-02 17:03:36.245774: Epoch time: 46.07 s
2025-10-02 17:03:36.246086: Yayy! New best EMA pseudo Dice: 0.5812000036239624
2025-10-02 17:03:37.305945: 
2025-10-02 17:03:37.306303: Epoch 16
2025-10-02 17:03:37.306521: Current learning rate: 0.00903
2025-10-02 17:04:23.434482: Validation loss did not improve from -0.37803. Patience: 4/50
2025-10-02 17:04:23.435106: train_loss -0.5029
2025-10-02 17:04:23.435299: val_loss -0.347
2025-10-02 17:04:23.435449: Pseudo dice [np.float32(0.6383)]
2025-10-02 17:04:23.435598: Epoch time: 46.13 s
2025-10-02 17:04:23.435743: Yayy! New best EMA pseudo Dice: 0.586899995803833
2025-10-02 17:04:24.483683: 
2025-10-02 17:04:24.484004: Epoch 17
2025-10-02 17:04:24.484238: Current learning rate: 0.00897
2025-10-02 17:05:10.665077: Validation loss did not improve from -0.37803. Patience: 5/50
2025-10-02 17:05:10.665537: train_loss -0.4892
2025-10-02 17:05:10.665711: val_loss -0.3709
2025-10-02 17:05:10.665834: Pseudo dice [np.float32(0.6441)]
2025-10-02 17:05:10.665994: Epoch time: 46.18 s
2025-10-02 17:05:10.666111: Yayy! New best EMA pseudo Dice: 0.5925999879837036
2025-10-02 17:05:11.718819: 
2025-10-02 17:05:11.719366: Epoch 18
2025-10-02 17:05:11.719760: Current learning rate: 0.00891
2025-10-02 17:05:57.847398: Validation loss did not improve from -0.37803. Patience: 6/50
2025-10-02 17:05:57.848580: train_loss -0.4983
2025-10-02 17:05:57.849046: val_loss -0.3623
2025-10-02 17:05:57.849413: Pseudo dice [np.float32(0.6405)]
2025-10-02 17:05:57.849785: Epoch time: 46.13 s
2025-10-02 17:05:57.850145: Yayy! New best EMA pseudo Dice: 0.5974000096321106
2025-10-02 17:05:58.897858: 
2025-10-02 17:05:58.898207: Epoch 19
2025-10-02 17:05:58.898394: Current learning rate: 0.00885
2025-10-02 17:06:45.049750: Validation loss improved from -0.37803 to -0.39691! Patience: 6/50
2025-10-02 17:06:45.050208: train_loss -0.5025
2025-10-02 17:06:45.050396: val_loss -0.3969
2025-10-02 17:06:45.050536: Pseudo dice [np.float32(0.6623)]
2025-10-02 17:06:45.050692: Epoch time: 46.15 s
2025-10-02 17:06:45.471621: Yayy! New best EMA pseudo Dice: 0.6039000153541565
2025-10-02 17:06:46.526676: 
2025-10-02 17:06:46.527340: Epoch 20
2025-10-02 17:06:46.527856: Current learning rate: 0.00879
2025-10-02 17:07:32.667763: Validation loss improved from -0.39691 to -0.42681! Patience: 0/50
2025-10-02 17:07:32.669096: train_loss -0.5121
2025-10-02 17:07:32.669487: val_loss -0.4268
2025-10-02 17:07:32.669871: Pseudo dice [np.float32(0.6665)]
2025-10-02 17:07:32.670347: Epoch time: 46.14 s
2025-10-02 17:07:32.670716: Yayy! New best EMA pseudo Dice: 0.6101999878883362
2025-10-02 17:07:33.731587: 
2025-10-02 17:07:33.732086: Epoch 21
2025-10-02 17:07:33.732506: Current learning rate: 0.00873
2025-10-02 17:08:19.882980: Validation loss improved from -0.42681 to -0.43040! Patience: 0/50
2025-10-02 17:08:19.883522: train_loss -0.5232
2025-10-02 17:08:19.883778: val_loss -0.4304
2025-10-02 17:08:19.884044: Pseudo dice [np.float32(0.6836)]
2025-10-02 17:08:19.884286: Epoch time: 46.15 s
2025-10-02 17:08:19.884494: Yayy! New best EMA pseudo Dice: 0.6175000071525574
2025-10-02 17:08:20.923033: 
2025-10-02 17:08:20.923334: Epoch 22
2025-10-02 17:08:20.923557: Current learning rate: 0.00867
2025-10-02 17:09:07.035484: Validation loss did not improve from -0.43040. Patience: 1/50
2025-10-02 17:09:07.036014: train_loss -0.5429
2025-10-02 17:09:07.036165: val_loss -0.3654
2025-10-02 17:09:07.036318: Pseudo dice [np.float32(0.6483)]
2025-10-02 17:09:07.036458: Epoch time: 46.11 s
2025-10-02 17:09:07.036604: Yayy! New best EMA pseudo Dice: 0.6205999851226807
2025-10-02 17:09:08.066842: 
2025-10-02 17:09:08.067263: Epoch 23
2025-10-02 17:09:08.067539: Current learning rate: 0.00861
2025-10-02 17:09:54.195848: Validation loss did not improve from -0.43040. Patience: 2/50
2025-10-02 17:09:54.196440: train_loss -0.5401
2025-10-02 17:09:54.196769: val_loss -0.3916
2025-10-02 17:09:54.197100: Pseudo dice [np.float32(0.6587)]
2025-10-02 17:09:54.197383: Epoch time: 46.13 s
2025-10-02 17:09:54.197664: Yayy! New best EMA pseudo Dice: 0.6244000196456909
2025-10-02 17:09:55.241830: 
2025-10-02 17:09:55.242206: Epoch 24
2025-10-02 17:09:55.242595: Current learning rate: 0.00855
2025-10-02 17:10:41.400267: Validation loss did not improve from -0.43040. Patience: 3/50
2025-10-02 17:10:41.401443: train_loss -0.5439
2025-10-02 17:10:41.401802: val_loss -0.3978
2025-10-02 17:10:41.402115: Pseudo dice [np.float32(0.6512)]
2025-10-02 17:10:41.402444: Epoch time: 46.16 s
2025-10-02 17:10:41.821223: Yayy! New best EMA pseudo Dice: 0.6270999908447266
2025-10-02 17:10:42.864533: 
2025-10-02 17:10:42.865031: Epoch 25
2025-10-02 17:10:42.865354: Current learning rate: 0.00849
2025-10-02 17:11:28.971578: Validation loss did not improve from -0.43040. Patience: 4/50
2025-10-02 17:11:28.972325: train_loss -0.5505
2025-10-02 17:11:28.972790: val_loss -0.4296
2025-10-02 17:11:28.973216: Pseudo dice [np.float32(0.6796)]
2025-10-02 17:11:28.973672: Epoch time: 46.11 s
2025-10-02 17:11:28.974096: Yayy! New best EMA pseudo Dice: 0.6323000192642212
2025-10-02 17:11:30.045414: 
2025-10-02 17:11:30.045747: Epoch 26
2025-10-02 17:11:30.045942: Current learning rate: 0.00843
2025-10-02 17:12:16.206845: Validation loss improved from -0.43040 to -0.44324! Patience: 4/50
2025-10-02 17:12:16.207470: train_loss -0.5606
2025-10-02 17:12:16.207637: val_loss -0.4432
2025-10-02 17:12:16.207762: Pseudo dice [np.float32(0.6842)]
2025-10-02 17:12:16.207905: Epoch time: 46.16 s
2025-10-02 17:12:16.208057: Yayy! New best EMA pseudo Dice: 0.637499988079071
2025-10-02 17:12:17.273468: 
2025-10-02 17:12:17.273748: Epoch 27
2025-10-02 17:12:17.273963: Current learning rate: 0.00836
2025-10-02 17:13:03.404590: Validation loss did not improve from -0.44324. Patience: 1/50
2025-10-02 17:13:03.404982: train_loss -0.5595
2025-10-02 17:13:03.405160: val_loss -0.3862
2025-10-02 17:13:03.405398: Pseudo dice [np.float32(0.648)]
2025-10-02 17:13:03.405543: Epoch time: 46.13 s
2025-10-02 17:13:03.405661: Yayy! New best EMA pseudo Dice: 0.6385999917984009
2025-10-02 17:13:04.878959: 
2025-10-02 17:13:04.879253: Epoch 28
2025-10-02 17:13:04.879447: Current learning rate: 0.0083
2025-10-02 17:13:51.031537: Validation loss did not improve from -0.44324. Patience: 2/50
2025-10-02 17:13:51.032744: train_loss -0.5668
2025-10-02 17:13:51.033093: val_loss -0.4292
2025-10-02 17:13:51.033438: Pseudo dice [np.float32(0.6834)]
2025-10-02 17:13:51.033762: Epoch time: 46.15 s
2025-10-02 17:13:51.034080: Yayy! New best EMA pseudo Dice: 0.6431000232696533
2025-10-02 17:13:52.187639: 
2025-10-02 17:13:52.187948: Epoch 29
2025-10-02 17:13:52.188206: Current learning rate: 0.00824
2025-10-02 17:14:38.337222: Validation loss did not improve from -0.44324. Patience: 3/50
2025-10-02 17:14:38.337698: train_loss -0.5668
2025-10-02 17:14:38.337895: val_loss -0.4177
2025-10-02 17:14:38.338075: Pseudo dice [np.float32(0.6687)]
2025-10-02 17:14:38.338282: Epoch time: 46.15 s
2025-10-02 17:14:38.787924: Yayy! New best EMA pseudo Dice: 0.6456000208854675
2025-10-02 17:14:39.864161: 
2025-10-02 17:14:39.864471: Epoch 30
2025-10-02 17:14:39.864709: Current learning rate: 0.00818
2025-10-02 17:15:26.030641: Validation loss did not improve from -0.44324. Patience: 4/50
2025-10-02 17:15:26.031747: train_loss -0.5718
2025-10-02 17:15:26.032247: val_loss -0.4057
2025-10-02 17:15:26.032668: Pseudo dice [np.float32(0.6744)]
2025-10-02 17:15:26.033124: Epoch time: 46.17 s
2025-10-02 17:15:26.033519: Yayy! New best EMA pseudo Dice: 0.6485000252723694
2025-10-02 17:15:27.121857: 
2025-10-02 17:15:27.122312: Epoch 31
2025-10-02 17:15:27.122568: Current learning rate: 0.00812
2025-10-02 17:16:13.290500: Validation loss did not improve from -0.44324. Patience: 5/50
2025-10-02 17:16:13.291115: train_loss -0.584
2025-10-02 17:16:13.291471: val_loss -0.3655
2025-10-02 17:16:13.291854: Pseudo dice [np.float32(0.6461)]
2025-10-02 17:16:13.292178: Epoch time: 46.17 s
2025-10-02 17:16:13.923956: 
2025-10-02 17:16:13.924394: Epoch 32
2025-10-02 17:16:13.924869: Current learning rate: 0.00806
2025-10-02 17:17:00.084280: Validation loss did not improve from -0.44324. Patience: 6/50
2025-10-02 17:17:00.085376: train_loss -0.5939
2025-10-02 17:17:00.085673: val_loss -0.4202
2025-10-02 17:17:00.085954: Pseudo dice [np.float32(0.6869)]
2025-10-02 17:17:00.086244: Epoch time: 46.16 s
2025-10-02 17:17:00.086596: Yayy! New best EMA pseudo Dice: 0.6521000266075134
2025-10-02 17:17:01.138622: 
2025-10-02 17:17:01.139156: Epoch 33
2025-10-02 17:17:01.139600: Current learning rate: 0.008
2025-10-02 17:17:47.306740: Validation loss did not improve from -0.44324. Patience: 7/50
2025-10-02 17:17:47.307251: train_loss -0.5928
2025-10-02 17:17:47.307460: val_loss -0.3847
2025-10-02 17:17:47.307616: Pseudo dice [np.float32(0.6603)]
2025-10-02 17:17:47.307788: Epoch time: 46.17 s
2025-10-02 17:17:47.307967: Yayy! New best EMA pseudo Dice: 0.652899980545044
2025-10-02 17:17:48.365558: 
2025-10-02 17:17:48.365840: Epoch 34
2025-10-02 17:17:48.366059: Current learning rate: 0.00793
2025-10-02 17:18:34.578454: Validation loss did not improve from -0.44324. Patience: 8/50
2025-10-02 17:18:34.579186: train_loss -0.5936
2025-10-02 17:18:34.579514: val_loss -0.416
2025-10-02 17:18:34.579662: Pseudo dice [np.float32(0.6752)]
2025-10-02 17:18:34.580035: Epoch time: 46.21 s
2025-10-02 17:18:34.998619: Yayy! New best EMA pseudo Dice: 0.6552000045776367
2025-10-02 17:18:36.034884: 
2025-10-02 17:18:36.035226: Epoch 35
2025-10-02 17:18:36.035414: Current learning rate: 0.00787
2025-10-02 17:19:22.166972: Validation loss did not improve from -0.44324. Patience: 9/50
2025-10-02 17:19:22.167544: train_loss -0.5997
2025-10-02 17:19:22.167943: val_loss -0.4358
2025-10-02 17:19:22.168284: Pseudo dice [np.float32(0.684)]
2025-10-02 17:19:22.168678: Epoch time: 46.13 s
2025-10-02 17:19:22.169008: Yayy! New best EMA pseudo Dice: 0.6581000089645386
2025-10-02 17:19:23.236901: 
2025-10-02 17:19:23.237178: Epoch 36
2025-10-02 17:19:23.237388: Current learning rate: 0.00781
2025-10-02 17:20:09.372693: Validation loss did not improve from -0.44324. Patience: 10/50
2025-10-02 17:20:09.373292: train_loss -0.6067
2025-10-02 17:20:09.373439: val_loss -0.4228
2025-10-02 17:20:09.373559: Pseudo dice [np.float32(0.6772)]
2025-10-02 17:20:09.373693: Epoch time: 46.14 s
2025-10-02 17:20:09.373864: Yayy! New best EMA pseudo Dice: 0.6600000262260437
2025-10-02 17:20:10.419354: 
2025-10-02 17:20:10.419708: Epoch 37
2025-10-02 17:20:10.419935: Current learning rate: 0.00775
2025-10-02 17:20:56.553108: Validation loss did not improve from -0.44324. Patience: 11/50
2025-10-02 17:20:56.553719: train_loss -0.6025
2025-10-02 17:20:56.554092: val_loss -0.4068
2025-10-02 17:20:56.554432: Pseudo dice [np.float32(0.6787)]
2025-10-02 17:20:56.554790: Epoch time: 46.14 s
2025-10-02 17:20:56.555115: Yayy! New best EMA pseudo Dice: 0.6618000268936157
2025-10-02 17:20:57.618938: 
2025-10-02 17:20:57.619259: Epoch 38
2025-10-02 17:20:57.619458: Current learning rate: 0.00769
2025-10-02 17:21:43.738720: Validation loss did not improve from -0.44324. Patience: 12/50
2025-10-02 17:21:43.739511: train_loss -0.6071
2025-10-02 17:21:43.739887: val_loss -0.3799
2025-10-02 17:21:43.740082: Pseudo dice [np.float32(0.6551)]
2025-10-02 17:21:43.740294: Epoch time: 46.12 s
2025-10-02 17:21:44.364071: 
2025-10-02 17:21:44.364547: Epoch 39
2025-10-02 17:21:44.364970: Current learning rate: 0.00763
2025-10-02 17:22:30.450690: Validation loss did not improve from -0.44324. Patience: 13/50
2025-10-02 17:22:30.451152: train_loss -0.617
2025-10-02 17:22:30.451345: val_loss -0.4083
2025-10-02 17:22:30.451482: Pseudo dice [np.float32(0.673)]
2025-10-02 17:22:30.451694: Epoch time: 46.09 s
2025-10-02 17:22:30.887350: Yayy! New best EMA pseudo Dice: 0.6624000072479248
2025-10-02 17:22:31.922521: 
2025-10-02 17:22:31.922860: Epoch 40
2025-10-02 17:22:31.923046: Current learning rate: 0.00756
2025-10-02 17:23:17.979245: Validation loss did not improve from -0.44324. Patience: 14/50
2025-10-02 17:23:17.979822: train_loss -0.6128
2025-10-02 17:23:17.980010: val_loss -0.4283
2025-10-02 17:23:17.980178: Pseudo dice [np.float32(0.6816)]
2025-10-02 17:23:17.980331: Epoch time: 46.06 s
2025-10-02 17:23:17.980457: Yayy! New best EMA pseudo Dice: 0.6643000245094299
2025-10-02 17:23:19.034755: 
2025-10-02 17:23:19.035049: Epoch 41
2025-10-02 17:23:19.035291: Current learning rate: 0.0075
2025-10-02 17:24:05.095010: Validation loss improved from -0.44324 to -0.44646! Patience: 14/50
2025-10-02 17:24:05.095610: train_loss -0.6148
2025-10-02 17:24:05.095899: val_loss -0.4465
2025-10-02 17:24:05.096183: Pseudo dice [np.float32(0.6934)]
2025-10-02 17:24:05.096542: Epoch time: 46.06 s
2025-10-02 17:24:05.096929: Yayy! New best EMA pseudo Dice: 0.6672000288963318
2025-10-02 17:24:06.127932: 
2025-10-02 17:24:06.128378: Epoch 42
2025-10-02 17:24:06.128716: Current learning rate: 0.00744
2025-10-02 17:24:52.245306: Validation loss did not improve from -0.44646. Patience: 1/50
2025-10-02 17:24:52.246525: train_loss -0.6273
2025-10-02 17:24:52.246894: val_loss -0.4125
2025-10-02 17:24:52.247275: Pseudo dice [np.float32(0.6695)]
2025-10-02 17:24:52.247639: Epoch time: 46.12 s
2025-10-02 17:24:52.247991: Yayy! New best EMA pseudo Dice: 0.6674000024795532
2025-10-02 17:24:53.694423: 
2025-10-02 17:24:53.694804: Epoch 43
2025-10-02 17:24:53.695030: Current learning rate: 0.00738
2025-10-02 17:25:39.751716: Validation loss did not improve from -0.44646. Patience: 2/50
2025-10-02 17:25:39.752105: train_loss -0.6251
2025-10-02 17:25:39.752304: val_loss -0.4304
2025-10-02 17:25:39.752484: Pseudo dice [np.float32(0.6806)]
2025-10-02 17:25:39.752735: Epoch time: 46.06 s
2025-10-02 17:25:39.752937: Yayy! New best EMA pseudo Dice: 0.6686999797821045
2025-10-02 17:25:40.812808: 
2025-10-02 17:25:40.813359: Epoch 44
2025-10-02 17:25:40.813567: Current learning rate: 0.00732
2025-10-02 17:26:26.830371: Validation loss did not improve from -0.44646. Patience: 3/50
2025-10-02 17:26:26.830918: train_loss -0.6306
2025-10-02 17:26:26.831125: val_loss -0.4304
2025-10-02 17:26:26.831290: Pseudo dice [np.float32(0.6807)]
2025-10-02 17:26:26.831524: Epoch time: 46.02 s
2025-10-02 17:26:27.263060: Yayy! New best EMA pseudo Dice: 0.6699000000953674
2025-10-02 17:26:28.281226: 
2025-10-02 17:26:28.281560: Epoch 45
2025-10-02 17:26:28.281895: Current learning rate: 0.00725
2025-10-02 17:27:14.308608: Validation loss did not improve from -0.44646. Patience: 4/50
2025-10-02 17:27:14.309045: train_loss -0.6381
2025-10-02 17:27:14.309269: val_loss -0.4017
2025-10-02 17:27:14.309616: Pseudo dice [np.float32(0.6672)]
2025-10-02 17:27:14.309975: Epoch time: 46.03 s
2025-10-02 17:27:14.917695: 
2025-10-02 17:27:14.918035: Epoch 46
2025-10-02 17:27:14.918238: Current learning rate: 0.00719
2025-10-02 17:28:00.941957: Validation loss did not improve from -0.44646. Patience: 5/50
2025-10-02 17:28:00.942565: train_loss -0.6324
2025-10-02 17:28:00.942718: val_loss -0.4404
2025-10-02 17:28:00.942875: Pseudo dice [np.float32(0.6946)]
2025-10-02 17:28:00.943033: Epoch time: 46.03 s
2025-10-02 17:28:00.943193: Yayy! New best EMA pseudo Dice: 0.6722000241279602
2025-10-02 17:28:01.977517: 
2025-10-02 17:28:01.977914: Epoch 47
2025-10-02 17:28:01.978303: Current learning rate: 0.00713
2025-10-02 17:28:47.976918: Validation loss did not improve from -0.44646. Patience: 6/50
2025-10-02 17:28:47.977569: train_loss -0.6417
2025-10-02 17:28:47.978051: val_loss -0.4447
2025-10-02 17:28:47.978499: Pseudo dice [np.float32(0.6961)]
2025-10-02 17:28:47.978912: Epoch time: 46.0 s
2025-10-02 17:28:47.979310: Yayy! New best EMA pseudo Dice: 0.6744999885559082
2025-10-02 17:28:49.029315: 
2025-10-02 17:28:49.029612: Epoch 48
2025-10-02 17:28:49.029820: Current learning rate: 0.00707
2025-10-02 17:29:35.080452: Validation loss did not improve from -0.44646. Patience: 7/50
2025-10-02 17:29:35.081410: train_loss -0.6488
2025-10-02 17:29:35.081828: val_loss -0.4387
2025-10-02 17:29:35.082186: Pseudo dice [np.float32(0.6854)]
2025-10-02 17:29:35.082501: Epoch time: 46.05 s
2025-10-02 17:29:35.082866: Yayy! New best EMA pseudo Dice: 0.675599992275238
2025-10-02 17:29:36.123536: 
2025-10-02 17:29:36.123955: Epoch 49
2025-10-02 17:29:36.124259: Current learning rate: 0.007
2025-10-02 17:30:22.110016: Validation loss improved from -0.44646 to -0.45745! Patience: 7/50
2025-10-02 17:30:22.110599: train_loss -0.6545
2025-10-02 17:30:22.110930: val_loss -0.4574
2025-10-02 17:30:22.111303: Pseudo dice [np.float32(0.6939)]
2025-10-02 17:30:22.111645: Epoch time: 45.99 s
2025-10-02 17:30:22.533046: Yayy! New best EMA pseudo Dice: 0.6775000095367432
2025-10-02 17:30:23.558887: 
2025-10-02 17:30:23.559135: Epoch 50
2025-10-02 17:30:23.559369: Current learning rate: 0.00694
2025-10-02 17:31:09.535320: Validation loss did not improve from -0.45745. Patience: 1/50
2025-10-02 17:31:09.535866: train_loss -0.6461
2025-10-02 17:31:09.536016: val_loss -0.4356
2025-10-02 17:31:09.536169: Pseudo dice [np.float32(0.6847)]
2025-10-02 17:31:09.536319: Epoch time: 45.98 s
2025-10-02 17:31:09.536451: Yayy! New best EMA pseudo Dice: 0.6782000064849854
2025-10-02 17:31:10.576872: 
2025-10-02 17:31:10.577329: Epoch 51
2025-10-02 17:31:10.577623: Current learning rate: 0.00688
2025-10-02 17:31:56.560485: Validation loss did not improve from -0.45745. Patience: 2/50
2025-10-02 17:31:56.561460: train_loss -0.6456
2025-10-02 17:31:56.562040: val_loss -0.4373
2025-10-02 17:31:56.562476: Pseudo dice [np.float32(0.6863)]
2025-10-02 17:31:56.562953: Epoch time: 45.99 s
2025-10-02 17:31:56.563506: Yayy! New best EMA pseudo Dice: 0.6790000200271606
2025-10-02 17:31:57.604668: 
2025-10-02 17:31:57.604973: Epoch 52
2025-10-02 17:31:57.605171: Current learning rate: 0.00682
2025-10-02 17:32:43.642674: Validation loss did not improve from -0.45745. Patience: 3/50
2025-10-02 17:32:43.643936: train_loss -0.6525
2025-10-02 17:32:43.644305: val_loss -0.4415
2025-10-02 17:32:43.644646: Pseudo dice [np.float32(0.6916)]
2025-10-02 17:32:43.644905: Epoch time: 46.04 s
2025-10-02 17:32:43.645046: Yayy! New best EMA pseudo Dice: 0.6802999973297119
2025-10-02 17:32:44.693600: 
2025-10-02 17:32:44.693936: Epoch 53
2025-10-02 17:32:44.694141: Current learning rate: 0.00675
2025-10-02 17:33:30.817251: Validation loss did not improve from -0.45745. Patience: 4/50
2025-10-02 17:33:30.817909: train_loss -0.6414
2025-10-02 17:33:30.818312: val_loss -0.4296
2025-10-02 17:33:30.818700: Pseudo dice [np.float32(0.6864)]
2025-10-02 17:33:30.819090: Epoch time: 46.12 s
2025-10-02 17:33:30.819483: Yayy! New best EMA pseudo Dice: 0.680899977684021
2025-10-02 17:33:31.877159: 
2025-10-02 17:33:31.877449: Epoch 54
2025-10-02 17:33:31.877660: Current learning rate: 0.00669
2025-10-02 17:34:18.062488: Validation loss did not improve from -0.45745. Patience: 5/50
2025-10-02 17:34:18.063211: train_loss -0.6517
2025-10-02 17:34:18.063464: val_loss -0.4201
2025-10-02 17:34:18.063838: Pseudo dice [np.float32(0.6736)]
2025-10-02 17:34:18.064020: Epoch time: 46.19 s
2025-10-02 17:34:19.107191: 
2025-10-02 17:34:19.107527: Epoch 55
2025-10-02 17:34:19.107800: Current learning rate: 0.00663
2025-10-02 17:35:05.327909: Validation loss did not improve from -0.45745. Patience: 6/50
2025-10-02 17:35:05.328427: train_loss -0.6567
2025-10-02 17:35:05.328667: val_loss -0.4078
2025-10-02 17:35:05.328859: Pseudo dice [np.float32(0.6782)]
2025-10-02 17:35:05.329057: Epoch time: 46.22 s
2025-10-02 17:35:05.955287: 
2025-10-02 17:35:05.955733: Epoch 56
2025-10-02 17:35:05.955948: Current learning rate: 0.00657
2025-10-02 17:35:52.199522: Validation loss did not improve from -0.45745. Patience: 7/50
2025-10-02 17:35:52.200809: train_loss -0.6614
2025-10-02 17:35:52.201318: val_loss -0.4368
2025-10-02 17:35:52.201714: Pseudo dice [np.float32(0.6883)]
2025-10-02 17:35:52.202135: Epoch time: 46.25 s
2025-10-02 17:35:52.829573: 
2025-10-02 17:35:52.829960: Epoch 57
2025-10-02 17:35:52.830148: Current learning rate: 0.0065
2025-10-02 17:36:39.080540: Validation loss did not improve from -0.45745. Patience: 8/50
2025-10-02 17:36:39.081234: train_loss -0.6579
2025-10-02 17:36:39.081635: val_loss -0.4273
2025-10-02 17:36:39.082008: Pseudo dice [np.float32(0.6788)]
2025-10-02 17:36:39.082412: Epoch time: 46.25 s
2025-10-02 17:36:39.704624: 
2025-10-02 17:36:39.704903: Epoch 58
2025-10-02 17:36:39.705086: Current learning rate: 0.00644
2025-10-02 17:37:25.943641: Validation loss did not improve from -0.45745. Patience: 9/50
2025-10-02 17:37:25.944275: train_loss -0.6608
2025-10-02 17:37:25.944465: val_loss -0.4248
2025-10-02 17:37:25.944626: Pseudo dice [np.float32(0.6838)]
2025-10-02 17:37:25.944776: Epoch time: 46.24 s
2025-10-02 17:37:25.944926: Yayy! New best EMA pseudo Dice: 0.680899977684021
2025-10-02 17:37:27.382387: 
2025-10-02 17:37:27.382911: Epoch 59
2025-10-02 17:37:27.383309: Current learning rate: 0.00638
2025-10-02 17:38:13.521641: Validation loss did not improve from -0.45745. Patience: 10/50
2025-10-02 17:38:13.522069: train_loss -0.6642
2025-10-02 17:38:13.522364: val_loss -0.4424
2025-10-02 17:38:13.522654: Pseudo dice [np.float32(0.6943)]
2025-10-02 17:38:13.522805: Epoch time: 46.14 s
2025-10-02 17:38:13.970183: Yayy! New best EMA pseudo Dice: 0.682200014591217
2025-10-02 17:38:15.012317: 
2025-10-02 17:38:15.012816: Epoch 60
2025-10-02 17:38:15.013210: Current learning rate: 0.00631
2025-10-02 17:39:01.160879: Validation loss did not improve from -0.45745. Patience: 11/50
2025-10-02 17:39:01.161520: train_loss -0.6793
2025-10-02 17:39:01.161664: val_loss -0.4193
2025-10-02 17:39:01.161911: Pseudo dice [np.float32(0.6813)]
2025-10-02 17:39:01.162080: Epoch time: 46.15 s
2025-10-02 17:39:01.790827: 
2025-10-02 17:39:01.791060: Epoch 61
2025-10-02 17:39:01.791224: Current learning rate: 0.00625
2025-10-02 17:39:47.910974: Validation loss did not improve from -0.45745. Patience: 12/50
2025-10-02 17:39:47.911429: train_loss -0.6721
2025-10-02 17:39:47.911616: val_loss -0.4069
2025-10-02 17:39:47.911945: Pseudo dice [np.float32(0.6833)]
2025-10-02 17:39:47.912222: Epoch time: 46.12 s
2025-10-02 17:39:47.912501: Yayy! New best EMA pseudo Dice: 0.6822999715805054
2025-10-02 17:39:48.997437: 
2025-10-02 17:39:48.998052: Epoch 62
2025-10-02 17:39:48.998511: Current learning rate: 0.00619
2025-10-02 17:40:35.089331: Validation loss did not improve from -0.45745. Patience: 13/50
2025-10-02 17:40:35.090581: train_loss -0.6824
2025-10-02 17:40:35.090950: val_loss -0.4406
2025-10-02 17:40:35.091276: Pseudo dice [np.float32(0.6984)]
2025-10-02 17:40:35.091587: Epoch time: 46.09 s
2025-10-02 17:40:35.091954: Yayy! New best EMA pseudo Dice: 0.683899998664856
2025-10-02 17:40:36.162644: 
2025-10-02 17:40:36.163159: Epoch 63
2025-10-02 17:40:36.163490: Current learning rate: 0.00612
2025-10-02 17:41:22.174529: Validation loss did not improve from -0.45745. Patience: 14/50
2025-10-02 17:41:22.175014: train_loss -0.6849
2025-10-02 17:41:22.175198: val_loss -0.4482
2025-10-02 17:41:22.175349: Pseudo dice [np.float32(0.6922)]
2025-10-02 17:41:22.175525: Epoch time: 46.01 s
2025-10-02 17:41:22.175739: Yayy! New best EMA pseudo Dice: 0.6847000122070312
2025-10-02 17:41:23.251908: 
2025-10-02 17:41:23.252247: Epoch 64
2025-10-02 17:41:23.252429: Current learning rate: 0.00606
2025-10-02 17:42:09.278593: Validation loss did not improve from -0.45745. Patience: 15/50
2025-10-02 17:42:09.279949: train_loss -0.6806
2025-10-02 17:42:09.280405: val_loss -0.4084
2025-10-02 17:42:09.280784: Pseudo dice [np.float32(0.6799)]
2025-10-02 17:42:09.281201: Epoch time: 46.03 s
2025-10-02 17:42:10.349609: 
2025-10-02 17:42:10.350035: Epoch 65
2025-10-02 17:42:10.350245: Current learning rate: 0.006
2025-10-02 17:42:56.334999: Validation loss did not improve from -0.45745. Patience: 16/50
2025-10-02 17:42:56.335511: train_loss -0.6873
2025-10-02 17:42:56.335752: val_loss -0.4163
2025-10-02 17:42:56.335891: Pseudo dice [np.float32(0.6825)]
2025-10-02 17:42:56.336030: Epoch time: 45.99 s
2025-10-02 17:42:56.968308: 
2025-10-02 17:42:56.968852: Epoch 66
2025-10-02 17:42:56.969129: Current learning rate: 0.00593
2025-10-02 17:43:42.932726: Validation loss did not improve from -0.45745. Patience: 17/50
2025-10-02 17:43:42.933447: train_loss -0.6975
2025-10-02 17:43:42.933610: val_loss -0.4144
2025-10-02 17:43:42.933793: Pseudo dice [np.float32(0.674)]
2025-10-02 17:43:42.933950: Epoch time: 45.97 s
2025-10-02 17:43:43.565552: 
2025-10-02 17:43:43.565786: Epoch 67
2025-10-02 17:43:43.566049: Current learning rate: 0.00587
2025-10-02 17:44:29.552385: Validation loss did not improve from -0.45745. Patience: 18/50
2025-10-02 17:44:29.552840: train_loss -0.6872
2025-10-02 17:44:29.553037: val_loss -0.3857
2025-10-02 17:44:29.553166: Pseudo dice [np.float32(0.6737)]
2025-10-02 17:44:29.553439: Epoch time: 45.99 s
2025-10-02 17:44:30.178966: 
2025-10-02 17:44:30.179214: Epoch 68
2025-10-02 17:44:30.179402: Current learning rate: 0.00581
2025-10-02 17:45:16.179219: Validation loss did not improve from -0.45745. Patience: 19/50
2025-10-02 17:45:16.179847: train_loss -0.7025
2025-10-02 17:45:16.180004: val_loss -0.4038
2025-10-02 17:45:16.180136: Pseudo dice [np.float32(0.6905)]
2025-10-02 17:45:16.180285: Epoch time: 46.0 s
2025-10-02 17:45:16.806898: 
2025-10-02 17:45:16.807387: Epoch 69
2025-10-02 17:45:16.807770: Current learning rate: 0.00574
2025-10-02 17:46:02.824942: Validation loss did not improve from -0.45745. Patience: 20/50
2025-10-02 17:46:02.825467: train_loss -0.7027
2025-10-02 17:46:02.825766: val_loss -0.4408
2025-10-02 17:46:02.826036: Pseudo dice [np.float32(0.6919)]
2025-10-02 17:46:02.826311: Epoch time: 46.02 s
2025-10-02 17:46:03.901604: 
2025-10-02 17:46:03.902033: Epoch 70
2025-10-02 17:46:03.902440: Current learning rate: 0.00568
2025-10-02 17:46:49.892452: Validation loss did not improve from -0.45745. Patience: 21/50
2025-10-02 17:46:49.893105: train_loss -0.7025
2025-10-02 17:46:49.893425: val_loss -0.4047
2025-10-02 17:46:49.893678: Pseudo dice [np.float32(0.683)]
2025-10-02 17:46:49.893812: Epoch time: 45.99 s
2025-10-02 17:46:50.520031: 
2025-10-02 17:46:50.520476: Epoch 71
2025-10-02 17:46:50.520811: Current learning rate: 0.00562
2025-10-02 17:47:36.605549: Validation loss did not improve from -0.45745. Patience: 22/50
2025-10-02 17:47:36.605989: train_loss -0.7067
2025-10-02 17:47:36.606198: val_loss -0.4064
2025-10-02 17:47:36.606430: Pseudo dice [np.float32(0.685)]
2025-10-02 17:47:36.606738: Epoch time: 46.09 s
2025-10-02 17:47:37.234468: 
2025-10-02 17:47:37.234820: Epoch 72
2025-10-02 17:47:37.235044: Current learning rate: 0.00555
2025-10-02 17:48:23.373173: Validation loss did not improve from -0.45745. Patience: 23/50
2025-10-02 17:48:23.373839: train_loss -0.7133
2025-10-02 17:48:23.374021: val_loss -0.4372
2025-10-02 17:48:23.374203: Pseudo dice [np.float32(0.7012)]
2025-10-02 17:48:23.374372: Epoch time: 46.14 s
2025-10-02 17:48:23.374549: Yayy! New best EMA pseudo Dice: 0.6855999827384949
2025-10-02 17:48:24.437770: 
2025-10-02 17:48:24.438117: Epoch 73
2025-10-02 17:48:24.438372: Current learning rate: 0.00549
2025-10-02 17:49:10.565958: Validation loss did not improve from -0.45745. Patience: 24/50
2025-10-02 17:49:10.566336: train_loss -0.7115
2025-10-02 17:49:10.566503: val_loss -0.453
2025-10-02 17:49:10.566642: Pseudo dice [np.float32(0.6995)]
2025-10-02 17:49:10.566812: Epoch time: 46.13 s
2025-10-02 17:49:10.566946: Yayy! New best EMA pseudo Dice: 0.6869999766349792
2025-10-02 17:49:12.032708: 
2025-10-02 17:49:12.033210: Epoch 74
2025-10-02 17:49:12.033415: Current learning rate: 0.00542
2025-10-02 17:49:58.204952: Validation loss did not improve from -0.45745. Patience: 25/50
2025-10-02 17:49:58.205660: train_loss -0.7131
2025-10-02 17:49:58.205856: val_loss -0.4098
2025-10-02 17:49:58.206011: Pseudo dice [np.float32(0.6854)]
2025-10-02 17:49:58.206160: Epoch time: 46.17 s
2025-10-02 17:49:59.266513: 
2025-10-02 17:49:59.266881: Epoch 75
2025-10-02 17:49:59.267094: Current learning rate: 0.00536
2025-10-02 17:50:45.469451: Validation loss did not improve from -0.45745. Patience: 26/50
2025-10-02 17:50:45.469978: train_loss -0.7127
2025-10-02 17:50:45.470213: val_loss -0.4204
2025-10-02 17:50:45.470441: Pseudo dice [np.float32(0.679)]
2025-10-02 17:50:45.470672: Epoch time: 46.2 s
2025-10-02 17:50:46.099813: 
2025-10-02 17:50:46.100173: Epoch 76
2025-10-02 17:50:46.100476: Current learning rate: 0.00529
2025-10-02 17:51:32.250404: Validation loss did not improve from -0.45745. Patience: 27/50
2025-10-02 17:51:32.250905: train_loss -0.7191
2025-10-02 17:51:32.251167: val_loss -0.4329
2025-10-02 17:51:32.251328: Pseudo dice [np.float32(0.6894)]
2025-10-02 17:51:32.251482: Epoch time: 46.15 s
2025-10-02 17:51:32.879389: 
2025-10-02 17:51:32.879733: Epoch 77
2025-10-02 17:51:32.879967: Current learning rate: 0.00523
2025-10-02 17:52:19.085029: Validation loss improved from -0.45745 to -0.46295! Patience: 27/50
2025-10-02 17:52:19.085428: train_loss -0.7278
2025-10-02 17:52:19.085653: val_loss -0.463
2025-10-02 17:52:19.085848: Pseudo dice [np.float32(0.7031)]
2025-10-02 17:52:19.086046: Epoch time: 46.21 s
2025-10-02 17:52:19.086232: Yayy! New best EMA pseudo Dice: 0.6880999803543091
2025-10-02 17:52:20.133721: 
2025-10-02 17:52:20.134137: Epoch 78
2025-10-02 17:52:20.134518: Current learning rate: 0.00517
2025-10-02 17:53:06.343641: Validation loss did not improve from -0.46295. Patience: 1/50
2025-10-02 17:53:06.344110: train_loss -0.7199
2025-10-02 17:53:06.344280: val_loss -0.4154
2025-10-02 17:53:06.344400: Pseudo dice [np.float32(0.6825)]
2025-10-02 17:53:06.344576: Epoch time: 46.21 s
2025-10-02 17:53:06.982608: 
2025-10-02 17:53:06.983126: Epoch 79
2025-10-02 17:53:06.983532: Current learning rate: 0.0051
2025-10-02 17:53:53.197521: Validation loss did not improve from -0.46295. Patience: 2/50
2025-10-02 17:53:53.197859: train_loss -0.73
2025-10-02 17:53:53.198026: val_loss -0.4567
2025-10-02 17:53:53.198226: Pseudo dice [np.float32(0.7118)]
2025-10-02 17:53:53.198433: Epoch time: 46.22 s
2025-10-02 17:53:53.631118: Yayy! New best EMA pseudo Dice: 0.6898999810218811
2025-10-02 17:53:54.701910: 
2025-10-02 17:53:54.702205: Epoch 80
2025-10-02 17:53:54.702410: Current learning rate: 0.00504
2025-10-02 17:54:40.915755: Validation loss did not improve from -0.46295. Patience: 3/50
2025-10-02 17:54:40.916334: train_loss -0.7298
2025-10-02 17:54:40.916480: val_loss -0.437
2025-10-02 17:54:40.916628: Pseudo dice [np.float32(0.6952)]
2025-10-02 17:54:40.916790: Epoch time: 46.22 s
2025-10-02 17:54:40.916930: Yayy! New best EMA pseudo Dice: 0.690500020980835
2025-10-02 17:54:41.983790: 
2025-10-02 17:54:41.984730: Epoch 81
2025-10-02 17:54:41.985136: Current learning rate: 0.00497
2025-10-02 17:55:28.195740: Validation loss did not improve from -0.46295. Patience: 4/50
2025-10-02 17:55:28.196094: train_loss -0.7337
2025-10-02 17:55:28.196286: val_loss -0.4345
2025-10-02 17:55:28.196421: Pseudo dice [np.float32(0.6891)]
2025-10-02 17:55:28.196574: Epoch time: 46.21 s
2025-10-02 17:55:28.835109: 
2025-10-02 17:55:28.835666: Epoch 82
2025-10-02 17:55:28.836086: Current learning rate: 0.00491
2025-10-02 17:56:15.026890: Validation loss did not improve from -0.46295. Patience: 5/50
2025-10-02 17:56:15.027636: train_loss -0.7366
2025-10-02 17:56:15.027971: val_loss -0.4161
2025-10-02 17:56:15.028195: Pseudo dice [np.float32(0.6945)]
2025-10-02 17:56:15.028400: Epoch time: 46.19 s
2025-10-02 17:56:15.028592: Yayy! New best EMA pseudo Dice: 0.6908000111579895
2025-10-02 17:56:16.077655: 
2025-10-02 17:56:16.077938: Epoch 83
2025-10-02 17:56:16.078181: Current learning rate: 0.00484
2025-10-02 17:57:02.273171: Validation loss improved from -0.46295 to -0.46456! Patience: 5/50
2025-10-02 17:57:02.273598: train_loss -0.7383
2025-10-02 17:57:02.273901: val_loss -0.4646
2025-10-02 17:57:02.274133: Pseudo dice [np.float32(0.7153)]
2025-10-02 17:57:02.274379: Epoch time: 46.2 s
2025-10-02 17:57:02.274647: Yayy! New best EMA pseudo Dice: 0.6931999921798706
2025-10-02 17:57:03.341545: 
2025-10-02 17:57:03.341982: Epoch 84
2025-10-02 17:57:03.342315: Current learning rate: 0.00478
2025-10-02 17:57:49.508555: Validation loss did not improve from -0.46456. Patience: 1/50
2025-10-02 17:57:49.509236: train_loss -0.7406
2025-10-02 17:57:49.509401: val_loss -0.4261
2025-10-02 17:57:49.509569: Pseudo dice [np.float32(0.6906)]
2025-10-02 17:57:49.509758: Epoch time: 46.17 s
2025-10-02 17:57:50.559270: 
2025-10-02 17:57:50.559611: Epoch 85
2025-10-02 17:57:50.559842: Current learning rate: 0.00471
2025-10-02 17:58:36.774052: Validation loss did not improve from -0.46456. Patience: 2/50
2025-10-02 17:58:36.774498: train_loss -0.7393
2025-10-02 17:58:36.774673: val_loss -0.4469
2025-10-02 17:58:36.774808: Pseudo dice [np.float32(0.7043)]
2025-10-02 17:58:36.774976: Epoch time: 46.22 s
2025-10-02 17:58:36.775112: Yayy! New best EMA pseudo Dice: 0.694100022315979
2025-10-02 17:58:37.820612: 
2025-10-02 17:58:37.821076: Epoch 86
2025-10-02 17:58:37.821320: Current learning rate: 0.00465
2025-10-02 17:59:23.957684: Validation loss did not improve from -0.46456. Patience: 3/50
2025-10-02 17:59:23.958624: train_loss -0.7441
2025-10-02 17:59:23.958776: val_loss -0.4526
2025-10-02 17:59:23.958916: Pseudo dice [np.float32(0.7047)]
2025-10-02 17:59:23.959055: Epoch time: 46.14 s
2025-10-02 17:59:23.959198: Yayy! New best EMA pseudo Dice: 0.6951000094413757
2025-10-02 17:59:25.012103: 
2025-10-02 17:59:25.012496: Epoch 87
2025-10-02 17:59:25.012925: Current learning rate: 0.00458
2025-10-02 18:00:11.132149: Validation loss did not improve from -0.46456. Patience: 4/50
2025-10-02 18:00:11.132571: train_loss -0.7445
2025-10-02 18:00:11.132820: val_loss -0.4126
2025-10-02 18:00:11.133008: Pseudo dice [np.float32(0.6843)]
2025-10-02 18:00:11.133166: Epoch time: 46.12 s
2025-10-02 18:00:11.746203: 
2025-10-02 18:00:11.746489: Epoch 88
2025-10-02 18:00:11.746671: Current learning rate: 0.00452
2025-10-02 18:00:57.886436: Validation loss did not improve from -0.46456. Patience: 5/50
2025-10-02 18:00:57.887764: train_loss -0.7386
2025-10-02 18:00:57.888142: val_loss -0.411
2025-10-02 18:00:57.888406: Pseudo dice [np.float32(0.6862)]
2025-10-02 18:00:57.888538: Epoch time: 46.14 s
2025-10-02 18:00:58.505350: 
2025-10-02 18:00:58.505804: Epoch 89
2025-10-02 18:00:58.506267: Current learning rate: 0.00445
2025-10-02 18:01:44.590544: Validation loss did not improve from -0.46456. Patience: 6/50
2025-10-02 18:01:44.591092: train_loss -0.7549
2025-10-02 18:01:44.591449: val_loss -0.4261
2025-10-02 18:01:44.591801: Pseudo dice [np.float32(0.6908)]
2025-10-02 18:01:44.592245: Epoch time: 46.09 s
2025-10-02 18:01:46.032731: 
2025-10-02 18:01:46.033003: Epoch 90
2025-10-02 18:01:46.033206: Current learning rate: 0.00438
2025-10-02 18:02:32.106363: Validation loss did not improve from -0.46456. Patience: 7/50
2025-10-02 18:02:32.107476: train_loss -0.7527
2025-10-02 18:02:32.107833: val_loss -0.3934
2025-10-02 18:02:32.108171: Pseudo dice [np.float32(0.6683)]
2025-10-02 18:02:32.108498: Epoch time: 46.08 s
2025-10-02 18:02:32.726528: 
2025-10-02 18:02:32.726875: Epoch 91
2025-10-02 18:02:32.727078: Current learning rate: 0.00432
2025-10-02 18:03:18.793214: Validation loss did not improve from -0.46456. Patience: 8/50
2025-10-02 18:03:18.793725: train_loss -0.7565
2025-10-02 18:03:18.794037: val_loss -0.3981
2025-10-02 18:03:18.794298: Pseudo dice [np.float32(0.6855)]
2025-10-02 18:03:18.794532: Epoch time: 46.07 s
2025-10-02 18:03:19.411150: 
2025-10-02 18:03:19.411495: Epoch 92
2025-10-02 18:03:19.411704: Current learning rate: 0.00425
2025-10-02 18:04:05.479579: Validation loss did not improve from -0.46456. Patience: 9/50
2025-10-02 18:04:05.480905: train_loss -0.7521
2025-10-02 18:04:05.481401: val_loss -0.4195
2025-10-02 18:04:05.481821: Pseudo dice [np.float32(0.6904)]
2025-10-02 18:04:05.482281: Epoch time: 46.07 s
2025-10-02 18:04:06.103945: 
2025-10-02 18:04:06.104292: Epoch 93
2025-10-02 18:04:06.104471: Current learning rate: 0.00419
2025-10-02 18:04:52.174415: Validation loss did not improve from -0.46456. Patience: 10/50
2025-10-02 18:04:52.174757: train_loss -0.7569
2025-10-02 18:04:52.174935: val_loss -0.3836
2025-10-02 18:04:52.175099: Pseudo dice [np.float32(0.6715)]
2025-10-02 18:04:52.175314: Epoch time: 46.07 s
2025-10-02 18:04:52.795069: 
2025-10-02 18:04:52.795521: Epoch 94
2025-10-02 18:04:52.795813: Current learning rate: 0.00412
2025-10-02 18:05:38.913279: Validation loss did not improve from -0.46456. Patience: 11/50
2025-10-02 18:05:38.913864: train_loss -0.763
2025-10-02 18:05:38.914016: val_loss -0.3969
2025-10-02 18:05:38.914144: Pseudo dice [np.float32(0.676)]
2025-10-02 18:05:38.914294: Epoch time: 46.12 s
2025-10-02 18:05:39.967365: 
2025-10-02 18:05:39.967765: Epoch 95
2025-10-02 18:05:39.968264: Current learning rate: 0.00405
2025-10-02 18:06:26.098661: Validation loss did not improve from -0.46456. Patience: 12/50
2025-10-02 18:06:26.099379: train_loss -0.7512
2025-10-02 18:06:26.099751: val_loss -0.3898
2025-10-02 18:06:26.100089: Pseudo dice [np.float32(0.6705)]
2025-10-02 18:06:26.100479: Epoch time: 46.13 s
2025-10-02 18:06:26.722332: 
2025-10-02 18:06:26.722623: Epoch 96
2025-10-02 18:06:26.722864: Current learning rate: 0.00399
2025-10-02 18:07:12.830323: Validation loss did not improve from -0.46456. Patience: 13/50
2025-10-02 18:07:12.830933: train_loss -0.7601
2025-10-02 18:07:12.831125: val_loss -0.4073
2025-10-02 18:07:12.831294: Pseudo dice [np.float32(0.6938)]
2025-10-02 18:07:12.831427: Epoch time: 46.11 s
2025-10-02 18:07:13.454687: 
2025-10-02 18:07:13.455037: Epoch 97
2025-10-02 18:07:13.455218: Current learning rate: 0.00392
2025-10-02 18:07:59.586646: Validation loss did not improve from -0.46456. Patience: 14/50
2025-10-02 18:07:59.587029: train_loss -0.7665
2025-10-02 18:07:59.587181: val_loss -0.4356
2025-10-02 18:07:59.587305: Pseudo dice [np.float32(0.692)]
2025-10-02 18:07:59.587441: Epoch time: 46.13 s
2025-10-02 18:08:00.212088: 
2025-10-02 18:08:00.212517: Epoch 98
2025-10-02 18:08:00.212946: Current learning rate: 0.00385
2025-10-02 18:08:46.335193: Validation loss did not improve from -0.46456. Patience: 15/50
2025-10-02 18:08:46.336258: train_loss -0.754
2025-10-02 18:08:46.336651: val_loss -0.4037
2025-10-02 18:08:46.336993: Pseudo dice [np.float32(0.6899)]
2025-10-02 18:08:46.337371: Epoch time: 46.12 s
2025-10-02 18:08:46.978305: 
2025-10-02 18:08:46.978758: Epoch 99
2025-10-02 18:08:46.979044: Current learning rate: 0.00379
2025-10-02 18:09:33.152894: Validation loss did not improve from -0.46456. Patience: 16/50
2025-10-02 18:09:33.153463: train_loss -0.7612
2025-10-02 18:09:33.153791: val_loss -0.4149
2025-10-02 18:09:33.154074: Pseudo dice [np.float32(0.6936)]
2025-10-02 18:09:33.154397: Epoch time: 46.18 s
2025-10-02 18:09:34.213898: 
2025-10-02 18:09:34.214285: Epoch 100
2025-10-02 18:09:34.214658: Current learning rate: 0.00372
2025-10-02 18:10:20.383145: Validation loss did not improve from -0.46456. Patience: 17/50
2025-10-02 18:10:20.383846: train_loss -0.7565
2025-10-02 18:10:20.384094: val_loss -0.4298
2025-10-02 18:10:20.384357: Pseudo dice [np.float32(0.6952)]
2025-10-02 18:10:20.384625: Epoch time: 46.17 s
2025-10-02 18:10:21.018547: 
2025-10-02 18:10:21.018892: Epoch 101
2025-10-02 18:10:21.019142: Current learning rate: 0.00365
2025-10-02 18:11:07.194949: Validation loss did not improve from -0.46456. Patience: 18/50
2025-10-02 18:11:07.195559: train_loss -0.7658
2025-10-02 18:11:07.195966: val_loss -0.4394
2025-10-02 18:11:07.196299: Pseudo dice [np.float32(0.6964)]
2025-10-02 18:11:07.196651: Epoch time: 46.18 s
2025-10-02 18:11:07.822356: 
2025-10-02 18:11:07.822871: Epoch 102
2025-10-02 18:11:07.823324: Current learning rate: 0.00359
2025-10-02 18:11:54.000511: Validation loss did not improve from -0.46456. Patience: 19/50
2025-10-02 18:11:54.001650: train_loss -0.7709
2025-10-02 18:11:54.002002: val_loss -0.4115
2025-10-02 18:11:54.002332: Pseudo dice [np.float32(0.6865)]
2025-10-02 18:11:54.002660: Epoch time: 46.18 s
2025-10-02 18:11:54.630637: 
2025-10-02 18:11:54.631003: Epoch 103
2025-10-02 18:11:54.631231: Current learning rate: 0.00352
2025-10-02 18:12:40.794945: Validation loss did not improve from -0.46456. Patience: 20/50
2025-10-02 18:12:40.795368: train_loss -0.7722
2025-10-02 18:12:40.795548: val_loss -0.4136
2025-10-02 18:12:40.795714: Pseudo dice [np.float32(0.686)]
2025-10-02 18:12:40.795889: Epoch time: 46.17 s
2025-10-02 18:12:41.432998: 
2025-10-02 18:12:41.433275: Epoch 104
2025-10-02 18:12:41.433462: Current learning rate: 0.00345
2025-10-02 18:13:27.622275: Validation loss did not improve from -0.46456. Patience: 21/50
2025-10-02 18:13:27.623271: train_loss -0.7786
2025-10-02 18:13:27.623659: val_loss -0.4047
2025-10-02 18:13:27.623872: Pseudo dice [np.float32(0.6851)]
2025-10-02 18:13:27.624233: Epoch time: 46.19 s
2025-10-02 18:13:28.680264: 
2025-10-02 18:13:28.680603: Epoch 105
2025-10-02 18:13:28.680811: Current learning rate: 0.00338
2025-10-02 18:14:14.854840: Validation loss did not improve from -0.46456. Patience: 22/50
2025-10-02 18:14:14.855512: train_loss -0.7769
2025-10-02 18:14:14.856005: val_loss -0.4287
2025-10-02 18:14:14.856354: Pseudo dice [np.float32(0.6993)]
2025-10-02 18:14:14.856698: Epoch time: 46.18 s
2025-10-02 18:14:15.487214: 
2025-10-02 18:14:15.487634: Epoch 106
2025-10-02 18:14:15.487953: Current learning rate: 0.00332
2025-10-02 18:15:01.675479: Validation loss did not improve from -0.46456. Patience: 23/50
2025-10-02 18:15:01.676107: train_loss -0.7771
2025-10-02 18:15:01.676286: val_loss -0.4236
2025-10-02 18:15:01.676428: Pseudo dice [np.float32(0.6974)]
2025-10-02 18:15:01.676583: Epoch time: 46.19 s
2025-10-02 18:15:02.705986: 
2025-10-02 18:15:02.706457: Epoch 107
2025-10-02 18:15:02.706837: Current learning rate: 0.00325
2025-10-02 18:15:48.905563: Validation loss did not improve from -0.46456. Patience: 24/50
2025-10-02 18:15:48.906241: train_loss -0.7808
2025-10-02 18:15:48.906664: val_loss -0.4424
2025-10-02 18:15:48.907028: Pseudo dice [np.float32(0.7064)]
2025-10-02 18:15:48.907402: Epoch time: 46.2 s
2025-10-02 18:15:49.542544: 
2025-10-02 18:15:49.543049: Epoch 108
2025-10-02 18:15:49.543458: Current learning rate: 0.00318
2025-10-02 18:16:35.789353: Validation loss did not improve from -0.46456. Patience: 25/50
2025-10-02 18:16:35.790564: train_loss -0.779
2025-10-02 18:16:35.790942: val_loss -0.4062
2025-10-02 18:16:35.791302: Pseudo dice [np.float32(0.6754)]
2025-10-02 18:16:35.791650: Epoch time: 46.25 s
2025-10-02 18:16:36.420432: 
2025-10-02 18:16:36.420862: Epoch 109
2025-10-02 18:16:36.421110: Current learning rate: 0.00311
2025-10-02 18:17:22.667627: Validation loss did not improve from -0.46456. Patience: 26/50
2025-10-02 18:17:22.668141: train_loss -0.7827
2025-10-02 18:17:22.668358: val_loss -0.4141
2025-10-02 18:17:22.668497: Pseudo dice [np.float32(0.6984)]
2025-10-02 18:17:22.668667: Epoch time: 46.25 s
2025-10-02 18:17:23.728037: 
2025-10-02 18:17:23.728310: Epoch 110
2025-10-02 18:17:23.728534: Current learning rate: 0.00304
2025-10-02 18:18:09.936412: Validation loss did not improve from -0.46456. Patience: 27/50
2025-10-02 18:18:09.937204: train_loss -0.7792
2025-10-02 18:18:09.937417: val_loss -0.4172
2025-10-02 18:18:09.937616: Pseudo dice [np.float32(0.6985)]
2025-10-02 18:18:09.937850: Epoch time: 46.21 s
2025-10-02 18:18:10.572054: 
2025-10-02 18:18:10.572361: Epoch 111
2025-10-02 18:18:10.572548: Current learning rate: 0.00297
2025-10-02 18:18:56.784395: Validation loss did not improve from -0.46456. Patience: 28/50
2025-10-02 18:18:56.784906: train_loss -0.7882
2025-10-02 18:18:56.785187: val_loss -0.4221
2025-10-02 18:18:56.785435: Pseudo dice [np.float32(0.6869)]
2025-10-02 18:18:56.785696: Epoch time: 46.21 s
2025-10-02 18:18:57.413434: 
2025-10-02 18:18:57.413825: Epoch 112
2025-10-02 18:18:57.414184: Current learning rate: 0.00291
2025-10-02 18:19:43.682459: Validation loss did not improve from -0.46456. Patience: 29/50
2025-10-02 18:19:43.684468: train_loss -0.7863
2025-10-02 18:19:43.684931: val_loss -0.4349
2025-10-02 18:19:43.685394: Pseudo dice [np.float32(0.7058)]
2025-10-02 18:19:43.685836: Epoch time: 46.27 s
2025-10-02 18:19:44.321103: 
2025-10-02 18:19:44.321460: Epoch 113
2025-10-02 18:19:44.321739: Current learning rate: 0.00284
2025-10-02 18:20:30.564698: Validation loss did not improve from -0.46456. Patience: 30/50
2025-10-02 18:20:30.565115: train_loss -0.7899
2025-10-02 18:20:30.565324: val_loss -0.4402
2025-10-02 18:20:30.565484: Pseudo dice [np.float32(0.7014)]
2025-10-02 18:20:30.565690: Epoch time: 46.24 s
2025-10-02 18:20:31.192748: 
2025-10-02 18:20:31.193221: Epoch 114
2025-10-02 18:20:31.193578: Current learning rate: 0.00277
2025-10-02 18:21:17.462339: Validation loss did not improve from -0.46456. Patience: 31/50
2025-10-02 18:21:17.463015: train_loss -0.79
2025-10-02 18:21:17.463168: val_loss -0.4608
2025-10-02 18:21:17.463323: Pseudo dice [np.float32(0.7066)]
2025-10-02 18:21:17.463479: Epoch time: 46.27 s
2025-10-02 18:21:18.516868: 
2025-10-02 18:21:18.517387: Epoch 115
2025-10-02 18:21:18.517752: Current learning rate: 0.0027
2025-10-02 18:22:04.765816: Validation loss did not improve from -0.46456. Patience: 32/50
2025-10-02 18:22:04.766310: train_loss -0.7922
2025-10-02 18:22:04.766484: val_loss -0.3875
2025-10-02 18:22:04.766612: Pseudo dice [np.float32(0.6803)]
2025-10-02 18:22:04.766752: Epoch time: 46.25 s
2025-10-02 18:22:05.399748: 
2025-10-02 18:22:05.400252: Epoch 116
2025-10-02 18:22:05.400625: Current learning rate: 0.00263
2025-10-02 18:22:51.678885: Validation loss did not improve from -0.46456. Patience: 33/50
2025-10-02 18:22:51.679507: train_loss -0.7908
2025-10-02 18:22:51.679701: val_loss -0.4091
2025-10-02 18:22:51.679831: Pseudo dice [np.float32(0.6981)]
2025-10-02 18:22:51.679964: Epoch time: 46.28 s
2025-10-02 18:22:52.312082: 
2025-10-02 18:22:52.312414: Epoch 117
2025-10-02 18:22:52.312606: Current learning rate: 0.00256
2025-10-02 18:23:38.578801: Validation loss did not improve from -0.46456. Patience: 34/50
2025-10-02 18:23:38.579405: train_loss -0.7959
2025-10-02 18:23:38.579791: val_loss -0.3794
2025-10-02 18:23:38.580145: Pseudo dice [np.float32(0.6869)]
2025-10-02 18:23:38.580524: Epoch time: 46.27 s
2025-10-02 18:23:39.214638: 
2025-10-02 18:23:39.214898: Epoch 118
2025-10-02 18:23:39.215074: Current learning rate: 0.00249
2025-10-02 18:24:25.463681: Validation loss did not improve from -0.46456. Patience: 35/50
2025-10-02 18:24:25.464877: train_loss -0.7967
2025-10-02 18:24:25.465244: val_loss -0.4003
2025-10-02 18:24:25.465607: Pseudo dice [np.float32(0.6942)]
2025-10-02 18:24:25.465983: Epoch time: 46.25 s
2025-10-02 18:24:26.103735: 
2025-10-02 18:24:26.104046: Epoch 119
2025-10-02 18:24:26.104244: Current learning rate: 0.00242
2025-10-02 18:25:12.319920: Validation loss did not improve from -0.46456. Patience: 36/50
2025-10-02 18:25:12.320549: train_loss -0.8052
2025-10-02 18:25:12.320961: val_loss -0.395
2025-10-02 18:25:12.321337: Pseudo dice [np.float32(0.6941)]
2025-10-02 18:25:12.321741: Epoch time: 46.22 s
2025-10-02 18:25:13.395555: 
2025-10-02 18:25:13.395923: Epoch 120
2025-10-02 18:25:13.396159: Current learning rate: 0.00235
2025-10-02 18:25:59.632109: Validation loss did not improve from -0.46456. Patience: 37/50
2025-10-02 18:25:59.633374: train_loss -0.8014
2025-10-02 18:25:59.633884: val_loss -0.4075
2025-10-02 18:25:59.634446: Pseudo dice [np.float32(0.7022)]
2025-10-02 18:25:59.634929: Epoch time: 46.24 s
2025-10-02 18:26:00.276579: 
2025-10-02 18:26:00.276961: Epoch 121
2025-10-02 18:26:00.277381: Current learning rate: 0.00228
2025-10-02 18:26:46.532809: Validation loss did not improve from -0.46456. Patience: 38/50
2025-10-02 18:26:46.533432: train_loss -0.8034
2025-10-02 18:26:46.533622: val_loss -0.4055
2025-10-02 18:26:46.533793: Pseudo dice [np.float32(0.6929)]
2025-10-02 18:26:46.533937: Epoch time: 46.26 s
2025-10-02 18:26:47.575233: 
2025-10-02 18:26:47.575801: Epoch 122
2025-10-02 18:26:47.576250: Current learning rate: 0.00221
2025-10-02 18:27:33.814332: Validation loss did not improve from -0.46456. Patience: 39/50
2025-10-02 18:27:33.814947: train_loss -0.803
2025-10-02 18:27:33.815116: val_loss -0.4333
2025-10-02 18:27:33.815322: Pseudo dice [np.float32(0.7186)]
2025-10-02 18:27:33.815657: Epoch time: 46.24 s
2025-10-02 18:27:33.816048: Yayy! New best EMA pseudo Dice: 0.6966000199317932
2025-10-02 18:27:34.890952: 
2025-10-02 18:27:34.891394: Epoch 123
2025-10-02 18:27:34.891713: Current learning rate: 0.00214
2025-10-02 18:28:21.091666: Validation loss did not improve from -0.46456. Patience: 40/50
2025-10-02 18:28:21.092108: train_loss -0.8052
2025-10-02 18:28:21.092301: val_loss -0.3964
2025-10-02 18:28:21.092453: Pseudo dice [np.float32(0.6894)]
2025-10-02 18:28:21.092666: Epoch time: 46.2 s
2025-10-02 18:28:21.726579: 
2025-10-02 18:28:21.726851: Epoch 124
2025-10-02 18:28:21.727035: Current learning rate: 0.00207
2025-10-02 18:29:07.847502: Validation loss did not improve from -0.46456. Patience: 41/50
2025-10-02 18:29:07.848648: train_loss -0.8109
2025-10-02 18:29:07.849010: val_loss -0.3827
2025-10-02 18:29:07.849318: Pseudo dice [np.float32(0.6854)]
2025-10-02 18:29:07.849648: Epoch time: 46.12 s
2025-10-02 18:29:08.919536: 
2025-10-02 18:29:08.919981: Epoch 125
2025-10-02 18:29:08.920170: Current learning rate: 0.00199
2025-10-02 18:29:55.015432: Validation loss did not improve from -0.46456. Patience: 42/50
2025-10-02 18:29:55.015920: train_loss -0.8079
2025-10-02 18:29:55.016150: val_loss -0.4151
2025-10-02 18:29:55.016408: Pseudo dice [np.float32(0.7018)]
2025-10-02 18:29:55.016681: Epoch time: 46.1 s
2025-10-02 18:29:55.661678: 
2025-10-02 18:29:55.662046: Epoch 126
2025-10-02 18:29:55.662275: Current learning rate: 0.00192
2025-10-02 18:30:41.733638: Validation loss did not improve from -0.46456. Patience: 43/50
2025-10-02 18:30:41.734874: train_loss -0.8119
2025-10-02 18:30:41.735223: val_loss -0.3914
2025-10-02 18:30:41.735579: Pseudo dice [np.float32(0.6914)]
2025-10-02 18:30:41.735769: Epoch time: 46.07 s
2025-10-02 18:30:42.369549: 
2025-10-02 18:30:42.369877: Epoch 127
2025-10-02 18:30:42.370069: Current learning rate: 0.00185
2025-10-02 18:31:28.472070: Validation loss did not improve from -0.46456. Patience: 44/50
2025-10-02 18:31:28.472607: train_loss -0.8158
2025-10-02 18:31:28.472900: val_loss -0.4111
2025-10-02 18:31:28.473189: Pseudo dice [np.float32(0.6964)]
2025-10-02 18:31:28.473550: Epoch time: 46.1 s
2025-10-02 18:31:29.109998: 
2025-10-02 18:31:29.110522: Epoch 128
2025-10-02 18:31:29.110834: Current learning rate: 0.00178
2025-10-02 18:32:15.231919: Validation loss did not improve from -0.46456. Patience: 45/50
2025-10-02 18:32:15.232596: train_loss -0.8151
2025-10-02 18:32:15.232777: val_loss -0.4531
2025-10-02 18:32:15.232927: Pseudo dice [np.float32(0.7119)]
2025-10-02 18:32:15.233088: Epoch time: 46.12 s
2025-10-02 18:32:15.233291: Yayy! New best EMA pseudo Dice: 0.6969000101089478
2025-10-02 18:32:16.300076: 
2025-10-02 18:32:16.300582: Epoch 129
2025-10-02 18:32:16.300948: Current learning rate: 0.0017
2025-10-02 18:33:02.358459: Validation loss did not improve from -0.46456. Patience: 46/50
2025-10-02 18:33:02.359004: train_loss -0.8152
2025-10-02 18:33:02.359335: val_loss -0.4271
2025-10-02 18:33:02.359628: Pseudo dice [np.float32(0.7043)]
2025-10-02 18:33:02.359967: Epoch time: 46.06 s
2025-10-02 18:33:02.802455: Yayy! New best EMA pseudo Dice: 0.6976000070571899
2025-10-02 18:33:03.836391: 
2025-10-02 18:33:03.836891: Epoch 130
2025-10-02 18:33:03.837249: Current learning rate: 0.00163
2025-10-02 18:33:49.935705: Validation loss did not improve from -0.46456. Patience: 47/50
2025-10-02 18:33:49.936341: train_loss -0.8134
2025-10-02 18:33:49.936504: val_loss -0.4383
2025-10-02 18:33:49.936651: Pseudo dice [np.float32(0.7042)]
2025-10-02 18:33:49.936804: Epoch time: 46.1 s
2025-10-02 18:33:49.936928: Yayy! New best EMA pseudo Dice: 0.6983000040054321
2025-10-02 18:33:51.005543: 
2025-10-02 18:33:51.005844: Epoch 131
2025-10-02 18:33:51.006085: Current learning rate: 0.00156
2025-10-02 18:34:37.087861: Validation loss did not improve from -0.46456. Patience: 48/50
2025-10-02 18:34:37.088467: train_loss -0.8172
2025-10-02 18:34:37.089065: val_loss -0.3811
2025-10-02 18:34:37.089453: Pseudo dice [np.float32(0.6861)]
2025-10-02 18:34:37.089822: Epoch time: 46.08 s
2025-10-02 18:34:37.712380: 
2025-10-02 18:34:37.712633: Epoch 132
2025-10-02 18:34:37.712806: Current learning rate: 0.00148
2025-10-02 18:35:23.822787: Validation loss did not improve from -0.46456. Patience: 49/50
2025-10-02 18:35:23.823403: train_loss -0.8178
2025-10-02 18:35:23.823576: val_loss -0.3935
2025-10-02 18:35:23.823725: Pseudo dice [np.float32(0.7005)]
2025-10-02 18:35:23.823906: Epoch time: 46.11 s
2025-10-02 18:35:24.447531: 
2025-10-02 18:35:24.447827: Epoch 133
2025-10-02 18:35:24.448009: Current learning rate: 0.00141
2025-10-02 18:36:10.514837: Validation loss did not improve from -0.46456. Patience: 50/50
2025-10-02 18:36:10.515175: train_loss -0.8176
2025-10-02 18:36:10.515368: val_loss -0.4076
2025-10-02 18:36:10.515497: Pseudo dice [np.float32(0.697)]
2025-10-02 18:36:10.515628: Epoch time: 46.07 s
2025-10-02 18:36:11.135719: 
2025-10-02 18:36:11.136151: Epoch 134
2025-10-02 18:36:11.136432: Current learning rate: 0.00133
2025-10-02 18:36:57.212213: Validation loss did not improve from -0.46456. Patience: 51/50
2025-10-02 18:36:57.212807: train_loss -0.8204
2025-10-02 18:36:57.212948: val_loss -0.4289
2025-10-02 18:36:57.213068: Pseudo dice [np.float32(0.7036)]
2025-10-02 18:36:57.213205: Epoch time: 46.08 s
2025-10-02 18:36:58.287317: 
2025-10-02 18:36:58.287650: Epoch 135
2025-10-02 18:36:58.287827: Current learning rate: 0.00126
2025-10-02 18:37:44.467868: Validation loss did not improve from -0.46456. Patience: 52/50
2025-10-02 18:37:44.468570: train_loss -0.8183
2025-10-02 18:37:44.469013: val_loss -0.4086
2025-10-02 18:37:44.469415: Pseudo dice [np.float32(0.6971)]
2025-10-02 18:37:44.469836: Epoch time: 46.18 s
2025-10-02 18:37:45.096800: 
2025-10-02 18:37:45.097072: Epoch 136
2025-10-02 18:37:45.097286: Current learning rate: 0.00118
2025-10-02 18:38:31.324310: Validation loss did not improve from -0.46456. Patience: 53/50
2025-10-02 18:38:31.325006: train_loss -0.8204
2025-10-02 18:38:31.325276: val_loss -0.4155
2025-10-02 18:38:31.325528: Pseudo dice [np.float32(0.7024)]
2025-10-02 18:38:31.325765: Epoch time: 46.23 s
2025-10-02 18:38:31.325944: Yayy! New best EMA pseudo Dice: 0.6984000205993652
2025-10-02 18:38:32.398550: 
2025-10-02 18:38:32.398796: Epoch 137
2025-10-02 18:38:32.399077: Current learning rate: 0.00111
2025-10-02 18:39:18.595011: Validation loss did not improve from -0.46456. Patience: 54/50
2025-10-02 18:39:18.595446: train_loss -0.8228
2025-10-02 18:39:18.595614: val_loss -0.4055
2025-10-02 18:39:18.595743: Pseudo dice [np.float32(0.6951)]
2025-10-02 18:39:18.595881: Epoch time: 46.2 s
2025-10-02 18:39:19.586730: 
2025-10-02 18:39:19.587096: Epoch 138
2025-10-02 18:39:19.587327: Current learning rate: 0.00103
2025-10-02 18:40:05.790130: Validation loss did not improve from -0.46456. Patience: 55/50
2025-10-02 18:40:05.791371: train_loss -0.828
2025-10-02 18:40:05.791816: val_loss -0.4234
2025-10-02 18:40:05.792192: Pseudo dice [np.float32(0.7077)]
2025-10-02 18:40:05.792623: Epoch time: 46.21 s
2025-10-02 18:40:05.793025: Yayy! New best EMA pseudo Dice: 0.6990000009536743
2025-10-02 18:40:06.860447: 
2025-10-02 18:40:06.860800: Epoch 139
2025-10-02 18:40:06.861197: Current learning rate: 0.00095
2025-10-02 18:40:53.121050: Validation loss did not improve from -0.46456. Patience: 56/50
2025-10-02 18:40:53.121466: train_loss -0.8278
2025-10-02 18:40:53.121686: val_loss -0.4466
2025-10-02 18:40:53.121834: Pseudo dice [np.float32(0.7172)]
2025-10-02 18:40:53.122104: Epoch time: 46.26 s
2025-10-02 18:40:53.568948: Yayy! New best EMA pseudo Dice: 0.7008000016212463
2025-10-02 18:40:54.625780: 
2025-10-02 18:40:54.626126: Epoch 140
2025-10-02 18:40:54.626328: Current learning rate: 0.00087
2025-10-02 18:41:40.868781: Validation loss did not improve from -0.46456. Patience: 57/50
2025-10-02 18:41:40.869629: train_loss -0.8238
2025-10-02 18:41:40.869806: val_loss -0.3827
2025-10-02 18:41:40.869954: Pseudo dice [np.float32(0.6935)]
2025-10-02 18:41:40.870124: Epoch time: 46.24 s
2025-10-02 18:41:41.505096: 
2025-10-02 18:41:41.505468: Epoch 141
2025-10-02 18:41:41.505701: Current learning rate: 0.00079
2025-10-02 18:42:27.788471: Validation loss did not improve from -0.46456. Patience: 58/50
2025-10-02 18:42:27.788951: train_loss -0.8281
2025-10-02 18:42:27.789207: val_loss -0.3907
2025-10-02 18:42:27.789505: Pseudo dice [np.float32(0.7032)]
2025-10-02 18:42:27.789739: Epoch time: 46.28 s
2025-10-02 18:42:28.418586: 
2025-10-02 18:42:28.418871: Epoch 142
2025-10-02 18:42:28.419063: Current learning rate: 0.00071
2025-10-02 18:43:14.698696: Validation loss did not improve from -0.46456. Patience: 59/50
2025-10-02 18:43:14.699273: train_loss -0.8293
2025-10-02 18:43:14.699427: val_loss -0.4026
2025-10-02 18:43:14.699577: Pseudo dice [np.float32(0.7016)]
2025-10-02 18:43:14.699713: Epoch time: 46.28 s
2025-10-02 18:43:15.330742: 
2025-10-02 18:43:15.331082: Epoch 143
2025-10-02 18:43:15.331307: Current learning rate: 0.00063
2025-10-02 18:44:01.598745: Validation loss did not improve from -0.46456. Patience: 60/50
2025-10-02 18:44:01.599373: train_loss -0.8281
2025-10-02 18:44:01.599877: val_loss -0.3864
2025-10-02 18:44:01.600279: Pseudo dice [np.float32(0.6934)]
2025-10-02 18:44:01.600644: Epoch time: 46.27 s
2025-10-02 18:44:02.228189: 
2025-10-02 18:44:02.228531: Epoch 144
2025-10-02 18:44:02.228742: Current learning rate: 0.00055
2025-10-02 18:44:48.482635: Validation loss did not improve from -0.46456. Patience: 61/50
2025-10-02 18:44:48.483268: train_loss -0.8323
2025-10-02 18:44:48.483452: val_loss -0.4001
2025-10-02 18:44:48.483599: Pseudo dice [np.float32(0.6992)]
2025-10-02 18:44:48.483755: Epoch time: 46.26 s
2025-10-02 18:44:49.558705: 
2025-10-02 18:44:49.559059: Epoch 145
2025-10-02 18:44:49.559265: Current learning rate: 0.00047
2025-10-02 18:45:35.811559: Validation loss did not improve from -0.46456. Patience: 62/50
2025-10-02 18:45:35.812140: train_loss -0.8323
2025-10-02 18:45:35.812524: val_loss -0.3983
2025-10-02 18:45:35.812650: Pseudo dice [np.float32(0.6941)]
2025-10-02 18:45:35.812782: Epoch time: 46.25 s
2025-10-02 18:45:36.445822: 
2025-10-02 18:45:36.446164: Epoch 146
2025-10-02 18:45:36.446394: Current learning rate: 0.00038
2025-10-02 18:46:22.712354: Validation loss did not improve from -0.46456. Patience: 63/50
2025-10-02 18:46:22.713341: train_loss -0.8347
2025-10-02 18:46:22.713673: val_loss -0.4288
2025-10-02 18:46:22.714008: Pseudo dice [np.float32(0.7028)]
2025-10-02 18:46:22.714340: Epoch time: 46.27 s
2025-10-02 18:46:23.348548: 
2025-10-02 18:46:23.348916: Epoch 147
2025-10-02 18:46:23.349118: Current learning rate: 0.0003
2025-10-02 18:47:09.664254: Validation loss did not improve from -0.46456. Patience: 64/50
2025-10-02 18:47:09.664697: train_loss -0.8315
2025-10-02 18:47:09.664914: val_loss -0.3982
2025-10-02 18:47:09.665070: Pseudo dice [np.float32(0.7011)]
2025-10-02 18:47:09.665243: Epoch time: 46.32 s
2025-10-02 18:47:10.296180: 
2025-10-02 18:47:10.296434: Epoch 148
2025-10-02 18:47:10.296625: Current learning rate: 0.00021
2025-10-02 18:47:56.533021: Validation loss did not improve from -0.46456. Patience: 65/50
2025-10-02 18:47:56.534362: train_loss -0.8327
2025-10-02 18:47:56.534763: val_loss -0.3858
2025-10-02 18:47:56.535172: Pseudo dice [np.float32(0.6914)]
2025-10-02 18:47:56.535614: Epoch time: 46.24 s
2025-10-02 18:47:57.165330: 
2025-10-02 18:47:57.165726: Epoch 149
2025-10-02 18:47:57.166094: Current learning rate: 0.00011
2025-10-02 18:48:43.441377: Validation loss did not improve from -0.46456. Patience: 66/50
2025-10-02 18:48:43.442091: train_loss -0.8355
2025-10-02 18:48:43.442638: val_loss -0.3988
2025-10-02 18:48:43.443022: Pseudo dice [np.float32(0.6955)]
2025-10-02 18:48:43.443426: Epoch time: 46.28 s
2025-10-02 18:48:44.537812: Training done.
2025-10-02 18:48:44.554544: Using splits from existing split file: /nfs/erelab001/shared/Computational_Group/Naravich/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset310_nnInteractive_Calcium_OCT_CrossValidation/splits_final.json
2025-10-02 18:48:44.555178: The split file contains 5 splits.
2025-10-02 18:48:44.555591: Desired fold for training: 1
2025-10-02 18:48:44.556033: This split has 6 training and 2 validation cases.
2025-10-02 18:48:44.556549: predicting 101-019
2025-10-02 18:48:44.559822: 101-019, shape torch.Size([1, 375, 498, 498]), rank 0
2025-10-02 18:49:31.647035: predicting 401-004
2025-10-02 18:49:31.663578: 401-004, shape torch.Size([1, 375, 498, 498]), rank 0
2025-10-02 18:50:18.587538: Validation complete
2025-10-02 18:50:18.587894: Mean Validation Dice:  0.6746813215719083
Finished training fold 1 saving to /nfs/erelab001/shared/Computational_Group/Naravich/datasets/nnUNet_Datasets/nnUNet_results/Dataset310_nnInteractive_Calcium_OCT_CrossValidation/nnUNetTrainer__nnUNetPlans__3d_32x160x128_b10/fold_1_No_Pretrained
