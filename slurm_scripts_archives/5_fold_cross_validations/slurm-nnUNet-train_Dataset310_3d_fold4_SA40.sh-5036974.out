/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/bin/python
Starting training with CONFIG=3d_32x160x128_b10, DATASET_ID=310, TRAINER=nnUNetTrainerScaleAnalysis40
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:169: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2025-10-06 01:13:13.204576: do_dummy_2d_data_aug: True
2025-10-06 01:13:13.205090: Using splits from existing split file: /nfs/erelab001/shared/Computational_Group/Naravich/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset310_nnInteractive_Calcium_OCT_CrossValidation/splits_final_40.json
2025-10-06 01:13:13.205292: The split file contains 5 splits.
2025-10-06 01:13:13.205391: Desired fold for training: 4
2025-10-06 01:13:13.205486: This split has 3 training and 5 validation cases.
using pin_memory on device 0
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
using pin_memory on device 0
2025-10-06 01:13:16.988866: Using torch.compile...

This is the configuration used by this training:
Configuration name: 3d_32x160x128_b10
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 10, 'patch_size': [32, 160, 128], 'median_image_size_in_voxels': [375.0, 498.0, 498.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'inherits_from': '3d_fullres'} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset310_nnInteractive_Calcium_OCT_CrossValidation', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.4977976381778717, 'mean': 0.1394134759902954, 'median': 0.09849607944488525, 'min': 0.0, 'percentile_00_5': 0.015305490233004093, 'percentile_99_5': 0.4977976381778717, 'std': 0.121165432035923}}} 

2025-10-06 01:13:18.778836: unpacking dataset...
2025-10-06 01:13:23.085402: unpacking done...
2025-10-06 01:13:23.087559: Unable to plot network architecture: nnUNet_compile is enabled!
2025-10-06 01:13:23.092571: 
2025-10-06 01:13:23.092797: Epoch 0
2025-10-06 01:13:23.092975: Current learning rate: 0.01
2025-10-06 01:14:15.583912: Validation loss improved from 1000.00000 to -0.12537! Patience: 0/50
2025-10-06 01:14:15.584595: train_loss -0.1728
2025-10-06 01:14:15.584777: val_loss -0.1254
2025-10-06 01:14:15.584966: Pseudo dice [np.float32(0.5128)]
2025-10-06 01:14:15.585106: Epoch time: 52.49 s
2025-10-06 01:14:15.585226: Yayy! New best EMA pseudo Dice: 0.5127999782562256
2025-10-06 01:14:16.760166: 
2025-10-06 01:14:16.760520: Epoch 1
2025-10-06 01:14:16.760704: Current learning rate: 0.00994
2025-10-06 01:15:03.060109: Validation loss improved from -0.12537 to -0.20130! Patience: 0/50
2025-10-06 01:15:03.060672: train_loss -0.2891
2025-10-06 01:15:03.060936: val_loss -0.2013
2025-10-06 01:15:03.061228: Pseudo dice [np.float32(0.5546)]
2025-10-06 01:15:03.061362: Epoch time: 46.3 s
2025-10-06 01:15:03.061558: Yayy! New best EMA pseudo Dice: 0.5170000195503235
2025-10-06 01:15:04.125545: 
2025-10-06 01:15:04.125766: Epoch 2
2025-10-06 01:15:04.125931: Current learning rate: 0.00988
2025-10-06 01:15:50.565733: Validation loss improved from -0.20130 to -0.21243! Patience: 0/50
2025-10-06 01:15:50.566283: train_loss -0.3226
2025-10-06 01:15:50.566468: val_loss -0.2124
2025-10-06 01:15:50.566610: Pseudo dice [np.float32(0.5656)]
2025-10-06 01:15:50.566758: Epoch time: 46.44 s
2025-10-06 01:15:50.566873: Yayy! New best EMA pseudo Dice: 0.5218999981880188
2025-10-06 01:15:51.650522: 
2025-10-06 01:15:51.650784: Epoch 3
2025-10-06 01:15:51.651042: Current learning rate: 0.00982
2025-10-06 01:16:38.074702: Validation loss improved from -0.21243 to -0.28667! Patience: 0/50
2025-10-06 01:16:38.075250: train_loss -0.3958
2025-10-06 01:16:38.075427: val_loss -0.2867
2025-10-06 01:16:38.075542: Pseudo dice [np.float32(0.6099)]
2025-10-06 01:16:38.075692: Epoch time: 46.43 s
2025-10-06 01:16:38.075816: Yayy! New best EMA pseudo Dice: 0.5307000279426575
2025-10-06 01:16:39.166207: 
2025-10-06 01:16:39.166586: Epoch 4
2025-10-06 01:16:39.166834: Current learning rate: 0.00976
2025-10-06 01:17:25.609260: Validation loss did not improve from -0.28667. Patience: 1/50
2025-10-06 01:17:25.609825: train_loss -0.4331
2025-10-06 01:17:25.610064: val_loss -0.225
2025-10-06 01:17:25.610212: Pseudo dice [np.float32(0.5818)]
2025-10-06 01:17:25.610422: Epoch time: 46.44 s
2025-10-06 01:17:25.987303: Yayy! New best EMA pseudo Dice: 0.5357999801635742
2025-10-06 01:17:27.045651: 
2025-10-06 01:17:27.046019: Epoch 5
2025-10-06 01:17:27.046252: Current learning rate: 0.0097
2025-10-06 01:18:13.527598: Validation loss improved from -0.28667 to -0.29783! Patience: 1/50
2025-10-06 01:18:13.528115: train_loss -0.4598
2025-10-06 01:18:13.528343: val_loss -0.2978
2025-10-06 01:18:13.528505: Pseudo dice [np.float32(0.6158)]
2025-10-06 01:18:13.528681: Epoch time: 46.48 s
2025-10-06 01:18:13.528872: Yayy! New best EMA pseudo Dice: 0.5437999963760376
2025-10-06 01:18:14.603400: 
2025-10-06 01:18:14.603682: Epoch 6
2025-10-06 01:18:14.603878: Current learning rate: 0.00964
2025-10-06 01:19:01.119597: Validation loss did not improve from -0.29783. Patience: 1/50
2025-10-06 01:19:01.120304: train_loss -0.4608
2025-10-06 01:19:01.120488: val_loss -0.2933
2025-10-06 01:19:01.120655: Pseudo dice [np.float32(0.6056)]
2025-10-06 01:19:01.120814: Epoch time: 46.52 s
2025-10-06 01:19:01.120943: Yayy! New best EMA pseudo Dice: 0.550000011920929
2025-10-06 01:19:02.211102: 
2025-10-06 01:19:02.211489: Epoch 7
2025-10-06 01:19:02.211751: Current learning rate: 0.00958
2025-10-06 01:19:48.714150: Validation loss improved from -0.29783 to -0.34251! Patience: 1/50
2025-10-06 01:19:48.714712: train_loss -0.4803
2025-10-06 01:19:48.714969: val_loss -0.3425
2025-10-06 01:19:48.715223: Pseudo dice [np.float32(0.6372)]
2025-10-06 01:19:48.715452: Epoch time: 46.5 s
2025-10-06 01:19:48.715644: Yayy! New best EMA pseudo Dice: 0.5587000250816345
2025-10-06 01:19:49.938129: 
2025-10-06 01:19:49.938471: Epoch 8
2025-10-06 01:19:49.938755: Current learning rate: 0.00952
2025-10-06 01:20:36.429918: Validation loss improved from -0.34251 to -0.37009! Patience: 0/50
2025-10-06 01:20:36.430471: train_loss -0.4915
2025-10-06 01:20:36.430615: val_loss -0.3701
2025-10-06 01:20:36.430730: Pseudo dice [np.float32(0.6456)]
2025-10-06 01:20:36.430883: Epoch time: 46.49 s
2025-10-06 01:20:36.431004: Yayy! New best EMA pseudo Dice: 0.5673999786376953
2025-10-06 01:20:37.521125: 
2025-10-06 01:20:37.521528: Epoch 9
2025-10-06 01:20:37.521827: Current learning rate: 0.00946
2025-10-06 01:21:23.890982: Validation loss did not improve from -0.37009. Patience: 1/50
2025-10-06 01:21:23.891677: train_loss -0.512
2025-10-06 01:21:23.891968: val_loss -0.3666
2025-10-06 01:21:23.892191: Pseudo dice [np.float32(0.6407)]
2025-10-06 01:21:23.892426: Epoch time: 46.37 s
2025-10-06 01:21:24.323070: Yayy! New best EMA pseudo Dice: 0.5746999979019165
2025-10-06 01:21:25.379380: 
2025-10-06 01:21:25.379700: Epoch 10
2025-10-06 01:21:25.379872: Current learning rate: 0.0094
2025-10-06 01:22:11.760234: Validation loss did not improve from -0.37009. Patience: 2/50
2025-10-06 01:22:11.760882: train_loss -0.5294
2025-10-06 01:22:11.761024: val_loss -0.2674
2025-10-06 01:22:11.761140: Pseudo dice [np.float32(0.598)]
2025-10-06 01:22:11.761275: Epoch time: 46.38 s
2025-10-06 01:22:11.761386: Yayy! New best EMA pseudo Dice: 0.5770000219345093
2025-10-06 01:22:12.856292: 
2025-10-06 01:22:12.856672: Epoch 11
2025-10-06 01:22:12.856871: Current learning rate: 0.00934
2025-10-06 01:22:59.310350: Validation loss did not improve from -0.37009. Patience: 3/50
2025-10-06 01:22:59.310865: train_loss -0.5301
2025-10-06 01:22:59.311008: val_loss -0.3375
2025-10-06 01:22:59.311120: Pseudo dice [np.float32(0.6335)]
2025-10-06 01:22:59.311275: Epoch time: 46.46 s
2025-10-06 01:22:59.311383: Yayy! New best EMA pseudo Dice: 0.5827000141143799
2025-10-06 01:23:00.779399: 
2025-10-06 01:23:00.779646: Epoch 12
2025-10-06 01:23:00.779832: Current learning rate: 0.00928
2025-10-06 01:23:47.371186: Validation loss improved from -0.37009 to -0.39009! Patience: 3/50
2025-10-06 01:23:47.371901: train_loss -0.5533
2025-10-06 01:23:47.372041: val_loss -0.3901
2025-10-06 01:23:47.372178: Pseudo dice [np.float32(0.6548)]
2025-10-06 01:23:47.372314: Epoch time: 46.59 s
2025-10-06 01:23:47.372461: Yayy! New best EMA pseudo Dice: 0.589900016784668
2025-10-06 01:23:48.469912: 
2025-10-06 01:23:48.470262: Epoch 13
2025-10-06 01:23:48.470492: Current learning rate: 0.00922
2025-10-06 01:24:35.021217: Validation loss did not improve from -0.39009. Patience: 1/50
2025-10-06 01:24:35.021659: train_loss -0.5559
2025-10-06 01:24:35.021941: val_loss -0.3816
2025-10-06 01:24:35.022084: Pseudo dice [np.float32(0.6394)]
2025-10-06 01:24:35.022227: Epoch time: 46.55 s
2025-10-06 01:24:35.022340: Yayy! New best EMA pseudo Dice: 0.5947999954223633
2025-10-06 01:24:36.108786: 
2025-10-06 01:24:36.109066: Epoch 14
2025-10-06 01:24:36.109285: Current learning rate: 0.00916
2025-10-06 01:25:22.621637: Validation loss did not improve from -0.39009. Patience: 2/50
2025-10-06 01:25:22.622279: train_loss -0.5565
2025-10-06 01:25:22.622466: val_loss -0.367
2025-10-06 01:25:22.622612: Pseudo dice [np.float32(0.6432)]
2025-10-06 01:25:22.622783: Epoch time: 46.51 s
2025-10-06 01:25:23.054149: Yayy! New best EMA pseudo Dice: 0.5996999740600586
2025-10-06 01:25:24.130532: 
2025-10-06 01:25:24.130867: Epoch 15
2025-10-06 01:25:24.131109: Current learning rate: 0.0091
2025-10-06 01:26:10.533666: Validation loss improved from -0.39009 to -0.42159! Patience: 2/50
2025-10-06 01:26:10.534285: train_loss -0.5668
2025-10-06 01:26:10.534474: val_loss -0.4216
2025-10-06 01:26:10.534650: Pseudo dice [np.float32(0.6805)]
2025-10-06 01:26:10.534837: Epoch time: 46.4 s
2025-10-06 01:26:10.534996: Yayy! New best EMA pseudo Dice: 0.6078000068664551
2025-10-06 01:26:11.677720: 
2025-10-06 01:26:11.678135: Epoch 16
2025-10-06 01:26:11.678408: Current learning rate: 0.00903
2025-10-06 01:26:58.159799: Validation loss did not improve from -0.42159. Patience: 1/50
2025-10-06 01:26:58.160305: train_loss -0.5727
2025-10-06 01:26:58.160483: val_loss -0.412
2025-10-06 01:26:58.160663: Pseudo dice [np.float32(0.6654)]
2025-10-06 01:26:58.160869: Epoch time: 46.48 s
2025-10-06 01:26:58.161029: Yayy! New best EMA pseudo Dice: 0.6134999990463257
2025-10-06 01:26:59.252211: 
2025-10-06 01:26:59.252563: Epoch 17
2025-10-06 01:26:59.252757: Current learning rate: 0.00897
2025-10-06 01:27:45.701821: Validation loss did not improve from -0.42159. Patience: 2/50
2025-10-06 01:27:45.702298: train_loss -0.5761
2025-10-06 01:27:45.702454: val_loss -0.3662
2025-10-06 01:27:45.702637: Pseudo dice [np.float32(0.6417)]
2025-10-06 01:27:45.702887: Epoch time: 46.45 s
2025-10-06 01:27:45.703090: Yayy! New best EMA pseudo Dice: 0.6162999868392944
2025-10-06 01:27:46.786144: 
2025-10-06 01:27:46.786412: Epoch 18
2025-10-06 01:27:46.786614: Current learning rate: 0.00891
2025-10-06 01:28:33.182129: Validation loss did not improve from -0.42159. Patience: 3/50
2025-10-06 01:28:33.182717: train_loss -0.5999
2025-10-06 01:28:33.182875: val_loss -0.3856
2025-10-06 01:28:33.183029: Pseudo dice [np.float32(0.6498)]
2025-10-06 01:28:33.183200: Epoch time: 46.4 s
2025-10-06 01:28:33.183309: Yayy! New best EMA pseudo Dice: 0.619700014591217
2025-10-06 01:28:34.258319: 
2025-10-06 01:28:34.258537: Epoch 19
2025-10-06 01:28:34.258771: Current learning rate: 0.00885
2025-10-06 01:29:20.690492: Validation loss improved from -0.42159 to -0.42605! Patience: 3/50
2025-10-06 01:29:20.690991: train_loss -0.607
2025-10-06 01:29:20.691131: val_loss -0.426
2025-10-06 01:29:20.691242: Pseudo dice [np.float32(0.6839)]
2025-10-06 01:29:20.691374: Epoch time: 46.43 s
2025-10-06 01:29:21.199967: Yayy! New best EMA pseudo Dice: 0.6261000037193298
2025-10-06 01:29:22.355963: 
2025-10-06 01:29:22.356335: Epoch 20
2025-10-06 01:29:22.356581: Current learning rate: 0.00879
2025-10-06 01:30:08.762909: Validation loss did not improve from -0.42605. Patience: 1/50
2025-10-06 01:30:08.763597: train_loss -0.5984
2025-10-06 01:30:08.763857: val_loss -0.3537
2025-10-06 01:30:08.764067: Pseudo dice [np.float32(0.637)]
2025-10-06 01:30:08.764322: Epoch time: 46.41 s
2025-10-06 01:30:08.764781: Yayy! New best EMA pseudo Dice: 0.6272000074386597
2025-10-06 01:30:10.105083: 
2025-10-06 01:30:10.105714: Epoch 21
2025-10-06 01:30:10.106339: Current learning rate: 0.00873
2025-10-06 01:30:56.527611: Validation loss did not improve from -0.42605. Patience: 2/50
2025-10-06 01:30:56.528203: train_loss -0.6072
2025-10-06 01:30:56.528364: val_loss -0.4052
2025-10-06 01:30:56.528496: Pseudo dice [np.float32(0.6772)]
2025-10-06 01:30:56.528669: Epoch time: 46.42 s
2025-10-06 01:30:56.528802: Yayy! New best EMA pseudo Dice: 0.6322000026702881
2025-10-06 01:30:57.598142: 
2025-10-06 01:30:57.598494: Epoch 22
2025-10-06 01:30:57.598685: Current learning rate: 0.00867
2025-10-06 01:31:44.029438: Validation loss did not improve from -0.42605. Patience: 3/50
2025-10-06 01:31:44.030062: train_loss -0.6125
2025-10-06 01:31:44.030242: val_loss -0.4035
2025-10-06 01:31:44.030392: Pseudo dice [np.float32(0.6716)]
2025-10-06 01:31:44.030564: Epoch time: 46.43 s
2025-10-06 01:31:44.030738: Yayy! New best EMA pseudo Dice: 0.6360999941825867
2025-10-06 01:31:45.105093: 
2025-10-06 01:31:45.105432: Epoch 23
2025-10-06 01:31:45.105674: Current learning rate: 0.00861
2025-10-06 01:32:31.582855: Validation loss did not improve from -0.42605. Patience: 4/50
2025-10-06 01:32:31.583253: train_loss -0.6271
2025-10-06 01:32:31.583457: val_loss -0.3827
2025-10-06 01:32:31.583611: Pseudo dice [np.float32(0.6525)]
2025-10-06 01:32:31.583883: Epoch time: 46.48 s
2025-10-06 01:32:31.584035: Yayy! New best EMA pseudo Dice: 0.6377999782562256
2025-10-06 01:32:33.016060: 
2025-10-06 01:32:33.016348: Epoch 24
2025-10-06 01:32:33.016526: Current learning rate: 0.00855
2025-10-06 01:33:19.513261: Validation loss improved from -0.42605 to -0.42775! Patience: 4/50
2025-10-06 01:33:19.513975: train_loss -0.6353
2025-10-06 01:33:19.514151: val_loss -0.4278
2025-10-06 01:33:19.514295: Pseudo dice [np.float32(0.6702)]
2025-10-06 01:33:19.514439: Epoch time: 46.5 s
2025-10-06 01:33:19.962455: Yayy! New best EMA pseudo Dice: 0.640999972820282
2025-10-06 01:33:21.053574: 
2025-10-06 01:33:21.053921: Epoch 25
2025-10-06 01:33:21.054119: Current learning rate: 0.00849
2025-10-06 01:34:07.599833: Validation loss did not improve from -0.42775. Patience: 1/50
2025-10-06 01:34:07.600339: train_loss -0.6265
2025-10-06 01:34:07.600485: val_loss -0.4144
2025-10-06 01:34:07.600714: Pseudo dice [np.float32(0.6861)]
2025-10-06 01:34:07.600952: Epoch time: 46.55 s
2025-10-06 01:34:07.601120: Yayy! New best EMA pseudo Dice: 0.6455000042915344
2025-10-06 01:34:08.674102: 
2025-10-06 01:34:08.674387: Epoch 26
2025-10-06 01:34:08.674559: Current learning rate: 0.00843
2025-10-06 01:34:55.177938: Validation loss did not improve from -0.42775. Patience: 2/50
2025-10-06 01:34:55.178603: train_loss -0.625
2025-10-06 01:34:55.178772: val_loss -0.3925
2025-10-06 01:34:55.178919: Pseudo dice [np.float32(0.6624)]
2025-10-06 01:34:55.179124: Epoch time: 46.51 s
2025-10-06 01:34:55.179260: Yayy! New best EMA pseudo Dice: 0.6471999883651733
2025-10-06 01:34:56.281797: 
2025-10-06 01:34:56.282078: Epoch 27
2025-10-06 01:34:56.282272: Current learning rate: 0.00836
2025-10-06 01:35:42.717850: Validation loss did not improve from -0.42775. Patience: 3/50
2025-10-06 01:35:42.718370: train_loss -0.6414
2025-10-06 01:35:42.718510: val_loss -0.4125
2025-10-06 01:35:42.718640: Pseudo dice [np.float32(0.6696)]
2025-10-06 01:35:42.718777: Epoch time: 46.44 s
2025-10-06 01:35:42.718925: Yayy! New best EMA pseudo Dice: 0.649399995803833
2025-10-06 01:35:43.792424: 
2025-10-06 01:35:43.792656: Epoch 28
2025-10-06 01:35:43.792816: Current learning rate: 0.0083
2025-10-06 01:36:30.348802: Validation loss did not improve from -0.42775. Patience: 4/50
2025-10-06 01:36:30.349426: train_loss -0.6508
2025-10-06 01:36:30.349578: val_loss -0.4038
2025-10-06 01:36:30.349702: Pseudo dice [np.float32(0.68)]
2025-10-06 01:36:30.349952: Epoch time: 46.56 s
2025-10-06 01:36:30.350066: Yayy! New best EMA pseudo Dice: 0.6524999737739563
2025-10-06 01:36:31.434178: 
2025-10-06 01:36:31.434518: Epoch 29
2025-10-06 01:36:31.434706: Current learning rate: 0.00824
2025-10-06 01:37:17.935305: Validation loss improved from -0.42775 to -0.44580! Patience: 4/50
2025-10-06 01:37:17.935805: train_loss -0.6516
2025-10-06 01:37:17.935988: val_loss -0.4458
2025-10-06 01:37:17.936137: Pseudo dice [np.float32(0.6843)]
2025-10-06 01:37:17.936312: Epoch time: 46.5 s
2025-10-06 01:37:18.366362: Yayy! New best EMA pseudo Dice: 0.6557000279426575
2025-10-06 01:37:19.451128: 
2025-10-06 01:37:19.451572: Epoch 30
2025-10-06 01:37:19.451866: Current learning rate: 0.00818
2025-10-06 01:38:05.951688: Validation loss did not improve from -0.44580. Patience: 1/50
2025-10-06 01:38:05.952193: train_loss -0.6606
2025-10-06 01:38:05.952334: val_loss -0.4155
2025-10-06 01:38:05.952509: Pseudo dice [np.float32(0.6766)]
2025-10-06 01:38:05.952675: Epoch time: 46.5 s
2025-10-06 01:38:05.952850: Yayy! New best EMA pseudo Dice: 0.657800018787384
2025-10-06 01:38:07.041697: 
2025-10-06 01:38:07.042163: Epoch 31
2025-10-06 01:38:07.042425: Current learning rate: 0.00812
2025-10-06 01:38:53.474113: Validation loss did not improve from -0.44580. Patience: 2/50
2025-10-06 01:38:53.474644: train_loss -0.662
2025-10-06 01:38:53.474827: val_loss -0.4109
2025-10-06 01:38:53.474970: Pseudo dice [np.float32(0.6703)]
2025-10-06 01:38:53.475127: Epoch time: 46.43 s
2025-10-06 01:38:53.475304: Yayy! New best EMA pseudo Dice: 0.6589999794960022
2025-10-06 01:38:54.577867: 
2025-10-06 01:38:54.578282: Epoch 32
2025-10-06 01:38:54.578575: Current learning rate: 0.00806
2025-10-06 01:39:40.979079: Validation loss did not improve from -0.44580. Patience: 3/50
2025-10-06 01:39:40.979766: train_loss -0.6796
2025-10-06 01:39:40.980115: val_loss -0.4132
2025-10-06 01:39:40.980377: Pseudo dice [np.float32(0.6812)]
2025-10-06 01:39:40.980636: Epoch time: 46.4 s
2025-10-06 01:39:40.981076: Yayy! New best EMA pseudo Dice: 0.6611999869346619
2025-10-06 01:39:42.116540: 
2025-10-06 01:39:42.116808: Epoch 33
2025-10-06 01:39:42.117030: Current learning rate: 0.008
2025-10-06 01:40:28.604997: Validation loss did not improve from -0.44580. Patience: 4/50
2025-10-06 01:40:28.605707: train_loss -0.6754
2025-10-06 01:40:28.605910: val_loss -0.4352
2025-10-06 01:40:28.606035: Pseudo dice [np.float32(0.685)]
2025-10-06 01:40:28.606189: Epoch time: 46.49 s
2025-10-06 01:40:28.606299: Yayy! New best EMA pseudo Dice: 0.6636000275611877
2025-10-06 01:40:29.697050: 
2025-10-06 01:40:29.697427: Epoch 34
2025-10-06 01:40:29.697638: Current learning rate: 0.00793
2025-10-06 01:41:16.287058: Validation loss did not improve from -0.44580. Patience: 5/50
2025-10-06 01:41:16.287637: train_loss -0.681
2025-10-06 01:41:16.287844: val_loss -0.3916
2025-10-06 01:41:16.288019: Pseudo dice [np.float32(0.6708)]
2025-10-06 01:41:16.288166: Epoch time: 46.59 s
2025-10-06 01:41:16.771963: Yayy! New best EMA pseudo Dice: 0.6643000245094299
2025-10-06 01:41:18.301407: 
2025-10-06 01:41:18.301661: Epoch 35
2025-10-06 01:41:18.301844: Current learning rate: 0.00787
2025-10-06 01:42:04.879596: Validation loss did not improve from -0.44580. Patience: 6/50
2025-10-06 01:42:04.879959: train_loss -0.6895
2025-10-06 01:42:04.880122: val_loss -0.4383
2025-10-06 01:42:04.880267: Pseudo dice [np.float32(0.6808)]
2025-10-06 01:42:04.880439: Epoch time: 46.58 s
2025-10-06 01:42:04.880569: Yayy! New best EMA pseudo Dice: 0.6660000085830688
2025-10-06 01:42:05.987377: 
2025-10-06 01:42:05.987740: Epoch 36
2025-10-06 01:42:05.987914: Current learning rate: 0.00781
2025-10-06 01:42:52.456756: Validation loss did not improve from -0.44580. Patience: 7/50
2025-10-06 01:42:52.457434: train_loss -0.6898
2025-10-06 01:42:52.457609: val_loss -0.3892
2025-10-06 01:42:52.457758: Pseudo dice [np.float32(0.6767)]
2025-10-06 01:42:52.457916: Epoch time: 46.47 s
2025-10-06 01:42:52.458099: Yayy! New best EMA pseudo Dice: 0.6669999957084656
2025-10-06 01:42:53.534232: 
2025-10-06 01:42:53.534580: Epoch 37
2025-10-06 01:42:53.534795: Current learning rate: 0.00775
2025-10-06 01:43:39.919906: Validation loss did not improve from -0.44580. Patience: 8/50
2025-10-06 01:43:39.920404: train_loss -0.7026
2025-10-06 01:43:39.920593: val_loss -0.3748
2025-10-06 01:43:39.920757: Pseudo dice [np.float32(0.6667)]
2025-10-06 01:43:39.920938: Epoch time: 46.39 s
2025-10-06 01:43:40.563792: 
2025-10-06 01:43:40.564072: Epoch 38
2025-10-06 01:43:40.564295: Current learning rate: 0.00769
2025-10-06 01:44:27.099584: Validation loss did not improve from -0.44580. Patience: 9/50
2025-10-06 01:44:27.100127: train_loss -0.6985
2025-10-06 01:44:27.100270: val_loss -0.4438
2025-10-06 01:44:27.100390: Pseudo dice [np.float32(0.6956)]
2025-10-06 01:44:27.100535: Epoch time: 46.54 s
2025-10-06 01:44:27.100650: Yayy! New best EMA pseudo Dice: 0.6699000000953674
2025-10-06 01:44:28.219897: 
2025-10-06 01:44:28.220167: Epoch 39
2025-10-06 01:44:28.220348: Current learning rate: 0.00763
2025-10-06 01:45:14.756235: Validation loss did not improve from -0.44580. Patience: 10/50
2025-10-06 01:45:14.756874: train_loss -0.6911
2025-10-06 01:45:14.757062: val_loss -0.4405
2025-10-06 01:45:14.757214: Pseudo dice [np.float32(0.689)]
2025-10-06 01:45:14.757415: Epoch time: 46.54 s
2025-10-06 01:45:15.193692: Yayy! New best EMA pseudo Dice: 0.6718000173568726
2025-10-06 01:45:16.282765: 
2025-10-06 01:45:16.283111: Epoch 40
2025-10-06 01:45:16.283350: Current learning rate: 0.00756
2025-10-06 01:46:02.757077: Validation loss did not improve from -0.44580. Patience: 11/50
2025-10-06 01:46:02.758674: train_loss -0.7016
2025-10-06 01:46:02.759023: val_loss -0.4238
2025-10-06 01:46:02.759213: Pseudo dice [np.float32(0.6717)]
2025-10-06 01:46:02.759393: Epoch time: 46.48 s
2025-10-06 01:46:03.416161: 
2025-10-06 01:46:03.416564: Epoch 41
2025-10-06 01:46:03.416759: Current learning rate: 0.0075
2025-10-06 01:46:49.867479: Validation loss did not improve from -0.44580. Patience: 12/50
2025-10-06 01:46:49.867988: train_loss -0.7068
2025-10-06 01:46:49.868184: val_loss -0.3976
2025-10-06 01:46:49.868345: Pseudo dice [np.float32(0.68)]
2025-10-06 01:46:49.868546: Epoch time: 46.45 s
2025-10-06 01:46:49.868757: Yayy! New best EMA pseudo Dice: 0.6725999712944031
2025-10-06 01:46:50.947649: 
2025-10-06 01:46:50.947903: Epoch 42
2025-10-06 01:46:50.948173: Current learning rate: 0.00744
2025-10-06 01:47:37.271959: Validation loss did not improve from -0.44580. Patience: 13/50
2025-10-06 01:47:37.272552: train_loss -0.7193
2025-10-06 01:47:37.272695: val_loss -0.3765
2025-10-06 01:47:37.272818: Pseudo dice [np.float32(0.6769)]
2025-10-06 01:47:37.272950: Epoch time: 46.33 s
2025-10-06 01:47:37.273067: Yayy! New best EMA pseudo Dice: 0.6729999780654907
2025-10-06 01:47:38.329177: 
2025-10-06 01:47:38.329461: Epoch 43
2025-10-06 01:47:38.329657: Current learning rate: 0.00738
2025-10-06 01:48:24.799287: Validation loss did not improve from -0.44580. Patience: 14/50
2025-10-06 01:48:24.799809: train_loss -0.7174
2025-10-06 01:48:24.800004: val_loss -0.3852
2025-10-06 01:48:24.800156: Pseudo dice [np.float32(0.6673)]
2025-10-06 01:48:24.800331: Epoch time: 46.47 s
2025-10-06 01:48:25.439109: 
2025-10-06 01:48:25.439311: Epoch 44
2025-10-06 01:48:25.439465: Current learning rate: 0.00732
2025-10-06 01:49:11.975672: Validation loss did not improve from -0.44580. Patience: 15/50
2025-10-06 01:49:11.976273: train_loss -0.7252
2025-10-06 01:49:11.976441: val_loss -0.3925
2025-10-06 01:49:11.976553: Pseudo dice [np.float32(0.668)]
2025-10-06 01:49:11.976681: Epoch time: 46.54 s
2025-10-06 01:49:13.053701: 
2025-10-06 01:49:13.053974: Epoch 45
2025-10-06 01:49:13.054234: Current learning rate: 0.00725
2025-10-06 01:49:59.457916: Validation loss did not improve from -0.44580. Patience: 16/50
2025-10-06 01:49:59.458435: train_loss -0.724
2025-10-06 01:49:59.458590: val_loss -0.2937
2025-10-06 01:49:59.458757: Pseudo dice [np.float32(0.6536)]
2025-10-06 01:49:59.458927: Epoch time: 46.41 s
2025-10-06 01:50:00.082493: 
2025-10-06 01:50:00.082754: Epoch 46
2025-10-06 01:50:00.082968: Current learning rate: 0.00719
2025-10-06 01:50:46.421807: Validation loss did not improve from -0.44580. Patience: 17/50
2025-10-06 01:50:46.422384: train_loss -0.7276
2025-10-06 01:50:46.422559: val_loss -0.4209
2025-10-06 01:50:46.422762: Pseudo dice [np.float32(0.6814)]
2025-10-06 01:50:46.422943: Epoch time: 46.34 s
2025-10-06 01:50:47.416137: 
2025-10-06 01:50:47.416373: Epoch 47
2025-10-06 01:50:47.416570: Current learning rate: 0.00713
2025-10-06 01:51:33.916731: Validation loss did not improve from -0.44580. Patience: 18/50
2025-10-06 01:51:33.917188: train_loss -0.7368
2025-10-06 01:51:33.917436: val_loss -0.4111
2025-10-06 01:51:33.917657: Pseudo dice [np.float32(0.6756)]
2025-10-06 01:51:33.917874: Epoch time: 46.5 s
2025-10-06 01:51:34.544049: 
2025-10-06 01:51:34.544427: Epoch 48
2025-10-06 01:51:34.544678: Current learning rate: 0.00707
2025-10-06 01:52:21.101560: Validation loss did not improve from -0.44580. Patience: 19/50
2025-10-06 01:52:21.102239: train_loss -0.7382
2025-10-06 01:52:21.102405: val_loss -0.4089
2025-10-06 01:52:21.102553: Pseudo dice [np.float32(0.6828)]
2025-10-06 01:52:21.102707: Epoch time: 46.56 s
2025-10-06 01:52:21.747855: 
2025-10-06 01:52:21.748210: Epoch 49
2025-10-06 01:52:21.748392: Current learning rate: 0.007
2025-10-06 01:53:08.457333: Validation loss did not improve from -0.44580. Patience: 20/50
2025-10-06 01:53:08.458066: train_loss -0.7258
2025-10-06 01:53:08.458333: val_loss -0.4153
2025-10-06 01:53:08.458493: Pseudo dice [np.float32(0.6928)]
2025-10-06 01:53:08.458655: Epoch time: 46.71 s
2025-10-06 01:53:08.930483: Yayy! New best EMA pseudo Dice: 0.6747999787330627
2025-10-06 01:53:10.045936: 
2025-10-06 01:53:10.046309: Epoch 50
2025-10-06 01:53:10.046561: Current learning rate: 0.00694
2025-10-06 01:53:56.554970: Validation loss did not improve from -0.44580. Patience: 21/50
2025-10-06 01:53:56.555557: train_loss -0.7367
2025-10-06 01:53:56.555816: val_loss -0.4293
2025-10-06 01:53:56.555995: Pseudo dice [np.float32(0.687)]
2025-10-06 01:53:56.556396: Epoch time: 46.51 s
2025-10-06 01:53:56.556523: Yayy! New best EMA pseudo Dice: 0.6759999990463257
2025-10-06 01:53:57.636276: 
2025-10-06 01:53:57.636636: Epoch 51
2025-10-06 01:53:57.636834: Current learning rate: 0.00688
2025-10-06 01:54:44.094641: Validation loss did not improve from -0.44580. Patience: 22/50
2025-10-06 01:54:44.095272: train_loss -0.7513
2025-10-06 01:54:44.095444: val_loss -0.4071
2025-10-06 01:54:44.095596: Pseudo dice [np.float32(0.6888)]
2025-10-06 01:54:44.095745: Epoch time: 46.46 s
2025-10-06 01:54:44.095862: Yayy! New best EMA pseudo Dice: 0.677299976348877
2025-10-06 01:54:45.193469: 
2025-10-06 01:54:45.193780: Epoch 52
2025-10-06 01:54:45.193972: Current learning rate: 0.00682
2025-10-06 01:55:31.595600: Validation loss did not improve from -0.44580. Patience: 23/50
2025-10-06 01:55:31.596272: train_loss -0.7541
2025-10-06 01:55:31.596548: val_loss -0.4341
2025-10-06 01:55:31.596746: Pseudo dice [np.float32(0.6948)]
2025-10-06 01:55:31.596935: Epoch time: 46.4 s
2025-10-06 01:55:31.597078: Yayy! New best EMA pseudo Dice: 0.679099977016449
2025-10-06 01:55:32.694528: 
2025-10-06 01:55:32.694839: Epoch 53
2025-10-06 01:55:32.695028: Current learning rate: 0.00675
2025-10-06 01:56:19.277156: Validation loss did not improve from -0.44580. Patience: 24/50
2025-10-06 01:56:19.277696: train_loss -0.7545
2025-10-06 01:56:19.277859: val_loss -0.4015
2025-10-06 01:56:19.278029: Pseudo dice [np.float32(0.6865)]
2025-10-06 01:56:19.278244: Epoch time: 46.58 s
2025-10-06 01:56:19.278438: Yayy! New best EMA pseudo Dice: 0.6797999739646912
2025-10-06 01:56:20.383082: 
2025-10-06 01:56:20.383318: Epoch 54
2025-10-06 01:56:20.383562: Current learning rate: 0.00669
2025-10-06 01:57:06.906527: Validation loss did not improve from -0.44580. Patience: 25/50
2025-10-06 01:57:06.907123: train_loss -0.7569
2025-10-06 01:57:06.907259: val_loss -0.3876
2025-10-06 01:57:06.907390: Pseudo dice [np.float32(0.6865)]
2025-10-06 01:57:06.907519: Epoch time: 46.52 s
2025-10-06 01:57:07.379261: Yayy! New best EMA pseudo Dice: 0.6804999709129333
2025-10-06 01:57:08.468343: 
2025-10-06 01:57:08.468707: Epoch 55
2025-10-06 01:57:08.468923: Current learning rate: 0.00663
2025-10-06 01:57:54.881286: Validation loss did not improve from -0.44580. Patience: 26/50
2025-10-06 01:57:54.881980: train_loss -0.7585
2025-10-06 01:57:54.882312: val_loss -0.3889
2025-10-06 01:57:54.882590: Pseudo dice [np.float32(0.6781)]
2025-10-06 01:57:54.882804: Epoch time: 46.41 s
2025-10-06 01:57:55.532094: 
2025-10-06 01:57:55.532449: Epoch 56
2025-10-06 01:57:55.532660: Current learning rate: 0.00657
2025-10-06 01:58:41.935051: Validation loss did not improve from -0.44580. Patience: 27/50
2025-10-06 01:58:41.935615: train_loss -0.7602
2025-10-06 01:58:41.935781: val_loss -0.3925
2025-10-06 01:58:41.935897: Pseudo dice [np.float32(0.6781)]
2025-10-06 01:58:41.936049: Epoch time: 46.4 s
2025-10-06 01:58:42.573342: 
2025-10-06 01:58:42.573656: Epoch 57
2025-10-06 01:58:42.573861: Current learning rate: 0.0065
2025-10-06 01:59:29.068403: Validation loss did not improve from -0.44580. Patience: 28/50
2025-10-06 01:59:29.069112: train_loss -0.7689
2025-10-06 01:59:29.069354: val_loss -0.4208
2025-10-06 01:59:29.069578: Pseudo dice [np.float32(0.69)]
2025-10-06 01:59:29.069811: Epoch time: 46.5 s
2025-10-06 01:59:29.070048: Yayy! New best EMA pseudo Dice: 0.6809999942779541
2025-10-06 01:59:30.201680: 
2025-10-06 01:59:30.202003: Epoch 58
2025-10-06 01:59:30.202212: Current learning rate: 0.00644
2025-10-06 02:00:16.824109: Validation loss did not improve from -0.44580. Patience: 29/50
2025-10-06 02:00:16.824672: train_loss -0.7693
2025-10-06 02:00:16.824893: val_loss -0.3818
2025-10-06 02:00:16.825067: Pseudo dice [np.float32(0.6816)]
2025-10-06 02:00:16.825242: Epoch time: 46.62 s
2025-10-06 02:00:16.825390: Yayy! New best EMA pseudo Dice: 0.6811000108718872
2025-10-06 02:00:18.335360: 
2025-10-06 02:00:18.335746: Epoch 59
2025-10-06 02:00:18.336004: Current learning rate: 0.00638
2025-10-06 02:01:04.927540: Validation loss did not improve from -0.44580. Patience: 30/50
2025-10-06 02:01:04.928232: train_loss -0.7722
2025-10-06 02:01:04.928653: val_loss -0.3755
2025-10-06 02:01:04.928894: Pseudo dice [np.float32(0.679)]
2025-10-06 02:01:04.929119: Epoch time: 46.59 s
2025-10-06 02:01:06.037472: 
2025-10-06 02:01:06.037836: Epoch 60
2025-10-06 02:01:06.038116: Current learning rate: 0.00631
2025-10-06 02:01:52.551273: Validation loss did not improve from -0.44580. Patience: 31/50
2025-10-06 02:01:52.551925: train_loss -0.781
2025-10-06 02:01:52.552107: val_loss -0.4129
2025-10-06 02:01:52.552239: Pseudo dice [np.float32(0.6884)]
2025-10-06 02:01:52.552372: Epoch time: 46.52 s
2025-10-06 02:01:52.552508: Yayy! New best EMA pseudo Dice: 0.6815999746322632
2025-10-06 02:01:53.640223: 
2025-10-06 02:01:53.640518: Epoch 61
2025-10-06 02:01:53.640725: Current learning rate: 0.00625
2025-10-06 02:02:40.164577: Validation loss did not improve from -0.44580. Patience: 32/50
2025-10-06 02:02:40.165045: train_loss -0.7804
2025-10-06 02:02:40.165254: val_loss -0.3905
2025-10-06 02:02:40.165527: Pseudo dice [np.float32(0.6786)]
2025-10-06 02:02:40.165679: Epoch time: 46.53 s
2025-10-06 02:02:40.822070: 
2025-10-06 02:02:40.822453: Epoch 62
2025-10-06 02:02:40.822668: Current learning rate: 0.00619
2025-10-06 02:03:27.294732: Validation loss did not improve from -0.44580. Patience: 33/50
2025-10-06 02:03:27.295366: train_loss -0.7797
2025-10-06 02:03:27.295501: val_loss -0.4154
2025-10-06 02:03:27.295682: Pseudo dice [np.float32(0.6887)]
2025-10-06 02:03:27.295882: Epoch time: 46.47 s
2025-10-06 02:03:27.296077: Yayy! New best EMA pseudo Dice: 0.6820999979972839
2025-10-06 02:03:28.396339: 
2025-10-06 02:03:28.396680: Epoch 63
2025-10-06 02:03:28.396904: Current learning rate: 0.00612
2025-10-06 02:04:14.982605: Validation loss did not improve from -0.44580. Patience: 34/50
2025-10-06 02:04:14.983363: train_loss -0.7821
2025-10-06 02:04:14.983663: val_loss -0.404
2025-10-06 02:04:14.983855: Pseudo dice [np.float32(0.6848)]
2025-10-06 02:04:14.984030: Epoch time: 46.59 s
2025-10-06 02:04:14.984176: Yayy! New best EMA pseudo Dice: 0.6822999715805054
2025-10-06 02:04:16.106127: 
2025-10-06 02:04:16.106443: Epoch 64
2025-10-06 02:04:16.106678: Current learning rate: 0.00606
2025-10-06 02:05:02.666985: Validation loss did not improve from -0.44580. Patience: 35/50
2025-10-06 02:05:02.667488: train_loss -0.7819
2025-10-06 02:05:02.667644: val_loss -0.3798
2025-10-06 02:05:02.667767: Pseudo dice [np.float32(0.6792)]
2025-10-06 02:05:02.667911: Epoch time: 46.56 s
2025-10-06 02:05:03.766370: 
2025-10-06 02:05:03.766721: Epoch 65
2025-10-06 02:05:03.767019: Current learning rate: 0.006
2025-10-06 02:05:50.285659: Validation loss did not improve from -0.44580. Patience: 36/50
2025-10-06 02:05:50.286217: train_loss -0.7861
2025-10-06 02:05:50.286509: val_loss -0.3904
2025-10-06 02:05:50.286800: Pseudo dice [np.float32(0.6825)]
2025-10-06 02:05:50.287004: Epoch time: 46.52 s
2025-10-06 02:05:50.951571: 
2025-10-06 02:05:50.951859: Epoch 66
2025-10-06 02:05:50.952041: Current learning rate: 0.00593
2025-10-06 02:06:37.450488: Validation loss did not improve from -0.44580. Patience: 37/50
2025-10-06 02:06:37.451400: train_loss -0.7888
2025-10-06 02:06:37.451659: val_loss -0.3909
2025-10-06 02:06:37.451859: Pseudo dice [np.float32(0.6757)]
2025-10-06 02:06:37.452109: Epoch time: 46.5 s
2025-10-06 02:06:38.102823: 
2025-10-06 02:06:38.103256: Epoch 67
2025-10-06 02:06:38.103571: Current learning rate: 0.00587
2025-10-06 02:07:24.646602: Validation loss did not improve from -0.44580. Patience: 38/50
2025-10-06 02:07:24.647070: train_loss -0.7881
2025-10-06 02:07:24.647251: val_loss -0.3964
2025-10-06 02:07:24.647428: Pseudo dice [np.float32(0.6875)]
2025-10-06 02:07:24.647608: Epoch time: 46.54 s
2025-10-06 02:07:25.293528: 
2025-10-06 02:07:25.293810: Epoch 68
2025-10-06 02:07:25.294007: Current learning rate: 0.00581
2025-10-06 02:08:11.882105: Validation loss did not improve from -0.44580. Patience: 39/50
2025-10-06 02:08:11.882768: train_loss -0.7922
2025-10-06 02:08:11.883179: val_loss -0.4002
2025-10-06 02:08:11.883306: Pseudo dice [np.float32(0.6768)]
2025-10-06 02:08:11.883435: Epoch time: 46.59 s
2025-10-06 02:08:12.538520: 
2025-10-06 02:08:12.538761: Epoch 69
2025-10-06 02:08:12.538970: Current learning rate: 0.00574
2025-10-06 02:08:59.243609: Validation loss did not improve from -0.44580. Patience: 40/50
2025-10-06 02:08:59.244197: train_loss -0.7873
2025-10-06 02:08:59.244352: val_loss -0.4289
2025-10-06 02:08:59.244510: Pseudo dice [np.float32(0.7015)]
2025-10-06 02:08:59.244647: Epoch time: 46.71 s
2025-10-06 02:09:00.116853: Yayy! New best EMA pseudo Dice: 0.6834999918937683
2025-10-06 02:09:01.221022: 
2025-10-06 02:09:01.221398: Epoch 70
2025-10-06 02:09:01.221567: Current learning rate: 0.00568
2025-10-06 02:09:47.673849: Validation loss did not improve from -0.44580. Patience: 41/50
2025-10-06 02:09:47.674503: train_loss -0.7951
2025-10-06 02:09:47.674674: val_loss -0.3817
2025-10-06 02:09:47.674901: Pseudo dice [np.float32(0.6789)]
2025-10-06 02:09:47.675052: Epoch time: 46.45 s
2025-10-06 02:09:48.321775: 
2025-10-06 02:09:48.322144: Epoch 71
2025-10-06 02:09:48.322366: Current learning rate: 0.00562
2025-10-06 02:10:34.736864: Validation loss did not improve from -0.44580. Patience: 42/50
2025-10-06 02:10:34.737236: train_loss -0.7929
2025-10-06 02:10:34.737501: val_loss -0.3976
2025-10-06 02:10:34.737633: Pseudo dice [np.float32(0.6713)]
2025-10-06 02:10:34.737874: Epoch time: 46.42 s
2025-10-06 02:10:35.379856: 
2025-10-06 02:10:35.380168: Epoch 72
2025-10-06 02:10:35.380341: Current learning rate: 0.00555
2025-10-06 02:11:21.787834: Validation loss did not improve from -0.44580. Patience: 43/50
2025-10-06 02:11:21.788935: train_loss -0.8001
2025-10-06 02:11:21.789334: val_loss -0.4096
2025-10-06 02:11:21.789522: Pseudo dice [np.float32(0.6931)]
2025-10-06 02:11:21.789798: Epoch time: 46.41 s
2025-10-06 02:11:22.455691: 
2025-10-06 02:11:22.455993: Epoch 73
2025-10-06 02:11:22.456225: Current learning rate: 0.00549
2025-10-06 02:12:08.992859: Validation loss did not improve from -0.44580. Patience: 44/50
2025-10-06 02:12:08.993335: train_loss -0.8057
2025-10-06 02:12:08.993545: val_loss -0.3449
2025-10-06 02:12:08.993779: Pseudo dice [np.float32(0.6769)]
2025-10-06 02:12:08.994012: Epoch time: 46.54 s
2025-10-06 02:12:09.652859: 
2025-10-06 02:12:09.653244: Epoch 74
2025-10-06 02:12:09.653524: Current learning rate: 0.00542
2025-10-06 02:12:56.249653: Validation loss did not improve from -0.44580. Patience: 45/50
2025-10-06 02:12:56.250283: train_loss -0.8069
2025-10-06 02:12:56.250458: val_loss -0.3983
2025-10-06 02:12:56.250612: Pseudo dice [np.float32(0.6935)]
2025-10-06 02:12:56.250775: Epoch time: 46.6 s
2025-10-06 02:12:57.354581: 
2025-10-06 02:12:57.354903: Epoch 75
2025-10-06 02:12:57.355083: Current learning rate: 0.00536
2025-10-06 02:13:43.882657: Validation loss did not improve from -0.44580. Patience: 46/50
2025-10-06 02:13:43.883203: train_loss -0.8149
2025-10-06 02:13:43.883368: val_loss -0.3475
2025-10-06 02:13:43.883516: Pseudo dice [np.float32(0.6784)]
2025-10-06 02:13:43.883689: Epoch time: 46.53 s
2025-10-06 02:13:44.532336: 
2025-10-06 02:13:44.532685: Epoch 76
2025-10-06 02:13:44.532919: Current learning rate: 0.00529
2025-10-06 02:14:30.991361: Validation loss did not improve from -0.44580. Patience: 47/50
2025-10-06 02:14:30.992104: train_loss -0.8115
2025-10-06 02:14:30.992320: val_loss -0.3815
2025-10-06 02:14:30.992508: Pseudo dice [np.float32(0.6856)]
2025-10-06 02:14:30.992758: Epoch time: 46.46 s
2025-10-06 02:14:31.632272: 
2025-10-06 02:14:31.632732: Epoch 77
2025-10-06 02:14:31.633036: Current learning rate: 0.00523
2025-10-06 02:15:18.096753: Validation loss did not improve from -0.44580. Patience: 48/50
2025-10-06 02:15:18.097299: train_loss -0.8072
2025-10-06 02:15:18.097446: val_loss -0.4133
2025-10-06 02:15:18.097626: Pseudo dice [np.float32(0.7082)]
2025-10-06 02:15:18.097814: Epoch time: 46.47 s
2025-10-06 02:15:18.097932: Yayy! New best EMA pseudo Dice: 0.685699999332428
2025-10-06 02:15:19.222739: 
2025-10-06 02:15:19.223082: Epoch 78
2025-10-06 02:15:19.223377: Current learning rate: 0.00517
2025-10-06 02:16:05.788503: Validation loss did not improve from -0.44580. Patience: 49/50
2025-10-06 02:16:05.789434: train_loss -0.8118
2025-10-06 02:16:05.789594: val_loss -0.3813
2025-10-06 02:16:05.789813: Pseudo dice [np.float32(0.6779)]
2025-10-06 02:16:05.790056: Epoch time: 46.57 s
2025-10-06 02:16:06.451570: 
2025-10-06 02:16:06.451815: Epoch 79
2025-10-06 02:16:06.451989: Current learning rate: 0.0051
2025-10-06 02:16:53.062199: Validation loss did not improve from -0.44580. Patience: 50/50
2025-10-06 02:16:53.062729: train_loss -0.8133
2025-10-06 02:16:53.062915: val_loss -0.3485
2025-10-06 02:16:53.063120: Pseudo dice [np.float32(0.6785)]
2025-10-06 02:16:53.063344: Epoch time: 46.61 s
2025-10-06 02:16:54.165777: 
2025-10-06 02:16:54.166145: Epoch 80
2025-10-06 02:16:54.166322: Current learning rate: 0.00504
2025-10-06 02:17:40.683521: Validation loss did not improve from -0.44580. Patience: 51/50
2025-10-06 02:17:40.684409: train_loss -0.824
2025-10-06 02:17:40.684660: val_loss -0.3715
2025-10-06 02:17:40.684836: Pseudo dice [np.float32(0.6856)]
2025-10-06 02:17:40.685022: Epoch time: 46.52 s
2025-10-06 02:17:41.738475: 
2025-10-06 02:17:41.738845: Epoch 81
2025-10-06 02:17:41.739017: Current learning rate: 0.00497
2025-10-06 02:18:28.230346: Validation loss did not improve from -0.44580. Patience: 52/50
2025-10-06 02:18:28.230961: train_loss -0.825
2025-10-06 02:18:28.231103: val_loss -0.4078
2025-10-06 02:18:28.231218: Pseudo dice [np.float32(0.6992)]
2025-10-06 02:18:28.231349: Epoch time: 46.49 s
2025-10-06 02:18:28.231464: Yayy! New best EMA pseudo Dice: 0.6858999729156494
2025-10-06 02:18:29.331462: 
2025-10-06 02:18:29.331833: Epoch 82
2025-10-06 02:18:29.332045: Current learning rate: 0.00491
2025-10-06 02:19:15.809936: Validation loss did not improve from -0.44580. Patience: 53/50
2025-10-06 02:19:15.810894: train_loss -0.8182
2025-10-06 02:19:15.811312: val_loss -0.3567
2025-10-06 02:19:15.811756: Pseudo dice [np.float32(0.681)]
2025-10-06 02:19:15.812231: Epoch time: 46.48 s
2025-10-06 02:19:16.459064: 
2025-10-06 02:19:16.459382: Epoch 83
2025-10-06 02:19:16.459586: Current learning rate: 0.00484
2025-10-06 02:20:02.953645: Validation loss did not improve from -0.44580. Patience: 54/50
2025-10-06 02:20:02.954182: train_loss -0.8247
2025-10-06 02:20:02.954448: val_loss -0.3522
2025-10-06 02:20:02.954623: Pseudo dice [np.float32(0.6843)]
2025-10-06 02:20:02.954817: Epoch time: 46.5 s
2025-10-06 02:20:03.598286: 
2025-10-06 02:20:03.598663: Epoch 84
2025-10-06 02:20:03.598899: Current learning rate: 0.00478
2025-10-06 02:20:50.047959: Validation loss did not improve from -0.44580. Patience: 55/50
2025-10-06 02:20:50.048498: train_loss -0.8264
2025-10-06 02:20:50.048649: val_loss -0.3848
2025-10-06 02:20:50.048792: Pseudo dice [np.float32(0.6867)]
2025-10-06 02:20:50.048919: Epoch time: 46.45 s
2025-10-06 02:20:51.118041: 
2025-10-06 02:20:51.118385: Epoch 85
2025-10-06 02:20:51.118548: Current learning rate: 0.00471
2025-10-06 02:21:37.525615: Validation loss did not improve from -0.44580. Patience: 56/50
2025-10-06 02:21:37.526233: train_loss -0.8289
2025-10-06 02:21:37.526563: val_loss -0.3604
2025-10-06 02:21:37.526767: Pseudo dice [np.float32(0.6755)]
2025-10-06 02:21:37.526927: Epoch time: 46.41 s
2025-10-06 02:21:38.165248: 
2025-10-06 02:21:38.165642: Epoch 86
2025-10-06 02:21:38.165913: Current learning rate: 0.00465
2025-10-06 02:22:24.594254: Validation loss did not improve from -0.44580. Patience: 57/50
2025-10-06 02:22:24.594799: train_loss -0.8215
2025-10-06 02:22:24.594998: val_loss -0.3469
2025-10-06 02:22:24.595120: Pseudo dice [np.float32(0.6743)]
2025-10-06 02:22:24.595257: Epoch time: 46.43 s
2025-10-06 02:22:25.221910: 
2025-10-06 02:22:25.222217: Epoch 87
2025-10-06 02:22:25.222436: Current learning rate: 0.00458
2025-10-06 02:23:11.673710: Validation loss did not improve from -0.44580. Patience: 58/50
2025-10-06 02:23:11.674351: train_loss -0.8253
2025-10-06 02:23:11.674582: val_loss -0.3545
2025-10-06 02:23:11.675027: Pseudo dice [np.float32(0.6764)]
2025-10-06 02:23:11.675260: Epoch time: 46.45 s
2025-10-06 02:23:12.321433: 
2025-10-06 02:23:12.321738: Epoch 88
2025-10-06 02:23:12.321936: Current learning rate: 0.00452
2025-10-06 02:23:58.826815: Validation loss did not improve from -0.44580. Patience: 59/50
2025-10-06 02:23:58.827394: train_loss -0.8303
2025-10-06 02:23:58.827561: val_loss -0.3672
2025-10-06 02:23:58.827754: Pseudo dice [np.float32(0.6863)]
2025-10-06 02:23:58.827917: Epoch time: 46.51 s
2025-10-06 02:23:59.460134: 
2025-10-06 02:23:59.460480: Epoch 89
2025-10-06 02:23:59.460664: Current learning rate: 0.00445
2025-10-06 02:24:45.967861: Validation loss did not improve from -0.44580. Patience: 60/50
2025-10-06 02:24:45.968267: train_loss -0.8273
2025-10-06 02:24:45.968424: val_loss -0.3992
2025-10-06 02:24:45.968535: Pseudo dice [np.float32(0.6872)]
2025-10-06 02:24:45.968659: Epoch time: 46.51 s
2025-10-06 02:24:47.083522: 
2025-10-06 02:24:47.083842: Epoch 90
2025-10-06 02:24:47.084001: Current learning rate: 0.00438
2025-10-06 02:25:33.564934: Validation loss did not improve from -0.44580. Patience: 61/50
2025-10-06 02:25:33.565572: train_loss -0.837
2025-10-06 02:25:33.565731: val_loss -0.3638
2025-10-06 02:25:33.565888: Pseudo dice [np.float32(0.6932)]
2025-10-06 02:25:33.566120: Epoch time: 46.48 s
2025-10-06 02:25:34.197374: 
2025-10-06 02:25:34.197693: Epoch 91
2025-10-06 02:25:34.197872: Current learning rate: 0.00432
2025-10-06 02:26:20.619071: Validation loss did not improve from -0.44580. Patience: 62/50
2025-10-06 02:26:20.619551: train_loss -0.8352
2025-10-06 02:26:20.619713: val_loss -0.432
2025-10-06 02:26:20.619916: Pseudo dice [np.float32(0.7098)]
2025-10-06 02:26:20.620098: Epoch time: 46.42 s
2025-10-06 02:26:20.620251: Yayy! New best EMA pseudo Dice: 0.6869999766349792
2025-10-06 02:26:21.698011: 
2025-10-06 02:26:21.698429: Epoch 92
2025-10-06 02:26:21.698705: Current learning rate: 0.00425
2025-10-06 02:27:08.215968: Validation loss did not improve from -0.44580. Patience: 63/50
2025-10-06 02:27:08.216645: train_loss -0.8328
2025-10-06 02:27:08.216912: val_loss -0.3739
2025-10-06 02:27:08.217163: Pseudo dice [np.float32(0.6892)]
2025-10-06 02:27:08.217435: Epoch time: 46.52 s
2025-10-06 02:27:08.217659: Yayy! New best EMA pseudo Dice: 0.6872000098228455
2025-10-06 02:27:09.706633: 
2025-10-06 02:27:09.706993: Epoch 93
2025-10-06 02:27:09.707245: Current learning rate: 0.00419
2025-10-06 02:27:56.236994: Validation loss did not improve from -0.44580. Patience: 64/50
2025-10-06 02:27:56.237557: train_loss -0.8355
2025-10-06 02:27:56.237764: val_loss -0.3971
2025-10-06 02:27:56.237906: Pseudo dice [np.float32(0.7011)]
2025-10-06 02:27:56.238087: Epoch time: 46.53 s
2025-10-06 02:27:56.238224: Yayy! New best EMA pseudo Dice: 0.6886000037193298
2025-10-06 02:27:57.329740: 
2025-10-06 02:27:57.330056: Epoch 94
2025-10-06 02:27:57.330238: Current learning rate: 0.00412
2025-10-06 02:28:43.804420: Validation loss did not improve from -0.44580. Patience: 65/50
2025-10-06 02:28:43.805120: train_loss -0.8372
2025-10-06 02:28:43.805332: val_loss -0.3555
2025-10-06 02:28:43.805543: Pseudo dice [np.float32(0.6834)]
2025-10-06 02:28:43.805765: Epoch time: 46.48 s
2025-10-06 02:28:44.880443: 
2025-10-06 02:28:44.880835: Epoch 95
2025-10-06 02:28:44.881067: Current learning rate: 0.00405
2025-10-06 02:29:31.338023: Validation loss did not improve from -0.44580. Patience: 66/50
2025-10-06 02:29:31.338673: train_loss -0.841
2025-10-06 02:29:31.338977: val_loss -0.3794
2025-10-06 02:29:31.339191: Pseudo dice [np.float32(0.6958)]
2025-10-06 02:29:31.339431: Epoch time: 46.46 s
2025-10-06 02:29:31.339591: Yayy! New best EMA pseudo Dice: 0.6888999938964844
2025-10-06 02:29:32.434411: 
2025-10-06 02:29:32.434677: Epoch 96
2025-10-06 02:29:32.434919: Current learning rate: 0.00399
2025-10-06 02:30:18.926098: Validation loss did not improve from -0.44580. Patience: 67/50
2025-10-06 02:30:18.926832: train_loss -0.841
2025-10-06 02:30:18.926975: val_loss -0.3623
2025-10-06 02:30:18.927213: Pseudo dice [np.float32(0.6859)]
2025-10-06 02:30:18.927411: Epoch time: 46.49 s
2025-10-06 02:30:19.563937: 
2025-10-06 02:30:19.564308: Epoch 97
2025-10-06 02:30:19.564518: Current learning rate: 0.00392
2025-10-06 02:31:06.049268: Validation loss did not improve from -0.44580. Patience: 68/50
2025-10-06 02:31:06.049684: train_loss -0.8392
2025-10-06 02:31:06.049865: val_loss -0.3787
2025-10-06 02:31:06.050001: Pseudo dice [np.float32(0.6848)]
2025-10-06 02:31:06.050169: Epoch time: 46.49 s
2025-10-06 02:31:06.696301: 
2025-10-06 02:31:06.696673: Epoch 98
2025-10-06 02:31:06.696962: Current learning rate: 0.00385
2025-10-06 02:31:53.235440: Validation loss did not improve from -0.44580. Patience: 69/50
2025-10-06 02:31:53.236026: train_loss -0.8391
2025-10-06 02:31:53.236206: val_loss -0.367
2025-10-06 02:31:53.236313: Pseudo dice [np.float32(0.6879)]
2025-10-06 02:31:53.236447: Epoch time: 46.54 s
2025-10-06 02:31:53.878732: 
2025-10-06 02:31:53.879128: Epoch 99
2025-10-06 02:31:53.879326: Current learning rate: 0.00379
2025-10-06 02:32:40.373378: Validation loss did not improve from -0.44580. Patience: 70/50
2025-10-06 02:32:40.373832: train_loss -0.8445
2025-10-06 02:32:40.374003: val_loss -0.3633
2025-10-06 02:32:40.374123: Pseudo dice [np.float32(0.6921)]
2025-10-06 02:32:40.374256: Epoch time: 46.5 s
2025-10-06 02:32:41.448659: 
2025-10-06 02:32:41.449043: Epoch 100
2025-10-06 02:32:41.449301: Current learning rate: 0.00372
2025-10-06 02:33:27.960489: Validation loss did not improve from -0.44580. Patience: 71/50
2025-10-06 02:33:27.960998: train_loss -0.8426
2025-10-06 02:33:27.961157: val_loss -0.3235
2025-10-06 02:33:27.961285: Pseudo dice [np.float32(0.6746)]
2025-10-06 02:33:27.961445: Epoch time: 46.51 s
2025-10-06 02:33:28.607945: 
2025-10-06 02:33:28.608347: Epoch 101
2025-10-06 02:33:28.608574: Current learning rate: 0.00365
2025-10-06 02:34:15.068775: Validation loss did not improve from -0.44580. Patience: 72/50
2025-10-06 02:34:15.069280: train_loss -0.8472
2025-10-06 02:34:15.069451: val_loss -0.3003
2025-10-06 02:34:15.069621: Pseudo dice [np.float32(0.6672)]
2025-10-06 02:34:15.069783: Epoch time: 46.46 s
2025-10-06 02:34:15.707085: 
2025-10-06 02:34:15.707408: Epoch 102
2025-10-06 02:34:15.707633: Current learning rate: 0.00359
2025-10-06 02:35:02.241627: Validation loss did not improve from -0.44580. Patience: 73/50
2025-10-06 02:35:02.242240: train_loss -0.8483
2025-10-06 02:35:02.242397: val_loss -0.3553
2025-10-06 02:35:02.242537: Pseudo dice [np.float32(0.6749)]
2025-10-06 02:35:02.242676: Epoch time: 46.54 s
2025-10-06 02:35:02.889135: 
2025-10-06 02:35:02.889478: Epoch 103
2025-10-06 02:35:02.889671: Current learning rate: 0.00352
2025-10-06 02:35:49.438499: Validation loss did not improve from -0.44580. Patience: 74/50
2025-10-06 02:35:49.439096: train_loss -0.8488
2025-10-06 02:35:49.439354: val_loss -0.3383
2025-10-06 02:35:49.439550: Pseudo dice [np.float32(0.6773)]
2025-10-06 02:35:49.439818: Epoch time: 46.55 s
2025-10-06 02:35:50.088040: 
2025-10-06 02:35:50.088396: Epoch 104
2025-10-06 02:35:50.088651: Current learning rate: 0.00345
2025-10-06 02:36:36.593743: Validation loss did not improve from -0.44580. Patience: 75/50
2025-10-06 02:36:36.594208: train_loss -0.8509
2025-10-06 02:36:36.594415: val_loss -0.3493
2025-10-06 02:36:36.594569: Pseudo dice [np.float32(0.6769)]
2025-10-06 02:36:36.594740: Epoch time: 46.51 s
2025-10-06 02:36:38.127445: 
2025-10-06 02:36:38.128033: Epoch 105
2025-10-06 02:36:38.128402: Current learning rate: 0.00338
2025-10-06 02:37:24.630090: Validation loss did not improve from -0.44580. Patience: 76/50
2025-10-06 02:37:24.630603: train_loss -0.8489
2025-10-06 02:37:24.630752: val_loss -0.3012
2025-10-06 02:37:24.630939: Pseudo dice [np.float32(0.672)]
2025-10-06 02:37:24.631084: Epoch time: 46.5 s
2025-10-06 02:37:25.278077: 
2025-10-06 02:37:25.278444: Epoch 106
2025-10-06 02:37:25.278650: Current learning rate: 0.00332
2025-10-06 02:38:11.804606: Validation loss did not improve from -0.44580. Patience: 77/50
2025-10-06 02:38:11.805123: train_loss -0.8515
2025-10-06 02:38:11.805532: val_loss -0.3381
2025-10-06 02:38:11.805700: Pseudo dice [np.float32(0.6946)]
2025-10-06 02:38:11.805881: Epoch time: 46.53 s
2025-10-06 02:38:12.451829: 
2025-10-06 02:38:12.452064: Epoch 107
2025-10-06 02:38:12.452259: Current learning rate: 0.00325
2025-10-06 02:38:58.904489: Validation loss did not improve from -0.44580. Patience: 78/50
2025-10-06 02:38:58.905013: train_loss -0.8538
2025-10-06 02:38:58.905151: val_loss -0.394
2025-10-06 02:38:58.905310: Pseudo dice [np.float32(0.7003)]
2025-10-06 02:38:58.905458: Epoch time: 46.45 s
2025-10-06 02:38:59.547379: 
2025-10-06 02:38:59.547651: Epoch 108
2025-10-06 02:38:59.547866: Current learning rate: 0.00318
2025-10-06 02:39:46.020616: Validation loss did not improve from -0.44580. Patience: 79/50
2025-10-06 02:39:46.021226: train_loss -0.8541
2025-10-06 02:39:46.021388: val_loss -0.3718
2025-10-06 02:39:46.021523: Pseudo dice [np.float32(0.6859)]
2025-10-06 02:39:46.021692: Epoch time: 46.47 s
2025-10-06 02:39:46.664361: 
2025-10-06 02:39:46.664703: Epoch 109
2025-10-06 02:39:46.664886: Current learning rate: 0.00311
2025-10-06 02:40:33.048891: Validation loss did not improve from -0.44580. Patience: 80/50
2025-10-06 02:40:33.049379: train_loss -0.8542
2025-10-06 02:40:33.049551: val_loss -0.35
2025-10-06 02:40:33.049694: Pseudo dice [np.float32(0.6888)]
2025-10-06 02:40:33.049888: Epoch time: 46.39 s
2025-10-06 02:40:34.170427: 
2025-10-06 02:40:34.170765: Epoch 110
2025-10-06 02:40:34.170991: Current learning rate: 0.00304
2025-10-06 02:41:20.699106: Validation loss did not improve from -0.44580. Patience: 81/50
2025-10-06 02:41:20.699603: train_loss -0.8579
2025-10-06 02:41:20.699748: val_loss -0.39
2025-10-06 02:41:20.699908: Pseudo dice [np.float32(0.7015)]
2025-10-06 02:41:20.700080: Epoch time: 46.53 s
2025-10-06 02:41:21.351035: 
2025-10-06 02:41:21.351623: Epoch 111
2025-10-06 02:41:21.352046: Current learning rate: 0.00297
2025-10-06 02:42:07.803216: Validation loss did not improve from -0.44580. Patience: 82/50
2025-10-06 02:42:07.803751: train_loss -0.8556
2025-10-06 02:42:07.804027: val_loss -0.3493
2025-10-06 02:42:07.804265: Pseudo dice [np.float32(0.6962)]
2025-10-06 02:42:07.804491: Epoch time: 46.45 s
2025-10-06 02:42:08.465719: 
2025-10-06 02:42:08.466089: Epoch 112
2025-10-06 02:42:08.466401: Current learning rate: 0.00291
2025-10-06 02:42:54.967923: Validation loss did not improve from -0.44580. Patience: 83/50
2025-10-06 02:42:54.968428: train_loss -0.8577
2025-10-06 02:42:54.968571: val_loss -0.3617
2025-10-06 02:42:54.968701: Pseudo dice [np.float32(0.6928)]
2025-10-06 02:42:54.968855: Epoch time: 46.5 s
2025-10-06 02:42:55.618722: 
2025-10-06 02:42:55.619150: Epoch 113
2025-10-06 02:42:55.619375: Current learning rate: 0.00284
2025-10-06 02:43:42.055893: Validation loss did not improve from -0.44580. Patience: 84/50
2025-10-06 02:43:42.056373: train_loss -0.8557
2025-10-06 02:43:42.056533: val_loss -0.3241
2025-10-06 02:43:42.056676: Pseudo dice [np.float32(0.6838)]
2025-10-06 02:43:42.056834: Epoch time: 46.44 s
2025-10-06 02:43:42.700443: 
2025-10-06 02:43:42.700756: Epoch 114
2025-10-06 02:43:42.701001: Current learning rate: 0.00277
2025-10-06 02:44:29.202522: Validation loss did not improve from -0.44580. Patience: 85/50
2025-10-06 02:44:29.203249: train_loss -0.858
2025-10-06 02:44:29.203472: val_loss -0.389
2025-10-06 02:44:29.203669: Pseudo dice [np.float32(0.6976)]
2025-10-06 02:44:29.203897: Epoch time: 46.5 s
2025-10-06 02:44:30.323593: 
2025-10-06 02:44:30.323959: Epoch 115
2025-10-06 02:44:30.324132: Current learning rate: 0.0027
2025-10-06 02:45:16.872529: Validation loss did not improve from -0.44580. Patience: 86/50
2025-10-06 02:45:16.873048: train_loss -0.8641
2025-10-06 02:45:16.873206: val_loss -0.3523
2025-10-06 02:45:16.873333: Pseudo dice [np.float32(0.6891)]
2025-10-06 02:45:16.873484: Epoch time: 46.55 s
2025-10-06 02:45:16.873600: Yayy! New best EMA pseudo Dice: 0.6888999938964844
2025-10-06 02:45:17.981236: 
2025-10-06 02:45:17.981539: Epoch 116
2025-10-06 02:45:17.981726: Current learning rate: 0.00263
2025-10-06 02:46:04.472816: Validation loss did not improve from -0.44580. Patience: 87/50
2025-10-06 02:46:04.473316: train_loss -0.8613
2025-10-06 02:46:04.473468: val_loss -0.353
2025-10-06 02:46:04.473581: Pseudo dice [np.float32(0.6837)]
2025-10-06 02:46:04.473711: Epoch time: 46.49 s
2025-10-06 02:46:05.515837: 
2025-10-06 02:46:05.516171: Epoch 117
2025-10-06 02:46:05.516407: Current learning rate: 0.00256
2025-10-06 02:46:52.036962: Validation loss did not improve from -0.44580. Patience: 88/50
2025-10-06 02:46:52.037354: train_loss -0.8608
2025-10-06 02:46:52.037503: val_loss -0.3633
2025-10-06 02:46:52.037699: Pseudo dice [np.float32(0.6873)]
2025-10-06 02:46:52.037900: Epoch time: 46.52 s
2025-10-06 02:46:52.706966: 
2025-10-06 02:46:52.707233: Epoch 118
2025-10-06 02:46:52.707412: Current learning rate: 0.00249
2025-10-06 02:47:39.238725: Validation loss did not improve from -0.44580. Patience: 89/50
2025-10-06 02:47:39.239285: train_loss -0.8643
2025-10-06 02:47:39.239447: val_loss -0.3715
2025-10-06 02:47:39.239632: Pseudo dice [np.float32(0.6893)]
2025-10-06 02:47:39.239822: Epoch time: 46.53 s
2025-10-06 02:47:39.893637: 
2025-10-06 02:47:39.894006: Epoch 119
2025-10-06 02:47:39.894541: Current learning rate: 0.00242
2025-10-06 02:48:26.411319: Validation loss did not improve from -0.44580. Patience: 90/50
2025-10-06 02:48:26.411960: train_loss -0.8631
2025-10-06 02:48:26.412200: val_loss -0.3397
2025-10-06 02:48:26.412366: Pseudo dice [np.float32(0.6928)]
2025-10-06 02:48:26.412619: Epoch time: 46.52 s
2025-10-06 02:48:27.559698: 
2025-10-06 02:48:27.560083: Epoch 120
2025-10-06 02:48:27.560327: Current learning rate: 0.00235
2025-10-06 02:49:14.071426: Validation loss did not improve from -0.44580. Patience: 91/50
2025-10-06 02:49:14.072095: train_loss -0.8682
2025-10-06 02:49:14.072261: val_loss -0.3531
2025-10-06 02:49:14.072378: Pseudo dice [np.float32(0.689)]
2025-10-06 02:49:14.072510: Epoch time: 46.51 s
2025-10-06 02:49:14.732486: 
2025-10-06 02:49:14.732812: Epoch 121
2025-10-06 02:49:14.733042: Current learning rate: 0.00228
2025-10-06 02:50:01.276958: Validation loss did not improve from -0.44580. Patience: 92/50
2025-10-06 02:50:01.277552: train_loss -0.8631
2025-10-06 02:50:01.277806: val_loss -0.4004
2025-10-06 02:50:01.278039: Pseudo dice [np.float32(0.7001)]
2025-10-06 02:50:01.278326: Epoch time: 46.55 s
2025-10-06 02:50:01.278576: Yayy! New best EMA pseudo Dice: 0.6898999810218811
2025-10-06 02:50:02.393862: 
2025-10-06 02:50:02.394167: Epoch 122
2025-10-06 02:50:02.394376: Current learning rate: 0.00221
2025-10-06 02:50:48.875332: Validation loss did not improve from -0.44580. Patience: 93/50
2025-10-06 02:50:48.875944: train_loss -0.8699
2025-10-06 02:50:48.876134: val_loss -0.3586
2025-10-06 02:50:48.876273: Pseudo dice [np.float32(0.6842)]
2025-10-06 02:50:48.876473: Epoch time: 46.48 s
2025-10-06 02:50:49.528259: 
2025-10-06 02:50:49.528487: Epoch 123
2025-10-06 02:50:49.528741: Current learning rate: 0.00214
2025-10-06 02:51:36.052952: Validation loss did not improve from -0.44580. Patience: 94/50
2025-10-06 02:51:36.053563: train_loss -0.8676
2025-10-06 02:51:36.053878: val_loss -0.3619
2025-10-06 02:51:36.054125: Pseudo dice [np.float32(0.6886)]
2025-10-06 02:51:36.054394: Epoch time: 46.53 s
2025-10-06 02:51:36.722086: 
2025-10-06 02:51:36.722409: Epoch 124
2025-10-06 02:51:36.722575: Current learning rate: 0.00207
2025-10-06 02:52:23.175356: Validation loss did not improve from -0.44580. Patience: 95/50
2025-10-06 02:52:23.176018: train_loss -0.8685
2025-10-06 02:52:23.176171: val_loss -0.3552
2025-10-06 02:52:23.176328: Pseudo dice [np.float32(0.6885)]
2025-10-06 02:52:23.176515: Epoch time: 46.45 s
2025-10-06 02:52:24.309837: 
2025-10-06 02:52:24.310097: Epoch 125
2025-10-06 02:52:24.310258: Current learning rate: 0.00199
2025-10-06 02:53:10.857006: Validation loss did not improve from -0.44580. Patience: 96/50
2025-10-06 02:53:10.857547: train_loss -0.8722
2025-10-06 02:53:10.857785: val_loss -0.3406
2025-10-06 02:53:10.858013: Pseudo dice [np.float32(0.6847)]
2025-10-06 02:53:10.858468: Epoch time: 46.55 s
2025-10-06 02:53:11.524496: 
2025-10-06 02:53:11.524742: Epoch 126
2025-10-06 02:53:11.524970: Current learning rate: 0.00192
2025-10-06 02:53:57.924165: Validation loss did not improve from -0.44580. Patience: 97/50
2025-10-06 02:53:57.924756: train_loss -0.8712
2025-10-06 02:53:57.924919: val_loss -0.3586
2025-10-06 02:53:57.925028: Pseudo dice [np.float32(0.6956)]
2025-10-06 02:53:57.925176: Epoch time: 46.4 s
2025-10-06 02:53:58.580516: 
2025-10-06 02:53:58.580860: Epoch 127
2025-10-06 02:53:58.581027: Current learning rate: 0.00185
2025-10-06 02:54:44.917376: Validation loss did not improve from -0.44580. Patience: 98/50
2025-10-06 02:54:44.917960: train_loss -0.8701
2025-10-06 02:54:44.918121: val_loss -0.3201
2025-10-06 02:54:44.918240: Pseudo dice [np.float32(0.6806)]
2025-10-06 02:54:44.918374: Epoch time: 46.34 s
2025-10-06 02:54:45.572635: 
2025-10-06 02:54:45.572987: Epoch 128
2025-10-06 02:54:45.573180: Current learning rate: 0.00178
2025-10-06 02:55:31.960504: Validation loss did not improve from -0.44580. Patience: 99/50
2025-10-06 02:55:31.961154: train_loss -0.8755
2025-10-06 02:55:31.961296: val_loss -0.337
2025-10-06 02:55:31.961408: Pseudo dice [np.float32(0.686)]
2025-10-06 02:55:31.961534: Epoch time: 46.39 s
2025-10-06 02:55:32.995074: 
2025-10-06 02:55:32.995406: Epoch 129
2025-10-06 02:55:32.995567: Current learning rate: 0.0017
2025-10-06 02:56:19.506647: Validation loss did not improve from -0.44580. Patience: 100/50
2025-10-06 02:56:19.507175: train_loss -0.8732
2025-10-06 02:56:19.507426: val_loss -0.3168
2025-10-06 02:56:19.507682: Pseudo dice [np.float32(0.684)]
2025-10-06 02:56:19.507985: Epoch time: 46.51 s
2025-10-06 02:56:20.649672: 
2025-10-06 02:56:20.650010: Epoch 130
2025-10-06 02:56:20.650297: Current learning rate: 0.00163
2025-10-06 02:57:07.016702: Validation loss did not improve from -0.44580. Patience: 101/50
2025-10-06 02:57:07.017774: train_loss -0.8707
2025-10-06 02:57:07.018077: val_loss -0.3486
2025-10-06 02:57:07.018333: Pseudo dice [np.float32(0.6881)]
2025-10-06 02:57:07.018642: Epoch time: 46.37 s
2025-10-06 02:57:07.674017: 
2025-10-06 02:57:07.674478: Epoch 131
2025-10-06 02:57:07.674789: Current learning rate: 0.00156
2025-10-06 02:57:54.078170: Validation loss did not improve from -0.44580. Patience: 102/50
2025-10-06 02:57:54.078715: train_loss -0.8736
2025-10-06 02:57:54.078914: val_loss -0.3537
2025-10-06 02:57:54.079051: Pseudo dice [np.float32(0.6958)]
2025-10-06 02:57:54.079215: Epoch time: 46.41 s
2025-10-06 02:57:54.725531: 
2025-10-06 02:57:54.725912: Epoch 132
2025-10-06 02:57:54.726107: Current learning rate: 0.00148
2025-10-06 02:58:41.193488: Validation loss did not improve from -0.44580. Patience: 103/50
2025-10-06 02:58:41.194121: train_loss -0.8729
2025-10-06 02:58:41.194289: val_loss -0.346
2025-10-06 02:58:41.194429: Pseudo dice [np.float32(0.6893)]
2025-10-06 02:58:41.194601: Epoch time: 46.47 s
2025-10-06 02:58:41.851665: 
2025-10-06 02:58:41.851952: Epoch 133
2025-10-06 02:58:41.852146: Current learning rate: 0.00141
2025-10-06 02:59:28.346567: Validation loss did not improve from -0.44580. Patience: 104/50
2025-10-06 02:59:28.347007: train_loss -0.8752
2025-10-06 02:59:28.347190: val_loss -0.3421
2025-10-06 02:59:28.347308: Pseudo dice [np.float32(0.6837)]
2025-10-06 02:59:28.347445: Epoch time: 46.5 s
2025-10-06 02:59:29.003726: 
2025-10-06 02:59:29.004058: Epoch 134
2025-10-06 02:59:29.004242: Current learning rate: 0.00133
2025-10-06 03:00:15.577568: Validation loss did not improve from -0.44580. Patience: 105/50
2025-10-06 03:00:15.578392: train_loss -0.874
2025-10-06 03:00:15.578646: val_loss -0.2952
2025-10-06 03:00:15.578804: Pseudo dice [np.float32(0.6839)]
2025-10-06 03:00:15.579050: Epoch time: 46.58 s
2025-10-06 03:00:16.720529: 
2025-10-06 03:00:16.720916: Epoch 135
2025-10-06 03:00:16.721133: Current learning rate: 0.00126
2025-10-06 03:01:03.288676: Validation loss did not improve from -0.44580. Patience: 106/50
2025-10-06 03:01:03.289147: train_loss -0.8774
2025-10-06 03:01:03.289335: val_loss -0.3885
2025-10-06 03:01:03.289472: Pseudo dice [np.float32(0.7071)]
2025-10-06 03:01:03.289602: Epoch time: 46.57 s
2025-10-06 03:01:03.949689: 
2025-10-06 03:01:03.950162: Epoch 136
2025-10-06 03:01:03.950338: Current learning rate: 0.00118
2025-10-06 03:01:50.516776: Validation loss did not improve from -0.44580. Patience: 107/50
2025-10-06 03:01:50.517404: train_loss -0.8776
2025-10-06 03:01:50.517558: val_loss -0.3545
2025-10-06 03:01:50.517673: Pseudo dice [np.float32(0.6919)]
2025-10-06 03:01:50.517903: Epoch time: 46.57 s
2025-10-06 03:01:50.518024: Yayy! New best EMA pseudo Dice: 0.6898999810218811
2025-10-06 03:01:51.627412: 
2025-10-06 03:01:51.627740: Epoch 137
2025-10-06 03:01:51.627991: Current learning rate: 0.00111
2025-10-06 03:02:38.183327: Validation loss did not improve from -0.44580. Patience: 108/50
2025-10-06 03:02:38.183783: train_loss -0.8776
2025-10-06 03:02:38.184014: val_loss -0.3182
2025-10-06 03:02:38.184168: Pseudo dice [np.float32(0.6783)]
2025-10-06 03:02:38.184359: Epoch time: 46.56 s
2025-10-06 03:02:38.834049: 
2025-10-06 03:02:38.834422: Epoch 138
2025-10-06 03:02:38.834686: Current learning rate: 0.00103
2025-10-06 03:03:25.383711: Validation loss did not improve from -0.44580. Patience: 109/50
2025-10-06 03:03:25.384303: train_loss -0.8791
2025-10-06 03:03:25.384576: val_loss -0.3211
2025-10-06 03:03:25.384742: Pseudo dice [np.float32(0.6895)]
2025-10-06 03:03:25.384966: Epoch time: 46.55 s
2025-10-06 03:03:26.039925: 
2025-10-06 03:03:26.040249: Epoch 139
2025-10-06 03:03:26.040499: Current learning rate: 0.00095
2025-10-06 03:04:12.581152: Validation loss did not improve from -0.44580. Patience: 110/50
2025-10-06 03:04:12.581664: train_loss -0.8783
2025-10-06 03:04:12.581826: val_loss -0.3439
2025-10-06 03:04:12.581963: Pseudo dice [np.float32(0.6912)]
2025-10-06 03:04:12.582106: Epoch time: 46.54 s
2025-10-06 03:04:14.116395: 
2025-10-06 03:04:14.116729: Epoch 140
2025-10-06 03:04:14.116932: Current learning rate: 0.00087
2025-10-06 03:05:00.682632: Validation loss did not improve from -0.44580. Patience: 111/50
2025-10-06 03:05:00.683454: train_loss -0.8798
2025-10-06 03:05:00.683661: val_loss -0.3196
2025-10-06 03:05:00.683845: Pseudo dice [np.float32(0.6872)]
2025-10-06 03:05:00.684024: Epoch time: 46.57 s
2025-10-06 03:05:01.345898: 
2025-10-06 03:05:01.346200: Epoch 141
2025-10-06 03:05:01.346394: Current learning rate: 0.00079
2025-10-06 03:05:47.855942: Validation loss did not improve from -0.44580. Patience: 112/50
2025-10-06 03:05:47.856375: train_loss -0.8792
2025-10-06 03:05:47.856587: val_loss -0.3481
2025-10-06 03:05:47.856762: Pseudo dice [np.float32(0.6807)]
2025-10-06 03:05:47.856944: Epoch time: 46.51 s
2025-10-06 03:05:48.516400: 
2025-10-06 03:05:48.516805: Epoch 142
2025-10-06 03:05:48.517017: Current learning rate: 0.00071
2025-10-06 03:06:35.035717: Validation loss did not improve from -0.44580. Patience: 113/50
2025-10-06 03:06:35.036391: train_loss -0.8829
2025-10-06 03:06:35.036536: val_loss -0.2995
2025-10-06 03:06:35.036658: Pseudo dice [np.float32(0.6613)]
2025-10-06 03:06:35.036832: Epoch time: 46.52 s
2025-10-06 03:06:35.686000: 
2025-10-06 03:06:35.686377: Epoch 143
2025-10-06 03:06:35.686587: Current learning rate: 0.00063
2025-10-06 03:07:22.126348: Validation loss did not improve from -0.44580. Patience: 114/50
2025-10-06 03:07:22.126893: train_loss -0.881
2025-10-06 03:07:22.127087: val_loss -0.348
2025-10-06 03:07:22.127246: Pseudo dice [np.float32(0.6885)]
2025-10-06 03:07:22.127499: Epoch time: 46.44 s
2025-10-06 03:07:22.802961: 
2025-10-06 03:07:22.803387: Epoch 144
2025-10-06 03:07:22.803607: Current learning rate: 0.00055
2025-10-06 03:08:09.262298: Validation loss did not improve from -0.44580. Patience: 115/50
2025-10-06 03:08:09.262964: train_loss -0.8825
2025-10-06 03:08:09.263122: val_loss -0.3655
2025-10-06 03:08:09.263244: Pseudo dice [np.float32(0.708)]
2025-10-06 03:08:09.263370: Epoch time: 46.46 s
2025-10-06 03:08:10.408454: 
2025-10-06 03:08:10.408731: Epoch 145
2025-10-06 03:08:10.408915: Current learning rate: 0.00047
2025-10-06 03:08:56.949797: Validation loss did not improve from -0.44580. Patience: 116/50
2025-10-06 03:08:56.950178: train_loss -0.8825
2025-10-06 03:08:56.950327: val_loss -0.3513
2025-10-06 03:08:56.950446: Pseudo dice [np.float32(0.6827)]
2025-10-06 03:08:56.950593: Epoch time: 46.54 s
2025-10-06 03:08:57.615000: 
2025-10-06 03:08:57.615375: Epoch 146
2025-10-06 03:08:57.615581: Current learning rate: 0.00038
2025-10-06 03:09:44.186715: Validation loss did not improve from -0.44580. Patience: 117/50
2025-10-06 03:09:44.187223: train_loss -0.8841
2025-10-06 03:09:44.187386: val_loss -0.3164
2025-10-06 03:09:44.187526: Pseudo dice [np.float32(0.6872)]
2025-10-06 03:09:44.187662: Epoch time: 46.57 s
2025-10-06 03:09:44.843398: 
2025-10-06 03:09:44.843783: Epoch 147
2025-10-06 03:09:44.843974: Current learning rate: 0.0003
2025-10-06 03:10:31.302227: Validation loss did not improve from -0.44580. Patience: 118/50
2025-10-06 03:10:31.302656: train_loss -0.8806
2025-10-06 03:10:31.302855: val_loss -0.3253
2025-10-06 03:10:31.303038: Pseudo dice [np.float32(0.682)]
2025-10-06 03:10:31.303236: Epoch time: 46.46 s
2025-10-06 03:10:31.961228: 
2025-10-06 03:10:31.961494: Epoch 148
2025-10-06 03:10:31.961800: Current learning rate: 0.00021
2025-10-06 03:11:18.290044: Validation loss did not improve from -0.44580. Patience: 119/50
2025-10-06 03:11:18.290619: train_loss -0.8842
2025-10-06 03:11:18.290802: val_loss -0.3405
2025-10-06 03:11:18.290967: Pseudo dice [np.float32(0.6879)]
2025-10-06 03:11:18.291164: Epoch time: 46.33 s
2025-10-06 03:11:18.955406: 
2025-10-06 03:11:18.955771: Epoch 149
2025-10-06 03:11:18.956012: Current learning rate: 0.00011
2025-10-06 03:12:05.333859: Validation loss did not improve from -0.44580. Patience: 120/50
2025-10-06 03:12:05.334308: train_loss -0.8845
2025-10-06 03:12:05.334460: val_loss -0.3231
2025-10-06 03:12:05.334612: Pseudo dice [np.float32(0.6913)]
2025-10-06 03:12:05.334753: Epoch time: 46.38 s
2025-10-06 03:12:06.506695: Training done.
2025-10-06 03:12:06.529101: Using splits from existing split file: /nfs/erelab001/shared/Computational_Group/Naravich/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset310_nnInteractive_Calcium_OCT_CrossValidation/splits_final_40.json
2025-10-06 03:12:06.531303: The split file contains 5 splits.
2025-10-06 03:12:06.532281: Desired fold for training: 4
2025-10-06 03:12:06.532807: This split has 3 training and 5 validation cases.
2025-10-06 03:12:06.533263: predicting 101-044
2025-10-06 03:12:06.536928: 101-044, shape torch.Size([1, 404, 498, 498]), rank 0
2025-10-06 03:12:47.835051: predicting 101-045
2025-10-06 03:12:47.849097: 101-045, shape torch.Size([1, 375, 498, 498]), rank 0
2025-10-06 03:13:22.166021: predicting 401-004
2025-10-06 03:13:22.179099: 401-004, shape torch.Size([1, 375, 498, 498]), rank 0
2025-10-06 03:13:56.395439: predicting 704-003
2025-10-06 03:13:56.408752: 704-003, shape torch.Size([1, 375, 498, 498]), rank 0
2025-10-06 03:14:30.620115: predicting 706-005
2025-10-06 03:14:30.639433: 706-005, shape torch.Size([1, 375, 498, 498]), rank 0
2025-10-06 03:15:18.236379: Validation complete
2025-10-06 03:15:18.236692: Mean Validation Dice:  0.6697330615278693
Finished training fold 4 saving to /nfs/erelab001/shared/Computational_Group/Naravich/datasets/nnUNet_Datasets/nnUNet_results/Dataset310_nnInteractive_Calcium_OCT_CrossValidation/nnUNetTrainerScaleAnalysis40__nnUNetPlans__3d_32x160x128_b10/fold_4_No_Pretrained
