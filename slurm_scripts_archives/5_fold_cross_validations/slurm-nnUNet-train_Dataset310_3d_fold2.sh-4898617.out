/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/bin/python
Starting training with CONFIG=3d_32x160x128_b10, DATASET_ID=310, TRAINER=nnUNetTrainer
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:169: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2025-10-02 18:53:11.379915: do_dummy_2d_data_aug: True
2025-10-02 18:53:11.380804: Using splits from existing split file: /nfs/erelab001/shared/Computational_Group/Naravich/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset310_nnInteractive_Calcium_OCT_CrossValidation/splits_final.json
2025-10-02 18:53:11.381279: The split file contains 5 splits.
2025-10-02 18:53:11.381406: Desired fold for training: 2
2025-10-02 18:53:11.381513: This split has 6 training and 2 validation cases.
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)
  output = output[crop_slices].contiguous()
using pin_memory on device 0
using pin_memory on device 0
2025-10-02 18:53:18.090757: Using torch.compile...

This is the configuration used by this training:
Configuration name: 3d_32x160x128_b10
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 10, 'patch_size': [32, 160, 128], 'median_image_size_in_voxels': [375.0, 498.0, 498.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'inherits_from': '3d_fullres'} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset310_nnInteractive_Calcium_OCT_CrossValidation', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.4977976381778717, 'mean': 0.1394134759902954, 'median': 0.09849607944488525, 'min': 0.0, 'percentile_00_5': 0.015305490233004093, 'percentile_99_5': 0.4977976381778717, 'std': 0.121165432035923}}} 

2025-10-02 18:53:19.343658: unpacking dataset...
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:7095: UserWarning: 
Online softmax is disabled on the fly since Inductor decides to
split the reduction. Cut an issue to PyTorch if this is an
important use case and you want to speed it up with online
softmax.

  warnings.warn(
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:7095: UserWarning: 
Online softmax is disabled on the fly since Inductor decides to
split the reduction. Cut an issue to PyTorch if this is an
important use case and you want to speed it up with online
softmax.

  warnings.warn(
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:7095: UserWarning: 
Online softmax is disabled on the fly since Inductor decides to
split the reduction. Cut an issue to PyTorch if this is an
important use case and you want to speed it up with online
softmax.

  warnings.warn(
/nfs/erelab001/shared/Computational_Group/Naravich/nnUNet/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:7095: UserWarning: 
Online softmax is disabled on the fly since Inductor decides to
split the reduction. Cut an issue to PyTorch if this is an
important use case and you want to speed it up with online
softmax.

  warnings.warn(
2025-10-02 18:53:23.720671: unpacking done...
2025-10-02 18:53:23.737767: Unable to plot network architecture: nnUNet_compile is enabled!
2025-10-02 18:53:23.743025: 
2025-10-02 18:53:23.743264: Epoch 0
2025-10-02 18:53:23.743587: Current learning rate: 0.01
2025-10-02 18:54:42.919822: Validation loss improved from 1000.00000 to -0.11226! Patience: 0/50
2025-10-02 18:54:42.920486: train_loss -0.1312
2025-10-02 18:54:42.920806: val_loss -0.1123
2025-10-02 18:54:42.921135: Pseudo dice [np.float32(0.5029)]
2025-10-02 18:54:42.921515: Epoch time: 79.18 s
2025-10-02 18:54:42.921697: Yayy! New best EMA pseudo Dice: 0.5029000043869019
2025-10-02 18:54:43.830636: 
2025-10-02 18:54:43.831043: Epoch 1
2025-10-02 18:54:43.831347: Current learning rate: 0.00994
2025-10-02 18:55:29.854195: Validation loss improved from -0.11226 to -0.19831! Patience: 0/50
2025-10-02 18:55:29.854961: train_loss -0.2599
2025-10-02 18:55:29.855315: val_loss -0.1983
2025-10-02 18:55:29.855652: Pseudo dice [np.float32(0.5359)]
2025-10-02 18:55:29.855989: Epoch time: 46.03 s
2025-10-02 18:55:29.856308: Yayy! New best EMA pseudo Dice: 0.5062000155448914
2025-10-02 18:55:30.928204: 
2025-10-02 18:55:30.928510: Epoch 2
2025-10-02 18:55:30.928719: Current learning rate: 0.00988
2025-10-02 18:56:16.979541: Validation loss improved from -0.19831 to -0.23785! Patience: 0/50
2025-10-02 18:56:16.980144: train_loss -0.269
2025-10-02 18:56:16.980499: val_loss -0.2379
2025-10-02 18:56:16.980646: Pseudo dice [np.float32(0.5531)]
2025-10-02 18:56:16.980808: Epoch time: 46.05 s
2025-10-02 18:56:16.980937: Yayy! New best EMA pseudo Dice: 0.5109000205993652
2025-10-02 18:56:18.058126: 
2025-10-02 18:56:18.058619: Epoch 3
2025-10-02 18:56:18.058954: Current learning rate: 0.00982
2025-10-02 18:57:04.194376: Validation loss did not improve from -0.23785. Patience: 1/50
2025-10-02 18:57:04.194890: train_loss -0.3139
2025-10-02 18:57:04.195038: val_loss -0.2216
2025-10-02 18:57:04.195164: Pseudo dice [np.float32(0.543)]
2025-10-02 18:57:04.195320: Epoch time: 46.14 s
2025-10-02 18:57:04.195462: Yayy! New best EMA pseudo Dice: 0.5141000151634216
2025-10-02 18:57:05.267516: 
2025-10-02 18:57:05.267837: Epoch 4
2025-10-02 18:57:05.268042: Current learning rate: 0.00976
2025-10-02 18:57:51.390348: Validation loss improved from -0.23785 to -0.33248! Patience: 1/50
2025-10-02 18:57:51.390922: train_loss -0.338
2025-10-02 18:57:51.391306: val_loss -0.3325
2025-10-02 18:57:51.391599: Pseudo dice [np.float32(0.612)]
2025-10-02 18:57:51.391792: Epoch time: 46.12 s
2025-10-02 18:57:51.775048: Yayy! New best EMA pseudo Dice: 0.5238999724388123
2025-10-02 18:57:52.830513: 
2025-10-02 18:57:52.830862: Epoch 5
2025-10-02 18:57:52.831091: Current learning rate: 0.0097
2025-10-02 18:58:38.977052: Validation loss did not improve from -0.33248. Patience: 1/50
2025-10-02 18:58:38.977508: train_loss -0.3588
2025-10-02 18:58:38.977690: val_loss -0.3205
2025-10-02 18:58:38.977834: Pseudo dice [np.float32(0.6169)]
2025-10-02 18:58:38.977986: Epoch time: 46.15 s
2025-10-02 18:58:38.978121: Yayy! New best EMA pseudo Dice: 0.5332000255584717
2025-10-02 18:58:40.035614: 
2025-10-02 18:58:40.036135: Epoch 6
2025-10-02 18:58:40.036538: Current learning rate: 0.00964
2025-10-02 18:59:26.134701: Validation loss did not improve from -0.33248. Patience: 2/50
2025-10-02 18:59:26.135444: train_loss -0.3748
2025-10-02 18:59:26.135842: val_loss -0.3305
2025-10-02 18:59:26.136050: Pseudo dice [np.float32(0.6186)]
2025-10-02 18:59:26.136192: Epoch time: 46.1 s
2025-10-02 18:59:26.136457: Yayy! New best EMA pseudo Dice: 0.541700005531311
2025-10-02 18:59:27.210868: 
2025-10-02 18:59:27.211405: Epoch 7
2025-10-02 18:59:27.211804: Current learning rate: 0.00958
2025-10-02 19:00:13.334901: Validation loss improved from -0.33248 to -0.35833! Patience: 2/50
2025-10-02 19:00:13.335355: train_loss -0.4032
2025-10-02 19:00:13.335545: val_loss -0.3583
2025-10-02 19:00:13.335719: Pseudo dice [np.float32(0.6299)]
2025-10-02 19:00:13.335884: Epoch time: 46.13 s
2025-10-02 19:00:13.336038: Yayy! New best EMA pseudo Dice: 0.5504999756813049
2025-10-02 19:00:14.417298: 
2025-10-02 19:00:14.417737: Epoch 8
2025-10-02 19:00:14.418003: Current learning rate: 0.00952
2025-10-02 19:01:00.594017: Validation loss did not improve from -0.35833. Patience: 1/50
2025-10-02 19:01:00.594513: train_loss -0.4204
2025-10-02 19:01:00.594737: val_loss -0.3058
2025-10-02 19:01:00.594927: Pseudo dice [np.float32(0.5958)]
2025-10-02 19:01:00.595099: Epoch time: 46.18 s
2025-10-02 19:01:00.595243: Yayy! New best EMA pseudo Dice: 0.5551000237464905
2025-10-02 19:01:01.697366: 
2025-10-02 19:01:01.697935: Epoch 9
2025-10-02 19:01:01.698411: Current learning rate: 0.00946
2025-10-02 19:01:47.873726: Validation loss did not improve from -0.35833. Patience: 2/50
2025-10-02 19:01:47.874184: train_loss -0.436
2025-10-02 19:01:47.874391: val_loss -0.3521
2025-10-02 19:01:47.874523: Pseudo dice [np.float32(0.626)]
2025-10-02 19:01:47.874689: Epoch time: 46.18 s
2025-10-02 19:01:48.318495: Yayy! New best EMA pseudo Dice: 0.5622000098228455
2025-10-02 19:01:49.379792: 
2025-10-02 19:01:49.380300: Epoch 10
2025-10-02 19:01:49.380583: Current learning rate: 0.0094
2025-10-02 19:02:35.558470: Validation loss improved from -0.35833 to -0.36465! Patience: 2/50
2025-10-02 19:02:35.558999: train_loss -0.4321
2025-10-02 19:02:35.559225: val_loss -0.3647
2025-10-02 19:02:35.559458: Pseudo dice [np.float32(0.6308)]
2025-10-02 19:02:35.559650: Epoch time: 46.18 s
2025-10-02 19:02:35.559866: Yayy! New best EMA pseudo Dice: 0.5690000057220459
2025-10-02 19:02:36.638250: 
2025-10-02 19:02:36.638557: Epoch 11
2025-10-02 19:02:36.638803: Current learning rate: 0.00934
2025-10-02 19:03:22.764530: Validation loss improved from -0.36465 to -0.39272! Patience: 0/50
2025-10-02 19:03:22.765181: train_loss -0.4491
2025-10-02 19:03:22.765586: val_loss -0.3927
2025-10-02 19:03:22.765934: Pseudo dice [np.float32(0.6294)]
2025-10-02 19:03:22.766325: Epoch time: 46.13 s
2025-10-02 19:03:22.766680: Yayy! New best EMA pseudo Dice: 0.574999988079071
2025-10-02 19:03:24.296408: 
2025-10-02 19:03:24.296820: Epoch 12
2025-10-02 19:03:24.297023: Current learning rate: 0.00928
2025-10-02 19:04:10.452258: Validation loss did not improve from -0.39272. Patience: 1/50
2025-10-02 19:04:10.452730: train_loss -0.4661
2025-10-02 19:04:10.452906: val_loss -0.3908
2025-10-02 19:04:10.453056: Pseudo dice [np.float32(0.6339)]
2025-10-02 19:04:10.453231: Epoch time: 46.16 s
2025-10-02 19:04:10.453409: Yayy! New best EMA pseudo Dice: 0.5809000134468079
2025-10-02 19:04:11.539430: 
2025-10-02 19:04:11.539787: Epoch 13
2025-10-02 19:04:11.539986: Current learning rate: 0.00922
2025-10-02 19:04:57.714484: Validation loss did not improve from -0.39272. Patience: 2/50
2025-10-02 19:04:57.715011: train_loss -0.4613
2025-10-02 19:04:57.715318: val_loss -0.3921
2025-10-02 19:04:57.715508: Pseudo dice [np.float32(0.6443)]
2025-10-02 19:04:57.715856: Epoch time: 46.18 s
2025-10-02 19:04:57.716079: Yayy! New best EMA pseudo Dice: 0.5873000025749207
2025-10-02 19:04:58.802726: 
2025-10-02 19:04:58.803093: Epoch 14
2025-10-02 19:04:58.803380: Current learning rate: 0.00916
2025-10-02 19:05:44.926502: Validation loss improved from -0.39272 to -0.40434! Patience: 2/50
2025-10-02 19:05:44.927194: train_loss -0.4788
2025-10-02 19:05:44.927586: val_loss -0.4043
2025-10-02 19:05:44.927882: Pseudo dice [np.float32(0.6431)]
2025-10-02 19:05:44.928198: Epoch time: 46.13 s
2025-10-02 19:05:45.358938: Yayy! New best EMA pseudo Dice: 0.5928999781608582
2025-10-02 19:05:46.425718: 
2025-10-02 19:05:46.426074: Epoch 15
2025-10-02 19:05:46.426300: Current learning rate: 0.0091
2025-10-02 19:06:32.576794: Validation loss improved from -0.40434 to -0.41206! Patience: 0/50
2025-10-02 19:06:32.577271: train_loss -0.4863
2025-10-02 19:06:32.577479: val_loss -0.4121
2025-10-02 19:06:32.577640: Pseudo dice [np.float32(0.6523)]
2025-10-02 19:06:32.577816: Epoch time: 46.15 s
2025-10-02 19:06:32.577985: Yayy! New best EMA pseudo Dice: 0.598800003528595
2025-10-02 19:06:33.660540: 
2025-10-02 19:06:33.661064: Epoch 16
2025-10-02 19:06:33.661479: Current learning rate: 0.00903
2025-10-02 19:07:19.833250: Validation loss improved from -0.41206 to -0.43109! Patience: 0/50
2025-10-02 19:07:19.833797: train_loss -0.4973
2025-10-02 19:07:19.833990: val_loss -0.4311
2025-10-02 19:07:19.834172: Pseudo dice [np.float32(0.6611)]
2025-10-02 19:07:19.834405: Epoch time: 46.17 s
2025-10-02 19:07:19.834572: Yayy! New best EMA pseudo Dice: 0.6050000190734863
2025-10-02 19:07:20.940635: 
2025-10-02 19:07:20.940900: Epoch 17
2025-10-02 19:07:20.941109: Current learning rate: 0.00897
2025-10-02 19:08:07.128268: Validation loss did not improve from -0.43109. Patience: 1/50
2025-10-02 19:08:07.128722: train_loss -0.5158
2025-10-02 19:08:07.128977: val_loss -0.4246
2025-10-02 19:08:07.129123: Pseudo dice [np.float32(0.6614)]
2025-10-02 19:08:07.129262: Epoch time: 46.19 s
2025-10-02 19:08:07.129500: Yayy! New best EMA pseudo Dice: 0.6107000112533569
2025-10-02 19:08:08.222847: 
2025-10-02 19:08:08.223082: Epoch 18
2025-10-02 19:08:08.223268: Current learning rate: 0.00891
2025-10-02 19:08:54.398741: Validation loss did not improve from -0.43109. Patience: 2/50
2025-10-02 19:08:54.399242: train_loss -0.5109
2025-10-02 19:08:54.399396: val_loss -0.3654
2025-10-02 19:08:54.399554: Pseudo dice [np.float32(0.6277)]
2025-10-02 19:08:54.399689: Epoch time: 46.18 s
2025-10-02 19:08:54.399913: Yayy! New best EMA pseudo Dice: 0.6123999953269958
2025-10-02 19:08:55.494168: 
2025-10-02 19:08:55.494701: Epoch 19
2025-10-02 19:08:55.495203: Current learning rate: 0.00885
2025-10-02 19:09:41.676859: Validation loss did not improve from -0.43109. Patience: 3/50
2025-10-02 19:09:41.677244: train_loss -0.5067
2025-10-02 19:09:41.677401: val_loss -0.4185
2025-10-02 19:09:41.677571: Pseudo dice [np.float32(0.6463)]
2025-10-02 19:09:41.677753: Epoch time: 46.18 s
2025-10-02 19:09:42.116963: Yayy! New best EMA pseudo Dice: 0.6158000230789185
2025-10-02 19:09:43.192575: 
2025-10-02 19:09:43.192937: Epoch 20
2025-10-02 19:09:43.193161: Current learning rate: 0.00879
2025-10-02 19:10:29.374635: Validation loss did not improve from -0.43109. Patience: 4/50
2025-10-02 19:10:29.375138: train_loss -0.5078
2025-10-02 19:10:29.375319: val_loss -0.4038
2025-10-02 19:10:29.375470: Pseudo dice [np.float32(0.6464)]
2025-10-02 19:10:29.375634: Epoch time: 46.18 s
2025-10-02 19:10:29.375799: Yayy! New best EMA pseudo Dice: 0.6187999844551086
2025-10-02 19:10:30.471476: 
2025-10-02 19:10:30.471884: Epoch 21
2025-10-02 19:10:30.472110: Current learning rate: 0.00873
2025-10-02 19:11:16.677150: Validation loss did not improve from -0.43109. Patience: 5/50
2025-10-02 19:11:16.677834: train_loss -0.521
2025-10-02 19:11:16.678240: val_loss -0.4228
2025-10-02 19:11:16.678616: Pseudo dice [np.float32(0.64)]
2025-10-02 19:11:16.679009: Epoch time: 46.21 s
2025-10-02 19:11:16.679364: Yayy! New best EMA pseudo Dice: 0.6208999752998352
2025-10-02 19:11:17.760278: 
2025-10-02 19:11:17.760875: Epoch 22
2025-10-02 19:11:17.761311: Current learning rate: 0.00867
2025-10-02 19:12:03.963160: Validation loss did not improve from -0.43109. Patience: 6/50
2025-10-02 19:12:03.963683: train_loss -0.5343
2025-10-02 19:12:03.963900: val_loss -0.4138
2025-10-02 19:12:03.964063: Pseudo dice [np.float32(0.6623)]
2025-10-02 19:12:03.964223: Epoch time: 46.2 s
2025-10-02 19:12:03.964407: Yayy! New best EMA pseudo Dice: 0.6251000165939331
2025-10-02 19:12:05.018453: 
2025-10-02 19:12:05.019000: Epoch 23
2025-10-02 19:12:05.019458: Current learning rate: 0.00861
2025-10-02 19:12:51.154142: Validation loss did not improve from -0.43109. Patience: 7/50
2025-10-02 19:12:51.154650: train_loss -0.5401
2025-10-02 19:12:51.154823: val_loss -0.3888
2025-10-02 19:12:51.155005: Pseudo dice [np.float32(0.6407)]
2025-10-02 19:12:51.155160: Epoch time: 46.14 s
2025-10-02 19:12:51.155295: Yayy! New best EMA pseudo Dice: 0.6266000270843506
2025-10-02 19:12:52.217825: 
2025-10-02 19:12:52.218350: Epoch 24
2025-10-02 19:12:52.218760: Current learning rate: 0.00855
2025-10-02 19:13:38.432225: Validation loss did not improve from -0.43109. Patience: 8/50
2025-10-02 19:13:38.433000: train_loss -0.5387
2025-10-02 19:13:38.433388: val_loss -0.4168
2025-10-02 19:13:38.433794: Pseudo dice [np.float32(0.6604)]
2025-10-02 19:13:38.434182: Epoch time: 46.22 s
2025-10-02 19:13:38.861716: Yayy! New best EMA pseudo Dice: 0.6299999952316284
2025-10-02 19:13:39.912426: 
2025-10-02 19:13:39.912703: Epoch 25
2025-10-02 19:13:39.912919: Current learning rate: 0.00849
2025-10-02 19:14:26.083770: Validation loss improved from -0.43109 to -0.45314! Patience: 8/50
2025-10-02 19:14:26.084422: train_loss -0.5393
2025-10-02 19:14:26.084753: val_loss -0.4531
2025-10-02 19:14:26.085072: Pseudo dice [np.float32(0.6805)]
2025-10-02 19:14:26.085408: Epoch time: 46.17 s
2025-10-02 19:14:26.085739: Yayy! New best EMA pseudo Dice: 0.6351000070571899
2025-10-02 19:14:27.149099: 
2025-10-02 19:14:27.149931: Epoch 26
2025-10-02 19:14:27.150322: Current learning rate: 0.00843
2025-10-02 19:15:13.330494: Validation loss did not improve from -0.45314. Patience: 1/50
2025-10-02 19:15:13.330964: train_loss -0.5408
2025-10-02 19:15:13.331115: val_loss -0.4485
2025-10-02 19:15:13.331275: Pseudo dice [np.float32(0.6793)]
2025-10-02 19:15:13.331511: Epoch time: 46.18 s
2025-10-02 19:15:13.331649: Yayy! New best EMA pseudo Dice: 0.6395000219345093
2025-10-02 19:15:14.890433: 
2025-10-02 19:15:14.890792: Epoch 27
2025-10-02 19:15:14.891020: Current learning rate: 0.00836
2025-10-02 19:16:01.089852: Validation loss did not improve from -0.45314. Patience: 2/50
2025-10-02 19:16:01.090330: train_loss -0.5396
2025-10-02 19:16:01.090522: val_loss -0.394
2025-10-02 19:16:01.090674: Pseudo dice [np.float32(0.6455)]
2025-10-02 19:16:01.090857: Epoch time: 46.2 s
2025-10-02 19:16:01.091061: Yayy! New best EMA pseudo Dice: 0.6401000022888184
2025-10-02 19:16:02.160660: 
2025-10-02 19:16:02.161018: Epoch 28
2025-10-02 19:16:02.161202: Current learning rate: 0.0083
2025-10-02 19:16:48.384445: Validation loss did not improve from -0.45314. Patience: 3/50
2025-10-02 19:16:48.385016: train_loss -0.5431
2025-10-02 19:16:48.385188: val_loss -0.4254
2025-10-02 19:16:48.385367: Pseudo dice [np.float32(0.6508)]
2025-10-02 19:16:48.385539: Epoch time: 46.23 s
2025-10-02 19:16:48.385702: Yayy! New best EMA pseudo Dice: 0.6412000060081482
2025-10-02 19:16:49.462259: 
2025-10-02 19:16:49.462701: Epoch 29
2025-10-02 19:16:49.462999: Current learning rate: 0.00824
2025-10-02 19:17:35.631550: Validation loss did not improve from -0.45314. Patience: 4/50
2025-10-02 19:17:35.632252: train_loss -0.5412
2025-10-02 19:17:35.632521: val_loss -0.4142
2025-10-02 19:17:35.632760: Pseudo dice [np.float32(0.6589)]
2025-10-02 19:17:35.633166: Epoch time: 46.17 s
2025-10-02 19:17:36.073449: Yayy! New best EMA pseudo Dice: 0.6428999900817871
2025-10-02 19:17:37.141288: 
2025-10-02 19:17:37.141655: Epoch 30
2025-10-02 19:17:37.141847: Current learning rate: 0.00818
2025-10-02 19:18:23.311699: Validation loss did not improve from -0.45314. Patience: 5/50
2025-10-02 19:18:23.312253: train_loss -0.5664
2025-10-02 19:18:23.312424: val_loss -0.407
2025-10-02 19:18:23.312559: Pseudo dice [np.float32(0.6484)]
2025-10-02 19:18:23.312717: Epoch time: 46.17 s
2025-10-02 19:18:23.312901: Yayy! New best EMA pseudo Dice: 0.6434999704360962
2025-10-02 19:18:24.390118: 
2025-10-02 19:18:24.390472: Epoch 31
2025-10-02 19:18:24.390687: Current learning rate: 0.00812
2025-10-02 19:19:10.624472: Validation loss did not improve from -0.45314. Patience: 6/50
2025-10-02 19:19:10.625073: train_loss -0.5609
2025-10-02 19:19:10.625283: val_loss -0.4242
2025-10-02 19:19:10.625451: Pseudo dice [np.float32(0.6601)]
2025-10-02 19:19:10.625687: Epoch time: 46.24 s
2025-10-02 19:19:10.625914: Yayy! New best EMA pseudo Dice: 0.6450999975204468
2025-10-02 19:19:11.695573: 
2025-10-02 19:19:11.695923: Epoch 32
2025-10-02 19:19:11.696150: Current learning rate: 0.00806
2025-10-02 19:19:57.827257: Validation loss did not improve from -0.45314. Patience: 7/50
2025-10-02 19:19:57.827767: train_loss -0.5556
2025-10-02 19:19:57.827990: val_loss -0.4363
2025-10-02 19:19:57.828167: Pseudo dice [np.float32(0.6648)]
2025-10-02 19:19:57.828353: Epoch time: 46.13 s
2025-10-02 19:19:57.828674: Yayy! New best EMA pseudo Dice: 0.6470999717712402
2025-10-02 19:19:58.920335: 
2025-10-02 19:19:58.920846: Epoch 33
2025-10-02 19:19:58.921306: Current learning rate: 0.008
2025-10-02 19:20:45.092820: Validation loss improved from -0.45314 to -0.45858! Patience: 7/50
2025-10-02 19:20:45.093505: train_loss -0.5516
2025-10-02 19:20:45.093892: val_loss -0.4586
2025-10-02 19:20:45.094255: Pseudo dice [np.float32(0.6869)]
2025-10-02 19:20:45.094493: Epoch time: 46.17 s
2025-10-02 19:20:45.094767: Yayy! New best EMA pseudo Dice: 0.6510999798774719
2025-10-02 19:20:46.176277: 
2025-10-02 19:20:46.176513: Epoch 34
2025-10-02 19:20:46.176835: Current learning rate: 0.00793
2025-10-02 19:21:32.326532: Validation loss did not improve from -0.45858. Patience: 1/50
2025-10-02 19:21:32.328027: train_loss -0.5759
2025-10-02 19:21:32.328519: val_loss -0.438
2025-10-02 19:21:32.328978: Pseudo dice [np.float32(0.6743)]
2025-10-02 19:21:32.329459: Epoch time: 46.15 s
2025-10-02 19:21:32.776852: Yayy! New best EMA pseudo Dice: 0.6534000039100647
2025-10-02 19:21:33.857267: 
2025-10-02 19:21:33.857695: Epoch 35
2025-10-02 19:21:33.858043: Current learning rate: 0.00787
2025-10-02 19:22:20.051865: Validation loss improved from -0.45858 to -0.46566! Patience: 1/50
2025-10-02 19:22:20.052419: train_loss -0.568
2025-10-02 19:22:20.052873: val_loss -0.4657
2025-10-02 19:22:20.053201: Pseudo dice [np.float32(0.6947)]
2025-10-02 19:22:20.053583: Epoch time: 46.2 s
2025-10-02 19:22:20.053947: Yayy! New best EMA pseudo Dice: 0.6575999855995178
2025-10-02 19:22:21.149938: 
2025-10-02 19:22:21.150577: Epoch 36
2025-10-02 19:22:21.150974: Current learning rate: 0.00781
2025-10-02 19:23:07.339739: Validation loss did not improve from -0.46566. Patience: 1/50
2025-10-02 19:23:07.340327: train_loss -0.5759
2025-10-02 19:23:07.340493: val_loss -0.407
2025-10-02 19:23:07.340620: Pseudo dice [np.float32(0.6424)]
2025-10-02 19:23:07.340755: Epoch time: 46.19 s
2025-10-02 19:23:07.987779: 
2025-10-02 19:23:07.988222: Epoch 37
2025-10-02 19:23:07.988586: Current learning rate: 0.00775
2025-10-02 19:23:54.253806: Validation loss did not improve from -0.46566. Patience: 2/50
2025-10-02 19:23:54.254736: train_loss -0.5919
2025-10-02 19:23:54.255074: val_loss -0.4518
2025-10-02 19:23:54.255394: Pseudo dice [np.float32(0.6743)]
2025-10-02 19:23:54.255728: Epoch time: 46.27 s
2025-10-02 19:23:54.256053: Yayy! New best EMA pseudo Dice: 0.6578999757766724
2025-10-02 19:23:55.340962: 
2025-10-02 19:23:55.341291: Epoch 38
2025-10-02 19:23:55.341501: Current learning rate: 0.00769
2025-10-02 19:24:41.579660: Validation loss did not improve from -0.46566. Patience: 3/50
2025-10-02 19:24:41.580406: train_loss -0.5812
2025-10-02 19:24:41.580728: val_loss -0.4434
2025-10-02 19:24:41.581012: Pseudo dice [np.float32(0.6717)]
2025-10-02 19:24:41.581354: Epoch time: 46.24 s
2025-10-02 19:24:41.581679: Yayy! New best EMA pseudo Dice: 0.6592000126838684
2025-10-02 19:24:42.674766: 
2025-10-02 19:24:42.675302: Epoch 39
2025-10-02 19:24:42.675757: Current learning rate: 0.00763
2025-10-02 19:25:28.881366: Validation loss did not improve from -0.46566. Patience: 4/50
2025-10-02 19:25:28.881914: train_loss -0.5878
2025-10-02 19:25:28.882216: val_loss -0.4492
2025-10-02 19:25:28.882355: Pseudo dice [np.float32(0.6779)]
2025-10-02 19:25:28.882727: Epoch time: 46.21 s
2025-10-02 19:25:29.316222: Yayy! New best EMA pseudo Dice: 0.6610999703407288
2025-10-02 19:25:30.412317: 
2025-10-02 19:25:30.412672: Epoch 40
2025-10-02 19:25:30.412930: Current learning rate: 0.00756
2025-10-02 19:26:16.590366: Validation loss did not improve from -0.46566. Patience: 5/50
2025-10-02 19:26:16.591123: train_loss -0.5945
2025-10-02 19:26:16.591340: val_loss -0.4564
2025-10-02 19:26:16.591487: Pseudo dice [np.float32(0.6732)]
2025-10-02 19:26:16.591771: Epoch time: 46.18 s
2025-10-02 19:26:16.592025: Yayy! New best EMA pseudo Dice: 0.6622999906539917
2025-10-02 19:26:17.701577: 
2025-10-02 19:26:17.701889: Epoch 41
2025-10-02 19:26:17.702152: Current learning rate: 0.0075
2025-10-02 19:27:03.931594: Validation loss did not improve from -0.46566. Patience: 6/50
2025-10-02 19:27:03.932338: train_loss -0.5951
2025-10-02 19:27:03.932832: val_loss -0.4261
2025-10-02 19:27:03.933231: Pseudo dice [np.float32(0.6618)]
2025-10-02 19:27:03.933545: Epoch time: 46.23 s
2025-10-02 19:27:05.047052: 
2025-10-02 19:27:05.047280: Epoch 42
2025-10-02 19:27:05.047500: Current learning rate: 0.00744
2025-10-02 19:27:51.253842: Validation loss did not improve from -0.46566. Patience: 7/50
2025-10-02 19:27:51.254345: train_loss -0.6011
2025-10-02 19:27:51.254512: val_loss -0.4226
2025-10-02 19:27:51.254637: Pseudo dice [np.float32(0.6633)]
2025-10-02 19:27:51.254834: Epoch time: 46.21 s
2025-10-02 19:27:51.254990: Yayy! New best EMA pseudo Dice: 0.6624000072479248
2025-10-02 19:27:52.330260: 
2025-10-02 19:27:52.330502: Epoch 43
2025-10-02 19:27:52.330688: Current learning rate: 0.00738
2025-10-02 19:28:38.506729: Validation loss did not improve from -0.46566. Patience: 8/50
2025-10-02 19:28:38.507310: train_loss -0.6096
2025-10-02 19:28:38.507463: val_loss -0.4363
2025-10-02 19:28:38.507606: Pseudo dice [np.float32(0.666)]
2025-10-02 19:28:38.507745: Epoch time: 46.18 s
2025-10-02 19:28:38.507869: Yayy! New best EMA pseudo Dice: 0.6626999974250793
2025-10-02 19:28:39.596270: 
2025-10-02 19:28:39.596629: Epoch 44
2025-10-02 19:28:39.596904: Current learning rate: 0.00732
2025-10-02 19:29:25.752336: Validation loss did not improve from -0.46566. Patience: 9/50
2025-10-02 19:29:25.752835: train_loss -0.608
2025-10-02 19:29:25.752981: val_loss -0.4389
2025-10-02 19:29:25.753113: Pseudo dice [np.float32(0.6758)]
2025-10-02 19:29:25.753275: Epoch time: 46.16 s
2025-10-02 19:29:26.200901: Yayy! New best EMA pseudo Dice: 0.6640999913215637
2025-10-02 19:29:27.276265: 
2025-10-02 19:29:27.276612: Epoch 45
2025-10-02 19:29:27.276837: Current learning rate: 0.00725
2025-10-02 19:30:13.413789: Validation loss did not improve from -0.46566. Patience: 10/50
2025-10-02 19:30:13.414311: train_loss -0.6114
2025-10-02 19:30:13.414487: val_loss -0.4468
2025-10-02 19:30:13.414706: Pseudo dice [np.float32(0.6788)]
2025-10-02 19:30:13.414870: Epoch time: 46.14 s
2025-10-02 19:30:13.415072: Yayy! New best EMA pseudo Dice: 0.6654999852180481
2025-10-02 19:30:14.487566: 
2025-10-02 19:30:14.487838: Epoch 46
2025-10-02 19:30:14.488154: Current learning rate: 0.00719
2025-10-02 19:31:00.625591: Validation loss did not improve from -0.46566. Patience: 11/50
2025-10-02 19:31:00.626217: train_loss -0.6139
2025-10-02 19:31:00.626371: val_loss -0.4433
2025-10-02 19:31:00.626546: Pseudo dice [np.float32(0.678)]
2025-10-02 19:31:00.626701: Epoch time: 46.14 s
2025-10-02 19:31:00.626881: Yayy! New best EMA pseudo Dice: 0.6668000221252441
2025-10-02 19:31:01.699744: 
2025-10-02 19:31:01.700139: Epoch 47
2025-10-02 19:31:01.700533: Current learning rate: 0.00713
2025-10-02 19:31:47.903494: Validation loss did not improve from -0.46566. Patience: 12/50
2025-10-02 19:31:47.903897: train_loss -0.6195
2025-10-02 19:31:47.904108: val_loss -0.4586
2025-10-02 19:31:47.904267: Pseudo dice [np.float32(0.6841)]
2025-10-02 19:31:47.904459: Epoch time: 46.2 s
2025-10-02 19:31:47.904604: Yayy! New best EMA pseudo Dice: 0.6685000061988831
2025-10-02 19:31:48.971091: 
2025-10-02 19:31:48.971457: Epoch 48
2025-10-02 19:31:48.971696: Current learning rate: 0.00707
2025-10-02 19:32:35.124152: Validation loss did not improve from -0.46566. Patience: 13/50
2025-10-02 19:32:35.124665: train_loss -0.6281
2025-10-02 19:32:35.124847: val_loss -0.4545
2025-10-02 19:32:35.125001: Pseudo dice [np.float32(0.6833)]
2025-10-02 19:32:35.125149: Epoch time: 46.15 s
2025-10-02 19:32:35.125311: Yayy! New best EMA pseudo Dice: 0.6700000166893005
2025-10-02 19:32:36.198753: 
2025-10-02 19:32:36.199095: Epoch 49
2025-10-02 19:32:36.199314: Current learning rate: 0.007
2025-10-02 19:33:22.377262: Validation loss did not improve from -0.46566. Patience: 14/50
2025-10-02 19:33:22.378078: train_loss -0.6244
2025-10-02 19:33:22.378461: val_loss -0.4512
2025-10-02 19:33:22.378807: Pseudo dice [np.float32(0.6668)]
2025-10-02 19:33:22.379475: Epoch time: 46.18 s
2025-10-02 19:33:23.440474: 
2025-10-02 19:33:23.440810: Epoch 50
2025-10-02 19:33:23.441021: Current learning rate: 0.00694
2025-10-02 19:34:09.610745: Validation loss did not improve from -0.46566. Patience: 15/50
2025-10-02 19:34:09.611231: train_loss -0.6345
2025-10-02 19:34:09.611432: val_loss -0.4599
2025-10-02 19:34:09.611573: Pseudo dice [np.float32(0.7031)]
2025-10-02 19:34:09.611745: Epoch time: 46.17 s
2025-10-02 19:34:09.611872: Yayy! New best EMA pseudo Dice: 0.6729999780654907
2025-10-02 19:34:10.699146: 
2025-10-02 19:34:10.699616: Epoch 51
2025-10-02 19:34:10.699919: Current learning rate: 0.00688
2025-10-02 19:34:56.847311: Validation loss improved from -0.46566 to -0.47900! Patience: 15/50
2025-10-02 19:34:56.847780: train_loss -0.6347
2025-10-02 19:34:56.847952: val_loss -0.479
2025-10-02 19:34:56.848084: Pseudo dice [np.float32(0.6952)]
2025-10-02 19:34:56.848231: Epoch time: 46.15 s
2025-10-02 19:34:56.848453: Yayy! New best EMA pseudo Dice: 0.6751999855041504
2025-10-02 19:34:57.928008: 
2025-10-02 19:34:57.928357: Epoch 52
2025-10-02 19:34:57.928575: Current learning rate: 0.00682
2025-10-02 19:35:44.078945: Validation loss did not improve from -0.47900. Patience: 1/50
2025-10-02 19:35:44.080276: train_loss -0.6384
2025-10-02 19:35:44.080627: val_loss -0.4304
2025-10-02 19:35:44.080930: Pseudo dice [np.float32(0.6691)]
2025-10-02 19:35:44.081231: Epoch time: 46.15 s
2025-10-02 19:35:44.715981: 
2025-10-02 19:35:44.716359: Epoch 53
2025-10-02 19:35:44.716538: Current learning rate: 0.00675
2025-10-02 19:36:30.889930: Validation loss did not improve from -0.47900. Patience: 2/50
2025-10-02 19:36:30.890374: train_loss -0.6426
2025-10-02 19:36:30.890537: val_loss -0.4555
2025-10-02 19:36:30.890684: Pseudo dice [np.float32(0.6773)]
2025-10-02 19:36:30.890832: Epoch time: 46.18 s
2025-10-02 19:36:31.529137: 
2025-10-02 19:36:31.529682: Epoch 54
2025-10-02 19:36:31.530096: Current learning rate: 0.00669
2025-10-02 19:37:17.664860: Validation loss did not improve from -0.47900. Patience: 3/50
2025-10-02 19:37:17.665405: train_loss -0.6432
2025-10-02 19:37:17.665621: val_loss -0.4588
2025-10-02 19:37:17.665778: Pseudo dice [np.float32(0.6843)]
2025-10-02 19:37:17.665958: Epoch time: 46.14 s
2025-10-02 19:37:18.116079: Yayy! New best EMA pseudo Dice: 0.6758000254631042
2025-10-02 19:37:19.172948: 
2025-10-02 19:37:19.173301: Epoch 55
2025-10-02 19:37:19.173501: Current learning rate: 0.00663
2025-10-02 19:38:05.323071: Validation loss improved from -0.47900 to -0.48077! Patience: 3/50
2025-10-02 19:38:05.323683: train_loss -0.6388
2025-10-02 19:38:05.323990: val_loss -0.4808
2025-10-02 19:38:05.324216: Pseudo dice [np.float32(0.7058)]
2025-10-02 19:38:05.324500: Epoch time: 46.15 s
2025-10-02 19:38:05.324688: Yayy! New best EMA pseudo Dice: 0.6787999868392944
2025-10-02 19:38:06.402918: 
2025-10-02 19:38:06.403466: Epoch 56
2025-10-02 19:38:06.403859: Current learning rate: 0.00657
2025-10-02 19:38:52.511839: Validation loss did not improve from -0.48077. Patience: 1/50
2025-10-02 19:38:52.512459: train_loss -0.6362
2025-10-02 19:38:52.512838: val_loss -0.4568
2025-10-02 19:38:52.513165: Pseudo dice [np.float32(0.6802)]
2025-10-02 19:38:52.513505: Epoch time: 46.11 s
2025-10-02 19:38:52.513774: Yayy! New best EMA pseudo Dice: 0.6790000200271606
2025-10-02 19:38:53.592493: 
2025-10-02 19:38:53.592921: Epoch 57
2025-10-02 19:38:53.593191: Current learning rate: 0.0065
2025-10-02 19:39:39.737032: Validation loss did not improve from -0.48077. Patience: 2/50
2025-10-02 19:39:39.737479: train_loss -0.6489
2025-10-02 19:39:39.737665: val_loss -0.4364
2025-10-02 19:39:39.737859: Pseudo dice [np.float32(0.6647)]
2025-10-02 19:39:39.738043: Epoch time: 46.15 s
2025-10-02 19:39:40.894964: 
2025-10-02 19:39:40.895339: Epoch 58
2025-10-02 19:39:40.895557: Current learning rate: 0.00644
2025-10-02 19:40:27.087786: Validation loss did not improve from -0.48077. Patience: 3/50
2025-10-02 19:40:27.089136: train_loss -0.6461
2025-10-02 19:40:27.089583: val_loss -0.4406
2025-10-02 19:40:27.090004: Pseudo dice [np.float32(0.6791)]
2025-10-02 19:40:27.090435: Epoch time: 46.19 s
2025-10-02 19:40:27.736232: 
2025-10-02 19:40:27.736604: Epoch 59
2025-10-02 19:40:27.736823: Current learning rate: 0.00638
2025-10-02 19:41:13.963114: Validation loss did not improve from -0.48077. Patience: 4/50
2025-10-02 19:41:13.963728: train_loss -0.6509
2025-10-02 19:41:13.964098: val_loss -0.4773
2025-10-02 19:41:13.964410: Pseudo dice [np.float32(0.7024)]
2025-10-02 19:41:13.964736: Epoch time: 46.23 s
2025-10-02 19:41:14.399877: Yayy! New best EMA pseudo Dice: 0.6801999807357788
2025-10-02 19:41:15.477849: 
2025-10-02 19:41:15.478195: Epoch 60
2025-10-02 19:41:15.478405: Current learning rate: 0.00631
2025-10-02 19:42:01.658170: Validation loss did not improve from -0.48077. Patience: 5/50
2025-10-02 19:42:01.658670: train_loss -0.6636
2025-10-02 19:42:01.658821: val_loss -0.4463
2025-10-02 19:42:01.659040: Pseudo dice [np.float32(0.6891)]
2025-10-02 19:42:01.659185: Epoch time: 46.18 s
2025-10-02 19:42:01.659324: Yayy! New best EMA pseudo Dice: 0.6811000108718872
2025-10-02 19:42:02.766355: 
2025-10-02 19:42:02.766691: Epoch 61
2025-10-02 19:42:02.766914: Current learning rate: 0.00625
2025-10-02 19:42:48.914231: Validation loss did not improve from -0.48077. Patience: 6/50
2025-10-02 19:42:48.914861: train_loss -0.6563
2025-10-02 19:42:48.915016: val_loss -0.4465
2025-10-02 19:42:48.915144: Pseudo dice [np.float32(0.6752)]
2025-10-02 19:42:48.915289: Epoch time: 46.15 s
2025-10-02 19:42:49.561229: 
2025-10-02 19:42:49.561567: Epoch 62
2025-10-02 19:42:49.561763: Current learning rate: 0.00619
2025-10-02 19:43:35.757359: Validation loss improved from -0.48077 to -0.50234! Patience: 6/50
2025-10-02 19:43:35.757947: train_loss -0.6624
2025-10-02 19:43:35.758124: val_loss -0.5023
2025-10-02 19:43:35.758334: Pseudo dice [np.float32(0.7033)]
2025-10-02 19:43:35.758504: Epoch time: 46.2 s
2025-10-02 19:43:35.758724: Yayy! New best EMA pseudo Dice: 0.682699978351593
2025-10-02 19:43:36.856562: 
2025-10-02 19:43:36.856824: Epoch 63
2025-10-02 19:43:36.857065: Current learning rate: 0.00612
2025-10-02 19:44:22.978584: Validation loss did not improve from -0.50234. Patience: 1/50
2025-10-02 19:44:22.979270: train_loss -0.6673
2025-10-02 19:44:22.979725: val_loss -0.4227
2025-10-02 19:44:22.980064: Pseudo dice [np.float32(0.6735)]
2025-10-02 19:44:22.980386: Epoch time: 46.12 s
2025-10-02 19:44:23.631740: 
2025-10-02 19:44:23.632234: Epoch 64
2025-10-02 19:44:23.632661: Current learning rate: 0.00606
2025-10-02 19:45:09.816384: Validation loss did not improve from -0.50234. Patience: 2/50
2025-10-02 19:45:09.817641: train_loss -0.6619
2025-10-02 19:45:09.818053: val_loss -0.4335
2025-10-02 19:45:09.818431: Pseudo dice [np.float32(0.6685)]
2025-10-02 19:45:09.818905: Epoch time: 46.19 s
2025-10-02 19:45:10.901928: 
2025-10-02 19:45:10.902192: Epoch 65
2025-10-02 19:45:10.902384: Current learning rate: 0.006
2025-10-02 19:45:57.054751: Validation loss did not improve from -0.50234. Patience: 3/50
2025-10-02 19:45:57.055237: train_loss -0.6784
2025-10-02 19:45:57.055484: val_loss -0.4655
2025-10-02 19:45:57.055768: Pseudo dice [np.float32(0.692)]
2025-10-02 19:45:57.056025: Epoch time: 46.15 s
2025-10-02 19:45:57.721939: 
2025-10-02 19:45:57.722294: Epoch 66
2025-10-02 19:45:57.722535: Current learning rate: 0.00593
2025-10-02 19:46:43.870236: Validation loss did not improve from -0.50234. Patience: 4/50
2025-10-02 19:46:43.870836: train_loss -0.6742
2025-10-02 19:46:43.871103: val_loss -0.436
2025-10-02 19:46:43.871359: Pseudo dice [np.float32(0.6692)]
2025-10-02 19:46:43.871557: Epoch time: 46.15 s
2025-10-02 19:46:44.528793: 
2025-10-02 19:46:44.529090: Epoch 67
2025-10-02 19:46:44.529311: Current learning rate: 0.00587
2025-10-02 19:47:30.686540: Validation loss did not improve from -0.50234. Patience: 5/50
2025-10-02 19:47:30.687114: train_loss -0.683
2025-10-02 19:47:30.687290: val_loss -0.4653
2025-10-02 19:47:30.687427: Pseudo dice [np.float32(0.7013)]
2025-10-02 19:47:30.687562: Epoch time: 46.16 s
2025-10-02 19:47:31.334228: 
2025-10-02 19:47:31.334612: Epoch 68
2025-10-02 19:47:31.334831: Current learning rate: 0.00581
2025-10-02 19:48:17.475912: Validation loss did not improve from -0.50234. Patience: 6/50
2025-10-02 19:48:17.476425: train_loss -0.6844
2025-10-02 19:48:17.476694: val_loss -0.4841
2025-10-02 19:48:17.476848: Pseudo dice [np.float32(0.7054)]
2025-10-02 19:48:17.476987: Epoch time: 46.14 s
2025-10-02 19:48:17.477142: Yayy! New best EMA pseudo Dice: 0.6848000288009644
2025-10-02 19:48:18.568060: 
2025-10-02 19:48:18.568365: Epoch 69
2025-10-02 19:48:18.568547: Current learning rate: 0.00574
2025-10-02 19:49:04.736682: Validation loss did not improve from -0.50234. Patience: 7/50
2025-10-02 19:49:04.737221: train_loss -0.6844
2025-10-02 19:49:04.737377: val_loss -0.4658
2025-10-02 19:49:04.737532: Pseudo dice [np.float32(0.6959)]
2025-10-02 19:49:04.737668: Epoch time: 46.17 s
2025-10-02 19:49:05.169202: Yayy! New best EMA pseudo Dice: 0.6858999729156494
2025-10-02 19:49:06.244472: 
2025-10-02 19:49:06.244890: Epoch 70
2025-10-02 19:49:06.245092: Current learning rate: 0.00568
2025-10-02 19:49:52.417248: Validation loss did not improve from -0.50234. Patience: 8/50
2025-10-02 19:49:52.417899: train_loss -0.6734
2025-10-02 19:49:52.418070: val_loss -0.4505
2025-10-02 19:49:52.418200: Pseudo dice [np.float32(0.6959)]
2025-10-02 19:49:52.418350: Epoch time: 46.17 s
2025-10-02 19:49:52.418476: Yayy! New best EMA pseudo Dice: 0.6869000196456909
2025-10-02 19:49:53.505631: 
2025-10-02 19:49:53.506059: Epoch 71
2025-10-02 19:49:53.506284: Current learning rate: 0.00562
2025-10-02 19:50:39.649294: Validation loss did not improve from -0.50234. Patience: 9/50
2025-10-02 19:50:39.649831: train_loss -0.6813
2025-10-02 19:50:39.649999: val_loss -0.4435
2025-10-02 19:50:39.650158: Pseudo dice [np.float32(0.6793)]
2025-10-02 19:50:39.650304: Epoch time: 46.14 s
2025-10-02 19:50:40.304140: 
2025-10-02 19:50:40.304584: Epoch 72
2025-10-02 19:50:40.304952: Current learning rate: 0.00555
2025-10-02 19:51:26.476315: Validation loss did not improve from -0.50234. Patience: 10/50
2025-10-02 19:51:26.477088: train_loss -0.695
2025-10-02 19:51:26.477243: val_loss -0.4813
2025-10-02 19:51:26.477431: Pseudo dice [np.float32(0.7006)]
2025-10-02 19:51:26.477576: Epoch time: 46.17 s
2025-10-02 19:51:26.477870: Yayy! New best EMA pseudo Dice: 0.6876000165939331
2025-10-02 19:51:28.067631: 
2025-10-02 19:51:28.067922: Epoch 73
2025-10-02 19:51:28.068223: Current learning rate: 0.00549
2025-10-02 19:52:14.274945: Validation loss did not improve from -0.50234. Patience: 11/50
2025-10-02 19:52:14.275448: train_loss -0.6967
2025-10-02 19:52:14.275626: val_loss -0.481
2025-10-02 19:52:14.275761: Pseudo dice [np.float32(0.704)]
2025-10-02 19:52:14.275989: Epoch time: 46.21 s
2025-10-02 19:52:14.276114: Yayy! New best EMA pseudo Dice: 0.6891999840736389
2025-10-02 19:52:15.378773: 
2025-10-02 19:52:15.379129: Epoch 74
2025-10-02 19:52:15.379426: Current learning rate: 0.00542
2025-10-02 19:53:01.547307: Validation loss did not improve from -0.50234. Patience: 12/50
2025-10-02 19:53:01.548036: train_loss -0.6999
2025-10-02 19:53:01.548222: val_loss -0.4882
2025-10-02 19:53:01.548435: Pseudo dice [np.float32(0.7078)]
2025-10-02 19:53:01.548607: Epoch time: 46.17 s
2025-10-02 19:53:01.993128: Yayy! New best EMA pseudo Dice: 0.691100001335144
2025-10-02 19:53:03.065747: 
2025-10-02 19:53:03.066028: Epoch 75
2025-10-02 19:53:03.066216: Current learning rate: 0.00536
2025-10-02 19:53:49.265511: Validation loss did not improve from -0.50234. Patience: 13/50
2025-10-02 19:53:49.265982: train_loss -0.7037
2025-10-02 19:53:49.266170: val_loss -0.4827
2025-10-02 19:53:49.266342: Pseudo dice [np.float32(0.6995)]
2025-10-02 19:53:49.266514: Epoch time: 46.2 s
2025-10-02 19:53:49.266669: Yayy! New best EMA pseudo Dice: 0.6919000148773193
2025-10-02 19:53:50.379171: 
2025-10-02 19:53:50.379651: Epoch 76
2025-10-02 19:53:50.380091: Current learning rate: 0.00529
2025-10-02 19:54:36.593503: Validation loss improved from -0.50234 to -0.50534! Patience: 13/50
2025-10-02 19:54:36.594339: train_loss -0.7
2025-10-02 19:54:36.594730: val_loss -0.5053
2025-10-02 19:54:36.594900: Pseudo dice [np.float32(0.7151)]
2025-10-02 19:54:36.595067: Epoch time: 46.22 s
2025-10-02 19:54:36.595433: Yayy! New best EMA pseudo Dice: 0.6941999793052673
2025-10-02 19:54:37.678169: 
2025-10-02 19:54:37.678480: Epoch 77
2025-10-02 19:54:37.678677: Current learning rate: 0.00523
2025-10-02 19:55:23.887379: Validation loss did not improve from -0.50534. Patience: 1/50
2025-10-02 19:55:23.887826: train_loss -0.7045
2025-10-02 19:55:23.887981: val_loss -0.4542
2025-10-02 19:55:23.888181: Pseudo dice [np.float32(0.6939)]
2025-10-02 19:55:23.888331: Epoch time: 46.21 s
2025-10-02 19:55:24.535609: 
2025-10-02 19:55:24.535901: Epoch 78
2025-10-02 19:55:24.536148: Current learning rate: 0.00517
2025-10-02 19:56:10.741813: Validation loss did not improve from -0.50534. Patience: 2/50
2025-10-02 19:56:10.742708: train_loss -0.7072
2025-10-02 19:56:10.742969: val_loss -0.4299
2025-10-02 19:56:10.743223: Pseudo dice [np.float32(0.6673)]
2025-10-02 19:56:10.743386: Epoch time: 46.21 s
2025-10-02 19:56:11.391003: 
2025-10-02 19:56:11.391288: Epoch 79
2025-10-02 19:56:11.391651: Current learning rate: 0.0051
2025-10-02 19:56:57.547400: Validation loss did not improve from -0.50534. Patience: 3/50
2025-10-02 19:56:57.547832: train_loss -0.7038
2025-10-02 19:56:57.548009: val_loss -0.4767
2025-10-02 19:56:57.548167: Pseudo dice [np.float32(0.7033)]
2025-10-02 19:56:57.548310: Epoch time: 46.16 s
2025-10-02 19:56:58.640172: 
2025-10-02 19:56:58.640773: Epoch 80
2025-10-02 19:56:58.641168: Current learning rate: 0.00504
2025-10-02 19:57:44.722153: Validation loss did not improve from -0.50534. Patience: 4/50
2025-10-02 19:57:44.723414: train_loss -0.7156
2025-10-02 19:57:44.723874: val_loss -0.4758
2025-10-02 19:57:44.724162: Pseudo dice [np.float32(0.7006)]
2025-10-02 19:57:44.724453: Epoch time: 46.08 s
2025-10-02 19:57:45.371611: 
2025-10-02 19:57:45.371993: Epoch 81
2025-10-02 19:57:45.372303: Current learning rate: 0.00497
2025-10-02 19:58:31.473679: Validation loss did not improve from -0.50534. Patience: 5/50
2025-10-02 19:58:31.474147: train_loss -0.7074
2025-10-02 19:58:31.474344: val_loss -0.4684
2025-10-02 19:58:31.474504: Pseudo dice [np.float32(0.6944)]
2025-10-02 19:58:31.474701: Epoch time: 46.1 s
2025-10-02 19:58:32.125644: 
2025-10-02 19:58:32.125988: Epoch 82
2025-10-02 19:58:32.126187: Current learning rate: 0.00491
2025-10-02 19:59:18.242624: Validation loss did not improve from -0.50534. Patience: 6/50
2025-10-02 19:59:18.243742: train_loss -0.714
2025-10-02 19:59:18.244090: val_loss -0.4771
2025-10-02 19:59:18.244406: Pseudo dice [np.float32(0.7052)]
2025-10-02 19:59:18.244740: Epoch time: 46.12 s
2025-10-02 19:59:18.245053: Yayy! New best EMA pseudo Dice: 0.6947000026702881
2025-10-02 19:59:19.346489: 
2025-10-02 19:59:19.346840: Epoch 83
2025-10-02 19:59:19.347116: Current learning rate: 0.00484
2025-10-02 20:00:05.486338: Validation loss did not improve from -0.50534. Patience: 7/50
2025-10-02 20:00:05.486983: train_loss -0.7231
2025-10-02 20:00:05.487398: val_loss -0.4905
2025-10-02 20:00:05.487765: Pseudo dice [np.float32(0.7098)]
2025-10-02 20:00:05.488157: Epoch time: 46.14 s
2025-10-02 20:00:05.488593: Yayy! New best EMA pseudo Dice: 0.6962000131607056
2025-10-02 20:00:06.568524: 
2025-10-02 20:00:06.568899: Epoch 84
2025-10-02 20:00:06.569206: Current learning rate: 0.00478
2025-10-02 20:00:52.731712: Validation loss did not improve from -0.50534. Patience: 8/50
2025-10-02 20:00:52.732517: train_loss -0.7244
2025-10-02 20:00:52.732723: val_loss -0.4486
2025-10-02 20:00:52.732902: Pseudo dice [np.float32(0.6806)]
2025-10-02 20:00:52.733093: Epoch time: 46.16 s
2025-10-02 20:00:53.797757: 
2025-10-02 20:00:53.798057: Epoch 85
2025-10-02 20:00:53.798281: Current learning rate: 0.00471
2025-10-02 20:01:39.946159: Validation loss did not improve from -0.50534. Patience: 9/50
2025-10-02 20:01:39.946665: train_loss -0.7315
2025-10-02 20:01:39.946818: val_loss -0.4732
2025-10-02 20:01:39.947013: Pseudo dice [np.float32(0.7028)]
2025-10-02 20:01:39.947312: Epoch time: 46.15 s
2025-10-02 20:01:40.578541: 
2025-10-02 20:01:40.578825: Epoch 86
2025-10-02 20:01:40.579015: Current learning rate: 0.00465
2025-10-02 20:02:26.708216: Validation loss did not improve from -0.50534. Patience: 10/50
2025-10-02 20:02:26.709350: train_loss -0.7204
2025-10-02 20:02:26.709636: val_loss -0.4718
2025-10-02 20:02:26.709939: Pseudo dice [np.float32(0.6938)]
2025-10-02 20:02:26.710246: Epoch time: 46.13 s
2025-10-02 20:02:27.330491: 
2025-10-02 20:02:27.330828: Epoch 87
2025-10-02 20:02:27.331046: Current learning rate: 0.00458
2025-10-02 20:03:13.502714: Validation loss did not improve from -0.50534. Patience: 11/50
2025-10-02 20:03:13.503151: train_loss -0.7276
2025-10-02 20:03:13.503376: val_loss -0.4737
2025-10-02 20:03:13.503530: Pseudo dice [np.float32(0.697)]
2025-10-02 20:03:13.503725: Epoch time: 46.17 s
2025-10-02 20:03:14.534230: 
2025-10-02 20:03:14.534586: Epoch 88
2025-10-02 20:03:14.534798: Current learning rate: 0.00452
2025-10-02 20:04:00.705653: Validation loss did not improve from -0.50534. Patience: 12/50
2025-10-02 20:04:00.706272: train_loss -0.7305
2025-10-02 20:04:00.706440: val_loss -0.4535
2025-10-02 20:04:00.706587: Pseudo dice [np.float32(0.6926)]
2025-10-02 20:04:00.706744: Epoch time: 46.17 s
2025-10-02 20:04:01.323267: 
2025-10-02 20:04:01.323625: Epoch 89
2025-10-02 20:04:01.323850: Current learning rate: 0.00445
2025-10-02 20:04:47.483347: Validation loss did not improve from -0.50534. Patience: 13/50
2025-10-02 20:04:47.483818: train_loss -0.7269
2025-10-02 20:04:47.483998: val_loss -0.4523
2025-10-02 20:04:47.484141: Pseudo dice [np.float32(0.6989)]
2025-10-02 20:04:47.484322: Epoch time: 46.16 s
2025-10-02 20:04:48.548834: 
2025-10-02 20:04:48.549194: Epoch 90
2025-10-02 20:04:48.549400: Current learning rate: 0.00438
2025-10-02 20:05:34.734138: Validation loss did not improve from -0.50534. Patience: 14/50
2025-10-02 20:05:34.735083: train_loss -0.736
2025-10-02 20:05:34.735321: val_loss -0.4787
2025-10-02 20:05:34.735521: Pseudo dice [np.float32(0.696)]
2025-10-02 20:05:34.735735: Epoch time: 46.19 s
2025-10-02 20:05:35.363551: 
2025-10-02 20:05:35.363995: Epoch 91
2025-10-02 20:05:35.364267: Current learning rate: 0.00432
2025-10-02 20:06:21.539208: Validation loss did not improve from -0.50534. Patience: 15/50
2025-10-02 20:06:21.539625: train_loss -0.7286
2025-10-02 20:06:21.539822: val_loss -0.4615
2025-10-02 20:06:21.539988: Pseudo dice [np.float32(0.6967)]
2025-10-02 20:06:21.540195: Epoch time: 46.18 s
2025-10-02 20:06:22.161123: 
2025-10-02 20:06:22.161465: Epoch 92
2025-10-02 20:06:22.161718: Current learning rate: 0.00425
2025-10-02 20:07:08.305256: Validation loss did not improve from -0.50534. Patience: 16/50
2025-10-02 20:07:08.305836: train_loss -0.7313
2025-10-02 20:07:08.306022: val_loss -0.4374
2025-10-02 20:07:08.306200: Pseudo dice [np.float32(0.672)]
2025-10-02 20:07:08.306433: Epoch time: 46.15 s
2025-10-02 20:07:08.938503: 
2025-10-02 20:07:08.938901: Epoch 93
2025-10-02 20:07:08.939194: Current learning rate: 0.00419
2025-10-02 20:07:55.068732: Validation loss did not improve from -0.50534. Patience: 17/50
2025-10-02 20:07:55.069161: train_loss -0.7379
2025-10-02 20:07:55.069358: val_loss -0.4826
2025-10-02 20:07:55.069493: Pseudo dice [np.float32(0.7134)]
2025-10-02 20:07:55.069642: Epoch time: 46.13 s
2025-10-02 20:07:55.703760: 
2025-10-02 20:07:55.704036: Epoch 94
2025-10-02 20:07:55.704227: Current learning rate: 0.00412
2025-10-02 20:08:41.838457: Validation loss did not improve from -0.50534. Patience: 18/50
2025-10-02 20:08:41.839155: train_loss -0.7418
2025-10-02 20:08:41.839311: val_loss -0.4743
2025-10-02 20:08:41.839445: Pseudo dice [np.float32(0.7139)]
2025-10-02 20:08:41.839589: Epoch time: 46.14 s
2025-10-02 20:08:42.303624: Yayy! New best EMA pseudo Dice: 0.6972000002861023
2025-10-02 20:08:43.359138: 
2025-10-02 20:08:43.359396: Epoch 95
2025-10-02 20:08:43.359575: Current learning rate: 0.00405
2025-10-02 20:09:29.515337: Validation loss did not improve from -0.50534. Patience: 19/50
2025-10-02 20:09:29.515794: train_loss -0.7352
2025-10-02 20:09:29.515959: val_loss -0.4596
2025-10-02 20:09:29.516090: Pseudo dice [np.float32(0.7031)]
2025-10-02 20:09:29.516250: Epoch time: 46.16 s
2025-10-02 20:09:29.516392: Yayy! New best EMA pseudo Dice: 0.6977999806404114
2025-10-02 20:09:30.578507: 
2025-10-02 20:09:30.578825: Epoch 96
2025-10-02 20:09:30.579010: Current learning rate: 0.00399
2025-10-02 20:10:16.714060: Validation loss did not improve from -0.50534. Patience: 20/50
2025-10-02 20:10:16.714707: train_loss -0.7389
2025-10-02 20:10:16.714857: val_loss -0.4776
2025-10-02 20:10:16.714996: Pseudo dice [np.float32(0.7127)]
2025-10-02 20:10:16.715189: Epoch time: 46.14 s
2025-10-02 20:10:16.715320: Yayy! New best EMA pseudo Dice: 0.6992999911308289
2025-10-02 20:10:17.803989: 
2025-10-02 20:10:17.804276: Epoch 97
2025-10-02 20:10:17.804462: Current learning rate: 0.00392
2025-10-02 20:11:03.904956: Validation loss did not improve from -0.50534. Patience: 21/50
2025-10-02 20:11:03.905584: train_loss -0.7426
2025-10-02 20:11:03.906009: val_loss -0.4725
2025-10-02 20:11:03.906350: Pseudo dice [np.float32(0.7108)]
2025-10-02 20:11:03.906697: Epoch time: 46.1 s
2025-10-02 20:11:03.907075: Yayy! New best EMA pseudo Dice: 0.7003999948501587
2025-10-02 20:11:04.978682: 
2025-10-02 20:11:04.978967: Epoch 98
2025-10-02 20:11:04.979180: Current learning rate: 0.00385
2025-10-02 20:11:51.072534: Validation loss did not improve from -0.50534. Patience: 22/50
2025-10-02 20:11:51.073046: train_loss -0.7496
2025-10-02 20:11:51.073197: val_loss -0.4999
2025-10-02 20:11:51.073333: Pseudo dice [np.float32(0.7193)]
2025-10-02 20:11:51.073498: Epoch time: 46.1 s
2025-10-02 20:11:51.073675: Yayy! New best EMA pseudo Dice: 0.7023000121116638
2025-10-02 20:11:52.150349: 
2025-10-02 20:11:52.159120: Epoch 99
2025-10-02 20:11:52.166092: Current learning rate: 0.00379
2025-10-02 20:12:38.268860: Validation loss did not improve from -0.50534. Patience: 23/50
2025-10-02 20:12:38.269335: train_loss -0.7479
2025-10-02 20:12:38.269522: val_loss -0.4672
2025-10-02 20:12:38.269692: Pseudo dice [np.float32(0.6998)]
2025-10-02 20:12:38.269950: Epoch time: 46.12 s
2025-10-02 20:12:39.345430: 
2025-10-02 20:12:39.345760: Epoch 100
2025-10-02 20:12:39.345994: Current learning rate: 0.00372
2025-10-02 20:13:25.481192: Validation loss did not improve from -0.50534. Patience: 24/50
2025-10-02 20:13:25.481683: train_loss -0.7501
2025-10-02 20:13:25.481837: val_loss -0.4989
2025-10-02 20:13:25.482009: Pseudo dice [np.float32(0.7089)]
2025-10-02 20:13:25.482200: Epoch time: 46.14 s
2025-10-02 20:13:25.482372: Yayy! New best EMA pseudo Dice: 0.7027000188827515
2025-10-02 20:13:26.550621: 
2025-10-02 20:13:26.550963: Epoch 101
2025-10-02 20:13:26.551198: Current learning rate: 0.00365
2025-10-02 20:14:12.652149: Validation loss did not improve from -0.50534. Patience: 25/50
2025-10-02 20:14:12.652515: train_loss -0.7544
2025-10-02 20:14:12.652746: val_loss -0.4727
2025-10-02 20:14:12.653009: Pseudo dice [np.float32(0.6981)]
2025-10-02 20:14:12.653303: Epoch time: 46.1 s
2025-10-02 20:14:13.285946: 
2025-10-02 20:14:13.286270: Epoch 102
2025-10-02 20:14:13.286492: Current learning rate: 0.00359
2025-10-02 20:14:59.415814: Validation loss did not improve from -0.50534. Patience: 26/50
2025-10-02 20:14:59.416340: train_loss -0.758
2025-10-02 20:14:59.416505: val_loss -0.4723
2025-10-02 20:14:59.416647: Pseudo dice [np.float32(0.7058)]
2025-10-02 20:14:59.416820: Epoch time: 46.13 s
2025-10-02 20:15:00.058575: 
2025-10-02 20:15:00.058910: Epoch 103
2025-10-02 20:15:00.059144: Current learning rate: 0.00352
2025-10-02 20:15:46.187215: Validation loss did not improve from -0.50534. Patience: 27/50
2025-10-02 20:15:46.187673: train_loss -0.7608
2025-10-02 20:15:46.187912: val_loss -0.4297
2025-10-02 20:15:46.188076: Pseudo dice [np.float32(0.6898)]
2025-10-02 20:15:46.188243: Epoch time: 46.13 s
2025-10-02 20:15:47.269417: 
2025-10-02 20:15:47.269697: Epoch 104
2025-10-02 20:15:47.269905: Current learning rate: 0.00345
2025-10-02 20:16:33.417550: Validation loss did not improve from -0.50534. Patience: 28/50
2025-10-02 20:16:33.418384: train_loss -0.7582
2025-10-02 20:16:33.418777: val_loss -0.4756
2025-10-02 20:16:33.419207: Pseudo dice [np.float32(0.7015)]
2025-10-02 20:16:33.419617: Epoch time: 46.15 s
2025-10-02 20:16:34.491484: 
2025-10-02 20:16:34.492012: Epoch 105
2025-10-02 20:16:34.492394: Current learning rate: 0.00338
2025-10-02 20:17:20.657453: Validation loss did not improve from -0.50534. Patience: 29/50
2025-10-02 20:17:20.657850: train_loss -0.7628
2025-10-02 20:17:20.658014: val_loss -0.4888
2025-10-02 20:17:20.658138: Pseudo dice [np.float32(0.725)]
2025-10-02 20:17:20.658277: Epoch time: 46.17 s
2025-10-02 20:17:20.658433: Yayy! New best EMA pseudo Dice: 0.7037000060081482
2025-10-02 20:17:21.735686: 
2025-10-02 20:17:21.736000: Epoch 106
2025-10-02 20:17:21.736217: Current learning rate: 0.00332
2025-10-02 20:18:07.901828: Validation loss did not improve from -0.50534. Patience: 30/50
2025-10-02 20:18:07.902269: train_loss -0.7651
2025-10-02 20:18:07.902439: val_loss -0.4521
2025-10-02 20:18:07.902594: Pseudo dice [np.float32(0.7016)]
2025-10-02 20:18:07.902765: Epoch time: 46.17 s
2025-10-02 20:18:08.546993: 
2025-10-02 20:18:08.547423: Epoch 107
2025-10-02 20:18:08.547763: Current learning rate: 0.00325
2025-10-02 20:18:54.718529: Validation loss did not improve from -0.50534. Patience: 31/50
2025-10-02 20:18:54.718956: train_loss -0.7688
2025-10-02 20:18:54.719124: val_loss -0.4441
2025-10-02 20:18:54.719251: Pseudo dice [np.float32(0.6937)]
2025-10-02 20:18:54.719404: Epoch time: 46.17 s
2025-10-02 20:18:55.359447: 
2025-10-02 20:18:55.359936: Epoch 108
2025-10-02 20:18:55.360229: Current learning rate: 0.00318
2025-10-02 20:19:41.529100: Validation loss did not improve from -0.50534. Patience: 32/50
2025-10-02 20:19:41.529622: train_loss -0.7686
2025-10-02 20:19:41.529831: val_loss -0.4757
2025-10-02 20:19:41.530017: Pseudo dice [np.float32(0.7126)]
2025-10-02 20:19:41.530199: Epoch time: 46.17 s
2025-10-02 20:19:42.165015: 
2025-10-02 20:19:42.165323: Epoch 109
2025-10-02 20:19:42.165550: Current learning rate: 0.00311
2025-10-02 20:20:28.318264: Validation loss did not improve from -0.50534. Patience: 33/50
2025-10-02 20:20:28.318917: train_loss -0.7746
2025-10-02 20:20:28.319226: val_loss -0.473
2025-10-02 20:20:28.319498: Pseudo dice [np.float32(0.7073)]
2025-10-02 20:20:28.319767: Epoch time: 46.15 s
2025-10-02 20:20:28.775835: Yayy! New best EMA pseudo Dice: 0.7038999795913696
2025-10-02 20:20:29.850156: 
2025-10-02 20:20:29.850633: Epoch 110
2025-10-02 20:20:29.851008: Current learning rate: 0.00304
2025-10-02 20:21:15.983834: Validation loss did not improve from -0.50534. Patience: 34/50
2025-10-02 20:21:15.984390: train_loss -0.7726
2025-10-02 20:21:15.984558: val_loss -0.4858
2025-10-02 20:21:15.984713: Pseudo dice [np.float32(0.7114)]
2025-10-02 20:21:15.984875: Epoch time: 46.13 s
2025-10-02 20:21:15.985021: Yayy! New best EMA pseudo Dice: 0.7046999931335449
2025-10-02 20:21:17.060107: 
2025-10-02 20:21:17.060354: Epoch 111
2025-10-02 20:21:17.060548: Current learning rate: 0.00297
2025-10-02 20:22:03.200059: Validation loss did not improve from -0.50534. Patience: 35/50
2025-10-02 20:22:03.200566: train_loss -0.7806
2025-10-02 20:22:03.200788: val_loss -0.4827
2025-10-02 20:22:03.200988: Pseudo dice [np.float32(0.7139)]
2025-10-02 20:22:03.201180: Epoch time: 46.14 s
2025-10-02 20:22:03.201348: Yayy! New best EMA pseudo Dice: 0.7056000232696533
2025-10-02 20:22:04.287572: 
2025-10-02 20:22:04.287958: Epoch 112
2025-10-02 20:22:04.288232: Current learning rate: 0.00291
2025-10-02 20:22:50.425478: Validation loss did not improve from -0.50534. Patience: 36/50
2025-10-02 20:22:50.425943: train_loss -0.7784
2025-10-02 20:22:50.426097: val_loss -0.4311
2025-10-02 20:22:50.426230: Pseudo dice [np.float32(0.6831)]
2025-10-02 20:22:50.426451: Epoch time: 46.14 s
2025-10-02 20:22:51.064747: 
2025-10-02 20:22:51.064998: Epoch 113
2025-10-02 20:22:51.065198: Current learning rate: 0.00284
2025-10-02 20:23:37.192463: Validation loss did not improve from -0.50534. Patience: 37/50
2025-10-02 20:23:37.192949: train_loss -0.7723
2025-10-02 20:23:37.193103: val_loss -0.4313
2025-10-02 20:23:37.193281: Pseudo dice [np.float32(0.6918)]
2025-10-02 20:23:37.193446: Epoch time: 46.13 s
2025-10-02 20:23:37.825981: 
2025-10-02 20:23:37.826338: Epoch 114
2025-10-02 20:23:37.826525: Current learning rate: 0.00277
2025-10-02 20:24:23.969195: Validation loss did not improve from -0.50534. Patience: 38/50
2025-10-02 20:24:23.969669: train_loss -0.7775
2025-10-02 20:24:23.969846: val_loss -0.4187
2025-10-02 20:24:23.969989: Pseudo dice [np.float32(0.6864)]
2025-10-02 20:24:23.970143: Epoch time: 46.14 s
2025-10-02 20:24:25.057384: 
2025-10-02 20:24:25.057715: Epoch 115
2025-10-02 20:24:25.057973: Current learning rate: 0.0027
2025-10-02 20:25:11.192137: Validation loss did not improve from -0.50534. Patience: 39/50
2025-10-02 20:25:11.192555: train_loss -0.7782
2025-10-02 20:25:11.192736: val_loss -0.4402
2025-10-02 20:25:11.192883: Pseudo dice [np.float32(0.7028)]
2025-10-02 20:25:11.193123: Epoch time: 46.14 s
2025-10-02 20:25:11.841909: 
2025-10-02 20:25:11.842127: Epoch 116
2025-10-02 20:25:11.842354: Current learning rate: 0.00263
2025-10-02 20:25:57.984288: Validation loss did not improve from -0.50534. Patience: 40/50
2025-10-02 20:25:57.984813: train_loss -0.7864
2025-10-02 20:25:57.984993: val_loss -0.4768
2025-10-02 20:25:57.985145: Pseudo dice [np.float32(0.7133)]
2025-10-02 20:25:57.985464: Epoch time: 46.14 s
2025-10-02 20:25:58.622854: 
2025-10-02 20:25:58.623137: Epoch 117
2025-10-02 20:25:58.623373: Current learning rate: 0.00256
2025-10-02 20:26:44.775643: Validation loss did not improve from -0.50534. Patience: 41/50
2025-10-02 20:26:44.776198: train_loss -0.7825
2025-10-02 20:26:44.776368: val_loss -0.4693
2025-10-02 20:26:44.776525: Pseudo dice [np.float32(0.7021)]
2025-10-02 20:26:44.776697: Epoch time: 46.15 s
2025-10-02 20:26:45.416893: 
2025-10-02 20:26:45.417242: Epoch 118
2025-10-02 20:26:45.417459: Current learning rate: 0.00249
2025-10-02 20:27:31.553389: Validation loss did not improve from -0.50534. Patience: 42/50
2025-10-02 20:27:31.553879: train_loss -0.7847
2025-10-02 20:27:31.554068: val_loss -0.4771
2025-10-02 20:27:31.554277: Pseudo dice [np.float32(0.7093)]
2025-10-02 20:27:31.554460: Epoch time: 46.14 s
2025-10-02 20:27:32.191287: 
2025-10-02 20:27:32.191614: Epoch 119
2025-10-02 20:27:32.191900: Current learning rate: 0.00242
2025-10-02 20:28:18.377074: Validation loss did not improve from -0.50534. Patience: 43/50
2025-10-02 20:28:18.377495: train_loss -0.7865
2025-10-02 20:28:18.377710: val_loss -0.4571
2025-10-02 20:28:18.377836: Pseudo dice [np.float32(0.6952)]
2025-10-02 20:28:18.378010: Epoch time: 46.19 s
2025-10-02 20:28:19.901307: 
2025-10-02 20:28:19.901685: Epoch 120
2025-10-02 20:28:19.901883: Current learning rate: 0.00235
2025-10-02 20:29:06.108022: Validation loss did not improve from -0.50534. Patience: 44/50
2025-10-02 20:29:06.108517: train_loss -0.7843
2025-10-02 20:29:06.108675: val_loss -0.4706
2025-10-02 20:29:06.108871: Pseudo dice [np.float32(0.7127)]
2025-10-02 20:29:06.109031: Epoch time: 46.21 s
2025-10-02 20:29:06.748338: 
2025-10-02 20:29:06.748702: Epoch 121
2025-10-02 20:29:06.748923: Current learning rate: 0.00228
2025-10-02 20:29:52.915689: Validation loss did not improve from -0.50534. Patience: 45/50
2025-10-02 20:29:52.916089: train_loss -0.7944
2025-10-02 20:29:52.916353: val_loss -0.4412
2025-10-02 20:29:52.916547: Pseudo dice [np.float32(0.6928)]
2025-10-02 20:29:52.916733: Epoch time: 46.17 s
2025-10-02 20:29:53.560128: 
2025-10-02 20:29:53.560378: Epoch 122
2025-10-02 20:29:53.560586: Current learning rate: 0.00221
2025-10-02 20:30:39.727517: Validation loss did not improve from -0.50534. Patience: 46/50
2025-10-02 20:30:39.728015: train_loss -0.7887
2025-10-02 20:30:39.728170: val_loss -0.451
2025-10-02 20:30:39.728320: Pseudo dice [np.float32(0.7061)]
2025-10-02 20:30:39.728495: Epoch time: 46.17 s
2025-10-02 20:30:40.379793: 
2025-10-02 20:30:40.380094: Epoch 123
2025-10-02 20:30:40.380295: Current learning rate: 0.00214
2025-10-02 20:31:26.530036: Validation loss did not improve from -0.50534. Patience: 47/50
2025-10-02 20:31:26.530493: train_loss -0.7948
2025-10-02 20:31:26.530667: val_loss -0.4502
2025-10-02 20:31:26.530811: Pseudo dice [np.float32(0.702)]
2025-10-02 20:31:26.530974: Epoch time: 46.15 s
2025-10-02 20:31:27.169392: 
2025-10-02 20:31:27.169733: Epoch 124
2025-10-02 20:31:27.169937: Current learning rate: 0.00207
2025-10-02 20:32:13.300827: Validation loss did not improve from -0.50534. Patience: 48/50
2025-10-02 20:32:13.301288: train_loss -0.794
2025-10-02 20:32:13.301481: val_loss -0.4705
2025-10-02 20:32:13.301677: Pseudo dice [np.float32(0.7137)]
2025-10-02 20:32:13.301930: Epoch time: 46.13 s
2025-10-02 20:32:14.393895: 
2025-10-02 20:32:14.394361: Epoch 125
2025-10-02 20:32:14.394777: Current learning rate: 0.00199
2025-10-02 20:33:00.551008: Validation loss did not improve from -0.50534. Patience: 49/50
2025-10-02 20:33:00.551455: train_loss -0.7983
2025-10-02 20:33:00.551598: val_loss -0.463
2025-10-02 20:33:00.551738: Pseudo dice [np.float32(0.7087)]
2025-10-02 20:33:00.551884: Epoch time: 46.16 s
2025-10-02 20:33:01.198130: 
2025-10-02 20:33:01.198462: Epoch 126
2025-10-02 20:33:01.198654: Current learning rate: 0.00192
2025-10-02 20:33:47.359053: Validation loss did not improve from -0.50534. Patience: 50/50
2025-10-02 20:33:47.359671: train_loss -0.8009
2025-10-02 20:33:47.359926: val_loss -0.4668
2025-10-02 20:33:47.360170: Pseudo dice [np.float32(0.7071)]
2025-10-02 20:33:47.360426: Epoch time: 46.16 s
2025-10-02 20:33:48.005436: 
2025-10-02 20:33:48.005750: Epoch 127
2025-10-02 20:33:48.006044: Current learning rate: 0.00185
2025-10-02 20:34:34.149382: Validation loss did not improve from -0.50534. Patience: 51/50
2025-10-02 20:34:34.149855: train_loss -0.7996
2025-10-02 20:34:34.150178: val_loss -0.4583
2025-10-02 20:34:34.150419: Pseudo dice [np.float32(0.7047)]
2025-10-02 20:34:34.150634: Epoch time: 46.15 s
2025-10-02 20:34:34.794311: 
2025-10-02 20:34:34.794673: Epoch 128
2025-10-02 20:34:34.794887: Current learning rate: 0.00178
2025-10-02 20:35:20.950377: Validation loss did not improve from -0.50534. Patience: 52/50
2025-10-02 20:35:20.950850: train_loss -0.7964
2025-10-02 20:35:20.950995: val_loss -0.451
2025-10-02 20:35:20.951128: Pseudo dice [np.float32(0.7095)]
2025-10-02 20:35:20.951288: Epoch time: 46.16 s
2025-10-02 20:35:21.581625: 
2025-10-02 20:35:21.582183: Epoch 129
2025-10-02 20:35:21.582612: Current learning rate: 0.0017
2025-10-02 20:36:07.725508: Validation loss did not improve from -0.50534. Patience: 53/50
2025-10-02 20:36:07.726003: train_loss -0.8026
2025-10-02 20:36:07.726169: val_loss -0.4471
2025-10-02 20:36:07.726321: Pseudo dice [np.float32(0.7002)]
2025-10-02 20:36:07.726469: Epoch time: 46.15 s
2025-10-02 20:36:08.804458: 
2025-10-02 20:36:08.804820: Epoch 130
2025-10-02 20:36:08.805087: Current learning rate: 0.00163
2025-10-02 20:36:54.896491: Validation loss did not improve from -0.50534. Patience: 54/50
2025-10-02 20:36:54.896928: train_loss -0.8037
2025-10-02 20:36:54.897121: val_loss -0.4525
2025-10-02 20:36:54.897282: Pseudo dice [np.float32(0.6916)]
2025-10-02 20:36:54.897442: Epoch time: 46.09 s
2025-10-02 20:36:55.535307: 
2025-10-02 20:36:55.535698: Epoch 131
2025-10-02 20:36:55.535898: Current learning rate: 0.00156
2025-10-02 20:37:41.693397: Validation loss did not improve from -0.50534. Patience: 55/50
2025-10-02 20:37:41.694010: train_loss -0.8061
2025-10-02 20:37:41.694377: val_loss -0.4834
2025-10-02 20:37:41.694746: Pseudo dice [np.float32(0.7142)]
2025-10-02 20:37:41.695111: Epoch time: 46.16 s
2025-10-02 20:37:42.322521: 
2025-10-02 20:37:42.322860: Epoch 132
2025-10-02 20:37:42.323061: Current learning rate: 0.00148
2025-10-02 20:38:28.462799: Validation loss did not improve from -0.50534. Patience: 56/50
2025-10-02 20:38:28.463290: train_loss -0.8033
2025-10-02 20:38:28.463462: val_loss -0.4583
2025-10-02 20:38:28.463605: Pseudo dice [np.float32(0.7089)]
2025-10-02 20:38:28.463761: Epoch time: 46.14 s
2025-10-02 20:38:29.097608: 
2025-10-02 20:38:29.098158: Epoch 133
2025-10-02 20:38:29.098370: Current learning rate: 0.00141
2025-10-02 20:39:15.247002: Validation loss did not improve from -0.50534. Patience: 57/50
2025-10-02 20:39:15.247392: train_loss -0.8098
2025-10-02 20:39:15.247551: val_loss -0.4739
2025-10-02 20:39:15.247746: Pseudo dice [np.float32(0.7126)]
2025-10-02 20:39:15.247954: Epoch time: 46.15 s
2025-10-02 20:39:15.875040: 
2025-10-02 20:39:15.875306: Epoch 134
2025-10-02 20:39:15.875480: Current learning rate: 0.00133
2025-10-02 20:40:02.033146: Validation loss did not improve from -0.50534. Patience: 58/50
2025-10-02 20:40:02.033674: train_loss -0.8097
2025-10-02 20:40:02.033822: val_loss -0.4657
2025-10-02 20:40:02.033973: Pseudo dice [np.float32(0.7158)]
2025-10-02 20:40:02.034229: Epoch time: 46.16 s
2025-10-02 20:40:02.485197: Yayy! New best EMA pseudo Dice: 0.7064999938011169
2025-10-02 20:40:03.556852: 
2025-10-02 20:40:03.557147: Epoch 135
2025-10-02 20:40:03.557337: Current learning rate: 0.00126
2025-10-02 20:40:49.754255: Validation loss did not improve from -0.50534. Patience: 59/50
2025-10-02 20:40:49.754913: train_loss -0.813
2025-10-02 20:40:49.755308: val_loss -0.4697
2025-10-02 20:40:49.755624: Pseudo dice [np.float32(0.7159)]
2025-10-02 20:40:49.755996: Epoch time: 46.2 s
2025-10-02 20:40:49.756393: Yayy! New best EMA pseudo Dice: 0.7074999809265137
2025-10-02 20:40:51.319511: 
2025-10-02 20:40:51.319867: Epoch 136
2025-10-02 20:40:51.320074: Current learning rate: 0.00118
2025-10-02 20:41:37.525993: Validation loss did not improve from -0.50534. Patience: 60/50
2025-10-02 20:41:37.526487: train_loss -0.8166
2025-10-02 20:41:37.526671: val_loss -0.4631
2025-10-02 20:41:37.526852: Pseudo dice [np.float32(0.7147)]
2025-10-02 20:41:37.527070: Epoch time: 46.21 s
2025-10-02 20:41:37.527267: Yayy! New best EMA pseudo Dice: 0.7081999778747559
2025-10-02 20:41:38.624601: 
2025-10-02 20:41:38.624968: Epoch 137
2025-10-02 20:41:38.625205: Current learning rate: 0.00111
2025-10-02 20:42:24.778150: Validation loss did not improve from -0.50534. Patience: 61/50
2025-10-02 20:42:24.778645: train_loss -0.814
2025-10-02 20:42:24.778855: val_loss -0.497
2025-10-02 20:42:24.779039: Pseudo dice [np.float32(0.723)]
2025-10-02 20:42:24.779252: Epoch time: 46.15 s
2025-10-02 20:42:24.779421: Yayy! New best EMA pseudo Dice: 0.7096999883651733
2025-10-02 20:42:25.869450: 
2025-10-02 20:42:25.869759: Epoch 138
2025-10-02 20:42:25.869968: Current learning rate: 0.00103
2025-10-02 20:43:12.020062: Validation loss did not improve from -0.50534. Patience: 62/50
2025-10-02 20:43:12.020865: train_loss -0.8143
2025-10-02 20:43:12.021301: val_loss -0.4601
2025-10-02 20:43:12.021703: Pseudo dice [np.float32(0.7118)]
2025-10-02 20:43:12.022137: Epoch time: 46.15 s
2025-10-02 20:43:12.022592: Yayy! New best EMA pseudo Dice: 0.7099000215530396
2025-10-02 20:43:13.111167: 
2025-10-02 20:43:13.111528: Epoch 139
2025-10-02 20:43:13.111733: Current learning rate: 0.00095
2025-10-02 20:43:59.254307: Validation loss did not improve from -0.50534. Patience: 63/50
2025-10-02 20:43:59.254772: train_loss -0.8138
2025-10-02 20:43:59.254949: val_loss -0.4555
2025-10-02 20:43:59.255165: Pseudo dice [np.float32(0.6971)]
2025-10-02 20:43:59.255352: Epoch time: 46.14 s
2025-10-02 20:44:00.341508: 
2025-10-02 20:44:00.342168: Epoch 140
2025-10-02 20:44:00.342445: Current learning rate: 0.00087
2025-10-02 20:44:46.467749: Validation loss did not improve from -0.50534. Patience: 64/50
2025-10-02 20:44:46.468297: train_loss -0.8178
2025-10-02 20:44:46.468443: val_loss -0.4833
2025-10-02 20:44:46.468563: Pseudo dice [np.float32(0.7243)]
2025-10-02 20:44:46.468714: Epoch time: 46.13 s
2025-10-02 20:44:46.468853: Yayy! New best EMA pseudo Dice: 0.7102000117301941
2025-10-02 20:44:47.566755: 
2025-10-02 20:44:47.567018: Epoch 141
2025-10-02 20:44:47.567202: Current learning rate: 0.00079
2025-10-02 20:45:33.727699: Validation loss did not improve from -0.50534. Patience: 65/50
2025-10-02 20:45:33.728326: train_loss -0.8201
2025-10-02 20:45:33.728646: val_loss -0.4786
2025-10-02 20:45:33.729028: Pseudo dice [np.float32(0.7228)]
2025-10-02 20:45:33.729366: Epoch time: 46.16 s
2025-10-02 20:45:33.729638: Yayy! New best EMA pseudo Dice: 0.7113999724388123
2025-10-02 20:45:34.809731: 
2025-10-02 20:45:34.810042: Epoch 142
2025-10-02 20:45:34.810304: Current learning rate: 0.00071
2025-10-02 20:46:20.960919: Validation loss did not improve from -0.50534. Patience: 66/50
2025-10-02 20:46:20.961475: train_loss -0.8203
2025-10-02 20:46:20.961624: val_loss -0.4485
2025-10-02 20:46:20.961747: Pseudo dice [np.float32(0.6999)]
2025-10-02 20:46:20.961887: Epoch time: 46.15 s
2025-10-02 20:46:21.597667: 
2025-10-02 20:46:21.598021: Epoch 143
2025-10-02 20:46:21.598227: Current learning rate: 0.00063
2025-10-02 20:47:07.722685: Validation loss did not improve from -0.50534. Patience: 67/50
2025-10-02 20:47:07.723072: train_loss -0.8197
2025-10-02 20:47:07.723264: val_loss -0.4611
2025-10-02 20:47:07.723411: Pseudo dice [np.float32(0.7114)]
2025-10-02 20:47:07.723569: Epoch time: 46.13 s
2025-10-02 20:47:08.361866: 
2025-10-02 20:47:08.362217: Epoch 144
2025-10-02 20:47:08.362433: Current learning rate: 0.00055
2025-10-02 20:47:54.547512: Validation loss did not improve from -0.50534. Patience: 68/50
2025-10-02 20:47:54.548012: train_loss -0.8213
2025-10-02 20:47:54.548176: val_loss -0.4632
2025-10-02 20:47:54.548346: Pseudo dice [np.float32(0.7224)]
2025-10-02 20:47:54.548488: Epoch time: 46.19 s
2025-10-02 20:47:54.985149: Yayy! New best EMA pseudo Dice: 0.7116000056266785
2025-10-02 20:47:56.040958: 
2025-10-02 20:47:56.041381: Epoch 145
2025-10-02 20:47:56.041642: Current learning rate: 0.00047
2025-10-02 20:48:42.230855: Validation loss did not improve from -0.50534. Patience: 69/50
2025-10-02 20:48:42.231940: train_loss -0.8254
2025-10-02 20:48:42.232347: val_loss -0.4443
2025-10-02 20:48:42.232733: Pseudo dice [np.float32(0.7112)]
2025-10-02 20:48:42.233125: Epoch time: 46.19 s
2025-10-02 20:48:42.881390: 
2025-10-02 20:48:42.881742: Epoch 146
2025-10-02 20:48:42.881955: Current learning rate: 0.00038
2025-10-02 20:49:29.115782: Validation loss did not improve from -0.50534. Patience: 70/50
2025-10-02 20:49:29.116359: train_loss -0.8207
2025-10-02 20:49:29.116596: val_loss -0.451
2025-10-02 20:49:29.116868: Pseudo dice [np.float32(0.7076)]
2025-10-02 20:49:29.117050: Epoch time: 46.24 s
2025-10-02 20:49:29.762714: 
2025-10-02 20:49:29.763109: Epoch 147
2025-10-02 20:49:29.763432: Current learning rate: 0.0003
2025-10-02 20:50:15.896773: Validation loss did not improve from -0.50534. Patience: 71/50
2025-10-02 20:50:15.897496: train_loss -0.8239
2025-10-02 20:50:15.897876: val_loss -0.4321
2025-10-02 20:50:15.898195: Pseudo dice [np.float32(0.6924)]
2025-10-02 20:50:15.898371: Epoch time: 46.14 s
2025-10-02 20:50:16.544105: 
2025-10-02 20:50:16.544382: Epoch 148
2025-10-02 20:50:16.544622: Current learning rate: 0.00021
2025-10-02 20:51:02.698253: Validation loss did not improve from -0.50534. Patience: 72/50
2025-10-02 20:51:02.698812: train_loss -0.8249
2025-10-02 20:51:02.699006: val_loss -0.4613
2025-10-02 20:51:02.699154: Pseudo dice [np.float32(0.7143)]
2025-10-02 20:51:02.699307: Epoch time: 46.16 s
2025-10-02 20:51:03.346294: 
2025-10-02 20:51:03.346855: Epoch 149
2025-10-02 20:51:03.347274: Current learning rate: 0.00011
2025-10-02 20:51:49.490872: Validation loss did not improve from -0.50534. Patience: 73/50
2025-10-02 20:51:49.491583: train_loss -0.8226
2025-10-02 20:51:49.491957: val_loss -0.4434
2025-10-02 20:51:49.492332: Pseudo dice [np.float32(0.695)]
2025-10-02 20:51:49.492687: Epoch time: 46.15 s
2025-10-02 20:51:50.638146: Training done.
2025-10-02 20:51:50.648226: Using splits from existing split file: /nfs/erelab001/shared/Computational_Group/Naravich/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset310_nnInteractive_Calcium_OCT_CrossValidation/splits_final.json
2025-10-02 20:51:50.648642: The split file contains 5 splits.
2025-10-02 20:51:50.649183: Desired fold for training: 2
2025-10-02 20:51:50.649471: This split has 6 training and 2 validation cases.
2025-10-02 20:51:50.649795: predicting 101-044
2025-10-02 20:51:50.652164: 101-044, shape torch.Size([1, 404, 498, 498]), rank 0
2025-10-02 20:52:30.805550: predicting 704-003
2025-10-02 20:52:30.815420: 704-003, shape torch.Size([1, 375, 498, 498]), rank 0
2025-10-02 20:53:17.870804: Validation complete
2025-10-02 20:53:17.871057: Mean Validation Dice:  0.6862509132235578
Finished training fold 2 saving to /nfs/erelab001/shared/Computational_Group/Naravich/datasets/nnUNet_Datasets/nnUNet_results/Dataset310_nnInteractive_Calcium_OCT_CrossValidation/nnUNetTrainer__nnUNetPlans__3d_32x160x128_b10/fold_2_No_Pretrained
