/home/gridsan/nchutisilp/.conda/envs/nnunet/bin/python
Starting training with CONFIG=3d_32x160x128_b10, DATASET_ID=307, TRAINER=nnUNetTrainerScaleAnalysis20

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2024-12-13 18:17:27.373853: Using torch.compile...

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2024-12-13 18:17:27.373717: Using torch.compile...
/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
################### Loading pretrained weights from file  /home/gridsan/nchutisilp/projects/OpenAI-CLIP/clip_preivl_poststent_pretrained_nnUNet.pt ###################
Below is the list of overlapping blocks in pretrained model and nnUNet architecture:
encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])
encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])
encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])
encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])
encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])
encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])
encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])
encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])
encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])
encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])
encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])
encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])
encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])
encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])
encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])
encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])
encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])
encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])
encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])
encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])
encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])
encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])
encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])
encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])
encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])
encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])
encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])
decoder.encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])
decoder.encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])
decoder.encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])
decoder.encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])
decoder.encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])
decoder.encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])
decoder.encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])
decoder.encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])
decoder.encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])
decoder.encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])
decoder.encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])
decoder.encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])
decoder.encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])
decoder.encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.stages.0.convs.0.conv.weight shape torch.Size([320, 640, 3, 3, 3])
decoder.stages.0.convs.0.conv.bias shape torch.Size([320])
decoder.stages.0.convs.0.norm.weight shape torch.Size([320])
decoder.stages.0.convs.0.norm.bias shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.0.weight shape torch.Size([320, 640, 3, 3, 3])
decoder.stages.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.stages.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.stages.0.convs.1.conv.bias shape torch.Size([320])
decoder.stages.0.convs.1.norm.weight shape torch.Size([320])
decoder.stages.0.convs.1.norm.bias shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.stages.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.stages.1.convs.0.conv.weight shape torch.Size([256, 512, 3, 3, 3])
decoder.stages.1.convs.0.conv.bias shape torch.Size([256])
decoder.stages.1.convs.0.norm.weight shape torch.Size([256])
decoder.stages.1.convs.0.norm.bias shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.0.weight shape torch.Size([256, 512, 3, 3, 3])
decoder.stages.1.convs.0.all_modules.0.bias shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.1.weight shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.1.bias shape torch.Size([256])
decoder.stages.1.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.stages.1.convs.1.conv.bias shape torch.Size([256])
decoder.stages.1.convs.1.norm.weight shape torch.Size([256])
decoder.stages.1.convs.1.norm.bias shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.stages.1.convs.1.all_modules.0.bias shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.1.weight shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.1.bias shape torch.Size([256])
decoder.stages.2.convs.0.conv.weight shape torch.Size([128, 256, 3, 3, 3])
decoder.stages.2.convs.0.conv.bias shape torch.Size([128])
decoder.stages.2.convs.0.norm.weight shape torch.Size([128])
decoder.stages.2.convs.0.norm.bias shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.0.weight shape torch.Size([128, 256, 3, 3, 3])
decoder.stages.2.convs.0.all_modules.0.bias shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.1.weight shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.1.bias shape torch.Size([128])
decoder.stages.2.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.stages.2.convs.1.conv.bias shape torch.Size([128])
decoder.stages.2.convs.1.norm.weight shape torch.Size([128])
decoder.stages.2.convs.1.norm.bias shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.stages.2.convs.1.all_modules.0.bias shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.1.weight shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.1.bias shape torch.Size([128])
decoder.stages.3.convs.0.conv.weight shape torch.Size([64, 128, 3, 3, 3])
decoder.stages.3.convs.0.conv.bias shape torch.Size([64])
decoder.stages.3.convs.0.norm.weight shape torch.Size([64])
decoder.stages.3.convs.0.norm.bias shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.0.weight shape torch.Size([64, 128, 3, 3, 3])
decoder.stages.3.convs.0.all_modules.0.bias shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.1.weight shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.1.bias shape torch.Size([64])
decoder.stages.3.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.stages.3.convs.1.conv.bias shape torch.Size([64])
decoder.stages.3.convs.1.norm.weight shape torch.Size([64])
decoder.stages.3.convs.1.norm.bias shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.stages.3.convs.1.all_modules.0.bias shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.1.weight shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.1.bias shape torch.Size([64])
decoder.stages.4.convs.0.conv.weight shape torch.Size([32, 64, 3, 3, 3])
decoder.stages.4.convs.0.conv.bias shape torch.Size([32])
decoder.stages.4.convs.0.norm.weight shape torch.Size([32])
decoder.stages.4.convs.0.norm.bias shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.0.weight shape torch.Size([32, 64, 3, 3, 3])
decoder.stages.4.convs.0.all_modules.0.bias shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.1.weight shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.1.bias shape torch.Size([32])
decoder.stages.4.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.stages.4.convs.1.conv.bias shape torch.Size([32])
decoder.stages.4.convs.1.norm.weight shape torch.Size([32])
decoder.stages.4.convs.1.norm.bias shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.stages.4.convs.1.all_modules.0.bias shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.1.weight shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.1.bias shape torch.Size([32])
decoder.transpconvs.0.weight shape torch.Size([320, 320, 1, 2, 2])
decoder.transpconvs.0.bias shape torch.Size([320])
decoder.transpconvs.1.weight shape torch.Size([320, 256, 2, 2, 2])
decoder.transpconvs.1.bias shape torch.Size([256])
decoder.transpconvs.2.weight shape torch.Size([256, 128, 2, 2, 2])
decoder.transpconvs.2.bias shape torch.Size([128])
decoder.transpconvs.3.weight shape torch.Size([128, 64, 2, 2, 2])
decoder.transpconvs.3.bias shape torch.Size([64])
decoder.transpconvs.4.weight shape torch.Size([64, 32, 2, 2, 2])
decoder.transpconvs.4.bias shape torch.Size([32])
################### Done ###################
2024-12-13 18:17:41.226341: do_dummy_2d_data_aug: True
2024-12-13 18:17:41.227428: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset307_Sohee_Calcium_OCT_CrossValidation/splits_final_20.json
2024-12-13 18:17:41.229661: The split file contains 5 splits.
2024-12-13 18:17:41.231219: Desired fold for training: 0
2024-12-13 18:17:41.232643: This split has 1 training and 7 validation cases.
################### Loading pretrained weights from file  /home/gridsan/nchutisilp/projects/OpenAI-CLIP/clip_preivl_poststent_pretrained_nnUNet.pt ###################
Below is the list of overlapping blocks in pretrained model and nnUNet architecture:
encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])
encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])
encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])
encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])
encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])
encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])
encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])
encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])
encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])
encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])
encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])
encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])
encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])
encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])
encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])
encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])
encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])
encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])
encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])
encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])
encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])
encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])
encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])
encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])
encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])
encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])
encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])
decoder.encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])
decoder.encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])
decoder.encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])
decoder.encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])
decoder.encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])
decoder.encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])
decoder.encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])
decoder.encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])
decoder.encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])
decoder.encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])
decoder.encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])
decoder.encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])
decoder.encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])
decoder.encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.stages.0.convs.0.conv.weight shape torch.Size([320, 640, 3, 3, 3])
decoder.stages.0.convs.0.conv.bias shape torch.Size([320])
decoder.stages.0.convs.0.norm.weight shape torch.Size([320])
decoder.stages.0.convs.0.norm.bias shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.0.weight shape torch.Size([320, 640, 3, 3, 3])
decoder.stages.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.stages.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.stages.0.convs.1.conv.bias shape torch.Size([320])
decoder.stages.0.convs.1.norm.weight shape torch.Size([320])
decoder.stages.0.convs.1.norm.bias shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.stages.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.stages.1.convs.0.conv.weight shape torch.Size([256, 512, 3, 3, 3])
decoder.stages.1.convs.0.conv.bias shape torch.Size([256])
decoder.stages.1.convs.0.norm.weight shape torch.Size([256])
decoder.stages.1.convs.0.norm.bias shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.0.weight shape torch.Size([256, 512, 3, 3, 3])
decoder.stages.1.convs.0.all_modules.0.bias shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.1.weight shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.1.bias shape torch.Size([256])
decoder.stages.1.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.stages.1.convs.1.conv.bias shape torch.Size([256])
decoder.stages.1.convs.1.norm.weight shape torch.Size([256])
decoder.stages.1.convs.1.norm.bias shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.stages.1.convs.1.all_modules.0.bias shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.1.weight shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.1.bias shape torch.Size([256])
decoder.stages.2.convs.0.conv.weight shape torch.Size([128, 256, 3, 3, 3])
decoder.stages.2.convs.0.conv.bias shape torch.Size([128])
decoder.stages.2.convs.0.norm.weight shape torch.Size([128])
decoder.stages.2.convs.0.norm.bias shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.0.weight shape torch.Size([128, 256, 3, 3, 3])
decoder.stages.2.convs.0.all_modules.0.bias shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.1.weight shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.1.bias shape torch.Size([128])
decoder.stages.2.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.stages.2.convs.1.conv.bias shape torch.Size([128])
decoder.stages.2.convs.1.norm.weight shape torch.Size([128])
decoder.stages.2.convs.1.norm.bias shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.stages.2.convs.1.all_modules.0.bias shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.1.weight shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.1.bias shape torch.Size([128])
decoder.stages.3.convs.0.conv.weight shape torch.Size([64, 128, 3, 3, 3])
decoder.stages.3.convs.0.conv.bias shape torch.Size([64])
decoder.stages.3.convs.0.norm.weight shape torch.Size([64])
decoder.stages.3.convs.0.norm.bias shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.0.weight shape torch.Size([64, 128, 3, 3, 3])
decoder.stages.3.convs.0.all_modules.0.bias shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.1.weight shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.1.bias shape torch.Size([64])
decoder.stages.3.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.stages.3.convs.1.conv.bias shape torch.Size([64])
decoder.stages.3.convs.1.norm.weight shape torch.Size([64])
decoder.stages.3.convs.1.norm.bias shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.stages.3.convs.1.all_modules.0.bias shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.1.weight shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.1.bias shape torch.Size([64])
decoder.stages.4.convs.0.conv.weight shape torch.Size([32, 64, 3, 3, 3])
decoder.stages.4.convs.0.conv.bias shape torch.Size([32])
decoder.stages.4.convs.0.norm.weight shape torch.Size([32])
decoder.stages.4.convs.0.norm.bias shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.0.weight shape torch.Size([32, 64, 3, 3, 3])
decoder.stages.4.convs.0.all_modules.0.bias shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.1.weight shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.1.bias shape torch.Size([32])
decoder.stages.4.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.stages.4.convs.1.conv.bias shape torch.Size([32])
decoder.stages.4.convs.1.norm.weight shape torch.Size([32])
decoder.stages.4.convs.1.norm.bias shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.stages.4.convs.1.all_modules.0.bias shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.1.weight shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.1.bias shape torch.Size([32])
decoder.transpconvs.0.weight shape torch.Size([320, 320, 1, 2, 2])
decoder.transpconvs.0.bias shape torch.Size([320])
decoder.transpconvs.1.weight shape torch.Size([320, 256, 2, 2, 2])
decoder.transpconvs.1.bias shape torch.Size([256])
decoder.transpconvs.2.weight shape torch.Size([256, 128, 2, 2, 2])
decoder.transpconvs.2.bias shape torch.Size([128])
decoder.transpconvs.3.weight shape torch.Size([128, 64, 2, 2, 2])
decoder.transpconvs.3.bias shape torch.Size([64])
decoder.transpconvs.4.weight shape torch.Size([64, 32, 2, 2, 2])
decoder.transpconvs.4.bias shape torch.Size([32])
################### Done ###################
2024-12-13 18:17:41.225472: do_dummy_2d_data_aug: True
2024-12-13 18:17:41.227371: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset307_Sohee_Calcium_OCT_CrossValidation/splits_final_20.json
2024-12-13 18:17:41.229413: The split file contains 5 splits.
2024-12-13 18:17:41.230877: Desired fold for training: 1
2024-12-13 18:17:41.232319: This split has 1 training and 7 validation cases.
using pin_memory on device 0
using pin_memory on device 0
using pin_memory on device 0

This is the configuration used by this training:
Configuration name: 3d_32x160x128_b10
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 10, 'patch_size': [32, 160, 128], 'median_image_size_in_voxels': [375.0, 498.0, 498.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'inherits_from': '3d_fullres'} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset307_Sohee_Calcium_OCT_CrossValidation', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.4977976381778717, 'mean': 0.13507525622844696, 'median': 0.09599608182907104, 'min': 0.0, 'percentile_00_5': 0.014754901640117168, 'percentile_99_5': 0.4977976381778717, 'std': 0.12025152146816254}}} 

2024-12-13 18:17:46.616523: unpacking dataset...
using pin_memory on device 0

This is the configuration used by this training:
Configuration name: 3d_32x160x128_b10
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 10, 'patch_size': [32, 160, 128], 'median_image_size_in_voxels': [375.0, 498.0, 498.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'inherits_from': '3d_fullres'} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset307_Sohee_Calcium_OCT_CrossValidation', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.4977976381778717, 'mean': 0.13507525622844696, 'median': 0.09599608182907104, 'min': 0.0, 'percentile_00_5': 0.014754901640117168, 'percentile_99_5': 0.4977976381778717, 'std': 0.12025152146816254}}} 

2024-12-13 18:17:47.733892: unpacking dataset...
2024-12-13 18:17:51.630533: unpacking done...
2024-12-13 18:17:51.685284: Unable to plot network architecture: nnUNet_compile is enabled!
2024-12-13 18:17:52.091199: 
2024-12-13 18:17:52.092325: Epoch 0
2024-12-13 18:17:52.093840: Current learning rate: 0.01
2024-12-13 18:21:38.965788: Validation loss improved from 1000.00000 to -0.13845! Patience: 0/50
2024-12-13 18:21:39.001665: train_loss -0.1644
2024-12-13 18:21:39.005010: val_loss -0.1385
2024-12-13 18:21:39.006043: Pseudo dice [0.5463]
2024-12-13 18:21:39.006839: Epoch time: 226.88 s
2024-12-13 18:21:39.007502: Yayy! New best EMA pseudo Dice: 0.5463
2024-12-13 18:21:42.317192: 
2024-12-13 18:21:42.318626: Epoch 1
2024-12-13 18:21:42.319536: Current learning rate: 0.00994
2024-12-13 18:23:33.484184: Validation loss improved from -0.13845 to -0.17964! Patience: 0/50
2024-12-13 18:23:33.485051: train_loss -0.4322
2024-12-13 18:23:33.486136: val_loss -0.1796
2024-12-13 18:23:33.486882: Pseudo dice [0.5319]
2024-12-13 18:23:33.487607: Epoch time: 111.17 s
2024-12-13 18:23:34.838228: 
2024-12-13 18:23:34.839392: Epoch 2
2024-12-13 18:23:34.840291: Current learning rate: 0.00988
2024-12-13 18:25:38.701587: Validation loss improved from -0.17964 to -0.21087! Patience: 0/50
2024-12-13 18:25:38.702298: train_loss -0.5026
2024-12-13 18:25:38.703162: val_loss -0.2109
2024-12-13 18:25:38.703846: Pseudo dice [0.5721]
2024-12-13 18:25:38.704501: Epoch time: 123.87 s
2024-12-13 18:25:38.705299: Yayy! New best EMA pseudo Dice: 0.5476
2024-12-13 18:25:40.499948: 
2024-12-13 18:25:40.501014: Epoch 3
2024-12-13 18:25:40.501670: Current learning rate: 0.00982
2024-12-13 18:27:48.066347: Validation loss improved from -0.21087 to -0.25102! Patience: 0/50
2024-12-13 18:27:48.067084: train_loss -0.5373
2024-12-13 18:27:48.067833: val_loss -0.251
2024-12-13 18:27:48.068475: Pseudo dice [0.6149]
2024-12-13 18:27:48.069245: Epoch time: 127.57 s
2024-12-13 18:27:48.069894: Yayy! New best EMA pseudo Dice: 0.5543
2024-12-13 18:27:49.824933: 
2024-12-13 18:27:49.825955: Epoch 4
2024-12-13 18:27:49.826730: Current learning rate: 0.00976
2024-12-13 18:30:12.166163: Validation loss improved from -0.25102 to -0.25427! Patience: 0/50
2024-12-13 18:30:12.166897: train_loss -0.5579
2024-12-13 18:30:12.167747: val_loss -0.2543
2024-12-13 18:30:12.168513: Pseudo dice [0.6079]
2024-12-13 18:30:12.169276: Epoch time: 142.34 s
2024-12-13 18:30:12.496248: Yayy! New best EMA pseudo Dice: 0.5597
2024-12-13 18:30:14.239639: 
2024-12-13 18:30:14.240836: Epoch 5
2024-12-13 18:30:14.241637: Current learning rate: 0.0097
2024-12-13 18:32:37.746054: Validation loss did not improve from -0.25427. Patience: 1/50
2024-12-13 18:32:37.746964: train_loss -0.5875
2024-12-13 18:32:37.747771: val_loss -0.2467
2024-12-13 18:32:37.748461: Pseudo dice [0.5923]
2024-12-13 18:32:37.749129: Epoch time: 143.51 s
2024-12-13 18:32:37.749775: Yayy! New best EMA pseudo Dice: 0.5629
2024-12-13 18:32:39.468078: 
2024-12-13 18:32:39.468953: Epoch 6
2024-12-13 18:32:39.469762: Current learning rate: 0.00964
2024-12-13 18:35:16.950725: Validation loss did not improve from -0.25427. Patience: 2/50
2024-12-13 18:35:16.951417: train_loss -0.6061
2024-12-13 18:35:16.952221: val_loss -0.2464
2024-12-13 18:35:16.952986: Pseudo dice [0.6136]
2024-12-13 18:35:16.953680: Epoch time: 157.48 s
2024-12-13 18:35:16.954339: Yayy! New best EMA pseudo Dice: 0.568
2024-12-13 18:35:18.692365: 
2024-12-13 18:35:18.693954: Epoch 7
2024-12-13 18:35:18.694863: Current learning rate: 0.00958
2024-12-13 18:37:52.622887: Validation loss improved from -0.25427 to -0.26051! Patience: 2/50
2024-12-13 18:37:52.623911: train_loss -0.6303
2024-12-13 18:37:52.624839: val_loss -0.2605
2024-12-13 18:37:52.625602: Pseudo dice [0.6097]
2024-12-13 18:37:52.626378: Epoch time: 153.93 s
2024-12-13 18:37:52.627222: Yayy! New best EMA pseudo Dice: 0.5722
2024-12-13 18:37:54.408826: 
2024-12-13 18:37:54.409940: Epoch 8
2024-12-13 18:37:54.410989: Current learning rate: 0.00952
2024-12-13 18:40:36.610527: Validation loss did not improve from -0.26051. Patience: 1/50
2024-12-13 18:40:36.611229: train_loss -0.6531
2024-12-13 18:40:36.612280: val_loss -0.1792
2024-12-13 18:40:36.613041: Pseudo dice [0.57]
2024-12-13 18:40:36.613728: Epoch time: 162.2 s
2024-12-13 18:40:38.376581: 
2024-12-13 18:40:38.377607: Epoch 9
2024-12-13 18:40:38.378422: Current learning rate: 0.00946
2024-12-13 18:43:12.558279: Validation loss did not improve from -0.26051. Patience: 2/50
2024-12-13 18:43:12.559073: train_loss -0.6564
2024-12-13 18:43:12.560148: val_loss -0.1952
2024-12-13 18:43:12.560881: Pseudo dice [0.5675]
2024-12-13 18:43:12.561474: Epoch time: 154.18 s
2024-12-13 18:43:14.225503: 
2024-12-13 18:43:14.226377: Epoch 10
2024-12-13 18:43:14.226974: Current learning rate: 0.0094
2024-12-13 18:46:26.561326: Validation loss did not improve from -0.26051. Patience: 3/50
2024-12-13 18:46:26.562171: train_loss -0.6673
2024-12-13 18:46:26.563061: val_loss -0.2172
2024-12-13 18:46:26.563825: Pseudo dice [0.589]
2024-12-13 18:46:26.564593: Epoch time: 192.34 s
2024-12-13 18:46:26.565523: Yayy! New best EMA pseudo Dice: 0.5733
2024-12-13 18:46:28.289707: 
2024-12-13 18:46:28.290911: Epoch 11
2024-12-13 18:46:28.291754: Current learning rate: 0.00934
2024-12-13 18:51:04.265514: Validation loss improved from -0.26051 to -0.27285! Patience: 3/50
2024-12-13 18:51:04.266671: train_loss -0.6775
2024-12-13 18:51:04.267536: val_loss -0.2729
2024-12-13 18:51:04.268378: Pseudo dice [0.6256]
2024-12-13 18:51:04.269117: Epoch time: 275.98 s
2024-12-13 18:51:04.269853: Yayy! New best EMA pseudo Dice: 0.5785
2024-12-13 18:51:05.991168: 
2024-12-13 18:51:05.992325: Epoch 12
2024-12-13 18:51:05.993136: Current learning rate: 0.00928
2024-12-13 18:55:43.212680: Validation loss did not improve from -0.27285. Patience: 1/50
2024-12-13 18:55:43.213630: train_loss -0.6821
2024-12-13 18:55:43.214308: val_loss -0.2335
2024-12-13 18:55:43.214947: Pseudo dice [0.5984]
2024-12-13 18:55:43.215557: Epoch time: 277.22 s
2024-12-13 18:55:43.216264: Yayy! New best EMA pseudo Dice: 0.5805
2024-12-13 18:55:44.965259: 
2024-12-13 18:55:44.966257: Epoch 13
2024-12-13 18:55:44.966884: Current learning rate: 0.00922
2024-12-13 19:00:44.837886: Validation loss did not improve from -0.27285. Patience: 2/50
2024-12-13 19:00:44.838720: train_loss -0.6971
2024-12-13 19:00:44.839365: val_loss -0.2291
2024-12-13 19:00:44.839977: Pseudo dice [0.6069]
2024-12-13 19:00:44.840581: Epoch time: 299.87 s
2024-12-13 19:00:44.841172: Yayy! New best EMA pseudo Dice: 0.5831
2024-12-13 19:00:46.577283: 
2024-12-13 19:00:46.578616: Epoch 14
2024-12-13 19:00:46.579262: Current learning rate: 0.00916
2024-12-13 19:05:10.205026: Validation loss did not improve from -0.27285. Patience: 3/50
2024-12-13 19:05:10.206042: train_loss -0.7002
2024-12-13 19:05:10.206872: val_loss -0.1734
2024-12-13 19:05:10.207638: Pseudo dice [0.5864]
2024-12-13 19:05:10.208443: Epoch time: 263.63 s
2024-12-13 19:05:10.605835: Yayy! New best EMA pseudo Dice: 0.5834
2024-12-13 19:05:12.407911: 
2024-12-13 19:05:12.409162: Epoch 15
2024-12-13 19:05:12.409849: Current learning rate: 0.0091
2024-12-13 19:09:43.735146: Validation loss did not improve from -0.27285. Patience: 4/50
2024-12-13 19:09:43.735782: train_loss -0.7068
2024-12-13 19:09:43.736519: val_loss -0.2094
2024-12-13 19:09:43.737170: Pseudo dice [0.5782]
2024-12-13 19:09:43.737833: Epoch time: 271.33 s
2024-12-13 19:09:45.094052: 
2024-12-13 19:09:45.094981: Epoch 16
2024-12-13 19:09:45.095787: Current learning rate: 0.00903
2024-12-13 19:14:40.514644: Validation loss did not improve from -0.27285. Patience: 5/50
2024-12-13 19:14:40.515486: train_loss -0.7081
2024-12-13 19:14:40.516140: val_loss -0.271
2024-12-13 19:14:40.516786: Pseudo dice [0.6144]
2024-12-13 19:14:40.517387: Epoch time: 295.42 s
2024-12-13 19:14:40.517956: Yayy! New best EMA pseudo Dice: 0.5861
2024-12-13 19:14:42.270651: 
2024-12-13 19:14:42.271984: Epoch 17
2024-12-13 19:14:42.272743: Current learning rate: 0.00897
2024-12-13 19:19:40.685321: Validation loss did not improve from -0.27285. Patience: 6/50
2024-12-13 19:19:40.686247: train_loss -0.7254
2024-12-13 19:19:40.687056: val_loss -0.2064
2024-12-13 19:19:40.687714: Pseudo dice [0.6011]
2024-12-13 19:19:40.688344: Epoch time: 298.42 s
2024-12-13 19:19:40.688910: Yayy! New best EMA pseudo Dice: 0.5876
2024-12-13 19:19:42.447709: 
2024-12-13 19:19:42.448743: Epoch 18
2024-12-13 19:19:42.449363: Current learning rate: 0.00891
2024-12-13 19:24:37.314115: Validation loss did not improve from -0.27285. Patience: 7/50
2024-12-13 19:24:37.315830: train_loss -0.7332
2024-12-13 19:24:37.316612: val_loss -0.2619
2024-12-13 19:24:37.317266: Pseudo dice [0.6205]
2024-12-13 19:24:37.318111: Epoch time: 294.87 s
2024-12-13 19:24:37.318902: Yayy! New best EMA pseudo Dice: 0.5909
2024-12-13 19:24:39.405620: 
2024-12-13 19:24:39.406319: Epoch 19
2024-12-13 19:24:39.407003: Current learning rate: 0.00885
2024-12-13 19:29:38.575483: Validation loss did not improve from -0.27285. Patience: 8/50
2024-12-13 19:29:38.576518: train_loss -0.7358
2024-12-13 19:29:38.578078: val_loss -0.255
2024-12-13 19:29:38.578971: Pseudo dice [0.6156]
2024-12-13 19:29:38.580351: Epoch time: 299.17 s
2024-12-13 19:29:38.909909: Yayy! New best EMA pseudo Dice: 0.5933
2024-12-13 19:29:40.757753: 
2024-12-13 19:29:40.758605: Epoch 20
2024-12-13 19:29:40.759314: Current learning rate: 0.00879
2024-12-13 19:34:56.533435: Validation loss did not improve from -0.27285. Patience: 9/50
2024-12-13 19:34:56.534292: train_loss -0.7271
2024-12-13 19:34:56.535189: val_loss -0.2142
2024-12-13 19:34:56.536203: Pseudo dice [0.5975]
2024-12-13 19:34:56.537465: Epoch time: 315.78 s
2024-12-13 19:34:56.538288: Yayy! New best EMA pseudo Dice: 0.5938
2024-12-13 19:34:58.322776: 
2024-12-13 19:34:58.324095: Epoch 21
2024-12-13 19:34:58.325171: Current learning rate: 0.00873
2024-12-13 19:40:12.743802: Validation loss did not improve from -0.27285. Patience: 10/50
2024-12-13 19:40:12.744699: train_loss -0.7406
2024-12-13 19:40:12.745784: val_loss -0.1919
2024-12-13 19:40:12.746805: Pseudo dice [0.5886]
2024-12-13 19:40:12.747684: Epoch time: 314.42 s
2024-12-13 19:40:14.051427: 
2024-12-13 19:40:14.052557: Epoch 22
2024-12-13 19:40:14.053186: Current learning rate: 0.00867
2024-12-13 19:45:34.211035: Validation loss did not improve from -0.27285. Patience: 11/50
2024-12-13 19:45:34.211677: train_loss -0.7479
2024-12-13 19:45:34.212571: val_loss -0.2483
2024-12-13 19:45:34.213554: Pseudo dice [0.622]
2024-12-13 19:45:34.214458: Epoch time: 320.16 s
2024-12-13 19:45:34.215254: Yayy! New best EMA pseudo Dice: 0.5961
2024-12-13 19:45:35.964702: 
2024-12-13 19:45:35.965615: Epoch 23
2024-12-13 19:45:35.966376: Current learning rate: 0.00861
2024-12-13 19:50:55.140888: Validation loss improved from -0.27285 to -0.27854! Patience: 11/50
2024-12-13 19:50:55.141900: train_loss -0.7441
2024-12-13 19:50:55.142526: val_loss -0.2785
2024-12-13 19:50:55.143197: Pseudo dice [0.631]
2024-12-13 19:50:55.143882: Epoch time: 319.18 s
2024-12-13 19:50:55.144471: Yayy! New best EMA pseudo Dice: 0.5996
2024-12-13 19:50:56.823150: 
2024-12-13 19:50:56.824088: Epoch 24
2024-12-13 19:50:56.824853: Current learning rate: 0.00855
2024-12-13 19:56:22.116932: Validation loss did not improve from -0.27854. Patience: 1/50
2024-12-13 19:56:22.117670: train_loss -0.7571
2024-12-13 19:56:22.118303: val_loss -0.1915
2024-12-13 19:56:22.118934: Pseudo dice [0.5947]
2024-12-13 19:56:22.119566: Epoch time: 325.3 s
2024-12-13 19:56:23.814894: 
2024-12-13 19:56:23.815997: Epoch 25
2024-12-13 19:56:23.816742: Current learning rate: 0.00849
2024-12-13 20:01:55.234939: Validation loss did not improve from -0.27854. Patience: 2/50
2024-12-13 20:01:55.235560: train_loss -0.7622
2024-12-13 20:01:55.236385: val_loss -0.173
2024-12-13 20:01:55.237157: Pseudo dice [0.5784]
2024-12-13 20:01:55.237991: Epoch time: 331.42 s
2024-12-13 20:01:56.581574: 
2024-12-13 20:01:56.582514: Epoch 26
2024-12-13 20:01:56.583672: Current learning rate: 0.00843
2024-12-13 20:07:17.237504: Validation loss did not improve from -0.27854. Patience: 3/50
2024-12-13 20:07:17.238432: train_loss -0.767
2024-12-13 20:07:17.239265: val_loss -0.2193
2024-12-13 20:07:17.240039: Pseudo dice [0.6199]
2024-12-13 20:07:17.240741: Epoch time: 320.66 s
2024-12-13 20:07:18.588318: 
2024-12-13 20:07:18.589460: Epoch 27
2024-12-13 20:07:18.590498: Current learning rate: 0.00836
2024-12-13 20:12:23.605242: Validation loss did not improve from -0.27854. Patience: 4/50
2024-12-13 20:12:23.605881: train_loss -0.7688
2024-12-13 20:12:23.606627: val_loss -0.1751
2024-12-13 20:12:23.607327: Pseudo dice [0.5895]
2024-12-13 20:12:23.608000: Epoch time: 305.02 s
2024-12-13 20:12:24.949970: 
2024-12-13 20:12:24.950823: Epoch 28
2024-12-13 20:12:24.951504: Current learning rate: 0.0083
2024-12-13 20:17:46.955097: Validation loss did not improve from -0.27854. Patience: 5/50
2024-12-13 20:17:46.955788: train_loss -0.776
2024-12-13 20:17:46.956442: val_loss -0.2453
2024-12-13 20:17:46.957049: Pseudo dice [0.6308]
2024-12-13 20:17:46.957693: Epoch time: 322.01 s
2024-12-13 20:17:46.958316: Yayy! New best EMA pseudo Dice: 0.6016
2024-12-13 20:17:48.719427: 
2024-12-13 20:17:48.720423: Epoch 29
2024-12-13 20:17:48.721300: Current learning rate: 0.00824
2024-12-13 20:23:24.657415: Validation loss did not improve from -0.27854. Patience: 6/50
2024-12-13 20:23:24.658254: train_loss -0.7728
2024-12-13 20:23:24.659297: val_loss -0.1868
2024-12-13 20:23:24.660312: Pseudo dice [0.5848]
2024-12-13 20:23:24.661014: Epoch time: 335.94 s
2024-12-13 20:23:26.842883: 
2024-12-13 20:23:26.844072: Epoch 30
2024-12-13 20:23:26.844731: Current learning rate: 0.00818
2024-12-13 20:28:36.235048: Validation loss did not improve from -0.27854. Patience: 7/50
2024-12-13 20:28:36.236029: train_loss -0.7762
2024-12-13 20:28:36.236708: val_loss -0.2449
2024-12-13 20:28:36.237351: Pseudo dice [0.618]
2024-12-13 20:28:36.237964: Epoch time: 309.39 s
2024-12-13 20:28:36.238563: Yayy! New best EMA pseudo Dice: 0.6017
2024-12-13 20:28:37.984445: 
2024-12-13 20:28:37.985637: Epoch 31
2024-12-13 20:28:37.986218: Current learning rate: 0.00812
2024-12-13 20:33:50.212420: Validation loss did not improve from -0.27854. Patience: 8/50
2024-12-13 20:33:50.213678: train_loss -0.7785
2024-12-13 20:33:50.214653: val_loss -0.224
2024-12-13 20:33:50.215284: Pseudo dice [0.6202]
2024-12-13 20:33:50.215923: Epoch time: 312.23 s
2024-12-13 20:33:50.216561: Yayy! New best EMA pseudo Dice: 0.6036
2024-12-13 20:33:51.975198: 
2024-12-13 20:33:51.976674: Epoch 32
2024-12-13 20:33:51.977565: Current learning rate: 0.00806
2024-12-13 20:39:27.894179: Validation loss did not improve from -0.27854. Patience: 9/50
2024-12-13 20:39:27.894876: train_loss -0.7801
2024-12-13 20:39:27.895682: val_loss -0.1867
2024-12-13 20:39:27.896356: Pseudo dice [0.599]
2024-12-13 20:39:27.897003: Epoch time: 335.92 s
2024-12-13 20:39:29.272841: 
2024-12-13 20:39:29.273796: Epoch 33
2024-12-13 20:39:29.274752: Current learning rate: 0.008
2024-12-13 20:45:04.492419: Validation loss did not improve from -0.27854. Patience: 10/50
2024-12-13 20:45:04.493654: train_loss -0.7849
2024-12-13 20:45:04.494501: val_loss -0.1913
2024-12-13 20:45:04.495265: Pseudo dice [0.6035]
2024-12-13 20:45:04.496060: Epoch time: 335.22 s
2024-12-13 20:45:05.936054: 
2024-12-13 20:45:05.937356: Epoch 34
2024-12-13 20:45:05.938148: Current learning rate: 0.00793
2024-12-13 20:52:39.449643: Validation loss did not improve from -0.27854. Patience: 11/50
2024-12-13 20:52:39.450519: train_loss -0.789
2024-12-13 20:52:39.451149: val_loss -0.2297
2024-12-13 20:52:39.451773: Pseudo dice [0.6332]
2024-12-13 20:52:39.452304: Epoch time: 453.52 s
2024-12-13 20:52:39.863301: Yayy! New best EMA pseudo Dice: 0.6062
2024-12-13 20:52:41.681664: 
2024-12-13 20:52:41.682417: Epoch 35
2024-12-13 20:52:41.682979: Current learning rate: 0.00787
2024-12-13 21:00:30.930062: Validation loss did not improve from -0.27854. Patience: 12/50
2024-12-13 21:00:30.930919: train_loss -0.7889
2024-12-13 21:00:30.931650: val_loss -0.0823
2024-12-13 21:00:30.932448: Pseudo dice [0.566]
2024-12-13 21:00:30.933124: Epoch time: 469.25 s
2024-12-13 21:00:32.363246: 
2024-12-13 21:00:32.364374: Epoch 36
2024-12-13 21:00:32.365178: Current learning rate: 0.00781
2024-12-13 21:09:06.733072: Validation loss did not improve from -0.27854. Patience: 13/50
2024-12-13 21:09:06.734108: train_loss -0.7911
2024-12-13 21:09:06.734826: val_loss -0.193
2024-12-13 21:09:06.735397: Pseudo dice [0.5991]
2024-12-13 21:09:06.736161: Epoch time: 514.37 s
2024-12-13 21:09:08.148991: 
2024-12-13 21:09:08.150329: Epoch 37
2024-12-13 21:09:08.150967: Current learning rate: 0.00775
2024-12-13 21:17:06.027002: Validation loss did not improve from -0.27854. Patience: 14/50
2024-12-13 21:17:06.027663: train_loss -0.789
2024-12-13 21:17:06.028336: val_loss -0.1825
2024-12-13 21:17:06.028983: Pseudo dice [0.6176]
2024-12-13 21:17:06.029900: Epoch time: 477.88 s
2024-12-13 21:17:07.429149: 
2024-12-13 21:17:07.429960: Epoch 38
2024-12-13 21:17:07.430738: Current learning rate: 0.00769
2024-12-13 21:25:14.076252: Validation loss did not improve from -0.27854. Patience: 15/50
2024-12-13 21:25:14.077154: train_loss -0.7922
2024-12-13 21:25:14.077976: val_loss -0.2344
2024-12-13 21:25:14.078663: Pseudo dice [0.639]
2024-12-13 21:25:14.079267: Epoch time: 486.65 s
2024-12-13 21:25:14.079897: Yayy! New best EMA pseudo Dice: 0.607
2024-12-13 21:25:15.919948: 
2024-12-13 21:25:15.921129: Epoch 39
2024-12-13 21:25:15.921813: Current learning rate: 0.00763
2024-12-13 21:33:43.764381: Validation loss did not improve from -0.27854. Patience: 16/50
2024-12-13 21:33:43.768416: train_loss -0.7977
2024-12-13 21:33:43.769794: val_loss -0.1755
2024-12-13 21:33:43.770363: Pseudo dice [0.6122]
2024-12-13 21:33:43.771562: Epoch time: 507.85 s
2024-12-13 21:33:44.124417: Yayy! New best EMA pseudo Dice: 0.6075
2024-12-13 21:33:45.927447: 
2024-12-13 21:33:45.928386: Epoch 40
2024-12-13 21:33:45.929141: Current learning rate: 0.00756
2024-12-13 21:42:46.070881: Validation loss did not improve from -0.27854. Patience: 17/50
2024-12-13 21:42:46.072024: train_loss -0.7968
2024-12-13 21:42:46.073140: val_loss -0.178
2024-12-13 21:42:46.074019: Pseudo dice [0.6118]
2024-12-13 21:42:46.074935: Epoch time: 540.15 s
2024-12-13 21:42:46.075744: Yayy! New best EMA pseudo Dice: 0.6079
2024-12-13 21:42:48.354579: 
2024-12-13 21:42:48.355724: Epoch 41
2024-12-13 21:42:48.356597: Current learning rate: 0.0075
2024-12-13 21:51:07.851383: Validation loss did not improve from -0.27854. Patience: 18/50
2024-12-13 21:51:07.852119: train_loss -0.7981
2024-12-13 21:51:07.852747: val_loss -0.2649
2024-12-13 21:51:07.853326: Pseudo dice [0.6419]
2024-12-13 21:51:07.853951: Epoch time: 499.5 s
2024-12-13 21:51:07.854803: Yayy! New best EMA pseudo Dice: 0.6113
2024-12-13 21:51:09.576649: 
2024-12-13 21:51:09.577659: Epoch 42
2024-12-13 21:51:09.578374: Current learning rate: 0.00744
2024-12-13 21:59:56.717925: Validation loss did not improve from -0.27854. Patience: 19/50
2024-12-13 21:59:56.718781: train_loss -0.7978
2024-12-13 21:59:56.719692: val_loss -0.1731
2024-12-13 21:59:56.720429: Pseudo dice [0.6185]
2024-12-13 21:59:56.721267: Epoch time: 527.14 s
2024-12-13 21:59:56.721999: Yayy! New best EMA pseudo Dice: 0.612
2024-12-13 21:59:58.480114: 
2024-12-13 21:59:58.481168: Epoch 43
2024-12-13 21:59:58.481833: Current learning rate: 0.00738
2024-12-13 22:09:03.509691: Validation loss did not improve from -0.27854. Patience: 20/50
2024-12-13 22:09:03.510641: train_loss -0.8038
2024-12-13 22:09:03.511333: val_loss -0.1983
2024-12-13 22:09:03.512104: Pseudo dice [0.6131]
2024-12-13 22:09:03.512872: Epoch time: 545.03 s
2024-12-13 22:09:03.513522: Yayy! New best EMA pseudo Dice: 0.6121
2024-12-13 22:09:05.278816: 
2024-12-13 22:09:05.279879: Epoch 44
2024-12-13 22:09:05.280521: Current learning rate: 0.00732
2024-12-13 22:18:06.383393: Validation loss did not improve from -0.27854. Patience: 21/50
2024-12-13 22:18:06.384431: train_loss -0.8065
2024-12-13 22:18:06.385404: val_loss -0.2012
2024-12-13 22:18:06.386307: Pseudo dice [0.6227]
2024-12-13 22:18:06.387208: Epoch time: 541.11 s
2024-12-13 22:18:06.820521: Yayy! New best EMA pseudo Dice: 0.6132
2024-12-13 22:18:08.642551: 
2024-12-13 22:18:08.643994: Epoch 45
2024-12-13 22:18:08.645084: Current learning rate: 0.00725
2024-12-13 22:27:11.122179: Validation loss did not improve from -0.27854. Patience: 22/50
2024-12-13 22:27:11.123080: train_loss -0.8063
2024-12-13 22:27:11.123780: val_loss -0.1612
2024-12-13 22:27:11.124536: Pseudo dice [0.5994]
2024-12-13 22:27:11.125191: Epoch time: 542.48 s
2024-12-13 22:27:12.489386: 
2024-12-13 22:27:12.490314: Epoch 46
2024-12-13 22:27:12.490970: Current learning rate: 0.00719
2024-12-13 22:35:51.873010: Validation loss did not improve from -0.27854. Patience: 23/50
2024-12-13 22:35:51.873868: train_loss -0.8096
2024-12-13 22:35:51.874484: val_loss -0.2426
2024-12-13 22:35:51.875104: Pseudo dice [0.6372]
2024-12-13 22:35:51.875710: Epoch time: 519.39 s
2024-12-13 22:35:51.876276: Yayy! New best EMA pseudo Dice: 0.6144
2024-12-13 22:35:53.690749: 
2024-12-13 22:35:53.691736: Epoch 47
2024-12-13 22:35:53.692364: Current learning rate: 0.00713
2024-12-13 22:45:09.911551: Validation loss did not improve from -0.27854. Patience: 24/50
2024-12-13 22:45:09.914662: train_loss -0.8093
2024-12-13 22:45:09.916190: val_loss -0.2576
2024-12-13 22:45:09.916931: Pseudo dice [0.6549]
2024-12-13 22:45:09.917939: Epoch time: 556.22 s
2024-12-13 22:45:09.918847: Yayy! New best EMA pseudo Dice: 0.6184
2024-12-13 22:45:11.700868: 
2024-12-13 22:45:11.701738: Epoch 48
2024-12-13 22:45:11.702397: Current learning rate: 0.00707
2024-12-13 22:54:23.655548: Validation loss did not improve from -0.27854. Patience: 25/50
2024-12-13 22:54:23.656345: train_loss -0.8111
2024-12-13 22:54:23.657200: val_loss -0.2578
2024-12-13 22:54:23.657823: Pseudo dice [0.6394]
2024-12-13 22:54:23.658475: Epoch time: 551.96 s
2024-12-13 22:54:23.659121: Yayy! New best EMA pseudo Dice: 0.6205
2024-12-13 22:54:25.403833: 
2024-12-13 22:54:25.404864: Epoch 49
2024-12-13 22:54:25.405529: Current learning rate: 0.007
2024-12-13 23:03:36.883620: Validation loss did not improve from -0.27854. Patience: 26/50
2024-12-13 23:03:36.884485: train_loss -0.8092
2024-12-13 23:03:36.885233: val_loss -0.2384
2024-12-13 23:03:36.885923: Pseudo dice [0.643]
2024-12-13 23:03:36.886702: Epoch time: 551.48 s
2024-12-13 23:03:37.275544: Yayy! New best EMA pseudo Dice: 0.6228
2024-12-13 23:03:39.069286: 
2024-12-13 23:03:39.070628: Epoch 50
2024-12-13 23:03:39.071494: Current learning rate: 0.00694
2024-12-13 23:12:16.547166: Validation loss did not improve from -0.27854. Patience: 27/50
2024-12-13 23:12:16.548028: train_loss -0.8129
2024-12-13 23:12:16.548670: val_loss -0.1084
2024-12-13 23:12:16.549230: Pseudo dice [0.5918]
2024-12-13 23:12:16.549957: Epoch time: 517.48 s
2024-12-13 23:12:18.563871: 
2024-12-13 23:12:18.565150: Epoch 51
2024-12-13 23:12:18.565853: Current learning rate: 0.00688
2024-12-13 23:20:43.954776: Validation loss did not improve from -0.27854. Patience: 28/50
2024-12-13 23:20:43.955592: train_loss -0.8179
2024-12-13 23:20:43.956290: val_loss -0.1956
2024-12-13 23:20:43.956966: Pseudo dice [0.6311]
2024-12-13 23:20:43.957671: Epoch time: 505.39 s
2024-12-13 23:20:45.360386: 
2024-12-13 23:20:45.361456: Epoch 52
2024-12-13 23:20:45.362146: Current learning rate: 0.00682
2024-12-13 23:30:12.028843: Validation loss did not improve from -0.27854. Patience: 29/50
2024-12-13 23:30:12.029637: train_loss -0.8195
2024-12-13 23:30:12.030578: val_loss -0.2077
2024-12-13 23:30:12.031310: Pseudo dice [0.6388]
2024-12-13 23:30:12.032219: Epoch time: 566.67 s
2024-12-13 23:30:13.403483: 
2024-12-13 23:30:13.404857: Epoch 53
2024-12-13 23:30:13.405561: Current learning rate: 0.00675
2024-12-13 23:39:08.768744: Validation loss did not improve from -0.27854. Patience: 30/50
2024-12-13 23:39:08.769499: train_loss -0.8185
2024-12-13 23:39:08.770138: val_loss -0.2091
2024-12-13 23:39:08.770738: Pseudo dice [0.6218]
2024-12-13 23:39:08.771445: Epoch time: 535.37 s
2024-12-13 23:39:10.153754: 
2024-12-13 23:39:10.155061: Epoch 54
2024-12-13 23:39:10.155747: Current learning rate: 0.00669
2024-12-13 23:48:22.387521: Validation loss did not improve from -0.27854. Patience: 31/50
2024-12-13 23:48:22.388803: train_loss -0.8226
2024-12-13 23:48:22.389678: val_loss -0.1895
2024-12-13 23:48:22.390375: Pseudo dice [0.6227]
2024-12-13 23:48:22.391092: Epoch time: 552.24 s
2024-12-13 23:48:24.175415: 
2024-12-13 23:48:24.176417: Epoch 55
2024-12-13 23:48:24.177046: Current learning rate: 0.00663
2024-12-13 23:57:43.148579: Validation loss did not improve from -0.27854. Patience: 32/50
2024-12-13 23:57:43.149209: train_loss -0.8244
2024-12-13 23:57:43.150087: val_loss -0.1712
2024-12-13 23:57:43.150733: Pseudo dice [0.6187]
2024-12-13 23:57:43.151372: Epoch time: 558.98 s
2024-12-13 23:57:44.596636: 
2024-12-13 23:57:44.597687: Epoch 56
2024-12-13 23:57:44.598414: Current learning rate: 0.00657
2024-12-14 00:07:03.063654: Validation loss did not improve from -0.27854. Patience: 33/50
2024-12-14 00:07:03.064396: train_loss -0.8242
2024-12-14 00:07:03.065037: val_loss -0.1936
2024-12-14 00:07:03.065652: Pseudo dice [0.6087]
2024-12-14 00:07:03.066233: Epoch time: 558.47 s
2024-12-14 00:07:04.484400: 
2024-12-14 00:07:04.485555: Epoch 57
2024-12-14 00:07:04.486225: Current learning rate: 0.0065
2024-12-14 00:16:24.440959: Validation loss did not improve from -0.27854. Patience: 34/50
2024-12-14 00:16:24.441821: train_loss -0.8242
2024-12-14 00:16:24.442477: val_loss -0.2554
2024-12-14 00:16:24.443122: Pseudo dice [0.6498]
2024-12-14 00:16:24.443773: Epoch time: 559.96 s
2024-12-14 00:16:24.444324: Yayy! New best EMA pseudo Dice: 0.6237
2024-12-14 00:16:26.165450: 
2024-12-14 00:16:26.166586: Epoch 58
2024-12-14 00:16:26.167288: Current learning rate: 0.00644
2024-12-14 00:25:53.791751: Validation loss did not improve from -0.27854. Patience: 35/50
2024-12-14 00:25:53.792742: train_loss -0.8245
2024-12-14 00:25:53.793507: val_loss -0.2401
2024-12-14 00:25:53.794106: Pseudo dice [0.6487]
2024-12-14 00:25:53.794699: Epoch time: 567.63 s
2024-12-14 00:25:53.795640: Yayy! New best EMA pseudo Dice: 0.6262
2024-12-14 00:25:55.587668: 
2024-12-14 00:25:55.588750: Epoch 59
2024-12-14 00:25:55.589501: Current learning rate: 0.00638
2024-12-14 00:35:23.962656: Validation loss did not improve from -0.27854. Patience: 36/50
2024-12-14 00:35:23.963520: train_loss -0.8218
2024-12-14 00:35:23.964348: val_loss -0.2292
2024-12-14 00:35:23.965274: Pseudo dice [0.6369]
2024-12-14 00:35:23.966019: Epoch time: 568.38 s
2024-12-14 00:35:24.393954: Yayy! New best EMA pseudo Dice: 0.6273
2024-12-14 00:35:26.198638: 
2024-12-14 00:35:26.199932: Epoch 60
2024-12-14 00:35:26.200824: Current learning rate: 0.00631
2024-12-14 00:44:26.813549: Validation loss did not improve from -0.27854. Patience: 37/50
2024-12-14 00:44:26.814427: train_loss -0.8231
2024-12-14 00:44:26.815337: val_loss -0.2123
2024-12-14 00:44:26.816069: Pseudo dice [0.6398]
2024-12-14 00:44:26.816741: Epoch time: 540.62 s
2024-12-14 00:44:26.817389: Yayy! New best EMA pseudo Dice: 0.6285
2024-12-14 00:44:28.610188: 
2024-12-14 00:44:28.611332: Epoch 61
2024-12-14 00:44:28.612067: Current learning rate: 0.00625
2024-12-14 00:53:20.207417: Validation loss did not improve from -0.27854. Patience: 38/50
2024-12-14 00:53:20.211551: train_loss -0.827
2024-12-14 00:53:20.212917: val_loss -0.0986
2024-12-14 00:53:20.213526: Pseudo dice [0.5933]
2024-12-14 00:53:20.214490: Epoch time: 531.6 s
2024-12-14 00:53:22.526031: 
2024-12-14 00:53:22.528265: Epoch 62
2024-12-14 00:53:22.528952: Current learning rate: 0.00619
2024-12-14 01:02:24.586295: Validation loss did not improve from -0.27854. Patience: 39/50
2024-12-14 01:02:24.587280: train_loss -0.8295
2024-12-14 01:02:24.587938: val_loss -0.1841
2024-12-14 01:02:24.588492: Pseudo dice [0.6366]
2024-12-14 01:02:24.589086: Epoch time: 542.06 s
2024-12-14 01:02:26.029102: 
2024-12-14 01:02:26.030527: Epoch 63
2024-12-14 01:02:26.031217: Current learning rate: 0.00612
2024-12-14 01:11:27.488415: Validation loss did not improve from -0.27854. Patience: 40/50
2024-12-14 01:11:27.489196: train_loss -0.8291
2024-12-14 01:11:27.489846: val_loss -0.184
2024-12-14 01:11:27.490450: Pseudo dice [0.6214]
2024-12-14 01:11:27.491001: Epoch time: 541.46 s
2024-12-14 01:11:28.920720: 
2024-12-14 01:11:28.922323: Epoch 64
2024-12-14 01:11:28.923001: Current learning rate: 0.00606
2024-12-14 01:21:16.631335: Validation loss did not improve from -0.27854. Patience: 41/50
2024-12-14 01:21:16.632476: train_loss -0.8319
2024-12-14 01:21:16.633561: val_loss -0.2197
2024-12-14 01:21:16.634437: Pseudo dice [0.6553]
2024-12-14 01:21:16.635338: Epoch time: 587.71 s
2024-12-14 01:21:17.054313: Yayy! New best EMA pseudo Dice: 0.6286
2024-12-14 01:21:18.863842: 
2024-12-14 01:21:18.865304: Epoch 65
2024-12-14 01:21:18.866175: Current learning rate: 0.006
2024-12-14 01:30:10.865511: Validation loss did not improve from -0.27854. Patience: 42/50
2024-12-14 01:30:10.866177: train_loss -0.8319
2024-12-14 01:30:10.867044: val_loss -0.1763
2024-12-14 01:30:10.867860: Pseudo dice [0.6424]
2024-12-14 01:30:10.868608: Epoch time: 532.0 s
2024-12-14 01:30:10.869387: Yayy! New best EMA pseudo Dice: 0.63
2024-12-14 01:30:12.725808: 
2024-12-14 01:30:12.727463: Epoch 66
2024-12-14 01:30:12.728338: Current learning rate: 0.00593
2024-12-14 01:38:43.762717: Validation loss did not improve from -0.27854. Patience: 43/50
2024-12-14 01:38:43.763550: train_loss -0.83
2024-12-14 01:38:43.764646: val_loss -0.1976
2024-12-14 01:38:43.765572: Pseudo dice [0.6268]
2024-12-14 01:38:43.766518: Epoch time: 511.04 s
2024-12-14 01:38:45.198950: 
2024-12-14 01:38:45.200399: Epoch 67
2024-12-14 01:38:45.201312: Current learning rate: 0.00587
2024-12-14 01:48:03.383418: Validation loss did not improve from -0.27854. Patience: 44/50
2024-12-14 01:48:03.384444: train_loss -0.836
2024-12-14 01:48:03.385324: val_loss -0.1278
2024-12-14 01:48:03.386192: Pseudo dice [0.604]
2024-12-14 01:48:03.387026: Epoch time: 558.19 s
2024-12-14 01:48:04.802832: 
2024-12-14 01:48:04.804673: Epoch 68
2024-12-14 01:48:04.805408: Current learning rate: 0.00581
2024-12-14 01:57:20.150730: Validation loss did not improve from -0.27854. Patience: 45/50
2024-12-14 01:57:20.153785: train_loss -0.8357
2024-12-14 01:57:20.154905: val_loss -0.2174
2024-12-14 01:57:20.155614: Pseudo dice [0.6288]
2024-12-14 01:57:20.156652: Epoch time: 555.35 s
2024-12-14 01:57:21.638482: 
2024-12-14 01:57:21.639844: Epoch 69
2024-12-14 01:57:21.640732: Current learning rate: 0.00574
2024-12-14 02:06:27.667723: Validation loss did not improve from -0.27854. Patience: 46/50
2024-12-14 02:06:27.668988: train_loss -0.8375
2024-12-14 02:06:27.670119: val_loss -0.2345
2024-12-14 02:06:27.670736: Pseudo dice [0.6491]
2024-12-14 02:06:27.671380: Epoch time: 546.03 s
2024-12-14 02:06:29.479485: 
2024-12-14 02:06:29.480556: Epoch 70
2024-12-14 02:06:29.481338: Current learning rate: 0.00568
2024-12-14 02:15:21.119826: Validation loss did not improve from -0.27854. Patience: 47/50
2024-12-14 02:15:21.120872: train_loss -0.835
2024-12-14 02:15:21.121686: val_loss -0.187
2024-12-14 02:15:21.122435: Pseudo dice [0.6292]
2024-12-14 02:15:21.123296: Epoch time: 531.64 s
2024-12-14 02:15:22.604864: 
2024-12-14 02:15:22.605767: Epoch 71
2024-12-14 02:15:22.606519: Current learning rate: 0.00562
2024-12-14 02:24:08.756241: Validation loss did not improve from -0.27854. Patience: 48/50
2024-12-14 02:24:08.757140: train_loss -0.8319
2024-12-14 02:24:08.757814: val_loss -0.1444
2024-12-14 02:24:08.758542: Pseudo dice [0.6034]
2024-12-14 02:24:08.759264: Epoch time: 526.15 s
2024-12-14 02:24:10.182832: 
2024-12-14 02:24:10.184011: Epoch 72
2024-12-14 02:24:10.184786: Current learning rate: 0.00555
2024-12-14 02:33:03.279709: Validation loss did not improve from -0.27854. Patience: 49/50
2024-12-14 02:33:03.280344: train_loss -0.8383
2024-12-14 02:33:03.280977: val_loss -0.1579
2024-12-14 02:33:03.281548: Pseudo dice [0.6207]
2024-12-14 02:33:03.282117: Epoch time: 533.1 s
2024-12-14 02:33:05.279946: 
2024-12-14 02:33:05.280886: Epoch 73
2024-12-14 02:33:05.281647: Current learning rate: 0.00549
2024-12-14 02:42:15.750378: Validation loss did not improve from -0.27854. Patience: 50/50
2024-12-14 02:42:15.751237: train_loss -0.841
2024-12-14 02:42:15.752220: val_loss -0.1776
2024-12-14 02:42:15.753174: Pseudo dice [0.6336]
2024-12-14 02:42:15.754567: Epoch time: 550.47 s
2024-12-14 02:42:17.210086: 
2024-12-14 02:42:17.211390: Epoch 74
2024-12-14 02:42:17.212376: Current learning rate: 0.00542
2024-12-14 02:51:21.644270: Validation loss did not improve from -0.27854. Patience: 51/50
2024-12-14 02:51:21.645175: train_loss -0.844
2024-12-14 02:51:21.645905: val_loss -0.1774
2024-12-14 02:51:21.646674: Pseudo dice [0.6335]
2024-12-14 02:51:21.647738: Epoch time: 544.44 s
2024-12-14 02:51:23.477647: 
2024-12-14 02:51:23.478719: Epoch 75
2024-12-14 02:51:23.479524: Current learning rate: 0.00536
2024-12-14 03:00:38.136751: Validation loss did not improve from -0.27854. Patience: 52/50
2024-12-14 03:00:38.140478: train_loss -0.8443
2024-12-14 03:00:38.141852: val_loss -0.1801
2024-12-14 03:00:38.142544: Pseudo dice [0.6207]
2024-12-14 03:00:38.143487: Epoch time: 554.66 s
2024-12-14 03:00:39.629111: 
2024-12-14 03:00:39.630183: Epoch 76
2024-12-14 03:00:39.631003: Current learning rate: 0.00529
2024-12-14 03:09:54.340635: Validation loss did not improve from -0.27854. Patience: 53/50
2024-12-14 03:09:54.341917: train_loss -0.8418
2024-12-14 03:09:54.342669: val_loss -0.2032
2024-12-14 03:09:54.343395: Pseudo dice [0.6402]
2024-12-14 03:09:54.344106: Epoch time: 554.71 s
2024-12-14 03:09:55.770148: 
2024-12-14 03:09:55.771201: Epoch 77
2024-12-14 03:09:55.771957: Current learning rate: 0.00523
2024-12-14 03:19:36.924813: Validation loss did not improve from -0.27854. Patience: 54/50
2024-12-14 03:19:36.925718: train_loss -0.845
2024-12-14 03:19:36.926386: val_loss -0.2007
2024-12-14 03:19:36.927067: Pseudo dice [0.6322]
2024-12-14 03:19:36.927722: Epoch time: 581.16 s
2024-12-14 03:19:38.372891: 
2024-12-14 03:19:38.373735: Epoch 78
2024-12-14 03:19:38.374349: Current learning rate: 0.00517
2024-12-14 03:29:01.563040: Validation loss did not improve from -0.27854. Patience: 55/50
2024-12-14 03:29:01.563939: train_loss -0.8448
2024-12-14 03:29:01.564666: val_loss -0.2144
2024-12-14 03:29:01.565318: Pseudo dice [0.642]
2024-12-14 03:29:01.565970: Epoch time: 563.19 s
2024-12-14 03:29:03.031716: 
2024-12-14 03:29:03.032866: Epoch 79
2024-12-14 03:29:03.033561: Current learning rate: 0.0051
2024-12-14 03:37:50.826622: Validation loss did not improve from -0.27854. Patience: 56/50
2024-12-14 03:37:50.827643: train_loss -0.8443
2024-12-14 03:37:50.828364: val_loss -0.1849
2024-12-14 03:37:50.828989: Pseudo dice [0.642]
2024-12-14 03:37:50.829724: Epoch time: 527.8 s
2024-12-14 03:37:51.220886: Yayy! New best EMA pseudo Dice: 0.6312
2024-12-14 03:37:53.016724: 
2024-12-14 03:37:53.017715: Epoch 80
2024-12-14 03:37:53.018422: Current learning rate: 0.00504
2024-12-14 03:47:05.639589: Validation loss did not improve from -0.27854. Patience: 57/50
2024-12-14 03:47:05.640569: train_loss -0.8499
2024-12-14 03:47:05.641811: val_loss -0.1891
2024-12-14 03:47:05.642838: Pseudo dice [0.644]
2024-12-14 03:47:05.643549: Epoch time: 552.62 s
2024-12-14 03:47:05.644198: Yayy! New best EMA pseudo Dice: 0.6325
2024-12-14 03:47:07.485567: 
2024-12-14 03:47:07.486741: Epoch 81
2024-12-14 03:47:07.487417: Current learning rate: 0.00497
2024-12-14 03:56:28.723384: Validation loss did not improve from -0.27854. Patience: 58/50
2024-12-14 03:56:28.724254: train_loss -0.8517
2024-12-14 03:56:28.724988: val_loss -0.1578
2024-12-14 03:56:28.725677: Pseudo dice [0.6316]
2024-12-14 03:56:28.726386: Epoch time: 561.24 s
2024-12-14 03:56:30.201325: 
2024-12-14 03:56:30.202391: Epoch 82
2024-12-14 03:56:30.203163: Current learning rate: 0.00491
2024-12-14 04:06:02.854582: Validation loss did not improve from -0.27854. Patience: 59/50
2024-12-14 04:06:02.874130: train_loss -0.8495
2024-12-14 04:06:02.876105: val_loss -0.2436
2024-12-14 04:06:02.876794: Pseudo dice [0.6524]
2024-12-14 04:06:02.878021: Epoch time: 572.67 s
2024-12-14 04:06:02.878959: Yayy! New best EMA pseudo Dice: 0.6344
2024-12-14 04:06:05.087704: 
2024-12-14 04:06:05.088544: Epoch 83
2024-12-14 04:06:05.089210: Current learning rate: 0.00484
2024-12-14 04:15:34.672812: Validation loss did not improve from -0.27854. Patience: 60/50
2024-12-14 04:15:34.674086: train_loss -0.849
2024-12-14 04:15:34.674870: val_loss -0.2113
2024-12-14 04:15:34.675584: Pseudo dice [0.6418]
2024-12-14 04:15:34.676337: Epoch time: 569.59 s
2024-12-14 04:15:34.677110: Yayy! New best EMA pseudo Dice: 0.6351
2024-12-14 04:15:36.440484: 
2024-12-14 04:15:36.441592: Epoch 84
2024-12-14 04:15:36.442342: Current learning rate: 0.00478
2024-12-14 04:24:41.635968: Validation loss did not improve from -0.27854. Patience: 61/50
2024-12-14 04:24:41.636660: train_loss -0.8504
2024-12-14 04:24:41.637507: val_loss -0.1689
2024-12-14 04:24:41.638263: Pseudo dice [0.6244]
2024-12-14 04:24:41.639051: Epoch time: 545.2 s
2024-12-14 04:24:43.384773: 
2024-12-14 04:24:43.386074: Epoch 85
2024-12-14 04:24:43.386944: Current learning rate: 0.00471
2024-12-14 04:33:32.983899: Validation loss did not improve from -0.27854. Patience: 62/50
2024-12-14 04:33:32.984528: train_loss -0.8513
2024-12-14 04:33:32.985361: val_loss -0.154
2024-12-14 04:33:32.986130: Pseudo dice [0.6258]
2024-12-14 04:33:32.987059: Epoch time: 529.6 s
2024-12-14 04:33:34.350838: 
2024-12-14 04:33:34.351967: Epoch 86
2024-12-14 04:33:34.352952: Current learning rate: 0.00465
2024-12-14 04:42:08.655797: Validation loss did not improve from -0.27854. Patience: 63/50
2024-12-14 04:42:08.656539: train_loss -0.8519
2024-12-14 04:42:08.657348: val_loss -0.1958
2024-12-14 04:42:08.658257: Pseudo dice [0.6366]
2024-12-14 04:42:08.658926: Epoch time: 514.31 s
2024-12-14 04:42:10.084121: 
2024-12-14 04:42:10.084929: Epoch 87
2024-12-14 04:42:10.085594: Current learning rate: 0.00458
2024-12-14 04:51:28.260926: Validation loss did not improve from -0.27854. Patience: 64/50
2024-12-14 04:51:28.261723: train_loss -0.8542
2024-12-14 04:51:28.262426: val_loss -0.1296
2024-12-14 04:51:28.262995: Pseudo dice [0.6231]
2024-12-14 04:51:28.263656: Epoch time: 558.18 s
2024-12-14 04:51:29.631299: 
2024-12-14 04:51:29.632178: Epoch 88
2024-12-14 04:51:29.632903: Current learning rate: 0.00452
2024-12-14 05:00:15.401210: Validation loss did not improve from -0.27854. Patience: 65/50
2024-12-14 05:00:15.402128: train_loss -0.8543
2024-12-14 05:00:15.402862: val_loss -0.1555
2024-12-14 05:00:15.403582: Pseudo dice [0.6355]
2024-12-14 05:00:15.404405: Epoch time: 525.77 s
2024-12-14 05:00:16.766371: 
2024-12-14 05:00:16.767623: Epoch 89
2024-12-14 05:00:16.768400: Current learning rate: 0.00445
2024-12-14 05:10:03.422313: Validation loss did not improve from -0.27854. Patience: 66/50
2024-12-14 05:10:03.423169: train_loss -0.8556
2024-12-14 05:10:03.424037: val_loss -0.176
2024-12-14 05:10:03.424872: Pseudo dice [0.6255]
2024-12-14 05:10:03.425673: Epoch time: 586.66 s
2024-12-14 05:10:05.283943: 
2024-12-14 05:10:05.284904: Epoch 90
2024-12-14 05:10:05.285547: Current learning rate: 0.00438
2024-12-14 05:19:29.002932: Validation loss did not improve from -0.27854. Patience: 67/50
2024-12-14 05:19:29.003705: train_loss -0.8532
2024-12-14 05:19:29.004480: val_loss -0.1714
2024-12-14 05:19:29.005200: Pseudo dice [0.6353]
2024-12-14 05:19:29.005975: Epoch time: 563.72 s
2024-12-14 05:19:30.374929: 
2024-12-14 05:19:30.376467: Epoch 91
2024-12-14 05:19:30.377224: Current learning rate: 0.00432
2024-12-14 05:29:30.479801: Validation loss did not improve from -0.27854. Patience: 68/50
2024-12-14 05:29:30.480820: train_loss -0.8564
2024-12-14 05:29:30.481736: val_loss -0.1505
2024-12-14 05:29:30.482373: Pseudo dice [0.6285]
2024-12-14 05:29:30.482981: Epoch time: 600.11 s
2024-12-14 05:29:31.853086: 
2024-12-14 05:29:31.854271: Epoch 92
2024-12-14 05:29:31.855098: Current learning rate: 0.00425
2024-12-14 05:38:46.189718: Validation loss did not improve from -0.27854. Patience: 69/50
2024-12-14 05:38:46.190705: train_loss -0.857
2024-12-14 05:38:46.191671: val_loss -0.1232
2024-12-14 05:38:46.192590: Pseudo dice [0.6217]
2024-12-14 05:38:46.193445: Epoch time: 554.34 s
2024-12-14 05:38:47.554317: 
2024-12-14 05:38:47.555519: Epoch 93
2024-12-14 05:38:47.556403: Current learning rate: 0.00419
2024-12-14 05:48:25.716663: Validation loss did not improve from -0.27854. Patience: 70/50
2024-12-14 05:48:25.717371: train_loss -0.8572
2024-12-14 05:48:25.718094: val_loss -0.1699
2024-12-14 05:48:25.718809: Pseudo dice [0.6462]
2024-12-14 05:48:25.719469: Epoch time: 578.16 s
2024-12-14 05:48:27.524922: 
2024-12-14 05:48:27.525951: Epoch 94
2024-12-14 05:48:27.526994: Current learning rate: 0.00412
2024-12-14 05:58:02.878490: Validation loss did not improve from -0.27854. Patience: 71/50
2024-12-14 05:58:02.879338: train_loss -0.8574
2024-12-14 05:58:02.880520: val_loss -0.1875
2024-12-14 05:58:02.881261: Pseudo dice [0.6318]
2024-12-14 05:58:02.881916: Epoch time: 575.36 s
2024-12-14 05:58:04.620523: 
2024-12-14 05:58:04.621628: Epoch 95
2024-12-14 05:58:04.622265: Current learning rate: 0.00405
2024-12-14 06:07:35.960600: Validation loss did not improve from -0.27854. Patience: 72/50
2024-12-14 06:07:35.961615: train_loss -0.8612
2024-12-14 06:07:35.962633: val_loss -0.1596
2024-12-14 06:07:35.963636: Pseudo dice [0.6429]
2024-12-14 06:07:35.964679: Epoch time: 571.34 s
2024-12-14 06:07:37.349522: 
2024-12-14 06:07:37.350794: Epoch 96
2024-12-14 06:07:37.351823: Current learning rate: 0.00399
2024-12-14 06:16:29.681295: Validation loss did not improve from -0.27854. Patience: 73/50
2024-12-14 06:16:29.684723: train_loss -0.8625
2024-12-14 06:16:29.686273: val_loss -0.122
2024-12-14 06:16:29.686946: Pseudo dice [0.6253]
2024-12-14 06:16:29.687726: Epoch time: 532.34 s
2024-12-14 06:16:31.147153: 
2024-12-14 06:16:31.148111: Epoch 97
2024-12-14 06:16:31.148715: Current learning rate: 0.00392
2024-12-14 06:25:35.426824: Validation loss did not improve from -0.27854. Patience: 74/50
2024-12-14 06:25:35.427617: train_loss -0.8606
2024-12-14 06:25:35.428405: val_loss -0.1446
2024-12-14 06:25:35.429412: Pseudo dice [0.6121]
2024-12-14 06:25:35.430346: Epoch time: 544.28 s
2024-12-14 06:25:36.832535: 
2024-12-14 06:25:36.833879: Epoch 98
2024-12-14 06:25:36.834729: Current learning rate: 0.00385
2024-12-14 06:34:53.398537: Validation loss did not improve from -0.27854. Patience: 75/50
2024-12-14 06:34:53.399367: train_loss -0.8639
2024-12-14 06:34:53.399991: val_loss -0.1535
2024-12-14 06:34:53.400646: Pseudo dice [0.6287]
2024-12-14 06:34:53.401258: Epoch time: 556.57 s
2024-12-14 06:34:54.838773: 
2024-12-14 06:34:54.839559: Epoch 99
2024-12-14 06:34:54.840224: Current learning rate: 0.00379
2024-12-14 06:43:55.320237: Validation loss did not improve from -0.27854. Patience: 76/50
2024-12-14 06:43:55.321103: train_loss -0.864
2024-12-14 06:43:55.321778: val_loss -0.1858
2024-12-14 06:43:55.322502: Pseudo dice [0.6474]
2024-12-14 06:43:55.323187: Epoch time: 540.48 s
2024-12-14 06:43:57.128520: 
2024-12-14 06:43:57.129653: Epoch 100
2024-12-14 06:43:57.130309: Current learning rate: 0.00372
2024-12-14 06:53:15.347713: Validation loss did not improve from -0.27854. Patience: 77/50
2024-12-14 06:53:15.348657: train_loss -0.8652
2024-12-14 06:53:15.349696: val_loss -0.1563
2024-12-14 06:53:15.350392: Pseudo dice [0.6291]
2024-12-14 06:53:15.351173: Epoch time: 558.22 s
2024-12-14 06:53:16.773086: 
2024-12-14 06:53:16.773946: Epoch 101
2024-12-14 06:53:16.774599: Current learning rate: 0.00365
2024-12-14 07:02:30.685190: Validation loss did not improve from -0.27854. Patience: 78/50
2024-12-14 07:02:30.685832: train_loss -0.8642
2024-12-14 07:02:30.686541: val_loss -0.1901
2024-12-14 07:02:30.687312: Pseudo dice [0.6444]
2024-12-14 07:02:30.687967: Epoch time: 553.91 s
2024-12-14 07:02:32.082028: 
2024-12-14 07:02:32.083030: Epoch 102
2024-12-14 07:02:32.083901: Current learning rate: 0.00359
2024-12-14 07:12:21.917473: Validation loss did not improve from -0.27854. Patience: 79/50
2024-12-14 07:12:21.918148: train_loss -0.8676
2024-12-14 07:12:21.918957: val_loss -0.1613
2024-12-14 07:12:21.919744: Pseudo dice [0.6316]
2024-12-14 07:12:21.920541: Epoch time: 589.84 s
2024-12-14 07:12:23.323340: 
2024-12-14 07:12:23.324237: Epoch 103
2024-12-14 07:12:23.325114: Current learning rate: 0.00352
2024-12-14 07:21:43.084146: Validation loss did not improve from -0.27854. Patience: 80/50
2024-12-14 07:21:43.089333: train_loss -0.8648
2024-12-14 07:21:43.090764: val_loss -0.1396
2024-12-14 07:21:43.091724: Pseudo dice [0.627]
2024-12-14 07:21:43.093336: Epoch time: 559.77 s
2024-12-14 07:21:44.530251: 
2024-12-14 07:21:44.531618: Epoch 104
2024-12-14 07:21:44.532640: Current learning rate: 0.00345
2024-12-14 07:31:15.002097: Validation loss did not improve from -0.27854. Patience: 81/50
2024-12-14 07:31:15.002955: train_loss -0.8648
2024-12-14 07:31:15.003678: val_loss -0.0672
2024-12-14 07:31:15.004329: Pseudo dice [0.5839]
2024-12-14 07:31:15.004923: Epoch time: 570.47 s
2024-12-14 07:31:17.221910: 
2024-12-14 07:31:17.223305: Epoch 105
2024-12-14 07:31:17.224280: Current learning rate: 0.00338
2024-12-14 07:41:23.735117: Validation loss did not improve from -0.27854. Patience: 82/50
2024-12-14 07:41:23.736065: train_loss -0.8686
2024-12-14 07:41:23.736907: val_loss -0.1709
2024-12-14 07:41:23.737710: Pseudo dice [0.6608]
2024-12-14 07:41:23.738500: Epoch time: 606.52 s
2024-12-14 07:41:25.142339: 
2024-12-14 07:41:25.143908: Epoch 106
2024-12-14 07:41:25.144906: Current learning rate: 0.00332
2024-12-14 07:50:32.283965: Validation loss did not improve from -0.27854. Patience: 83/50
2024-12-14 07:50:32.284923: train_loss -0.8671
2024-12-14 07:50:32.285537: val_loss -0.1269
2024-12-14 07:50:32.286128: Pseudo dice [0.6297]
2024-12-14 07:50:32.286870: Epoch time: 547.14 s
2024-12-14 07:50:33.687562: 
2024-12-14 07:50:33.688776: Epoch 107
2024-12-14 07:50:33.689363: Current learning rate: 0.00325
2024-12-14 08:00:37.957353: Validation loss did not improve from -0.27854. Patience: 84/50
2024-12-14 08:00:37.958222: train_loss -0.8697
2024-12-14 08:00:37.959064: val_loss -0.105
2024-12-14 08:00:37.959649: Pseudo dice [0.6221]
2024-12-14 08:00:37.960328: Epoch time: 604.27 s
2024-12-14 08:00:39.366386: 
2024-12-14 08:00:39.367498: Epoch 108
2024-12-14 08:00:39.368161: Current learning rate: 0.00318
2024-12-14 08:10:02.551529: Validation loss did not improve from -0.27854. Patience: 85/50
2024-12-14 08:10:02.552165: train_loss -0.8715
2024-12-14 08:10:02.553248: val_loss -0.1469
2024-12-14 08:10:02.553983: Pseudo dice [0.6264]
2024-12-14 08:10:02.554631: Epoch time: 563.19 s
2024-12-14 08:10:03.952741: 
2024-12-14 08:10:03.953516: Epoch 109
2024-12-14 08:10:03.954150: Current learning rate: 0.00311
2024-12-14 08:19:12.469006: Validation loss did not improve from -0.27854. Patience: 86/50
2024-12-14 08:19:12.469864: train_loss -0.8727
2024-12-14 08:19:12.470536: val_loss -0.1786
2024-12-14 08:19:12.471186: Pseudo dice [0.6398]
2024-12-14 08:19:12.472637: Epoch time: 548.52 s
2024-12-14 08:19:14.244115: 
2024-12-14 08:19:14.245326: Epoch 110
2024-12-14 08:19:14.246219: Current learning rate: 0.00304
2024-12-14 08:28:32.337932: Validation loss did not improve from -0.27854. Patience: 87/50
2024-12-14 08:28:32.338958: train_loss -0.8731
2024-12-14 08:28:32.339724: val_loss -0.1263
2024-12-14 08:28:32.340286: Pseudo dice [0.6256]
2024-12-14 08:28:32.341389: Epoch time: 558.1 s
2024-12-14 08:28:33.745806: 
2024-12-14 08:28:33.746964: Epoch 111
2024-12-14 08:28:33.747735: Current learning rate: 0.00297
2024-12-14 08:37:38.132179: Validation loss did not improve from -0.27854. Patience: 88/50
2024-12-14 08:37:38.133198: train_loss -0.8724
2024-12-14 08:37:38.133976: val_loss -0.1253
2024-12-14 08:37:38.134716: Pseudo dice [0.6289]
2024-12-14 08:37:38.135382: Epoch time: 544.39 s
2024-12-14 08:37:39.601869: 
2024-12-14 08:37:39.603023: Epoch 112
2024-12-14 08:37:39.603649: Current learning rate: 0.00291
2024-12-14 08:46:38.384978: Validation loss did not improve from -0.27854. Patience: 89/50
2024-12-14 08:46:38.385627: train_loss -0.8756
2024-12-14 08:46:38.386327: val_loss -0.1316
2024-12-14 08:46:38.386981: Pseudo dice [0.6249]
2024-12-14 08:46:38.387809: Epoch time: 538.78 s
2024-12-14 08:46:39.785004: 
2024-12-14 08:46:39.786171: Epoch 113
2024-12-14 08:46:39.786831: Current learning rate: 0.00284
2024-12-14 08:55:56.523703: Validation loss did not improve from -0.27854. Patience: 90/50
2024-12-14 08:55:56.524979: train_loss -0.8757
2024-12-14 08:55:56.525682: val_loss -0.1395
2024-12-14 08:55:56.526450: Pseudo dice [0.6256]
2024-12-14 08:55:56.527351: Epoch time: 556.74 s
2024-12-14 08:55:57.934827: 
2024-12-14 08:55:57.936193: Epoch 114
2024-12-14 08:55:57.936742: Current learning rate: 0.00277
2024-12-14 09:05:19.820936: Validation loss did not improve from -0.27854. Patience: 91/50
2024-12-14 09:05:19.821857: train_loss -0.8766
2024-12-14 09:05:19.822831: val_loss -0.155
2024-12-14 09:05:19.823552: Pseudo dice [0.6336]
2024-12-14 09:05:19.824341: Epoch time: 561.89 s
2024-12-14 09:05:21.638367: 
2024-12-14 09:05:21.639534: Epoch 115
2024-12-14 09:05:21.640334: Current learning rate: 0.0027
2024-12-14 09:14:47.299643: Validation loss did not improve from -0.27854. Patience: 92/50
2024-12-14 09:14:47.300349: train_loss -0.8762
2024-12-14 09:14:47.301493: val_loss -0.1225
2024-12-14 09:14:47.302122: Pseudo dice [0.6225]
2024-12-14 09:14:47.302783: Epoch time: 565.66 s
2024-12-14 09:14:49.359415: 
2024-12-14 09:14:49.360274: Epoch 116
2024-12-14 09:14:49.360915: Current learning rate: 0.00263
2024-12-14 09:24:35.914835: Validation loss did not improve from -0.27854. Patience: 93/50
2024-12-14 09:24:35.915797: train_loss -0.8774
2024-12-14 09:24:35.916749: val_loss -0.189
2024-12-14 09:24:35.917655: Pseudo dice [0.6435]
2024-12-14 09:24:35.918481: Epoch time: 586.56 s
2024-12-14 09:24:37.365543: 
2024-12-14 09:24:37.366831: Epoch 117
2024-12-14 09:24:37.367785: Current learning rate: 0.00256
2024-12-14 09:34:22.142527: Validation loss did not improve from -0.27854. Patience: 94/50
2024-12-14 09:34:22.147803: train_loss -0.8768
2024-12-14 09:34:22.149655: val_loss -0.147
2024-12-14 09:34:22.150236: Pseudo dice [0.6291]
2024-12-14 09:34:22.151248: Epoch time: 584.78 s
2024-12-14 09:34:23.626000: 
2024-12-14 09:34:23.627184: Epoch 118
2024-12-14 09:34:23.627784: Current learning rate: 0.00249
2024-12-14 09:44:10.494342: Validation loss did not improve from -0.27854. Patience: 95/50
2024-12-14 09:44:10.495407: train_loss -0.8774
2024-12-14 09:44:10.496296: val_loss -0.1565
2024-12-14 09:44:10.496998: Pseudo dice [0.6362]
2024-12-14 09:44:10.497725: Epoch time: 586.87 s
2024-12-14 09:44:11.940192: 
2024-12-14 09:44:11.941410: Epoch 119
2024-12-14 09:44:11.942229: Current learning rate: 0.00242
2024-12-14 09:54:27.032087: Validation loss did not improve from -0.27854. Patience: 96/50
2024-12-14 09:54:27.032878: train_loss -0.8798
2024-12-14 09:54:27.033591: val_loss -0.129
2024-12-14 09:54:27.034169: Pseudo dice [0.6315]
2024-12-14 09:54:27.034763: Epoch time: 615.09 s
2024-12-14 09:54:28.878073: 
2024-12-14 09:54:28.879300: Epoch 120
2024-12-14 09:54:28.879883: Current learning rate: 0.00235
2024-12-14 10:03:49.610976: Validation loss did not improve from -0.27854. Patience: 97/50
2024-12-14 10:03:49.611908: train_loss -0.8808
2024-12-14 10:03:49.612919: val_loss -0.1447
2024-12-14 10:03:49.613750: Pseudo dice [0.6388]
2024-12-14 10:03:49.614366: Epoch time: 560.73 s
2024-12-14 10:03:51.042171: 
2024-12-14 10:03:51.043224: Epoch 121
2024-12-14 10:03:51.043876: Current learning rate: 0.00228
2024-12-14 10:13:28.778048: Validation loss did not improve from -0.27854. Patience: 98/50
2024-12-14 10:13:28.778976: train_loss -0.8796
2024-12-14 10:13:28.779704: val_loss -0.0973
2024-12-14 10:13:28.780451: Pseudo dice [0.6154]
2024-12-14 10:13:28.781281: Epoch time: 577.74 s
2024-12-14 10:13:30.209256: 
2024-12-14 10:13:30.210479: Epoch 122
2024-12-14 10:13:30.211245: Current learning rate: 0.00221
2024-12-14 10:22:41.901264: Validation loss did not improve from -0.27854. Patience: 99/50
2024-12-14 10:22:41.902176: train_loss -0.8817
2024-12-14 10:22:41.902890: val_loss -0.1252
2024-12-14 10:22:41.903525: Pseudo dice [0.6323]
2024-12-14 10:22:41.904146: Epoch time: 551.69 s
2024-12-14 10:22:43.381655: 
2024-12-14 10:22:43.382817: Epoch 123
2024-12-14 10:22:43.383574: Current learning rate: 0.00214
2024-12-14 10:31:54.614583: Validation loss did not improve from -0.27854. Patience: 100/50
2024-12-14 10:31:54.615530: train_loss -0.8843
2024-12-14 10:31:54.616209: val_loss -0.118
2024-12-14 10:31:54.616772: Pseudo dice [0.635]
2024-12-14 10:31:54.617345: Epoch time: 551.24 s
2024-12-14 10:31:56.049441: 
2024-12-14 10:31:56.050748: Epoch 124
2024-12-14 10:31:56.051323: Current learning rate: 0.00207
2024-12-14 10:42:34.604106: Validation loss did not improve from -0.27854. Patience: 101/50
2024-12-14 10:42:34.605684: train_loss -0.884
2024-12-14 10:42:34.606342: val_loss -0.1642
2024-12-14 10:42:34.606938: Pseudo dice [0.6512]
2024-12-14 10:42:34.607538: Epoch time: 638.56 s
2024-12-14 10:42:36.404997: 
2024-12-14 10:42:36.406185: Epoch 125
2024-12-14 10:42:36.406805: Current learning rate: 0.00199
2024-12-14 10:52:21.719689: Validation loss did not improve from -0.27854. Patience: 102/50
2024-12-14 10:52:21.720785: train_loss -0.8847
2024-12-14 10:52:21.721612: val_loss -0.1347
2024-12-14 10:52:21.722371: Pseudo dice [0.6356]
2024-12-14 10:52:21.723168: Epoch time: 585.32 s
2024-12-14 10:52:23.874718: 
2024-12-14 10:52:23.875822: Epoch 126
2024-12-14 10:52:23.876638: Current learning rate: 0.00192
2024-12-14 11:01:42.307287: Validation loss did not improve from -0.27854. Patience: 103/50
2024-12-14 11:01:42.307896: train_loss -0.8834
2024-12-14 11:01:42.308566: val_loss -0.1817
2024-12-14 11:01:42.309229: Pseudo dice [0.6524]
2024-12-14 11:01:42.309834: Epoch time: 558.43 s
2024-12-14 11:01:43.749334: 
2024-12-14 11:01:43.750195: Epoch 127
2024-12-14 11:01:43.750845: Current learning rate: 0.00185
2024-12-14 11:11:11.548390: Validation loss did not improve from -0.27854. Patience: 104/50
2024-12-14 11:11:11.549200: train_loss -0.8843
2024-12-14 11:11:11.550221: val_loss -0.1243
2024-12-14 11:11:11.551135: Pseudo dice [0.6237]
2024-12-14 11:11:11.551976: Epoch time: 567.8 s
2024-12-14 11:11:13.004975: 
2024-12-14 11:11:13.006168: Epoch 128
2024-12-14 11:11:13.007029: Current learning rate: 0.00178
2024-12-14 11:20:39.115291: Validation loss did not improve from -0.27854. Patience: 105/50
2024-12-14 11:20:39.116153: train_loss -0.8865
2024-12-14 11:20:39.116917: val_loss -0.1259
2024-12-14 11:20:39.117658: Pseudo dice [0.6301]
2024-12-14 11:20:39.118318: Epoch time: 566.11 s
2024-12-14 11:20:40.556030: 
2024-12-14 11:20:40.557223: Epoch 129
2024-12-14 11:20:40.557798: Current learning rate: 0.0017
2024-12-14 11:30:23.892983: Validation loss did not improve from -0.27854. Patience: 106/50
2024-12-14 11:30:23.893967: train_loss -0.8859
2024-12-14 11:30:23.894769: val_loss -0.1394
2024-12-14 11:30:23.895399: Pseudo dice [0.6313]
2024-12-14 11:30:23.896059: Epoch time: 583.34 s
2024-12-14 11:30:25.766554: 
2024-12-14 11:30:25.767617: Epoch 130
2024-12-14 11:30:25.768319: Current learning rate: 0.00163
2024-12-14 11:40:26.095844: Validation loss did not improve from -0.27854. Patience: 107/50
2024-12-14 11:40:26.100893: train_loss -0.8875
2024-12-14 11:40:26.103049: val_loss -0.0915
2024-12-14 11:40:26.104186: Pseudo dice [0.6208]
2024-12-14 11:40:26.105356: Epoch time: 600.33 s
2024-12-14 11:40:27.528313: 
2024-12-14 11:40:27.529941: Epoch 131
2024-12-14 11:40:27.530736: Current learning rate: 0.00156
2024-12-14 11:50:05.174686: Validation loss did not improve from -0.27854. Patience: 108/50
2024-12-14 11:50:05.175351: train_loss -0.8867
2024-12-14 11:50:05.176208: val_loss -0.1166
2024-12-14 11:50:05.176826: Pseudo dice [0.6276]
2024-12-14 11:50:05.177432: Epoch time: 577.65 s
2024-12-14 11:50:06.604066: 
2024-12-14 11:50:06.604939: Epoch 132
2024-12-14 11:50:06.605799: Current learning rate: 0.00148
2024-12-14 12:00:38.621135: Validation loss did not improve from -0.27854. Patience: 109/50
2024-12-14 12:00:38.622195: train_loss -0.8868
2024-12-14 12:00:38.623437: val_loss -0.1007
2024-12-14 12:00:38.624402: Pseudo dice [0.6293]
2024-12-14 12:00:38.625534: Epoch time: 632.02 s
2024-12-14 12:00:40.049495: 
2024-12-14 12:00:40.050842: Epoch 133
2024-12-14 12:00:40.051687: Current learning rate: 0.00141
2024-12-14 12:10:07.552039: Validation loss did not improve from -0.27854. Patience: 110/50
2024-12-14 12:10:07.552713: train_loss -0.8891
2024-12-14 12:10:07.553523: val_loss -0.0848
2024-12-14 12:10:07.554350: Pseudo dice [0.6294]
2024-12-14 12:10:07.554956: Epoch time: 567.5 s
2024-12-14 12:10:08.969959: 
2024-12-14 12:10:08.970783: Epoch 134
2024-12-14 12:10:08.971413: Current learning rate: 0.00133
2024-12-14 12:19:47.757345: Validation loss did not improve from -0.27854. Patience: 111/50
2024-12-14 12:19:47.758223: train_loss -0.8881
2024-12-14 12:19:47.758888: val_loss -0.0904
2024-12-14 12:19:47.759513: Pseudo dice [0.621]
2024-12-14 12:19:47.760139: Epoch time: 578.79 s
2024-12-14 12:19:49.566666: 
2024-12-14 12:19:49.567943: Epoch 135
2024-12-14 12:19:49.568558: Current learning rate: 0.00126
2024-12-14 12:29:18.327922: Validation loss did not improve from -0.27854. Patience: 112/50
2024-12-14 12:29:18.328928: train_loss -0.889
2024-12-14 12:29:18.330068: val_loss -0.0863
2024-12-14 12:29:18.330829: Pseudo dice [0.6146]
2024-12-14 12:29:18.331807: Epoch time: 568.76 s
2024-12-14 12:29:19.737834: 
2024-12-14 12:29:19.738983: Epoch 136
2024-12-14 12:29:19.739671: Current learning rate: 0.00118
2024-12-14 12:38:54.224999: Validation loss did not improve from -0.27854. Patience: 113/50
2024-12-14 12:38:54.225907: train_loss -0.8884
2024-12-14 12:38:54.226880: val_loss -0.1403
2024-12-14 12:38:54.227958: Pseudo dice [0.6222]
2024-12-14 12:38:54.229149: Epoch time: 574.49 s
2024-12-14 12:38:55.657891: 
2024-12-14 12:38:55.659035: Epoch 137
2024-12-14 12:38:55.659698: Current learning rate: 0.00111
2024-12-14 12:48:38.423010: Validation loss did not improve from -0.27854. Patience: 114/50
2024-12-14 12:48:38.425061: train_loss -0.8878
2024-12-14 12:48:38.425968: val_loss -0.1096
2024-12-14 12:48:38.426686: Pseudo dice [0.6328]
2024-12-14 12:48:38.427446: Epoch time: 582.77 s
2024-12-14 12:48:39.896119: 
2024-12-14 12:48:39.897204: Epoch 138
2024-12-14 12:48:39.898002: Current learning rate: 0.00103
2024-12-14 12:55:29.812562: Validation loss did not improve from -0.27854. Patience: 115/50
2024-12-14 12:55:29.813365: train_loss -0.891
2024-12-14 12:55:29.814331: val_loss -0.1066
2024-12-14 12:55:29.815265: Pseudo dice [0.641]
2024-12-14 12:55:29.816197: Epoch time: 409.92 s
2024-12-14 12:55:31.274273: 
2024-12-14 12:55:31.275952: Epoch 139
2024-12-14 12:55:31.276913: Current learning rate: 0.00095
2024-12-14 13:02:58.710269: Validation loss did not improve from -0.27854. Patience: 116/50
2024-12-14 13:02:58.711274: train_loss -0.8916
2024-12-14 13:02:58.712027: val_loss -0.1255
2024-12-14 13:02:58.712703: Pseudo dice [0.6381]
2024-12-14 13:02:58.713380: Epoch time: 447.44 s
2024-12-14 13:03:00.575197: 
2024-12-14 13:03:00.576252: Epoch 140
2024-12-14 13:03:00.577214: Current learning rate: 0.00087
2024-12-14 13:10:26.557625: Validation loss did not improve from -0.27854. Patience: 117/50
2024-12-14 13:10:26.558799: train_loss -0.8928
2024-12-14 13:10:26.559539: val_loss -0.1174
2024-12-14 13:10:26.560155: Pseudo dice [0.6307]
2024-12-14 13:10:26.560784: Epoch time: 445.98 s
2024-12-14 13:10:28.003028: 
2024-12-14 13:10:28.004415: Epoch 141
2024-12-14 13:10:28.005263: Current learning rate: 0.00079
2024-12-14 13:18:14.096009: Validation loss did not improve from -0.27854. Patience: 118/50
2024-12-14 13:18:14.096741: train_loss -0.8931
2024-12-14 13:18:14.097545: val_loss -0.1507
2024-12-14 13:18:14.098309: Pseudo dice [0.646]
2024-12-14 13:18:14.099200: Epoch time: 466.09 s
2024-12-14 13:18:15.558645: 
2024-12-14 13:18:15.559510: Epoch 142
2024-12-14 13:18:15.560249: Current learning rate: 0.00071
2024-12-14 13:25:26.706927: Validation loss did not improve from -0.27854. Patience: 119/50
2024-12-14 13:25:26.707498: train_loss -0.8921
2024-12-14 13:25:26.708162: val_loss -0.1025
2024-12-14 13:25:26.708797: Pseudo dice [0.6324]
2024-12-14 13:25:26.709467: Epoch time: 431.15 s
2024-12-14 13:25:28.122356: 
2024-12-14 13:25:28.123123: Epoch 143
2024-12-14 13:25:28.123834: Current learning rate: 0.00063
2024-12-14 13:32:58.791966: Validation loss did not improve from -0.27854. Patience: 120/50
2024-12-14 13:32:58.792809: train_loss -0.8918
2024-12-14 13:32:58.793524: val_loss -0.0832
2024-12-14 13:32:58.794216: Pseudo dice [0.6217]
2024-12-14 13:32:58.794939: Epoch time: 450.67 s
2024-12-14 13:33:00.230182: 
2024-12-14 13:33:00.231461: Epoch 144
2024-12-14 13:33:00.232263: Current learning rate: 0.00055
2024-12-14 13:39:59.705163: Validation loss did not improve from -0.27854. Patience: 121/50
2024-12-14 13:39:59.706197: train_loss -0.8926
2024-12-14 13:39:59.707047: val_loss -0.0894
2024-12-14 13:39:59.708195: Pseudo dice [0.6221]
2024-12-14 13:39:59.709197: Epoch time: 419.48 s
2024-12-14 13:40:01.558490: 
2024-12-14 13:40:01.559761: Epoch 145
2024-12-14 13:40:01.560419: Current learning rate: 0.00047
2024-12-14 13:47:13.740423: Validation loss did not improve from -0.27854. Patience: 122/50
2024-12-14 13:47:13.741374: train_loss -0.8952
2024-12-14 13:47:13.742113: val_loss -0.1301
2024-12-14 13:47:13.742748: Pseudo dice [0.6321]
2024-12-14 13:47:13.743384: Epoch time: 432.18 s
2024-12-14 13:47:15.166909: 
2024-12-14 13:47:15.168255: Epoch 146
2024-12-14 13:47:15.169057: Current learning rate: 0.00038
2024-12-14 13:54:49.468578: Validation loss did not improve from -0.27854. Patience: 123/50
2024-12-14 13:54:49.472476: train_loss -0.8925
2024-12-14 13:54:49.474772: val_loss -0.0518
2024-12-14 13:54:49.475624: Pseudo dice [0.6147]
2024-12-14 13:54:49.477286: Epoch time: 454.31 s
2024-12-14 13:54:50.932675: 
2024-12-14 13:54:50.934064: Epoch 147
2024-12-14 13:54:50.934861: Current learning rate: 0.0003
2024-12-14 14:02:31.810714: Validation loss did not improve from -0.27854. Patience: 124/50
2024-12-14 14:02:31.811657: train_loss -0.8929
2024-12-14 14:02:31.812471: val_loss -0.1314
2024-12-14 14:02:31.813274: Pseudo dice [0.6457]
2024-12-14 14:02:31.814112: Epoch time: 460.88 s
2024-12-14 14:02:33.831849: 
2024-12-14 14:02:33.833051: Epoch 148
2024-12-14 14:02:33.833815: Current learning rate: 0.00021
2024-12-14 14:10:18.109338: Validation loss did not improve from -0.27854. Patience: 125/50
2024-12-14 14:10:18.110052: train_loss -0.8935
2024-12-14 14:10:18.110758: val_loss -0.0876
2024-12-14 14:10:18.111459: Pseudo dice [0.6193]
2024-12-14 14:10:18.112128: Epoch time: 464.28 s
2024-12-14 14:10:19.523278: 
2024-12-14 14:10:19.524142: Epoch 149
2024-12-14 14:10:19.524752: Current learning rate: 0.00011
2024-12-14 14:17:43.871739: Validation loss did not improve from -0.27854. Patience: 126/50
2024-12-14 14:17:43.872890: train_loss -0.8937
2024-12-14 14:17:43.873579: val_loss -0.1364
2024-12-14 14:17:43.874201: Pseudo dice [0.6445]
2024-12-14 14:17:43.874792: Epoch time: 444.35 s
2024-12-14 14:17:45.759689: Training done.
2024-12-14 14:17:45.923166: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset307_Sohee_Calcium_OCT_CrossValidation/splits_final_20.json
2024-12-14 14:17:45.950807: The split file contains 5 splits.
2024-12-14 14:17:45.951831: Desired fold for training: 1
2024-12-14 14:17:45.952442: This split has 1 training and 7 validation cases.
2024-12-14 14:17:45.953722: predicting 101-019
2024-12-14 14:17:45.970453: 101-019, shape torch.Size([1, 375, 498, 498]), rank 0
2024-12-14 14:20:14.451765: predicting 101-045
2024-12-14 14:20:14.476239: 101-045, shape torch.Size([1, 375, 498, 498]), rank 0
2024-12-14 14:22:06.951270: predicting 106-002
2024-12-14 14:22:06.965636: 106-002, shape torch.Size([1, 539, 498, 498]), rank 0
2024-12-14 14:25:01.906390: predicting 401-004
2024-12-14 14:25:01.930547: 401-004, shape torch.Size([1, 375, 498, 498]), rank 0
2024-12-14 14:28:23.068597: predicting 701-013
2024-12-14 14:28:23.079795: 701-013, shape torch.Size([1, 375, 498, 498]), rank 0
2024-12-14 14:30:42.259827: predicting 704-003
2024-12-14 14:30:42.271718: 704-003, shape torch.Size([1, 375, 498, 498]), rank 0
2024-12-14 14:32:36.220117: predicting 706-005
2024-12-14 14:32:36.233137: 706-005, shape torch.Size([1, 375, 498, 498]), rank 0
2024-12-14 14:34:57.469107: Validation complete
2024-12-14 14:34:57.469568: Mean Validation Dice:  0.594779889842153
2024-12-13 18:17:51.795772: unpacking done...
2024-12-13 18:17:51.804590: Unable to plot network architecture: nnUNet_compile is enabled!
2024-12-13 18:17:52.088967: 
2024-12-13 18:17:52.090153: Epoch 0
2024-12-13 18:17:52.091344: Current learning rate: 0.01
2024-12-13 18:22:10.238127: Validation loss improved from 1000.00000 to -0.00083! Patience: 0/50
2024-12-13 18:22:10.239225: train_loss -0.1136
2024-12-13 18:22:10.240013: val_loss -0.0008
2024-12-13 18:22:10.240722: Pseudo dice [0.3725]
2024-12-13 18:22:10.241537: Epoch time: 258.15 s
2024-12-13 18:22:10.242214: Yayy! New best EMA pseudo Dice: 0.3725
2024-12-13 18:22:11.866555: 
2024-12-13 18:22:11.867381: Epoch 1
2024-12-13 18:22:11.868136: Current learning rate: 0.00994
2024-12-13 18:29:11.507742: Validation loss improved from -0.00083 to -0.19625! Patience: 0/50
2024-12-13 18:29:11.508661: train_loss -0.3508
2024-12-13 18:29:11.509710: val_loss -0.1963
2024-12-13 18:29:11.510656: Pseudo dice [0.576]
2024-12-13 18:29:11.511656: Epoch time: 419.64 s
2024-12-13 18:29:11.512691: Yayy! New best EMA pseudo Dice: 0.3929
2024-12-13 18:29:13.440571: 
2024-12-13 18:29:13.441774: Epoch 2
2024-12-13 18:29:13.442719: Current learning rate: 0.00988
2024-12-13 18:36:59.393499: Validation loss improved from -0.19625 to -0.22047! Patience: 0/50
2024-12-13 18:36:59.394184: train_loss -0.4756
2024-12-13 18:36:59.394987: val_loss -0.2205
2024-12-13 18:36:59.395662: Pseudo dice [0.577]
2024-12-13 18:36:59.396368: Epoch time: 465.95 s
2024-12-13 18:36:59.397022: Yayy! New best EMA pseudo Dice: 0.4113
2024-12-13 18:37:01.392056: 
2024-12-13 18:37:01.392896: Epoch 3
2024-12-13 18:37:01.393759: Current learning rate: 0.00982
2024-12-13 18:45:28.338551: Validation loss did not improve from -0.22047. Patience: 1/50
2024-12-13 18:45:28.339408: train_loss -0.5158
2024-12-13 18:45:28.340154: val_loss -0.1275
2024-12-13 18:45:28.340817: Pseudo dice [0.5073]
2024-12-13 18:45:28.341469: Epoch time: 506.95 s
2024-12-13 18:45:28.342067: Yayy! New best EMA pseudo Dice: 0.4209
2024-12-13 18:45:30.268312: 
2024-12-13 18:45:30.269193: Epoch 4
2024-12-13 18:45:30.270018: Current learning rate: 0.00976
2024-12-13 18:55:13.905634: Validation loss did not improve from -0.22047. Patience: 2/50
2024-12-13 18:55:13.906633: train_loss -0.5999
2024-12-13 18:55:13.907647: val_loss -0.1816
2024-12-13 18:55:13.908396: Pseudo dice [0.5672]
2024-12-13 18:55:13.909177: Epoch time: 583.64 s
2024-12-13 18:55:14.245062: Yayy! New best EMA pseudo Dice: 0.4355
2024-12-13 18:55:16.086492: 
2024-12-13 18:55:16.087747: Epoch 5
2024-12-13 18:55:16.088504: Current learning rate: 0.0097
2024-12-13 19:05:28.139543: Validation loss did not improve from -0.22047. Patience: 3/50
2024-12-13 19:05:28.140374: train_loss -0.6336
2024-12-13 19:05:28.141158: val_loss -0.1767
2024-12-13 19:05:28.141734: Pseudo dice [0.5443]
2024-12-13 19:05:28.142353: Epoch time: 612.05 s
2024-12-13 19:05:28.142900: Yayy! New best EMA pseudo Dice: 0.4464
2024-12-13 19:05:30.034993: 
2024-12-13 19:05:30.035943: Epoch 6
2024-12-13 19:05:30.036815: Current learning rate: 0.00964
2024-12-13 19:15:23.236969: Validation loss did not improve from -0.22047. Patience: 4/50
2024-12-13 19:15:23.238034: train_loss -0.6512
2024-12-13 19:15:23.238863: val_loss -0.1582
2024-12-13 19:15:23.239578: Pseudo dice [0.5419]
2024-12-13 19:15:23.240342: Epoch time: 593.2 s
2024-12-13 19:15:23.241045: Yayy! New best EMA pseudo Dice: 0.456
2024-12-13 19:15:25.166473: 
2024-12-13 19:15:25.167845: Epoch 7
2024-12-13 19:15:25.168845: Current learning rate: 0.00958
2024-12-13 19:25:42.588390: Validation loss improved from -0.22047 to -0.23061! Patience: 4/50
2024-12-13 19:25:42.589688: train_loss -0.6805
2024-12-13 19:25:42.590533: val_loss -0.2306
2024-12-13 19:25:42.591231: Pseudo dice [0.5737]
2024-12-13 19:25:42.591947: Epoch time: 617.42 s
2024-12-13 19:25:42.592664: Yayy! New best EMA pseudo Dice: 0.4677
2024-12-13 19:25:44.816762: 
2024-12-13 19:25:44.818054: Epoch 8
2024-12-13 19:25:44.818816: Current learning rate: 0.00952
2024-12-13 19:36:00.679615: Validation loss did not improve from -0.23061. Patience: 1/50
2024-12-13 19:36:00.680310: train_loss -0.6967
2024-12-13 19:36:00.681261: val_loss -0.0248
2024-12-13 19:36:00.682192: Pseudo dice [0.4802]
2024-12-13 19:36:00.683198: Epoch time: 615.86 s
2024-12-13 19:36:00.684147: Yayy! New best EMA pseudo Dice: 0.469
2024-12-13 19:36:02.652650: 
2024-12-13 19:36:02.653598: Epoch 9
2024-12-13 19:36:02.654445: Current learning rate: 0.00946
2024-12-13 19:46:07.422636: Validation loss did not improve from -0.23061. Patience: 2/50
2024-12-13 19:46:07.423459: train_loss -0.7144
2024-12-13 19:46:07.424200: val_loss -0.1418
2024-12-13 19:46:07.425046: Pseudo dice [0.5595]
2024-12-13 19:46:07.425759: Epoch time: 604.77 s
2024-12-13 19:46:07.805846: Yayy! New best EMA pseudo Dice: 0.478
2024-12-13 19:46:09.727593: 
2024-12-13 19:46:09.728948: Epoch 10
2024-12-13 19:46:09.729880: Current learning rate: 0.0094
2024-12-13 19:57:16.455627: Validation loss did not improve from -0.23061. Patience: 3/50
2024-12-13 19:57:16.456633: train_loss -0.7284
2024-12-13 19:57:16.457542: val_loss -0.0733
2024-12-13 19:57:16.458274: Pseudo dice [0.534]
2024-12-13 19:57:16.458909: Epoch time: 666.73 s
2024-12-13 19:57:16.459694: Yayy! New best EMA pseudo Dice: 0.4836
2024-12-13 19:57:18.369536: 
2024-12-13 19:57:18.370584: Epoch 11
2024-12-13 19:57:18.371317: Current learning rate: 0.00934
2024-12-13 20:07:41.676557: Validation loss did not improve from -0.23061. Patience: 4/50
2024-12-13 20:07:41.677563: train_loss -0.7429
2024-12-13 20:07:41.678281: val_loss -0.1025
2024-12-13 20:07:41.678918: Pseudo dice [0.5359]
2024-12-13 20:07:41.679586: Epoch time: 623.31 s
2024-12-13 20:07:41.680196: Yayy! New best EMA pseudo Dice: 0.4889
2024-12-13 20:07:43.530721: 
2024-12-13 20:07:43.532086: Epoch 12
2024-12-13 20:07:43.532843: Current learning rate: 0.00928
2024-12-13 20:17:48.385501: Validation loss did not improve from -0.23061. Patience: 5/50
2024-12-13 20:17:48.386222: train_loss -0.7426
2024-12-13 20:17:48.386939: val_loss -0.1822
2024-12-13 20:17:48.387568: Pseudo dice [0.5748]
2024-12-13 20:17:48.388175: Epoch time: 604.86 s
2024-12-13 20:17:48.388783: Yayy! New best EMA pseudo Dice: 0.4975
2024-12-13 20:17:50.375519: 
2024-12-13 20:17:50.376644: Epoch 13
2024-12-13 20:17:50.377414: Current learning rate: 0.00922
2024-12-13 20:28:28.191080: Validation loss did not improve from -0.23061. Patience: 6/50
2024-12-13 20:28:28.211855: train_loss -0.7507
2024-12-13 20:28:28.213655: val_loss -0.2268
2024-12-13 20:28:28.214583: Pseudo dice [0.605]
2024-12-13 20:28:28.215792: Epoch time: 637.82 s
2024-12-13 20:28:28.216885: Yayy! New best EMA pseudo Dice: 0.5082
2024-12-13 20:28:30.365691: 
2024-12-13 20:28:30.367149: Epoch 14
2024-12-13 20:28:30.368227: Current learning rate: 0.00916
2024-12-13 20:39:02.308830: Validation loss did not improve from -0.23061. Patience: 7/50
2024-12-13 20:39:02.309668: train_loss -0.7578
2024-12-13 20:39:02.310539: val_loss -0.1275
2024-12-13 20:39:02.311377: Pseudo dice [0.5733]
2024-12-13 20:39:02.312270: Epoch time: 631.95 s
2024-12-13 20:39:02.737335: Yayy! New best EMA pseudo Dice: 0.5147
2024-12-13 20:39:04.640425: 
2024-12-13 20:39:04.641682: Epoch 15
2024-12-13 20:39:04.642616: Current learning rate: 0.0091
2024-12-13 20:50:14.996742: Validation loss did not improve from -0.23061. Patience: 8/50
2024-12-13 20:50:14.997657: train_loss -0.766
2024-12-13 20:50:14.998552: val_loss -0.1169
2024-12-13 20:50:14.999428: Pseudo dice [0.5444]
2024-12-13 20:50:15.000213: Epoch time: 670.36 s
2024-12-13 20:50:15.001059: Yayy! New best EMA pseudo Dice: 0.5177
2024-12-13 20:50:16.903762: 
2024-12-13 20:50:16.905199: Epoch 16
2024-12-13 20:50:16.905970: Current learning rate: 0.00903
2024-12-13 21:02:01.284984: Validation loss did not improve from -0.23061. Patience: 9/50
2024-12-13 21:02:01.285766: train_loss -0.7735
2024-12-13 21:02:01.286622: val_loss -0.1453
2024-12-13 21:02:01.287311: Pseudo dice [0.5803]
2024-12-13 21:02:01.288021: Epoch time: 704.38 s
2024-12-13 21:02:01.288710: Yayy! New best EMA pseudo Dice: 0.5239
2024-12-13 21:02:03.149051: 
2024-12-13 21:02:03.150671: Epoch 17
2024-12-13 21:02:03.151646: Current learning rate: 0.00897
2024-12-13 21:13:59.051297: Validation loss did not improve from -0.23061. Patience: 10/50
2024-12-13 21:13:59.052779: train_loss -0.7805
2024-12-13 21:13:59.054291: val_loss -0.0784
2024-12-13 21:13:59.055279: Pseudo dice [0.5565]
2024-12-13 21:13:59.056174: Epoch time: 715.9 s
2024-12-13 21:13:59.057111: Yayy! New best EMA pseudo Dice: 0.5272
2024-12-13 21:14:00.947402: 
2024-12-13 21:14:00.948352: Epoch 18
2024-12-13 21:14:00.949220: Current learning rate: 0.00891
2024-12-13 21:25:33.411175: Validation loss did not improve from -0.23061. Patience: 11/50
2024-12-13 21:25:33.412104: train_loss -0.7853
2024-12-13 21:25:33.412907: val_loss -0.1266
2024-12-13 21:25:33.413710: Pseudo dice [0.55]
2024-12-13 21:25:33.414459: Epoch time: 692.47 s
2024-12-13 21:25:33.415124: Yayy! New best EMA pseudo Dice: 0.5295
2024-12-13 21:25:35.801429: 
2024-12-13 21:25:35.802708: Epoch 19
2024-12-13 21:25:35.803352: Current learning rate: 0.00885
2024-12-13 21:37:17.498418: Validation loss did not improve from -0.23061. Patience: 12/50
2024-12-13 21:37:17.499921: train_loss -0.7923
2024-12-13 21:37:17.500601: val_loss -0.1121
2024-12-13 21:37:17.501152: Pseudo dice [0.5663]
2024-12-13 21:37:17.501777: Epoch time: 701.7 s
2024-12-13 21:37:17.863538: Yayy! New best EMA pseudo Dice: 0.5332
2024-12-13 21:37:19.615698: 
2024-12-13 21:37:19.616445: Epoch 20
2024-12-13 21:37:19.617067: Current learning rate: 0.00879
2024-12-13 21:49:00.521179: Validation loss did not improve from -0.23061. Patience: 13/50
2024-12-13 21:49:00.522154: train_loss -0.7932
2024-12-13 21:49:00.522905: val_loss -0.0668
2024-12-13 21:49:00.523557: Pseudo dice [0.5263]
2024-12-13 21:49:00.524226: Epoch time: 700.91 s
2024-12-13 21:49:01.979696: 
2024-12-13 21:49:01.981061: Epoch 21
2024-12-13 21:49:01.982159: Current learning rate: 0.00873
2024-12-13 22:00:35.976423: Validation loss did not improve from -0.23061. Patience: 14/50
2024-12-13 22:00:35.977348: train_loss -0.7985
2024-12-13 22:00:35.978340: val_loss -0.0465
2024-12-13 22:00:35.979159: Pseudo dice [0.5286]
2024-12-13 22:00:35.979922: Epoch time: 694.0 s
2024-12-13 22:00:37.322387: 
2024-12-13 22:00:37.323683: Epoch 22
2024-12-13 22:00:37.324571: Current learning rate: 0.00867
2024-12-13 22:12:34.780583: Validation loss did not improve from -0.23061. Patience: 15/50
2024-12-13 22:12:34.781400: train_loss -0.7998
2024-12-13 22:12:34.782144: val_loss -0.0643
2024-12-13 22:12:34.782842: Pseudo dice [0.5632]
2024-12-13 22:12:34.783547: Epoch time: 717.46 s
2024-12-13 22:12:34.784191: Yayy! New best EMA pseudo Dice: 0.5352
2024-12-13 22:12:36.584659: 
2024-12-13 22:12:36.585601: Epoch 23
2024-12-13 22:12:36.586203: Current learning rate: 0.00861
2024-12-13 22:23:47.085581: Validation loss did not improve from -0.23061. Patience: 16/50
2024-12-13 22:23:47.086402: train_loss -0.8027
2024-12-13 22:23:47.087306: val_loss -0.0052
2024-12-13 22:23:47.088126: Pseudo dice [0.4931]
2024-12-13 22:23:47.088762: Epoch time: 670.5 s
2024-12-13 22:23:48.475698: 
2024-12-13 22:23:48.476903: Epoch 24
2024-12-13 22:23:48.477912: Current learning rate: 0.00855
2024-12-13 22:35:28.417688: Validation loss did not improve from -0.23061. Patience: 17/50
2024-12-13 22:35:28.418523: train_loss -0.8077
2024-12-13 22:35:28.419224: val_loss -0.032
2024-12-13 22:35:28.419983: Pseudo dice [0.518]
2024-12-13 22:35:28.420712: Epoch time: 699.94 s
2024-12-13 22:35:30.254170: 
2024-12-13 22:35:30.255007: Epoch 25
2024-12-13 22:35:30.255784: Current learning rate: 0.00849
2024-12-13 22:47:25.449444: Validation loss did not improve from -0.23061. Patience: 18/50
2024-12-13 22:47:25.450970: train_loss -0.805
2024-12-13 22:47:25.451709: val_loss -0.0661
2024-12-13 22:47:25.452432: Pseudo dice [0.5415]
2024-12-13 22:47:25.453074: Epoch time: 715.2 s
2024-12-13 22:47:26.860476: 
2024-12-13 22:47:26.861490: Epoch 26
2024-12-13 22:47:26.862221: Current learning rate: 0.00843
2024-12-13 22:58:23.040822: Validation loss did not improve from -0.23061. Patience: 19/50
2024-12-13 22:58:23.041587: train_loss -0.8131
2024-12-13 22:58:23.042333: val_loss -0.1511
2024-12-13 22:58:23.042888: Pseudo dice [0.5783]
2024-12-13 22:58:23.043508: Epoch time: 656.18 s
2024-12-13 22:58:23.044200: Yayy! New best EMA pseudo Dice: 0.5356
2024-12-13 22:58:24.752671: 
2024-12-13 22:58:24.753441: Epoch 27
2024-12-13 22:58:24.754115: Current learning rate: 0.00836
2024-12-13 23:10:02.841281: Validation loss did not improve from -0.23061. Patience: 20/50
2024-12-13 23:10:02.842206: train_loss -0.8162
2024-12-13 23:10:02.842934: val_loss -0.1676
2024-12-13 23:10:02.843554: Pseudo dice [0.5989]
2024-12-13 23:10:02.844113: Epoch time: 698.09 s
2024-12-13 23:10:02.844754: Yayy! New best EMA pseudo Dice: 0.542
2024-12-13 23:10:04.634970: 
2024-12-13 23:10:04.635995: Epoch 28
2024-12-13 23:10:04.636690: Current learning rate: 0.0083
2024-12-13 23:21:42.004270: Validation loss did not improve from -0.23061. Patience: 21/50
2024-12-13 23:21:42.005081: train_loss -0.8166
2024-12-13 23:21:42.006227: val_loss -0.1413
2024-12-13 23:21:42.006957: Pseudo dice [0.5704]
2024-12-13 23:21:42.007777: Epoch time: 697.37 s
2024-12-13 23:21:42.008582: Yayy! New best EMA pseudo Dice: 0.5448
2024-12-13 23:21:44.163628: 
2024-12-13 23:21:44.164883: Epoch 29
2024-12-13 23:21:44.165807: Current learning rate: 0.00824
2024-12-13 23:33:29.522568: Validation loss did not improve from -0.23061. Patience: 22/50
2024-12-13 23:33:29.523284: train_loss -0.8189
2024-12-13 23:33:29.523994: val_loss -0.047
2024-12-13 23:33:29.524684: Pseudo dice [0.558]
2024-12-13 23:33:29.525374: Epoch time: 705.36 s
2024-12-13 23:33:29.858839: Yayy! New best EMA pseudo Dice: 0.5461
2024-12-13 23:33:31.628053: 
2024-12-13 23:33:31.628963: Epoch 30
2024-12-13 23:33:31.629704: Current learning rate: 0.00818
2024-12-13 23:45:41.321003: Validation loss did not improve from -0.23061. Patience: 23/50
2024-12-13 23:45:41.339932: train_loss -0.824
2024-12-13 23:45:41.342202: val_loss -0.0448
2024-12-13 23:45:41.342897: Pseudo dice [0.528]
2024-12-13 23:45:41.344045: Epoch time: 729.7 s
2024-12-13 23:45:42.862923: 
2024-12-13 23:45:42.863985: Epoch 31
2024-12-13 23:45:42.864703: Current learning rate: 0.00812
2024-12-13 23:57:32.758495: Validation loss did not improve from -0.23061. Patience: 24/50
2024-12-13 23:57:32.759593: train_loss -0.8252
2024-12-13 23:57:32.760625: val_loss -0.1183
2024-12-13 23:57:32.761406: Pseudo dice [0.5813]
2024-12-13 23:57:32.762068: Epoch time: 709.9 s
2024-12-13 23:57:32.762811: Yayy! New best EMA pseudo Dice: 0.548
2024-12-13 23:57:34.456875: 
2024-12-13 23:57:34.457718: Epoch 32
2024-12-13 23:57:34.458454: Current learning rate: 0.00806
2024-12-14 00:09:45.485354: Validation loss did not improve from -0.23061. Patience: 25/50
2024-12-14 00:09:45.486246: train_loss -0.8272
2024-12-14 00:09:45.487022: val_loss -0.1625
2024-12-14 00:09:45.487669: Pseudo dice [0.594]
2024-12-14 00:09:45.488342: Epoch time: 731.03 s
2024-12-14 00:09:45.488994: Yayy! New best EMA pseudo Dice: 0.5526
2024-12-14 00:09:47.316803: 
2024-12-14 00:09:47.317916: Epoch 33
2024-12-14 00:09:47.318622: Current learning rate: 0.008
2024-12-14 00:21:29.763770: Validation loss did not improve from -0.23061. Patience: 26/50
2024-12-14 00:21:29.764660: train_loss -0.8284
2024-12-14 00:21:29.765492: val_loss -0.0262
2024-12-14 00:21:29.766095: Pseudo dice [0.5339]
2024-12-14 00:21:29.766700: Epoch time: 702.45 s
2024-12-14 00:21:31.203343: 
2024-12-14 00:21:31.204361: Epoch 34
2024-12-14 00:21:31.205095: Current learning rate: 0.00793
2024-12-14 00:33:16.411381: Validation loss did not improve from -0.23061. Patience: 27/50
2024-12-14 00:33:16.412023: train_loss -0.8296
2024-12-14 00:33:16.412748: val_loss -0.1252
2024-12-14 00:33:16.413535: Pseudo dice [0.575]
2024-12-14 00:33:16.414246: Epoch time: 705.21 s
2024-12-14 00:33:16.831645: Yayy! New best EMA pseudo Dice: 0.5532
2024-12-14 00:33:18.632553: 
2024-12-14 00:33:18.633433: Epoch 35
2024-12-14 00:33:18.634132: Current learning rate: 0.00787
2024-12-14 00:44:30.406239: Validation loss did not improve from -0.23061. Patience: 28/50
2024-12-14 00:44:30.407205: train_loss -0.8291
2024-12-14 00:44:30.407843: val_loss -0.1057
2024-12-14 00:44:30.408570: Pseudo dice [0.5693]
2024-12-14 00:44:30.409173: Epoch time: 671.78 s
2024-12-14 00:44:30.409861: Yayy! New best EMA pseudo Dice: 0.5548
2024-12-14 00:44:32.276197: 
2024-12-14 00:44:32.277388: Epoch 36
2024-12-14 00:44:32.278125: Current learning rate: 0.00781
2024-12-14 00:55:54.416155: Validation loss did not improve from -0.23061. Patience: 29/50
2024-12-14 00:55:54.417742: train_loss -0.832
2024-12-14 00:55:54.418501: val_loss 0.0439
2024-12-14 00:55:54.419266: Pseudo dice [0.5179]
2024-12-14 00:55:54.420089: Epoch time: 682.14 s
2024-12-14 00:55:55.891260: 
2024-12-14 00:55:55.892364: Epoch 37
2024-12-14 00:55:55.893293: Current learning rate: 0.00775
2024-12-14 01:07:44.437038: Validation loss did not improve from -0.23061. Patience: 30/50
2024-12-14 01:07:44.437973: train_loss -0.8359
2024-12-14 01:07:44.438854: val_loss -0.0397
2024-12-14 01:07:44.439539: Pseudo dice [0.5426]
2024-12-14 01:07:44.440199: Epoch time: 708.55 s
2024-12-14 01:07:45.841148: 
2024-12-14 01:07:45.842163: Epoch 38
2024-12-14 01:07:45.843170: Current learning rate: 0.00769
2024-12-14 01:19:33.688858: Validation loss did not improve from -0.23061. Patience: 31/50
2024-12-14 01:19:33.689582: train_loss -0.8347
2024-12-14 01:19:33.690280: val_loss -0.0141
2024-12-14 01:19:33.690929: Pseudo dice [0.5328]
2024-12-14 01:19:33.691659: Epoch time: 707.85 s
2024-12-14 01:19:35.193953: 
2024-12-14 01:19:35.194899: Epoch 39
2024-12-14 01:19:35.195903: Current learning rate: 0.00763
2024-12-14 01:30:43.069849: Validation loss did not improve from -0.23061. Patience: 32/50
2024-12-14 01:30:43.070813: train_loss -0.8391
2024-12-14 01:30:43.071772: val_loss -0.0719
2024-12-14 01:30:43.072838: Pseudo dice [0.5577]
2024-12-14 01:30:43.073718: Epoch time: 667.88 s
2024-12-14 01:30:45.257215: 
2024-12-14 01:30:45.258316: Epoch 40
2024-12-14 01:30:45.258997: Current learning rate: 0.00756
2024-12-14 01:42:24.085447: Validation loss did not improve from -0.23061. Patience: 33/50
2024-12-14 01:42:24.086407: train_loss -0.8411
2024-12-14 01:42:24.087270: val_loss -0.0092
2024-12-14 01:42:24.087811: Pseudo dice [0.5373]
2024-12-14 01:42:24.088562: Epoch time: 698.83 s
2024-12-14 01:42:25.502175: 
2024-12-14 01:42:25.503317: Epoch 41
2024-12-14 01:42:25.504007: Current learning rate: 0.0075
2024-12-14 01:52:59.608273: Validation loss did not improve from -0.23061. Patience: 34/50
2024-12-14 01:52:59.610039: train_loss -0.8423
2024-12-14 01:52:59.611643: val_loss -0.0305
2024-12-14 01:52:59.612494: Pseudo dice [0.532]
2024-12-14 01:52:59.613375: Epoch time: 634.11 s
2024-12-14 01:53:00.944783: 
2024-12-14 01:53:00.945917: Epoch 42
2024-12-14 01:53:00.946635: Current learning rate: 0.00744
2024-12-14 02:04:37.082191: Validation loss did not improve from -0.23061. Patience: 35/50
2024-12-14 02:04:37.085391: train_loss -0.8421
2024-12-14 02:04:37.086673: val_loss -0.0115
2024-12-14 02:04:37.087350: Pseudo dice [0.5533]
2024-12-14 02:04:37.087992: Epoch time: 696.14 s
2024-12-14 02:04:38.432707: 
2024-12-14 02:04:38.433947: Epoch 43
2024-12-14 02:04:38.434642: Current learning rate: 0.00738
2024-12-14 02:16:03.421233: Validation loss did not improve from -0.23061. Patience: 36/50
2024-12-14 02:16:03.421949: train_loss -0.8462
2024-12-14 02:16:03.422620: val_loss -0.0188
2024-12-14 02:16:03.423308: Pseudo dice [0.5495]
2024-12-14 02:16:03.423927: Epoch time: 684.99 s
2024-12-14 02:16:04.747813: 
2024-12-14 02:16:04.748647: Epoch 44
2024-12-14 02:16:04.749363: Current learning rate: 0.00732
2024-12-14 02:27:41.065442: Validation loss did not improve from -0.23061. Patience: 37/50
2024-12-14 02:27:41.066434: train_loss -0.8459
2024-12-14 02:27:41.067320: val_loss -0.0136
2024-12-14 02:27:41.068140: Pseudo dice [0.5282]
2024-12-14 02:27:41.068946: Epoch time: 696.32 s
2024-12-14 02:27:42.737725: 
2024-12-14 02:27:42.738956: Epoch 45
2024-12-14 02:27:42.739925: Current learning rate: 0.00725
2024-12-14 02:39:08.473031: Validation loss did not improve from -0.23061. Patience: 38/50
2024-12-14 02:39:08.473825: train_loss -0.8472
2024-12-14 02:39:08.474725: val_loss -0.0155
2024-12-14 02:39:08.475602: Pseudo dice [0.5401]
2024-12-14 02:39:08.476421: Epoch time: 685.74 s
2024-12-14 02:39:09.791601: 
2024-12-14 02:39:09.792863: Epoch 46
2024-12-14 02:39:09.794014: Current learning rate: 0.00719
2024-12-14 02:50:28.813571: Validation loss did not improve from -0.23061. Patience: 39/50
2024-12-14 02:50:28.814413: train_loss -0.8498
2024-12-14 02:50:28.815231: val_loss -0.093
2024-12-14 02:50:28.815864: Pseudo dice [0.5834]
2024-12-14 02:50:28.816488: Epoch time: 679.02 s
2024-12-14 02:50:30.141267: 
2024-12-14 02:50:30.142447: Epoch 47
2024-12-14 02:50:30.143151: Current learning rate: 0.00713
2024-12-14 03:01:34.973722: Validation loss did not improve from -0.23061. Patience: 40/50
2024-12-14 03:01:34.975198: train_loss -0.8488
2024-12-14 03:01:34.975964: val_loss -0.0266
2024-12-14 03:01:34.976574: Pseudo dice [0.5615]
2024-12-14 03:01:34.977424: Epoch time: 664.84 s
2024-12-14 03:01:36.301225: 
2024-12-14 03:01:36.302225: Epoch 48
2024-12-14 03:01:36.302937: Current learning rate: 0.00707
2024-12-14 03:12:48.235133: Validation loss did not improve from -0.23061. Patience: 41/50
2024-12-14 03:12:48.236172: train_loss -0.8519
2024-12-14 03:12:48.236768: val_loss -0.0006
2024-12-14 03:12:48.237328: Pseudo dice [0.5461]
2024-12-14 03:12:48.237943: Epoch time: 671.94 s
2024-12-14 03:12:49.574307: 
2024-12-14 03:12:49.575520: Epoch 49
2024-12-14 03:12:49.576276: Current learning rate: 0.007
2024-12-14 03:24:30.258305: Validation loss did not improve from -0.23061. Patience: 42/50
2024-12-14 03:24:30.258958: train_loss -0.8529
2024-12-14 03:24:30.259812: val_loss -0.0638
2024-12-14 03:24:30.260646: Pseudo dice [0.5622]
2024-12-14 03:24:30.261448: Epoch time: 700.69 s
2024-12-14 03:24:32.114971: 
2024-12-14 03:24:32.115905: Epoch 50
2024-12-14 03:24:32.116823: Current learning rate: 0.00694
2024-12-14 03:36:00.646548: Validation loss did not improve from -0.23061. Patience: 43/50
2024-12-14 03:36:00.647525: train_loss -0.8513
2024-12-14 03:36:00.648225: val_loss -0.0375
2024-12-14 03:36:00.648790: Pseudo dice [0.5569]
2024-12-14 03:36:00.649365: Epoch time: 688.53 s
2024-12-14 03:36:02.744314: 
2024-12-14 03:36:02.745389: Epoch 51
2024-12-14 03:36:02.746196: Current learning rate: 0.00688
2024-12-14 03:47:54.096090: Validation loss did not improve from -0.23061. Patience: 44/50
2024-12-14 03:47:54.096737: train_loss -0.8534
2024-12-14 03:47:54.097531: val_loss 0.0225
2024-12-14 03:47:54.098284: Pseudo dice [0.5228]
2024-12-14 03:47:54.099043: Epoch time: 711.35 s
2024-12-14 03:47:55.444296: 
2024-12-14 03:47:55.445356: Epoch 52
2024-12-14 03:47:55.446146: Current learning rate: 0.00682
2024-12-14 03:59:41.613807: Validation loss did not improve from -0.23061. Patience: 45/50
2024-12-14 03:59:41.614655: train_loss -0.8553
2024-12-14 03:59:41.615545: val_loss -0.037
2024-12-14 03:59:41.616399: Pseudo dice [0.5485]
2024-12-14 03:59:41.617102: Epoch time: 706.17 s
2024-12-14 03:59:42.986518: 
2024-12-14 03:59:42.987675: Epoch 53
2024-12-14 03:59:42.988458: Current learning rate: 0.00675
2024-12-14 04:11:40.505852: Validation loss did not improve from -0.23061. Patience: 46/50
2024-12-14 04:11:40.507482: train_loss -0.8581
2024-12-14 04:11:40.508523: val_loss -0.0213
2024-12-14 04:11:40.509498: Pseudo dice [0.5661]
2024-12-14 04:11:40.510539: Epoch time: 717.52 s
2024-12-14 04:11:41.947955: 
2024-12-14 04:11:41.949320: Epoch 54
2024-12-14 04:11:41.950347: Current learning rate: 0.00669
2024-12-14 04:22:58.124733: Validation loss did not improve from -0.23061. Patience: 47/50
2024-12-14 04:22:58.125475: train_loss -0.8578
2024-12-14 04:22:58.126160: val_loss -0.0186
2024-12-14 04:22:58.126774: Pseudo dice [0.566]
2024-12-14 04:22:58.127570: Epoch time: 676.18 s
2024-12-14 04:22:59.841221: 
2024-12-14 04:22:59.842158: Epoch 55
2024-12-14 04:22:59.842863: Current learning rate: 0.00663
2024-12-14 04:34:10.662924: Validation loss did not improve from -0.23061. Patience: 48/50
2024-12-14 04:34:10.663893: train_loss -0.8578
2024-12-14 04:34:10.664984: val_loss 1e-04
2024-12-14 04:34:10.665935: Pseudo dice [0.5453]
2024-12-14 04:34:10.666748: Epoch time: 670.82 s
2024-12-14 04:34:12.029459: 
2024-12-14 04:34:12.030829: Epoch 56
2024-12-14 04:34:12.031931: Current learning rate: 0.00657
2024-12-14 04:45:44.120235: Validation loss did not improve from -0.23061. Patience: 49/50
2024-12-14 04:45:44.121078: train_loss -0.86
2024-12-14 04:45:44.121737: val_loss 0.0492
2024-12-14 04:45:44.122415: Pseudo dice [0.5334]
2024-12-14 04:45:44.123103: Epoch time: 692.09 s
2024-12-14 04:45:45.547780: 
2024-12-14 04:45:45.548928: Epoch 57
2024-12-14 04:45:45.549637: Current learning rate: 0.0065
2024-12-14 04:57:13.108170: Validation loss did not improve from -0.23061. Patience: 50/50
2024-12-14 04:57:13.108969: train_loss -0.8628
2024-12-14 04:57:13.109772: val_loss 0.0983
2024-12-14 04:57:13.110483: Pseudo dice [0.5102]
2024-12-14 04:57:13.111367: Epoch time: 687.56 s
2024-12-14 04:57:14.507651: 
2024-12-14 04:57:14.509061: Epoch 58
2024-12-14 04:57:14.510094: Current learning rate: 0.00644
2024-12-14 05:09:03.351700: Validation loss did not improve from -0.23061. Patience: 51/50
2024-12-14 05:09:03.370338: train_loss -0.8579
2024-12-14 05:09:03.371679: val_loss -0.0556
2024-12-14 05:09:03.372461: Pseudo dice [0.5632]
2024-12-14 05:09:03.373373: Epoch time: 708.86 s
2024-12-14 05:09:04.802859: 
2024-12-14 05:09:04.803753: Epoch 59
2024-12-14 05:09:04.804464: Current learning rate: 0.00638
2024-12-14 05:21:05.273199: Validation loss did not improve from -0.23061. Patience: 52/50
2024-12-14 05:21:05.274351: train_loss -0.8615
2024-12-14 05:21:05.275447: val_loss 0.048
2024-12-14 05:21:05.276144: Pseudo dice [0.5226]
2024-12-14 05:21:05.276961: Epoch time: 720.47 s
2024-12-14 05:21:07.027110: 
2024-12-14 05:21:07.028376: Epoch 60
2024-12-14 05:21:07.029112: Current learning rate: 0.00631
2024-12-14 05:32:21.536364: Validation loss did not improve from -0.23061. Patience: 53/50
2024-12-14 05:32:21.537471: train_loss -0.8639
2024-12-14 05:32:21.538134: val_loss 0.0678
2024-12-14 05:32:21.538736: Pseudo dice [0.5475]
2024-12-14 05:32:21.539406: Epoch time: 674.51 s
2024-12-14 05:32:23.488730: 
2024-12-14 05:32:23.489983: Epoch 61
2024-12-14 05:32:23.490651: Current learning rate: 0.00625
2024-12-14 05:43:46.849339: Validation loss did not improve from -0.23061. Patience: 54/50
2024-12-14 05:43:46.850239: train_loss -0.8663
2024-12-14 05:43:46.850961: val_loss 0.0437
2024-12-14 05:43:46.851652: Pseudo dice [0.541]
2024-12-14 05:43:46.852364: Epoch time: 683.36 s
2024-12-14 05:43:48.223489: 
2024-12-14 05:43:48.224818: Epoch 62
2024-12-14 05:43:48.225725: Current learning rate: 0.00619
2024-12-14 05:55:17.538990: Validation loss did not improve from -0.23061. Patience: 55/50
2024-12-14 05:55:17.539660: train_loss -0.8671
2024-12-14 05:55:17.540366: val_loss 0.0605
2024-12-14 05:55:17.541062: Pseudo dice [0.517]
2024-12-14 05:55:17.541750: Epoch time: 689.32 s
2024-12-14 05:55:18.945551: 
2024-12-14 05:55:18.946532: Epoch 63
2024-12-14 05:55:18.947256: Current learning rate: 0.00612
2024-12-14 06:07:04.108625: Validation loss did not improve from -0.23061. Patience: 56/50
2024-12-14 06:07:04.109509: train_loss -0.8679
2024-12-14 06:07:04.110202: val_loss 0.0213
2024-12-14 06:07:04.110884: Pseudo dice [0.557]
2024-12-14 06:07:04.111630: Epoch time: 705.17 s
2024-12-14 06:07:05.510578: 
2024-12-14 06:07:05.511767: Epoch 64
2024-12-14 06:07:05.512486: Current learning rate: 0.00606
2024-12-14 06:19:29.517706: Validation loss did not improve from -0.23061. Patience: 57/50
2024-12-14 06:19:29.519347: train_loss -0.8696
2024-12-14 06:19:29.520261: val_loss 0.0902
2024-12-14 06:19:29.520936: Pseudo dice [0.5362]
2024-12-14 06:19:29.521966: Epoch time: 744.01 s
2024-12-14 06:19:31.285087: 
2024-12-14 06:19:31.286494: Epoch 65
2024-12-14 06:19:31.287472: Current learning rate: 0.006
2024-12-14 06:31:30.339926: Validation loss did not improve from -0.23061. Patience: 58/50
2024-12-14 06:31:30.341008: train_loss -0.8679
2024-12-14 06:31:30.341721: val_loss -0.015
2024-12-14 06:31:30.342333: Pseudo dice [0.5383]
2024-12-14 06:31:30.342957: Epoch time: 719.06 s
2024-12-14 06:31:31.752789: 
2024-12-14 06:31:31.753776: Epoch 66
2024-12-14 06:31:31.754348: Current learning rate: 0.00593
2024-12-14 06:42:42.796191: Validation loss did not improve from -0.23061. Patience: 59/50
2024-12-14 06:42:42.796941: train_loss -0.8687
2024-12-14 06:42:42.797826: val_loss -0.0347
2024-12-14 06:42:42.798655: Pseudo dice [0.5718]
2024-12-14 06:42:42.799487: Epoch time: 671.05 s
2024-12-14 06:42:44.215949: 
2024-12-14 06:42:44.216957: Epoch 67
2024-12-14 06:42:44.217882: Current learning rate: 0.00587
2024-12-14 06:53:43.141821: Validation loss did not improve from -0.23061. Patience: 60/50
2024-12-14 06:53:43.142734: train_loss -0.8694
2024-12-14 06:53:43.143523: val_loss -0.0213
2024-12-14 06:53:43.144349: Pseudo dice [0.5569]
2024-12-14 06:53:43.145036: Epoch time: 658.93 s
2024-12-14 06:53:44.527600: 
2024-12-14 06:53:44.528811: Epoch 68
2024-12-14 06:53:44.529596: Current learning rate: 0.00581
2024-12-14 07:05:38.222032: Validation loss did not improve from -0.23061. Patience: 61/50
2024-12-14 07:05:38.223052: train_loss -0.8727
2024-12-14 07:05:38.224029: val_loss 0.0831
2024-12-14 07:05:38.224923: Pseudo dice [0.5456]
2024-12-14 07:05:38.225761: Epoch time: 713.7 s
2024-12-14 07:05:39.603942: 
2024-12-14 07:05:39.605243: Epoch 69
2024-12-14 07:05:39.606277: Current learning rate: 0.00574
2024-12-14 07:17:34.082707: Validation loss did not improve from -0.23061. Patience: 62/50
2024-12-14 07:17:34.084383: train_loss -0.8715
2024-12-14 07:17:34.085707: val_loss 0.0193
2024-12-14 07:17:34.086430: Pseudo dice [0.5576]
2024-12-14 07:17:34.087366: Epoch time: 714.48 s
2024-12-14 07:17:35.888686: 
2024-12-14 07:17:35.889988: Epoch 70
2024-12-14 07:17:35.890784: Current learning rate: 0.00568
2024-12-14 07:28:53.695000: Validation loss did not improve from -0.23061. Patience: 63/50
2024-12-14 07:28:53.695799: train_loss -0.8734
2024-12-14 07:28:53.696544: val_loss 0.09
2024-12-14 07:28:53.697189: Pseudo dice [0.5455]
2024-12-14 07:28:53.697823: Epoch time: 677.81 s
2024-12-14 07:28:55.082297: 
2024-12-14 07:28:55.083227: Epoch 71
2024-12-14 07:28:55.083984: Current learning rate: 0.00562
2024-12-14 07:40:09.791069: Validation loss did not improve from -0.23061. Patience: 64/50
2024-12-14 07:40:09.792271: train_loss -0.8718
2024-12-14 07:40:09.793033: val_loss 0.2132
2024-12-14 07:40:09.793816: Pseudo dice [0.4742]
2024-12-14 07:40:09.794505: Epoch time: 674.71 s
2024-12-14 07:40:11.587935: 
2024-12-14 07:40:11.589127: Epoch 72
2024-12-14 07:40:11.589847: Current learning rate: 0.00555
2024-12-14 07:51:53.122681: Validation loss did not improve from -0.23061. Patience: 65/50
2024-12-14 07:51:53.123435: train_loss -0.8746
2024-12-14 07:51:53.124427: val_loss 0.1563
2024-12-14 07:51:53.125347: Pseudo dice [0.4988]
2024-12-14 07:51:53.126270: Epoch time: 701.54 s
2024-12-14 07:51:54.517963: 
2024-12-14 07:51:54.519101: Epoch 73
2024-12-14 07:51:54.520189: Current learning rate: 0.00549
2024-12-14 08:04:11.056065: Validation loss did not improve from -0.23061. Patience: 66/50
2024-12-14 08:04:11.057032: train_loss -0.8781
2024-12-14 08:04:11.057656: val_loss 0.0832
2024-12-14 08:04:11.058253: Pseudo dice [0.5188]
2024-12-14 08:04:11.059000: Epoch time: 736.54 s
2024-12-14 08:04:12.444299: 
2024-12-14 08:04:12.445529: Epoch 74
2024-12-14 08:04:12.446279: Current learning rate: 0.00542
2024-12-14 08:15:10.319660: Validation loss did not improve from -0.23061. Patience: 67/50
2024-12-14 08:15:10.320595: train_loss -0.876
2024-12-14 08:15:10.321669: val_loss 0.0808
2024-12-14 08:15:10.322582: Pseudo dice [0.5252]
2024-12-14 08:15:10.323364: Epoch time: 657.88 s
2024-12-14 08:15:12.093751: 
2024-12-14 08:15:12.094877: Epoch 75
2024-12-14 08:15:12.095985: Current learning rate: 0.00536
2024-12-14 08:26:31.743892: Validation loss did not improve from -0.23061. Patience: 68/50
2024-12-14 08:26:31.748015: train_loss -0.8775
2024-12-14 08:26:31.750024: val_loss 0.0392
2024-12-14 08:26:31.750963: Pseudo dice [0.518]
2024-12-14 08:26:31.752423: Epoch time: 679.65 s
2024-12-14 08:26:33.161874: 
2024-12-14 08:26:33.162625: Epoch 76
2024-12-14 08:26:33.163272: Current learning rate: 0.00529
2024-12-14 08:38:41.181746: Validation loss did not improve from -0.23061. Patience: 69/50
2024-12-14 08:38:41.182669: train_loss -0.8798
2024-12-14 08:38:41.183310: val_loss -0.0145
2024-12-14 08:38:41.183913: Pseudo dice [0.5541]
2024-12-14 08:38:41.184563: Epoch time: 728.02 s
2024-12-14 08:38:42.577360: 
2024-12-14 08:38:42.578863: Epoch 77
2024-12-14 08:38:42.579658: Current learning rate: 0.00523
2024-12-14 08:50:13.715468: Validation loss did not improve from -0.23061. Patience: 70/50
2024-12-14 08:50:13.716079: train_loss -0.8791
2024-12-14 08:50:13.716843: val_loss 0.0672
2024-12-14 08:50:13.717542: Pseudo dice [0.535]
2024-12-14 08:50:13.718340: Epoch time: 691.14 s
2024-12-14 08:50:15.134425: 
2024-12-14 08:50:15.135576: Epoch 78
2024-12-14 08:50:15.136492: Current learning rate: 0.00517
2024-12-14 09:01:55.276722: Validation loss did not improve from -0.23061. Patience: 71/50
2024-12-14 09:01:55.277554: train_loss -0.8803
2024-12-14 09:01:55.278275: val_loss 0.0996
2024-12-14 09:01:55.278845: Pseudo dice [0.5067]
2024-12-14 09:01:55.279420: Epoch time: 700.14 s
2024-12-14 09:01:56.709484: 
2024-12-14 09:01:56.710678: Epoch 79
2024-12-14 09:01:56.711364: Current learning rate: 0.0051
2024-12-14 09:13:22.698455: Validation loss did not improve from -0.23061. Patience: 72/50
2024-12-14 09:13:22.699370: train_loss -0.8814
2024-12-14 09:13:22.700138: val_loss 0.0373
2024-12-14 09:13:22.700837: Pseudo dice [0.5298]
2024-12-14 09:13:22.701631: Epoch time: 685.99 s
2024-12-14 09:13:24.636221: 
2024-12-14 09:13:24.637425: Epoch 80
2024-12-14 09:13:24.638159: Current learning rate: 0.00504
2024-12-14 09:25:05.211521: Validation loss did not improve from -0.23061. Patience: 73/50
2024-12-14 09:25:05.212418: train_loss -0.8813
2024-12-14 09:25:05.213092: val_loss 0.1073
2024-12-14 09:25:05.213749: Pseudo dice [0.5032]
2024-12-14 09:25:05.214387: Epoch time: 700.58 s
2024-12-14 09:25:06.682028: 
2024-12-14 09:25:06.683075: Epoch 81
2024-12-14 09:25:06.683674: Current learning rate: 0.00497
2024-12-14 09:36:45.103508: Validation loss did not improve from -0.23061. Patience: 74/50
2024-12-14 09:36:45.105015: train_loss -0.8828
2024-12-14 09:36:45.105662: val_loss 0.1426
2024-12-14 09:36:45.106265: Pseudo dice [0.5154]
2024-12-14 09:36:45.106899: Epoch time: 698.42 s
2024-12-14 09:36:46.536054: 
2024-12-14 09:36:46.536958: Epoch 82
2024-12-14 09:36:46.537598: Current learning rate: 0.00491
2024-12-14 09:47:43.820032: Validation loss did not improve from -0.23061. Patience: 75/50
2024-12-14 09:47:43.820836: train_loss -0.8816
2024-12-14 09:47:43.821506: val_loss 0.1498
2024-12-14 09:47:43.822211: Pseudo dice [0.4913]
2024-12-14 09:47:43.822973: Epoch time: 657.29 s
2024-12-14 09:47:45.494907: 
2024-12-14 09:47:45.495841: Epoch 83
2024-12-14 09:47:45.496604: Current learning rate: 0.00484
2024-12-14 09:59:11.160888: Validation loss did not improve from -0.23061. Patience: 76/50
2024-12-14 09:59:11.161620: train_loss -0.8826
2024-12-14 09:59:11.162324: val_loss 0.1256
2024-12-14 09:59:11.162920: Pseudo dice [0.5038]
2024-12-14 09:59:11.163497: Epoch time: 685.67 s
2024-12-14 09:59:12.481933: 
2024-12-14 09:59:12.482760: Epoch 84
2024-12-14 09:59:12.483364: Current learning rate: 0.00478
2024-12-14 10:11:09.491423: Validation loss did not improve from -0.23061. Patience: 77/50
2024-12-14 10:11:09.492301: train_loss -0.8829
2024-12-14 10:11:09.493153: val_loss 0.038
2024-12-14 10:11:09.493952: Pseudo dice [0.5431]
2024-12-14 10:11:09.494659: Epoch time: 717.01 s
2024-12-14 10:11:11.240169: 
2024-12-14 10:11:11.241653: Epoch 85
2024-12-14 10:11:11.242649: Current learning rate: 0.00471
2024-12-14 10:23:23.477321: Validation loss did not improve from -0.23061. Patience: 78/50
2024-12-14 10:23:23.477934: train_loss -0.8866
2024-12-14 10:23:23.478661: val_loss 0.0465
2024-12-14 10:23:23.479233: Pseudo dice [0.5387]
2024-12-14 10:23:23.479888: Epoch time: 732.24 s
2024-12-14 10:23:24.815789: 
2024-12-14 10:23:24.816692: Epoch 86
2024-12-14 10:23:24.817415: Current learning rate: 0.00465
2024-12-14 10:34:30.469988: Validation loss did not improve from -0.23061. Patience: 79/50
2024-12-14 10:34:30.473651: train_loss -0.8871
2024-12-14 10:34:30.475479: val_loss 0.0586
2024-12-14 10:34:30.476408: Pseudo dice [0.5503]
2024-12-14 10:34:30.477588: Epoch time: 665.66 s
2024-12-14 10:34:31.829879: 
2024-12-14 10:34:31.831231: Epoch 87
2024-12-14 10:34:31.832241: Current learning rate: 0.00458
2024-12-14 10:46:02.982083: Validation loss did not improve from -0.23061. Patience: 80/50
2024-12-14 10:46:02.983131: train_loss -0.8885
2024-12-14 10:46:02.984073: val_loss 0.0219
2024-12-14 10:46:02.985033: Pseudo dice [0.5541]
2024-12-14 10:46:02.985709: Epoch time: 691.15 s
2024-12-14 10:46:04.323285: 
2024-12-14 10:46:04.324432: Epoch 88
2024-12-14 10:46:04.325249: Current learning rate: 0.00452
2024-12-14 10:57:34.085513: Validation loss did not improve from -0.23061. Patience: 81/50
2024-12-14 10:57:34.086476: train_loss -0.8874
2024-12-14 10:57:34.087486: val_loss 0.1421
2024-12-14 10:57:34.088277: Pseudo dice [0.5121]
2024-12-14 10:57:34.089182: Epoch time: 689.76 s
2024-12-14 10:57:35.419787: 
2024-12-14 10:57:35.421012: Epoch 89
2024-12-14 10:57:35.422118: Current learning rate: 0.00445
2024-12-14 11:09:00.179659: Validation loss did not improve from -0.23061. Patience: 82/50
2024-12-14 11:09:00.180294: train_loss -0.8892
2024-12-14 11:09:00.180987: val_loss 0.131
2024-12-14 11:09:00.181643: Pseudo dice [0.5185]
2024-12-14 11:09:00.182464: Epoch time: 684.76 s
2024-12-14 11:09:01.845314: 
2024-12-14 11:09:01.846230: Epoch 90
2024-12-14 11:09:01.846971: Current learning rate: 0.00438
2024-12-14 11:20:16.253731: Validation loss did not improve from -0.23061. Patience: 83/50
2024-12-14 11:20:16.254477: train_loss -0.8903
2024-12-14 11:20:16.255150: val_loss 0.1998
2024-12-14 11:20:16.255784: Pseudo dice [0.4895]
2024-12-14 11:20:16.256475: Epoch time: 674.41 s
2024-12-14 11:20:17.586900: 
2024-12-14 11:20:17.587902: Epoch 91
2024-12-14 11:20:17.588614: Current learning rate: 0.00432
2024-12-14 11:32:24.558910: Validation loss did not improve from -0.23061. Patience: 84/50
2024-12-14 11:32:24.559604: train_loss -0.8905
2024-12-14 11:32:24.560210: val_loss 0.053
2024-12-14 11:32:24.560794: Pseudo dice [0.5471]
2024-12-14 11:32:24.561356: Epoch time: 726.97 s
2024-12-14 11:32:25.898257: 
2024-12-14 11:32:25.899133: Epoch 92
2024-12-14 11:32:25.900151: Current learning rate: 0.00425
2024-12-14 11:44:15.230481: Validation loss did not improve from -0.23061. Patience: 85/50
2024-12-14 11:44:15.232170: train_loss -0.8916
2024-12-14 11:44:15.233170: val_loss 0.0959
2024-12-14 11:44:15.233894: Pseudo dice [0.5331]
2024-12-14 11:44:15.234569: Epoch time: 709.34 s
2024-12-14 11:44:16.626685: 
2024-12-14 11:44:16.627793: Epoch 93
2024-12-14 11:44:16.628494: Current learning rate: 0.00419
2024-12-14 11:56:14.944778: Validation loss did not improve from -0.23061. Patience: 86/50
2024-12-14 11:56:14.945630: train_loss -0.8917
2024-12-14 11:56:14.946713: val_loss 0.1059
2024-12-14 11:56:14.947360: Pseudo dice [0.5294]
2024-12-14 11:56:14.947957: Epoch time: 718.32 s
2024-12-14 11:56:17.034559: 
2024-12-14 11:56:17.035507: Epoch 94
2024-12-14 11:56:17.036126: Current learning rate: 0.00412
2024-12-14 12:08:13.637631: Validation loss did not improve from -0.23061. Patience: 87/50
2024-12-14 12:08:13.638642: train_loss -0.8915
2024-12-14 12:08:13.639384: val_loss 0.0666
2024-12-14 12:08:13.639992: Pseudo dice [0.5512]
2024-12-14 12:08:13.640744: Epoch time: 716.61 s
2024-12-14 12:08:15.550960: 
2024-12-14 12:08:15.552007: Epoch 95
2024-12-14 12:08:15.552645: Current learning rate: 0.00405
2024-12-14 12:19:59.352365: Validation loss did not improve from -0.23061. Patience: 88/50
2024-12-14 12:19:59.353302: train_loss -0.8923
2024-12-14 12:19:59.354073: val_loss 0.1128
2024-12-14 12:19:59.354825: Pseudo dice [0.5357]
2024-12-14 12:19:59.355596: Epoch time: 703.8 s
2024-12-14 12:20:00.693369: 
2024-12-14 12:20:00.694602: Epoch 96
2024-12-14 12:20:00.695275: Current learning rate: 0.00399
2024-12-14 12:31:56.129306: Validation loss did not improve from -0.23061. Patience: 89/50
2024-12-14 12:31:56.130298: train_loss -0.8934
2024-12-14 12:31:56.131029: val_loss 0.1518
2024-12-14 12:31:56.131675: Pseudo dice [0.5139]
2024-12-14 12:31:56.132429: Epoch time: 715.44 s
2024-12-14 12:31:57.489413: 
2024-12-14 12:31:57.490444: Epoch 97
2024-12-14 12:31:57.491113: Current learning rate: 0.00392
2024-12-14 12:43:56.192879: Validation loss did not improve from -0.23061. Patience: 90/50
2024-12-14 12:43:56.195632: train_loss -0.8947
2024-12-14 12:43:56.197810: val_loss 0.2078
2024-12-14 12:43:56.198624: Pseudo dice [0.4851]
2024-12-14 12:43:56.199733: Epoch time: 718.71 s
2024-12-14 12:43:57.966509: 
2024-12-14 12:43:57.967824: Epoch 98
2024-12-14 12:43:57.968668: Current learning rate: 0.00385
2024-12-14 12:55:36.642992: Validation loss did not improve from -0.23061. Patience: 91/50
2024-12-14 12:55:36.644163: train_loss -0.8934
2024-12-14 12:55:36.645198: val_loss 0.1314
2024-12-14 12:55:36.646164: Pseudo dice [0.5127]
2024-12-14 12:55:36.647032: Epoch time: 698.68 s
2024-12-14 12:55:38.013418: 
2024-12-14 12:55:38.014904: Epoch 99
2024-12-14 12:55:38.015852: Current learning rate: 0.00379
2024-12-14 13:06:54.704528: Validation loss did not improve from -0.23061. Patience: 92/50
2024-12-14 13:06:54.705661: train_loss -0.8944
2024-12-14 13:06:54.706415: val_loss 0.2116
2024-12-14 13:06:54.707047: Pseudo dice [0.4796]
2024-12-14 13:06:54.707766: Epoch time: 676.69 s
2024-12-14 13:06:56.474981: 
2024-12-14 13:06:56.476046: Epoch 100
2024-12-14 13:06:56.476736: Current learning rate: 0.00372
2024-12-14 13:19:09.812194: Validation loss did not improve from -0.23061. Patience: 93/50
2024-12-14 13:19:09.812953: train_loss -0.8972
2024-12-14 13:19:09.813639: val_loss 0.0705
2024-12-14 13:19:09.814296: Pseudo dice [0.5415]
2024-12-14 13:19:09.815255: Epoch time: 733.34 s
2024-12-14 13:19:11.162323: 
2024-12-14 13:19:11.163532: Epoch 101
2024-12-14 13:19:11.164222: Current learning rate: 0.00365
2024-12-14 13:31:10.510953: Validation loss did not improve from -0.23061. Patience: 94/50
2024-12-14 13:31:10.511843: train_loss -0.8974
2024-12-14 13:31:10.512641: val_loss 0.1098
2024-12-14 13:31:10.513359: Pseudo dice [0.5354]
2024-12-14 13:31:10.514061: Epoch time: 719.35 s
2024-12-14 13:31:11.889747: 
2024-12-14 13:31:11.891277: Epoch 102
2024-12-14 13:31:11.892176: Current learning rate: 0.00359
2024-12-14 13:43:44.935539: Validation loss did not improve from -0.23061. Patience: 95/50
2024-12-14 13:43:44.936408: train_loss -0.8978
2024-12-14 13:43:44.937231: val_loss 0.1525
2024-12-14 13:43:44.937971: Pseudo dice [0.5156]
2024-12-14 13:43:44.938604: Epoch time: 753.05 s
2024-12-14 13:43:46.349300: 
2024-12-14 13:43:46.350556: Epoch 103
2024-12-14 13:43:46.351298: Current learning rate: 0.00352
2024-12-14 13:56:05.431795: Validation loss did not improve from -0.23061. Patience: 96/50
2024-12-14 13:56:05.433391: train_loss -0.8958
2024-12-14 13:56:05.434363: val_loss 0.216
2024-12-14 13:56:05.434997: Pseudo dice [0.5045]
2024-12-14 13:56:05.435667: Epoch time: 739.09 s
2024-12-14 13:56:06.856026: 
2024-12-14 13:56:06.856806: Epoch 104
2024-12-14 13:56:06.857409: Current learning rate: 0.00345
2024-12-14 14:08:05.357512: Validation loss did not improve from -0.23061. Patience: 97/50
2024-12-14 14:08:05.358473: train_loss -0.8974
2024-12-14 14:08:05.359175: val_loss 0.1628
2024-12-14 14:08:05.359952: Pseudo dice [0.5234]
2024-12-14 14:08:05.360526: Epoch time: 718.5 s
2024-12-14 14:08:07.127233: 
2024-12-14 14:08:07.128366: Epoch 105
2024-12-14 14:08:07.129028: Current learning rate: 0.00338
2024-12-14 14:20:49.691491: Validation loss did not improve from -0.23061. Patience: 98/50
2024-12-14 14:20:49.692385: train_loss -0.8994
2024-12-14 14:20:49.693215: val_loss 0.2018
2024-12-14 14:20:49.693956: Pseudo dice [0.4993]
2024-12-14 14:20:49.694673: Epoch time: 762.57 s
2024-12-14 14:20:51.462358: 
2024-12-14 14:20:51.463809: Epoch 106
2024-12-14 14:20:51.464819: Current learning rate: 0.00332
2024-12-14 14:35:23.550054: Validation loss did not improve from -0.23061. Patience: 99/50
2024-12-14 14:35:23.550851: train_loss -0.8997
2024-12-14 14:35:23.551767: val_loss 0.1923
2024-12-14 14:35:23.552580: Pseudo dice [0.5083]
2024-12-14 14:35:23.553601: Epoch time: 872.09 s
2024-12-14 14:35:24.897155: 
2024-12-14 14:35:24.898081: Epoch 107
2024-12-14 14:35:24.898921: Current learning rate: 0.00325
2024-12-14 14:50:50.665032: Validation loss did not improve from -0.23061. Patience: 100/50
2024-12-14 14:50:50.665850: train_loss -0.9
2024-12-14 14:50:50.666677: val_loss 0.1394
2024-12-14 14:50:50.667387: Pseudo dice [0.5252]
2024-12-14 14:50:50.668006: Epoch time: 925.77 s
2024-12-14 14:50:52.037286: 
2024-12-14 14:50:52.038406: Epoch 108
2024-12-14 14:50:52.039136: Current learning rate: 0.00318
2024-12-14 15:03:59.513787: Validation loss did not improve from -0.23061. Patience: 101/50
2024-12-14 15:03:59.514911: train_loss -0.9009
2024-12-14 15:03:59.515643: val_loss 0.1705
2024-12-14 15:03:59.516604: Pseudo dice [0.4912]
2024-12-14 15:03:59.517292: Epoch time: 787.48 s
2024-12-14 15:04:00.978338: 
2024-12-14 15:04:00.979344: Epoch 109
2024-12-14 15:04:00.980243: Current learning rate: 0.00311
2024-12-14 15:17:14.855561: Validation loss did not improve from -0.23061. Patience: 102/50
2024-12-14 15:17:14.856524: train_loss -0.8989
2024-12-14 15:17:14.857273: val_loss 0.2133
2024-12-14 15:17:14.857967: Pseudo dice [0.5159]
2024-12-14 15:17:14.858633: Epoch time: 793.88 s
2024-12-14 15:17:16.611117: 
2024-12-14 15:17:16.612152: Epoch 110
2024-12-14 15:17:16.612911: Current learning rate: 0.00304
2024-12-14 15:26:48.405818: Validation loss did not improve from -0.23061. Patience: 103/50
2024-12-14 15:26:48.406770: train_loss -0.8984
2024-12-14 15:26:48.407574: val_loss 0.1539
2024-12-14 15:26:48.408401: Pseudo dice [0.5158]
2024-12-14 15:26:48.409224: Epoch time: 571.8 s
2024-12-14 15:26:49.756993: 
2024-12-14 15:26:49.758251: Epoch 111
2024-12-14 15:26:49.759157: Current learning rate: 0.00297
2024-12-14 15:33:44.650274: Validation loss did not improve from -0.23061. Patience: 104/50
2024-12-14 15:33:44.651156: train_loss -0.9007
2024-12-14 15:33:44.652491: val_loss 0.1391
2024-12-14 15:33:44.653615: Pseudo dice [0.5273]
2024-12-14 15:33:44.654588: Epoch time: 414.9 s
2024-12-14 15:33:46.089342: 
2024-12-14 15:33:46.091022: Epoch 112
2024-12-14 15:33:46.092236: Current learning rate: 0.00291
2024-12-14 15:41:40.392004: Validation loss did not improve from -0.23061. Patience: 105/50
2024-12-14 15:41:40.412458: train_loss -0.9005
2024-12-14 15:41:40.414368: val_loss 0.2509
2024-12-14 15:41:40.415253: Pseudo dice [0.4842]
2024-12-14 15:41:40.416466: Epoch time: 474.32 s
2024-12-14 15:41:41.855579: 
2024-12-14 15:41:41.856694: Epoch 113
2024-12-14 15:41:41.857408: Current learning rate: 0.00284
2024-12-14 15:49:22.283098: Validation loss did not improve from -0.23061. Patience: 106/50
2024-12-14 15:49:22.283954: train_loss -0.9031
2024-12-14 15:49:22.284596: val_loss 0.0753
2024-12-14 15:49:22.285208: Pseudo dice [0.5262]
2024-12-14 15:49:22.285780: Epoch time: 460.43 s
2024-12-14 15:49:23.665088: 
2024-12-14 15:49:23.666105: Epoch 114
2024-12-14 15:49:23.666710: Current learning rate: 0.00277
2024-12-14 15:57:00.955478: Validation loss did not improve from -0.23061. Patience: 107/50
2024-12-14 15:57:00.956668: train_loss -0.9023
2024-12-14 15:57:00.957794: val_loss 0.154
2024-12-14 15:57:00.958658: Pseudo dice [0.5318]
2024-12-14 15:57:00.959386: Epoch time: 457.29 s
2024-12-14 15:57:02.790492: 
2024-12-14 15:57:02.791404: Epoch 115
2024-12-14 15:57:02.792086: Current learning rate: 0.0027
2024-12-14 16:05:22.637194: Validation loss did not improve from -0.23061. Patience: 108/50
2024-12-14 16:05:22.638242: train_loss -0.9032
2024-12-14 16:05:22.639046: val_loss 0.1252
2024-12-14 16:05:22.639775: Pseudo dice [0.513]
2024-12-14 16:05:22.640349: Epoch time: 499.85 s
2024-12-14 16:05:24.018786: 
2024-12-14 16:05:24.019905: Epoch 116
2024-12-14 16:05:24.020722: Current learning rate: 0.00263
2024-12-14 16:12:31.191124: Validation loss did not improve from -0.23061. Patience: 109/50
2024-12-14 16:12:31.191966: train_loss -0.9032
2024-12-14 16:12:31.192596: val_loss 0.1651
2024-12-14 16:12:31.193225: Pseudo dice [0.514]
2024-12-14 16:12:31.193866: Epoch time: 427.17 s
2024-12-14 16:12:32.964177: 
2024-12-14 16:12:32.965731: Epoch 117
2024-12-14 16:12:32.966753: Current learning rate: 0.00256
2024-12-14 16:18:58.581513: Validation loss did not improve from -0.23061. Patience: 110/50
2024-12-14 16:18:58.582394: train_loss -0.9039
2024-12-14 16:18:58.583144: val_loss 0.216
2024-12-14 16:18:58.583817: Pseudo dice [0.487]
2024-12-14 16:18:58.584560: Epoch time: 385.62 s
2024-12-14 16:18:59.958657: 
2024-12-14 16:18:59.959931: Epoch 118
2024-12-14 16:18:59.960730: Current learning rate: 0.00249
2024-12-14 16:25:15.340911: Validation loss did not improve from -0.23061. Patience: 111/50
2024-12-14 16:25:15.342027: train_loss -0.9041
2024-12-14 16:25:15.342683: val_loss 0.1276
2024-12-14 16:25:15.343693: Pseudo dice [0.5393]
2024-12-14 16:25:15.344463: Epoch time: 375.38 s
2024-12-14 16:25:16.722805: 
2024-12-14 16:25:16.723794: Epoch 119
2024-12-14 16:25:16.724882: Current learning rate: 0.00242
2024-12-14 16:29:17.586965: Validation loss did not improve from -0.23061. Patience: 112/50
2024-12-14 16:29:17.589325: train_loss -0.9049
2024-12-14 16:29:17.591064: val_loss 0.1542
2024-12-14 16:29:17.591873: Pseudo dice [0.5115]
2024-12-14 16:29:17.593080: Epoch time: 240.87 s
2024-12-14 16:29:19.458283: 
2024-12-14 16:29:19.459637: Epoch 120
2024-12-14 16:29:19.460618: Current learning rate: 0.00235
2024-12-14 16:33:24.495448: Validation loss did not improve from -0.23061. Patience: 113/50
2024-12-14 16:33:24.496378: train_loss -0.9075
2024-12-14 16:33:24.497220: val_loss 0.1244
2024-12-14 16:33:24.498345: Pseudo dice [0.523]
2024-12-14 16:33:24.499333: Epoch time: 245.04 s
2024-12-14 16:33:25.942254: 
2024-12-14 16:33:25.943342: Epoch 121
2024-12-14 16:33:25.944009: Current learning rate: 0.00228
2024-12-14 16:37:57.697257: Validation loss did not improve from -0.23061. Patience: 114/50
2024-12-14 16:37:57.698228: train_loss -0.9051
2024-12-14 16:37:57.699105: val_loss 0.1545
2024-12-14 16:37:57.699868: Pseudo dice [0.53]
2024-12-14 16:37:57.700546: Epoch time: 271.76 s
2024-12-14 16:37:59.102251: 
2024-12-14 16:37:59.103814: Epoch 122
2024-12-14 16:37:59.104609: Current learning rate: 0.00221
2024-12-14 16:41:39.114243: Validation loss did not improve from -0.23061. Patience: 115/50
2024-12-14 16:41:39.115196: train_loss -0.9067
2024-12-14 16:41:39.116010: val_loss 0.177
2024-12-14 16:41:39.116673: Pseudo dice [0.5055]
2024-12-14 16:41:39.117388: Epoch time: 220.01 s
2024-12-14 16:41:40.503253: 
2024-12-14 16:41:40.504697: Epoch 123
2024-12-14 16:41:40.505513: Current learning rate: 0.00214
2024-12-14 16:45:42.341841: Validation loss did not improve from -0.23061. Patience: 116/50
2024-12-14 16:45:42.344127: train_loss -0.9055
2024-12-14 16:45:42.344820: val_loss 0.2844
2024-12-14 16:45:42.345552: Pseudo dice [0.4778]
2024-12-14 16:45:42.346160: Epoch time: 241.84 s
2024-12-14 16:45:43.734936: 
2024-12-14 16:45:43.736152: Epoch 124
2024-12-14 16:45:43.736777: Current learning rate: 0.00207
2024-12-14 16:50:55.061869: Validation loss did not improve from -0.23061. Patience: 117/50
2024-12-14 16:50:55.062862: train_loss -0.9074
2024-12-14 16:50:55.063581: val_loss 0.2358
2024-12-14 16:50:55.064240: Pseudo dice [0.4998]
2024-12-14 16:50:55.064902: Epoch time: 311.33 s
2024-12-14 16:50:56.898218: 
2024-12-14 16:50:56.899568: Epoch 125
2024-12-14 16:50:56.900245: Current learning rate: 0.00199
2024-12-14 16:55:57.662258: Validation loss did not improve from -0.23061. Patience: 118/50
2024-12-14 16:55:57.663101: train_loss -0.908
2024-12-14 16:55:57.664068: val_loss 0.0757
2024-12-14 16:55:57.664827: Pseudo dice [0.5455]
2024-12-14 16:55:57.665532: Epoch time: 300.77 s
2024-12-14 16:55:59.050958: 
2024-12-14 16:55:59.052425: Epoch 126
2024-12-14 16:55:59.053692: Current learning rate: 0.00192
2024-12-14 16:59:28.611207: Validation loss did not improve from -0.23061. Patience: 119/50
2024-12-14 16:59:28.612070: train_loss -0.9081
2024-12-14 16:59:28.612890: val_loss 0.1849
2024-12-14 16:59:28.613420: Pseudo dice [0.5163]
2024-12-14 16:59:28.614030: Epoch time: 209.56 s
2024-12-14 16:59:30.025508: 
2024-12-14 16:59:30.026654: Epoch 127
2024-12-14 16:59:30.027262: Current learning rate: 0.00185
2024-12-14 17:03:54.388186: Validation loss did not improve from -0.23061. Patience: 120/50
2024-12-14 17:03:54.389177: train_loss -0.908
2024-12-14 17:03:54.390467: val_loss 0.217
2024-12-14 17:03:54.391326: Pseudo dice [0.5061]
2024-12-14 17:03:54.392020: Epoch time: 264.36 s
2024-12-14 17:03:56.406952: 
2024-12-14 17:03:56.408353: Epoch 128
2024-12-14 17:03:56.409471: Current learning rate: 0.00178
2024-12-14 17:08:35.759691: Validation loss did not improve from -0.23061. Patience: 121/50
2024-12-14 17:08:35.760624: train_loss -0.9077
2024-12-14 17:08:35.761528: val_loss 0.1574
2024-12-14 17:08:35.762341: Pseudo dice [0.5318]
2024-12-14 17:08:35.763131: Epoch time: 279.35 s
2024-12-14 17:08:37.126948: 
2024-12-14 17:08:37.128273: Epoch 129
2024-12-14 17:08:37.129071: Current learning rate: 0.0017
2024-12-14 17:13:16.449735: Validation loss did not improve from -0.23061. Patience: 122/50
2024-12-14 17:13:16.450664: train_loss -0.9078
2024-12-14 17:13:16.451644: val_loss 0.2252
2024-12-14 17:13:16.452413: Pseudo dice [0.5056]
2024-12-14 17:13:16.453396: Epoch time: 279.32 s
2024-12-14 17:13:18.280189: 
2024-12-14 17:13:18.281218: Epoch 130
2024-12-14 17:13:18.282093: Current learning rate: 0.00163
2024-12-14 17:18:54.613251: Validation loss did not improve from -0.23061. Patience: 123/50
2024-12-14 17:18:54.614652: train_loss -0.91
2024-12-14 17:18:54.615676: val_loss 0.2469
2024-12-14 17:18:54.616330: Pseudo dice [0.4866]
2024-12-14 17:18:54.616876: Epoch time: 336.34 s
2024-12-14 17:18:55.992045: 
2024-12-14 17:18:55.993207: Epoch 131
2024-12-14 17:18:55.994161: Current learning rate: 0.00156
2024-12-14 17:24:07.754113: Validation loss did not improve from -0.23061. Patience: 124/50
2024-12-14 17:24:07.755004: train_loss -0.9121
2024-12-14 17:24:07.756015: val_loss 0.2336
2024-12-14 17:24:07.756932: Pseudo dice [0.4951]
2024-12-14 17:24:07.757847: Epoch time: 311.76 s
2024-12-14 17:24:09.114713: 
2024-12-14 17:24:09.116168: Epoch 132
2024-12-14 17:24:09.117110: Current learning rate: 0.00148
2024-12-14 17:27:28.201225: Validation loss did not improve from -0.23061. Patience: 125/50
2024-12-14 17:27:28.202020: train_loss -0.9102
2024-12-14 17:27:28.202897: val_loss 0.1428
2024-12-14 17:27:28.203551: Pseudo dice [0.53]
2024-12-14 17:27:28.204280: Epoch time: 199.09 s
2024-12-14 17:27:29.562061: 
2024-12-14 17:27:29.563590: Epoch 133
2024-12-14 17:27:29.564819: Current learning rate: 0.00141
2024-12-14 17:30:43.092899: Validation loss did not improve from -0.23061. Patience: 126/50
2024-12-14 17:30:43.093521: train_loss -0.9106
2024-12-14 17:30:43.094157: val_loss 0.2171
2024-12-14 17:30:43.094758: Pseudo dice [0.5079]
2024-12-14 17:30:43.095387: Epoch time: 193.53 s
2024-12-14 17:30:44.454419: 
2024-12-14 17:30:44.455788: Epoch 134
2024-12-14 17:30:44.456737: Current learning rate: 0.00133
2024-12-14 17:34:35.821157: Validation loss did not improve from -0.23061. Patience: 127/50
2024-12-14 17:34:35.823446: train_loss -0.9103
2024-12-14 17:34:35.824937: val_loss 0.169
2024-12-14 17:34:35.825575: Pseudo dice [0.5212]
2024-12-14 17:34:35.826560: Epoch time: 231.37 s
2024-12-14 17:34:37.634327: 
2024-12-14 17:34:37.635516: Epoch 135
2024-12-14 17:34:37.636143: Current learning rate: 0.00126
2024-12-14 17:38:06.976717: Validation loss did not improve from -0.23061. Patience: 128/50
2024-12-14 17:38:06.978046: train_loss -0.9111
2024-12-14 17:38:06.978893: val_loss 0.0969
2024-12-14 17:38:06.979617: Pseudo dice [0.5294]
2024-12-14 17:38:06.980260: Epoch time: 209.34 s
2024-12-14 17:38:08.368982: 
2024-12-14 17:38:08.370215: Epoch 136
2024-12-14 17:38:08.371031: Current learning rate: 0.00118
2024-12-14 17:41:55.442937: Validation loss did not improve from -0.23061. Patience: 129/50
2024-12-14 17:41:55.443811: train_loss -0.9103
2024-12-14 17:41:55.444727: val_loss 0.2259
2024-12-14 17:41:55.445809: Pseudo dice [0.5098]
2024-12-14 17:41:55.446480: Epoch time: 227.08 s
2024-12-14 17:41:56.829499: 
2024-12-14 17:41:56.830603: Epoch 137
2024-12-14 17:41:56.831396: Current learning rate: 0.00111
2024-12-14 17:46:51.970018: Validation loss did not improve from -0.23061. Patience: 130/50
2024-12-14 17:46:51.971061: train_loss -0.9124
2024-12-14 17:46:51.971768: val_loss 0.126
2024-12-14 17:46:51.972462: Pseudo dice [0.543]
2024-12-14 17:46:51.973157: Epoch time: 295.14 s
2024-12-14 17:46:53.362579: 
2024-12-14 17:46:53.363667: Epoch 138
2024-12-14 17:46:53.364319: Current learning rate: 0.00103
2024-12-14 17:50:19.143523: Validation loss did not improve from -0.23061. Patience: 131/50
2024-12-14 17:50:19.145338: train_loss -0.9124
2024-12-14 17:50:19.146346: val_loss 0.1457
2024-12-14 17:50:19.147069: Pseudo dice [0.53]
2024-12-14 17:50:19.147795: Epoch time: 205.78 s
2024-12-14 17:50:20.656046: 
2024-12-14 17:50:20.658428: Epoch 139
2024-12-14 17:50:20.659588: Current learning rate: 0.00095
2024-12-14 17:54:24.545978: Validation loss did not improve from -0.23061. Patience: 132/50
2024-12-14 17:54:24.559093: train_loss -0.9119
2024-12-14 17:54:24.560057: val_loss 0.1828
2024-12-14 17:54:24.560901: Pseudo dice [0.5047]
2024-12-14 17:54:24.561745: Epoch time: 243.91 s
2024-12-14 17:54:27.698001: 
2024-12-14 17:54:27.699486: Epoch 140
2024-12-14 17:54:27.700514: Current learning rate: 0.00087
2024-12-14 17:59:03.234965: Validation loss did not improve from -0.23061. Patience: 133/50
2024-12-14 17:59:03.235987: train_loss -0.9106
2024-12-14 17:59:03.237039: val_loss 0.2189
2024-12-14 17:59:03.238195: Pseudo dice [0.4984]
2024-12-14 17:59:03.239169: Epoch time: 275.54 s
2024-12-14 17:59:04.667704: 
2024-12-14 17:59:04.669088: Epoch 141
2024-12-14 17:59:04.670144: Current learning rate: 0.00079
2024-12-14 18:03:35.689919: Validation loss did not improve from -0.23061. Patience: 134/50
2024-12-14 18:03:35.691947: train_loss -0.9133
2024-12-14 18:03:35.692899: val_loss 0.1852
2024-12-14 18:03:35.693611: Pseudo dice [0.5132]
2024-12-14 18:03:35.694506: Epoch time: 271.03 s
2024-12-14 18:03:37.138859: 
2024-12-14 18:03:37.139937: Epoch 142
2024-12-14 18:03:37.140643: Current learning rate: 0.00071
2024-12-14 18:07:42.133389: Validation loss did not improve from -0.23061. Patience: 135/50
2024-12-14 18:07:42.134321: train_loss -0.9128
2024-12-14 18:07:42.135253: val_loss 0.2191
2024-12-14 18:07:42.135943: Pseudo dice [0.4891]
2024-12-14 18:07:42.136726: Epoch time: 245.0 s
2024-12-14 18:07:43.522719: 
2024-12-14 18:07:43.524096: Epoch 143
2024-12-14 18:07:43.524802: Current learning rate: 0.00063
2024-12-14 18:11:46.250671: Validation loss did not improve from -0.23061. Patience: 136/50
2024-12-14 18:11:46.251593: train_loss -0.9147
2024-12-14 18:11:46.252338: val_loss 0.1997
2024-12-14 18:11:46.253067: Pseudo dice [0.5131]
2024-12-14 18:11:46.253713: Epoch time: 242.73 s
2024-12-14 18:11:47.674671: 
2024-12-14 18:11:47.675769: Epoch 144
2024-12-14 18:11:47.676543: Current learning rate: 0.00055
2024-12-14 18:16:15.818337: Validation loss did not improve from -0.23061. Patience: 137/50
2024-12-14 18:16:15.819186: train_loss -0.9133
2024-12-14 18:16:15.820061: val_loss 0.098
2024-12-14 18:16:15.820875: Pseudo dice [0.5368]
2024-12-14 18:16:15.822083: Epoch time: 268.15 s
2024-12-14 18:16:17.597909: 
2024-12-14 18:16:17.599495: Epoch 145
2024-12-14 18:16:17.600452: Current learning rate: 0.00047
2024-12-14 18:20:07.941233: Validation loss did not improve from -0.23061. Patience: 138/50
2024-12-14 18:20:07.942274: train_loss -0.9134
2024-12-14 18:20:07.943430: val_loss 0.2347
2024-12-14 18:20:07.944442: Pseudo dice [0.5033]
2024-12-14 18:20:07.945230: Epoch time: 230.35 s
2024-12-14 18:20:09.349266: 
2024-12-14 18:20:09.350782: Epoch 146
2024-12-14 18:20:09.351761: Current learning rate: 0.00038
2024-12-14 18:25:06.436943: Validation loss did not improve from -0.23061. Patience: 139/50
2024-12-14 18:25:06.438005: train_loss -0.9146
2024-12-14 18:25:06.438650: val_loss 0.1553
2024-12-14 18:25:06.439390: Pseudo dice [0.5295]
2024-12-14 18:25:06.440015: Epoch time: 297.09 s
2024-12-14 18:25:07.846962: 
2024-12-14 18:25:07.848113: Epoch 147
2024-12-14 18:25:07.849281: Current learning rate: 0.0003
2024-12-14 18:28:56.509903: Validation loss did not improve from -0.23061. Patience: 140/50
2024-12-14 18:28:56.510898: train_loss -0.9144
2024-12-14 18:28:56.511681: val_loss 0.1475
2024-12-14 18:28:56.512288: Pseudo dice [0.5114]
2024-12-14 18:28:56.512856: Epoch time: 228.67 s
2024-12-14 18:28:57.905607: 
2024-12-14 18:28:57.906507: Epoch 148
2024-12-14 18:28:57.907159: Current learning rate: 0.00021
2024-12-14 18:33:06.689183: Validation loss did not improve from -0.23061. Patience: 141/50
2024-12-14 18:33:06.690261: train_loss -0.915
2024-12-14 18:33:06.691071: val_loss 0.2009
2024-12-14 18:33:06.691726: Pseudo dice [0.5206]
2024-12-14 18:33:06.692411: Epoch time: 248.79 s
2024-12-14 18:33:08.150171: 
2024-12-14 18:33:08.151422: Epoch 149
2024-12-14 18:33:08.152182: Current learning rate: 0.00011
2024-12-14 18:38:26.888362: Validation loss did not improve from -0.23061. Patience: 142/50
2024-12-14 18:38:26.889297: train_loss -0.9157
2024-12-14 18:38:26.890086: val_loss 0.2236
2024-12-14 18:38:26.890830: Pseudo dice [0.5137]
2024-12-14 18:38:26.891596: Epoch time: 318.74 s
2024-12-14 18:38:28.698015: Training done.
2024-12-14 18:38:28.903408: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset307_Sohee_Calcium_OCT_CrossValidation/splits_final_20.json
2024-12-14 18:38:28.910452: The split file contains 5 splits.
2024-12-14 18:38:28.911301: Desired fold for training: 0
2024-12-14 18:38:28.911975: This split has 1 training and 7 validation cases.
2024-12-14 18:38:28.912762: predicting 101-019
2024-12-14 18:38:28.953647: 101-019, shape torch.Size([1, 375, 498, 498]), rank 0
2024-12-14 18:41:48.704757: predicting 101-044
2024-12-14 18:41:48.720371: 101-044, shape torch.Size([1, 404, 498, 498]), rank 0
2024-12-14 18:44:14.834639: predicting 101-045
2024-12-14 18:44:14.855766: 101-045, shape torch.Size([1, 375, 498, 498]), rank 0
2024-12-14 18:46:14.682873: predicting 106-002
2024-12-14 18:46:14.707907: 106-002, shape torch.Size([1, 539, 498, 498]), rank 0
2024-12-14 18:49:24.661089: predicting 701-013
2024-12-14 18:49:24.981039: 701-013, shape torch.Size([1, 375, 498, 498]), rank 0
2024-12-14 18:51:44.417704: predicting 704-003
2024-12-14 18:51:44.437219: 704-003, shape torch.Size([1, 375, 498, 498]), rank 0
2024-12-14 18:53:43.020476: predicting 706-005
2024-12-14 18:53:43.040042: 706-005, shape torch.Size([1, 375, 498, 498]), rank 0
2024-12-14 18:56:14.353900: Validation complete
2024-12-14 18:56:14.355021: Mean Validation Dice:  0.5043703143316701

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2024-12-14 18:56:27.065374: Using torch.compile...

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2024-12-14 18:56:27.067043: Using torch.compile...
/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
################### Loading pretrained weights from file  /home/gridsan/nchutisilp/projects/OpenAI-CLIP/clip_preivl_poststent_pretrained_nnUNet.pt ###################
Below is the list of overlapping blocks in pretrained model and nnUNet architecture:
encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])
encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])
encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])
encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])
encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])
encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])
encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])
encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])
encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])
encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])
encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])
encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])
encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])
encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])
encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])
encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])
encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])
encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])
encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])
encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])
encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])
encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])
encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])
encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])
encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])
encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])
encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])
decoder.encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])
decoder.encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])
decoder.encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])
decoder.encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])
decoder.encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])
decoder.encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])
decoder.encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])
decoder.encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])
decoder.encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])
decoder.encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])
decoder.encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])
decoder.encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])
decoder.encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])
decoder.encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.stages.0.convs.0.conv.weight shape torch.Size([320, 640, 3, 3, 3])
decoder.stages.0.convs.0.conv.bias shape torch.Size([320])
decoder.stages.0.convs.0.norm.weight shape torch.Size([320])
decoder.stages.0.convs.0.norm.bias shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.0.weight shape torch.Size([320, 640, 3, 3, 3])
decoder.stages.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.stages.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.stages.0.convs.1.conv.bias shape torch.Size([320])
decoder.stages.0.convs.1.norm.weight shape torch.Size([320])
decoder.stages.0.convs.1.norm.bias shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.stages.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.stages.1.convs.0.conv.weight shape torch.Size([256, 512, 3, 3, 3])
decoder.stages.1.convs.0.conv.bias shape torch.Size([256])
decoder.stages.1.convs.0.norm.weight shape torch.Size([256])
decoder.stages.1.convs.0.norm.bias shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.0.weight shape torch.Size([256, 512, 3, 3, 3])
decoder.stages.1.convs.0.all_modules.0.bias shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.1.weight shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.1.bias shape torch.Size([256])
decoder.stages.1.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.stages.1.convs.1.conv.bias shape torch.Size([256])
decoder.stages.1.convs.1.norm.weight shape torch.Size([256])
decoder.stages.1.convs.1.norm.bias shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.stages.1.convs.1.all_modules.0.bias shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.1.weight shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.1.bias shape torch.Size([256])
decoder.stages.2.convs.0.conv.weight shape torch.Size([128, 256, 3, 3, 3])
decoder.stages.2.convs.0.conv.bias shape torch.Size([128])
decoder.stages.2.convs.0.norm.weight shape torch.Size([128])
decoder.stages.2.convs.0.norm.bias shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.0.weight shape torch.Size([128, 256, 3, 3, 3])
decoder.stages.2.convs.0.all_modules.0.bias shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.1.weight shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.1.bias shape torch.Size([128])
decoder.stages.2.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.stages.2.convs.1.conv.bias shape torch.Size([128])
decoder.stages.2.convs.1.norm.weight shape torch.Size([128])
decoder.stages.2.convs.1.norm.bias shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.stages.2.convs.1.all_modules.0.bias shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.1.weight shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.1.bias shape torch.Size([128])
decoder.stages.3.convs.0.conv.weight shape torch.Size([64, 128, 3, 3, 3])
decoder.stages.3.convs.0.conv.bias shape torch.Size([64])
decoder.stages.3.convs.0.norm.weight shape torch.Size([64])
decoder.stages.3.convs.0.norm.bias shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.0.weight shape torch.Size([64, 128, 3, 3, 3])
decoder.stages.3.convs.0.all_modules.0.bias shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.1.weight shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.1.bias shape torch.Size([64])
decoder.stages.3.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.stages.3.convs.1.conv.bias shape torch.Size([64])
decoder.stages.3.convs.1.norm.weight shape torch.Size([64])
decoder.stages.3.convs.1.norm.bias shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.stages.3.convs.1.all_modules.0.bias shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.1.weight shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.1.bias shape torch.Size([64])
decoder.stages.4.convs.0.conv.weight shape torch.Size([32, 64, 3, 3, 3])
decoder.stages.4.convs.0.conv.bias shape torch.Size([32])
decoder.stages.4.convs.0.norm.weight shape torch.Size([32])
decoder.stages.4.convs.0.norm.bias shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.0.weight shape torch.Size([32, 64, 3, 3, 3])
decoder.stages.4.convs.0.all_modules.0.bias shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.1.weight shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.1.bias shape torch.Size([32])
decoder.stages.4.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.stages.4.convs.1.conv.bias shape torch.Size([32])
decoder.stages.4.convs.1.norm.weight shape torch.Size([32])
decoder.stages.4.convs.1.norm.bias shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.stages.4.convs.1.all_modules.0.bias shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.1.weight shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.1.bias shape torch.Size([32])
decoder.transpconvs.0.weight shape torch.Size([320, 320, 1, 2, 2])
decoder.transpconvs.0.bias shape torch.Size([320])
decoder.transpconvs.1.weight shape torch.Size([320, 256, 2, 2, 2])
decoder.transpconvs.1.bias shape torch.Size([256])
decoder.transpconvs.2.weight shape torch.Size([256, 128, 2, 2, 2])
decoder.transpconvs.2.bias shape torch.Size([128])
decoder.transpconvs.3.weight shape torch.Size([128, 64, 2, 2, 2])
decoder.transpconvs.3.bias shape torch.Size([64])
decoder.transpconvs.4.weight shape torch.Size([64, 32, 2, 2, 2])
decoder.transpconvs.4.bias shape torch.Size([32])
################### Done ###################
2024-12-14 18:56:33.178398: do_dummy_2d_data_aug: True
2024-12-14 18:56:33.180503: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset307_Sohee_Calcium_OCT_CrossValidation/splits_final_20.json
2024-12-14 18:56:33.182823: The split file contains 5 splits.
2024-12-14 18:56:33.184119: Desired fold for training: 2
2024-12-14 18:56:33.185245: This split has 1 training and 7 validation cases.
################### Loading pretrained weights from file  /home/gridsan/nchutisilp/projects/OpenAI-CLIP/clip_preivl_poststent_pretrained_nnUNet.pt ###################
Below is the list of overlapping blocks in pretrained model and nnUNet architecture:
encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])
encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])
encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])
encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])
encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])
encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])
encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])
encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])
encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])
encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])
encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])
encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])
encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])
encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])
encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])
encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])
encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])
encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])
encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])
encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])
encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])
encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])
encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])
encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])
encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])
encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])
encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])
decoder.encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])
decoder.encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])
decoder.encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])
decoder.encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])
decoder.encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])
decoder.encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])
decoder.encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])
decoder.encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])
decoder.encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])
decoder.encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])
decoder.encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])
decoder.encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])
decoder.encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])
decoder.encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.stages.0.convs.0.conv.weight shape torch.Size([320, 640, 3, 3, 3])
decoder.stages.0.convs.0.conv.bias shape torch.Size([320])
decoder.stages.0.convs.0.norm.weight shape torch.Size([320])
decoder.stages.0.convs.0.norm.bias shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.0.weight shape torch.Size([320, 640, 3, 3, 3])
decoder.stages.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.stages.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.stages.0.convs.1.conv.bias shape torch.Size([320])
decoder.stages.0.convs.1.norm.weight shape torch.Size([320])
decoder.stages.0.convs.1.norm.bias shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.stages.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.stages.1.convs.0.conv.weight shape torch.Size([256, 512, 3, 3, 3])
decoder.stages.1.convs.0.conv.bias shape torch.Size([256])
decoder.stages.1.convs.0.norm.weight shape torch.Size([256])
decoder.stages.1.convs.0.norm.bias shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.0.weight shape torch.Size([256, 512, 3, 3, 3])
decoder.stages.1.convs.0.all_modules.0.bias shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.1.weight shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.1.bias shape torch.Size([256])
decoder.stages.1.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.stages.1.convs.1.conv.bias shape torch.Size([256])
decoder.stages.1.convs.1.norm.weight shape torch.Size([256])
decoder.stages.1.convs.1.norm.bias shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.stages.1.convs.1.all_modules.0.bias shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.1.weight shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.1.bias shape torch.Size([256])
decoder.stages.2.convs.0.conv.weight shape torch.Size([128, 256, 3, 3, 3])
decoder.stages.2.convs.0.conv.bias shape torch.Size([128])
decoder.stages.2.convs.0.norm.weight shape torch.Size([128])
decoder.stages.2.convs.0.norm.bias shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.0.weight shape torch.Size([128, 256, 3, 3, 3])
decoder.stages.2.convs.0.all_modules.0.bias shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.1.weight shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.1.bias shape torch.Size([128])
decoder.stages.2.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.stages.2.convs.1.conv.bias shape torch.Size([128])
decoder.stages.2.convs.1.norm.weight shape torch.Size([128])
decoder.stages.2.convs.1.norm.bias shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.stages.2.convs.1.all_modules.0.bias shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.1.weight shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.1.bias shape torch.Size([128])
decoder.stages.3.convs.0.conv.weight shape torch.Size([64, 128, 3, 3, 3])
decoder.stages.3.convs.0.conv.bias shape torch.Size([64])
decoder.stages.3.convs.0.norm.weight shape torch.Size([64])
decoder.stages.3.convs.0.norm.bias shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.0.weight shape torch.Size([64, 128, 3, 3, 3])
decoder.stages.3.convs.0.all_modules.0.bias shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.1.weight shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.1.bias shape torch.Size([64])
decoder.stages.3.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.stages.3.convs.1.conv.bias shape torch.Size([64])
decoder.stages.3.convs.1.norm.weight shape torch.Size([64])
decoder.stages.3.convs.1.norm.bias shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.stages.3.convs.1.all_modules.0.bias shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.1.weight shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.1.bias shape torch.Size([64])
decoder.stages.4.convs.0.conv.weight shape torch.Size([32, 64, 3, 3, 3])
decoder.stages.4.convs.0.conv.bias shape torch.Size([32])
decoder.stages.4.convs.0.norm.weight shape torch.Size([32])
decoder.stages.4.convs.0.norm.bias shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.0.weight shape torch.Size([32, 64, 3, 3, 3])
decoder.stages.4.convs.0.all_modules.0.bias shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.1.weight shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.1.bias shape torch.Size([32])
decoder.stages.4.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.stages.4.convs.1.conv.bias shape torch.Size([32])
decoder.stages.4.convs.1.norm.weight shape torch.Size([32])
decoder.stages.4.convs.1.norm.bias shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.stages.4.convs.1.all_modules.0.bias shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.1.weight shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.1.bias shape torch.Size([32])
decoder.transpconvs.0.weight shape torch.Size([320, 320, 1, 2, 2])
decoder.transpconvs.0.bias shape torch.Size([320])
decoder.transpconvs.1.weight shape torch.Size([320, 256, 2, 2, 2])
decoder.transpconvs.1.bias shape torch.Size([256])
decoder.transpconvs.2.weight shape torch.Size([256, 128, 2, 2, 2])
decoder.transpconvs.2.bias shape torch.Size([128])
decoder.transpconvs.3.weight shape torch.Size([128, 64, 2, 2, 2])
decoder.transpconvs.3.bias shape torch.Size([64])
decoder.transpconvs.4.weight shape torch.Size([64, 32, 2, 2, 2])
decoder.transpconvs.4.bias shape torch.Size([32])
################### Done ###################
2024-12-14 18:56:33.178380: do_dummy_2d_data_aug: True
2024-12-14 18:56:33.180530: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset307_Sohee_Calcium_OCT_CrossValidation/splits_final_20.json
2024-12-14 18:56:33.183115: The split file contains 5 splits.
2024-12-14 18:56:33.184385: Desired fold for training: 3
2024-12-14 18:56:33.185542: This split has 1 training and 7 validation cases.
using pin_memory on device 0
using pin_memory on device 0
using pin_memory on device 0

This is the configuration used by this training:
Configuration name: 3d_32x160x128_b10
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 10, 'patch_size': [32, 160, 128], 'median_image_size_in_voxels': [375.0, 498.0, 498.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'inherits_from': '3d_fullres'} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset307_Sohee_Calcium_OCT_CrossValidation', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.4977976381778717, 'mean': 0.13507525622844696, 'median': 0.09599608182907104, 'min': 0.0, 'percentile_00_5': 0.014754901640117168, 'percentile_99_5': 0.4977976381778717, 'std': 0.12025152146816254}}} 

2024-12-14 18:57:12.587543: unpacking dataset...
using pin_memory on device 0

This is the configuration used by this training:
Configuration name: 3d_32x160x128_b10
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 10, 'patch_size': [32, 160, 128], 'median_image_size_in_voxels': [375.0, 498.0, 498.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'inherits_from': '3d_fullres'} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset307_Sohee_Calcium_OCT_CrossValidation', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.4977976381778717, 'mean': 0.13507525622844696, 'median': 0.09599608182907104, 'min': 0.0, 'percentile_00_5': 0.014754901640117168, 'percentile_99_5': 0.4977976381778717, 'std': 0.12025152146816254}}} 

2024-12-14 18:57:13.690642: unpacking dataset...
2024-12-14 18:57:16.877693: unpacking done...
2024-12-14 18:57:17.032533: Unable to plot network architecture: nnUNet_compile is enabled!
2024-12-14 18:57:17.227262: 
2024-12-14 18:57:17.228231: Epoch 0
2024-12-14 18:57:17.229013: Current learning rate: 0.01
2024-12-14 18:57:18.002172: unpacking done...
2024-12-14 18:57:18.010488: Unable to plot network architecture: nnUNet_compile is enabled!
2024-12-14 18:57:18.050805: 
2024-12-14 18:57:18.055112: Epoch 0
2024-12-14 18:57:18.056659: Current learning rate: 0.01
concurrent.futures.process._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/concurrent/futures/process.py", line 246, in _process_worker
    r = call_item.fn(*call_item.args, **call_item.kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/codecache.py", line 2492, in _worker_compile
    kernel = TritonCodeCache.load(kernel_name, source_code)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/codecache.py", line 2205, in load
    mod = PyCodeCache.load(source_code)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/codecache.py", line 2137, in load
    return cls.load_by_key_path(key, path, linemap, attrs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/codecache.py", line 2160, in load_by_key_path
    exec(code, mod.__dict__, mod.__dict__)
  File "/state/partition1/slurm_tmp/27610623.4294967291.0/torchinductor_nchutisilp/mi/cmiw2qf7itcobuks3gbegnakrhpe7ottqryxbfonhlv6ftvemsk5.py", line 12, in <module>
    @triton_heuristics.persistent_reduction(
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/triton_heuristics.py", line 1366, in persistent_reduction
    return cached_autotune(
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/triton_heuristics.py", line 883, in cached_autotune
    best_config = json.loads(fd.read())
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/json/decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 159 (char 158)
"""
concurrent.futures.process._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/concurrent/futures/process.py", line 246, in _process_worker
    r = call_item.fn(*call_item.args, **call_item.kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/codecache.py", line 2492, in _worker_compile
    kernel = TritonCodeCache.load(kernel_name, source_code)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/codecache.py", line 2205, in load
    mod = PyCodeCache.load(source_code)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/codecache.py", line 2137, in load
    return cls.load_by_key_path(key, path, linemap, attrs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/codecache.py", line 2160, in load_by_key_path
    exec(code, mod.__dict__, mod.__dict__)
  File "/state/partition1/slurm_tmp/27610623.4294967291.0/torchinductor_nchutisilp/mi/cmiw2qf7itcobuks3gbegnakrhpe7ottqryxbfonhlv6ftvemsk5.py", line 12, in <module>
    @triton_heuristics.persistent_reduction(
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/triton_heuristics.py", line 1366, in persistent_reduction
    return cached_autotune(
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/triton_heuristics.py", line 883, in cached_autotune
    best_config = json.loads(fd.read())
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/json/decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 159 (char 158)
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):

The above exception was the direct cause of the following exception:

  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/bin/nnUNetv2_train", line 8, in <module>
Traceback (most recent call last):
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/bin/nnUNetv2_train", line 8, in <module>
    sys.exit(run_training_entry())
  File "/home/gridsan/nchutisilp/projects/nnUNet/nnunetv2/run/run_training.py", line 275, in run_training_entry
    sys.exit(run_training_entry())
  File "/home/gridsan/nchutisilp/projects/nnUNet/nnunetv2/run/run_training.py", line 275, in run_training_entry
    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,
  File "/home/gridsan/nchutisilp/projects/nnUNet/nnunetv2/run/run_training.py", line 211, in run_training
    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,
  File "/home/gridsan/nchutisilp/projects/nnUNet/nnunetv2/run/run_training.py", line 211, in run_training
    nnunet_trainer.run_training()
  File "/home/gridsan/nchutisilp/projects/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py", line 1399, in run_training
    nnunet_trainer.run_training()
  File "/home/gridsan/nchutisilp/projects/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py", line 1399, in run_training
    train_outputs.append(self.train_step(next(self.dataloader_train)))
  File "/home/gridsan/nchutisilp/projects/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py", line 1014, in train_step
    train_outputs.append(self.train_step(next(self.dataloader_train)))
  File "/home/gridsan/nchutisilp/projects/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py", line 1014, in train_step
    self.grad_scaler.scale(l).backward()
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_tensor.py", line 525, in backward
    self.grad_scaler.scale(l).backward()
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/autograd/__init__.py", line 267, in backward
    torch.autograd.backward(
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    _engine_run_backward(
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/autograd/function.py", line 301, in apply
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/autograd/function.py", line 301, in apply
    return user_fn(self, *args)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 882, in backward
    return user_fn(self, *args)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 882, in backward
    out = call_compiled_backward()
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 827, in call_compiled_backward
    out = call_compiled_backward()
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 827, in call_compiled_backward
    CompiledFunction.compiled_bw = aot_config.bw_compiler(
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_dynamo/backends/common.py", line 36, in _wrapped_bw_compiler
    CompiledFunction.compiled_bw = aot_config.bw_compiler(
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_dynamo/backends/common.py", line 36, in _wrapped_bw_compiler
    return disable(disable(bw_compiler)(*args, **kwargs))
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py", line 451, in _fn
    return disable(disable(bw_compiler)(*args, **kwargs))
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py", line 451, in _fn
    return fn(*args, **kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_dynamo/external_utils.py", line 36, in inner
    return fn(*args, **kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_dynamo/external_utils.py", line 36, in inner
    return fn(*args, **kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_dynamo/utils.py", line 262, in time_wrapper
    return fn(*args, **kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_dynamo/utils.py", line 262, in time_wrapper
    r = func(*args, **kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/compile_fx.py", line 1293, in bw_compiler
    r = func(*args, **kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/compile_fx.py", line 1293, in bw_compiler
    return inner_compile(
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
    return inner_compile(
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
    inner_compiled_fn = compiler_fn(gm, example_inputs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/debug.py", line 304, in inner
    inner_compiled_fn = compiler_fn(gm, example_inputs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/debug.py", line 304, in inner
    return fn(*args, **kwargs)
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
    return fn(*args, **kwargs)
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/contextlib.py", line 79, in inner
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_dynamo/utils.py", line 262, in time_wrapper
    return func(*args, **kwds)
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_dynamo/utils.py", line 262, in time_wrapper
    r = func(*args, **kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/compile_fx.py", line 438, in compile_fx_inner
    r = func(*args, **kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/compile_fx.py", line 438, in compile_fx_inner
    compiled_graph = fx_codegen_and_compile(
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/compile_fx.py", line 714, in fx_codegen_and_compile
    compiled_graph = fx_codegen_and_compile(
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/compile_fx.py", line 714, in fx_codegen_and_compile
    compiled_fn = graph.compile_to_fn()
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/graph.py", line 1307, in compile_to_fn
    compiled_fn = graph.compile_to_fn()
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/graph.py", line 1307, in compile_to_fn
    return self.compile_to_module().call
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_dynamo/utils.py", line 262, in time_wrapper
    r = func(*args, **kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/graph.py", line 1254, in compile_to_module
    return self.compile_to_module().call
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_dynamo/utils.py", line 262, in time_wrapper
    r = func(*args, **kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/graph.py", line 1254, in compile_to_module
    mod = PyCodeCache.load_by_key_path(
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/codecache.py", line 2160, in load_by_key_path
    mod = PyCodeCache.load_by_key_path(
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/codecache.py", line 2160, in load_by_key_path
    exec(code, mod.__dict__, mod.__dict__)
  File "/state/partition1/slurm_tmp/27610623.4294967291.0/torchinductor_nchutisilp/fk/cfkzw4jvrpa2bhvdgnufitgyufd6rqae4wpy5abnrfmhcvecqets.py", line 3651, in <module>
    exec(code, mod.__dict__, mod.__dict__)
  File "/state/partition1/slurm_tmp/27610623.4294967291.0/torchinductor_nchutisilp/fk/cfkzw4jvrpa2bhvdgnufitgyufd6rqae4wpy5abnrfmhcvecqets.py", line 3651, in <module>
    async_compile.wait(globals())
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/codecache.py", line 2715, in wait
    async_compile.wait(globals())
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/codecache.py", line 2715, in wait
    scope[key] = result.result()
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/codecache.py", line 2522, in result
    self.future.result()
    scope[key] = result.result()
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/codecache.py", line 2522, in result
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/concurrent/futures/_base.py", line 439, in result
    self.future.result()
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/concurrent/futures/_base.py", line 439, in result
    return self.__get_result()
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/concurrent/futures/_base.py", line 391, in __get_result
    return self.__get_result()
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/concurrent/futures/_base.py", line 391, in __get_result
    raise self._exception
json.decoder.JSONDecodeError: Extra data: line 1 column 159 (char 158)
    raise self._exception
json.decoder.JSONDecodeError: Extra data: line 1 column 159 (char 158)
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/threading.py", line 980, in _bootstrap_inner
Exception in thread Thread-2:
Traceback (most recent call last):
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/threading.py", line 980, in _bootstrap_inner
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/threading.py", line 980, in _bootstrap_inner
Exception in thread Thread-2:
Traceback (most recent call last):
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/threading.py", line 980, in _bootstrap_inner
    self.run()
    self.run()
    self.run()
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/threading.py", line 917, in run
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/threading.py", line 917, in run
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/threading.py", line 917, in run
    self.run()
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/threading.py", line 917, in run
    self._target(*self._args, **self._kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py", line 125, in results_loop
    self._target(*self._args, **self._kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py", line 125, in results_loop
    self._target(*self._args, **self._kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py", line 125, in results_loop
    self._target(*self._args, **self._kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py", line 125, in results_loop
    raise e
    raise e
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py", line 103, in results_loop
    raise e
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py", line 103, in results_loop
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py", line 103, in results_loop
    raise RuntimeError("One or more background workers are no longer alive. Exiting. Please check the "
RuntimeError: One or more background workers are no longer alive. Exiting. Please check the print statements above for the actual error message
    raise RuntimeError("One or more background workers are no longer alive. Exiting. Please check the "
RuntimeError: One or more background workers are no longer alive. Exiting. Please check the print statements above for the actual error message

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2024-12-14 18:58:06.494697: Using torch.compile...
/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
################### Loading pretrained weights from file  /home/gridsan/nchutisilp/projects/OpenAI-CLIP/clip_preivl_poststent_pretrained_nnUNet.pt ###################
Below is the list of overlapping blocks in pretrained model and nnUNet architecture:
encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])
encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])
encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])
encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])
encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])
encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])
encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])
encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])
encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])
encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])
encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])
encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])
encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])
encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])
encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])
encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])
encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])
encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])
encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])
encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])
encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])
encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])
encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])
encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])
encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])
encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])
encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])
decoder.encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])
decoder.encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])
decoder.encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])
decoder.encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])
decoder.encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])
decoder.encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])
decoder.encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])
decoder.encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])
decoder.encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])
decoder.encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])
decoder.encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])
decoder.encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])
decoder.encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])
decoder.encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.stages.0.convs.0.conv.weight shape torch.Size([320, 640, 3, 3, 3])
decoder.stages.0.convs.0.conv.bias shape torch.Size([320])
decoder.stages.0.convs.0.norm.weight shape torch.Size([320])
decoder.stages.0.convs.0.norm.bias shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.0.weight shape torch.Size([320, 640, 3, 3, 3])
decoder.stages.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.stages.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.stages.0.convs.1.conv.bias shape torch.Size([320])
decoder.stages.0.convs.1.norm.weight shape torch.Size([320])
decoder.stages.0.convs.1.norm.bias shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.stages.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.stages.1.convs.0.conv.weight shape torch.Size([256, 512, 3, 3, 3])
decoder.stages.1.convs.0.conv.bias shape torch.Size([256])
decoder.stages.1.convs.0.norm.weight shape torch.Size([256])
decoder.stages.1.convs.0.norm.bias shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.0.weight shape torch.Size([256, 512, 3, 3, 3])
decoder.stages.1.convs.0.all_modules.0.bias shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.1.weight shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.1.bias shape torch.Size([256])
decoder.stages.1.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.stages.1.convs.1.conv.bias shape torch.Size([256])
decoder.stages.1.convs.1.norm.weight shape torch.Size([256])
decoder.stages.1.convs.1.norm.bias shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.stages.1.convs.1.all_modules.0.bias shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.1.weight shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.1.bias shape torch.Size([256])
decoder.stages.2.convs.0.conv.weight shape torch.Size([128, 256, 3, 3, 3])
decoder.stages.2.convs.0.conv.bias shape torch.Size([128])
decoder.stages.2.convs.0.norm.weight shape torch.Size([128])
decoder.stages.2.convs.0.norm.bias shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.0.weight shape torch.Size([128, 256, 3, 3, 3])
decoder.stages.2.convs.0.all_modules.0.bias shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.1.weight shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.1.bias shape torch.Size([128])
decoder.stages.2.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.stages.2.convs.1.conv.bias shape torch.Size([128])
decoder.stages.2.convs.1.norm.weight shape torch.Size([128])
decoder.stages.2.convs.1.norm.bias shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.stages.2.convs.1.all_modules.0.bias shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.1.weight shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.1.bias shape torch.Size([128])
decoder.stages.3.convs.0.conv.weight shape torch.Size([64, 128, 3, 3, 3])
decoder.stages.3.convs.0.conv.bias shape torch.Size([64])
decoder.stages.3.convs.0.norm.weight shape torch.Size([64])
decoder.stages.3.convs.0.norm.bias shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.0.weight shape torch.Size([64, 128, 3, 3, 3])
decoder.stages.3.convs.0.all_modules.0.bias shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.1.weight shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.1.bias shape torch.Size([64])
decoder.stages.3.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.stages.3.convs.1.conv.bias shape torch.Size([64])
decoder.stages.3.convs.1.norm.weight shape torch.Size([64])
decoder.stages.3.convs.1.norm.bias shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.stages.3.convs.1.all_modules.0.bias shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.1.weight shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.1.bias shape torch.Size([64])
decoder.stages.4.convs.0.conv.weight shape torch.Size([32, 64, 3, 3, 3])
decoder.stages.4.convs.0.conv.bias shape torch.Size([32])
decoder.stages.4.convs.0.norm.weight shape torch.Size([32])
decoder.stages.4.convs.0.norm.bias shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.0.weight shape torch.Size([32, 64, 3, 3, 3])
decoder.stages.4.convs.0.all_modules.0.bias shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.1.weight shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.1.bias shape torch.Size([32])
decoder.stages.4.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.stages.4.convs.1.conv.bias shape torch.Size([32])
decoder.stages.4.convs.1.norm.weight shape torch.Size([32])
decoder.stages.4.convs.1.norm.bias shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.stages.4.convs.1.all_modules.0.bias shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.1.weight shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.1.bias shape torch.Size([32])
decoder.transpconvs.0.weight shape torch.Size([320, 320, 1, 2, 2])
decoder.transpconvs.0.bias shape torch.Size([320])
decoder.transpconvs.1.weight shape torch.Size([320, 256, 2, 2, 2])
decoder.transpconvs.1.bias shape torch.Size([256])
decoder.transpconvs.2.weight shape torch.Size([256, 128, 2, 2, 2])
decoder.transpconvs.2.bias shape torch.Size([128])
decoder.transpconvs.3.weight shape torch.Size([128, 64, 2, 2, 2])
decoder.transpconvs.3.bias shape torch.Size([64])
decoder.transpconvs.4.weight shape torch.Size([64, 32, 2, 2, 2])
decoder.transpconvs.4.bias shape torch.Size([32])
################### Done ###################
2024-12-14 18:58:07.317921: do_dummy_2d_data_aug: True
2024-12-14 18:58:07.319754: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset307_Sohee_Calcium_OCT_CrossValidation/splits_final_20.json
2024-12-14 18:58:07.322530: The split file contains 5 splits.
2024-12-14 18:58:07.323696: Desired fold for training: 4
2024-12-14 18:58:07.324935: This split has 1 training and 7 validation cases.
using pin_memory on device 0
using pin_memory on device 0

This is the configuration used by this training:
Configuration name: 3d_32x160x128_b10
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 10, 'patch_size': [32, 160, 128], 'median_image_size_in_voxels': [375.0, 498.0, 498.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'inherits_from': '3d_fullres'} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset307_Sohee_Calcium_OCT_CrossValidation', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.4977976381778717, 'mean': 0.13507525622844696, 'median': 0.09599608182907104, 'min': 0.0, 'percentile_00_5': 0.014754901640117168, 'percentile_99_5': 0.4977976381778717, 'std': 0.12025152146816254}}} 

2024-12-14 18:58:37.348666: unpacking dataset...
2024-12-14 18:58:41.508085: unpacking done...
2024-12-14 18:58:41.516385: Unable to plot network architecture: nnUNet_compile is enabled!
2024-12-14 18:58:41.554814: 
2024-12-14 18:58:41.556014: Epoch 0
2024-12-14 18:58:41.557410: Current learning rate: 0.01
concurrent.futures.process._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/concurrent/futures/process.py", line 246, in _process_worker
    r = call_item.fn(*call_item.args, **call_item.kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/codecache.py", line 2492, in _worker_compile
    kernel = TritonCodeCache.load(kernel_name, source_code)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/codecache.py", line 2205, in load
    mod = PyCodeCache.load(source_code)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/codecache.py", line 2137, in load
    return cls.load_by_key_path(key, path, linemap, attrs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/codecache.py", line 2160, in load_by_key_path
    exec(code, mod.__dict__, mod.__dict__)
  File "/state/partition1/slurm_tmp/27610623.4294967291.0/torchinductor_nchutisilp/mi/cmiw2qf7itcobuks3gbegnakrhpe7ottqryxbfonhlv6ftvemsk5.py", line 12, in <module>
    @triton_heuristics.persistent_reduction(
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/triton_heuristics.py", line 1366, in persistent_reduction
    return cached_autotune(
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/triton_heuristics.py", line 883, in cached_autotune
    best_config = json.loads(fd.read())
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/json/decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 159 (char 158)
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/bin/nnUNetv2_train", line 8, in <module>
    sys.exit(run_training_entry())
  File "/home/gridsan/nchutisilp/projects/nnUNet/nnunetv2/run/run_training.py", line 275, in run_training_entry
    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,
  File "/home/gridsan/nchutisilp/projects/nnUNet/nnunetv2/run/run_training.py", line 211, in run_training
    nnunet_trainer.run_training()
  File "/home/gridsan/nchutisilp/projects/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py", line 1399, in run_training
    train_outputs.append(self.train_step(next(self.dataloader_train)))
  File "/home/gridsan/nchutisilp/projects/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py", line 1014, in train_step
    self.grad_scaler.scale(l).backward()
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/autograd/function.py", line 301, in apply
    return user_fn(self, *args)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 882, in backward
    out = call_compiled_backward()
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 827, in call_compiled_backward
    CompiledFunction.compiled_bw = aot_config.bw_compiler(
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_dynamo/backends/common.py", line 36, in _wrapped_bw_compiler
    return disable(disable(bw_compiler)(*args, **kwargs))
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py", line 451, in _fn
    return fn(*args, **kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_dynamo/external_utils.py", line 36, in inner
    return fn(*args, **kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_dynamo/utils.py", line 262, in time_wrapper
    r = func(*args, **kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/compile_fx.py", line 1293, in bw_compiler
    return inner_compile(
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_dynamo/repro/after_aot.py", line 83, in debug_wrapper
    inner_compiled_fn = compiler_fn(gm, example_inputs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/debug.py", line 304, in inner
    return fn(*args, **kwargs)
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_dynamo/utils.py", line 262, in time_wrapper
    r = func(*args, **kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/compile_fx.py", line 438, in compile_fx_inner
    compiled_graph = fx_codegen_and_compile(
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/compile_fx.py", line 714, in fx_codegen_and_compile
    compiled_fn = graph.compile_to_fn()
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/graph.py", line 1307, in compile_to_fn
    return self.compile_to_module().call
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_dynamo/utils.py", line 262, in time_wrapper
    r = func(*args, **kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/graph.py", line 1254, in compile_to_module
    mod = PyCodeCache.load_by_key_path(
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/codecache.py", line 2160, in load_by_key_path
    exec(code, mod.__dict__, mod.__dict__)
  File "/state/partition1/slurm_tmp/27610623.4294967291.0/torchinductor_nchutisilp/fk/cfkzw4jvrpa2bhvdgnufitgyufd6rqae4wpy5abnrfmhcvecqets.py", line 3651, in <module>
    async_compile.wait(globals())
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/codecache.py", line 2715, in wait
    scope[key] = result.result()
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/_inductor/codecache.py", line 2522, in result
    self.future.result()
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/concurrent/futures/_base.py", line 439, in result
    return self.__get_result()
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/concurrent/futures/_base.py", line 391, in __get_result
    raise self._exception
json.decoder.JSONDecodeError: Extra data: line 1 column 159 (char 158)
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/threading.py", line 980, in _bootstrap_inner
Exception in thread Thread-2:
Traceback (most recent call last):
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/threading.py", line 980, in _bootstrap_inner
    self.run()
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/threading.py", line 917, in run
    self._target(*self._args, **self._kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py", line 125, in results_loop
    self.run()
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/threading.py", line 917, in run
    raise e
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py", line 103, in results_loop
    self._target(*self._args, **self._kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py", line 125, in results_loop
    raise RuntimeError("One or more background workers are no longer alive. Exiting. Please check the "
RuntimeError: One or more background workers are no longer alive. Exiting. Please check the print statements above for the actual error message
    raise e
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py", line 103, in results_loop
    raise RuntimeError("One or more background workers are no longer alive. Exiting. Please check the "
RuntimeError: One or more background workers are no longer alive. Exiting. Please check the print statements above for the actual error message
