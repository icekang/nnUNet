/home/gridsan/nchutisilp/.conda/envs/nnunet/bin/python
wandb: Tracking run with wandb version 0.16.6
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2024-05-07 13:59:32.752599: do_dummy_2d_data_aug: True
2024-05-07 13:59:32.756855: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset302_Calcium_OCTv2/splits_final.json
2024-05-07 13:59:32.774006: The split file contains 3 splits.
2024-05-07 13:59:32.775442: Desired fold for training: 0
2024-05-07 13:59:32.777030: This split has 4 training and 2 validation cases.
using pin_memory on device 0
using pin_memory on device 0
2024-05-07 14:00:02.039364: Using torch.compile...
/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "

This is the configuration used by this training:
Configuration name: 3d_128x512x512_b10
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [32, 512, 512], 'median_image_size_in_voxels': [375.0, 498.0, 498.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'inherits_from': '3d_fullres'} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset302_Calcium_OCTv2', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.4977976381778717, 'mean': 0.13332499563694, 'median': 0.08871842920780182, 'min': 0.0, 'percentile_00_5': 0.014754901640117168, 'percentile_99_5': 0.4977976381778717, 'std': 0.12022686749696732}}} 

2024-05-07 14:00:15.806397: unpacking dataset...
2024-05-07 14:00:21.747631: unpacking done...
2024-05-07 14:00:21.787767: Unable to plot network architecture: nnUNet_compile is enabled!
2024-05-07 14:00:22.208559: 
2024-05-07 14:00:22.210419: Epoch 0
2024-05-07 14:00:22.213099: Current learning rate: 0.01
2024-05-07 14:07:07.607777: Validation loss improved from 1000.00000 to -0.28147! Patience: 0/50
2024-05-07 14:07:07.611226: train_loss -0.2202
2024-05-07 14:07:07.613272: val_loss -0.2815
2024-05-07 14:07:07.614519: Pseudo dice [0.4595]
2024-05-07 14:07:07.615930: Epoch time: 405.4 s
2024-05-07 14:07:07.617037: Yayy! New best EMA pseudo Dice: 0.4595
2024-05-07 14:07:09.158339: 
2024-05-07 14:07:09.162281: Epoch 1
2024-05-07 14:07:09.164002: Current learning rate: 0.00999
2024-05-07 14:11:04.593418: Validation loss did not improve from -0.28147. Patience: 1/50
2024-05-07 14:11:04.597418: train_loss -0.3712
2024-05-07 14:11:04.599206: val_loss -0.2557
2024-05-07 14:11:04.600624: Pseudo dice [0.4776]
2024-05-07 14:11:04.601615: Epoch time: 235.44 s
2024-05-07 14:11:04.602884: Yayy! New best EMA pseudo Dice: 0.4613
2024-05-07 14:11:06.176357: 
2024-05-07 14:11:06.180654: Epoch 2
2024-05-07 14:11:06.182549: Current learning rate: 0.00998
2024-05-07 14:14:59.253408: Validation loss improved from -0.28147 to -0.31794! Patience: 1/50
2024-05-07 14:14:59.257066: train_loss -0.3933
2024-05-07 14:14:59.259818: val_loss -0.3179
2024-05-07 14:14:59.261653: Pseudo dice [0.5078]
2024-05-07 14:14:59.263020: Epoch time: 233.08 s
2024-05-07 14:14:59.264311: Yayy! New best EMA pseudo Dice: 0.466
2024-05-07 14:15:00.896771: 
2024-05-07 14:15:00.900568: Epoch 3
2024-05-07 14:15:00.902260: Current learning rate: 0.00997
2024-05-07 14:18:54.533448: Validation loss improved from -0.31794 to -0.31931! Patience: 0/50
2024-05-07 14:18:54.536595: train_loss -0.435
2024-05-07 14:18:54.538434: val_loss -0.3193
2024-05-07 14:18:54.539898: Pseudo dice [0.515]
2024-05-07 14:18:54.541199: Epoch time: 233.64 s
2024-05-07 14:18:54.542470: Yayy! New best EMA pseudo Dice: 0.4709
2024-05-07 14:18:56.161959: 
2024-05-07 14:18:56.166282: Epoch 4
2024-05-07 14:18:56.167803: Current learning rate: 0.00996
2024-05-07 14:22:49.330605: Validation loss improved from -0.31931 to -0.32269! Patience: 0/50
2024-05-07 14:22:49.335510: train_loss -0.4699
2024-05-07 14:22:49.337059: val_loss -0.3227
2024-05-07 14:22:49.338355: Pseudo dice [0.5035]
2024-05-07 14:22:49.339795: Epoch time: 233.18 s
2024-05-07 14:22:49.652919: Yayy! New best EMA pseudo Dice: 0.4741
2024-05-07 14:22:51.268990: 
2024-05-07 14:22:51.273529: Epoch 5
2024-05-07 14:22:51.275842: Current learning rate: 0.00995
2024-05-07 14:26:44.149585: Validation loss improved from -0.32269 to -0.38397! Patience: 0/50
2024-05-07 14:26:44.153313: train_loss -0.4752
2024-05-07 14:26:44.155638: val_loss -0.384
2024-05-07 14:26:44.157676: Pseudo dice [0.5617]
2024-05-07 14:26:44.160030: Epoch time: 232.89 s
2024-05-07 14:26:44.162006: Yayy! New best EMA pseudo Dice: 0.4829
2024-05-07 14:26:45.754026: 
2024-05-07 14:26:45.756791: Epoch 6
2024-05-07 14:26:45.759194: Current learning rate: 0.00995
2024-05-07 14:30:39.682272: Validation loss did not improve from -0.38397. Patience: 1/50
2024-05-07 14:30:39.686200: train_loss -0.4668
2024-05-07 14:30:39.688033: val_loss -0.3398
2024-05-07 14:30:39.689277: Pseudo dice [0.5157]
2024-05-07 14:30:39.690222: Epoch time: 233.93 s
2024-05-07 14:30:39.691176: Yayy! New best EMA pseudo Dice: 0.4862
2024-05-07 14:30:41.414881: 
2024-05-07 14:30:41.419702: Epoch 7
2024-05-07 14:30:41.421205: Current learning rate: 0.00994
2024-05-07 14:34:34.885570: Validation loss improved from -0.38397 to -0.41852! Patience: 1/50
2024-05-07 14:34:34.888587: train_loss -0.4856
2024-05-07 14:34:34.890809: val_loss -0.4185
2024-05-07 14:34:34.892223: Pseudo dice [0.5737]
2024-05-07 14:34:34.893585: Epoch time: 233.47 s
2024-05-07 14:34:34.894996: Yayy! New best EMA pseudo Dice: 0.4949
2024-05-07 14:34:37.196192: 
2024-05-07 14:34:37.199515: Epoch 8
2024-05-07 14:34:37.201300: Current learning rate: 0.00993
2024-05-07 14:38:31.838232: Validation loss improved from -0.41852 to -0.44813! Patience: 0/50
2024-05-07 14:38:31.841999: train_loss -0.5302
2024-05-07 14:38:31.844201: val_loss -0.4481
2024-05-07 14:38:31.845963: Pseudo dice [0.5873]
2024-05-07 14:38:31.847965: Epoch time: 234.65 s
2024-05-07 14:38:31.849176: Yayy! New best EMA pseudo Dice: 0.5042
2024-05-07 14:38:33.428715: 
2024-05-07 14:38:33.432184: Epoch 9
2024-05-07 14:38:33.433777: Current learning rate: 0.00992
2024-05-07 14:42:27.702628: Validation loss improved from -0.44813 to -0.47197! Patience: 0/50
2024-05-07 14:42:27.706922: train_loss -0.5477
2024-05-07 14:42:27.709212: val_loss -0.472
2024-05-07 14:42:27.710891: Pseudo dice [0.6195]
2024-05-07 14:42:27.712478: Epoch time: 234.28 s
2024-05-07 14:42:28.070087: Yayy! New best EMA pseudo Dice: 0.5157
2024-05-07 14:42:29.591594: 
2024-05-07 14:42:29.595931: Epoch 10
2024-05-07 14:42:29.598296: Current learning rate: 0.00991
2024-05-07 14:46:23.212775: Validation loss did not improve from -0.47197. Patience: 1/50
2024-05-07 14:46:23.216867: train_loss -0.5431
2024-05-07 14:46:23.218916: val_loss -0.3648
2024-05-07 14:46:23.220218: Pseudo dice [0.5131]
2024-05-07 14:46:23.221255: Epoch time: 233.63 s
2024-05-07 14:46:24.454467: 
2024-05-07 14:46:24.457822: Epoch 11
2024-05-07 14:46:24.458983: Current learning rate: 0.0099
2024-05-07 14:50:18.004715: Validation loss improved from -0.47197 to -0.50282! Patience: 1/50
2024-05-07 14:50:18.008788: train_loss -0.5661
2024-05-07 14:50:18.010779: val_loss -0.5028
2024-05-07 14:50:18.011780: Pseudo dice [0.6416]
2024-05-07 14:50:18.013294: Epoch time: 233.56 s
2024-05-07 14:50:18.014715: Yayy! New best EMA pseudo Dice: 0.528
2024-05-07 14:50:19.604450: 
2024-05-07 14:50:19.608483: Epoch 12
2024-05-07 14:50:19.609924: Current learning rate: 0.00989
2024-05-07 14:54:13.562184: Validation loss did not improve from -0.50282. Patience: 1/50
2024-05-07 14:54:13.566230: train_loss -0.5777
2024-05-07 14:54:13.568847: val_loss -0.4594
2024-05-07 14:54:13.570571: Pseudo dice [0.6091]
2024-05-07 14:54:13.571789: Epoch time: 233.96 s
2024-05-07 14:54:13.572867: Yayy! New best EMA pseudo Dice: 0.5361
2024-05-07 14:54:15.174858: 
2024-05-07 14:54:15.179776: Epoch 13
2024-05-07 14:54:15.181952: Current learning rate: 0.00988
2024-05-07 14:58:09.279628: Validation loss did not improve from -0.50282. Patience: 2/50
2024-05-07 14:58:09.282843: train_loss -0.5744
2024-05-07 14:58:09.285059: val_loss -0.484
2024-05-07 14:58:09.286704: Pseudo dice [0.6255]
2024-05-07 14:58:09.288643: Epoch time: 234.11 s
2024-05-07 14:58:09.290771: Yayy! New best EMA pseudo Dice: 0.5451
2024-05-07 14:58:10.889168: 
2024-05-07 14:58:10.893348: Epoch 14
2024-05-07 14:58:10.896657: Current learning rate: 0.00987
2024-05-07 15:02:04.678179: Validation loss improved from -0.50282 to -0.51816! Patience: 2/50
2024-05-07 15:02:04.681838: train_loss -0.5735
2024-05-07 15:02:04.683134: val_loss -0.5182
2024-05-07 15:02:04.684451: Pseudo dice [0.6551]
2024-05-07 15:02:04.685671: Epoch time: 233.79 s
2024-05-07 15:02:05.045329: Yayy! New best EMA pseudo Dice: 0.5561
2024-05-07 15:02:06.648591: 
2024-05-07 15:02:06.652878: Epoch 15
2024-05-07 15:02:06.654856: Current learning rate: 0.00986
2024-05-07 15:06:00.351091: Validation loss did not improve from -0.51816. Patience: 1/50
2024-05-07 15:06:00.355194: train_loss -0.585
2024-05-07 15:06:00.357315: val_loss -0.4663
2024-05-07 15:06:00.358936: Pseudo dice [0.6203]
2024-05-07 15:06:00.360661: Epoch time: 233.71 s
2024-05-07 15:06:00.362318: Yayy! New best EMA pseudo Dice: 0.5625
2024-05-07 15:06:02.125585: 
2024-05-07 15:06:02.128993: Epoch 16
2024-05-07 15:06:02.130910: Current learning rate: 0.00986
2024-05-07 15:09:57.085884: Validation loss did not improve from -0.51816. Patience: 2/50
2024-05-07 15:09:57.090430: train_loss -0.6082
2024-05-07 15:09:57.093182: val_loss -0.4223
2024-05-07 15:09:57.094754: Pseudo dice [0.5863]
2024-05-07 15:09:57.096008: Epoch time: 234.97 s
2024-05-07 15:09:57.097269: Yayy! New best EMA pseudo Dice: 0.5649
2024-05-07 15:09:58.855844: 
2024-05-07 15:09:58.859067: Epoch 17
2024-05-07 15:09:58.860798: Current learning rate: 0.00985
2024-05-07 15:13:51.472994: Validation loss did not improve from -0.51816. Patience: 3/50
2024-05-07 15:13:51.478937: train_loss -0.591
2024-05-07 15:13:51.481929: val_loss -0.4681
2024-05-07 15:13:51.483340: Pseudo dice [0.6137]
2024-05-07 15:13:51.485126: Epoch time: 232.62 s
2024-05-07 15:13:51.486468: Yayy! New best EMA pseudo Dice: 0.5698
2024-05-07 15:13:53.401724: 
2024-05-07 15:13:53.404730: Epoch 18
2024-05-07 15:13:53.406246: Current learning rate: 0.00984
2024-05-07 15:17:46.513464: Validation loss improved from -0.51816 to -0.54836! Patience: 3/50
2024-05-07 15:17:46.517226: train_loss -0.626
2024-05-07 15:17:46.519163: val_loss -0.5484
2024-05-07 15:17:46.521030: Pseudo dice [0.6806]
2024-05-07 15:17:46.521971: Epoch time: 233.12 s
2024-05-07 15:17:46.523054: Yayy! New best EMA pseudo Dice: 0.5809
2024-05-07 15:17:48.728023: 
2024-05-07 15:17:48.732258: Epoch 19
2024-05-07 15:17:48.734196: Current learning rate: 0.00983
2024-05-07 15:21:43.227363: Validation loss did not improve from -0.54836. Patience: 1/50
2024-05-07 15:21:43.231059: train_loss -0.6275
2024-05-07 15:21:43.232567: val_loss -0.5034
2024-05-07 15:21:43.233745: Pseudo dice [0.6395]
2024-05-07 15:21:43.235214: Epoch time: 234.5 s
2024-05-07 15:21:43.573700: Yayy! New best EMA pseudo Dice: 0.5867
2024-05-07 15:21:45.210413: 
2024-05-07 15:21:45.213855: Epoch 20
2024-05-07 15:21:45.215531: Current learning rate: 0.00982
2024-05-07 15:25:39.866969: Validation loss did not improve from -0.54836. Patience: 2/50
2024-05-07 15:25:39.869686: train_loss -0.6253
2024-05-07 15:25:39.870942: val_loss -0.5205
2024-05-07 15:25:39.872155: Pseudo dice [0.6505]
2024-05-07 15:25:39.873197: Epoch time: 234.66 s
2024-05-07 15:25:39.874193: Yayy! New best EMA pseudo Dice: 0.5931
2024-05-07 15:25:41.559578: 
2024-05-07 15:25:41.563992: Epoch 21
2024-05-07 15:25:41.566175: Current learning rate: 0.00981
2024-05-07 15:29:36.220904: Validation loss did not improve from -0.54836. Patience: 3/50
2024-05-07 15:29:36.223926: train_loss -0.62
2024-05-07 15:29:36.226560: val_loss -0.4627
2024-05-07 15:29:36.228151: Pseudo dice [0.6139]
2024-05-07 15:29:36.229794: Epoch time: 234.67 s
2024-05-07 15:29:36.231451: Yayy! New best EMA pseudo Dice: 0.5952
2024-05-07 15:29:37.881337: 
2024-05-07 15:29:37.883835: Epoch 22
2024-05-07 15:29:37.885617: Current learning rate: 0.0098
2024-05-07 15:33:32.565248: Validation loss did not improve from -0.54836. Patience: 4/50
2024-05-07 15:33:32.568031: train_loss -0.6334
2024-05-07 15:33:32.569853: val_loss -0.5163
2024-05-07 15:33:32.571135: Pseudo dice [0.6559]
2024-05-07 15:33:32.572453: Epoch time: 234.69 s
2024-05-07 15:33:32.574118: Yayy! New best EMA pseudo Dice: 0.6012
2024-05-07 15:33:34.118610: 
2024-05-07 15:33:34.122175: Epoch 23
2024-05-07 15:33:34.123382: Current learning rate: 0.00979
2024-05-07 15:37:28.677986: Validation loss did not improve from -0.54836. Patience: 5/50
2024-05-07 15:37:28.681102: train_loss -0.6471
2024-05-07 15:37:28.683181: val_loss -0.4294
2024-05-07 15:37:28.684530: Pseudo dice [0.5816]
2024-05-07 15:37:28.686170: Epoch time: 234.56 s
2024-05-07 15:37:30.141234: 
2024-05-07 15:37:30.144461: Epoch 24
2024-05-07 15:37:30.146119: Current learning rate: 0.00978
2024-05-07 15:41:24.849785: Validation loss improved from -0.54836 to -0.57723! Patience: 5/50
2024-05-07 15:41:24.852183: train_loss -0.6571
2024-05-07 15:41:24.854201: val_loss -0.5772
2024-05-07 15:41:24.855648: Pseudo dice [0.6827]
2024-05-07 15:41:24.857056: Epoch time: 234.71 s
2024-05-07 15:41:25.253333: Yayy! New best EMA pseudo Dice: 0.6076
2024-05-07 15:41:26.999109: 
2024-05-07 15:41:27.002527: Epoch 25
2024-05-07 15:41:27.005426: Current learning rate: 0.00977
2024-05-07 15:45:21.700914: Validation loss did not improve from -0.57723. Patience: 1/50
2024-05-07 15:45:21.703885: train_loss -0.6687
2024-05-07 15:45:21.705601: val_loss -0.5309
2024-05-07 15:45:21.706985: Pseudo dice [0.6659]
2024-05-07 15:45:21.708033: Epoch time: 234.71 s
2024-05-07 15:45:21.709194: Yayy! New best EMA pseudo Dice: 0.6135
2024-05-07 15:45:23.351049: 
2024-05-07 15:45:23.355747: Epoch 26
2024-05-07 15:45:23.357517: Current learning rate: 0.00977
2024-05-07 15:49:18.231164: Validation loss did not improve from -0.57723. Patience: 2/50
2024-05-07 15:49:18.234518: train_loss -0.6806
2024-05-07 15:49:18.236392: val_loss -0.5601
2024-05-07 15:49:18.237801: Pseudo dice [0.6885]
2024-05-07 15:49:18.239131: Epoch time: 234.89 s
2024-05-07 15:49:18.240348: Yayy! New best EMA pseudo Dice: 0.621
2024-05-07 15:49:19.796141: 
2024-05-07 15:49:19.799676: Epoch 27
2024-05-07 15:49:19.801496: Current learning rate: 0.00976
2024-05-07 15:53:14.339842: Validation loss did not improve from -0.57723. Patience: 3/50
2024-05-07 15:53:14.343494: train_loss -0.6822
2024-05-07 15:53:14.345325: val_loss -0.5292
2024-05-07 15:53:14.347200: Pseudo dice [0.6611]
2024-05-07 15:53:14.349115: Epoch time: 234.55 s
2024-05-07 15:53:14.350567: Yayy! New best EMA pseudo Dice: 0.625
2024-05-07 15:53:15.951769: 
2024-05-07 15:53:15.955668: Epoch 28
2024-05-07 15:53:15.957480: Current learning rate: 0.00975
2024-05-07 15:57:10.590935: Validation loss did not improve from -0.57723. Patience: 4/50
2024-05-07 15:57:10.605102: train_loss -0.681
2024-05-07 15:57:10.607435: val_loss -0.5413
2024-05-07 15:57:10.609494: Pseudo dice [0.6897]
2024-05-07 15:57:10.611486: Epoch time: 234.65 s
2024-05-07 15:57:10.613048: Yayy! New best EMA pseudo Dice: 0.6314
2024-05-07 15:57:12.159470: 
2024-05-07 15:57:12.163355: Epoch 29
2024-05-07 15:57:12.165726: Current learning rate: 0.00974
2024-05-07 16:01:06.695588: Validation loss did not improve from -0.57723. Patience: 5/50
2024-05-07 16:01:06.699248: train_loss -0.6889
2024-05-07 16:01:06.701705: val_loss -0.5616
2024-05-07 16:01:06.703572: Pseudo dice [0.6928]
2024-05-07 16:01:06.705263: Epoch time: 234.54 s
2024-05-07 16:01:07.069171: Yayy! New best EMA pseudo Dice: 0.6376
2024-05-07 16:01:08.634986: 
2024-05-07 16:01:08.639295: Epoch 30
2024-05-07 16:01:08.641244: Current learning rate: 0.00973
2024-05-07 16:05:03.849126: Validation loss did not improve from -0.57723. Patience: 6/50
2024-05-07 16:05:03.852773: train_loss -0.6716
2024-05-07 16:05:03.855158: val_loss -0.5261
2024-05-07 16:05:03.856915: Pseudo dice [0.6749]
2024-05-07 16:05:03.858485: Epoch time: 235.22 s
2024-05-07 16:05:03.860338: Yayy! New best EMA pseudo Dice: 0.6413
2024-05-07 16:05:06.189760: 
2024-05-07 16:05:06.193311: Epoch 31
2024-05-07 16:05:06.195148: Current learning rate: 0.00972
2024-05-07 16:09:00.948860: Validation loss did not improve from -0.57723. Patience: 7/50
2024-05-07 16:09:00.951285: train_loss -0.6808
2024-05-07 16:09:00.953012: val_loss -0.5547
2024-05-07 16:09:00.954049: Pseudo dice [0.6835]
2024-05-07 16:09:00.955186: Epoch time: 234.76 s
2024-05-07 16:09:00.956340: Yayy! New best EMA pseudo Dice: 0.6455
2024-05-07 16:09:02.781928: 
2024-05-07 16:09:02.784822: Epoch 32
2024-05-07 16:09:02.786341: Current learning rate: 0.00971
2024-05-07 16:12:59.054871: Validation loss did not improve from -0.57723. Patience: 8/50
2024-05-07 16:12:59.064084: train_loss -0.665
2024-05-07 16:12:59.065860: val_loss -0.5272
2024-05-07 16:12:59.067185: Pseudo dice [0.66]
2024-05-07 16:12:59.068875: Epoch time: 236.28 s
2024-05-07 16:12:59.070356: Yayy! New best EMA pseudo Dice: 0.647
2024-05-07 16:13:00.836910: 
2024-05-07 16:13:00.840112: Epoch 33
2024-05-07 16:13:00.842198: Current learning rate: 0.0097
2024-05-07 16:16:56.368338: Validation loss did not improve from -0.57723. Patience: 9/50
2024-05-07 16:16:56.370929: train_loss -0.6808
2024-05-07 16:16:56.372379: val_loss -0.5303
2024-05-07 16:16:56.373878: Pseudo dice [0.6791]
2024-05-07 16:16:56.378124: Epoch time: 235.54 s
2024-05-07 16:16:56.379824: Yayy! New best EMA pseudo Dice: 0.6502
2024-05-07 16:16:58.525976: 
2024-05-07 16:16:58.538284: Epoch 34
2024-05-07 16:16:58.539854: Current learning rate: 0.00969
2024-05-07 16:20:54.959136: Validation loss did not improve from -0.57723. Patience: 10/50
2024-05-07 16:20:55.003465: train_loss -0.6956
2024-05-07 16:20:55.007358: val_loss -0.5679
2024-05-07 16:20:55.009173: Pseudo dice [0.6878]
2024-05-07 16:20:55.010732: Epoch time: 236.44 s
2024-05-07 16:20:55.400472: Yayy! New best EMA pseudo Dice: 0.654
2024-05-07 16:20:57.217485: 
2024-05-07 16:20:57.222628: Epoch 35
2024-05-07 16:20:57.224743: Current learning rate: 0.00968
2024-05-07 16:24:52.975753: Validation loss did not improve from -0.57723. Patience: 11/50
2024-05-07 16:24:52.978539: train_loss -0.7016
2024-05-07 16:24:52.980359: val_loss -0.5647
2024-05-07 16:24:52.981947: Pseudo dice [0.6966]
2024-05-07 16:24:52.983423: Epoch time: 235.76 s
2024-05-07 16:24:52.985250: Yayy! New best EMA pseudo Dice: 0.6582
2024-05-07 16:24:54.563928: 
2024-05-07 16:24:54.568031: Epoch 36
2024-05-07 16:24:54.570099: Current learning rate: 0.00968
2024-05-07 16:28:50.320243: Validation loss did not improve from -0.57723. Patience: 12/50
2024-05-07 16:28:50.323126: train_loss -0.6916
2024-05-07 16:28:50.324865: val_loss -0.5398
2024-05-07 16:28:50.326170: Pseudo dice [0.6753]
2024-05-07 16:28:50.327544: Epoch time: 235.76 s
2024-05-07 16:28:50.328591: Yayy! New best EMA pseudo Dice: 0.6599
2024-05-07 16:28:51.983520: 
2024-05-07 16:28:51.987130: Epoch 37
2024-05-07 16:28:51.988795: Current learning rate: 0.00967
2024-05-07 16:32:47.816064: Validation loss did not improve from -0.57723. Patience: 13/50
2024-05-07 16:32:47.819533: train_loss -0.7163
2024-05-07 16:32:47.821709: val_loss -0.5452
2024-05-07 16:32:47.823662: Pseudo dice [0.6745]
2024-05-07 16:32:47.825952: Epoch time: 235.84 s
2024-05-07 16:32:47.827911: Yayy! New best EMA pseudo Dice: 0.6614
2024-05-07 16:32:49.474040: 
2024-05-07 16:32:49.477880: Epoch 38
2024-05-07 16:32:49.479856: Current learning rate: 0.00966
2024-05-07 16:36:45.662649: Validation loss improved from -0.57723 to -0.59297! Patience: 13/50
2024-05-07 16:36:45.665037: train_loss -0.705
2024-05-07 16:36:45.666499: val_loss -0.593
2024-05-07 16:36:45.667737: Pseudo dice [0.712]
2024-05-07 16:36:45.668999: Epoch time: 236.19 s
2024-05-07 16:36:45.670163: Yayy! New best EMA pseudo Dice: 0.6664
2024-05-07 16:36:47.642149: 
2024-05-07 16:36:47.645246: Epoch 39
2024-05-07 16:36:47.646716: Current learning rate: 0.00965
2024-05-07 16:40:43.568726: Validation loss did not improve from -0.59297. Patience: 1/50
2024-05-07 16:40:43.571456: train_loss -0.7142
2024-05-07 16:40:43.572845: val_loss -0.5485
2024-05-07 16:40:43.574073: Pseudo dice [0.695]
2024-05-07 16:40:43.575129: Epoch time: 235.93 s
2024-05-07 16:40:43.968015: Yayy! New best EMA pseudo Dice: 0.6693
2024-05-07 16:40:45.573243: 
2024-05-07 16:40:45.576967: Epoch 40
2024-05-07 16:40:45.579602: Current learning rate: 0.00964
2024-05-07 16:44:41.749513: Validation loss did not improve from -0.59297. Patience: 2/50
2024-05-07 16:44:41.752141: train_loss -0.7228
2024-05-07 16:44:41.754176: val_loss -0.5759
2024-05-07 16:44:41.755707: Pseudo dice [0.6976]
2024-05-07 16:44:41.757468: Epoch time: 236.18 s
2024-05-07 16:44:41.758838: Yayy! New best EMA pseudo Dice: 0.6721
2024-05-07 16:44:43.548810: 
2024-05-07 16:44:43.552593: Epoch 41
2024-05-07 16:44:43.554129: Current learning rate: 0.00963
2024-05-07 16:48:38.510761: Validation loss did not improve from -0.59297. Patience: 3/50
2024-05-07 16:48:38.513661: train_loss -0.7155
2024-05-07 16:48:38.515308: val_loss -0.5544
2024-05-07 16:48:38.516844: Pseudo dice [0.6891]
2024-05-07 16:48:38.518658: Epoch time: 234.97 s
2024-05-07 16:48:38.520051: Yayy! New best EMA pseudo Dice: 0.6738
2024-05-07 16:48:43.292563: 
2024-05-07 16:48:43.296427: Epoch 42
2024-05-07 16:48:43.298150: Current learning rate: 0.00962
2024-05-07 16:52:38.210069: Validation loss did not improve from -0.59297. Patience: 4/50
2024-05-07 16:52:38.213629: train_loss -0.7132
2024-05-07 16:52:38.215564: val_loss -0.548
2024-05-07 16:52:38.216747: Pseudo dice [0.6752]
2024-05-07 16:52:38.217854: Epoch time: 234.92 s
2024-05-07 16:52:38.218871: Yayy! New best EMA pseudo Dice: 0.674
2024-05-07 16:52:39.828303: 
2024-05-07 16:52:39.831606: Epoch 43
2024-05-07 16:52:39.833472: Current learning rate: 0.00961
2024-05-07 16:56:34.513515: Validation loss did not improve from -0.59297. Patience: 5/50
2024-05-07 16:56:34.517234: train_loss -0.7261
2024-05-07 16:56:34.519598: val_loss -0.5323
2024-05-07 16:56:34.521849: Pseudo dice [0.6683]
2024-05-07 16:56:34.523573: Epoch time: 234.69 s
2024-05-07 16:56:35.773787: 
2024-05-07 16:56:35.777704: Epoch 44
2024-05-07 16:56:35.779169: Current learning rate: 0.0096
2024-05-07 17:00:30.584306: Validation loss did not improve from -0.59297. Patience: 6/50
2024-05-07 17:00:30.587004: train_loss -0.7234
2024-05-07 17:00:30.588396: val_loss -0.5525
2024-05-07 17:00:30.589977: Pseudo dice [0.6779]
2024-05-07 17:00:30.591360: Epoch time: 234.81 s
2024-05-07 17:00:32.121041: 
2024-05-07 17:00:32.123411: Epoch 45
2024-05-07 17:00:32.124565: Current learning rate: 0.00959
2024-05-07 17:04:26.643379: Validation loss did not improve from -0.59297. Patience: 7/50
2024-05-07 17:04:26.646012: train_loss -0.718
2024-05-07 17:04:26.647651: val_loss -0.4687
2024-05-07 17:04:26.648815: Pseudo dice [0.6213]
2024-05-07 17:04:26.649983: Epoch time: 234.53 s
2024-05-07 17:04:27.839345: 
2024-05-07 17:04:27.843572: Epoch 46
2024-05-07 17:04:27.845920: Current learning rate: 0.00959
2024-05-07 17:08:22.227766: Validation loss did not improve from -0.59297. Patience: 8/50
2024-05-07 17:08:22.231203: train_loss -0.717
2024-05-07 17:08:22.232930: val_loss -0.5574
2024-05-07 17:08:22.234190: Pseudo dice [0.6903]
2024-05-07 17:08:22.235295: Epoch time: 234.39 s
2024-05-07 17:08:23.456023: 
2024-05-07 17:08:23.459186: Epoch 47
2024-05-07 17:08:23.460594: Current learning rate: 0.00958
2024-05-07 17:12:17.669717: Validation loss did not improve from -0.59297. Patience: 9/50
2024-05-07 17:12:17.672629: train_loss -0.714
2024-05-07 17:12:17.674429: val_loss -0.5599
2024-05-07 17:12:17.675766: Pseudo dice [0.6886]
2024-05-07 17:12:17.676933: Epoch time: 234.22 s
2024-05-07 17:12:19.041409: 
2024-05-07 17:12:19.044005: Epoch 48
2024-05-07 17:12:19.045412: Current learning rate: 0.00957
2024-05-07 17:16:19.145337: Validation loss did not improve from -0.59297. Patience: 10/50
2024-05-07 17:16:19.165942: train_loss -0.7282
2024-05-07 17:16:19.167680: val_loss -0.5824
2024-05-07 17:16:19.169047: Pseudo dice [0.7075]
2024-05-07 17:16:19.170223: Epoch time: 240.11 s
2024-05-07 17:16:19.171242: Yayy! New best EMA pseudo Dice: 0.6761
2024-05-07 17:16:21.096269: 
2024-05-07 17:16:21.099789: Epoch 49
2024-05-07 17:16:21.101450: Current learning rate: 0.00956
2024-05-07 17:20:14.585633: Validation loss did not improve from -0.59297. Patience: 11/50
2024-05-07 17:20:14.588191: train_loss -0.735
2024-05-07 17:20:14.589775: val_loss -0.4468
2024-05-07 17:20:14.590901: Pseudo dice [0.6117]
2024-05-07 17:20:14.592028: Epoch time: 233.49 s
2024-05-07 17:20:16.149174: 
2024-05-07 17:20:16.152460: Epoch 50
2024-05-07 17:20:16.154097: Current learning rate: 0.00955
2024-05-07 17:24:10.624284: Validation loss did not improve from -0.59297. Patience: 12/50
2024-05-07 17:24:10.662505: train_loss -0.7412
2024-05-07 17:24:10.666334: val_loss -0.5792
2024-05-07 17:24:10.668344: Pseudo dice [0.7006]
2024-05-07 17:24:10.670131: Epoch time: 234.51 s
2024-05-07 17:24:12.317324: 
2024-05-07 17:24:12.319098: Epoch 51
2024-05-07 17:24:12.320706: Current learning rate: 0.00954
2024-05-07 17:28:06.553931: Validation loss did not improve from -0.59297. Patience: 13/50
2024-05-07 17:28:06.556932: train_loss -0.7372
2024-05-07 17:28:06.558714: val_loss -0.5693
2024-05-07 17:28:06.559885: Pseudo dice [0.7003]
2024-05-07 17:28:06.560931: Epoch time: 234.24 s
2024-05-07 17:28:07.822284: 
2024-05-07 17:28:07.825036: Epoch 52
2024-05-07 17:28:07.826325: Current learning rate: 0.00953
2024-05-07 17:32:01.789129: Validation loss improved from -0.59297 to -0.59380! Patience: 13/50
2024-05-07 17:32:01.790872: train_loss -0.751
2024-05-07 17:32:01.792481: val_loss -0.5938
2024-05-07 17:32:01.793899: Pseudo dice [0.7077]
2024-05-07 17:32:01.794993: Epoch time: 233.97 s
2024-05-07 17:32:01.796079: Yayy! New best EMA pseudo Dice: 0.6787
2024-05-07 17:32:04.185315: 
2024-05-07 17:32:04.187691: Epoch 53
2024-05-07 17:32:04.189239: Current learning rate: 0.00952
2024-05-07 17:35:58.783469: Validation loss did not improve from -0.59380. Patience: 1/50
2024-05-07 17:35:58.785240: train_loss -0.7444
2024-05-07 17:35:58.786660: val_loss -0.5915
2024-05-07 17:35:58.788193: Pseudo dice [0.7177]
2024-05-07 17:35:58.789444: Epoch time: 234.6 s
2024-05-07 17:35:58.790775: Yayy! New best EMA pseudo Dice: 0.6826
2024-05-07 17:36:02.223799: 
2024-05-07 17:36:02.226728: Epoch 54
2024-05-07 17:36:02.272944: Current learning rate: 0.00951
2024-05-07 17:39:57.474687: Validation loss did not improve from -0.59380. Patience: 2/50
2024-05-07 17:39:57.476826: train_loss -0.7462
2024-05-07 17:39:57.478303: val_loss -0.5914
2024-05-07 17:39:57.479685: Pseudo dice [0.7156]
2024-05-07 17:39:57.480897: Epoch time: 235.25 s
2024-05-07 17:39:57.860487: Yayy! New best EMA pseudo Dice: 0.6859
2024-05-07 17:39:59.537663: 
2024-05-07 17:39:59.540529: Epoch 55
2024-05-07 17:39:59.542613: Current learning rate: 0.0095
2024-05-07 17:43:55.101165: Validation loss improved from -0.59380 to -0.63223! Patience: 2/50
2024-05-07 17:43:55.102694: train_loss -0.744
2024-05-07 17:43:55.104126: val_loss -0.6322
2024-05-07 17:43:55.105314: Pseudo dice [0.7455]
2024-05-07 17:43:55.106445: Epoch time: 235.57 s
2024-05-07 17:43:55.107798: Yayy! New best EMA pseudo Dice: 0.6919
2024-05-07 17:43:56.769692: 
2024-05-07 17:43:56.772650: Epoch 56
2024-05-07 17:43:56.774959: Current learning rate: 0.00949
2024-05-07 17:47:52.451911: Validation loss did not improve from -0.63223. Patience: 1/50
2024-05-07 17:47:52.453586: train_loss -0.7499
2024-05-07 17:47:52.455149: val_loss -0.5593
2024-05-07 17:47:52.456290: Pseudo dice [0.6935]
2024-05-07 17:47:52.457413: Epoch time: 235.69 s
2024-05-07 17:47:52.458541: Yayy! New best EMA pseudo Dice: 0.692
2024-05-07 17:47:54.027786: 
2024-05-07 17:47:54.030674: Epoch 57
2024-05-07 17:47:54.031884: Current learning rate: 0.00949
2024-05-07 17:51:49.573935: Validation loss did not improve from -0.63223. Patience: 2/50
2024-05-07 17:51:49.575408: train_loss -0.7503
2024-05-07 17:51:49.576814: val_loss -0.5781
2024-05-07 17:51:49.578018: Pseudo dice [0.7098]
2024-05-07 17:51:49.579317: Epoch time: 235.55 s
2024-05-07 17:51:49.580498: Yayy! New best EMA pseudo Dice: 0.6938
2024-05-07 17:51:51.213536: 
2024-05-07 17:51:51.215525: Epoch 58
2024-05-07 17:51:51.216564: Current learning rate: 0.00948
2024-05-07 17:55:47.680541: Validation loss did not improve from -0.63223. Patience: 3/50
2024-05-07 17:55:47.682784: train_loss -0.7633
2024-05-07 17:55:47.684907: val_loss -0.6056
2024-05-07 17:55:47.685996: Pseudo dice [0.7323]
2024-05-07 17:55:47.687393: Epoch time: 236.47 s
2024-05-07 17:55:47.688827: Yayy! New best EMA pseudo Dice: 0.6976
2024-05-07 17:55:49.378024: 
2024-05-07 17:55:49.380824: Epoch 59
2024-05-07 17:55:49.382176: Current learning rate: 0.00947
2024-05-07 17:59:46.238633: Validation loss did not improve from -0.63223. Patience: 4/50
2024-05-07 17:59:46.241180: train_loss -0.7555
2024-05-07 17:59:46.242818: val_loss -0.5561
2024-05-07 17:59:46.244278: Pseudo dice [0.6938]
2024-05-07 17:59:46.245777: Epoch time: 236.86 s
2024-05-07 17:59:48.044460: 
2024-05-07 17:59:48.047268: Epoch 60
2024-05-07 17:59:48.048617: Current learning rate: 0.00946
2024-05-07 18:03:44.058936: Validation loss did not improve from -0.63223. Patience: 5/50
2024-05-07 18:03:44.060509: train_loss -0.7575
2024-05-07 18:03:44.062627: val_loss -0.5312
2024-05-07 18:03:44.064645: Pseudo dice [0.6932]
2024-05-07 18:03:44.066512: Epoch time: 236.02 s
2024-05-07 18:03:45.376082: 
2024-05-07 18:03:45.377924: Epoch 61
2024-05-07 18:03:45.379774: Current learning rate: 0.00945
2024-05-07 18:07:41.582223: Validation loss did not improve from -0.63223. Patience: 6/50
2024-05-07 18:07:41.583771: train_loss -0.7534
2024-05-07 18:07:41.585314: val_loss -0.5389
2024-05-07 18:07:41.586706: Pseudo dice [0.6915]
2024-05-07 18:07:41.587940: Epoch time: 236.21 s
2024-05-07 18:07:42.983417: 
2024-05-07 18:07:42.985877: Epoch 62
2024-05-07 18:07:42.987067: Current learning rate: 0.00944
2024-05-07 18:11:39.111645: Validation loss did not improve from -0.63223. Patience: 7/50
2024-05-07 18:11:39.113529: train_loss -0.7549
2024-05-07 18:11:39.115504: val_loss -0.5774
2024-05-07 18:11:39.116575: Pseudo dice [0.706]
2024-05-07 18:11:39.117607: Epoch time: 236.13 s
2024-05-07 18:11:40.533610: 
2024-05-07 18:11:40.535891: Epoch 63
2024-05-07 18:11:40.537603: Current learning rate: 0.00943
2024-05-07 18:15:36.975266: Validation loss did not improve from -0.63223. Patience: 8/50
2024-05-07 18:15:36.976762: train_loss -0.7576
2024-05-07 18:15:36.977854: val_loss -0.5854
2024-05-07 18:15:36.978841: Pseudo dice [0.7143]
2024-05-07 18:15:36.979831: Epoch time: 236.44 s
2024-05-07 18:15:36.980829: Yayy! New best EMA pseudo Dice: 0.699
2024-05-07 18:15:38.778786: 
2024-05-07 18:15:38.781157: Epoch 64
2024-05-07 18:15:38.782595: Current learning rate: 0.00942
2024-05-07 18:19:34.847617: Validation loss did not improve from -0.63223. Patience: 9/50
2024-05-07 18:19:34.849215: train_loss -0.7667
2024-05-07 18:19:34.850421: val_loss -0.5874
2024-05-07 18:19:34.851869: Pseudo dice [0.7077]
2024-05-07 18:19:34.853362: Epoch time: 236.07 s
2024-05-07 18:19:35.222404: Yayy! New best EMA pseudo Dice: 0.6999
2024-05-07 18:19:37.831863: 
2024-05-07 18:19:37.834780: Epoch 65
2024-05-07 18:19:37.836812: Current learning rate: 0.00941
2024-05-07 18:23:35.905652: Validation loss did not improve from -0.63223. Patience: 10/50
2024-05-07 18:23:35.926455: train_loss -0.7687
2024-05-07 18:23:35.928256: val_loss -0.5813
2024-05-07 18:23:35.929348: Pseudo dice [0.7074]
2024-05-07 18:23:35.930691: Epoch time: 238.09 s
2024-05-07 18:23:35.932031: Yayy! New best EMA pseudo Dice: 0.7006
2024-05-07 18:23:37.842741: 
2024-05-07 18:23:37.844542: Epoch 66
2024-05-07 18:23:37.845709: Current learning rate: 0.0094
2024-05-07 18:27:34.078415: Validation loss did not improve from -0.63223. Patience: 11/50
2024-05-07 18:27:34.081779: train_loss -0.7765
2024-05-07 18:27:34.084035: val_loss -0.6047
2024-05-07 18:27:34.085562: Pseudo dice [0.723]
2024-05-07 18:27:34.086824: Epoch time: 236.24 s
2024-05-07 18:27:34.088382: Yayy! New best EMA pseudo Dice: 0.7029
2024-05-07 18:27:35.960558: 
2024-05-07 18:27:35.962766: Epoch 67
2024-05-07 18:27:35.963947: Current learning rate: 0.00939
2024-05-07 18:31:31.812041: Validation loss did not improve from -0.63223. Patience: 12/50
2024-05-07 18:31:31.814363: train_loss -0.7788
2024-05-07 18:31:31.820044: val_loss -0.6292
2024-05-07 18:31:31.821382: Pseudo dice [0.7376]
2024-05-07 18:31:31.823374: Epoch time: 235.85 s
2024-05-07 18:31:31.824937: Yayy! New best EMA pseudo Dice: 0.7063
2024-05-07 18:31:33.857456: 
2024-05-07 18:31:33.860306: Epoch 68
2024-05-07 18:31:33.862010: Current learning rate: 0.00939
2024-05-07 18:35:29.450936: Validation loss did not improve from -0.63223. Patience: 13/50
2024-05-07 18:35:29.452635: train_loss -0.772
2024-05-07 18:35:29.454569: val_loss -0.568
2024-05-07 18:35:29.456393: Pseudo dice [0.7114]
2024-05-07 18:35:29.457512: Epoch time: 235.6 s
2024-05-07 18:35:29.458774: Yayy! New best EMA pseudo Dice: 0.7068
2024-05-07 18:35:31.246495: 
2024-05-07 18:35:31.248218: Epoch 69
2024-05-07 18:35:31.249593: Current learning rate: 0.00938
2024-05-07 18:39:27.262610: Validation loss did not improve from -0.63223. Patience: 14/50
2024-05-07 18:39:27.264394: train_loss -0.7732
2024-05-07 18:39:27.265888: val_loss -0.5909
2024-05-07 18:39:27.267291: Pseudo dice [0.7158]
2024-05-07 18:39:27.268492: Epoch time: 236.02 s
2024-05-07 18:39:27.679684: Yayy! New best EMA pseudo Dice: 0.7077
2024-05-07 18:39:29.427434: 
2024-05-07 18:39:29.429517: Epoch 70
2024-05-07 18:39:29.430708: Current learning rate: 0.00937
2024-05-07 18:43:26.197812: Validation loss did not improve from -0.63223. Patience: 15/50
2024-05-07 18:43:26.199383: train_loss -0.7662
2024-05-07 18:43:26.200893: val_loss -0.5546
2024-05-07 18:43:26.202652: Pseudo dice [0.6891]
2024-05-07 18:43:26.204125: Epoch time: 236.77 s
2024-05-07 18:43:27.622368: 
2024-05-07 18:43:27.624979: Epoch 71
2024-05-07 18:43:27.627385: Current learning rate: 0.00936
2024-05-07 18:47:24.589675: Validation loss did not improve from -0.63223. Patience: 16/50
2024-05-07 18:47:24.591200: train_loss -0.7653
2024-05-07 18:47:24.592399: val_loss -0.6096
2024-05-07 18:47:24.593452: Pseudo dice [0.7273]
2024-05-07 18:47:24.595334: Epoch time: 236.97 s
2024-05-07 18:47:24.596426: Yayy! New best EMA pseudo Dice: 0.708
2024-05-07 18:47:26.441733: 
2024-05-07 18:47:26.443223: Epoch 72
2024-05-07 18:47:26.444814: Current learning rate: 0.00935
2024-05-07 18:51:22.267013: Validation loss did not improve from -0.63223. Patience: 17/50
2024-05-07 18:51:22.268507: train_loss -0.7742
2024-05-07 18:51:22.269927: val_loss -0.5947
2024-05-07 18:51:22.270947: Pseudo dice [0.7144]
2024-05-07 18:51:22.272144: Epoch time: 235.83 s
2024-05-07 18:51:22.273239: Yayy! New best EMA pseudo Dice: 0.7086
2024-05-07 18:51:24.019977: 
2024-05-07 18:51:24.022401: Epoch 73
2024-05-07 18:51:24.023729: Current learning rate: 0.00934
2024-05-07 18:55:19.084368: Validation loss did not improve from -0.63223. Patience: 18/50
2024-05-07 18:55:19.086048: train_loss -0.7831
2024-05-07 18:55:19.087276: val_loss -0.606
2024-05-07 18:55:19.088852: Pseudo dice [0.7317]
2024-05-07 18:55:19.089994: Epoch time: 235.07 s
2024-05-07 18:55:19.090985: Yayy! New best EMA pseudo Dice: 0.711
2024-05-07 18:55:20.823378: 
2024-05-07 18:55:20.825941: Epoch 74
2024-05-07 18:55:20.827394: Current learning rate: 0.00933
2024-05-07 18:59:16.998612: Validation loss did not improve from -0.63223. Patience: 19/50
2024-05-07 18:59:17.000194: train_loss -0.7861
2024-05-07 18:59:17.002325: val_loss -0.6009
2024-05-07 18:59:17.003801: Pseudo dice [0.7211]
2024-05-07 18:59:17.004940: Epoch time: 236.18 s
2024-05-07 18:59:17.417044: Yayy! New best EMA pseudo Dice: 0.712
2024-05-07 18:59:19.288494: 
2024-05-07 18:59:19.290393: Epoch 75
2024-05-07 18:59:19.291605: Current learning rate: 0.00932
2024-05-07 19:03:14.136621: Validation loss did not improve from -0.63223. Patience: 20/50
2024-05-07 19:03:14.138008: train_loss -0.786
2024-05-07 19:03:14.139040: val_loss -0.6143
2024-05-07 19:03:14.140009: Pseudo dice [0.7328]
2024-05-07 19:03:14.141120: Epoch time: 234.85 s
2024-05-07 19:03:14.142133: Yayy! New best EMA pseudo Dice: 0.7141
2024-05-07 19:03:16.975948: 
2024-05-07 19:03:16.978040: Epoch 76
2024-05-07 19:03:16.979311: Current learning rate: 0.00931
2024-05-07 19:07:11.575380: Validation loss did not improve from -0.63223. Patience: 21/50
2024-05-07 19:07:11.576935: train_loss -0.7795
2024-05-07 19:07:11.578207: val_loss -0.5435
2024-05-07 19:07:11.579381: Pseudo dice [0.6819]
2024-05-07 19:07:11.580634: Epoch time: 234.6 s
2024-05-07 19:07:13.059377: 
2024-05-07 19:07:13.061378: Epoch 77
2024-05-07 19:07:13.062874: Current learning rate: 0.0093
2024-05-07 19:11:08.417216: Validation loss did not improve from -0.63223. Patience: 22/50
2024-05-07 19:11:08.418952: train_loss -0.7793
2024-05-07 19:11:08.420259: val_loss -0.5786
2024-05-07 19:11:08.421733: Pseudo dice [0.7069]
2024-05-07 19:11:08.423476: Epoch time: 235.36 s
2024-05-07 19:11:09.924435: 
2024-05-07 19:11:09.926005: Epoch 78
2024-05-07 19:11:09.927418: Current learning rate: 0.0093
2024-05-07 19:15:03.791286: Validation loss did not improve from -0.63223. Patience: 23/50
2024-05-07 19:15:03.792986: train_loss -0.776
2024-05-07 19:15:03.794322: val_loss -0.5866
2024-05-07 19:15:03.796025: Pseudo dice [0.7183]
2024-05-07 19:15:03.798057: Epoch time: 233.87 s
2024-05-07 19:15:05.274974: 
2024-05-07 19:15:05.277702: Epoch 79
2024-05-07 19:15:05.279231: Current learning rate: 0.00929
2024-05-07 19:19:01.473057: Validation loss did not improve from -0.63223. Patience: 24/50
2024-05-07 19:19:01.474738: train_loss -0.7898
2024-05-07 19:19:01.476409: val_loss -0.6226
2024-05-07 19:19:01.477585: Pseudo dice [0.7359]
2024-05-07 19:19:01.478855: Epoch time: 236.2 s
2024-05-07 19:19:03.450516: 
2024-05-07 19:19:03.453140: Epoch 80
2024-05-07 19:19:03.454973: Current learning rate: 0.00928
2024-05-07 19:22:57.560207: Validation loss did not improve from -0.63223. Patience: 25/50
2024-05-07 19:22:57.561908: train_loss -0.7859
2024-05-07 19:22:57.563402: val_loss -0.5731
2024-05-07 19:22:57.564876: Pseudo dice [0.7008]
2024-05-07 19:22:57.566271: Epoch time: 234.11 s
2024-05-07 19:22:59.020290: 
2024-05-07 19:22:59.022135: Epoch 81
2024-05-07 19:22:59.023642: Current learning rate: 0.00927
2024-05-07 19:26:55.676930: Validation loss did not improve from -0.63223. Patience: 26/50
2024-05-07 19:26:55.680205: train_loss -0.7956
2024-05-07 19:26:55.682313: val_loss -0.6292
2024-05-07 19:26:55.684054: Pseudo dice [0.7384]
2024-05-07 19:26:55.685564: Epoch time: 236.66 s
2024-05-07 19:26:55.687017: Yayy! New best EMA pseudo Dice: 0.715
2024-05-07 19:26:57.747064: 
2024-05-07 19:26:57.749315: Epoch 82
2024-05-07 19:26:57.750679: Current learning rate: 0.00926
2024-05-07 19:30:52.467339: Validation loss did not improve from -0.63223. Patience: 27/50
2024-05-07 19:30:52.468861: train_loss -0.7945
2024-05-07 19:30:52.470483: val_loss -0.6089
2024-05-07 19:30:52.472177: Pseudo dice [0.7271]
2024-05-07 19:30:52.474017: Epoch time: 234.72 s
2024-05-07 19:30:52.475507: Yayy! New best EMA pseudo Dice: 0.7162
2024-05-07 19:30:54.157932: 
2024-05-07 19:30:54.160978: Epoch 83
2024-05-07 19:30:54.162444: Current learning rate: 0.00925
2024-05-07 19:34:49.070835: Validation loss did not improve from -0.63223. Patience: 28/50
2024-05-07 19:34:49.073387: train_loss -0.7951
2024-05-07 19:34:49.075559: val_loss -0.6
2024-05-07 19:34:49.076700: Pseudo dice [0.7212]
2024-05-07 19:34:49.077919: Epoch time: 234.92 s
2024-05-07 19:34:49.078868: Yayy! New best EMA pseudo Dice: 0.7167
2024-05-07 19:34:50.935476: 
2024-05-07 19:34:50.937506: Epoch 84
2024-05-07 19:34:50.938701: Current learning rate: 0.00924
2024-05-07 19:38:45.165546: Validation loss did not improve from -0.63223. Patience: 29/50
2024-05-07 19:38:45.168750: train_loss -0.7924
2024-05-07 19:38:45.170446: val_loss -0.5732
2024-05-07 19:38:45.172101: Pseudo dice [0.706]
2024-05-07 19:38:45.173454: Epoch time: 234.23 s
2024-05-07 19:38:46.773073: 
2024-05-07 19:38:46.775021: Epoch 85
2024-05-07 19:38:46.776286: Current learning rate: 0.00923
2024-05-07 19:42:41.494557: Validation loss did not improve from -0.63223. Patience: 30/50
2024-05-07 19:42:41.496283: train_loss -0.7994
2024-05-07 19:42:41.497477: val_loss -0.525
2024-05-07 19:42:41.498616: Pseudo dice [0.6717]
2024-05-07 19:42:41.499685: Epoch time: 234.72 s
2024-05-07 19:42:42.863264: 
2024-05-07 19:42:42.865825: Epoch 86
2024-05-07 19:42:42.867568: Current learning rate: 0.00922
2024-05-07 19:46:39.827178: Validation loss did not improve from -0.63223. Patience: 31/50
2024-05-07 19:46:39.828740: train_loss -0.7876
2024-05-07 19:46:39.830096: val_loss -0.5621
2024-05-07 19:46:39.831817: Pseudo dice [0.7008]
2024-05-07 19:46:39.833056: Epoch time: 236.97 s
2024-05-07 19:46:42.720620: 
2024-05-07 19:46:42.722909: Epoch 87
2024-05-07 19:46:42.724641: Current learning rate: 0.00921
2024-05-07 19:50:39.291395: Validation loss did not improve from -0.63223. Patience: 32/50
2024-05-07 19:50:39.293270: train_loss -0.7776
2024-05-07 19:50:39.295014: val_loss -0.4507
2024-05-07 19:50:39.296170: Pseudo dice [0.6101]
2024-05-07 19:50:39.297303: Epoch time: 236.57 s
2024-05-07 19:50:40.643304: 
2024-05-07 19:50:40.645540: Epoch 88
2024-05-07 19:50:40.646890: Current learning rate: 0.0092
2024-05-07 19:54:37.442182: Validation loss did not improve from -0.63223. Patience: 33/50
2024-05-07 19:54:37.444203: train_loss -0.7725
2024-05-07 19:54:37.445917: val_loss -0.5977
2024-05-07 19:54:37.447886: Pseudo dice [0.722]
2024-05-07 19:54:37.449927: Epoch time: 236.8 s
2024-05-07 19:54:38.829656: 
2024-05-07 19:54:38.831532: Epoch 89
2024-05-07 19:54:38.832893: Current learning rate: 0.0092
2024-05-07 19:58:35.927801: Validation loss did not improve from -0.63223. Patience: 34/50
2024-05-07 19:58:35.930107: train_loss -0.7818
2024-05-07 19:58:35.931606: val_loss -0.6046
2024-05-07 19:58:35.932621: Pseudo dice [0.7242]
2024-05-07 19:58:35.933645: Epoch time: 237.1 s
2024-05-07 19:58:37.712533: 
2024-05-07 19:58:37.715086: Epoch 90
2024-05-07 19:58:37.716363: Current learning rate: 0.00919
2024-05-07 20:02:34.010442: Validation loss did not improve from -0.63223. Patience: 35/50
2024-05-07 20:02:34.012019: train_loss -0.7853
2024-05-07 20:02:34.013080: val_loss -0.6027
2024-05-07 20:02:34.014338: Pseudo dice [0.7184]
2024-05-07 20:02:34.015399: Epoch time: 236.3 s
2024-05-07 20:02:35.340776: 
2024-05-07 20:02:35.343112: Epoch 91
2024-05-07 20:02:35.344414: Current learning rate: 0.00918
2024-05-07 20:06:30.554213: Validation loss did not improve from -0.63223. Patience: 36/50
2024-05-07 20:06:30.556042: train_loss -0.7863
2024-05-07 20:06:30.558189: val_loss -0.6015
2024-05-07 20:06:30.559550: Pseudo dice [0.7244]
2024-05-07 20:06:30.560786: Epoch time: 235.22 s
2024-05-07 20:06:31.851333: 
2024-05-07 20:06:31.853119: Epoch 92
2024-05-07 20:06:31.854323: Current learning rate: 0.00917
2024-05-07 20:10:27.363155: Validation loss did not improve from -0.63223. Patience: 37/50
2024-05-07 20:10:27.384594: train_loss -0.797
2024-05-07 20:10:27.386778: val_loss -0.6156
2024-05-07 20:10:27.388053: Pseudo dice [0.7299]
2024-05-07 20:10:27.389381: Epoch time: 235.51 s
2024-05-07 20:10:28.950728: 
2024-05-07 20:10:28.953196: Epoch 93
2024-05-07 20:10:28.954586: Current learning rate: 0.00916
2024-05-07 20:14:23.866248: Validation loss did not improve from -0.63223. Patience: 38/50
2024-05-07 20:14:23.867866: train_loss -0.8011
2024-05-07 20:14:23.869136: val_loss -0.611
2024-05-07 20:14:23.870317: Pseudo dice [0.7243]
2024-05-07 20:14:23.871412: Epoch time: 234.92 s
2024-05-07 20:14:25.201874: 
2024-05-07 20:14:25.203459: Epoch 94
2024-05-07 20:14:25.204663: Current learning rate: 0.00915
2024-05-07 20:18:19.385864: Validation loss did not improve from -0.63223. Patience: 39/50
2024-05-07 20:18:19.387606: train_loss -0.804
2024-05-07 20:18:19.388871: val_loss -0.6
2024-05-07 20:18:19.389978: Pseudo dice [0.7198]
2024-05-07 20:18:19.390995: Epoch time: 234.19 s
2024-05-07 20:18:21.190280: 
2024-05-07 20:18:21.192090: Epoch 95
2024-05-07 20:18:21.193405: Current learning rate: 0.00914
2024-05-07 20:22:15.231473: Validation loss did not improve from -0.63223. Patience: 40/50
2024-05-07 20:22:15.233027: train_loss -0.8034
2024-05-07 20:22:15.235232: val_loss -0.5884
2024-05-07 20:22:15.236575: Pseudo dice [0.7139]
2024-05-07 20:22:15.238484: Epoch time: 234.04 s
2024-05-07 20:22:16.593044: 
2024-05-07 20:22:16.594659: Epoch 96
2024-05-07 20:22:16.596379: Current learning rate: 0.00913
2024-05-07 20:26:11.346675: Validation loss did not improve from -0.63223. Patience: 41/50
2024-05-07 20:26:11.348267: train_loss -0.8049
2024-05-07 20:26:11.349559: val_loss -0.5783
2024-05-07 20:26:11.350681: Pseudo dice [0.7153]
2024-05-07 20:26:11.351843: Epoch time: 234.76 s
2024-05-07 20:26:12.564579: 
2024-05-07 20:26:12.566774: Epoch 97
2024-05-07 20:26:12.567956: Current learning rate: 0.00912
2024-05-07 20:30:06.348303: Validation loss improved from -0.63223 to -0.63371! Patience: 41/50
2024-05-07 20:30:06.350003: train_loss -0.8017
2024-05-07 20:30:06.351264: val_loss -0.6337
2024-05-07 20:30:06.352352: Pseudo dice [0.7451]
2024-05-07 20:30:06.353296: Epoch time: 233.79 s
2024-05-07 20:30:07.706232: 
2024-05-07 20:30:07.708373: Epoch 98
2024-05-07 20:30:07.709464: Current learning rate: 0.00911
2024-05-07 20:34:03.140851: Validation loss did not improve from -0.63371. Patience: 1/50
2024-05-07 20:34:03.143670: train_loss -0.797
2024-05-07 20:34:03.145270: val_loss -0.6334
2024-05-07 20:34:03.146291: Pseudo dice [0.74]
2024-05-07 20:34:03.147552: Epoch time: 235.44 s
2024-05-07 20:34:03.148790: Yayy! New best EMA pseudo Dice: 0.7184
2024-05-07 20:34:07.599736: 
2024-05-07 20:34:07.602311: Epoch 99
2024-05-07 20:34:07.603742: Current learning rate: 0.0091
2024-05-07 20:38:02.564739: Validation loss did not improve from -0.63371. Patience: 2/50
2024-05-07 20:38:02.567837: train_loss -0.8032
2024-05-07 20:38:02.570460: val_loss -0.5589
2024-05-07 20:38:02.571711: Pseudo dice [0.7095]
2024-05-07 20:38:02.573308: Epoch time: 234.97 s
2024-05-07 20:38:04.304078: 
2024-05-07 20:38:04.306880: Epoch 100
2024-05-07 20:38:04.308314: Current learning rate: 0.0091
2024-05-07 20:41:58.003198: Validation loss did not improve from -0.63371. Patience: 3/50
2024-05-07 20:41:58.004689: train_loss -0.8042
2024-05-07 20:41:58.006166: val_loss -0.6024
2024-05-07 20:41:58.008003: Pseudo dice [0.7248]
2024-05-07 20:41:58.009321: Epoch time: 233.7 s
2024-05-07 20:41:59.389373: 
2024-05-07 20:41:59.392291: Epoch 101
2024-05-07 20:41:59.393753: Current learning rate: 0.00909
2024-05-07 20:45:54.269476: Validation loss did not improve from -0.63371. Patience: 4/50
2024-05-07 20:45:54.271931: train_loss -0.8102
2024-05-07 20:45:54.273279: val_loss -0.5816
2024-05-07 20:45:54.274496: Pseudo dice [0.7123]
2024-05-07 20:45:54.275821: Epoch time: 234.88 s
2024-05-07 20:45:55.604165: 
2024-05-07 20:45:55.607013: Epoch 102
2024-05-07 20:45:55.608499: Current learning rate: 0.00908
2024-05-07 20:49:49.603815: Validation loss did not improve from -0.63371. Patience: 5/50
2024-05-07 20:49:49.605730: train_loss -0.8162
2024-05-07 20:49:49.607149: val_loss -0.5949
2024-05-07 20:49:49.608517: Pseudo dice [0.7148]
2024-05-07 20:49:49.609534: Epoch time: 234.0 s
2024-05-07 20:49:50.913957: 
2024-05-07 20:49:50.916483: Epoch 103
2024-05-07 20:49:50.918096: Current learning rate: 0.00907
2024-05-07 20:53:48.030563: Validation loss did not improve from -0.63371. Patience: 6/50
2024-05-07 20:53:48.032730: train_loss -0.8114
2024-05-07 20:53:48.034132: val_loss -0.597
2024-05-07 20:53:48.035529: Pseudo dice [0.7152]
2024-05-07 20:53:48.036831: Epoch time: 237.12 s
2024-05-07 20:53:49.407251: 
2024-05-07 20:53:49.409410: Epoch 104
2024-05-07 20:53:49.410898: Current learning rate: 0.00906
2024-05-07 20:57:43.236709: Validation loss did not improve from -0.63371. Patience: 7/50
2024-05-07 20:57:43.238223: train_loss -0.8081
2024-05-07 20:57:43.239916: val_loss -0.5985
2024-05-07 20:57:43.241395: Pseudo dice [0.7293]
2024-05-07 20:57:43.242442: Epoch time: 233.83 s
2024-05-07 20:57:45.045159: 
2024-05-07 20:57:45.047307: Epoch 105
2024-05-07 20:57:45.048889: Current learning rate: 0.00905
2024-05-07 21:01:39.939474: Validation loss did not improve from -0.63371. Patience: 8/50
2024-05-07 21:01:39.941009: train_loss -0.8128
2024-05-07 21:01:39.942277: val_loss -0.5751
2024-05-07 21:01:39.943416: Pseudo dice [0.7006]
2024-05-07 21:01:39.944596: Epoch time: 234.9 s
2024-05-07 21:01:41.316487: 
2024-05-07 21:01:41.318712: Epoch 106
2024-05-07 21:01:41.320303: Current learning rate: 0.00904
2024-05-07 21:05:36.840671: Validation loss improved from -0.63371 to -0.64283! Patience: 8/50
2024-05-07 21:05:36.842753: train_loss -0.8147
2024-05-07 21:05:36.844545: val_loss -0.6428
2024-05-07 21:05:36.845654: Pseudo dice [0.7392]
2024-05-07 21:05:36.847023: Epoch time: 235.53 s
2024-05-07 21:05:36.848394: Yayy! New best EMA pseudo Dice: 0.7188
2024-05-07 21:05:38.543265: 
2024-05-07 21:05:38.545633: Epoch 107
2024-05-07 21:05:38.547074: Current learning rate: 0.00903
2024-05-07 21:09:35.874027: Validation loss did not improve from -0.64283. Patience: 1/50
2024-05-07 21:09:35.876425: train_loss -0.8172
2024-05-07 21:09:35.878010: val_loss -0.5578
2024-05-07 21:09:35.879191: Pseudo dice [0.6902]
2024-05-07 21:09:35.880342: Epoch time: 237.33 s
2024-05-07 21:09:37.285458: 
2024-05-07 21:09:37.288212: Epoch 108
2024-05-07 21:09:37.289625: Current learning rate: 0.00902
2024-05-07 21:13:34.492612: Validation loss did not improve from -0.64283. Patience: 2/50
2024-05-07 21:13:34.495474: train_loss -0.8127
2024-05-07 21:13:34.497324: val_loss -0.6066
2024-05-07 21:13:34.498531: Pseudo dice [0.7231]
2024-05-07 21:13:34.500283: Epoch time: 237.21 s
2024-05-07 21:13:35.854716: 
2024-05-07 21:13:35.857224: Epoch 109
2024-05-07 21:13:35.858689: Current learning rate: 0.00901
2024-05-07 21:17:32.729413: Validation loss did not improve from -0.64283. Patience: 3/50
2024-05-07 21:17:32.730897: train_loss -0.8133
2024-05-07 21:17:32.732119: val_loss -0.5836
2024-05-07 21:17:32.733391: Pseudo dice [0.7087]
2024-05-07 21:17:32.734838: Epoch time: 236.88 s
2024-05-07 21:17:34.471114: 
2024-05-07 21:17:34.473149: Epoch 110
2024-05-07 21:17:34.474213: Current learning rate: 0.009
2024-05-07 21:21:30.300297: Validation loss did not improve from -0.64283. Patience: 4/50
2024-05-07 21:21:30.302341: train_loss -0.818
2024-05-07 21:21:30.304422: val_loss -0.5772
2024-05-07 21:21:30.306252: Pseudo dice [0.7092]
2024-05-07 21:21:30.307615: Epoch time: 235.83 s
2024-05-07 21:21:34.530294: 
2024-05-07 21:21:34.532832: Epoch 111
2024-05-07 21:21:34.534096: Current learning rate: 0.009
2024-05-07 21:25:32.272247: Validation loss did not improve from -0.64283. Patience: 5/50
2024-05-07 21:25:32.273924: train_loss -0.8188
2024-05-07 21:25:32.275429: val_loss -0.5484
2024-05-07 21:25:32.276904: Pseudo dice [0.7006]
2024-05-07 21:25:32.278204: Epoch time: 237.75 s
2024-05-07 21:25:33.680647: 
2024-05-07 21:25:33.683164: Epoch 112
2024-05-07 21:25:33.684534: Current learning rate: 0.00899
2024-05-07 21:29:31.956640: Validation loss did not improve from -0.64283. Patience: 6/50
2024-05-07 21:29:31.958233: train_loss -0.8107
2024-05-07 21:29:31.959450: val_loss -0.6144
2024-05-07 21:29:31.960475: Pseudo dice [0.7263]
2024-05-07 21:29:31.961544: Epoch time: 238.28 s
2024-05-07 21:29:33.239430: 
2024-05-07 21:29:33.242085: Epoch 113
2024-05-07 21:29:33.243322: Current learning rate: 0.00898
2024-05-07 21:33:28.727357: Validation loss did not improve from -0.64283. Patience: 7/50
2024-05-07 21:33:28.728809: train_loss -0.8203
2024-05-07 21:33:28.730020: val_loss -0.5856
2024-05-07 21:33:28.731311: Pseudo dice [0.7262]
2024-05-07 21:33:28.732702: Epoch time: 235.49 s
2024-05-07 21:33:30.022371: 
2024-05-07 21:33:30.024413: Epoch 114
2024-05-07 21:33:30.025813: Current learning rate: 0.00897
2024-05-07 21:37:26.112681: Validation loss did not improve from -0.64283. Patience: 8/50
2024-05-07 21:37:26.114945: train_loss -0.8175
2024-05-07 21:37:26.116367: val_loss -0.5372
2024-05-07 21:37:26.117596: Pseudo dice [0.6736]
2024-05-07 21:37:26.118697: Epoch time: 236.09 s
2024-05-07 21:37:28.025459: 
2024-05-07 21:37:28.027495: Epoch 115
2024-05-07 21:37:28.028899: Current learning rate: 0.00896
2024-05-07 21:41:22.311055: Validation loss did not improve from -0.64283. Patience: 9/50
2024-05-07 21:41:22.312728: train_loss -0.8103
2024-05-07 21:41:22.314691: val_loss -0.6151
2024-05-07 21:41:22.316276: Pseudo dice [0.7278]
2024-05-07 21:41:22.317330: Epoch time: 234.29 s
2024-05-07 21:41:23.659174: 
2024-05-07 21:41:23.661353: Epoch 116
2024-05-07 21:41:23.662808: Current learning rate: 0.00895
2024-05-07 21:45:18.961439: Validation loss did not improve from -0.64283. Patience: 10/50
2024-05-07 21:45:18.964634: train_loss -0.8086
2024-05-07 21:45:18.967495: val_loss -0.5689
2024-05-07 21:45:18.968935: Pseudo dice [0.7095]
2024-05-07 21:45:18.971185: Epoch time: 235.31 s
2024-05-07 21:45:20.391982: 
2024-05-07 21:45:20.394500: Epoch 117
2024-05-07 21:45:20.396229: Current learning rate: 0.00894
2024-05-07 21:49:13.883920: Validation loss did not improve from -0.64283. Patience: 11/50
2024-05-07 21:49:13.886872: train_loss -0.817
2024-05-07 21:49:13.888864: val_loss -0.588
2024-05-07 21:49:13.890146: Pseudo dice [0.7191]
2024-05-07 21:49:13.891744: Epoch time: 233.5 s
2024-05-07 21:49:15.179318: 
2024-05-07 21:49:15.182214: Epoch 118
2024-05-07 21:49:15.184086: Current learning rate: 0.00893
2024-05-07 21:53:08.862032: Validation loss did not improve from -0.64283. Patience: 12/50
2024-05-07 21:53:08.863684: train_loss -0.8169
2024-05-07 21:53:08.864954: val_loss -0.5922
2024-05-07 21:53:08.866049: Pseudo dice [0.72]
2024-05-07 21:53:08.867345: Epoch time: 233.69 s
2024-05-07 21:53:10.434414: 
2024-05-07 21:53:10.436857: Epoch 119
2024-05-07 21:53:10.438200: Current learning rate: 0.00892
2024-05-07 21:57:04.218626: Validation loss did not improve from -0.64283. Patience: 13/50
2024-05-07 21:57:04.220134: train_loss -0.8162
2024-05-07 21:57:04.221355: val_loss -0.5513
2024-05-07 21:57:04.222344: Pseudo dice [0.7058]
2024-05-07 21:57:04.223454: Epoch time: 233.79 s
2024-05-07 21:57:05.988310: 
2024-05-07 21:57:05.990629: Epoch 120
2024-05-07 21:57:05.992235: Current learning rate: 0.00891
2024-05-07 22:00:59.266984: Validation loss did not improve from -0.64283. Patience: 14/50
2024-05-07 22:00:59.268844: train_loss -0.8121
2024-05-07 22:00:59.270267: val_loss -0.5925
2024-05-07 22:00:59.271883: Pseudo dice [0.7184]
2024-05-07 22:00:59.272889: Epoch time: 233.28 s
2024-05-07 22:01:00.541385: 
2024-05-07 22:01:00.543625: Epoch 121
2024-05-07 22:01:00.544900: Current learning rate: 0.0089
2024-05-07 22:04:54.765169: Validation loss did not improve from -0.64283. Patience: 15/50
2024-05-07 22:04:54.767535: train_loss -0.81
2024-05-07 22:04:54.769708: val_loss -0.5797
2024-05-07 22:04:54.771206: Pseudo dice [0.7117]
2024-05-07 22:04:54.772739: Epoch time: 234.23 s
2024-05-07 22:04:58.327111: 
2024-05-07 22:04:58.329358: Epoch 122
2024-05-07 22:04:58.330681: Current learning rate: 0.00889
2024-05-07 22:08:52.730914: Validation loss did not improve from -0.64283. Patience: 16/50
2024-05-07 22:08:52.732638: train_loss -0.8131
2024-05-07 22:08:52.734025: val_loss -0.5753
2024-05-07 22:08:52.735210: Pseudo dice [0.7038]
2024-05-07 22:08:52.736910: Epoch time: 234.41 s
2024-05-07 22:08:54.048537: 
2024-05-07 22:08:54.050758: Epoch 123
2024-05-07 22:08:54.052449: Current learning rate: 0.00889
2024-05-07 22:12:49.252742: Validation loss did not improve from -0.64283. Patience: 17/50
2024-05-07 22:12:49.255252: train_loss -0.8221
2024-05-07 22:12:49.258164: val_loss -0.5809
2024-05-07 22:12:49.260010: Pseudo dice [0.7102]
2024-05-07 22:12:49.261329: Epoch time: 235.21 s
2024-05-07 22:12:50.635350: 
2024-05-07 22:12:50.637099: Epoch 124
2024-05-07 22:12:50.638698: Current learning rate: 0.00888
2024-05-07 22:16:45.361487: Validation loss did not improve from -0.64283. Patience: 18/50
2024-05-07 22:16:45.363118: train_loss -0.822
2024-05-07 22:16:45.364771: val_loss -0.6008
2024-05-07 22:16:45.365873: Pseudo dice [0.7178]
2024-05-07 22:16:45.367050: Epoch time: 234.73 s
2024-05-07 22:16:47.101259: 
2024-05-07 22:16:47.103085: Epoch 125
2024-05-07 22:16:47.104357: Current learning rate: 0.00887
2024-05-07 22:20:41.852946: Validation loss did not improve from -0.64283. Patience: 19/50
2024-05-07 22:20:41.855127: train_loss -0.8204
2024-05-07 22:20:41.857073: val_loss -0.6043
2024-05-07 22:20:41.858408: Pseudo dice [0.7274]
2024-05-07 22:20:41.859638: Epoch time: 234.75 s
2024-05-07 22:20:43.272830: 
2024-05-07 22:20:43.275413: Epoch 126
2024-05-07 22:20:43.279303: Current learning rate: 0.00886
2024-05-07 22:24:39.646746: Validation loss did not improve from -0.64283. Patience: 20/50
2024-05-07 22:24:39.648916: train_loss -0.8233
2024-05-07 22:24:39.650583: val_loss -0.6049
2024-05-07 22:24:39.651831: Pseudo dice [0.7286]
2024-05-07 22:24:39.652986: Epoch time: 236.38 s
2024-05-07 22:24:41.037104: 
2024-05-07 22:24:41.039794: Epoch 127
2024-05-07 22:24:41.041209: Current learning rate: 0.00885
2024-05-07 22:28:37.647274: Validation loss did not improve from -0.64283. Patience: 21/50
2024-05-07 22:28:37.648747: train_loss -0.8293
2024-05-07 22:28:37.650329: val_loss -0.5488
2024-05-07 22:28:37.651930: Pseudo dice [0.6866]
2024-05-07 22:28:37.653272: Epoch time: 236.61 s
2024-05-07 22:28:38.982426: 
2024-05-07 22:28:38.984588: Epoch 128
2024-05-07 22:28:38.986459: Current learning rate: 0.00884
2024-05-07 22:32:34.927228: Validation loss did not improve from -0.64283. Patience: 22/50
2024-05-07 22:32:34.929627: train_loss -0.8236
2024-05-07 22:32:34.931247: val_loss -0.5977
2024-05-07 22:32:34.932439: Pseudo dice [0.7213]
2024-05-07 22:32:34.933836: Epoch time: 235.95 s
2024-05-07 22:32:36.241743: 
2024-05-07 22:32:36.244503: Epoch 129
2024-05-07 22:32:36.246086: Current learning rate: 0.00883
2024-05-07 22:36:34.127188: Validation loss did not improve from -0.64283. Patience: 23/50
2024-05-07 22:36:34.129036: train_loss -0.8281
2024-05-07 22:36:34.130778: val_loss -0.5542
2024-05-07 22:36:34.132492: Pseudo dice [0.6968]
2024-05-07 22:36:34.134401: Epoch time: 237.89 s
2024-05-07 22:36:35.973043: 
2024-05-07 22:36:35.975086: Epoch 130
2024-05-07 22:36:35.976814: Current learning rate: 0.00882
2024-05-07 22:40:33.749295: Validation loss did not improve from -0.64283. Patience: 24/50
2024-05-07 22:40:33.751647: train_loss -0.8248
2024-05-07 22:40:33.753278: val_loss -0.5751
2024-05-07 22:40:33.754630: Pseudo dice [0.7105]
2024-05-07 22:40:33.755719: Epoch time: 237.78 s
2024-05-07 22:40:35.188132: 
2024-05-07 22:40:35.189752: Epoch 131
2024-05-07 22:40:35.190856: Current learning rate: 0.00881
2024-05-07 22:44:33.208820: Validation loss did not improve from -0.64283. Patience: 25/50
2024-05-07 22:44:33.211085: train_loss -0.8283
2024-05-07 22:44:33.212824: val_loss -0.5977
2024-05-07 22:44:33.214241: Pseudo dice [0.7203]
2024-05-07 22:44:33.215637: Epoch time: 238.02 s
2024-05-07 22:44:34.628384: 
2024-05-07 22:44:34.630473: Epoch 132
2024-05-07 22:44:34.632074: Current learning rate: 0.0088
2024-05-07 22:48:29.786156: Validation loss did not improve from -0.64283. Patience: 26/50
2024-05-07 22:48:29.788473: train_loss -0.8275
2024-05-07 22:48:29.826886: val_loss -0.5613
2024-05-07 22:48:29.828626: Pseudo dice [0.7051]
2024-05-07 22:48:29.830921: Epoch time: 235.16 s
2024-05-07 22:48:31.423435: 
2024-05-07 22:48:31.425434: Epoch 133
2024-05-07 22:48:31.426868: Current learning rate: 0.00879
2024-05-07 22:52:26.960961: Validation loss did not improve from -0.64283. Patience: 27/50
2024-05-07 22:52:26.962656: train_loss -0.8279
2024-05-07 22:52:26.964386: val_loss -0.5869
2024-05-07 22:52:26.965486: Pseudo dice [0.7236]
2024-05-07 22:52:26.966640: Epoch time: 235.54 s
2024-05-07 22:52:30.553765: 
2024-05-07 22:52:30.556005: Epoch 134
2024-05-07 22:52:30.557371: Current learning rate: 0.00879
2024-05-07 22:56:26.465964: Validation loss did not improve from -0.64283. Patience: 28/50
2024-05-07 22:56:26.467636: train_loss -0.8245
2024-05-07 22:56:26.469313: val_loss -0.542
2024-05-07 22:56:26.470969: Pseudo dice [0.6948]
2024-05-07 22:56:26.472461: Epoch time: 235.92 s
2024-05-07 22:56:28.308094: 
2024-05-07 22:56:28.310063: Epoch 135
2024-05-07 22:56:28.311698: Current learning rate: 0.00878
2024-05-07 23:00:24.527693: Validation loss did not improve from -0.64283. Patience: 29/50
2024-05-07 23:00:24.529508: train_loss -0.8246
2024-05-07 23:00:24.531156: val_loss -0.5803
2024-05-07 23:00:24.532922: Pseudo dice [0.7125]
2024-05-07 23:00:24.534162: Epoch time: 236.22 s
2024-05-07 23:00:25.959003: 
2024-05-07 23:00:25.961328: Epoch 136
2024-05-07 23:00:25.962836: Current learning rate: 0.00877
2024-05-07 23:04:22.060467: Validation loss did not improve from -0.64283. Patience: 30/50
2024-05-07 23:04:22.062015: train_loss -0.8304
2024-05-07 23:04:22.063832: val_loss -0.6
2024-05-07 23:04:22.065351: Pseudo dice [0.7324]
2024-05-07 23:04:22.066766: Epoch time: 236.1 s
2024-05-07 23:04:23.435461: 
2024-05-07 23:04:23.438070: Epoch 137
2024-05-07 23:04:23.439470: Current learning rate: 0.00876
2024-05-07 23:08:19.538845: Validation loss did not improve from -0.64283. Patience: 31/50
2024-05-07 23:08:19.540433: train_loss -0.8309
2024-05-07 23:08:19.542135: val_loss -0.5729
2024-05-07 23:08:19.543583: Pseudo dice [0.7055]
2024-05-07 23:08:19.544793: Epoch time: 236.11 s
2024-05-07 23:08:21.020765: 
2024-05-07 23:08:21.022712: Epoch 138
2024-05-07 23:08:21.023846: Current learning rate: 0.00875
2024-05-07 23:12:17.031039: Validation loss did not improve from -0.64283. Patience: 32/50
2024-05-07 23:12:17.033256: train_loss -0.8288
2024-05-07 23:12:17.034825: val_loss -0.5751
2024-05-07 23:12:17.036328: Pseudo dice [0.717]
2024-05-07 23:12:17.037591: Epoch time: 236.01 s
2024-05-07 23:12:18.479465: 
2024-05-07 23:12:18.481499: Epoch 139
2024-05-07 23:12:18.483305: Current learning rate: 0.00874
2024-05-07 23:16:14.153143: Validation loss did not improve from -0.64283. Patience: 33/50
2024-05-07 23:16:14.154957: train_loss -0.826
2024-05-07 23:16:14.156919: val_loss -0.5979
2024-05-07 23:16:14.158331: Pseudo dice [0.7193]
2024-05-07 23:16:14.159730: Epoch time: 235.68 s
2024-05-07 23:16:16.123020: 
2024-05-07 23:16:16.125767: Epoch 140
2024-05-07 23:16:16.127450: Current learning rate: 0.00873
2024-05-07 23:20:13.671351: Validation loss did not improve from -0.64283. Patience: 34/50
2024-05-07 23:20:13.673184: train_loss -0.8314
2024-05-07 23:20:13.674971: val_loss -0.5716
2024-05-07 23:20:13.676687: Pseudo dice [0.702]
2024-05-07 23:20:13.678131: Epoch time: 237.55 s
2024-05-07 23:20:15.136025: 
2024-05-07 23:20:15.138233: Epoch 141
2024-05-07 23:20:15.139689: Current learning rate: 0.00872
2024-05-07 23:24:11.476955: Validation loss did not improve from -0.64283. Patience: 35/50
2024-05-07 23:24:11.478866: train_loss -0.8258
2024-05-07 23:24:11.480324: val_loss -0.5713
2024-05-07 23:24:11.482015: Pseudo dice [0.7109]
2024-05-07 23:24:11.483978: Epoch time: 236.34 s
2024-05-07 23:24:12.925531: 
2024-05-07 23:24:12.927790: Epoch 142
2024-05-07 23:24:12.929103: Current learning rate: 0.00871
2024-05-07 23:28:08.457231: Validation loss did not improve from -0.64283. Patience: 36/50
2024-05-07 23:28:08.459543: train_loss -0.8383
2024-05-07 23:28:08.461128: val_loss -0.5668
2024-05-07 23:28:08.462204: Pseudo dice [0.7138]
2024-05-07 23:28:08.463392: Epoch time: 235.54 s
2024-05-07 23:28:09.946818: 
2024-05-07 23:28:09.949584: Epoch 143
2024-05-07 23:28:09.951824: Current learning rate: 0.0087
2024-05-07 23:32:07.923374: Validation loss did not improve from -0.64283. Patience: 37/50
2024-05-07 23:32:07.925088: train_loss -0.8319
2024-05-07 23:32:07.926301: val_loss -0.5702
2024-05-07 23:32:07.927444: Pseudo dice [0.7168]
2024-05-07 23:32:07.928570: Epoch time: 237.98 s
2024-05-07 23:32:09.340722: 
2024-05-07 23:32:09.342952: Epoch 144
2024-05-07 23:32:09.344450: Current learning rate: 0.00869
2024-05-07 23:36:04.109897: Validation loss did not improve from -0.64283. Patience: 38/50
2024-05-07 23:36:04.111836: train_loss -0.8298
2024-05-07 23:36:04.113357: val_loss -0.6087
2024-05-07 23:36:04.114579: Pseudo dice [0.7342]
2024-05-07 23:36:04.115630: Epoch time: 234.77 s
2024-05-07 23:36:06.260131: 
2024-05-07 23:36:06.264951: Epoch 145
2024-05-07 23:36:06.266828: Current learning rate: 0.00868
2024-05-07 23:40:02.779968: Validation loss did not improve from -0.64283. Patience: 39/50
2024-05-07 23:40:02.782054: train_loss -0.8339
2024-05-07 23:40:02.783221: val_loss -0.611
2024-05-07 23:40:02.784400: Pseudo dice [0.7318]
2024-05-07 23:40:02.785526: Epoch time: 236.52 s
2024-05-07 23:40:04.180484: 
2024-05-07 23:40:04.182612: Epoch 146
2024-05-07 23:40:04.184232: Current learning rate: 0.00868
2024-05-07 23:43:59.845199: Validation loss did not improve from -0.64283. Patience: 40/50
2024-05-07 23:43:59.847209: train_loss -0.8344
2024-05-07 23:43:59.849199: val_loss -0.542
2024-05-07 23:43:59.850253: Pseudo dice [0.6996]
2024-05-07 23:43:59.851320: Epoch time: 235.67 s
2024-05-07 23:44:01.252369: 
2024-05-07 23:44:01.254405: Epoch 147
2024-05-07 23:44:01.255475: Current learning rate: 0.00867
2024-05-07 23:47:56.531796: Validation loss did not improve from -0.64283. Patience: 41/50
2024-05-07 23:47:56.535105: train_loss -0.8342
2024-05-07 23:47:56.537326: val_loss -0.5895
2024-05-07 23:47:56.538943: Pseudo dice [0.7095]
2024-05-07 23:47:56.541403: Epoch time: 235.28 s
2024-05-07 23:47:58.002179: 
2024-05-07 23:47:58.004760: Epoch 148
2024-05-07 23:47:58.006330: Current learning rate: 0.00866
2024-05-07 23:51:54.363595: Validation loss did not improve from -0.64283. Patience: 42/50
2024-05-07 23:51:54.365290: train_loss -0.836
2024-05-07 23:51:54.366740: val_loss -0.601
2024-05-07 23:51:54.368532: Pseudo dice [0.7296]
2024-05-07 23:51:54.370505: Epoch time: 236.36 s
2024-05-07 23:51:55.727422: 
2024-05-07 23:51:55.730258: Epoch 149
2024-05-07 23:51:55.731859: Current learning rate: 0.00865
2024-05-07 23:55:50.923478: Validation loss did not improve from -0.64283. Patience: 43/50
2024-05-07 23:55:50.925962: train_loss -0.833
2024-05-07 23:55:50.928658: val_loss -0.6154
2024-05-07 23:55:50.929955: Pseudo dice [0.7402]
2024-05-07 23:55:50.931214: Epoch time: 235.2 s
2024-05-07 23:55:52.891405: 
2024-05-07 23:55:52.893606: Epoch 150
2024-05-07 23:55:52.894866: Current learning rate: 0.00864
2024-05-07 23:59:48.493532: Validation loss did not improve from -0.64283. Patience: 44/50
2024-05-07 23:59:48.495370: train_loss -0.8365
2024-05-07 23:59:48.497135: val_loss -0.5846
2024-05-07 23:59:48.498955: Pseudo dice [0.7264]
2024-05-07 23:59:48.500985: Epoch time: 235.61 s
2024-05-07 23:59:48.502515: Yayy! New best EMA pseudo Dice: 0.7192
2024-05-07 23:59:50.240376: 
2024-05-07 23:59:50.243006: Epoch 151
2024-05-07 23:59:50.245184: Current learning rate: 0.00863
2024-05-08 00:03:45.633365: Validation loss did not improve from -0.64283. Patience: 45/50
2024-05-08 00:03:45.636178: train_loss -0.8255
2024-05-08 00:03:45.637999: val_loss -0.5585
2024-05-08 00:03:45.639160: Pseudo dice [0.7074]
2024-05-08 00:03:45.640950: Epoch time: 235.4 s
2024-05-08 00:03:47.179580: 
2024-05-08 00:03:47.395962: Epoch 152
2024-05-08 00:03:47.397506: Current learning rate: 0.00862
2024-05-08 00:07:46.011774: Validation loss did not improve from -0.64283. Patience: 46/50
2024-05-08 00:07:46.013259: train_loss -0.8251
2024-05-08 00:07:46.014556: val_loss -0.6074
2024-05-08 00:07:46.015666: Pseudo dice [0.7199]
2024-05-08 00:07:46.016933: Epoch time: 238.84 s
2024-05-08 00:07:47.474328: 
2024-05-08 00:07:47.476077: Epoch 153
2024-05-08 00:07:47.477825: Current learning rate: 0.00861
2024-05-08 00:11:43.088995: Validation loss did not improve from -0.64283. Patience: 47/50
2024-05-08 00:11:43.090479: train_loss -0.8304
2024-05-08 00:11:43.091694: val_loss -0.6011
2024-05-08 00:11:43.092676: Pseudo dice [0.7263]
2024-05-08 00:11:43.093702: Epoch time: 235.62 s
2024-05-08 00:11:44.993431: 
2024-05-08 00:11:44.995224: Epoch 154
2024-05-08 00:11:44.996399: Current learning rate: 0.0086
2024-05-08 00:15:40.540908: Validation loss did not improve from -0.64283. Patience: 48/50
2024-05-08 00:15:40.543487: train_loss -0.8331
2024-05-08 00:15:40.545099: val_loss -0.5673
2024-05-08 00:15:40.546502: Pseudo dice [0.6985]
2024-05-08 00:15:40.547857: Epoch time: 235.55 s
2024-05-08 00:15:42.367056: 
2024-05-08 00:15:42.369093: Epoch 155
2024-05-08 00:15:42.370218: Current learning rate: 0.00859
2024-05-08 00:19:37.547298: Validation loss did not improve from -0.64283. Patience: 49/50
2024-05-08 00:19:37.548902: train_loss -0.8312
2024-05-08 00:19:37.550914: val_loss -0.6019
2024-05-08 00:19:37.552408: Pseudo dice [0.7302]
2024-05-08 00:19:37.554344: Epoch time: 235.18 s
2024-05-08 00:19:41.869320: 
2024-05-08 00:19:41.871598: Epoch 156
2024-05-08 00:19:41.873583: Current learning rate: 0.00858
2024-05-08 00:23:36.723125: Validation loss did not improve from -0.64283. Patience: 50/50
2024-05-08 00:23:36.724716: train_loss -0.833
2024-05-08 00:23:36.726122: val_loss -0.5617
2024-05-08 00:23:36.727337: Pseudo dice [0.7104]
2024-05-08 00:23:36.728372: Epoch time: 234.86 s
2024-05-08 00:23:38.104476: Patience reached. Stopping training.
2024-05-08 00:23:38.729531: Training done.
2024-05-08 00:23:40.498536: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset302_Calcium_OCTv2/splits_final.json
2024-05-08 00:23:40.520374: The split file contains 3 splits.
2024-05-08 00:23:40.522331: Desired fold for training: 0
2024-05-08 00:23:40.523615: This split has 4 training and 2 validation cases.
2024-05-08 00:23:40.525076: predicting 101-019
2024-05-08 00:23:40.680144: 101-019, shape torch.Size([1, 375, 498, 498]), rank 0
2024-05-08 00:25:21.469516: predicting 704-003
2024-05-08 00:25:21.487440: 704-003, shape torch.Size([1, 375, 498, 498]), rank 0
2024-05-08 00:29:40.778800: Validation complete
2024-05-08 00:29:40.780008: Mean Validation Dice:  0.6960887920704024
wandb: 
wandb: Run history:
wandb:            ema_fg_dice 
wandb:   epoch_end_timestamps 
wandb: epoch_start_timestamps 
wandb:                    lrs 
wandb:           mean_fg_dice 
wandb:           train_losses 
wandb:             val_losses 
wandb: 
wandb: Run summary:
wandb:            ema_fg_dice 0.71751
wandb:   epoch_end_timestamps 1715142216.72454
wandb: epoch_start_timestamps 1715141981.86693
wandb:                    lrs 0.00858
wandb:           mean_fg_dice 0.71039
wandb:           train_losses -0.83303
wandb:             val_losses -0.56168
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset302_Calcium_OCTv2/nnUNetTrainer__nnUNetPlans__3d_128x512x512_b10/fold_0/wandb/offline-run-20240507_135928-1ffqy9wa
wandb: Find logs at: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset302_Calcium_OCTv2/nnUNetTrainer__nnUNetPlans__3d_128x512x512_b10/fold_0/wandb/offline-run-20240507_135928-1ffqy9wa/logs
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6d0c88ca00>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6cf2df2ac0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6d0c907b20>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6cf2f333d0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6cfce32ac0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6cede5dd00>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
FOLD 0 CONFIG 3d_128x512x512_b10 TRAINER nnUNetTrainer
usage: nnUNetv2_predict [-h] -i I -o O -d D [-p P] [-tr TR] -c C
                        [-f F [F ...]] [-step_size STEP_SIZE] [--disable_tta]
                        [--verbose] [--save_probabilities]
                        [--continue_prediction] [-chk CHK] [-npp NPP]
                        [-nps NPS]
                        [-prev_stage_predictions PREV_STAGE_PREDICTIONS]
                        [-num_parts NUM_PARTS] [-part_id PART_ID]
                        [-device DEVICE] [--disable_progress_bar]
nnUNetv2_predict: error: argument -d: expected one argument

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

Traceback (most recent call last):
  File "/home/gridsan/nchutisilp/.local/bin/nnUNetv2_evaluate_simple", line 8, in <module>
    sys.exit(evaluate_simple_entry_point())
  File "/home/gridsan/nchutisilp/projects/nnUNet/nnunetv2/evaluation/evaluate_predictions.py", line 251, in evaluate_simple_entry_point
    compute_metrics_on_folder_simple(args.gt_folder, args.pred_folder, args.l, args.o, args.np, args.il, chill=args.chill)
  File "/home/gridsan/nchutisilp/projects/nnUNet/nnunetv2/evaluation/evaluate_predictions.py", line 213, in compute_metrics_on_folder_simple
    compute_metrics_on_folder(folder_ref, folder_pred, output_file, rw, file_ending,
  File "/home/gridsan/nchutisilp/projects/nnUNet/nnunetv2/evaluation/evaluate_predictions.py", line 139, in compute_metrics_on_folder
    assert all(present), "Not all files in folder_ref exist in folder_pred"
AssertionError: Not all files in folder_ref exist in folder_pred
Completed FOLD 0 CONFIG 3d_128x512x512_b10 TRAINER nnUNetTrainer
