/home/gridsan/nchutisilp/.conda/envs/nnunet/bin/python
wandb: Tracking run with wandb version 0.16.6
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2024-11-15 06:50:28.819153: Using torch.compile...
/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
################### Loading pretrained weights from file  /home/gridsan/nchutisilp/projects/OpenAI-CLIP/logs/CLIP_PreIVL_PostStent_wd/nnunet.pt ###################
Below is the list of overlapping blocks in pretrained model and nnUNet architecture:
encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])
encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])
encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])
encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])
encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])
encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])
encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])
encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])
encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])
encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])
encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])
encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])
encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])
encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])
encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])
encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])
encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])
encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])
encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])
encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])
encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])
encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])
encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])
encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])
encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])
encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])
encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])
decoder.encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])
decoder.encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])
decoder.encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])
decoder.encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])
decoder.encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])
decoder.encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])
decoder.encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])
decoder.encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])
decoder.encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])
decoder.encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])
decoder.encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])
decoder.encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])
decoder.encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])
decoder.encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.stages.0.convs.0.conv.weight shape torch.Size([320, 640, 3, 3, 3])
decoder.stages.0.convs.0.conv.bias shape torch.Size([320])
decoder.stages.0.convs.0.norm.weight shape torch.Size([320])
decoder.stages.0.convs.0.norm.bias shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.0.weight shape torch.Size([320, 640, 3, 3, 3])
decoder.stages.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.stages.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.stages.0.convs.1.conv.bias shape torch.Size([320])
decoder.stages.0.convs.1.norm.weight shape torch.Size([320])
decoder.stages.0.convs.1.norm.bias shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.stages.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.stages.1.convs.0.conv.weight shape torch.Size([256, 512, 3, 3, 3])
decoder.stages.1.convs.0.conv.bias shape torch.Size([256])
decoder.stages.1.convs.0.norm.weight shape torch.Size([256])
decoder.stages.1.convs.0.norm.bias shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.0.weight shape torch.Size([256, 512, 3, 3, 3])
decoder.stages.1.convs.0.all_modules.0.bias shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.1.weight shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.1.bias shape torch.Size([256])
decoder.stages.1.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.stages.1.convs.1.conv.bias shape torch.Size([256])
decoder.stages.1.convs.1.norm.weight shape torch.Size([256])
decoder.stages.1.convs.1.norm.bias shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.stages.1.convs.1.all_modules.0.bias shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.1.weight shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.1.bias shape torch.Size([256])
decoder.stages.2.convs.0.conv.weight shape torch.Size([128, 256, 3, 3, 3])
decoder.stages.2.convs.0.conv.bias shape torch.Size([128])
decoder.stages.2.convs.0.norm.weight shape torch.Size([128])
decoder.stages.2.convs.0.norm.bias shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.0.weight shape torch.Size([128, 256, 3, 3, 3])
decoder.stages.2.convs.0.all_modules.0.bias shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.1.weight shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.1.bias shape torch.Size([128])
decoder.stages.2.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.stages.2.convs.1.conv.bias shape torch.Size([128])
decoder.stages.2.convs.1.norm.weight shape torch.Size([128])
decoder.stages.2.convs.1.norm.bias shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.stages.2.convs.1.all_modules.0.bias shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.1.weight shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.1.bias shape torch.Size([128])
decoder.stages.3.convs.0.conv.weight shape torch.Size([64, 128, 3, 3, 3])
decoder.stages.3.convs.0.conv.bias shape torch.Size([64])
decoder.stages.3.convs.0.norm.weight shape torch.Size([64])
decoder.stages.3.convs.0.norm.bias shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.0.weight shape torch.Size([64, 128, 3, 3, 3])
decoder.stages.3.convs.0.all_modules.0.bias shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.1.weight shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.1.bias shape torch.Size([64])
decoder.stages.3.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.stages.3.convs.1.conv.bias shape torch.Size([64])
decoder.stages.3.convs.1.norm.weight shape torch.Size([64])
decoder.stages.3.convs.1.norm.bias shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.stages.3.convs.1.all_modules.0.bias shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.1.weight shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.1.bias shape torch.Size([64])
decoder.stages.4.convs.0.conv.weight shape torch.Size([32, 64, 3, 3, 3])
decoder.stages.4.convs.0.conv.bias shape torch.Size([32])
decoder.stages.4.convs.0.norm.weight shape torch.Size([32])
decoder.stages.4.convs.0.norm.bias shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.0.weight shape torch.Size([32, 64, 3, 3, 3])
decoder.stages.4.convs.0.all_modules.0.bias shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.1.weight shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.1.bias shape torch.Size([32])
decoder.stages.4.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.stages.4.convs.1.conv.bias shape torch.Size([32])
decoder.stages.4.convs.1.norm.weight shape torch.Size([32])
decoder.stages.4.convs.1.norm.bias shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.stages.4.convs.1.all_modules.0.bias shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.1.weight shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.1.bias shape torch.Size([32])
decoder.transpconvs.0.weight shape torch.Size([320, 320, 1, 2, 2])
decoder.transpconvs.0.bias shape torch.Size([320])
decoder.transpconvs.1.weight shape torch.Size([320, 256, 2, 2, 2])
decoder.transpconvs.1.bias shape torch.Size([256])
decoder.transpconvs.2.weight shape torch.Size([256, 128, 2, 2, 2])
decoder.transpconvs.2.bias shape torch.Size([128])
decoder.transpconvs.3.weight shape torch.Size([128, 64, 2, 2, 2])
decoder.transpconvs.3.bias shape torch.Size([64])
decoder.transpconvs.4.weight shape torch.Size([64, 32, 2, 2, 2])
decoder.transpconvs.4.bias shape torch.Size([32])
################### Done ###################
2024-11-15 06:50:29.805164: do_dummy_2d_data_aug: True
2024-11-15 06:50:29.808792: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset302_Calcium_OCTv2/splits_final.json
2024-11-15 06:50:29.811686: The split file contains 3 splits.
2024-11-15 06:50:29.813120: Desired fold for training: 2
2024-11-15 06:50:29.814045: This split has 4 training and 2 validation cases.
using pin_memory on device 0
using pin_memory on device 0

This is the configuration used by this training:
Configuration name: 3d_32x160x128_b10
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 10, 'patch_size': [32, 160, 128], 'median_image_size_in_voxels': [375.0, 498.0, 498.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'inherits_from': '3d_fullres'} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset302_Calcium_OCTv2', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.4977976381778717, 'mean': 0.13332499563694, 'median': 0.08871842920780182, 'min': 0.0, 'percentile_00_5': 0.014754901640117168, 'percentile_99_5': 0.4977976381778717, 'std': 0.12022686749696732}}} 

2024-11-15 06:50:36.783106: unpacking dataset...
2024-11-15 06:50:41.656237: unpacking done...
2024-11-15 06:50:41.707322: Unable to plot network architecture: nnUNet_compile is enabled!
2024-11-15 06:50:41.770315: 
2024-11-15 06:50:41.771874: Epoch 0
2024-11-15 06:50:41.772896: Current learning rate: 0.0
2024-11-15 06:50:41.773949: encoder learning rate: 0.0
2024-11-15 06:50:41.774918: decoder.stages learning rate: 0.01
2024-11-15 06:50:41.775795: decoder.transpconvs learning rate: 0.01
2024-11-15 06:50:41.776708: decoder.seg_layers learning rate: 0.01
2024-11-15 06:54:24.568555: Validation loss improved from 1000.00000 to -0.14417! Patience: 0/50
2024-11-15 06:54:24.569916: train_loss -0.0305
2024-11-15 06:54:24.571068: val_loss -0.1442
2024-11-15 06:54:24.572104: Pseudo dice [0.5121]
2024-11-15 06:54:24.573130: Epoch time: 222.8 s
2024-11-15 06:54:24.574074: Yayy! New best EMA pseudo Dice: 0.5121
2024-11-15 06:54:26.148310: 
2024-11-15 06:54:26.150222: Epoch 1
2024-11-15 06:54:26.151662: Current learning rate: 0.0
2024-11-15 06:54:26.152861: encoder learning rate: 0.0
2024-11-15 06:54:26.154092: decoder.stages learning rate: 0.00992
2024-11-15 06:54:26.155180: decoder.transpconvs learning rate: 0.00992
2024-11-15 06:54:26.156282: decoder.seg_layers learning rate: 0.00992
2024-11-15 06:59:43.760649: Validation loss improved from -0.14417 to -0.17943! Patience: 0/50
2024-11-15 06:59:43.762165: train_loss -0.2052
2024-11-15 06:59:43.763556: val_loss -0.1794
2024-11-15 06:59:43.764658: Pseudo dice [0.5466]
2024-11-15 06:59:43.765699: Epoch time: 317.62 s
2024-11-15 06:59:43.766623: Yayy! New best EMA pseudo Dice: 0.5155
2024-11-15 06:59:45.449263: 
2024-11-15 06:59:45.450729: Epoch 2
2024-11-15 06:59:45.451915: Current learning rate: 0.0
2024-11-15 06:59:45.453121: encoder learning rate: 0.0
2024-11-15 06:59:45.454071: decoder.stages learning rate: 0.00985
2024-11-15 06:59:45.455120: decoder.transpconvs learning rate: 0.00985
2024-11-15 06:59:45.456031: decoder.seg_layers learning rate: 0.00985
2024-11-15 07:04:55.712900: Validation loss improved from -0.17943 to -0.23759! Patience: 0/50
2024-11-15 07:04:55.714363: train_loss -0.2641
2024-11-15 07:04:55.715379: val_loss -0.2376
2024-11-15 07:04:55.716158: Pseudo dice [0.5747]
2024-11-15 07:04:55.717027: Epoch time: 310.27 s
2024-11-15 07:04:55.717890: Yayy! New best EMA pseudo Dice: 0.5214
2024-11-15 07:04:57.426044: 
2024-11-15 07:04:57.427471: Epoch 3
2024-11-15 07:04:57.428427: Current learning rate: 0.0
2024-11-15 07:04:57.429335: encoder learning rate: 0.0
2024-11-15 07:04:57.430197: decoder.stages learning rate: 0.00977
2024-11-15 07:04:57.430986: decoder.transpconvs learning rate: 0.00977
2024-11-15 07:04:57.431720: decoder.seg_layers learning rate: 0.00977
2024-11-15 07:10:11.673961: Validation loss improved from -0.23759 to -0.27842! Patience: 0/50
2024-11-15 07:10:11.677739: train_loss -0.2827
2024-11-15 07:10:11.679137: val_loss -0.2784
2024-11-15 07:10:11.680220: Pseudo dice [0.6024]
2024-11-15 07:10:11.681183: Epoch time: 314.25 s
2024-11-15 07:10:11.682652: Yayy! New best EMA pseudo Dice: 0.5295
2024-11-15 07:10:13.343572: 
2024-11-15 07:10:13.345079: Epoch 4
2024-11-15 07:10:13.347631: Current learning rate: 0.0
2024-11-15 07:10:13.349233: encoder learning rate: 0.0
2024-11-15 07:10:13.350215: decoder.stages learning rate: 0.0097
2024-11-15 07:10:13.351050: decoder.transpconvs learning rate: 0.0097
2024-11-15 07:10:13.351876: decoder.seg_layers learning rate: 0.0097
2024-11-15 07:15:22.527617: Validation loss did not improve from -0.27842. Patience: 1/50
2024-11-15 07:15:22.528954: train_loss -0.3151
2024-11-15 07:15:22.530679: val_loss -0.2757
2024-11-15 07:15:22.531767: Pseudo dice [0.5975]
2024-11-15 07:15:22.532749: Epoch time: 309.19 s
2024-11-15 07:15:22.912089: Yayy! New best EMA pseudo Dice: 0.5363
2024-11-15 07:15:24.551088: 
2024-11-15 07:15:24.552696: Epoch 5
2024-11-15 07:15:24.553644: Current learning rate: 0.0
2024-11-15 07:15:24.554597: encoder learning rate: 0.0
2024-11-15 07:15:24.555353: decoder.stages learning rate: 0.00962
2024-11-15 07:15:24.556197: decoder.transpconvs learning rate: 0.00962
2024-11-15 07:15:24.557096: decoder.seg_layers learning rate: 0.00962
2024-11-15 07:20:23.674377: Validation loss did not improve from -0.27842. Patience: 2/50
2024-11-15 07:20:23.675978: train_loss -0.3219
2024-11-15 07:20:23.677533: val_loss -0.2408
2024-11-15 07:20:23.679125: Pseudo dice [0.5657]
2024-11-15 07:20:23.680297: Epoch time: 299.13 s
2024-11-15 07:20:23.681922: Yayy! New best EMA pseudo Dice: 0.5393
2024-11-15 07:20:25.274767: 
2024-11-15 07:20:25.277456: Epoch 6
2024-11-15 07:20:25.279109: Current learning rate: 0.0
2024-11-15 07:20:25.281055: encoder learning rate: 0.0
2024-11-15 07:20:25.283073: decoder.stages learning rate: 0.00955
2024-11-15 07:20:25.284482: decoder.transpconvs learning rate: 0.00955
2024-11-15 07:20:25.285386: decoder.seg_layers learning rate: 0.00955
2024-11-15 07:25:28.649496: Validation loss improved from -0.27842 to -0.29813! Patience: 2/50
2024-11-15 07:25:28.651000: train_loss -0.3431
2024-11-15 07:25:28.652114: val_loss -0.2981
2024-11-15 07:25:28.653128: Pseudo dice [0.6153]
2024-11-15 07:25:28.654250: Epoch time: 303.38 s
2024-11-15 07:25:28.655120: Yayy! New best EMA pseudo Dice: 0.5469
2024-11-15 07:25:30.280197: 
2024-11-15 07:25:30.281908: Epoch 7
2024-11-15 07:25:30.282860: Current learning rate: 0.0
2024-11-15 07:25:30.283926: encoder learning rate: 0.0
2024-11-15 07:25:30.284770: decoder.stages learning rate: 0.00947
2024-11-15 07:25:30.285593: decoder.transpconvs learning rate: 0.00947
2024-11-15 07:25:30.286564: decoder.seg_layers learning rate: 0.00947
2024-11-15 07:30:38.573262: Validation loss improved from -0.29813 to -0.30447! Patience: 0/50
2024-11-15 07:30:38.574702: train_loss -0.3473
2024-11-15 07:30:38.575669: val_loss -0.3045
2024-11-15 07:30:38.576522: Pseudo dice [0.6062]
2024-11-15 07:30:38.577380: Epoch time: 308.3 s
2024-11-15 07:30:38.578255: Yayy! New best EMA pseudo Dice: 0.5528
2024-11-15 07:30:40.628603: 
2024-11-15 07:30:40.630546: Epoch 8
2024-11-15 07:30:40.631472: Current learning rate: 0.0
2024-11-15 07:30:40.632466: encoder learning rate: 0.0
2024-11-15 07:30:40.633343: decoder.stages learning rate: 0.0094
2024-11-15 07:30:40.634576: decoder.transpconvs learning rate: 0.0094
2024-11-15 07:30:40.635441: decoder.seg_layers learning rate: 0.0094
2024-11-15 07:35:52.305373: Validation loss did not improve from -0.30447. Patience: 1/50
2024-11-15 07:35:52.306658: train_loss -0.3563
2024-11-15 07:35:52.307745: val_loss -0.2859
2024-11-15 07:35:52.308941: Pseudo dice [0.5965]
2024-11-15 07:35:52.310201: Epoch time: 311.68 s
2024-11-15 07:35:52.311083: Yayy! New best EMA pseudo Dice: 0.5572
2024-11-15 07:35:53.964145: 
2024-11-15 07:35:53.965768: Epoch 9
2024-11-15 07:35:53.966812: Current learning rate: 0.0
2024-11-15 07:35:53.967796: encoder learning rate: 0.0
2024-11-15 07:35:53.968651: decoder.stages learning rate: 0.00932
2024-11-15 07:35:53.969363: decoder.transpconvs learning rate: 0.00932
2024-11-15 07:35:53.970198: decoder.seg_layers learning rate: 0.00932
2024-11-15 07:41:12.340579: Validation loss improved from -0.30447 to -0.32361! Patience: 1/50
2024-11-15 07:41:12.341949: train_loss -0.3668
2024-11-15 07:41:12.343018: val_loss -0.3236
2024-11-15 07:41:12.343866: Pseudo dice [0.6308]
2024-11-15 07:41:12.345172: Epoch time: 318.38 s
2024-11-15 07:41:12.725752: Yayy! New best EMA pseudo Dice: 0.5645
2024-11-15 07:41:14.308126: 
2024-11-15 07:41:14.310019: Epoch 10
2024-11-15 07:41:14.310938: Current learning rate: 0.0
2024-11-15 07:41:14.311904: encoder learning rate: 0.0
2024-11-15 07:41:14.312830: decoder.stages learning rate: 0.00925
2024-11-15 07:41:14.313565: decoder.transpconvs learning rate: 0.00925
2024-11-15 07:41:14.314311: decoder.seg_layers learning rate: 0.00925
2024-11-15 07:46:42.383203: Validation loss improved from -0.32361 to -0.32704! Patience: 0/50
2024-11-15 07:46:42.384872: train_loss -0.3797
2024-11-15 07:46:42.386135: val_loss -0.327
2024-11-15 07:46:42.387010: Pseudo dice [0.6135]
2024-11-15 07:46:42.388200: Epoch time: 328.08 s
2024-11-15 07:46:42.389295: Yayy! New best EMA pseudo Dice: 0.5694
2024-11-15 07:46:43.988411: 
2024-11-15 07:46:43.990340: Epoch 11
2024-11-15 07:46:43.991420: Current learning rate: 0.0
2024-11-15 07:46:43.992544: encoder learning rate: 0.0
2024-11-15 07:46:43.993543: decoder.stages learning rate: 0.00917
2024-11-15 07:46:43.994592: decoder.transpconvs learning rate: 0.00917
2024-11-15 07:46:43.995599: decoder.seg_layers learning rate: 0.00917
2024-11-15 07:52:02.476192: Validation loss did not improve from -0.32704. Patience: 1/50
2024-11-15 07:52:02.477468: train_loss -0.3909
2024-11-15 07:52:02.478540: val_loss -0.3246
2024-11-15 07:52:02.479363: Pseudo dice [0.6185]
2024-11-15 07:52:02.480319: Epoch time: 318.49 s
2024-11-15 07:52:02.481109: Yayy! New best EMA pseudo Dice: 0.5743
2024-11-15 07:52:04.106727: 
2024-11-15 07:52:04.108229: Epoch 12
2024-11-15 07:52:04.109108: Current learning rate: 0.0
2024-11-15 07:52:04.110052: encoder learning rate: 0.0
2024-11-15 07:52:04.110855: decoder.stages learning rate: 0.0091
2024-11-15 07:52:04.111720: decoder.transpconvs learning rate: 0.0091
2024-11-15 07:52:04.112568: decoder.seg_layers learning rate: 0.0091
2024-11-15 07:57:36.755375: Validation loss did not improve from -0.32704. Patience: 2/50
2024-11-15 07:57:36.809829: train_loss -0.3992
2024-11-15 07:57:36.812350: val_loss -0.3222
2024-11-15 07:57:36.813403: Pseudo dice [0.6234]
2024-11-15 07:57:36.814872: Epoch time: 332.65 s
2024-11-15 07:57:36.815877: Yayy! New best EMA pseudo Dice: 0.5792
2024-11-15 07:57:38.872684: 
2024-11-15 07:57:38.874337: Epoch 13
2024-11-15 07:57:38.875289: Current learning rate: 0.0
2024-11-15 07:57:38.876764: encoder learning rate: 0.0
2024-11-15 07:57:38.877974: decoder.stages learning rate: 0.00902
2024-11-15 07:57:38.878850: decoder.transpconvs learning rate: 0.00902
2024-11-15 07:57:38.879575: decoder.seg_layers learning rate: 0.00902
2024-11-15 08:03:12.686780: Validation loss did not improve from -0.32704. Patience: 3/50
2024-11-15 08:03:12.715018: train_loss -0.3928
2024-11-15 08:03:12.717517: val_loss -0.3205
2024-11-15 08:03:12.718770: Pseudo dice [0.6107]
2024-11-15 08:03:12.720115: Epoch time: 333.84 s
2024-11-15 08:03:12.721158: Yayy! New best EMA pseudo Dice: 0.5824
2024-11-15 08:03:14.602215: 
2024-11-15 08:03:14.604049: Epoch 14
2024-11-15 08:03:14.605633: Current learning rate: 0.0
2024-11-15 08:03:14.607086: encoder learning rate: 0.0
2024-11-15 08:03:14.608347: decoder.stages learning rate: 0.00894
2024-11-15 08:03:14.609600: decoder.transpconvs learning rate: 0.00894
2024-11-15 08:03:14.610707: decoder.seg_layers learning rate: 0.00894
2024-11-15 08:08:27.592054: Validation loss did not improve from -0.32704. Patience: 4/50
2024-11-15 08:08:27.594122: train_loss -0.4045
2024-11-15 08:08:27.596076: val_loss -0.2636
2024-11-15 08:08:27.597788: Pseudo dice [0.5874]
2024-11-15 08:08:27.598951: Epoch time: 312.99 s
2024-11-15 08:08:27.945191: Yayy! New best EMA pseudo Dice: 0.5829
2024-11-15 08:08:29.624652: 
2024-11-15 08:08:29.626372: Epoch 15
2024-11-15 08:08:29.627289: Current learning rate: 0.0
2024-11-15 08:08:29.628205: encoder learning rate: 0.0
2024-11-15 08:08:29.629125: decoder.stages learning rate: 0.00887
2024-11-15 08:08:29.629917: decoder.transpconvs learning rate: 0.00887
2024-11-15 08:08:29.630821: decoder.seg_layers learning rate: 0.00887
2024-11-15 08:13:52.453604: Validation loss did not improve from -0.32704. Patience: 5/50
2024-11-15 08:13:52.454914: train_loss -0.4213
2024-11-15 08:13:52.455810: val_loss -0.3203
2024-11-15 08:13:52.456763: Pseudo dice [0.6079]
2024-11-15 08:13:52.457700: Epoch time: 322.83 s
2024-11-15 08:13:52.458548: Yayy! New best EMA pseudo Dice: 0.5854
2024-11-15 08:13:54.180110: 
2024-11-15 08:13:54.181821: Epoch 16
2024-11-15 08:13:54.183132: Current learning rate: 0.0
2024-11-15 08:13:54.184602: encoder learning rate: 0.0
2024-11-15 08:13:54.186246: decoder.stages learning rate: 0.00879
2024-11-15 08:13:54.187352: decoder.transpconvs learning rate: 0.00879
2024-11-15 08:13:54.188487: decoder.seg_layers learning rate: 0.00879
2024-11-15 08:19:25.050121: Validation loss improved from -0.32704 to -0.34671! Patience: 5/50
2024-11-15 08:19:25.051463: train_loss -0.4126
2024-11-15 08:19:25.052474: val_loss -0.3467
2024-11-15 08:19:25.053467: Pseudo dice [0.6338]
2024-11-15 08:19:25.054303: Epoch time: 330.87 s
2024-11-15 08:19:25.055038: Yayy! New best EMA pseudo Dice: 0.5902
2024-11-15 08:19:26.740098: 
2024-11-15 08:19:26.741503: Epoch 17
2024-11-15 08:19:26.742460: Current learning rate: 0.0
2024-11-15 08:19:26.743459: encoder learning rate: 0.0
2024-11-15 08:19:26.744318: decoder.stages learning rate: 0.00872
2024-11-15 08:19:26.745069: decoder.transpconvs learning rate: 0.00872
2024-11-15 08:19:26.745863: decoder.seg_layers learning rate: 0.00872
2024-11-15 08:25:03.522660: Validation loss did not improve from -0.34671. Patience: 1/50
2024-11-15 08:25:03.523968: train_loss -0.4296
2024-11-15 08:25:03.525140: val_loss -0.2911
2024-11-15 08:25:03.526055: Pseudo dice [0.5645]
2024-11-15 08:25:03.526992: Epoch time: 336.79 s
2024-11-15 08:25:04.808996: 
2024-11-15 08:25:04.811817: Epoch 18
2024-11-15 08:25:04.813485: Current learning rate: 0.0
2024-11-15 08:25:04.814518: encoder learning rate: 0.0
2024-11-15 08:25:04.815308: decoder.stages learning rate: 0.00864
2024-11-15 08:25:04.816180: decoder.transpconvs learning rate: 0.00864
2024-11-15 08:25:04.816960: decoder.seg_layers learning rate: 0.00864
2024-11-15 08:30:43.096811: Validation loss did not improve from -0.34671. Patience: 2/50
2024-11-15 08:30:43.098135: train_loss -0.4378
2024-11-15 08:30:43.099275: val_loss -0.33
2024-11-15 08:30:43.100207: Pseudo dice [0.6336]
2024-11-15 08:30:43.101165: Epoch time: 338.29 s
2024-11-15 08:30:43.102520: Yayy! New best EMA pseudo Dice: 0.5923
2024-11-15 08:30:47.976765: 
2024-11-15 08:30:47.978641: Epoch 19
2024-11-15 08:30:47.979450: Current learning rate: 0.0
2024-11-15 08:30:47.980354: encoder learning rate: 0.0
2024-11-15 08:30:47.981179: decoder.stages learning rate: 0.00856
2024-11-15 08:30:47.982142: decoder.transpconvs learning rate: 0.00856
2024-11-15 08:30:47.982955: decoder.seg_layers learning rate: 0.00856
2024-11-15 08:36:26.901626: Validation loss did not improve from -0.34671. Patience: 3/50
2024-11-15 08:36:26.903036: train_loss -0.4321
2024-11-15 08:36:26.904459: val_loss -0.2849
2024-11-15 08:36:26.905378: Pseudo dice [0.6083]
2024-11-15 08:36:26.906317: Epoch time: 338.93 s
2024-11-15 08:36:27.308323: Yayy! New best EMA pseudo Dice: 0.5939
2024-11-15 08:36:28.962335: 
2024-11-15 08:36:28.963906: Epoch 20
2024-11-15 08:36:28.964809: Current learning rate: 0.00849
2024-11-15 08:36:28.965785: encoder learning rate: 0.00849
2024-11-15 08:36:28.967154: decoder.stages learning rate: 0.00849
2024-11-15 08:36:28.968179: decoder.transpconvs learning rate: 0.00849
2024-11-15 08:36:28.969579: decoder.seg_layers learning rate: 0.00849
2024-11-15 08:42:01.844204: Validation loss did not improve from -0.34671. Patience: 4/50
2024-11-15 08:42:01.846471: train_loss -0.2523
2024-11-15 08:42:01.847753: val_loss -0.2766
2024-11-15 08:42:01.848687: Pseudo dice [0.5881]
2024-11-15 08:42:01.849585: Epoch time: 332.89 s
2024-11-15 08:42:03.227880: 
2024-11-15 08:42:03.229816: Epoch 21
2024-11-15 08:42:03.231050: Current learning rate: 0.00841
2024-11-15 08:42:03.232705: encoder learning rate: 0.00841
2024-11-15 08:42:03.233817: decoder.stages learning rate: 0.00841
2024-11-15 08:42:03.234610: decoder.transpconvs learning rate: 0.00841
2024-11-15 08:42:03.235332: decoder.seg_layers learning rate: 0.00841
2024-11-15 08:47:38.272888: Validation loss did not improve from -0.34671. Patience: 5/50
2024-11-15 08:47:38.274154: train_loss -0.3612
2024-11-15 08:47:38.275719: val_loss -0.3007
2024-11-15 08:47:38.276634: Pseudo dice [0.6174]
2024-11-15 08:47:38.277507: Epoch time: 335.05 s
2024-11-15 08:47:38.278341: Yayy! New best EMA pseudo Dice: 0.5957
2024-11-15 08:47:39.945170: 
2024-11-15 08:47:39.947824: Epoch 22
2024-11-15 08:47:39.949894: Current learning rate: 0.00833
2024-11-15 08:47:39.951421: encoder learning rate: 0.00833
2024-11-15 08:47:39.952508: decoder.stages learning rate: 0.00833
2024-11-15 08:47:39.953417: decoder.transpconvs learning rate: 0.00833
2024-11-15 08:47:39.954558: decoder.seg_layers learning rate: 0.00833
2024-11-15 08:53:17.746470: Validation loss did not improve from -0.34671. Patience: 6/50
2024-11-15 08:53:17.747741: train_loss -0.4164
2024-11-15 08:53:17.748912: val_loss -0.2767
2024-11-15 08:53:17.749773: Pseudo dice [0.5711]
2024-11-15 08:53:17.750619: Epoch time: 337.8 s
2024-11-15 08:53:19.067423: 
2024-11-15 08:53:19.069519: Epoch 23
2024-11-15 08:53:19.070944: Current learning rate: 0.00826
2024-11-15 08:53:19.072056: encoder learning rate: 0.00826
2024-11-15 08:53:19.072934: decoder.stages learning rate: 0.00826
2024-11-15 08:53:19.073833: decoder.transpconvs learning rate: 0.00826
2024-11-15 08:53:19.074691: decoder.seg_layers learning rate: 0.00826
2024-11-15 08:58:51.502794: Validation loss improved from -0.34671 to -0.34810! Patience: 6/50
2024-11-15 08:58:51.503793: train_loss -0.434
2024-11-15 08:58:51.504813: val_loss -0.3481
2024-11-15 08:58:51.506140: Pseudo dice [0.6314]
2024-11-15 08:58:51.507175: Epoch time: 332.44 s
2024-11-15 08:58:51.508065: Yayy! New best EMA pseudo Dice: 0.5971
2024-11-15 08:58:53.163609: 
2024-11-15 08:58:53.165159: Epoch 24
2024-11-15 08:58:53.166277: Current learning rate: 0.00818
2024-11-15 08:58:53.167416: encoder learning rate: 0.00818
2024-11-15 08:58:53.168388: decoder.stages learning rate: 0.00818
2024-11-15 08:58:53.169477: decoder.transpconvs learning rate: 0.00818
2024-11-15 08:58:53.170401: decoder.seg_layers learning rate: 0.00818
2024-11-15 09:04:39.573405: Validation loss improved from -0.34810 to -0.37219! Patience: 0/50
2024-11-15 09:04:39.579203: train_loss -0.4548
2024-11-15 09:04:39.582189: val_loss -0.3722
2024-11-15 09:04:39.583230: Pseudo dice [0.6435]
2024-11-15 09:04:39.584707: Epoch time: 346.42 s
2024-11-15 09:04:40.346975: Yayy! New best EMA pseudo Dice: 0.6017
2024-11-15 09:04:42.033963: 
2024-11-15 09:04:42.035990: Epoch 25
2024-11-15 09:04:42.036828: Current learning rate: 0.0081
2024-11-15 09:04:42.038392: encoder learning rate: 0.0081
2024-11-15 09:04:42.039604: decoder.stages learning rate: 0.0081
2024-11-15 09:04:42.040348: decoder.transpconvs learning rate: 0.0081
2024-11-15 09:04:42.041119: decoder.seg_layers learning rate: 0.0081
2024-11-15 09:10:21.582680: Validation loss did not improve from -0.37219. Patience: 1/50
2024-11-15 09:10:21.584940: train_loss -0.481
2024-11-15 09:10:21.587041: val_loss -0.3718
2024-11-15 09:10:21.588122: Pseudo dice [0.6517]
2024-11-15 09:10:21.589057: Epoch time: 339.55 s
2024-11-15 09:10:21.589962: Yayy! New best EMA pseudo Dice: 0.6067
2024-11-15 09:10:23.299407: 
2024-11-15 09:10:23.300910: Epoch 26
2024-11-15 09:10:23.301802: Current learning rate: 0.00803
2024-11-15 09:10:23.302654: encoder learning rate: 0.00803
2024-11-15 09:10:23.303524: decoder.stages learning rate: 0.00803
2024-11-15 09:10:23.304398: decoder.transpconvs learning rate: 0.00803
2024-11-15 09:10:23.305260: decoder.seg_layers learning rate: 0.00803
2024-11-15 09:15:59.113944: Validation loss improved from -0.37219 to -0.41184! Patience: 1/50
2024-11-15 09:15:59.115619: train_loss -0.486
2024-11-15 09:15:59.117437: val_loss -0.4118
2024-11-15 09:15:59.119047: Pseudo dice [0.6726]
2024-11-15 09:15:59.120310: Epoch time: 335.82 s
2024-11-15 09:15:59.121224: Yayy! New best EMA pseudo Dice: 0.6133
2024-11-15 09:16:00.834722: 
2024-11-15 09:16:00.836382: Epoch 27
2024-11-15 09:16:00.837465: Current learning rate: 0.00795
2024-11-15 09:16:00.838575: encoder learning rate: 0.00795
2024-11-15 09:16:00.839634: decoder.stages learning rate: 0.00795
2024-11-15 09:16:00.840575: decoder.transpconvs learning rate: 0.00795
2024-11-15 09:16:00.841608: decoder.seg_layers learning rate: 0.00795
2024-11-15 09:21:25.995198: Validation loss did not improve from -0.41184. Patience: 1/50
2024-11-15 09:21:25.996438: train_loss -0.4903
2024-11-15 09:21:25.997907: val_loss -0.3953
2024-11-15 09:21:25.998781: Pseudo dice [0.6583]
2024-11-15 09:21:25.999532: Epoch time: 325.16 s
2024-11-15 09:21:26.000242: Yayy! New best EMA pseudo Dice: 0.6178
2024-11-15 09:21:27.693019: 
2024-11-15 09:21:27.694911: Epoch 28
2024-11-15 09:21:27.695890: Current learning rate: 0.00787
2024-11-15 09:21:27.696872: encoder learning rate: 0.00787
2024-11-15 09:21:27.697728: decoder.stages learning rate: 0.00787
2024-11-15 09:21:27.698546: decoder.transpconvs learning rate: 0.00787
2024-11-15 09:21:27.699323: decoder.seg_layers learning rate: 0.00787
2024-11-15 09:27:05.894584: Validation loss did not improve from -0.41184. Patience: 2/50
2024-11-15 09:27:05.895830: train_loss -0.5055
2024-11-15 09:27:05.897005: val_loss -0.3912
2024-11-15 09:27:05.897943: Pseudo dice [0.6548]
2024-11-15 09:27:05.898814: Epoch time: 338.2 s
2024-11-15 09:27:05.899735: Yayy! New best EMA pseudo Dice: 0.6215
2024-11-15 09:27:07.575581: 
2024-11-15 09:27:07.577283: Epoch 29
2024-11-15 09:27:07.578230: Current learning rate: 0.0078
2024-11-15 09:27:07.579211: encoder learning rate: 0.0078
2024-11-15 09:27:07.580247: decoder.stages learning rate: 0.0078
2024-11-15 09:27:07.581147: decoder.transpconvs learning rate: 0.0078
2024-11-15 09:27:07.582175: decoder.seg_layers learning rate: 0.0078
2024-11-15 09:32:55.042095: Validation loss did not improve from -0.41184. Patience: 3/50
2024-11-15 09:32:55.043491: train_loss -0.5192
2024-11-15 09:32:55.045018: val_loss -0.3692
2024-11-15 09:32:55.045964: Pseudo dice [0.643]
2024-11-15 09:32:55.046878: Epoch time: 347.47 s
2024-11-15 09:32:55.469931: Yayy! New best EMA pseudo Dice: 0.6236
2024-11-15 09:32:58.061804: 
2024-11-15 09:32:58.064038: Epoch 30
2024-11-15 09:32:58.064966: Current learning rate: 0.00772
2024-11-15 09:32:58.066743: encoder learning rate: 0.00772
2024-11-15 09:32:58.068490: decoder.stages learning rate: 0.00772
2024-11-15 09:32:58.069714: decoder.transpconvs learning rate: 0.00772
2024-11-15 09:32:58.071298: decoder.seg_layers learning rate: 0.00772
2024-11-15 09:38:30.673841: Validation loss did not improve from -0.41184. Patience: 4/50
2024-11-15 09:38:30.675429: train_loss -0.5399
2024-11-15 09:38:30.676742: val_loss -0.2884
2024-11-15 09:38:30.677657: Pseudo dice [0.581]
2024-11-15 09:38:30.678604: Epoch time: 332.61 s
2024-11-15 09:38:32.219237: 
2024-11-15 09:38:32.220865: Epoch 31
2024-11-15 09:38:32.221876: Current learning rate: 0.00764
2024-11-15 09:38:32.222931: encoder learning rate: 0.00764
2024-11-15 09:38:32.224198: decoder.stages learning rate: 0.00764
2024-11-15 09:38:32.225213: decoder.transpconvs learning rate: 0.00764
2024-11-15 09:38:32.226177: decoder.seg_layers learning rate: 0.00764
2024-11-15 09:44:06.936992: Validation loss did not improve from -0.41184. Patience: 5/50
2024-11-15 09:44:06.938323: train_loss -0.5218
2024-11-15 09:44:06.939289: val_loss -0.4058
2024-11-15 09:44:06.940197: Pseudo dice [0.6622]
2024-11-15 09:44:06.941113: Epoch time: 334.72 s
2024-11-15 09:44:06.941832: Yayy! New best EMA pseudo Dice: 0.6237
2024-11-15 09:44:08.719629: 
2024-11-15 09:44:08.721450: Epoch 32
2024-11-15 09:44:08.723938: Current learning rate: 0.00756
2024-11-15 09:44:08.725711: encoder learning rate: 0.00756
2024-11-15 09:44:08.726603: decoder.stages learning rate: 0.00756
2024-11-15 09:44:08.727988: decoder.transpconvs learning rate: 0.00756
2024-11-15 09:44:08.729357: decoder.seg_layers learning rate: 0.00756
2024-11-15 09:50:03.189200: Validation loss did not improve from -0.41184. Patience: 6/50
2024-11-15 09:50:03.190475: train_loss -0.5413
2024-11-15 09:50:03.191670: val_loss -0.4
2024-11-15 09:50:03.192749: Pseudo dice [0.6645]
2024-11-15 09:50:03.194064: Epoch time: 354.47 s
2024-11-15 09:50:03.195413: Yayy! New best EMA pseudo Dice: 0.6278
2024-11-15 09:50:05.295503: 
2024-11-15 09:50:05.297389: Epoch 33
2024-11-15 09:50:05.298555: Current learning rate: 0.00749
2024-11-15 09:50:05.300051: encoder learning rate: 0.00749
2024-11-15 09:50:05.301308: decoder.stages learning rate: 0.00749
2024-11-15 09:50:05.302141: decoder.transpconvs learning rate: 0.00749
2024-11-15 09:50:05.303072: decoder.seg_layers learning rate: 0.00749
2024-11-15 09:55:58.677287: Validation loss did not improve from -0.41184. Patience: 7/50
2024-11-15 09:55:58.679780: train_loss -0.554
2024-11-15 09:55:58.681138: val_loss -0.3948
2024-11-15 09:55:58.682068: Pseudo dice [0.6567]
2024-11-15 09:55:58.682973: Epoch time: 353.39 s
2024-11-15 09:55:58.683711: Yayy! New best EMA pseudo Dice: 0.6306
2024-11-15 09:56:00.477095: 
2024-11-15 09:56:00.478567: Epoch 34
2024-11-15 09:56:00.479454: Current learning rate: 0.00741
2024-11-15 09:56:00.480489: encoder learning rate: 0.00741
2024-11-15 09:56:00.481326: decoder.stages learning rate: 0.00741
2024-11-15 09:56:00.482153: decoder.transpconvs learning rate: 0.00741
2024-11-15 09:56:00.482935: decoder.seg_layers learning rate: 0.00741
2024-11-15 10:02:01.777213: Validation loss improved from -0.41184 to -0.43774! Patience: 7/50
2024-11-15 10:02:01.778487: train_loss -0.5601
2024-11-15 10:02:01.779542: val_loss -0.4377
2024-11-15 10:02:01.780343: Pseudo dice [0.6793]
2024-11-15 10:02:01.781305: Epoch time: 361.3 s
2024-11-15 10:02:02.163826: Yayy! New best EMA pseudo Dice: 0.6355
2024-11-15 10:02:03.897244: 
2024-11-15 10:02:03.899201: Epoch 35
2024-11-15 10:02:03.900269: Current learning rate: 0.00733
2024-11-15 10:02:03.901412: encoder learning rate: 0.00733
2024-11-15 10:02:03.902659: decoder.stages learning rate: 0.00733
2024-11-15 10:02:03.904156: decoder.transpconvs learning rate: 0.00733
2024-11-15 10:02:03.905716: decoder.seg_layers learning rate: 0.00733
2024-11-15 10:07:59.951010: Validation loss did not improve from -0.43774. Patience: 1/50
2024-11-15 10:07:59.966135: train_loss -0.5534
2024-11-15 10:07:59.967537: val_loss -0.4267
2024-11-15 10:07:59.968494: Pseudo dice [0.6806]
2024-11-15 10:07:59.969759: Epoch time: 356.07 s
2024-11-15 10:07:59.970734: Yayy! New best EMA pseudo Dice: 0.64
2024-11-15 10:08:02.579429: 
2024-11-15 10:08:02.581183: Epoch 36
2024-11-15 10:08:02.582371: Current learning rate: 0.00725
2024-11-15 10:08:02.583610: encoder learning rate: 0.00725
2024-11-15 10:08:02.584658: decoder.stages learning rate: 0.00725
2024-11-15 10:08:02.585778: decoder.transpconvs learning rate: 0.00725
2024-11-15 10:08:02.586848: decoder.seg_layers learning rate: 0.00725
2024-11-15 10:14:12.766655: Validation loss did not improve from -0.43774. Patience: 2/50
2024-11-15 10:14:12.769806: train_loss -0.5616
2024-11-15 10:14:12.772023: val_loss -0.3892
2024-11-15 10:14:12.773212: Pseudo dice [0.6515]
2024-11-15 10:14:12.774604: Epoch time: 370.19 s
2024-11-15 10:14:12.775553: Yayy! New best EMA pseudo Dice: 0.6412
2024-11-15 10:14:14.607617: 
2024-11-15 10:14:14.609027: Epoch 37
2024-11-15 10:14:14.609905: Current learning rate: 0.00718
2024-11-15 10:14:14.611282: encoder learning rate: 0.00718
2024-11-15 10:14:14.612098: decoder.stages learning rate: 0.00718
2024-11-15 10:14:14.612929: decoder.transpconvs learning rate: 0.00718
2024-11-15 10:14:14.613754: decoder.seg_layers learning rate: 0.00718
2024-11-15 10:20:10.639597: Validation loss improved from -0.43774 to -0.45500! Patience: 2/50
2024-11-15 10:20:10.640655: train_loss -0.5655
2024-11-15 10:20:10.642233: val_loss -0.455
2024-11-15 10:20:10.643398: Pseudo dice [0.6937]
2024-11-15 10:20:10.644576: Epoch time: 356.03 s
2024-11-15 10:20:10.645688: Yayy! New best EMA pseudo Dice: 0.6464
2024-11-15 10:20:12.510358: 
2024-11-15 10:20:12.512589: Epoch 38
2024-11-15 10:20:12.513827: Current learning rate: 0.0071
2024-11-15 10:20:12.515059: encoder learning rate: 0.0071
2024-11-15 10:20:12.516210: decoder.stages learning rate: 0.0071
2024-11-15 10:20:12.517302: decoder.transpconvs learning rate: 0.0071
2024-11-15 10:20:12.518202: decoder.seg_layers learning rate: 0.0071
2024-11-15 10:25:51.555319: Validation loss did not improve from -0.45500. Patience: 1/50
2024-11-15 10:25:51.556452: train_loss -0.5746
2024-11-15 10:25:51.557334: val_loss -0.3702
2024-11-15 10:25:51.558149: Pseudo dice [0.6413]
2024-11-15 10:25:51.559031: Epoch time: 339.05 s
2024-11-15 10:25:52.935430: 
2024-11-15 10:25:52.936859: Epoch 39
2024-11-15 10:25:52.937691: Current learning rate: 0.00702
2024-11-15 10:25:52.938688: encoder learning rate: 0.00702
2024-11-15 10:25:52.939570: decoder.stages learning rate: 0.00702
2024-11-15 10:25:52.940415: decoder.transpconvs learning rate: 0.00702
2024-11-15 10:25:52.941111: decoder.seg_layers learning rate: 0.00702
2024-11-15 10:32:08.516340: Validation loss did not improve from -0.45500. Patience: 2/50
2024-11-15 10:32:08.517564: train_loss -0.5823
2024-11-15 10:32:08.519140: val_loss -0.4166
2024-11-15 10:32:08.520329: Pseudo dice [0.6776]
2024-11-15 10:32:08.521291: Epoch time: 375.58 s
2024-11-15 10:32:08.949883: Yayy! New best EMA pseudo Dice: 0.6491
2024-11-15 10:32:10.718481: 
2024-11-15 10:32:10.720400: Epoch 40
2024-11-15 10:32:10.721791: Current learning rate: 0.00694
2024-11-15 10:32:10.722850: encoder learning rate: 0.00694
2024-11-15 10:32:10.724216: decoder.stages learning rate: 0.00694
2024-11-15 10:32:10.725344: decoder.transpconvs learning rate: 0.00694
2024-11-15 10:32:10.726089: decoder.seg_layers learning rate: 0.00694
2024-11-15 10:38:13.169644: Validation loss did not improve from -0.45500. Patience: 3/50
2024-11-15 10:38:13.171527: train_loss -0.5893
2024-11-15 10:38:13.173189: val_loss -0.4226
2024-11-15 10:38:13.174272: Pseudo dice [0.6698]
2024-11-15 10:38:13.175177: Epoch time: 362.45 s
2024-11-15 10:38:13.176098: Yayy! New best EMA pseudo Dice: 0.6511
2024-11-15 10:38:17.614359: 
2024-11-15 10:38:17.616046: Epoch 41
2024-11-15 10:38:17.617263: Current learning rate: 0.00686
2024-11-15 10:38:17.618289: encoder learning rate: 0.00686
2024-11-15 10:38:17.619212: decoder.stages learning rate: 0.00686
2024-11-15 10:38:17.619981: decoder.transpconvs learning rate: 0.00686
2024-11-15 10:38:17.620699: decoder.seg_layers learning rate: 0.00686
2024-11-15 10:44:10.912270: Validation loss did not improve from -0.45500. Patience: 4/50
2024-11-15 10:44:10.914038: train_loss -0.582
2024-11-15 10:44:10.915321: val_loss -0.4064
2024-11-15 10:44:10.916177: Pseudo dice [0.6616]
2024-11-15 10:44:10.917029: Epoch time: 353.3 s
2024-11-15 10:44:10.917893: Yayy! New best EMA pseudo Dice: 0.6522
2024-11-15 10:44:12.658280: 
2024-11-15 10:44:12.659872: Epoch 42
2024-11-15 10:44:12.660856: Current learning rate: 0.00679
2024-11-15 10:44:12.661896: encoder learning rate: 0.00679
2024-11-15 10:44:12.662650: decoder.stages learning rate: 0.00679
2024-11-15 10:44:12.663383: decoder.transpconvs learning rate: 0.00679
2024-11-15 10:44:12.664590: decoder.seg_layers learning rate: 0.00679
2024-11-15 10:50:10.623895: Validation loss did not improve from -0.45500. Patience: 5/50
2024-11-15 10:50:10.625641: train_loss -0.5936
2024-11-15 10:50:10.628063: val_loss -0.413
2024-11-15 10:50:10.629564: Pseudo dice [0.6766]
2024-11-15 10:50:10.630893: Epoch time: 357.97 s
2024-11-15 10:50:10.632140: Yayy! New best EMA pseudo Dice: 0.6546
2024-11-15 10:50:12.308873: 
2024-11-15 10:50:12.310663: Epoch 43
2024-11-15 10:50:12.312014: Current learning rate: 0.00671
2024-11-15 10:50:12.313287: encoder learning rate: 0.00671
2024-11-15 10:50:12.314407: decoder.stages learning rate: 0.00671
2024-11-15 10:50:12.315538: decoder.transpconvs learning rate: 0.00671
2024-11-15 10:50:12.316573: decoder.seg_layers learning rate: 0.00671
2024-11-15 10:55:56.157407: Validation loss did not improve from -0.45500. Patience: 6/50
2024-11-15 10:55:56.158721: train_loss -0.5972
2024-11-15 10:55:56.160054: val_loss -0.4485
2024-11-15 10:55:56.160903: Pseudo dice [0.6932]
2024-11-15 10:55:56.161828: Epoch time: 343.85 s
2024-11-15 10:55:56.162651: Yayy! New best EMA pseudo Dice: 0.6585
2024-11-15 10:55:57.943586: 
2024-11-15 10:55:57.945108: Epoch 44
2024-11-15 10:55:57.946004: Current learning rate: 0.00663
2024-11-15 10:55:57.947663: encoder learning rate: 0.00663
2024-11-15 10:55:57.948648: decoder.stages learning rate: 0.00663
2024-11-15 10:55:57.949618: decoder.transpconvs learning rate: 0.00663
2024-11-15 10:55:57.950622: decoder.seg_layers learning rate: 0.00663
2024-11-15 11:01:59.843996: Validation loss did not improve from -0.45500. Patience: 7/50
2024-11-15 11:01:59.845313: train_loss -0.6096
2024-11-15 11:01:59.846605: val_loss -0.4393
2024-11-15 11:01:59.847677: Pseudo dice [0.6907]
2024-11-15 11:01:59.848567: Epoch time: 361.9 s
2024-11-15 11:02:00.296711: Yayy! New best EMA pseudo Dice: 0.6617
2024-11-15 11:02:01.967785: 
2024-11-15 11:02:01.969256: Epoch 45
2024-11-15 11:02:01.970204: Current learning rate: 0.00655
2024-11-15 11:02:01.971224: encoder learning rate: 0.00655
2024-11-15 11:02:01.972216: decoder.stages learning rate: 0.00655
2024-11-15 11:02:01.972941: decoder.transpconvs learning rate: 0.00655
2024-11-15 11:02:01.973708: decoder.seg_layers learning rate: 0.00655
2024-11-15 11:07:52.817491: Validation loss improved from -0.45500 to -0.46178! Patience: 7/50
2024-11-15 11:07:52.818671: train_loss -0.6067
2024-11-15 11:07:52.819700: val_loss -0.4618
2024-11-15 11:07:52.820773: Pseudo dice [0.693]
2024-11-15 11:07:52.821945: Epoch time: 350.85 s
2024-11-15 11:07:52.822984: Yayy! New best EMA pseudo Dice: 0.6648
2024-11-15 11:07:54.568575: 
2024-11-15 11:07:54.570653: Epoch 46
2024-11-15 11:07:54.574058: Current learning rate: 0.00647
2024-11-15 11:07:54.576103: encoder learning rate: 0.00647
2024-11-15 11:07:54.577297: decoder.stages learning rate: 0.00647
2024-11-15 11:07:54.578412: decoder.transpconvs learning rate: 0.00647
2024-11-15 11:07:54.579411: decoder.seg_layers learning rate: 0.00647
2024-11-15 11:12:36.017830: Validation loss did not improve from -0.46178. Patience: 1/50
2024-11-15 11:12:36.020978: train_loss -0.6187
2024-11-15 11:12:36.022529: val_loss -0.4221
2024-11-15 11:12:36.023553: Pseudo dice [0.6768]
2024-11-15 11:12:36.024582: Epoch time: 281.45 s
2024-11-15 11:12:36.025566: Yayy! New best EMA pseudo Dice: 0.666
2024-11-15 11:12:37.892695: 
2024-11-15 11:12:37.894410: Epoch 47
2024-11-15 11:12:37.895437: Current learning rate: 0.00639
2024-11-15 11:12:37.896466: encoder learning rate: 0.00639
2024-11-15 11:12:37.897504: decoder.stages learning rate: 0.00639
2024-11-15 11:12:37.898419: decoder.transpconvs learning rate: 0.00639
2024-11-15 11:12:37.899417: decoder.seg_layers learning rate: 0.00639
2024-11-15 11:14:13.412617: Validation loss did not improve from -0.46178. Patience: 2/50
2024-11-15 11:14:13.451943: train_loss -0.624
2024-11-15 11:14:13.453876: val_loss -0.4013
2024-11-15 11:14:13.454898: Pseudo dice [0.6731]
2024-11-15 11:14:13.455716: Epoch time: 95.55 s
2024-11-15 11:14:13.456540: Yayy! New best EMA pseudo Dice: 0.6667
2024-11-15 11:14:15.291119: 
2024-11-15 11:14:15.292893: Epoch 48
2024-11-15 11:14:15.293913: Current learning rate: 0.00631
2024-11-15 11:14:15.294863: encoder learning rate: 0.00631
2024-11-15 11:14:15.295703: decoder.stages learning rate: 0.00631
2024-11-15 11:14:15.296471: decoder.transpconvs learning rate: 0.00631
2024-11-15 11:14:15.297165: decoder.seg_layers learning rate: 0.00631
2024-11-15 11:15:47.363118: Validation loss did not improve from -0.46178. Patience: 3/50
2024-11-15 11:15:47.365413: train_loss -0.6225
2024-11-15 11:15:47.368317: val_loss -0.4561
2024-11-15 11:15:47.369355: Pseudo dice [0.6978]
2024-11-15 11:15:47.370789: Epoch time: 92.08 s
2024-11-15 11:15:47.371699: Yayy! New best EMA pseudo Dice: 0.6698
2024-11-15 11:15:49.015325: 
2024-11-15 11:15:49.017461: Epoch 49
2024-11-15 11:15:49.018422: Current learning rate: 0.00624
2024-11-15 11:15:49.019465: encoder learning rate: 0.00624
2024-11-15 11:15:49.020470: decoder.stages learning rate: 0.00624
2024-11-15 11:15:49.021326: decoder.transpconvs learning rate: 0.00624
2024-11-15 11:15:49.022307: decoder.seg_layers learning rate: 0.00624
2024-11-15 11:17:21.260718: Validation loss did not improve from -0.46178. Patience: 4/50
2024-11-15 11:17:21.262197: train_loss -0.6284
2024-11-15 11:17:21.263851: val_loss -0.4285
2024-11-15 11:17:21.264886: Pseudo dice [0.688]
2024-11-15 11:17:21.265879: Epoch time: 92.25 s
2024-11-15 11:17:21.630732: Yayy! New best EMA pseudo Dice: 0.6717
2024-11-15 11:17:23.329236: 
2024-11-15 11:17:23.331261: Epoch 50
2024-11-15 11:17:23.332512: Current learning rate: 0.00616
2024-11-15 11:17:23.333650: encoder learning rate: 0.00616
2024-11-15 11:17:23.334769: decoder.stages learning rate: 0.00616
2024-11-15 11:17:23.335794: decoder.transpconvs learning rate: 0.00616
2024-11-15 11:17:23.336783: decoder.seg_layers learning rate: 0.00616
2024-11-15 11:18:55.743366: Validation loss improved from -0.46178 to -0.47234! Patience: 4/50
2024-11-15 11:18:55.744691: train_loss -0.6368
2024-11-15 11:18:55.745771: val_loss -0.4723
2024-11-15 11:18:55.746599: Pseudo dice [0.6997]
2024-11-15 11:18:55.747545: Epoch time: 92.42 s
2024-11-15 11:18:55.748432: Yayy! New best EMA pseudo Dice: 0.6745
2024-11-15 11:18:57.399580: 
2024-11-15 11:18:57.401337: Epoch 51
2024-11-15 11:18:57.402525: Current learning rate: 0.00608
2024-11-15 11:18:57.404201: encoder learning rate: 0.00608
2024-11-15 11:18:57.405498: decoder.stages learning rate: 0.00608
2024-11-15 11:18:57.406473: decoder.transpconvs learning rate: 0.00608
2024-11-15 11:18:57.407416: decoder.seg_layers learning rate: 0.00608
2024-11-15 11:20:29.795399: Validation loss did not improve from -0.47234. Patience: 1/50
2024-11-15 11:20:29.797049: train_loss -0.6337
2024-11-15 11:20:29.798774: val_loss -0.4399
2024-11-15 11:20:29.799784: Pseudo dice [0.6897]
2024-11-15 11:20:29.800749: Epoch time: 92.4 s
2024-11-15 11:20:29.801690: Yayy! New best EMA pseudo Dice: 0.676
2024-11-15 11:20:31.565949: 
2024-11-15 11:20:31.568078: Epoch 52
2024-11-15 11:20:31.569085: Current learning rate: 0.006
2024-11-15 11:20:31.570445: encoder learning rate: 0.006
2024-11-15 11:20:31.571450: decoder.stages learning rate: 0.006
2024-11-15 11:20:31.572571: decoder.transpconvs learning rate: 0.006
2024-11-15 11:20:31.573705: decoder.seg_layers learning rate: 0.006
2024-11-15 11:22:03.765335: Validation loss did not improve from -0.47234. Patience: 2/50
2024-11-15 11:22:03.766849: train_loss -0.6411
2024-11-15 11:22:03.768371: val_loss -0.4226
2024-11-15 11:22:03.769398: Pseudo dice [0.6749]
2024-11-15 11:22:03.770385: Epoch time: 92.2 s
2024-11-15 11:22:06.042881: 
2024-11-15 11:22:06.044861: Epoch 53
2024-11-15 11:22:06.045820: Current learning rate: 0.00592
2024-11-15 11:22:06.047019: encoder learning rate: 0.00592
2024-11-15 11:22:06.048107: decoder.stages learning rate: 0.00592
2024-11-15 11:22:06.048924: decoder.transpconvs learning rate: 0.00592
2024-11-15 11:22:06.049807: decoder.seg_layers learning rate: 0.00592
2024-11-15 11:23:38.620340: Validation loss did not improve from -0.47234. Patience: 3/50
2024-11-15 11:23:38.622032: train_loss -0.6363
2024-11-15 11:23:38.623050: val_loss -0.4647
2024-11-15 11:23:38.623897: Pseudo dice [0.6975]
2024-11-15 11:23:38.624828: Epoch time: 92.58 s
2024-11-15 11:23:38.625813: Yayy! New best EMA pseudo Dice: 0.678
2024-11-15 11:23:40.263168: 
2024-11-15 11:23:40.265200: Epoch 54
2024-11-15 11:23:40.266225: Current learning rate: 0.00584
2024-11-15 11:23:40.267233: encoder learning rate: 0.00584
2024-11-15 11:23:40.268159: decoder.stages learning rate: 0.00584
2024-11-15 11:23:40.269088: decoder.transpconvs learning rate: 0.00584
2024-11-15 11:23:40.270158: decoder.seg_layers learning rate: 0.00584
2024-11-15 11:25:12.076475: Validation loss did not improve from -0.47234. Patience: 4/50
2024-11-15 11:25:12.078299: train_loss -0.6461
2024-11-15 11:25:12.079374: val_loss -0.413
2024-11-15 11:25:12.080171: Pseudo dice [0.6669]
2024-11-15 11:25:12.081169: Epoch time: 91.82 s
2024-11-15 11:25:13.768576: 
2024-11-15 11:25:13.770469: Epoch 55
2024-11-15 11:25:13.771460: Current learning rate: 0.00576
2024-11-15 11:25:13.772574: encoder learning rate: 0.00576
2024-11-15 11:25:13.773461: decoder.stages learning rate: 0.00576
2024-11-15 11:25:13.774744: decoder.transpconvs learning rate: 0.00576
2024-11-15 11:25:13.775830: decoder.seg_layers learning rate: 0.00576
2024-11-15 11:26:45.849385: Validation loss did not improve from -0.47234. Patience: 5/50
2024-11-15 11:26:45.851067: train_loss -0.6434
2024-11-15 11:26:45.852398: val_loss -0.4288
2024-11-15 11:26:45.853517: Pseudo dice [0.6727]
2024-11-15 11:26:45.854589: Epoch time: 92.08 s
2024-11-15 11:26:47.164241: 
2024-11-15 11:26:47.166149: Epoch 56
2024-11-15 11:26:47.167326: Current learning rate: 0.00568
2024-11-15 11:26:47.168680: encoder learning rate: 0.00568
2024-11-15 11:26:47.169899: decoder.stages learning rate: 0.00568
2024-11-15 11:26:47.171121: decoder.transpconvs learning rate: 0.00568
2024-11-15 11:26:47.172180: decoder.seg_layers learning rate: 0.00568
2024-11-15 11:28:18.914726: Validation loss did not improve from -0.47234. Patience: 6/50
2024-11-15 11:28:18.916345: train_loss -0.6456
2024-11-15 11:28:18.917516: val_loss -0.4381
2024-11-15 11:28:18.918559: Pseudo dice [0.6843]
2024-11-15 11:28:18.919428: Epoch time: 91.75 s
2024-11-15 11:28:20.204970: 
2024-11-15 11:28:20.206741: Epoch 57
2024-11-15 11:28:20.207721: Current learning rate: 0.0056
2024-11-15 11:28:20.208806: encoder learning rate: 0.0056
2024-11-15 11:28:20.209703: decoder.stages learning rate: 0.0056
2024-11-15 11:28:20.210485: decoder.transpconvs learning rate: 0.0056
2024-11-15 11:28:20.211306: decoder.seg_layers learning rate: 0.0056
2024-11-15 11:29:52.472345: Validation loss did not improve from -0.47234. Patience: 7/50
2024-11-15 11:29:52.473820: train_loss -0.6473
2024-11-15 11:29:52.474995: val_loss -0.4447
2024-11-15 11:29:52.476011: Pseudo dice [0.6854]
2024-11-15 11:29:52.476896: Epoch time: 92.27 s
2024-11-15 11:29:52.477725: Yayy! New best EMA pseudo Dice: 0.6781
2024-11-15 11:29:54.176081: 
2024-11-15 11:29:54.178080: Epoch 58
2024-11-15 11:29:54.179053: Current learning rate: 0.00552
2024-11-15 11:29:54.180099: encoder learning rate: 0.00552
2024-11-15 11:29:54.180960: decoder.stages learning rate: 0.00552
2024-11-15 11:29:54.181812: decoder.transpconvs learning rate: 0.00552
2024-11-15 11:29:54.182793: decoder.seg_layers learning rate: 0.00552
2024-11-15 11:31:26.129377: Validation loss did not improve from -0.47234. Patience: 8/50
2024-11-15 11:31:26.131205: train_loss -0.6486
2024-11-15 11:31:26.132731: val_loss -0.4275
2024-11-15 11:31:26.133788: Pseudo dice [0.6773]
2024-11-15 11:31:26.134695: Epoch time: 91.96 s
2024-11-15 11:31:27.500168: 
2024-11-15 11:31:27.503660: Epoch 59
2024-11-15 11:31:27.505533: Current learning rate: 0.00544
2024-11-15 11:31:27.506569: encoder learning rate: 0.00544
2024-11-15 11:31:27.507690: decoder.stages learning rate: 0.00544
2024-11-15 11:31:27.508565: decoder.transpconvs learning rate: 0.00544
2024-11-15 11:31:27.509438: decoder.seg_layers learning rate: 0.00544
2024-11-15 11:32:59.642007: Validation loss did not improve from -0.47234. Patience: 9/50
2024-11-15 11:32:59.643611: train_loss -0.6597
2024-11-15 11:32:59.645397: val_loss -0.4225
2024-11-15 11:32:59.646806: Pseudo dice [0.6633]
2024-11-15 11:32:59.648148: Epoch time: 92.15 s
2024-11-15 11:33:01.329048: 
2024-11-15 11:33:01.331717: Epoch 60
2024-11-15 11:33:01.333724: Current learning rate: 0.00536
2024-11-15 11:33:01.335349: encoder learning rate: 0.00536
2024-11-15 11:33:01.336651: decoder.stages learning rate: 0.00536
2024-11-15 11:33:01.338143: decoder.transpconvs learning rate: 0.00536
2024-11-15 11:33:01.340670: decoder.seg_layers learning rate: 0.00536
2024-11-15 11:34:33.101534: Validation loss did not improve from -0.47234. Patience: 10/50
2024-11-15 11:34:33.103822: train_loss -0.6517
2024-11-15 11:34:33.105428: val_loss -0.452
2024-11-15 11:34:33.106524: Pseudo dice [0.6892]
2024-11-15 11:34:33.107580: Epoch time: 91.78 s
2024-11-15 11:34:34.427133: 
2024-11-15 11:34:34.429009: Epoch 61
2024-11-15 11:34:34.430036: Current learning rate: 0.00528
2024-11-15 11:34:34.431256: encoder learning rate: 0.00528
2024-11-15 11:34:34.432135: decoder.stages learning rate: 0.00528
2024-11-15 11:34:34.433092: decoder.transpconvs learning rate: 0.00528
2024-11-15 11:34:34.433933: decoder.seg_layers learning rate: 0.00528
2024-11-15 11:36:06.788426: Validation loss did not improve from -0.47234. Patience: 11/50
2024-11-15 11:36:06.789660: train_loss -0.6504
2024-11-15 11:36:06.790835: val_loss -0.4149
2024-11-15 11:36:06.791695: Pseudo dice [0.674]
2024-11-15 11:36:06.792561: Epoch time: 92.36 s
2024-11-15 11:36:08.044553: 
2024-11-15 11:36:08.046138: Epoch 62
2024-11-15 11:36:08.047356: Current learning rate: 0.0052
2024-11-15 11:36:08.049173: encoder learning rate: 0.0052
2024-11-15 11:36:08.050830: decoder.stages learning rate: 0.0052
2024-11-15 11:36:08.051763: decoder.transpconvs learning rate: 0.0052
2024-11-15 11:36:08.052722: decoder.seg_layers learning rate: 0.0052
2024-11-15 11:37:39.945877: Validation loss did not improve from -0.47234. Patience: 12/50
2024-11-15 11:37:39.947159: train_loss -0.6535
2024-11-15 11:37:39.948370: val_loss -0.428
2024-11-15 11:37:39.949281: Pseudo dice [0.6805]
2024-11-15 11:37:39.950219: Epoch time: 91.9 s
2024-11-15 11:37:41.230730: 
2024-11-15 11:37:41.232448: Epoch 63
2024-11-15 11:37:41.233660: Current learning rate: 0.00512
2024-11-15 11:37:41.234957: encoder learning rate: 0.00512
2024-11-15 11:37:41.235929: decoder.stages learning rate: 0.00512
2024-11-15 11:37:41.236845: decoder.transpconvs learning rate: 0.00512
2024-11-15 11:37:41.237740: decoder.seg_layers learning rate: 0.00512
2024-11-15 11:39:13.333071: Validation loss did not improve from -0.47234. Patience: 13/50
2024-11-15 11:39:13.334781: train_loss -0.6659
2024-11-15 11:39:13.336043: val_loss -0.4066
2024-11-15 11:39:13.337073: Pseudo dice [0.6767]
2024-11-15 11:39:13.338107: Epoch time: 92.11 s
2024-11-15 11:39:14.678815: 
2024-11-15 11:39:14.680542: Epoch 64
2024-11-15 11:39:14.681880: Current learning rate: 0.00504
2024-11-15 11:39:14.683174: encoder learning rate: 0.00504
2024-11-15 11:39:14.684534: decoder.stages learning rate: 0.00504
2024-11-15 11:39:14.685752: decoder.transpconvs learning rate: 0.00504
2024-11-15 11:39:14.686888: decoder.seg_layers learning rate: 0.00504
2024-11-15 11:40:47.338296: Validation loss did not improve from -0.47234. Patience: 14/50
2024-11-15 11:40:47.339621: train_loss -0.6698
2024-11-15 11:40:47.341159: val_loss -0.4549
2024-11-15 11:40:47.342164: Pseudo dice [0.6869]
2024-11-15 11:40:47.343199: Epoch time: 92.66 s
2024-11-15 11:40:47.729594: Yayy! New best EMA pseudo Dice: 0.6786
2024-11-15 11:40:49.425689: 
2024-11-15 11:40:49.428628: Epoch 65
2024-11-15 11:40:49.430132: Current learning rate: 0.00496
2024-11-15 11:40:49.431195: encoder learning rate: 0.00496
2024-11-15 11:40:49.432305: decoder.stages learning rate: 0.00496
2024-11-15 11:40:49.433083: decoder.transpconvs learning rate: 0.00496
2024-11-15 11:40:49.433978: decoder.seg_layers learning rate: 0.00496
2024-11-15 11:42:21.490005: Validation loss did not improve from -0.47234. Patience: 15/50
2024-11-15 11:42:21.491596: train_loss -0.6679
2024-11-15 11:42:21.493279: val_loss -0.4562
2024-11-15 11:42:21.494212: Pseudo dice [0.6932]
2024-11-15 11:42:21.495135: Epoch time: 92.07 s
2024-11-15 11:42:21.495862: Yayy! New best EMA pseudo Dice: 0.68
2024-11-15 11:42:23.156752: 
2024-11-15 11:42:23.158594: Epoch 66
2024-11-15 11:42:23.159933: Current learning rate: 0.00487
2024-11-15 11:42:23.161185: encoder learning rate: 0.00487
2024-11-15 11:42:23.162151: decoder.stages learning rate: 0.00487
2024-11-15 11:42:23.163028: decoder.transpconvs learning rate: 0.00487
2024-11-15 11:42:23.163878: decoder.seg_layers learning rate: 0.00487
2024-11-15 11:43:55.695687: Validation loss improved from -0.47234 to -0.47959! Patience: 15/50
2024-11-15 11:43:55.697205: train_loss -0.6711
2024-11-15 11:43:55.698410: val_loss -0.4796
2024-11-15 11:43:55.699278: Pseudo dice [0.7069]
2024-11-15 11:43:55.700211: Epoch time: 92.54 s
2024-11-15 11:43:55.701066: Yayy! New best EMA pseudo Dice: 0.6827
2024-11-15 11:43:57.393628: 
2024-11-15 11:43:57.395317: Epoch 67
2024-11-15 11:43:57.396310: Current learning rate: 0.00479
2024-11-15 11:43:57.397355: encoder learning rate: 0.00479
2024-11-15 11:43:57.398428: decoder.stages learning rate: 0.00479
2024-11-15 11:43:57.399208: decoder.transpconvs learning rate: 0.00479
2024-11-15 11:43:57.400079: decoder.seg_layers learning rate: 0.00479
2024-11-15 11:45:29.755235: Validation loss did not improve from -0.47959. Patience: 1/50
2024-11-15 11:45:29.756627: train_loss -0.6698
2024-11-15 11:45:29.758104: val_loss -0.4116
2024-11-15 11:45:29.759163: Pseudo dice [0.6626]
2024-11-15 11:45:29.760173: Epoch time: 92.36 s
2024-11-15 11:45:31.056602: 
2024-11-15 11:45:31.058635: Epoch 68
2024-11-15 11:45:31.059824: Current learning rate: 0.00471
2024-11-15 11:45:31.060795: encoder learning rate: 0.00471
2024-11-15 11:45:31.061743: decoder.stages learning rate: 0.00471
2024-11-15 11:45:31.062734: decoder.transpconvs learning rate: 0.00471
2024-11-15 11:45:31.063746: decoder.seg_layers learning rate: 0.00471
2024-11-15 11:47:04.389886: Validation loss did not improve from -0.47959. Patience: 2/50
2024-11-15 11:47:04.391402: train_loss -0.6712
2024-11-15 11:47:04.392728: val_loss -0.4704
2024-11-15 11:47:04.393794: Pseudo dice [0.7058]
2024-11-15 11:47:04.394772: Epoch time: 93.34 s
2024-11-15 11:47:04.395635: Yayy! New best EMA pseudo Dice: 0.6832
2024-11-15 11:47:06.083937: 
2024-11-15 11:47:06.085486: Epoch 69
2024-11-15 11:47:06.086737: Current learning rate: 0.00463
2024-11-15 11:47:06.087769: encoder learning rate: 0.00463
2024-11-15 11:47:06.088694: decoder.stages learning rate: 0.00463
2024-11-15 11:47:06.089515: decoder.transpconvs learning rate: 0.00463
2024-11-15 11:47:06.090754: decoder.seg_layers learning rate: 0.00463
2024-11-15 11:48:38.580274: Validation loss did not improve from -0.47959. Patience: 3/50
2024-11-15 11:48:38.581919: train_loss -0.6886
2024-11-15 11:48:38.583386: val_loss -0.4621
2024-11-15 11:48:38.584343: Pseudo dice [0.7069]
2024-11-15 11:48:38.585396: Epoch time: 92.5 s
2024-11-15 11:48:38.957363: Yayy! New best EMA pseudo Dice: 0.6856
2024-11-15 11:48:40.650083: 
2024-11-15 11:48:40.651807: Epoch 70
2024-11-15 11:48:40.652781: Current learning rate: 0.00455
2024-11-15 11:48:40.653892: encoder learning rate: 0.00455
2024-11-15 11:48:40.654835: decoder.stages learning rate: 0.00455
2024-11-15 11:48:40.655764: decoder.transpconvs learning rate: 0.00455
2024-11-15 11:48:40.656651: decoder.seg_layers learning rate: 0.00455
2024-11-15 11:50:12.902178: Validation loss did not improve from -0.47959. Patience: 4/50
2024-11-15 11:50:12.903507: train_loss -0.6848
2024-11-15 11:50:12.904753: val_loss -0.4718
2024-11-15 11:50:12.905684: Pseudo dice [0.7017]
2024-11-15 11:50:12.906570: Epoch time: 92.25 s
2024-11-15 11:50:12.907362: Yayy! New best EMA pseudo Dice: 0.6872
2024-11-15 11:50:14.596901: 
2024-11-15 11:50:14.598530: Epoch 71
2024-11-15 11:50:14.599519: Current learning rate: 0.00447
2024-11-15 11:50:14.600508: encoder learning rate: 0.00447
2024-11-15 11:50:14.601365: decoder.stages learning rate: 0.00447
2024-11-15 11:50:14.602158: decoder.transpconvs learning rate: 0.00447
2024-11-15 11:50:14.603079: decoder.seg_layers learning rate: 0.00447
2024-11-15 11:51:46.908167: Validation loss did not improve from -0.47959. Patience: 5/50
2024-11-15 11:51:46.909556: train_loss -0.6826
2024-11-15 11:51:46.911158: val_loss -0.4295
2024-11-15 11:51:46.912251: Pseudo dice [0.6778]
2024-11-15 11:51:46.913239: Epoch time: 92.31 s
2024-11-15 11:51:48.283527: 
2024-11-15 11:51:48.285210: Epoch 72
2024-11-15 11:51:48.286314: Current learning rate: 0.00438
2024-11-15 11:51:48.287359: encoder learning rate: 0.00438
2024-11-15 11:51:48.288483: decoder.stages learning rate: 0.00438
2024-11-15 11:51:48.289521: decoder.transpconvs learning rate: 0.00438
2024-11-15 11:51:48.290582: decoder.seg_layers learning rate: 0.00438
2024-11-15 11:53:21.389252: Validation loss did not improve from -0.47959. Patience: 6/50
2024-11-15 11:53:21.390625: train_loss -0.6845
2024-11-15 11:53:21.391901: val_loss -0.4497
2024-11-15 11:53:21.392808: Pseudo dice [0.6922]
2024-11-15 11:53:21.393863: Epoch time: 93.11 s
2024-11-15 11:53:22.691969: 
2024-11-15 11:53:22.694020: Epoch 73
2024-11-15 11:53:22.695068: Current learning rate: 0.0043
2024-11-15 11:53:22.696231: encoder learning rate: 0.0043
2024-11-15 11:53:22.697403: decoder.stages learning rate: 0.0043
2024-11-15 11:53:22.698369: decoder.transpconvs learning rate: 0.0043
2024-11-15 11:53:22.699223: decoder.seg_layers learning rate: 0.0043
2024-11-15 11:54:55.249328: Validation loss did not improve from -0.47959. Patience: 7/50
2024-11-15 11:54:55.250716: train_loss -0.6882
2024-11-15 11:54:55.252129: val_loss -0.4758
2024-11-15 11:54:55.253054: Pseudo dice [0.7029]
2024-11-15 11:54:55.254014: Epoch time: 92.56 s
2024-11-15 11:54:55.254990: Yayy! New best EMA pseudo Dice: 0.6885
2024-11-15 11:54:56.944582: 
2024-11-15 11:54:56.946389: Epoch 74
2024-11-15 11:54:56.947519: Current learning rate: 0.00422
2024-11-15 11:54:56.948596: encoder learning rate: 0.00422
2024-11-15 11:54:56.949411: decoder.stages learning rate: 0.00422
2024-11-15 11:54:56.950264: decoder.transpconvs learning rate: 0.00422
2024-11-15 11:54:56.951232: decoder.seg_layers learning rate: 0.00422
2024-11-15 11:56:29.631556: Validation loss improved from -0.47959 to -0.48217! Patience: 7/50
2024-11-15 11:56:29.634395: train_loss -0.6938
2024-11-15 11:56:29.636247: val_loss -0.4822
2024-11-15 11:56:29.637232: Pseudo dice [0.7075]
2024-11-15 11:56:29.638188: Epoch time: 92.69 s
2024-11-15 11:56:30.033848: Yayy! New best EMA pseudo Dice: 0.6904
2024-11-15 11:56:32.468426: 
2024-11-15 11:56:32.470232: Epoch 75
2024-11-15 11:56:32.471622: Current learning rate: 0.00414
2024-11-15 11:56:32.473566: encoder learning rate: 0.00414
2024-11-15 11:56:32.474553: decoder.stages learning rate: 0.00414
2024-11-15 11:56:32.475420: decoder.transpconvs learning rate: 0.00414
2024-11-15 11:56:32.476398: decoder.seg_layers learning rate: 0.00414
2024-11-15 11:58:04.715263: Validation loss did not improve from -0.48217. Patience: 1/50
2024-11-15 11:58:04.716426: train_loss -0.6967
2024-11-15 11:58:04.717817: val_loss -0.4256
2024-11-15 11:58:04.718921: Pseudo dice [0.6892]
2024-11-15 11:58:04.720250: Epoch time: 92.25 s
2024-11-15 11:58:06.024738: 
2024-11-15 11:58:06.026540: Epoch 76
2024-11-15 11:58:06.027640: Current learning rate: 0.00405
2024-11-15 11:58:06.028890: encoder learning rate: 0.00405
2024-11-15 11:58:06.029890: decoder.stages learning rate: 0.00405
2024-11-15 11:58:06.031041: decoder.transpconvs learning rate: 0.00405
2024-11-15 11:58:06.031985: decoder.seg_layers learning rate: 0.00405
2024-11-15 11:59:38.564309: Validation loss improved from -0.48217 to -0.51030! Patience: 1/50
2024-11-15 11:59:38.565563: train_loss -0.6947
2024-11-15 11:59:38.566908: val_loss -0.5103
2024-11-15 11:59:38.568056: Pseudo dice [0.7232]
2024-11-15 11:59:38.569130: Epoch time: 92.54 s
2024-11-15 11:59:38.570225: Yayy! New best EMA pseudo Dice: 0.6935
2024-11-15 11:59:40.239574: 
2024-11-15 11:59:40.241501: Epoch 77
2024-11-15 11:59:40.242594: Current learning rate: 0.00397
2024-11-15 11:59:40.243648: encoder learning rate: 0.00397
2024-11-15 11:59:40.244702: decoder.stages learning rate: 0.00397
2024-11-15 11:59:40.245720: decoder.transpconvs learning rate: 0.00397
2024-11-15 11:59:40.246628: decoder.seg_layers learning rate: 0.00397
2024-11-15 12:01:12.524252: Validation loss did not improve from -0.51030. Patience: 1/50
2024-11-15 12:01:12.525528: train_loss -0.7043
2024-11-15 12:01:12.526685: val_loss -0.4405
2024-11-15 12:01:12.527787: Pseudo dice [0.6805]
2024-11-15 12:01:12.528879: Epoch time: 92.29 s
2024-11-15 12:01:13.844423: 
2024-11-15 12:01:13.846134: Epoch 78
2024-11-15 12:01:13.847279: Current learning rate: 0.00389
2024-11-15 12:01:13.848478: encoder learning rate: 0.00389
2024-11-15 12:01:13.849502: decoder.stages learning rate: 0.00389
2024-11-15 12:01:13.850482: decoder.transpconvs learning rate: 0.00389
2024-11-15 12:01:13.851500: decoder.seg_layers learning rate: 0.00389
2024-11-15 12:02:45.989239: Validation loss did not improve from -0.51030. Patience: 2/50
2024-11-15 12:02:45.990368: train_loss -0.6989
2024-11-15 12:02:45.991612: val_loss -0.4517
2024-11-15 12:02:45.992556: Pseudo dice [0.6935]
2024-11-15 12:02:45.993401: Epoch time: 92.15 s
2024-11-15 12:02:47.324335: 
2024-11-15 12:02:47.325652: Epoch 79
2024-11-15 12:02:47.326721: Current learning rate: 0.0038
2024-11-15 12:02:47.327738: encoder learning rate: 0.0038
2024-11-15 12:02:47.328600: decoder.stages learning rate: 0.0038
2024-11-15 12:02:47.329445: decoder.transpconvs learning rate: 0.0038
2024-11-15 12:02:47.330249: decoder.seg_layers learning rate: 0.0038
2024-11-15 12:04:19.384768: Validation loss did not improve from -0.51030. Patience: 3/50
2024-11-15 12:04:19.386067: train_loss -0.7062
2024-11-15 12:04:19.387136: val_loss -0.4445
2024-11-15 12:04:19.388059: Pseudo dice [0.688]
2024-11-15 12:04:19.388979: Epoch time: 92.06 s
2024-11-15 12:04:21.107264: 
2024-11-15 12:04:21.108464: Epoch 80
2024-11-15 12:04:21.109396: Current learning rate: 0.00372
2024-11-15 12:04:21.110339: encoder learning rate: 0.00372
2024-11-15 12:04:21.111281: decoder.stages learning rate: 0.00372
2024-11-15 12:04:21.112197: decoder.transpconvs learning rate: 0.00372
2024-11-15 12:04:21.113122: decoder.seg_layers learning rate: 0.00372
2024-11-15 12:05:53.235329: Validation loss did not improve from -0.51030. Patience: 4/50
2024-11-15 12:05:53.236459: train_loss -0.6979
2024-11-15 12:05:53.237428: val_loss -0.4414
2024-11-15 12:05:53.238261: Pseudo dice [0.6766]
2024-11-15 12:05:53.239008: Epoch time: 92.13 s
2024-11-15 12:05:54.555682: 
2024-11-15 12:05:54.557290: Epoch 81
2024-11-15 12:05:54.558309: Current learning rate: 0.00364
2024-11-15 12:05:54.559320: encoder learning rate: 0.00364
2024-11-15 12:05:54.560250: decoder.stages learning rate: 0.00364
2024-11-15 12:05:54.561116: decoder.transpconvs learning rate: 0.00364
2024-11-15 12:05:54.561861: decoder.seg_layers learning rate: 0.00364
2024-11-15 12:07:27.006417: Validation loss did not improve from -0.51030. Patience: 5/50
2024-11-15 12:07:27.007553: train_loss -0.7132
2024-11-15 12:07:27.008843: val_loss -0.4882
2024-11-15 12:07:27.009777: Pseudo dice [0.7111]
2024-11-15 12:07:27.010762: Epoch time: 92.45 s
2024-11-15 12:07:28.346703: 
2024-11-15 12:07:28.348375: Epoch 82
2024-11-15 12:07:28.349380: Current learning rate: 0.00355
2024-11-15 12:07:28.350552: encoder learning rate: 0.00355
2024-11-15 12:07:28.351459: decoder.stages learning rate: 0.00355
2024-11-15 12:07:28.352343: decoder.transpconvs learning rate: 0.00355
2024-11-15 12:07:28.353485: decoder.seg_layers learning rate: 0.00355
2024-11-15 12:09:00.429354: Validation loss did not improve from -0.51030. Patience: 6/50
2024-11-15 12:09:00.430610: train_loss -0.7054
2024-11-15 12:09:00.431754: val_loss -0.486
2024-11-15 12:09:00.432624: Pseudo dice [0.7138]
2024-11-15 12:09:00.433578: Epoch time: 92.09 s
2024-11-15 12:09:00.434512: Yayy! New best EMA pseudo Dice: 0.6946
2024-11-15 12:09:02.030435: 
2024-11-15 12:09:02.031698: Epoch 83
2024-11-15 12:09:02.032690: Current learning rate: 0.00347
2024-11-15 12:09:02.033609: encoder learning rate: 0.00347
2024-11-15 12:09:02.034444: decoder.stages learning rate: 0.00347
2024-11-15 12:09:02.035282: decoder.transpconvs learning rate: 0.00347
2024-11-15 12:09:02.036112: decoder.seg_layers learning rate: 0.00347
2024-11-15 12:10:33.817412: Validation loss did not improve from -0.51030. Patience: 7/50
2024-11-15 12:10:33.818578: train_loss -0.7075
2024-11-15 12:10:33.819729: val_loss -0.4396
2024-11-15 12:10:33.820784: Pseudo dice [0.6861]
2024-11-15 12:10:33.821710: Epoch time: 91.79 s
2024-11-15 12:10:35.077562: 
2024-11-15 12:10:35.078904: Epoch 84
2024-11-15 12:10:35.079823: Current learning rate: 0.00338
2024-11-15 12:10:35.080761: encoder learning rate: 0.00338
2024-11-15 12:10:35.081640: decoder.stages learning rate: 0.00338
2024-11-15 12:10:35.082481: decoder.transpconvs learning rate: 0.00338
2024-11-15 12:10:35.083358: decoder.seg_layers learning rate: 0.00338
2024-11-15 12:12:06.903172: Validation loss did not improve from -0.51030. Patience: 8/50
2024-11-15 12:12:06.904323: train_loss -0.7075
2024-11-15 12:12:06.905638: val_loss -0.5001
2024-11-15 12:12:06.906628: Pseudo dice [0.7244]
2024-11-15 12:12:06.907639: Epoch time: 91.83 s
2024-11-15 12:12:07.285058: Yayy! New best EMA pseudo Dice: 0.6968
2024-11-15 12:12:08.884781: 
2024-11-15 12:12:08.886203: Epoch 85
2024-11-15 12:12:08.887012: Current learning rate: 0.0033
2024-11-15 12:12:08.887984: encoder learning rate: 0.0033
2024-11-15 12:12:08.888763: decoder.stages learning rate: 0.0033
2024-11-15 12:12:08.889563: decoder.transpconvs learning rate: 0.0033
2024-11-15 12:12:08.890464: decoder.seg_layers learning rate: 0.0033
2024-11-15 12:13:41.192053: Validation loss did not improve from -0.51030. Patience: 9/50
2024-11-15 12:13:41.193559: train_loss -0.7132
2024-11-15 12:13:41.195168: val_loss -0.4933
2024-11-15 12:13:41.196285: Pseudo dice [0.7202]
2024-11-15 12:13:41.197462: Epoch time: 92.31 s
2024-11-15 12:13:41.198496: Yayy! New best EMA pseudo Dice: 0.6992
2024-11-15 12:13:42.853799: 
2024-11-15 12:13:42.855350: Epoch 86
2024-11-15 12:13:42.856484: Current learning rate: 0.00321
2024-11-15 12:13:42.857661: encoder learning rate: 0.00321
2024-11-15 12:13:42.858626: decoder.stages learning rate: 0.00321
2024-11-15 12:13:42.859501: decoder.transpconvs learning rate: 0.00321
2024-11-15 12:13:42.860452: decoder.seg_layers learning rate: 0.00321
2024-11-15 12:15:15.087588: Validation loss did not improve from -0.51030. Patience: 10/50
2024-11-15 12:15:15.089199: train_loss -0.7183
2024-11-15 12:15:15.090808: val_loss -0.4731
2024-11-15 12:15:15.091862: Pseudo dice [0.716]
2024-11-15 12:15:15.092944: Epoch time: 92.24 s
2024-11-15 12:15:15.093809: Yayy! New best EMA pseudo Dice: 0.7008
2024-11-15 12:15:17.175704: 
2024-11-15 12:15:17.177924: Epoch 87
2024-11-15 12:15:17.179038: Current learning rate: 0.00313
2024-11-15 12:15:17.180208: encoder learning rate: 0.00313
2024-11-15 12:15:17.181392: decoder.stages learning rate: 0.00313
2024-11-15 12:15:17.182253: decoder.transpconvs learning rate: 0.00313
2024-11-15 12:15:17.183112: decoder.seg_layers learning rate: 0.00313
2024-11-15 12:16:52.726666: Validation loss did not improve from -0.51030. Patience: 11/50
2024-11-15 12:16:52.728037: train_loss -0.7171
2024-11-15 12:16:52.729224: val_loss -0.4498
2024-11-15 12:16:52.730400: Pseudo dice [0.7021]
2024-11-15 12:16:52.731416: Epoch time: 95.55 s
2024-11-15 12:16:52.732376: Yayy! New best EMA pseudo Dice: 0.701
2024-11-15 12:16:54.966008: 
2024-11-15 12:16:54.969052: Epoch 88
2024-11-15 12:16:54.970600: Current learning rate: 0.00304
2024-11-15 12:16:54.971798: encoder learning rate: 0.00304
2024-11-15 12:16:54.972999: decoder.stages learning rate: 0.00304
2024-11-15 12:16:54.974020: decoder.transpconvs learning rate: 0.00304
2024-11-15 12:16:54.975073: decoder.seg_layers learning rate: 0.00304
2024-11-15 12:18:51.600811: Validation loss did not improve from -0.51030. Patience: 12/50
2024-11-15 12:18:51.656544: train_loss -0.7144
2024-11-15 12:18:51.658345: val_loss -0.4863
2024-11-15 12:18:51.659449: Pseudo dice [0.7166]
2024-11-15 12:18:51.664236: Epoch time: 116.66 s
2024-11-15 12:18:51.666072: Yayy! New best EMA pseudo Dice: 0.7025
2024-11-15 12:18:54.048420: 
2024-11-15 12:18:54.050403: Epoch 89
2024-11-15 12:18:54.052181: Current learning rate: 0.00296
2024-11-15 12:18:54.053879: encoder learning rate: 0.00296
2024-11-15 12:18:54.054834: decoder.stages learning rate: 0.00296
2024-11-15 12:18:54.056222: decoder.transpconvs learning rate: 0.00296
2024-11-15 12:18:54.057952: decoder.seg_layers learning rate: 0.00296
2024-11-15 12:20:29.208981: Validation loss did not improve from -0.51030. Patience: 13/50
2024-11-15 12:20:29.244656: train_loss -0.7238
2024-11-15 12:20:29.287454: val_loss -0.471
2024-11-15 12:20:29.289183: Pseudo dice [0.7119]
2024-11-15 12:20:29.312531: Epoch time: 95.16 s
2024-11-15 12:20:29.685076: Yayy! New best EMA pseudo Dice: 0.7035
2024-11-15 12:20:31.461844: 
2024-11-15 12:20:31.463729: Epoch 90
2024-11-15 12:20:31.464937: Current learning rate: 0.00287
2024-11-15 12:20:31.466089: encoder learning rate: 0.00287
2024-11-15 12:20:31.467152: decoder.stages learning rate: 0.00287
2024-11-15 12:20:31.468347: decoder.transpconvs learning rate: 0.00287
2024-11-15 12:20:31.469896: decoder.seg_layers learning rate: 0.00287
2024-11-15 12:21:58.905159: Validation loss did not improve from -0.51030. Patience: 14/50
2024-11-15 12:21:58.906667: train_loss -0.7164
2024-11-15 12:21:58.907889: val_loss -0.4229
2024-11-15 12:21:58.908976: Pseudo dice [0.6748]
2024-11-15 12:21:58.910046: Epoch time: 87.45 s
2024-11-15 12:22:00.292662: 
2024-11-15 12:22:00.294883: Epoch 91
2024-11-15 12:22:00.296549: Current learning rate: 0.00279
2024-11-15 12:22:00.298556: encoder learning rate: 0.00279
2024-11-15 12:22:00.299953: decoder.stages learning rate: 0.00279
2024-11-15 12:22:00.301111: decoder.transpconvs learning rate: 0.00279
2024-11-15 12:22:00.302022: decoder.seg_layers learning rate: 0.00279
2024-11-15 12:23:28.109606: Validation loss did not improve from -0.51030. Patience: 15/50
2024-11-15 12:23:28.111400: train_loss -0.7212
2024-11-15 12:23:28.113046: val_loss -0.4116
2024-11-15 12:23:28.114790: Pseudo dice [0.682]
2024-11-15 12:23:28.116542: Epoch time: 87.82 s
2024-11-15 12:23:29.294251: 
2024-11-15 12:23:29.296531: Epoch 92
2024-11-15 12:23:29.297628: Current learning rate: 0.0027
2024-11-15 12:23:29.298847: encoder learning rate: 0.0027
2024-11-15 12:23:29.299644: decoder.stages learning rate: 0.0027
2024-11-15 12:23:29.300549: decoder.transpconvs learning rate: 0.0027
2024-11-15 12:23:29.301887: decoder.seg_layers learning rate: 0.0027
2024-11-15 12:24:57.181100: Validation loss did not improve from -0.51030. Patience: 16/50
2024-11-15 12:24:57.182663: train_loss -0.7233
2024-11-15 12:24:57.185092: val_loss -0.4676
2024-11-15 12:24:57.186959: Pseudo dice [0.7019]
2024-11-15 12:24:57.187998: Epoch time: 87.89 s
2024-11-15 12:24:58.363968: 
2024-11-15 12:24:58.367211: Epoch 93
2024-11-15 12:24:58.368984: Current learning rate: 0.00261
2024-11-15 12:24:58.370621: encoder learning rate: 0.00261
2024-11-15 12:24:58.372475: decoder.stages learning rate: 0.00261
2024-11-15 12:24:58.373437: decoder.transpconvs learning rate: 0.00261
2024-11-15 12:24:58.374266: decoder.seg_layers learning rate: 0.00261
2024-11-15 12:26:26.499367: Validation loss did not improve from -0.51030. Patience: 17/50
2024-11-15 12:26:26.500821: train_loss -0.7282
2024-11-15 12:26:26.502017: val_loss -0.455
2024-11-15 12:26:26.502998: Pseudo dice [0.6962]
2024-11-15 12:26:26.504087: Epoch time: 88.14 s
2024-11-15 12:26:27.685595: 
2024-11-15 12:26:27.688031: Epoch 94
2024-11-15 12:26:27.689235: Current learning rate: 0.00252
2024-11-15 12:26:27.690438: encoder learning rate: 0.00252
2024-11-15 12:26:27.691598: decoder.stages learning rate: 0.00252
2024-11-15 12:26:27.692515: decoder.transpconvs learning rate: 0.00252
2024-11-15 12:26:27.693584: decoder.seg_layers learning rate: 0.00252
2024-11-15 12:27:55.875151: Validation loss did not improve from -0.51030. Patience: 18/50
2024-11-15 12:27:55.876645: train_loss -0.7284
2024-11-15 12:27:55.878055: val_loss -0.449
2024-11-15 12:27:55.879012: Pseudo dice [0.6962]
2024-11-15 12:27:55.879891: Epoch time: 88.19 s
2024-11-15 12:27:57.397533: 
2024-11-15 12:27:57.399425: Epoch 95
2024-11-15 12:27:57.400509: Current learning rate: 0.00244
2024-11-15 12:27:57.401436: encoder learning rate: 0.00244
2024-11-15 12:27:57.402528: decoder.stages learning rate: 0.00244
2024-11-15 12:27:57.403393: decoder.transpconvs learning rate: 0.00244
2024-11-15 12:27:57.405087: decoder.seg_layers learning rate: 0.00244
2024-11-15 12:29:25.548053: Validation loss did not improve from -0.51030. Patience: 19/50
2024-11-15 12:29:25.549377: train_loss -0.727
2024-11-15 12:29:25.550758: val_loss -0.4535
2024-11-15 12:29:25.551879: Pseudo dice [0.7038]
2024-11-15 12:29:25.553015: Epoch time: 88.15 s
2024-11-15 12:29:26.736969: 
2024-11-15 12:29:26.739322: Epoch 96
2024-11-15 12:29:26.740371: Current learning rate: 0.00235
2024-11-15 12:29:26.741392: encoder learning rate: 0.00235
2024-11-15 12:29:26.742270: decoder.stages learning rate: 0.00235
2024-11-15 12:29:26.743144: decoder.transpconvs learning rate: 0.00235
2024-11-15 12:29:26.743998: decoder.seg_layers learning rate: 0.00235
2024-11-15 12:30:54.685974: Validation loss did not improve from -0.51030. Patience: 20/50
2024-11-15 12:30:54.687471: train_loss -0.7231
2024-11-15 12:30:54.688721: val_loss -0.4855
2024-11-15 12:30:54.689666: Pseudo dice [0.7143]
2024-11-15 12:30:54.690543: Epoch time: 87.95 s
2024-11-15 12:30:55.928801: 
2024-11-15 12:30:55.931392: Epoch 97
2024-11-15 12:30:55.932526: Current learning rate: 0.00226
2024-11-15 12:30:55.933833: encoder learning rate: 0.00226
2024-11-15 12:30:55.935239: decoder.stages learning rate: 0.00226
2024-11-15 12:30:55.937119: decoder.transpconvs learning rate: 0.00226
2024-11-15 12:30:55.938227: decoder.seg_layers learning rate: 0.00226
2024-11-15 12:32:23.966477: Validation loss did not improve from -0.51030. Patience: 21/50
2024-11-15 12:32:23.967784: train_loss -0.7238
2024-11-15 12:32:23.969255: val_loss -0.4966
2024-11-15 12:32:23.970138: Pseudo dice [0.726]
2024-11-15 12:32:23.970965: Epoch time: 88.04 s
2024-11-15 12:32:25.156664: 
2024-11-15 12:32:25.159501: Epoch 98
2024-11-15 12:32:25.162021: Current learning rate: 0.00217
2024-11-15 12:32:25.163830: encoder learning rate: 0.00217
2024-11-15 12:32:25.164793: decoder.stages learning rate: 0.00217
2024-11-15 12:32:25.165572: decoder.transpconvs learning rate: 0.00217
2024-11-15 12:32:25.166858: decoder.seg_layers learning rate: 0.00217
2024-11-15 12:33:52.904722: Validation loss did not improve from -0.51030. Patience: 22/50
2024-11-15 12:33:52.906559: train_loss -0.7306
2024-11-15 12:33:52.907702: val_loss -0.4016
2024-11-15 12:33:52.908615: Pseudo dice [0.6654]
2024-11-15 12:33:52.909551: Epoch time: 87.75 s
2024-11-15 12:33:56.362019: 
2024-11-15 12:33:56.364552: Epoch 99
2024-11-15 12:33:56.366259: Current learning rate: 0.00208
2024-11-15 12:33:56.367475: encoder learning rate: 0.00208
2024-11-15 12:33:56.368434: decoder.stages learning rate: 0.00208
2024-11-15 12:33:56.369138: decoder.transpconvs learning rate: 0.00208
2024-11-15 12:33:56.369988: decoder.seg_layers learning rate: 0.00208
2024-11-15 12:35:23.841183: Validation loss did not improve from -0.51030. Patience: 23/50
2024-11-15 12:35:23.842560: train_loss -0.7266
2024-11-15 12:35:23.843978: val_loss -0.4948
2024-11-15 12:35:23.845112: Pseudo dice [0.7204]
2024-11-15 12:35:23.846596: Epoch time: 87.48 s
2024-11-15 12:35:25.374950: 
2024-11-15 12:35:25.377263: Epoch 100
2024-11-15 12:35:25.378259: Current learning rate: 0.00199
2024-11-15 12:35:25.379235: encoder learning rate: 0.00199
2024-11-15 12:35:25.380071: decoder.stages learning rate: 0.00199
2024-11-15 12:35:25.380853: decoder.transpconvs learning rate: 0.00199
2024-11-15 12:35:25.381672: decoder.seg_layers learning rate: 0.00199
2024-11-15 12:36:53.100739: Validation loss did not improve from -0.51030. Patience: 24/50
2024-11-15 12:36:53.102740: train_loss -0.7324
2024-11-15 12:36:53.104745: val_loss -0.4637
2024-11-15 12:36:53.106249: Pseudo dice [0.7057]
2024-11-15 12:36:53.107158: Epoch time: 87.73 s
2024-11-15 12:36:54.279144: 
2024-11-15 12:36:54.280993: Epoch 101
2024-11-15 12:36:54.282080: Current learning rate: 0.0019
2024-11-15 12:36:54.283118: encoder learning rate: 0.0019
2024-11-15 12:36:54.284140: decoder.stages learning rate: 0.0019
2024-11-15 12:36:54.285067: decoder.transpconvs learning rate: 0.0019
2024-11-15 12:36:54.286183: decoder.seg_layers learning rate: 0.0019
2024-11-15 12:38:21.931455: Validation loss did not improve from -0.51030. Patience: 25/50
2024-11-15 12:38:21.932484: train_loss -0.7309
2024-11-15 12:38:21.933746: val_loss -0.4719
2024-11-15 12:38:21.934630: Pseudo dice [0.7065]
2024-11-15 12:38:21.935587: Epoch time: 87.65 s
2024-11-15 12:38:23.121748: 
2024-11-15 12:38:23.124504: Epoch 102
2024-11-15 12:38:23.126592: Current learning rate: 0.00181
2024-11-15 12:38:23.128621: encoder learning rate: 0.00181
2024-11-15 12:38:23.130527: decoder.stages learning rate: 0.00181
2024-11-15 12:38:23.131995: decoder.transpconvs learning rate: 0.00181
2024-11-15 12:38:23.132966: decoder.seg_layers learning rate: 0.00181
2024-11-15 12:39:50.697405: Validation loss did not improve from -0.51030. Patience: 26/50
2024-11-15 12:39:50.698778: train_loss -0.7305
2024-11-15 12:39:50.699986: val_loss -0.444
2024-11-15 12:39:50.701640: Pseudo dice [0.6943]
2024-11-15 12:39:50.703429: Epoch time: 87.58 s
2024-11-15 12:39:51.894795: 
2024-11-15 12:39:51.896848: Epoch 103
2024-11-15 12:39:51.898470: Current learning rate: 0.00172
2024-11-15 12:39:51.899861: encoder learning rate: 0.00172
2024-11-15 12:39:51.901499: decoder.stages learning rate: 0.00172
2024-11-15 12:39:51.903218: decoder.transpconvs learning rate: 0.00172
2024-11-15 12:39:51.904070: decoder.seg_layers learning rate: 0.00172
2024-11-15 12:41:19.552337: Validation loss did not improve from -0.51030. Patience: 27/50
2024-11-15 12:41:19.554201: train_loss -0.7327
2024-11-15 12:41:19.555596: val_loss -0.4757
2024-11-15 12:41:19.556537: Pseudo dice [0.7098]
2024-11-15 12:41:19.557443: Epoch time: 87.66 s
2024-11-15 12:41:20.835796: 
2024-11-15 12:41:20.837780: Epoch 104
2024-11-15 12:41:20.839496: Current learning rate: 0.00163
2024-11-15 12:41:20.841351: encoder learning rate: 0.00163
2024-11-15 12:41:20.842335: decoder.stages learning rate: 0.00163
2024-11-15 12:41:20.843485: decoder.transpconvs learning rate: 0.00163
2024-11-15 12:41:20.845075: decoder.seg_layers learning rate: 0.00163
2024-11-15 12:42:48.500095: Validation loss did not improve from -0.51030. Patience: 28/50
2024-11-15 12:42:48.501585: train_loss -0.7397
2024-11-15 12:42:48.503035: val_loss -0.4374
2024-11-15 12:42:48.503926: Pseudo dice [0.6879]
2024-11-15 12:42:48.504829: Epoch time: 87.67 s
2024-11-15 12:42:50.044860: 
2024-11-15 12:42:50.047034: Epoch 105
2024-11-15 12:42:50.048651: Current learning rate: 0.00154
2024-11-15 12:42:50.050239: encoder learning rate: 0.00154
2024-11-15 12:42:50.051980: decoder.stages learning rate: 0.00154
2024-11-15 12:42:50.053088: decoder.transpconvs learning rate: 0.00154
2024-11-15 12:42:50.054242: decoder.seg_layers learning rate: 0.00154
2024-11-15 12:44:17.667199: Validation loss did not improve from -0.51030. Patience: 29/50
2024-11-15 12:44:17.668236: train_loss -0.734
2024-11-15 12:44:17.669157: val_loss -0.4349
2024-11-15 12:44:17.670047: Pseudo dice [0.6837]
2024-11-15 12:44:17.670940: Epoch time: 87.63 s
2024-11-15 12:44:18.866053: 
2024-11-15 12:44:18.867588: Epoch 106
2024-11-15 12:44:18.868489: Current learning rate: 0.00145
2024-11-15 12:44:18.869480: encoder learning rate: 0.00145
2024-11-15 12:44:18.870355: decoder.stages learning rate: 0.00145
2024-11-15 12:44:18.871211: decoder.transpconvs learning rate: 0.00145
2024-11-15 12:44:18.871975: decoder.seg_layers learning rate: 0.00145
2024-11-15 12:45:46.788907: Validation loss did not improve from -0.51030. Patience: 30/50
2024-11-15 12:45:46.791154: train_loss -0.7377
2024-11-15 12:45:46.793776: val_loss -0.4513
2024-11-15 12:45:46.795201: Pseudo dice [0.6943]
2024-11-15 12:45:46.795984: Epoch time: 87.93 s
2024-11-15 12:45:47.981982: 
2024-11-15 12:45:47.984181: Epoch 107
2024-11-15 12:45:47.985428: Current learning rate: 0.00135
2024-11-15 12:45:47.986962: encoder learning rate: 0.00135
2024-11-15 12:45:47.988349: decoder.stages learning rate: 0.00135
2024-11-15 12:45:47.989191: decoder.transpconvs learning rate: 0.00135
2024-11-15 12:45:47.990017: decoder.seg_layers learning rate: 0.00135
2024-11-15 12:47:16.040500: Validation loss did not improve from -0.51030. Patience: 31/50
2024-11-15 12:47:16.041698: train_loss -0.7422
2024-11-15 12:47:16.042984: val_loss -0.4607
2024-11-15 12:47:16.044104: Pseudo dice [0.7035]
2024-11-15 12:47:16.045172: Epoch time: 88.06 s
2024-11-15 12:47:17.234110: 
2024-11-15 12:47:17.236903: Epoch 108
2024-11-15 12:47:17.238403: Current learning rate: 0.00126
2024-11-15 12:47:17.240124: encoder learning rate: 0.00126
2024-11-15 12:47:17.241678: decoder.stages learning rate: 0.00126
2024-11-15 12:47:17.243052: decoder.transpconvs learning rate: 0.00126
2024-11-15 12:47:17.244481: decoder.seg_layers learning rate: 0.00126
2024-11-15 12:48:45.321046: Validation loss did not improve from -0.51030. Patience: 32/50
2024-11-15 12:48:45.322224: train_loss -0.7395
2024-11-15 12:48:45.323550: val_loss -0.4515
2024-11-15 12:48:45.324764: Pseudo dice [0.7021]
2024-11-15 12:48:45.325992: Epoch time: 88.09 s
2024-11-15 12:48:46.544231: 
2024-11-15 12:48:46.546713: Epoch 109
2024-11-15 12:48:46.548110: Current learning rate: 0.00116
2024-11-15 12:48:46.549438: encoder learning rate: 0.00116
2024-11-15 12:48:46.550642: decoder.stages learning rate: 0.00116
2024-11-15 12:48:46.551881: decoder.transpconvs learning rate: 0.00116
2024-11-15 12:48:46.553046: decoder.seg_layers learning rate: 0.00116
2024-11-15 12:50:14.656286: Validation loss did not improve from -0.51030. Patience: 33/50
2024-11-15 12:50:14.657817: train_loss -0.7427
2024-11-15 12:50:14.658934: val_loss -0.4309
2024-11-15 12:50:14.659892: Pseudo dice [0.6886]
2024-11-15 12:50:14.660717: Epoch time: 88.12 s
2024-11-15 12:50:16.233768: 
2024-11-15 12:50:16.236150: Epoch 110
2024-11-15 12:50:16.237058: Current learning rate: 0.00107
2024-11-15 12:50:16.238155: encoder learning rate: 0.00107
2024-11-15 12:50:16.239034: decoder.stages learning rate: 0.00107
2024-11-15 12:50:16.239923: decoder.transpconvs learning rate: 0.00107
2024-11-15 12:50:16.240872: decoder.seg_layers learning rate: 0.00107
2024-11-15 12:51:44.123985: Validation loss did not improve from -0.51030. Patience: 34/50
2024-11-15 12:51:44.125267: train_loss -0.7444
2024-11-15 12:51:44.126615: val_loss -0.4706
2024-11-15 12:51:44.127582: Pseudo dice [0.71]
2024-11-15 12:51:44.128467: Epoch time: 87.89 s
2024-11-15 12:51:45.737803: 
2024-11-15 12:51:45.740698: Epoch 111
2024-11-15 12:51:45.742172: Current learning rate: 0.00097
2024-11-15 12:51:45.743708: encoder learning rate: 0.00097
2024-11-15 12:51:45.745280: decoder.stages learning rate: 0.00097
2024-11-15 12:51:45.746300: decoder.transpconvs learning rate: 0.00097
2024-11-15 12:51:45.747156: decoder.seg_layers learning rate: 0.00097
2024-11-15 12:53:13.684274: Validation loss did not improve from -0.51030. Patience: 35/50
2024-11-15 12:53:13.686311: train_loss -0.7452
2024-11-15 12:53:13.687743: val_loss -0.4779
2024-11-15 12:53:13.688823: Pseudo dice [0.7073]
2024-11-15 12:53:13.689730: Epoch time: 87.95 s
2024-11-15 12:53:14.878888: 
2024-11-15 12:53:14.880464: Epoch 112
2024-11-15 12:53:14.881408: Current learning rate: 0.00087
2024-11-15 12:53:14.882829: encoder learning rate: 0.00087
2024-11-15 12:53:14.884138: decoder.stages learning rate: 0.00087
2024-11-15 12:53:14.885258: decoder.transpconvs learning rate: 0.00087
2024-11-15 12:53:14.886724: decoder.seg_layers learning rate: 0.00087
2024-11-15 12:54:42.830605: Validation loss did not improve from -0.51030. Patience: 36/50
2024-11-15 12:54:42.831960: train_loss -0.7418
2024-11-15 12:54:42.833125: val_loss -0.4383
2024-11-15 12:54:42.833985: Pseudo dice [0.6753]
2024-11-15 12:54:42.834838: Epoch time: 87.95 s
2024-11-15 12:54:44.030041: 
2024-11-15 12:54:44.032852: Epoch 113
2024-11-15 12:54:44.034229: Current learning rate: 0.00078
2024-11-15 12:54:44.035159: encoder learning rate: 0.00078
2024-11-15 12:54:44.036067: decoder.stages learning rate: 0.00078
2024-11-15 12:54:44.036829: decoder.transpconvs learning rate: 0.00078
2024-11-15 12:54:44.037600: decoder.seg_layers learning rate: 0.00078
2024-11-15 12:56:12.007052: Validation loss did not improve from -0.51030. Patience: 37/50
2024-11-15 12:56:12.008369: train_loss -0.7528
2024-11-15 12:56:12.009959: val_loss -0.4238
2024-11-15 12:56:12.011372: Pseudo dice [0.6803]
2024-11-15 12:56:12.012342: Epoch time: 87.98 s
2024-11-15 12:56:13.213588: 
2024-11-15 12:56:13.215792: Epoch 114
2024-11-15 12:56:13.216640: Current learning rate: 0.00067
2024-11-15 12:56:13.218072: encoder learning rate: 0.00067
2024-11-15 12:56:13.219468: decoder.stages learning rate: 0.00067
2024-11-15 12:56:13.220767: decoder.transpconvs learning rate: 0.00067
2024-11-15 12:56:13.221561: decoder.seg_layers learning rate: 0.00067
2024-11-15 12:57:41.214764: Validation loss did not improve from -0.51030. Patience: 38/50
2024-11-15 12:57:41.216136: train_loss -0.7499
2024-11-15 12:57:41.217979: val_loss -0.4255
2024-11-15 12:57:41.219317: Pseudo dice [0.682]
2024-11-15 12:57:41.220618: Epoch time: 88.0 s
2024-11-15 12:57:42.809222: 
2024-11-15 12:57:42.812102: Epoch 115
2024-11-15 12:57:42.814228: Current learning rate: 0.00057
2024-11-15 12:57:42.816098: encoder learning rate: 0.00057
2024-11-15 12:57:42.817271: decoder.stages learning rate: 0.00057
2024-11-15 12:57:42.818802: decoder.transpconvs learning rate: 0.00057
2024-11-15 12:57:42.820429: decoder.seg_layers learning rate: 0.00057
2024-11-15 12:59:10.750690: Validation loss did not improve from -0.51030. Patience: 39/50
2024-11-15 12:59:10.752150: train_loss -0.7485
2024-11-15 12:59:10.753883: val_loss -0.4508
2024-11-15 12:59:10.755672: Pseudo dice [0.6959]
2024-11-15 12:59:10.756804: Epoch time: 87.94 s
2024-11-15 12:59:11.966467: 
2024-11-15 12:59:11.968687: Epoch 116
2024-11-15 12:59:11.969929: Current learning rate: 0.00047
2024-11-15 12:59:11.971164: encoder learning rate: 0.00047
2024-11-15 12:59:11.972242: decoder.stages learning rate: 0.00047
2024-11-15 12:59:11.973238: decoder.transpconvs learning rate: 0.00047
2024-11-15 12:59:11.974232: decoder.seg_layers learning rate: 0.00047
2024-11-15 13:00:40.024326: Validation loss did not improve from -0.51030. Patience: 40/50
2024-11-15 13:00:40.025364: train_loss -0.7466
2024-11-15 13:00:40.026408: val_loss -0.4672
2024-11-15 13:00:40.027339: Pseudo dice [0.715]
2024-11-15 13:00:40.028255: Epoch time: 88.06 s
2024-11-15 13:00:41.248932: 
2024-11-15 13:00:41.250912: Epoch 117
2024-11-15 13:00:41.252471: Current learning rate: 0.00036
2024-11-15 13:00:41.253783: encoder learning rate: 0.00036
2024-11-15 13:00:41.254834: decoder.stages learning rate: 0.00036
2024-11-15 13:00:41.255745: decoder.transpconvs learning rate: 0.00036
2024-11-15 13:00:41.256591: decoder.seg_layers learning rate: 0.00036
2024-11-15 13:02:09.185885: Validation loss did not improve from -0.51030. Patience: 41/50
2024-11-15 13:02:09.187410: train_loss -0.7494
2024-11-15 13:02:09.188813: val_loss -0.4525
2024-11-15 13:02:09.189811: Pseudo dice [0.6894]
2024-11-15 13:02:09.190682: Epoch time: 87.94 s
2024-11-15 13:02:10.402514: 
2024-11-15 13:02:10.405534: Epoch 118
2024-11-15 13:02:10.407025: Current learning rate: 0.00025
2024-11-15 13:02:10.409657: encoder learning rate: 0.00025
2024-11-15 13:02:10.411513: decoder.stages learning rate: 0.00025
2024-11-15 13:02:10.412355: decoder.transpconvs learning rate: 0.00025
2024-11-15 13:02:10.413125: decoder.seg_layers learning rate: 0.00025
2024-11-15 13:03:38.475416: Validation loss did not improve from -0.51030. Patience: 42/50
2024-11-15 13:03:38.476625: train_loss -0.7448
2024-11-15 13:03:38.477786: val_loss -0.4733
2024-11-15 13:03:38.479034: Pseudo dice [0.7004]
2024-11-15 13:03:38.479911: Epoch time: 88.08 s
2024-11-15 13:03:39.712961: 
2024-11-15 13:03:39.714548: Epoch 119
2024-11-15 13:03:39.716002: Current learning rate: 0.00013
2024-11-15 13:03:39.717518: encoder learning rate: 0.00013
2024-11-15 13:03:39.719085: decoder.stages learning rate: 0.00013
2024-11-15 13:03:39.720583: decoder.transpconvs learning rate: 0.00013
2024-11-15 13:03:39.722232: decoder.seg_layers learning rate: 0.00013
2024-11-15 13:05:07.718699: Validation loss did not improve from -0.51030. Patience: 43/50
2024-11-15 13:05:07.720062: train_loss -0.7471
2024-11-15 13:05:07.721621: val_loss -0.4713
2024-11-15 13:05:07.723211: Pseudo dice [0.7048]
2024-11-15 13:05:07.724712: Epoch time: 88.01 s
2024-11-15 13:05:09.304957: 
2024-11-15 13:05:09.306787: Epoch 120
2024-11-15 13:05:09.307711: Current learning rate: 0.0
2024-11-15 13:05:09.308762: encoder learning rate: 0.0
2024-11-15 13:05:09.309753: decoder.stages learning rate: 0.0
2024-11-15 13:05:09.310926: decoder.transpconvs learning rate: 0.0
2024-11-15 13:05:09.312163: decoder.seg_layers learning rate: 0.0
2024-11-15 13:06:37.757021: Validation loss did not improve from -0.51030. Patience: 44/50
2024-11-15 13:06:37.758422: train_loss -0.7483
2024-11-15 13:06:37.759675: val_loss -0.4165
2024-11-15 13:06:37.760966: Pseudo dice [0.6836]
2024-11-15 13:06:37.762641: Epoch time: 88.45 s
2024-11-15 13:06:38.979719: 
2024-11-15 13:06:38.982322: Epoch 121
2024-11-15 13:06:39.033070: Current learning rate: (-0.00013+4e-05j)
Traceback (most recent call last):
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/bin/nnUNetv2_train", line 8, in <module>
    sys.exit(run_training_entry())
  File "/home/gridsan/nchutisilp/projects/nnUNet/nnunetv2/run/run_training.py", line 275, in run_training_entry
    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,
  File "/home/gridsan/nchutisilp/projects/nnUNet/nnunetv2/run/run_training.py", line 211, in run_training
    nnunet_trainer.run_training()
  File "/home/gridsan/nchutisilp/projects/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py", line 1398, in run_training
    self.on_train_epoch_start()
  File "/home/gridsan/nchutisilp/projects/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer4PretrainedEncoder.py", line 19, in on_train_epoch_start
    super().on_train_epoch_start()
  File "/home/gridsan/nchutisilp/projects/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py", line 993, in on_train_epoch_start
    self.logger.log('lrs', self.optimizer.param_groups[0]['lr'], self.current_epoch)
  File "/home/gridsan/nchutisilp/projects/nnUNet/nnunetv2/training/logging/nnunet_logger.py", line 48, in log
    wandb.log({key: value}, step=epoch)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/wandb/sdk/wandb_run.py", line 420, in wrapper
    return func(self, *args, **kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/wandb/sdk/wandb_run.py", line 371, in wrapper_fn
    return func(self, *args, **kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/wandb/sdk/wandb_run.py", line 361, in wrapper
    return func(self, *args, **kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/wandb/sdk/wandb_run.py", line 1838, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/wandb/sdk/wandb_run.py", line 1602, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/wandb/sdk/wandb_run.py", line 1474, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/wandb/sdk/interface/interface.py", line 596, in publish_partial_history
    item.value_json = json_dumps_safer_history(v)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/wandb/util.py", line 842, in json_dumps_safer_history
    return dumps(obj, cls=WandBHistoryJSONEncoder, **kwargs)
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/json/__init__.py", line 234, in dumps
    return cls(
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/wandb/util.py", line 807, in default
    return json.JSONEncoder.default(self, obj)
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type complex is not JSON serializable
wandb: 
wandb: Run history:
wandb:            ema_fg_dice ▁▂▂▃▃▄▄▄▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇███████████████
wandb:   epoch_end_timestamps ▁▁▂▂▂▂▃▃▃▄▄▄▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████
wandb: epoch_start_timestamps ▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████
wandb:                    lrs ▁▁▁▁▁▁▁███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁
wandb:           mean_fg_dice ▁▄▄▅▅▄▅▄▅▆▃▆▆▆▇▆▇▆▆▆▆▇▆▇▇█▆▇██▇▇▆▇▇▇█▇█▇
wandb:           train_losses █▆▅▅▄▄▄▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_losses █▅▅▅▅▅▄▅▄▃▅▃▃▃▂▃▃▃▃▃▃▂▃▂▂▁▂▂▂▂▂▂▃▂▂▂▂▃▂▃
wandb: 
wandb: Run summary:
wandb:            ema_fg_dice 0.69595
wandb:   epoch_end_timestamps 1731693997.75825
wandb: epoch_start_timestamps 1731693998.97789
wandb:                    lrs 0.0
wandb:           mean_fg_dice 0.68362
wandb:           train_losses -0.74828
wandb:             val_losses -0.41648
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset302_Calcium_OCTv2/nnUNetTrainer4PretrainedEncoder__nnUNetPlans__3d_32x160x128_b10/fold_2/wandb/offline-run-20241115_065026-us57coo3
wandb: Find logs at: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset302_Calcium_OCTv2/nnUNetTrainer4PretrainedEncoder__nnUNetPlans__3d_32x160x128_b10/fold_2/wandb/offline-run-20241115_065026-us57coo3/logs
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f58204e85b0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f587016c7c0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f58200f6340>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f588c1c5e80>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f588c1c5d00>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f588c1c57c0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
Exception in thread Thread-4:
Traceback (most recent call last):
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/threading.py", line 980, in _bootstrap_inner
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/threading.py", line 980, in _bootstrap_inner
FOLD 2 CONFIG 3d_32x160x128_b10 TRAINER nnUNetTrainer4PretrainedEncoder

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 2 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 2 cases that I would like to predict

Predicting 101-045:
perform_everything_on_device: True
  0%|          | 0/966 [00:00<?, ?it/s]  0%|          | 1/966 [00:20<5:36:34, 20.93s/it]  0%|          | 3/966 [00:21<1:28:07,  5.49s/it]  1%|          | 5/966 [00:21<43:41,  2.73s/it]    1%|          | 6/966 [00:21<32:25,  2.03s/it]  1%|          | 7/966 [00:21<23:55,  1.50s/it]  1%|          | 8/966 [00:21<17:38,  1.10s/it]  1%|          | 9/966 [00:21<13:04,  1.22it/s]  1%|          | 10/966 [00:21<09:47,  1.63it/s]  1%|          | 11/966 [00:22<07:27,  2.14it/s]  1%|          | 12/966 [00:22<05:47,  2.74it/s]  1%|▏         | 13/966 [00:22<04:37,  3.44it/s]  1%|▏         | 14/966 [00:22<03:47,  4.18it/s]  2%|▏         | 15/966 [00:22<03:12,  4.94it/s]  2%|▏         | 16/966 [00:22<02:47,  5.66it/s]  2%|▏         | 17/966 [00:22<02:30,  6.30it/s]  2%|▏         | 18/966 [00:22<02:18,  6.84it/s]  2%|▏         | 19/966 [00:22<02:10,  7.27it/s]  2%|▏         | 20/966 [00:23<02:04,  7.61it/s]  2%|▏         | 21/966 [00:23<01:59,  7.88it/s]  2%|▏         | 22/966 [00:23<01:57,  8.06it/s]  2%|▏         | 23/966 [00:23<01:55,  8.20it/s]  2%|▏         | 24/966 [00:23<01:53,  8.28it/s]  3%|▎         | 25/966 [00:23<01:52,  8.36it/s]  3%|▎         | 26/966 [00:23<01:51,  8.42it/s]  3%|▎         | 27/966 [00:23<01:50,  8.48it/s]  3%|▎         | 28/966 [00:24<01:50,  8.49it/s]  3%|▎         | 29/966 [00:24<01:50,  8.52it/s]  3%|▎         | 30/966 [00:24<01:49,  8.53it/s]  3%|▎         | 31/966 [00:24<01:49,  8.54it/s]  3%|▎         | 32/966 [00:24<01:49,  8.54it/s]  3%|▎         | 33/966 [00:24<01:49,  8.54it/s]  4%|▎         | 34/966 [00:24<01:49,  8.55it/s]  4%|▎         | 35/966 [00:24<01:48,  8.55it/s]  4%|▎         | 36/966 [00:24<01:48,  8.56it/s]  4%|▍         | 37/966 [00:25<01:48,  8.57it/s]  4%|▍         | 38/966 [00:25<01:48,  8.59it/s]  4%|▍         | 39/966 [00:25<01:48,  8.58it/s]  4%|▍         | 40/966 [00:25<01:48,  8.57it/s]  4%|▍         | 41/966 [00:25<01:47,  8.58it/s]  4%|▍         | 42/966 [00:25<01:47,  8.58it/s]  4%|▍         | 43/966 [00:25<01:47,  8.60it/s]  5%|▍         | 44/966 [00:25<01:47,  8.61it/s]  5%|▍         | 45/966 [00:26<01:46,  8.62it/s]  5%|▍         | 46/966 [00:26<01:46,  8.61it/s]  5%|▍         | 47/966 [00:26<01:46,  8.59it/s]  5%|▍         | 48/966 [00:26<01:47,  8.58it/s]  5%|▌         | 49/966 [00:26<01:46,  8.57it/s]  5%|▌         | 50/966 [00:26<01:46,  8.59it/s]  5%|▌         | 51/966 [00:26<01:46,  8.57it/s]  5%|▌         | 52/966 [00:26<01:46,  8.56it/s]  5%|▌         | 53/966 [00:26<01:46,  8.54it/s]  6%|▌         | 54/966 [00:27<01:46,  8.54it/s]  6%|▌         | 55/966 [00:27<01:46,  8.55it/s]  6%|▌         | 56/966 [00:27<01:46,  8.54it/s]  6%|▌         | 57/966 [00:27<01:46,  8.55it/s]  6%|▌         | 58/966 [00:27<01:46,  8.55it/s]  6%|▌         | 59/966 [00:27<01:46,  8.54it/s]  6%|▌         | 60/966 [00:27<01:46,  8.54it/s]  6%|▋         | 61/966 [00:27<01:46,  8.54it/s]  6%|▋         | 62/966 [00:27<01:45,  8.53it/s]  7%|▋         | 63/966 [00:28<01:45,  8.52it/s]  7%|▋         | 64/966 [00:28<01:45,  8.52it/s]  7%|▋         | 65/966 [00:28<01:45,  8.53it/s]  7%|▋         | 66/966 [00:28<01:45,  8.53it/s]  7%|▋         | 67/966 [00:28<01:45,  8.53it/s]  7%|▋         | 68/966 [00:28<01:45,  8.55it/s]  7%|▋         | 69/966 [00:28<01:44,  8.57it/s]  7%|▋         | 70/966 [00:28<01:44,  8.56it/s]  7%|▋         | 71/966 [00:29<01:44,  8.56it/s]  7%|▋         | 72/966 [00:29<01:44,  8.57it/s]  8%|▊         | 73/966 [00:29<01:44,  8.58it/s]  8%|▊         | 74/966 [00:29<01:44,  8.57it/s]  8%|▊         | 75/966 [00:29<01:44,  8.56it/s]  8%|▊         | 76/966 [00:29<01:44,  8.56it/s]  8%|▊         | 77/966 [00:29<01:43,  8.56it/s]  8%|▊         | 78/966 [00:29<01:43,  8.58it/s]  8%|▊         | 79/966 [00:29<01:43,  8.57it/s]  8%|▊         | 80/966 [00:30<01:43,  8.58it/s]  8%|▊         | 81/966 [00:30<01:43,  8.58it/s]  8%|▊         | 82/966 [00:30<01:43,  8.57it/s]  9%|▊         | 83/966 [00:30<01:42,  8.58it/s]  9%|▊         | 84/966 [00:30<01:42,  8.58it/s]  9%|▉         | 85/966 [00:30<01:42,  8.58it/s]  9%|▉         | 86/966 [00:30<01:42,  8.57it/s]  9%|▉         | 87/966 [00:30<01:42,  8.57it/s]  9%|▉         | 88/966 [00:31<01:42,  8.56it/s]  9%|▉         | 89/966 [00:31<01:42,  8.56it/s]  9%|▉         | 90/966 [00:31<01:42,  8.57it/s]  9%|▉         | 91/966 [00:31<01:42,  8.57it/s] 10%|▉         | 92/966 [00:31<01:41,  8.57it/s] 10%|▉         | 93/966 [00:31<01:41,  8.58it/s] 10%|▉         | 94/966 [00:31<01:41,  8.55it/s] 10%|▉         | 95/966 [00:31<01:42,  8.54it/s] 10%|▉         | 96/966 [00:31<01:42,  8.52it/s] 10%|█         | 97/966 [00:32<01:42,  8.52it/s] 10%|█         | 98/966 [00:32<01:41,  8.53it/s] 10%|█         | 99/966 [00:32<01:41,  8.53it/s] 10%|█         | 100/966 [00:32<01:41,  8.53it/s] 10%|█         | 101/966 [00:32<01:41,  8.54it/s] 11%|█         | 102/966 [00:32<01:41,  8.52it/s] 11%|█         | 103/966 [00:32<01:41,  8.53it/s] 11%|█         | 104/966 [00:32<01:41,  8.53it/s] 11%|█         | 105/966 [00:33<01:40,  8.53it/s] 11%|█         | 106/966 [00:33<01:40,  8.52it/s] 11%|█         | 107/966 [00:33<01:41,  8.50it/s] 11%|█         | 108/966 [00:33<01:40,  8.51it/s] 11%|█▏        | 109/966 [00:33<01:40,  8.52it/s] 11%|█▏        | 110/966 [00:33<01:40,  8.51it/s] 11%|█▏        | 111/966 [00:33<01:40,  8.51it/s] 12%|█▏        | 112/966 [00:33<01:40,  8.53it/s] 12%|█▏        | 113/966 [00:33<01:39,  8.55it/s] 12%|█▏        | 114/966 [00:34<01:39,  8.55it/s] 12%|█▏        | 115/966 [00:34<01:39,  8.55it/s] 12%|█▏        | 116/966 [00:34<01:39,  8.54it/s] 12%|█▏        | 117/966 [00:34<01:39,  8.53it/s] 12%|█▏        | 118/966 [00:34<01:39,  8.52it/s] 12%|█▏        | 119/966 [00:34<01:39,  8.53it/s] 12%|█▏        | 120/966 [00:34<01:39,  8.52it/s] 13%|█▎        | 121/966 [00:34<01:39,  8.53it/s] 13%|█▎        | 122/966 [00:35<01:38,  8.53it/s] 13%|█▎        | 123/966 [00:35<01:38,  8.52it/s] 13%|█▎        | 124/966 [00:35<01:38,  8.51it/s] 13%|█▎        | 125/966 [00:35<01:38,  8.51it/s] 13%|█▎        | 126/966 [00:35<01:38,  8.50it/s] 13%|█▎        | 127/966 [00:35<01:38,  8.50it/s] 13%|█▎        | 128/966 [00:35<01:38,  8.52it/s] 13%|█▎        | 129/966 [00:35<01:38,  8.54it/s] 13%|█▎        | 130/966 [00:35<01:38,  8.53it/s] 14%|█▎        | 131/966 [00:36<01:37,  8.55it/s] 14%|█▎        | 132/966 [00:36<01:37,  8.55it/s] 14%|█▍        | 133/966 [00:36<01:37,  8.57it/s] 14%|█▍        | 134/966 [00:36<01:36,  8.58it/s] 14%|█▍        | 135/966 [00:36<01:37,  8.56it/s] 14%|█▍        | 136/966 [00:36<01:36,  8.56it/s] 14%|█▍        | 137/966 [00:36<01:36,  8.56it/s] 14%|█▍        | 138/966 [00:36<01:36,  8.55it/s] 14%|█▍        | 139/966 [00:37<01:36,  8.54it/s] 14%|█▍        | 140/966 [00:37<01:36,  8.53it/s] 15%|█▍        | 141/966 [00:37<01:36,  8.56it/s] 15%|█▍        | 142/966 [00:37<01:36,  8.54it/s] 15%|█▍        | 143/966 [00:37<01:36,  8.55it/s] 15%|█▍        | 144/966 [00:37<01:36,  8.55it/s] 15%|█▌        | 145/966 [00:37<01:36,  8.53it/s] 15%|█▌        | 146/966 [00:37<01:36,  8.53it/s] 15%|█▌        | 147/966 [00:37<01:35,  8.54it/s] 15%|█▌        | 148/966 [00:38<01:35,  8.54it/s] 15%|█▌        | 149/966 [00:38<01:35,  8.54it/s] 16%|█▌        | 150/966 [00:38<01:35,  8.52it/s] 16%|█▌        | 151/966 [00:38<01:35,  8.53it/s] 16%|█▌        | 152/966 [00:38<01:35,  8.54it/s] 16%|█▌        | 153/966 [00:38<01:35,  8.52it/s] 16%|█▌        | 154/966 [00:38<01:35,  8.51it/s] 16%|█▌        | 155/966 [00:38<01:35,  8.52it/s] 16%|█▌        | 156/966 [00:38<01:35,  8.53it/s] 16%|█▋        | 157/966 [00:39<01:35,  8.51it/s] 16%|█▋        | 158/966 [00:39<01:34,  8.51it/s] 16%|█▋        | 159/966 [00:39<01:34,  8.50it/s] 17%|█▋        | 160/966 [00:39<01:34,  8.50it/s] 17%|█▋        | 161/966 [00:39<01:34,  8.50it/s] 17%|█▋        | 162/966 [00:39<01:34,  8.51it/s] 17%|█▋        | 163/966 [00:39<01:34,  8.50it/s] 17%|█▋        | 164/966 [00:39<01:34,  8.51it/s] 17%|█▋        | 165/966 [00:40<01:34,  8.51it/s] 17%|█▋        | 166/966 [00:40<01:34,  8.51it/s] 17%|█▋        | 167/966 [00:40<01:33,  8.52it/s] 17%|█▋        | 168/966 [00:40<01:33,  8.52it/s] 17%|█▋        | 169/966 [00:40<01:33,  8.54it/s] 18%|█▊        | 170/966 [00:40<01:32,  8.57it/s] 18%|█▊        | 171/966 [00:40<01:32,  8.57it/s] 18%|█▊        | 172/966 [00:40<01:32,  8.57it/s] 18%|█▊        | 173/966 [00:40<01:32,  8.56it/s] 18%|█▊        | 174/966 [00:41<01:32,  8.55it/s] 18%|█▊        | 175/966 [00:41<01:32,  8.55it/s] 18%|█▊        | 176/966 [00:41<01:32,  8.54it/s] 18%|█▊        | 177/966 [00:41<01:32,  8.54it/s] 18%|█▊        | 178/966 [00:41<01:32,  8.53it/s] 19%|█▊        | 179/966 [00:41<01:32,  8.53it/s] 19%|█▊        | 180/966 [00:41<01:32,  8.52it/s] 19%|█▊        | 181/966 [00:41<01:32,  8.52it/s] 19%|█▉        | 182/966 [00:42<01:32,  8.51it/s] 19%|█▉        | 183/966 [00:42<01:31,  8.52it/s] 19%|█▉        | 184/966 [00:42<01:31,  8.53it/s] 19%|█▉        | 185/966 [00:42<01:31,  8.52it/s] 19%|█▉        | 186/966 [00:42<01:31,  8.53it/s] 19%|█▉        | 187/966 [00:42<01:31,  8.52it/s] 19%|█▉        | 188/966 [00:42<01:31,  8.52it/s] 20%|█▉        | 189/966 [00:42<01:31,  8.52it/s] 20%|█▉        | 190/966 [00:42<01:31,  8.52it/s] 20%|█▉        | 191/966 [00:43<01:30,  8.53it/s] 20%|█▉        | 192/966 [00:43<01:30,  8.51it/s] 20%|█▉        | 193/966 [00:43<01:30,  8.52it/s] 20%|██        | 194/966 [00:43<01:30,  8.53it/s] 20%|██        | 195/966 [00:43<01:30,  8.52it/s] 20%|██        | 196/966 [00:43<01:30,  8.52it/s] 20%|██        | 197/966 [00:43<01:30,  8.52it/s] 20%|██        | 198/966 [00:43<01:30,  8.51it/s] 21%|██        | 199/966 [00:44<01:29,  8.53it/s] 21%|██        | 200/966 [00:44<01:29,  8.54it/s] 21%|██        | 201/966 [00:44<01:29,  8.53it/s] 21%|██        | 202/966 [00:44<01:29,  8.52it/s] 21%|██        | 203/966 [00:44<01:29,  8.52it/s] 21%|██        | 204/966 [00:44<01:29,  8.53it/s] 21%|██        | 205/966 [00:44<01:29,  8.54it/s] 21%|██▏       | 206/966 [00:44<01:28,  8.55it/s] 21%|██▏       | 207/966 [00:44<01:28,  8.54it/s] 22%|██▏       | 208/966 [00:45<01:28,  8.54it/s] 22%|██▏       | 209/966 [00:45<01:28,  8.55it/s] 22%|██▏       | 210/966 [00:45<01:28,  8.56it/s] 22%|██▏       | 211/966 [00:45<01:28,  8.55it/s] 22%|██▏       | 212/966 [00:45<01:28,  8.56it/s] 22%|██▏       | 213/966 [00:45<01:27,  8.57it/s] 22%|██▏       | 214/966 [00:45<01:27,  8.56it/s] 22%|██▏       | 215/966 [00:45<01:28,  8.52it/s] 22%|██▏       | 216/966 [00:46<01:28,  8.50it/s] 22%|██▏       | 217/966 [00:46<01:28,  8.50it/s] 23%|██▎       | 218/966 [00:46<01:27,  8.51it/s] 23%|██▎       | 219/966 [00:46<01:27,  8.51it/s] 23%|██▎       | 220/966 [00:46<01:27,  8.51it/s] 23%|██▎       | 221/966 [00:46<01:27,  8.52it/s] 23%|██▎       | 222/966 [00:46<01:27,  8.53it/s] 23%|██▎       | 223/966 [00:46<01:26,  8.54it/s] 23%|██▎       | 224/966 [00:46<01:26,  8.54it/s] 23%|██▎       | 225/966 [00:47<01:26,  8.54it/s] 23%|██▎       | 226/966 [00:47<01:26,  8.52it/s] 23%|██▎       | 227/966 [00:47<01:26,  8.53it/s] 24%|██▎       | 228/966 [00:47<01:26,  8.52it/s] 24%|██▎       | 229/966 [00:47<01:26,  8.52it/s] 24%|██▍       | 230/966 [00:47<01:26,  8.51it/s] 24%|██▍       | 231/966 [00:47<01:26,  8.50it/s] 24%|██▍       | 232/966 [00:47<01:26,  8.49it/s] 24%|██▍       | 233/966 [00:48<01:26,  8.48it/s] 24%|██▍       | 234/966 [00:48<01:26,  8.50it/s] 24%|██▍       | 235/966 [00:48<01:25,  8.51it/s] 24%|██▍       | 236/966 [00:48<01:25,  8.50it/s] 25%|██▍       | 237/966 [00:48<01:25,  8.50it/s] 25%|██▍       | 238/966 [00:48<01:25,  8.49it/s] 25%|██▍       | 239/966 [00:48<01:25,  8.49it/s] 25%|██▍       | 240/966 [00:48<01:25,  8.51it/s] 25%|██▍       | 241/966 [00:48<01:25,  8.49it/s] 25%|██▌       | 242/966 [00:49<01:25,  8.47it/s] 25%|██▌       | 243/966 [00:49<01:25,  8.46it/s] 25%|██▌       | 244/966 [00:49<01:25,  8.45it/s] 25%|██▌       | 245/966 [00:49<01:25,  8.45it/s] 25%|██▌       | 246/966 [00:49<01:25,  8.46it/s] 26%|██▌       | 247/966 [00:49<01:24,  8.48it/s] 26%|██▌       | 248/966 [00:49<01:24,  8.50it/s] 26%|██▌       | 249/966 [00:49<01:24,  8.52it/s] 26%|██▌       | 250/966 [00:50<01:23,  8.53it/s] 26%|██▌       | 251/966 [00:50<01:23,  8.53it/s] 26%|██▌       | 252/966 [00:50<01:23,  8.52it/s] 26%|██▌       | 253/966 [00:50<01:23,  8.53it/s] 26%|██▋       | 254/966 [00:50<01:23,  8.53it/s] 26%|██▋       | 255/966 [00:50<01:23,  8.53it/s] 27%|██▋       | 256/966 [00:50<01:23,  8.55it/s] 27%|██▋       | 257/966 [00:50<01:22,  8.55it/s] 27%|██▋       | 258/966 [00:50<01:22,  8.54it/s] 27%|██▋       | 259/966 [00:51<01:22,  8.53it/s] 27%|██▋       | 260/966 [00:51<01:22,  8.52it/s] 27%|██▋       | 261/966 [00:51<01:22,  8.52it/s] 27%|██▋       | 262/966 [00:51<01:22,  8.53it/s] 27%|██▋       | 263/966 [00:51<01:22,  8.54it/s] 27%|██▋       | 264/966 [00:51<01:22,  8.53it/s] 27%|██▋       | 265/966 [00:51<01:22,  8.52it/s] 28%|██▊       | 266/966 [00:51<01:22,  8.53it/s] 28%|██▊       | 267/966 [00:52<01:22,  8.52it/s] 28%|██▊       | 268/966 [00:52<01:21,  8.51it/s] 28%|██▊       | 269/966 [00:52<01:21,  8.51it/s] 28%|██▊       | 270/966 [00:52<01:21,  8.51it/s] 28%|██▊       | 271/966 [00:52<01:21,  8.50it/s] 28%|██▊       | 272/966 [00:52<01:21,  8.50it/s] 28%|██▊       | 273/966 [00:52<01:21,  8.48it/s] 28%|██▊       | 274/966 [00:52<01:21,  8.47it/s] 28%|██▊       | 275/966 [00:52<01:21,  8.48it/s] 29%|██▊       | 276/966 [00:53<01:21,  8.49it/s] 29%|██▊       | 277/966 [00:53<01:21,  8.50it/s] 29%|██▉       | 278/966 [00:53<01:20,  8.51it/s] 29%|██▉       | 279/966 [00:53<01:20,  8.52it/s] 29%|██▉       | 280/966 [00:53<01:20,  8.52it/s] 29%|██▉       | 281/966 [00:53<01:20,  8.51it/s] 29%|██▉       | 282/966 [00:53<01:20,  8.51it/s] 29%|██▉       | 283/966 [00:53<01:20,  8.51it/s] 29%|██▉       | 284/966 [00:54<01:20,  8.50it/s] 30%|██▉       | 285/966 [00:54<01:20,  8.50it/s] 30%|██▉       | 286/966 [00:54<01:20,  8.48it/s] 30%|██▉       | 287/966 [00:54<01:20,  8.47it/s] 30%|██▉       | 288/966 [00:54<01:19,  8.50it/s] 30%|██▉       | 289/966 [00:54<01:19,  8.51it/s] 30%|███       | 290/966 [00:54<01:19,  8.53it/s] 30%|███       | 291/966 [00:54<01:19,  8.52it/s] 30%|███       | 292/966 [00:54<01:19,  8.53it/s] 30%|███       | 293/966 [00:55<01:18,  8.52it/s] 30%|███       | 294/966 [00:55<01:18,  8.53it/s] 31%|███       | 295/966 [00:55<01:18,  8.54it/s] 31%|███       | 296/966 [00:55<01:18,  8.55it/s] 31%|███       | 297/966 [00:55<01:18,  8.55it/s] 31%|███       | 298/966 [00:55<01:18,  8.55it/s] 31%|███       | 299/966 [00:55<01:18,  8.55it/s] 31%|███       | 300/966 [00:55<01:18,  8.54it/s] 31%|███       | 301/966 [00:56<01:17,  8.53it/s] 31%|███▏      | 302/966 [00:56<01:17,  8.53it/s] 31%|███▏      | 303/966 [00:56<01:17,  8.52it/s] 31%|███▏      | 304/966 [00:56<01:17,  8.51it/s] 32%|███▏      | 305/966 [00:56<01:17,  8.50it/s] 32%|███▏      | 306/966 [00:56<01:17,  8.49it/s] 32%|███▏      | 307/966 [00:56<01:17,  8.49it/s] 32%|███▏      | 308/966 [00:56<01:17,  8.51it/s] 32%|███▏      | 309/966 [00:56<01:17,  8.52it/s] 32%|███▏      | 310/966 [00:57<01:17,  8.52it/s] 32%|███▏      | 311/966 [00:57<01:16,  8.52it/s] 32%|███▏      | 312/966 [00:57<01:16,  8.53it/s] 32%|███▏      | 313/966 [00:57<01:16,  8.50it/s] 33%|███▎      | 314/966 [00:57<01:16,  8.48it/s] 33%|███▎      | 315/966 [00:57<01:16,  8.47it/s] 33%|███▎      | 316/966 [00:57<01:16,  8.47it/s] 33%|███▎      | 317/966 [00:57<01:16,  8.48it/s] 33%|███▎      | 318/966 [00:58<01:16,  8.48it/s] 33%|███▎      | 319/966 [00:58<01:16,  8.49it/s] 33%|███▎      | 320/966 [00:58<01:16,  8.49it/s] 33%|███▎      | 321/966 [00:58<01:16,  8.48it/s] 33%|███▎      | 322/966 [00:58<01:15,  8.49it/s] 33%|███▎      | 323/966 [00:58<01:15,  8.49it/s] 34%|███▎      | 324/966 [00:58<01:15,  8.49it/s] 34%|███▎      | 325/966 [00:58<01:15,  8.50it/s] 34%|███▎      | 326/966 [00:58<01:15,  8.52it/s] 34%|███▍      | 327/966 [00:59<01:14,  8.53it/s] 34%|███▍      | 328/966 [00:59<01:15,  8.50it/s] 34%|███▍      | 329/966 [00:59<01:15,  8.49it/s] 34%|███▍      | 330/966 [00:59<01:15,  8.48it/s] 34%|███▍      | 331/966 [00:59<01:14,  8.50it/s] 34%|███▍      | 332/966 [00:59<01:14,  8.52it/s] 34%|███▍      | 333/966 [00:59<01:14,  8.54it/s] 35%|███▍      | 334/966 [00:59<01:14,  8.52it/s] 35%|███▍      | 335/966 [01:00<01:14,  8.52it/s] 35%|███▍      | 336/966 [01:00<01:13,  8.52it/s] 35%|███▍      | 337/966 [01:00<01:13,  8.52it/s] 35%|███▍      | 338/966 [01:00<01:13,  8.55it/s] 35%|███▌      | 339/966 [01:00<01:13,  8.54it/s] 35%|███▌      | 340/966 [01:00<01:13,  8.53it/s] 35%|███▌      | 341/966 [01:00<01:13,  8.52it/s] 35%|███▌      | 342/966 [01:00<01:13,  8.51it/s] 36%|███▌      | 343/966 [01:00<01:13,  8.49it/s] 36%|███▌      | 344/966 [01:01<01:13,  8.50it/s] 36%|███▌      | 345/966 [01:01<01:13,  8.50it/s] 36%|███▌      | 346/966 [01:01<01:12,  8.51it/s] 36%|███▌      | 347/966 [01:01<01:12,  8.51it/s] 36%|███▌      | 348/966 [01:01<01:12,  8.51it/s] 36%|███▌      | 349/966 [01:01<01:12,  8.51it/s] 36%|███▌      | 350/966 [01:01<01:12,  8.51it/s] 36%|███▋      | 351/966 [01:01<01:12,  8.50it/s] 36%|███▋      | 352/966 [01:02<01:12,  8.48it/s] 37%|███▋      | 353/966 [01:02<01:12,  8.49it/s] 37%|███▋      | 354/966 [01:02<01:12,  8.50it/s] 37%|███▋      | 355/966 [01:02<01:11,  8.51it/s] 37%|███▋      | 356/966 [01:02<01:11,  8.52it/s] 37%|███▋      | 357/966 [01:02<01:11,  8.50it/s] 37%|███▋      | 358/966 [01:02<01:11,  8.48it/s] 37%|███▋      | 359/966 [01:02<01:11,  8.46it/s] 37%|███▋      | 360/966 [01:02<01:11,  8.45it/s] 37%|███▋      | 361/966 [01:03<01:11,  8.46it/s] 37%|███▋      | 362/966 [01:03<01:11,  8.47it/s] 38%|███▊      | 363/966 [01:03<01:11,  8.48it/s] 38%|███▊      | 364/966 [01:03<01:11,  8.47it/s] 38%|███▊      | 365/966 [01:03<01:11,  8.46it/s] 38%|███▊      | 366/966 [01:03<01:10,  8.45it/s] 38%|███▊      | 367/966 [01:03<01:10,  8.46it/s] 38%|███▊      | 368/966 [01:03<01:10,  8.47it/s] 38%|███▊      | 369/966 [01:04<01:10,  8.47it/s] 38%|███▊      | 370/966 [01:04<01:10,  8.48it/s] 38%|███▊      | 371/966 [01:04<01:10,  8.48it/s] 39%|███▊      | 372/966 [01:04<01:09,  8.49it/s] 39%|███▊      | 373/966 [01:04<01:09,  8.51it/s] 39%|███▊      | 374/966 [01:04<01:09,  8.50it/s] 39%|███▉      | 375/966 [01:04<01:09,  8.51it/s] 39%|███▉      | 376/966 [01:04<01:09,  8.50it/s] 39%|███▉      | 377/966 [01:04<01:09,  8.51it/s] 39%|███▉      | 378/966 [01:05<01:09,  8.51it/s] 39%|███▉      | 379/966 [01:05<01:08,  8.51it/s] 39%|███▉      | 380/966 [01:05<01:08,  8.54it/s] 39%|███▉      | 381/966 [01:05<01:08,  8.54it/s] 40%|███▉      | 382/966 [01:05<01:08,  8.53it/s] 40%|███▉      | 383/966 [01:05<01:08,  8.52it/s] 40%|███▉      | 384/966 [01:05<01:08,  8.49it/s] 40%|███▉      | 385/966 [01:05<01:08,  8.49it/s] 40%|███▉      | 386/966 [01:06<01:08,  8.50it/s] 40%|████      | 387/966 [01:06<01:08,  8.50it/s] 40%|████      | 388/966 [01:06<01:08,  8.49it/s] 40%|████      | 389/966 [01:06<01:08,  8.48it/s] 40%|████      | 390/966 [01:06<01:07,  8.49it/s] 40%|████      | 391/966 [01:06<01:07,  8.50it/s] 41%|████      | 392/966 [01:06<01:07,  8.49it/s] 41%|████      | 393/966 [01:06<01:07,  8.48it/s] 41%|████      | 394/966 [01:06<01:07,  8.48it/s] 41%|████      | 395/966 [01:07<01:07,  8.48it/s] 41%|████      | 396/966 [01:07<01:07,  8.47it/s] 41%|████      | 397/966 [01:07<01:07,  8.46it/s] 41%|████      | 398/966 [01:07<01:07,  8.45it/s] 41%|████▏     | 399/966 [01:07<01:07,  8.45it/s] 41%|████▏     | 400/966 [01:07<01:07,  8.44it/s] 42%|████▏     | 401/966 [01:07<01:06,  8.44it/s] 42%|████▏     | 402/966 [01:07<01:06,  8.43it/s] 42%|████▏     | 403/966 [01:08<01:06,  8.43it/s] 42%|████▏     | 404/966 [01:08<01:06,  8.45it/s] 42%|████▏     | 405/966 [01:08<01:06,  8.44it/s] 42%|████▏     | 406/966 [01:08<01:06,  8.45it/s] 42%|████▏     | 407/966 [01:08<01:05,  8.47it/s] 42%|████▏     | 408/966 [01:08<01:05,  8.47it/s] 42%|████▏     | 409/966 [01:08<01:05,  8.49it/s] 42%|████▏     | 410/966 [01:08<01:05,  8.50it/s] 43%|████▎     | 411/966 [01:08<01:05,  8.49it/s] 43%|████▎     | 412/966 [01:09<01:05,  8.49it/s] 43%|████▎     | 413/966 [01:09<01:05,  8.49it/s] 43%|████▎     | 414/966 [01:09<01:04,  8.50it/s] 43%|████▎     | 415/966 [01:09<01:04,  8.51it/s] 43%|████▎     | 416/966 [01:09<01:04,  8.51it/s] 43%|████▎     | 417/966 [01:09<01:04,  8.50it/s] 43%|████▎     | 418/966 [01:09<01:04,  8.49it/s] 43%|████▎     | 419/966 [01:09<01:04,  8.49it/s] 43%|████▎     | 420/966 [01:10<01:04,  8.49it/s] 44%|████▎     | 421/966 [01:10<01:04,  8.50it/s] 44%|████▎     | 422/966 [01:10<01:03,  8.52it/s] 44%|████▍     | 423/966 [01:10<01:03,  8.51it/s] 44%|████▍     | 424/966 [01:10<01:03,  8.52it/s] 44%|████▍     | 425/966 [01:10<01:03,  8.51it/s] 44%|████▍     | 426/966 [01:10<01:03,  8.50it/s] 44%|████▍     | 427/966 [01:10<01:03,  8.50it/s] 44%|████▍     | 428/966 [01:10<01:03,  8.52it/s] 44%|████▍     | 429/966 [01:11<01:03,  8.52it/s] 45%|████▍     | 430/966 [01:11<01:02,  8.52it/s] 45%|████▍     | 431/966 [01:11<01:02,  8.52it/s] 45%|████▍     | 432/966 [01:11<01:02,  8.51it/s] 45%|████▍     | 433/966 [01:11<01:02,  8.48it/s] 45%|████▍     | 434/966 [01:11<01:02,  8.47it/s] 45%|████▌     | 435/966 [01:11<01:02,  8.46it/s] 45%|████▌     | 436/966 [01:11<01:02,  8.45it/s] 45%|████▌     | 437/966 [01:12<01:02,  8.46it/s] 45%|████▌     | 438/966 [01:12<01:02,  8.46it/s] 45%|████▌     | 439/966 [01:12<01:02,  8.47it/s] 46%|████▌     | 440/966 [01:12<01:02,  8.46it/s] 46%|████▌     | 441/966 [01:12<01:02,  8.46it/s] 46%|████▌     | 442/966 [01:12<01:01,  8.47it/s] 46%|████▌     | 443/966 [01:12<01:01,  8.47it/s] 46%|████▌     | 444/966 [01:12<01:01,  8.48it/s] 46%|████▌     | 445/966 [01:12<01:01,  8.49it/s] 46%|████▌     | 446/966 [01:13<01:01,  8.50it/s] 46%|████▋     | 447/966 [01:13<01:01,  8.51it/s] 46%|████▋     | 448/966 [01:13<01:00,  8.51it/s] 46%|████▋     | 449/966 [01:13<01:00,  8.51it/s] 47%|████▋     | 450/966 [01:13<01:00,  8.51it/s] 47%|████▋     | 451/966 [01:13<01:00,  8.51it/s] 47%|████▋     | 452/966 [01:13<01:00,  8.50it/s] 47%|████▋     | 453/966 [01:13<01:00,  8.50it/s] 47%|████▋     | 454/966 [01:14<01:00,  8.49it/s] 47%|████▋     | 455/966 [01:14<01:00,  8.48it/s] 47%|████▋     | 456/966 [01:14<01:00,  8.48it/s] 47%|████▋     | 457/966 [01:14<00:59,  8.50it/s] 47%|████▋     | 458/966 [01:14<00:59,  8.51it/s] 48%|████▊     | 459/966 [01:14<00:59,  8.50it/s] 48%|████▊     | 460/966 [01:14<00:59,  8.50it/s] 48%|████▊     | 461/966 [01:14<00:59,  8.50it/s] 48%|████▊     | 462/966 [01:14<00:59,  8.51it/s] 48%|████▊     | 463/966 [01:15<00:58,  8.53it/s] 48%|████▊     | 464/966 [01:15<00:58,  8.54it/s] 48%|████▊     | 465/966 [01:15<00:58,  8.52it/s] 48%|████▊     | 466/966 [01:15<00:58,  8.51it/s] 48%|████▊     | 467/966 [01:15<00:58,  8.51it/s] 48%|████▊     | 468/966 [01:15<00:58,  8.51it/s] 49%|████▊     | 469/966 [01:15<00:58,  8.52it/s] 49%|████▊     | 470/966 [01:15<00:58,  8.53it/s] 49%|████▉     | 471/966 [01:16<00:58,  8.53it/s] 49%|████▉     | 472/966 [01:16<00:57,  8.52it/s] 49%|████▉     | 473/966 [01:16<00:57,  8.51it/s] 49%|████▉     | 474/966 [01:16<00:57,  8.50it/s] 49%|████▉     | 475/966 [01:16<00:57,  8.48it/s] 49%|████▉     | 476/966 [01:16<00:57,  8.46it/s] 49%|████▉     | 477/966 [01:16<00:57,  8.45it/s] 49%|████▉     | 478/966 [01:16<00:57,  8.45it/s] 50%|████▉     | 479/966 [01:16<00:57,  8.44it/s] 50%|████▉     | 480/966 [01:17<00:57,  8.45it/s] 50%|████▉     | 481/966 [01:17<00:57,  8.47it/s] 50%|████▉     | 482/966 [01:17<00:57,  8.48it/s] 50%|█████     | 483/966 [01:17<00:56,  8.49it/s] 50%|█████     | 484/966 [01:17<00:56,  8.48it/s] 50%|█████     | 485/966 [01:17<00:56,  8.48it/s] 50%|█████     | 486/966 [01:17<00:56,  8.46it/s] 50%|█████     | 487/966 [01:17<00:56,  8.46it/s] 51%|█████     | 488/966 [01:18<00:56,  8.47it/s] 51%|█████     | 489/966 [01:18<00:56,  8.48it/s] 51%|█████     | 490/966 [01:18<00:56,  8.49it/s] 51%|█████     | 491/966 [01:18<00:56,  8.48it/s] 51%|█████     | 492/966 [01:18<00:55,  8.50it/s] 51%|█████     | 493/966 [01:18<00:55,  8.49it/s] 51%|█████     | 494/966 [01:18<00:55,  8.48it/s] 51%|█████     | 495/966 [01:18<00:55,  8.47it/s] 51%|█████▏    | 496/966 [01:18<00:55,  8.48it/s] 51%|█████▏    | 497/966 [01:19<00:55,  8.48it/s] 52%|█████▏    | 498/966 [01:19<00:55,  8.46it/s] 52%|█████▏    | 499/966 [01:19<00:55,  8.47it/s] 52%|█████▏    | 500/966 [01:19<00:55,  8.46it/s] 52%|█████▏    | 501/966 [01:19<00:54,  8.46it/s] 52%|█████▏    | 502/966 [01:19<00:54,  8.47it/s] 52%|█████▏    | 503/966 [01:19<00:54,  8.49it/s] 52%|█████▏    | 504/966 [01:19<00:54,  8.51it/s] 52%|█████▏    | 505/966 [01:20<00:54,  8.53it/s] 52%|█████▏    | 506/966 [01:20<00:53,  8.54it/s] 52%|█████▏    | 507/966 [01:20<00:53,  8.53it/s] 53%|█████▎    | 508/966 [01:20<00:53,  8.51it/s] 53%|█████▎    | 509/966 [01:20<00:53,  8.51it/s] 53%|█████▎    | 510/966 [01:20<00:53,  8.50it/s] 53%|█████▎    | 511/966 [01:20<00:53,  8.50it/s] 53%|█████▎    | 512/966 [01:20<00:53,  8.51it/s] 53%|█████▎    | 513/966 [01:20<00:53,  8.51it/s] 53%|█████▎    | 514/966 [01:21<00:53,  8.51it/s] 53%|█████▎    | 515/966 [01:21<00:53,  8.51it/s] 53%|█████▎    | 516/966 [01:21<00:52,  8.51it/s] 54%|█████▎    | 517/966 [01:21<00:52,  8.50it/s] 54%|█████▎    | 518/966 [01:21<00:52,  8.49it/s] 54%|█████▎    | 519/966 [01:21<00:52,  8.47it/s] 54%|█████▍    | 520/966 [01:21<00:52,  8.46it/s] 54%|█████▍    | 521/966 [01:21<00:52,  8.45it/s] 54%|█████▍    | 522/966 [01:22<00:52,  8.46it/s] 54%|█████▍    | 523/966 [01:22<00:52,  8.48it/s] 54%|█████▍    | 524/966 [01:22<00:52,  8.48it/s] 54%|█████▍    | 525/966 [01:22<00:52,  8.48it/s] 54%|█████▍    | 526/966 [01:22<00:51,  8.50it/s] 55%|█████▍    | 527/966 [01:22<00:51,  8.49it/s] 55%|█████▍    | 528/966 [01:22<00:51,  8.49it/s] 55%|█████▍    | 529/966 [01:22<00:51,  8.47it/s] 55%|█████▍    | 530/966 [01:22<00:51,  8.47it/s] 55%|█████▍    | 531/966 [01:23<00:51,  8.49it/s] 55%|█████▌    | 532/966 [01:23<00:51,  8.49it/s] 55%|█████▌    | 533/966 [01:23<00:51,  8.48it/s] 55%|█████▌    | 534/966 [01:23<00:50,  8.49it/s] 55%|█████▌    | 535/966 [01:23<00:50,  8.50it/s] 55%|█████▌    | 536/966 [01:23<00:50,  8.50it/s] 56%|█████▌    | 537/966 [01:23<00:50,  8.50it/s] 56%|█████▌    | 538/966 [01:23<00:50,  8.50it/s] 56%|█████▌    | 539/966 [01:24<00:50,  8.49it/s] 56%|█████▌    | 540/966 [01:24<00:50,  8.47it/s] 56%|█████▌    | 541/966 [01:24<00:50,  8.48it/s] 56%|█████▌    | 542/966 [01:24<00:50,  8.46it/s] 56%|█████▌    | 543/966 [01:24<00:50,  8.45it/s] 56%|█████▋    | 544/966 [01:24<00:49,  8.45it/s] 56%|█████▋    | 545/966 [01:24<00:49,  8.45it/s] 57%|█████▋    | 546/966 [01:24<00:49,  8.45it/s] 57%|█████▋    | 547/966 [01:24<00:49,  8.47it/s] 57%|█████▋    | 548/966 [01:25<00:49,  8.48it/s] 57%|█████▋    | 549/966 [01:25<00:49,  8.48it/s] 57%|█████▋    | 550/966 [01:25<00:49,  8.47it/s] 57%|█████▋    | 551/966 [01:25<00:49,  8.46it/s] 57%|█████▋    | 552/966 [01:25<00:48,  8.46it/s] 57%|█████▋    | 553/966 [01:25<00:48,  8.47it/s] 57%|█████▋    | 554/966 [01:25<00:48,  8.48it/s] 57%|█████▋    | 555/966 [01:25<00:48,  8.49it/s] 58%|█████▊    | 556/966 [01:26<00:48,  8.50it/s] 58%|█████▊    | 557/966 [01:26<00:48,  8.50it/s] 58%|█████▊    | 558/966 [01:26<00:47,  8.50it/s] 58%|█████▊    | 559/966 [01:26<00:47,  8.50it/s] 58%|█████▊    | 560/966 [01:26<00:47,  8.49it/s] 58%|█████▊    | 561/966 [01:26<00:47,  8.47it/s] 58%|█████▊    | 562/966 [01:26<00:47,  8.45it/s] 58%|█████▊    | 563/966 [01:26<00:47,  8.46it/s] 58%|█████▊    | 564/966 [01:26<00:47,  8.47it/s] 58%|█████▊    | 565/966 [01:27<00:47,  8.47it/s] 59%|█████▊    | 566/966 [01:27<00:47,  8.49it/s] 59%|█████▊    | 567/966 [01:27<00:47,  8.49it/s] 59%|█████▉    | 568/966 [01:27<00:46,  8.49it/s] 59%|█████▉    | 569/966 [01:27<00:46,  8.48it/s] 59%|█████▉    | 570/966 [01:27<00:46,  8.49it/s] 59%|█████▉    | 571/966 [01:27<00:46,  8.49it/s] 59%|█████▉    | 572/966 [01:27<00:46,  8.47it/s] 59%|█████▉    | 573/966 [01:28<00:46,  8.47it/s] 59%|█████▉    | 574/966 [01:28<00:46,  8.47it/s] 60%|█████▉    | 575/966 [01:28<00:46,  8.48it/s] 60%|█████▉    | 576/966 [01:28<00:45,  8.49it/s] 60%|█████▉    | 577/966 [01:28<00:45,  8.49it/s] 60%|█████▉    | 578/966 [01:28<00:45,  8.49it/s] 60%|█████▉    | 579/966 [01:28<00:45,  8.50it/s] 60%|██████    | 580/966 [01:28<00:45,  8.49it/s] 60%|██████    | 581/966 [01:28<00:45,  8.47it/s] 60%|██████    | 582/966 [01:29<00:45,  8.48it/s] 60%|██████    | 583/966 [01:29<00:45,  8.48it/s] 60%|██████    | 584/966 [01:29<00:45,  8.48it/s] 61%|██████    | 585/966 [01:29<00:45,  8.47it/s] 61%|██████    | 586/966 [01:29<00:44,  8.47it/s] 61%|██████    | 587/966 [01:29<00:44,  8.45it/s] 61%|██████    | 588/966 [01:29<00:44,  8.44it/s] 61%|██████    | 589/966 [01:29<00:44,  8.46it/s] 61%|██████    | 590/966 [01:30<00:44,  8.48it/s] 61%|██████    | 591/966 [01:30<00:44,  8.49it/s] 61%|██████▏   | 592/966 [01:30<00:43,  8.51it/s] 61%|██████▏   | 593/966 [01:30<00:43,  8.49it/s] 61%|██████▏   | 594/966 [01:30<00:43,  8.49it/s] 62%|██████▏   | 595/966 [01:30<00:43,  8.49it/s] 62%|██████▏   | 596/966 [01:30<00:43,  8.51it/s] 62%|██████▏   | 597/966 [01:30<00:43,  8.50it/s] 62%|██████▏   | 598/966 [01:31<00:43,  8.48it/s] 62%|██████▏   | 599/966 [01:31<00:43,  8.47it/s] 62%|██████▏   | 600/966 [01:31<00:43,  8.47it/s] 62%|██████▏   | 601/966 [01:31<00:43,  8.48it/s] 62%|██████▏   | 602/966 [01:31<00:42,  8.47it/s] 62%|██████▏   | 603/966 [01:31<00:42,  8.45it/s] 63%|██████▎   | 604/966 [01:31<00:42,  8.45it/s] 63%|██████▎   | 605/966 [01:31<00:42,  8.44it/s] 63%|██████▎   | 606/966 [01:31<00:42,  8.45it/s] 63%|██████▎   | 607/966 [01:32<00:42,  8.45it/s] 63%|██████▎   | 608/966 [01:32<00:42,  8.46it/s] 63%|██████▎   | 609/966 [01:32<00:42,  8.47it/s] 63%|██████▎   | 610/966 [01:32<00:42,  8.47it/s] 63%|██████▎   | 611/966 [01:32<00:41,  8.46it/s] 63%|██████▎   | 612/966 [01:32<00:41,  8.45it/s] 63%|██████▎   | 613/966 [01:32<00:41,  8.44it/s] 64%|██████▎   | 614/966 [01:32<00:41,  8.44it/s] 64%|██████▎   | 615/966 [01:33<00:41,  8.45it/s] 64%|██████▍   | 616/966 [01:33<00:41,  8.44it/s] 64%|██████▍   | 617/966 [01:33<00:41,  8.44it/s] 64%|██████▍   | 618/966 [01:33<00:41,  8.46it/s] 64%|██████▍   | 619/966 [01:33<00:40,  8.47it/s] 64%|██████▍   | 620/966 [01:33<00:40,  8.48it/s] 64%|██████▍   | 621/966 [01:33<00:40,  8.47it/s] 64%|██████▍   | 622/966 [01:33<00:40,  8.46it/s] 64%|██████▍   | 623/966 [01:33<00:40,  8.46it/s] 65%|██████▍   | 624/966 [01:34<00:40,  8.47it/s] 65%|██████▍   | 625/966 [01:34<00:40,  8.49it/s] 65%|██████▍   | 626/966 [01:34<00:40,  8.50it/s] 65%|██████▍   | 627/966 [01:34<00:39,  8.50it/s] 65%|██████▌   | 628/966 [01:34<00:39,  8.49it/s] 65%|██████▌   | 629/966 [01:34<00:39,  8.47it/s] 65%|██████▌   | 630/966 [01:34<00:39,  8.47it/s] 65%|██████▌   | 631/966 [01:34<00:39,  8.48it/s] 65%|██████▌   | 632/966 [01:35<00:39,  8.50it/s] 66%|██████▌   | 633/966 [01:35<00:39,  8.49it/s] 66%|██████▌   | 634/966 [01:35<00:39,  8.49it/s] 66%|██████▌   | 635/966 [01:35<00:38,  8.49it/s] 66%|██████▌   | 636/966 [01:35<00:38,  8.49it/s] 66%|██████▌   | 637/966 [01:35<00:38,  8.49it/s] 66%|██████▌   | 638/966 [01:35<00:38,  8.49it/s] 66%|██████▌   | 639/966 [01:35<00:38,  8.49it/s] 66%|██████▋   | 640/966 [01:35<00:38,  8.50it/s] 66%|██████▋   | 641/966 [01:36<00:38,  8.50it/s] 66%|██████▋   | 642/966 [01:36<00:38,  8.49it/s] 67%|██████▋   | 643/966 [01:36<00:38,  8.49it/s] 67%|██████▋   | 644/966 [01:36<00:37,  8.47it/s] 67%|██████▋   | 645/966 [01:36<00:37,  8.49it/s] 67%|██████▋   | 646/966 [01:36<00:37,  8.48it/s] 67%|██████▋   | 647/966 [01:36<00:37,  8.46it/s] 67%|██████▋   | 648/966 [01:36<00:37,  8.45it/s] 67%|██████▋   | 649/966 [01:37<00:37,  8.44it/s] 67%|██████▋   | 650/966 [01:37<00:37,  8.44it/s] 67%|██████▋   | 651/966 [01:37<00:37,  8.45it/s] 67%|██████▋   | 652/966 [01:37<00:37,  8.44it/s] 68%|██████▊   | 653/966 [01:37<00:37,  8.44it/s] 68%|██████▊   | 654/966 [01:37<00:36,  8.44it/s] 68%|██████▊   | 655/966 [01:37<00:36,  8.43it/s] 68%|██████▊   | 656/966 [01:37<00:36,  8.43it/s] 68%|██████▊   | 657/966 [01:37<00:36,  8.43it/s] 68%|██████▊   | 658/966 [01:38<00:36,  8.45it/s] 68%|██████▊   | 659/966 [01:38<00:36,  8.45it/s] 68%|██████▊   | 660/966 [01:38<00:36,  8.45it/s] 68%|██████▊   | 661/966 [01:38<00:36,  8.44it/s] 69%|██████▊   | 662/966 [01:38<00:36,  8.44it/s] 69%|██████▊   | 663/966 [01:38<00:35,  8.43it/s] 69%|██████▊   | 664/966 [01:38<00:35,  8.43it/s] 69%|██████▉   | 665/966 [01:38<00:35,  8.42it/s] 69%|██████▉   | 666/966 [01:39<00:35,  8.44it/s] 69%|██████▉   | 667/966 [01:39<00:35,  8.46it/s] 69%|██████▉   | 668/966 [01:39<00:35,  8.48it/s] 69%|██████▉   | 669/966 [01:39<00:35,  8.47it/s] 69%|██████▉   | 670/966 [01:39<00:34,  8.47it/s] 69%|██████▉   | 671/966 [01:39<00:34,  8.48it/s] 70%|██████▉   | 672/966 [01:39<00:34,  8.48it/s] 70%|██████▉   | 673/966 [01:39<00:34,  8.49it/s] 70%|██████▉   | 674/966 [01:39<00:34,  8.49it/s] 70%|██████▉   | 675/966 [01:40<00:34,  8.47it/s] 70%|██████▉   | 676/966 [01:40<00:34,  8.46it/s] 70%|███████   | 677/966 [01:40<00:34,  8.45it/s] 70%|███████   | 678/966 [01:40<00:34,  8.44it/s] 70%|███████   | 679/966 [01:40<00:33,  8.46it/s] 70%|███████   | 680/966 [01:40<00:33,  8.49it/s] 70%|███████   | 681/966 [01:40<00:33,  8.49it/s] 71%|███████   | 682/966 [01:40<00:33,  8.49it/s] 71%|███████   | 683/966 [01:41<00:33,  8.50it/s] 71%|███████   | 684/966 [01:41<00:33,  8.50it/s] 71%|███████   | 685/966 [01:41<00:33,  8.48it/s] 71%|███████   | 686/966 [01:41<00:33,  8.48it/s] 71%|███████   | 687/966 [01:41<00:32,  8.47it/s] 71%|███████   | 688/966 [01:41<00:32,  8.48it/s] 71%|███████▏  | 689/966 [01:41<00:32,  8.47it/s] 71%|███████▏  | 690/966 [01:41<00:32,  8.46it/s] 72%|███████▏  | 691/966 [01:41<00:32,  8.45it/s] 72%|███████▏  | 692/966 [01:42<00:32,  8.43it/s] 72%|███████▏  | 693/966 [01:42<00:32,  8.43it/s] 72%|███████▏  | 694/966 [01:42<00:32,  8.42it/s] 72%|███████▏  | 695/966 [01:42<00:32,  8.42it/s] 72%|███████▏  | 696/966 [01:42<00:32,  8.43it/s] 72%|███████▏  | 697/966 [01:42<00:31,  8.44it/s] 72%|███████▏  | 698/966 [01:42<00:31,  8.45it/s] 72%|███████▏  | 699/966 [01:42<00:31,  8.44it/s] 72%|███████▏  | 700/966 [01:43<00:31,  8.43it/s] 73%|███████▎  | 701/966 [01:43<00:31,  8.43it/s] 73%|███████▎  | 702/966 [01:43<00:31,  8.45it/s] 73%|███████▎  | 703/966 [01:43<00:31,  8.46it/s] 73%|███████▎  | 704/966 [01:43<00:30,  8.46it/s] 73%|███████▎  | 705/966 [01:43<00:30,  8.45it/s] 73%|███████▎  | 706/966 [01:43<00:30,  8.45it/s] 73%|███████▎  | 707/966 [01:43<00:30,  8.44it/s] 73%|███████▎  | 708/966 [01:44<00:30,  8.44it/s] 73%|███████▎  | 709/966 [01:44<00:30,  8.47it/s] 73%|███████▎  | 710/966 [01:44<00:30,  8.47it/s] 74%|███████▎  | 711/966 [01:44<00:30,  8.48it/s] 74%|███████▎  | 712/966 [01:44<00:29,  8.49it/s] 74%|███████▍  | 713/966 [01:44<00:29,  8.47it/s] 74%|███████▍  | 714/966 [01:44<00:29,  8.46it/s] 74%|███████▍  | 715/966 [01:44<00:29,  8.47it/s] 74%|███████▍  | 716/966 [01:44<00:29,  8.47it/s] 74%|███████▍  | 717/966 [01:45<00:29,  8.48it/s] 74%|███████▍  | 718/966 [01:45<00:29,  8.47it/s] 74%|███████▍  | 719/966 [01:45<00:29,  8.48it/s] 75%|███████▍  | 720/966 [01:45<00:29,  8.47it/s] 75%|███████▍  | 721/966 [01:45<00:28,  8.46it/s] 75%|███████▍  | 722/966 [01:45<00:28,  8.48it/s] 75%|███████▍  | 723/966 [01:45<00:28,  8.49it/s] 75%|███████▍  | 724/966 [01:45<00:28,  8.49it/s] 75%|███████▌  | 725/966 [01:46<00:28,  8.47it/s] 75%|███████▌  | 726/966 [01:46<00:28,  8.47it/s] 75%|███████▌  | 727/966 [01:46<00:28,  8.47it/s] 75%|███████▌  | 728/966 [01:46<00:28,  8.45it/s] 75%|███████▌  | 729/966 [01:46<00:28,  8.44it/s] 76%|███████▌  | 730/966 [01:46<00:27,  8.45it/s] 76%|███████▌  | 731/966 [01:46<00:27,  8.44it/s] 76%|███████▌  | 732/966 [01:46<00:27,  8.47it/s] 76%|███████▌  | 733/966 [01:46<00:27,  8.48it/s] 76%|███████▌  | 734/966 [01:47<00:27,  8.46it/s] 76%|███████▌  | 735/966 [01:47<00:27,  8.47it/s] 76%|███████▌  | 736/966 [01:47<00:27,  8.46it/s] 76%|███████▋  | 737/966 [01:47<00:27,  8.45it/s] 76%|███████▋  | 738/966 [01:47<00:27,  8.44it/s] 77%|███████▋  | 739/966 [01:47<00:26,  8.45it/s] 77%|███████▋  | 740/966 [01:47<00:26,  8.45it/s] 77%|███████▋  | 741/966 [01:47<00:26,  8.44it/s] 77%|███████▋  | 742/966 [01:48<00:26,  8.44it/s] 77%|███████▋  | 743/966 [01:48<00:26,  8.45it/s] 77%|███████▋  | 744/966 [01:48<00:26,  8.45it/s] 77%|███████▋  | 745/966 [01:48<00:26,  8.46it/s] 77%|███████▋  | 746/966 [01:48<00:26,  8.46it/s] 77%|███████▋  | 747/966 [01:48<00:25,  8.44it/s] 77%|███████▋  | 748/966 [01:48<00:25,  8.44it/s] 78%|███████▊  | 749/966 [01:48<00:25,  8.44it/s] 78%|███████▊  | 750/966 [01:48<00:25,  8.44it/s] 78%|███████▊  | 751/966 [01:49<00:25,  8.46it/s] 78%|███████▊  | 752/966 [01:49<00:25,  8.47it/s] 78%|███████▊  | 753/966 [01:49<00:25,  8.47it/s] 78%|███████▊  | 754/966 [01:49<00:25,  8.46it/s] 78%|███████▊  | 755/966 [01:49<00:24,  8.47it/s] 78%|███████▊  | 756/966 [01:49<00:24,  8.49it/s] 78%|███████▊  | 757/966 [01:49<00:24,  8.49it/s] 78%|███████▊  | 758/966 [01:49<00:24,  8.49it/s] 79%|███████▊  | 759/966 [01:50<00:24,  8.49it/s] 79%|███████▊  | 760/966 [01:50<00:24,  8.47it/s] 79%|███████▉  | 761/966 [01:50<00:24,  8.46it/s] 79%|███████▉  | 762/966 [01:50<00:24,  8.45it/s] 79%|███████▉  | 763/966 [01:50<00:24,  8.45it/s] 79%|███████▉  | 764/966 [01:50<00:23,  8.46it/s] 79%|███████▉  | 765/966 [01:50<00:23,  8.46it/s] 79%|███████▉  | 766/966 [01:50<00:23,  8.45it/s] 79%|███████▉  | 767/966 [01:50<00:23,  8.44it/s] 80%|███████▉  | 768/966 [01:51<00:23,  8.46it/s] 80%|███████▉  | 769/966 [01:51<00:23,  8.47it/s] 80%|███████▉  | 770/966 [01:51<00:23,  8.48it/s] 80%|███████▉  | 771/966 [01:51<00:23,  8.47it/s] 80%|███████▉  | 772/966 [01:51<00:22,  8.47it/s] 80%|████████  | 773/966 [01:51<00:22,  8.47it/s] 80%|████████  | 774/966 [01:51<00:22,  8.47it/s] 80%|████████  | 775/966 [01:51<00:22,  8.47it/s] 80%|████████  | 776/966 [01:52<00:22,  8.48it/s] 80%|████████  | 777/966 [01:52<00:22,  8.48it/s] 81%|████████  | 778/966 [01:52<00:22,  8.46it/s] 81%|████████  | 779/966 [01:52<00:22,  8.45it/s] 81%|████████  | 780/966 [01:52<00:22,  8.45it/s] 81%|████████  | 781/966 [01:52<00:21,  8.44it/s] 81%|████████  | 782/966 [01:52<00:21,  8.45it/s] 81%|████████  | 783/966 [01:52<00:21,  8.44it/s] 81%|████████  | 784/966 [01:52<00:21,  8.44it/s] 81%|████████▏ | 785/966 [01:53<00:21,  8.44it/s] 81%|████████▏ | 786/966 [01:53<00:21,  8.44it/s] 81%|████████▏ | 787/966 [01:53<00:21,  8.45it/s] 82%|████████▏ | 788/966 [01:53<00:21,  8.47it/s] 82%|████████▏ | 789/966 [01:53<00:20,  8.46it/s] 82%|████████▏ | 790/966 [01:53<00:20,  8.47it/s] 82%|████████▏ | 791/966 [01:53<00:20,  8.48it/s] 82%|████████▏ | 792/966 [01:53<00:20,  8.47it/s] 82%|████████▏ | 793/966 [01:54<00:20,  8.48it/s] 82%|████████▏ | 794/966 [01:54<00:20,  8.48it/s] 82%|████████▏ | 795/966 [01:54<00:20,  8.48it/s] 82%|████████▏ | 796/966 [01:54<00:20,  8.48it/s] 83%|████████▎ | 797/966 [01:54<00:19,  8.46it/s] 83%|████████▎ | 798/966 [01:54<00:19,  8.46it/s] 83%|████████▎ | 799/966 [01:54<00:19,  8.48it/s] 83%|████████▎ | 800/966 [01:54<00:19,  8.49it/s] 83%|████████▎ | 801/966 [01:54<00:19,  8.47it/s] 83%|████████▎ | 802/966 [01:55<00:19,  8.45it/s] 83%|████████▎ | 803/966 [01:55<00:19,  8.44it/s] 83%|████████▎ | 804/966 [01:55<00:19,  8.45it/s] 83%|████████▎ | 805/966 [01:55<00:19,  8.47it/s] 83%|████████▎ | 806/966 [01:55<00:18,  8.47it/s] 84%|████████▎ | 807/966 [01:55<00:18,  8.49it/s] 84%|████████▎ | 808/966 [01:55<00:18,  8.47it/s] 84%|████████▎ | 809/966 [01:55<00:18,  8.46it/s] 84%|████████▍ | 810/966 [01:56<00:18,  8.47it/s] 84%|████████▍ | 811/966 [01:56<00:18,  8.46it/s] 84%|████████▍ | 812/966 [01:56<00:18,  8.45it/s] 84%|████████▍ | 813/966 [01:56<00:18,  8.44it/s] 84%|████████▍ | 814/966 [01:56<00:17,  8.45it/s] 84%|████████▍ | 815/966 [01:56<00:17,  8.45it/s] 84%|████████▍ | 816/966 [01:56<00:17,  8.45it/s] 85%|████████▍ | 817/966 [01:56<00:17,  8.44it/s] 85%|████████▍ | 818/966 [01:57<00:17,  8.43it/s] 85%|████████▍ | 819/966 [01:57<00:17,  8.45it/s] 85%|████████▍ | 820/966 [01:57<00:17,  8.45it/s] 85%|████████▍ | 821/966 [01:57<00:17,  8.45it/s] 85%|████████▌ | 822/966 [01:57<00:17,  8.46it/s] 85%|████████▌ | 823/966 [01:57<00:16,  8.45it/s] 85%|████████▌ | 824/966 [01:57<00:16,  8.45it/s] 85%|████████▌ | 825/966 [01:57<00:16,  8.44it/s] 86%|████████▌ | 826/966 [01:57<00:16,  8.45it/s] 86%|████████▌ | 827/966 [01:58<00:16,  8.46it/s] 86%|████████▌ | 828/966 [01:58<00:16,  8.47it/s] 86%|████████▌ | 829/966 [01:58<00:16,  8.46it/s] 86%|████████▌ | 830/966 [01:58<00:16,  8.46it/s] 86%|████████▌ | 831/966 [01:58<00:15,  8.46it/s] 86%|████████▌ | 832/966 [01:58<00:15,  8.47it/s] 86%|████████▌ | 833/966 [01:58<00:15,  8.47it/s] 86%|████████▋ | 834/966 [01:58<00:15,  8.48it/s] 86%|████████▋ | 835/966 [01:59<00:15,  8.49it/s] 87%|████████▋ | 836/966 [01:59<00:15,  8.49it/s] 87%|████████▋ | 837/966 [01:59<00:15,  8.48it/s] 87%|████████▋ | 838/966 [01:59<00:15,  8.46it/s] 87%|████████▋ | 839/966 [01:59<00:14,  8.48it/s] 87%|████████▋ | 840/966 [01:59<00:14,  8.48it/s] 87%|████████▋ | 841/966 [01:59<00:14,  8.49it/s] 87%|████████▋ | 842/966 [01:59<00:14,  8.49it/s] 87%|████████▋ | 843/966 [01:59<00:14,  8.49it/s] 87%|████████▋ | 844/966 [02:00<00:14,  8.48it/s] 87%|████████▋ | 845/966 [02:00<00:14,  8.48it/s] 88%|████████▊ | 846/966 [02:00<00:14,  8.47it/s] 88%|████████▊ | 847/966 [02:00<00:14,  8.47it/s] 88%|████████▊ | 848/966 [02:00<00:13,  8.49it/s] 88%|████████▊ | 849/966 [02:00<00:13,  8.49it/s] 88%|████████▊ | 850/966 [02:00<00:13,  8.47it/s] 88%|████████▊ | 851/966 [02:00<00:13,  8.46it/s] 88%|████████▊ | 852/966 [02:01<00:13,  8.45it/s] 88%|████████▊ | 853/966 [02:01<00:13,  8.46it/s] 88%|████████▊ | 854/966 [02:01<00:13,  8.47it/s] 89%|████████▊ | 855/966 [02:01<00:13,  8.47it/s] 89%|████████▊ | 856/966 [02:01<00:12,  8.47it/s] 89%|████████▊ | 857/966 [02:01<00:12,  8.47it/s] 89%|████████▉ | 858/966 [02:01<00:12,  8.47it/s] 89%|████████▉ | 859/966 [02:01<00:12,  8.47it/s] 89%|████████▉ | 860/966 [02:01<00:12,  8.46it/s] 89%|████████▉ | 861/966 [02:02<00:12,  8.46it/s] 89%|████████▉ | 862/966 [02:02<00:12,  8.46it/s] 89%|████████▉ | 863/966 [02:02<00:12,  8.45it/s] 89%|████████▉ | 864/966 [02:02<00:12,  8.44it/s] 90%|████████▉ | 865/966 [02:02<00:11,  8.43it/s] 90%|████████▉ | 866/966 [02:02<00:11,  8.44it/s] 90%|████████▉ | 867/966 [02:02<00:11,  8.45it/s] 90%|████████▉ | 868/966 [02:02<00:11,  8.44it/s] 90%|████████▉ | 869/966 [02:03<00:11,  8.43it/s] 90%|█████████ | 870/966 [02:03<00:11,  8.44it/s] 90%|█████████ | 871/966 [02:03<00:11,  8.44it/s] 90%|█████████ | 872/966 [02:03<00:11,  8.45it/s] 90%|█████████ | 873/966 [02:03<00:10,  8.46it/s] 90%|█████████ | 874/966 [02:03<00:10,  8.47it/s] 91%|█████████ | 875/966 [02:03<00:10,  8.47it/s] 91%|█████████ | 876/966 [02:03<00:10,  8.47it/s] 91%|█████████ | 877/966 [02:03<00:10,  8.48it/s] 91%|█████████ | 878/966 [02:04<00:10,  8.49it/s] 91%|█████████ | 879/966 [02:04<00:10,  8.49it/s] 91%|█████████ | 880/966 [02:04<00:10,  8.49it/s] 91%|█████████ | 881/966 [02:04<00:10,  8.47it/s] 91%|█████████▏| 882/966 [02:04<00:09,  8.48it/s] 91%|█████████▏| 883/966 [02:04<00:09,  8.48it/s] 92%|█████████▏| 884/966 [02:04<00:09,  8.49it/s] 92%|█████████▏| 885/966 [02:04<00:09,  8.49it/s] 92%|█████████▏| 886/966 [02:05<00:09,  8.49it/s] 92%|█████████▏| 887/966 [02:05<00:09,  8.46it/s] 92%|█████████▏| 888/966 [02:05<00:09,  8.45it/s] 92%|█████████▏| 889/966 [02:05<00:09,  8.46it/s] 92%|█████████▏| 890/966 [02:05<00:08,  8.47it/s] 92%|█████████▏| 891/966 [02:05<00:08,  8.46it/s] 92%|█████████▏| 892/966 [02:05<00:08,  8.47it/s] 92%|█████████▏| 893/966 [02:05<00:08,  8.47it/s] 93%|█████████▎| 894/966 [02:05<00:08,  8.48it/s] 93%|█████████▎| 895/966 [02:06<00:08,  8.47it/s] 93%|█████████▎| 896/966 [02:06<00:08,  8.45it/s] 93%|█████████▎| 897/966 [02:06<00:08,  8.45it/s] 93%|█████████▎| 898/966 [02:06<00:08,  8.44it/s] 93%|█████████▎| 899/966 [02:06<00:07,  8.45it/s] 93%|█████████▎| 900/966 [02:06<00:07,  8.45it/s] 93%|█████████▎| 901/966 [02:06<00:07,  8.47it/s] 93%|█████████▎| 902/966 [02:06<00:07,  8.47it/s] 93%|█████████▎| 903/966 [02:07<00:07,  8.48it/s] 94%|█████████▎| 904/966 [02:07<00:07,  8.46it/s] 94%|█████████▎| 905/966 [02:07<00:07,  8.47it/s] 94%|█████████▍| 906/966 [02:07<00:07,  8.46it/s] 94%|█████████▍| 907/966 [02:07<00:06,  8.45it/s] 94%|█████████▍| 908/966 [02:07<00:06,  8.44it/s] 94%|█████████▍| 909/966 [02:07<00:06,  8.44it/s] 94%|█████████▍| 910/966 [02:07<00:06,  8.44it/s] 94%|█████████▍| 911/966 [02:07<00:06,  8.44it/s] 94%|█████████▍| 912/966 [02:08<00:06,  8.43it/s] 95%|█████████▍| 913/966 [02:08<00:06,  8.44it/s] 95%|█████████▍| 914/966 [02:08<00:06,  8.45it/s] 95%|█████████▍| 915/966 [02:08<00:06,  8.46it/s] 95%|█████████▍| 916/966 [02:08<00:05,  8.48it/s] 95%|█████████▍| 917/966 [02:08<00:05,  8.48it/s] 95%|█████████▌| 918/966 [02:08<00:05,  8.48it/s] 95%|█████████▌| 919/966 [02:08<00:05,  8.51it/s] 95%|█████████▌| 920/966 [02:09<00:05,  8.49it/s] 95%|█████████▌| 921/966 [02:09<00:05,  8.47it/s] 95%|█████████▌| 922/966 [02:09<00:05,  8.47it/s] 96%|█████████▌| 923/966 [02:09<00:05,  8.46it/s] 96%|█████████▌| 924/966 [02:09<00:04,  8.47it/s] 96%|█████████▌| 925/966 [02:09<00:04,  8.47it/s] 96%|█████████▌| 926/966 [02:09<00:04,  8.49it/s] 96%|█████████▌| 927/966 [02:09<00:04,  8.50it/s] 96%|█████████▌| 928/966 [02:09<00:04,  8.49it/s] 96%|█████████▌| 929/966 [02:10<00:04,  8.47it/s] 96%|█████████▋| 930/966 [02:10<00:04,  8.46it/s] 96%|█████████▋| 931/966 [02:10<00:04,  8.47it/s] 96%|█████████▋| 932/966 [02:10<00:04,  8.47it/s] 97%|█████████▋| 933/966 [02:10<00:03,  8.47it/s] 97%|█████████▋| 934/966 [02:10<00:03,  8.46it/s] 97%|█████████▋| 935/966 [02:10<00:03,  8.46it/s] 97%|█████████▋| 936/966 [02:10<00:03,  8.47it/s] 97%|█████████▋| 937/966 [02:11<00:03,  8.48it/s] 97%|█████████▋| 938/966 [02:11<00:03,  8.47it/s] 97%|█████████▋| 939/966 [02:11<00:03,  8.48it/s] 97%|█████████▋| 940/966 [02:11<00:03,  8.47it/s] 97%|█████████▋| 941/966 [02:11<00:02,  8.47it/s] 98%|█████████▊| 942/966 [02:11<00:02,  8.46it/s] 98%|█████████▊| 943/966 [02:11<00:02,  8.45it/s] 98%|█████████▊| 944/966 [02:11<00:02,  8.45it/s] 98%|█████████▊| 945/966 [02:12<00:02,  8.44it/s] 98%|█████████▊| 946/966 [02:12<00:02,  8.43it/s] 98%|█████████▊| 947/966 [02:12<00:02,  8.44it/s] 98%|█████████▊| 948/966 [02:12<00:02,  8.44it/s] 98%|█████████▊| 949/966 [02:12<00:02,  8.43it/s] 98%|█████████▊| 950/966 [02:12<00:01,  8.43it/s] 98%|█████████▊| 951/966 [02:12<00:01,  8.43it/s] 99%|█████████▊| 952/966 [02:12<00:01,  8.45it/s] 99%|█████████▊| 953/966 [02:12<00:01,  8.45it/s] 99%|█████████▉| 954/966 [02:13<00:01,  8.44it/s] 99%|█████████▉| 955/966 [02:13<00:01,  8.44it/s] 99%|█████████▉| 956/966 [02:13<00:01,  8.45it/s] 99%|█████████▉| 957/966 [02:13<00:01,  8.45it/s] 99%|█████████▉| 958/966 [02:13<00:00,  8.46it/s] 99%|█████████▉| 959/966 [02:13<00:00,  8.47it/s] 99%|█████████▉| 960/966 [02:13<00:00,  8.48it/s] 99%|█████████▉| 961/966 [02:13<00:00,  8.48it/s]100%|█████████▉| 962/966 [02:14<00:00,  8.49it/s]100%|█████████▉| 963/966 [02:14<00:00,  8.48it/s]100%|█████████▉| 964/966 [02:14<00:00,  8.46it/s]100%|█████████▉| 965/966 [02:14<00:00,  8.47it/s]100%|██████████| 966/966 [02:14<00:00,  8.47it/s]100%|██████████| 966/966 [02:14<00:00,  7.18it/s]
sending off prediction to background worker for resampling and export
done with 101-045

Predicting 706-005:
perform_everything_on_device: True
  0%|          | 0/966 [00:00<?, ?it/s]  0%|          | 2/966 [00:00<01:26, 11.15it/s]  0%|          | 4/966 [00:00<01:42,  9.41it/s]  1%|          | 5/966 [00:00<01:45,  9.12it/s]  1%|          | 6/966 [00:00<01:47,  8.91it/s]  1%|          | 7/966 [00:00<01:49,  8.78it/s]  1%|          | 8/966 [00:00<01:50,  8.69it/s]  1%|          | 9/966 [00:01<01:50,  8.63it/s]  1%|          | 10/966 [00:01<01:51,  8.59it/s]  1%|          | 11/966 [00:01<01:51,  8.54it/s]  1%|          | 12/966 [00:01<01:51,  8.55it/s]  1%|▏         | 13/966 [00:01<01:51,  8.52it/s]  1%|▏         | 14/966 [00:01<01:52,  8.50it/s]  2%|▏         | 15/966 [00:01<01:51,  8.50it/s]  2%|▏         | 16/966 [00:01<01:51,  8.49it/s]  2%|▏         | 17/966 [00:01<01:51,  8.47it/s]  2%|▏         | 18/966 [00:02<01:52,  8.46it/s]  2%|▏         | 19/966 [00:02<01:52,  8.46it/s]  2%|▏         | 20/966 [00:02<01:51,  8.45it/s]  2%|▏         | 21/966 [00:02<01:51,  8.45it/s]  2%|▏         | 22/966 [00:02<01:51,  8.44it/s]  2%|▏         | 23/966 [00:02<01:51,  8.44it/s]  2%|▏         | 24/966 [00:02<01:51,  8.44it/s]  3%|▎         | 25/966 [00:02<01:51,  8.44it/s]  3%|▎         | 26/966 [00:03<01:51,  8.44it/s]  3%|▎         | 27/966 [00:03<01:51,  8.44it/s]  3%|▎         | 28/966 [00:03<01:51,  8.43it/s]  3%|▎         | 29/966 [00:03<01:50,  8.44it/s]  3%|▎         | 30/966 [00:03<01:50,  8.45it/s]  3%|▎         | 31/966 [00:03<01:50,  8.46it/s]  3%|▎         | 32/966 [00:03<01:50,  8.49it/s]  3%|▎         | 33/966 [00:03<01:49,  8.49it/s]  4%|▎         | 34/966 [00:03<01:49,  8.48it/s]  4%|▎         | 35/966 [00:04<01:49,  8.48it/s]  4%|▎         | 36/966 [00:04<01:49,  8.49it/s]  4%|▍         | 37/966 [00:04<01:49,  8.49it/s]  4%|▍         | 38/966 [00:04<01:49,  8.49it/s]  4%|▍         | 39/966 [00:04<01:49,  8.49it/s]  4%|▍         | 40/966 [00:04<01:49,  8.48it/s]  4%|▍         | 41/966 [00:04<01:49,  8.47it/s]  4%|▍         | 42/966 [00:04<01:49,  8.48it/s]  4%|▍         | 43/966 [00:05<01:48,  8.49it/s]  5%|▍         | 44/966 [00:05<01:48,  8.49it/s]  5%|▍         | 45/966 [00:05<01:48,  8.49it/s]  5%|▍         | 46/966 [00:05<01:48,  8.49it/s]  5%|▍         | 47/966 [00:05<01:48,  8.47it/s]  5%|▍         | 48/966 [00:05<01:48,  8.46it/s]  5%|▌         | 49/966 [00:05<01:48,  8.48it/s]  5%|▌         | 50/966 [00:05<01:47,  8.49it/s]  5%|▌         | 51/966 [00:05<01:47,  8.49it/s]  5%|▌         | 52/966 [00:06<01:47,  8.49it/s]  5%|▌         | 53/966 [00:06<01:47,  8.48it/s]  6%|▌         | 54/966 [00:06<01:47,  8.46it/s]  6%|▌         | 55/966 [00:06<01:47,  8.45it/s]  6%|▌         | 56/966 [00:06<01:47,  8.46it/s]  6%|▌         | 57/966 [00:06<01:47,  8.46it/s]  6%|▌         | 58/966 [00:06<01:47,  8.47it/s]  6%|▌         | 59/966 [00:06<01:47,  8.47it/s]  6%|▌         | 60/966 [00:07<01:46,  8.48it/s]  6%|▋         | 61/966 [00:07<01:46,  8.47it/s]  6%|▋         | 62/966 [00:07<01:46,  8.45it/s]  7%|▋         | 63/966 [00:07<01:46,  8.47it/s]  7%|▋         | 64/966 [00:07<01:46,  8.48it/s]  7%|▋         | 65/966 [00:07<01:46,  8.48it/s]  7%|▋         | 66/966 [00:07<01:46,  8.48it/s]  7%|▋         | 67/966 [00:07<01:46,  8.46it/s]  7%|▋         | 68/966 [00:07<01:46,  8.46it/s]  7%|▋         | 69/966 [00:08<01:46,  8.45it/s]  7%|▋         | 70/966 [00:08<01:46,  8.44it/s]  7%|▋         | 71/966 [00:08<01:46,  8.44it/s]  7%|▋         | 72/966 [00:08<01:45,  8.44it/s]  8%|▊         | 73/966 [00:08<01:45,  8.45it/s]  8%|▊         | 74/966 [00:08<01:45,  8.46it/s]  8%|▊         | 75/966 [00:08<01:45,  8.47it/s]  8%|▊         | 76/966 [00:08<01:44,  8.48it/s]  8%|▊         | 77/966 [00:09<01:44,  8.47it/s]  8%|▊         | 78/966 [00:09<01:44,  8.46it/s]  8%|▊         | 79/966 [00:09<01:44,  8.48it/s]  8%|▊         | 80/966 [00:09<01:44,  8.49it/s]  8%|▊         | 81/966 [00:09<01:44,  8.48it/s]  8%|▊         | 82/966 [00:09<01:44,  8.48it/s]  9%|▊         | 83/966 [00:09<01:44,  8.49it/s]  9%|▊         | 84/966 [00:09<01:43,  8.51it/s]  9%|▉         | 85/966 [00:09<01:43,  8.52it/s]  9%|▉         | 86/966 [00:10<01:43,  8.51it/s]  9%|▉         | 87/966 [00:10<01:43,  8.49it/s]  9%|▉         | 88/966 [00:10<01:43,  8.48it/s]  9%|▉         | 89/966 [00:10<01:43,  8.48it/s]  9%|▉         | 90/966 [00:10<01:43,  8.48it/s]  9%|▉         | 91/966 [00:10<01:43,  8.47it/s] 10%|▉         | 92/966 [00:10<01:43,  8.48it/s] 10%|▉         | 93/966 [00:10<01:43,  8.47it/s] 10%|▉         | 94/966 [00:11<01:43,  8.46it/s] 10%|▉         | 95/966 [00:11<01:43,  8.45it/s] 10%|▉         | 96/966 [00:11<01:43,  8.44it/s] 10%|█         | 97/966 [00:11<01:42,  8.44it/s] 10%|█         | 98/966 [00:11<01:42,  8.46it/s] 10%|█         | 99/966 [00:11<01:42,  8.46it/s] 10%|█         | 100/966 [00:11<01:42,  8.46it/s] 10%|█         | 101/966 [00:11<01:42,  8.45it/s] 11%|█         | 102/966 [00:11<01:42,  8.46it/s] 11%|█         | 103/966 [00:12<01:41,  8.47it/s] 11%|█         | 104/966 [00:12<01:41,  8.48it/s] 11%|█         | 105/966 [00:12<01:41,  8.48it/s] 11%|█         | 106/966 [00:12<01:41,  8.49it/s] 11%|█         | 107/966 [00:12<01:41,  8.47it/s] 11%|█         | 108/966 [00:12<01:41,  8.47it/s] 11%|█▏        | 109/966 [00:12<01:41,  8.44it/s] 11%|█▏        | 110/966 [00:12<01:41,  8.45it/s] 11%|█▏        | 111/966 [00:13<01:41,  8.46it/s] 12%|█▏        | 112/966 [00:13<01:41,  8.45it/s] 12%|█▏        | 113/966 [00:13<01:40,  8.45it/s] 12%|█▏        | 114/966 [00:13<01:40,  8.44it/s] 12%|█▏        | 115/966 [00:13<01:40,  8.44it/s] 12%|█▏        | 116/966 [00:13<01:40,  8.45it/s] 12%|█▏        | 117/966 [00:13<01:40,  8.44it/s] 12%|█▏        | 118/966 [00:13<01:40,  8.43it/s] 12%|█▏        | 119/966 [00:13<01:40,  8.44it/s] 12%|█▏        | 120/966 [00:14<01:40,  8.45it/s] 13%|█▎        | 121/966 [00:14<01:39,  8.46it/s] 13%|█▎        | 122/966 [00:14<01:39,  8.46it/s] 13%|█▎        | 123/966 [00:14<01:39,  8.45it/s] 13%|█▎        | 124/966 [00:14<01:39,  8.45it/s] 13%|█▎        | 125/966 [00:14<01:39,  8.46it/s] 13%|█▎        | 126/966 [00:14<01:39,  8.45it/s] 13%|█▎        | 127/966 [00:14<01:39,  8.45it/s] 13%|█▎        | 128/966 [00:15<01:39,  8.46it/s] 13%|█▎        | 129/966 [00:15<01:38,  8.46it/s] 13%|█▎        | 130/966 [00:15<01:38,  8.45it/s] 14%|█▎        | 131/966 [00:15<01:38,  8.45it/s] 14%|█▎        | 132/966 [00:15<01:38,  8.47it/s] 14%|█▍        | 133/966 [00:15<01:38,  8.48it/s] 14%|█▍        | 134/966 [00:15<01:38,  8.49it/s] 14%|█▍        | 135/966 [00:15<01:38,  8.47it/s] 14%|█▍        | 136/966 [00:16<01:38,  8.46it/s] 14%|█▍        | 137/966 [00:16<01:38,  8.45it/s] 14%|█▍        | 138/966 [00:16<01:38,  8.44it/s] 14%|█▍        | 139/966 [00:16<01:37,  8.45it/s] 14%|█▍        | 140/966 [00:16<01:37,  8.46it/s] 15%|█▍        | 141/966 [00:16<01:37,  8.46it/s] 15%|█▍        | 142/966 [00:16<01:37,  8.47it/s] 15%|█▍        | 143/966 [00:16<01:37,  8.47it/s] 15%|█▍        | 144/966 [00:16<01:37,  8.47it/s] 15%|█▌        | 145/966 [00:17<01:37,  8.45it/s] 15%|█▌        | 146/966 [00:17<01:36,  8.46it/s] 15%|█▌        | 147/966 [00:17<01:36,  8.47it/s] 15%|█▌        | 148/966 [00:17<01:36,  8.46it/s] 15%|█▌        | 149/966 [00:17<01:36,  8.45it/s] 16%|█▌        | 150/966 [00:17<01:36,  8.45it/s] 16%|█▌        | 151/966 [00:17<01:36,  8.44it/s] 16%|█▌        | 152/966 [00:17<01:36,  8.46it/s] 16%|█▌        | 153/966 [00:18<01:36,  8.46it/s] 16%|█▌        | 154/966 [00:18<01:36,  8.45it/s] 16%|█▌        | 155/966 [00:18<01:36,  8.44it/s] 16%|█▌        | 156/966 [00:18<01:35,  8.44it/s] 16%|█▋        | 157/966 [00:18<01:35,  8.44it/s] 16%|█▋        | 158/966 [00:18<01:35,  8.44it/s] 16%|█▋        | 159/966 [00:18<01:35,  8.43it/s] 17%|█▋        | 160/966 [00:18<01:35,  8.43it/s] 17%|█▋        | 161/966 [00:18<01:35,  8.43it/s] 17%|█▋        | 162/966 [00:19<01:35,  8.43it/s] 17%|█▋        | 163/966 [00:19<01:34,  8.46it/s] 17%|█▋        | 164/966 [00:19<01:34,  8.46it/s] 17%|█▋        | 165/966 [00:19<01:34,  8.47it/s] 17%|█▋        | 166/966 [00:19<01:34,  8.48it/s] 17%|█▋        | 167/966 [00:19<01:34,  8.48it/s] 17%|█▋        | 168/966 [00:19<01:34,  8.47it/s] 17%|█▋        | 169/966 [00:19<01:34,  8.47it/s] 18%|█▊        | 170/966 [00:20<01:33,  8.48it/s] 18%|█▊        | 171/966 [00:20<01:33,  8.47it/s] 18%|█▊        | 172/966 [00:20<01:33,  8.46it/s] 18%|█▊        | 173/966 [00:20<01:33,  8.46it/s] 18%|█▊        | 174/966 [00:20<01:33,  8.47it/s] 18%|█▊        | 175/966 [00:20<01:33,  8.47it/s] 18%|█▊        | 176/966 [00:20<01:33,  8.48it/s] 18%|█▊        | 177/966 [00:20<01:32,  8.49it/s] 18%|█▊        | 178/966 [00:20<01:32,  8.49it/s] 19%|█▊        | 179/966 [00:21<01:32,  8.49it/s] 19%|█▊        | 180/966 [00:21<01:32,  8.48it/s] 19%|█▊        | 181/966 [00:21<01:32,  8.49it/s] 19%|█▉        | 182/966 [00:21<01:32,  8.47it/s] 19%|█▉        | 183/966 [00:21<01:32,  8.47it/s] 19%|█▉        | 184/966 [00:21<01:32,  8.46it/s] 19%|█▉        | 185/966 [00:21<01:32,  8.45it/s] 19%|█▉        | 186/966 [00:21<01:32,  8.45it/s] 19%|█▉        | 187/966 [00:22<01:32,  8.44it/s] 19%|█▉        | 188/966 [00:22<01:32,  8.44it/s] 20%|█▉        | 189/966 [00:22<01:31,  8.45it/s] 20%|█▉        | 190/966 [00:22<01:31,  8.47it/s] 20%|█▉        | 191/966 [00:22<01:31,  8.47it/s] 20%|█▉        | 192/966 [00:22<01:31,  8.47it/s] 20%|█▉        | 193/966 [00:22<01:31,  8.46it/s] 20%|██        | 194/966 [00:22<01:31,  8.46it/s] 20%|██        | 195/966 [00:22<01:31,  8.45it/s] 20%|██        | 196/966 [00:23<01:31,  8.45it/s] 20%|██        | 197/966 [00:23<01:31,  8.43it/s] 20%|██        | 198/966 [00:23<01:31,  8.44it/s] 21%|██        | 199/966 [00:23<01:30,  8.44it/s] 21%|██        | 200/966 [00:23<01:30,  8.43it/s] 21%|██        | 201/966 [00:23<01:30,  8.43it/s] 21%|██        | 202/966 [00:23<01:30,  8.43it/s] 21%|██        | 203/966 [00:23<01:30,  8.44it/s] 21%|██        | 204/966 [00:24<01:30,  8.46it/s] 21%|██        | 205/966 [00:24<01:29,  8.47it/s] 21%|██▏       | 206/966 [00:24<01:29,  8.47it/s] 21%|██▏       | 207/966 [00:24<01:29,  8.46it/s] 22%|██▏       | 208/966 [00:24<01:29,  8.47it/s] 22%|██▏       | 209/966 [00:24<01:29,  8.49it/s] 22%|██▏       | 210/966 [00:24<01:28,  8.49it/s] 22%|██▏       | 211/966 [00:24<01:29,  8.48it/s] 22%|██▏       | 212/966 [00:24<01:28,  8.49it/s] 22%|██▏       | 213/966 [00:25<01:28,  8.49it/s] 22%|██▏       | 214/966 [00:25<01:28,  8.49it/s] 22%|██▏       | 215/966 [00:25<01:28,  8.47it/s] 22%|██▏       | 216/966 [00:25<01:28,  8.47it/s] 22%|██▏       | 217/966 [00:25<01:28,  8.48it/s] 23%|██▎       | 218/966 [00:25<01:28,  8.48it/s] 23%|██▎       | 219/966 [00:25<01:28,  8.47it/s] 23%|██▎       | 220/966 [00:25<01:28,  8.46it/s] 23%|██▎       | 221/966 [00:26<01:28,  8.45it/s] 23%|██▎       | 222/966 [00:26<01:27,  8.46it/s] 23%|██▎       | 223/966 [00:26<01:27,  8.48it/s] 23%|██▎       | 224/966 [00:26<01:27,  8.49it/s] 23%|██▎       | 225/966 [00:26<01:27,  8.49it/s] 23%|██▎       | 226/966 [00:26<01:27,  8.49it/s] 23%|██▎       | 227/966 [00:26<01:27,  8.48it/s] 24%|██▎       | 228/966 [00:26<01:27,  8.47it/s] 24%|██▎       | 229/966 [00:26<01:27,  8.47it/s] 24%|██▍       | 230/966 [00:27<01:27,  8.45it/s] 24%|██▍       | 231/966 [00:27<01:27,  8.45it/s] 24%|██▍       | 232/966 [00:27<01:26,  8.44it/s] 24%|██▍       | 233/966 [00:27<01:26,  8.45it/s] 24%|██▍       | 234/966 [00:27<01:26,  8.45it/s] 24%|██▍       | 235/966 [00:27<01:26,  8.44it/s] 24%|██▍       | 236/966 [00:27<01:26,  8.44it/s] 25%|██▍       | 237/966 [00:27<01:26,  8.45it/s] 25%|██▍       | 238/966 [00:28<01:26,  8.45it/s] 25%|██▍       | 239/966 [00:28<01:26,  8.45it/s] 25%|██▍       | 240/966 [00:28<01:25,  8.45it/s] 25%|██▍       | 241/966 [00:28<01:25,  8.44it/s] 25%|██▌       | 242/966 [00:28<01:25,  8.44it/s] 25%|██▌       | 243/966 [00:28<01:25,  8.44it/s] 25%|██▌       | 244/966 [00:28<01:25,  8.44it/s] 25%|██▌       | 245/966 [00:28<01:25,  8.46it/s] 25%|██▌       | 246/966 [00:29<01:25,  8.46it/s] 26%|██▌       | 247/966 [00:29<01:24,  8.47it/s] 26%|██▌       | 248/966 [00:29<01:24,  8.46it/s] 26%|██▌       | 249/966 [00:29<01:24,  8.47it/s] 26%|██▌       | 250/966 [00:29<01:24,  8.46it/s] 26%|██▌       | 251/966 [00:29<01:24,  8.47it/s] 26%|██▌       | 252/966 [00:29<01:24,  8.47it/s] 26%|██▌       | 253/966 [00:29<01:24,  8.46it/s] 26%|██▋       | 254/966 [00:29<01:24,  8.45it/s] 26%|██▋       | 255/966 [00:30<01:24,  8.44it/s] 27%|██▋       | 256/966 [00:30<01:24,  8.44it/s] 27%|██▋       | 257/966 [00:30<01:24,  8.44it/s] 27%|██▋       | 258/966 [00:30<01:23,  8.43it/s] 27%|██▋       | 259/966 [00:30<01:23,  8.45it/s] 27%|██▋       | 260/966 [00:30<01:23,  8.47it/s] 27%|██▋       | 261/966 [00:30<01:23,  8.48it/s] 27%|██▋       | 262/966 [00:30<01:23,  8.47it/s] 27%|██▋       | 263/966 [00:31<01:23,  8.46it/s] 27%|██▋       | 264/966 [00:31<01:23,  8.45it/s] 27%|██▋       | 265/966 [00:31<01:22,  8.46it/s] 28%|██▊       | 266/966 [00:31<01:22,  8.45it/s] 28%|██▊       | 267/966 [00:31<01:22,  8.45it/s] 28%|██▊       | 268/966 [00:31<01:22,  8.44it/s] 28%|██▊       | 269/966 [00:31<01:22,  8.45it/s] 28%|██▊       | 270/966 [00:31<01:22,  8.46it/s] 28%|██▊       | 271/966 [00:31<01:22,  8.47it/s] 28%|██▊       | 272/966 [00:32<01:22,  8.44it/s] 28%|██▊       | 273/966 [00:32<01:21,  8.46it/s] 28%|██▊       | 274/966 [00:32<01:21,  8.46it/s] 28%|██▊       | 275/966 [00:32<01:21,  8.47it/s] 29%|██▊       | 276/966 [00:32<01:21,  8.48it/s] 29%|██▊       | 277/966 [00:32<01:21,  8.49it/s] 29%|██▉       | 278/966 [00:32<01:21,  8.47it/s] 29%|██▉       | 279/966 [00:32<01:21,  8.47it/s] 29%|██▉       | 280/966 [00:33<01:21,  8.45it/s] 29%|██▉       | 281/966 [00:33<01:21,  8.44it/s] 29%|██▉       | 282/966 [00:33<01:20,  8.47it/s] 29%|██▉       | 283/966 [00:33<01:20,  8.46it/s] 29%|██▉       | 284/966 [00:33<01:20,  8.46it/s] 30%|██▉       | 285/966 [00:33<01:20,  8.45it/s] 30%|██▉       | 286/966 [00:33<01:20,  8.45it/s] 30%|██▉       | 287/966 [00:33<01:20,  8.44it/s] 30%|██▉       | 288/966 [00:33<01:20,  8.44it/s] 30%|██▉       | 289/966 [00:34<01:20,  8.45it/s] 30%|███       | 290/966 [00:34<01:20,  8.44it/s] 30%|███       | 291/966 [00:34<01:19,  8.44it/s] 30%|███       | 292/966 [00:34<01:19,  8.43it/s] 30%|███       | 293/966 [00:34<01:19,  8.43it/s] 30%|███       | 294/966 [00:34<01:19,  8.43it/s] 31%|███       | 295/966 [00:34<01:19,  8.43it/s] 31%|███       | 296/966 [00:34<01:19,  8.45it/s] 31%|███       | 297/966 [00:35<01:19,  8.45it/s] 31%|███       | 298/966 [00:35<01:18,  8.46it/s] 31%|███       | 299/966 [00:35<01:18,  8.47it/s] 31%|███       | 300/966 [00:35<01:18,  8.46it/s] 31%|███       | 301/966 [00:35<01:18,  8.46it/s] 31%|███▏      | 302/966 [00:35<01:18,  8.47it/s] 31%|███▏      | 303/966 [00:35<01:18,  8.47it/s] 31%|███▏      | 304/966 [00:35<01:18,  8.46it/s] 32%|███▏      | 305/966 [00:35<01:18,  8.46it/s] 32%|███▏      | 306/966 [00:36<01:17,  8.47it/s] 32%|███▏      | 307/966 [00:36<01:17,  8.46it/s] 32%|███▏      | 308/966 [00:36<01:17,  8.47it/s] 32%|███▏      | 309/966 [00:36<01:17,  8.45it/s] 32%|███▏      | 310/966 [00:36<01:17,  8.45it/s] 32%|███▏      | 311/966 [00:36<01:17,  8.45it/s] 32%|███▏      | 312/966 [00:36<01:17,  8.44it/s] 32%|███▏      | 313/966 [00:36<01:17,  8.44it/s] 33%|███▎      | 314/966 [00:37<01:17,  8.43it/s] 33%|███▎      | 315/966 [00:37<01:17,  8.44it/s] 33%|███▎      | 316/966 [00:37<01:17,  8.44it/s] 33%|███▎      | 317/966 [00:37<01:16,  8.43it/s] 33%|███▎      | 318/966 [00:37<01:16,  8.43it/s] 33%|███▎      | 319/966 [00:37<01:16,  8.43it/s] 33%|███▎      | 320/966 [00:37<01:16,  8.42it/s] 33%|███▎      | 321/966 [00:37<01:16,  8.43it/s] 33%|███▎      | 322/966 [00:38<01:16,  8.43it/s] 33%|███▎      | 323/966 [00:38<01:16,  8.44it/s] 34%|███▎      | 324/966 [00:38<01:15,  8.46it/s] 34%|███▎      | 325/966 [00:38<01:15,  8.46it/s] 34%|███▎      | 326/966 [00:38<01:15,  8.46it/s] 34%|███▍      | 327/966 [00:38<01:15,  8.47it/s] 34%|███▍      | 328/966 [00:38<01:15,  8.45it/s] 34%|███▍      | 329/966 [00:38<01:15,  8.45it/s] 34%|███▍      | 330/966 [00:38<01:15,  8.45it/s] 34%|███▍      | 331/966 [00:39<01:15,  8.46it/s] 34%|███▍      | 332/966 [00:39<01:14,  8.47it/s] 34%|███▍      | 333/966 [00:39<01:14,  8.48it/s] 35%|███▍      | 334/966 [00:39<01:14,  8.47it/s] 35%|███▍      | 335/966 [00:39<01:14,  8.45it/s] 35%|███▍      | 336/966 [00:39<01:14,  8.46it/s] 35%|███▍      | 337/966 [00:39<01:14,  8.47it/s] 35%|███▍      | 338/966 [00:39<01:14,  8.46it/s] 35%|███▌      | 339/966 [00:40<01:14,  8.46it/s] 35%|███▌      | 340/966 [00:40<01:14,  8.45it/s] 35%|███▌      | 341/966 [00:40<01:13,  8.45it/s] 35%|███▌      | 342/966 [00:40<01:13,  8.45it/s] 36%|███▌      | 343/966 [00:40<01:13,  8.45it/s] 36%|███▌      | 344/966 [00:40<01:13,  8.46it/s] 36%|███▌      | 345/966 [00:40<01:13,  8.46it/s] 36%|███▌      | 346/966 [00:40<01:13,  8.46it/s] 36%|███▌      | 347/966 [00:40<01:13,  8.46it/s] 36%|███▌      | 348/966 [00:41<01:13,  8.45it/s] 36%|███▌      | 349/966 [00:41<01:12,  8.46it/s] 36%|███▌      | 350/966 [00:41<01:12,  8.46it/s] 36%|███▋      | 351/966 [00:41<01:12,  8.46it/s] 36%|███▋      | 352/966 [00:41<01:12,  8.45it/s] 37%|███▋      | 353/966 [00:41<01:12,  8.45it/s] 37%|███▋      | 354/966 [00:41<01:12,  8.45it/s] 37%|███▋      | 355/966 [00:41<01:12,  8.44it/s] 37%|███▋      | 356/966 [00:42<01:12,  8.44it/s] 37%|███▋      | 357/966 [00:42<01:12,  8.44it/s] 37%|███▋      | 358/966 [00:42<01:12,  8.43it/s] 37%|███▋      | 359/966 [00:42<01:11,  8.44it/s] 37%|███▋      | 360/966 [00:42<01:11,  8.45it/s] 37%|███▋      | 361/966 [00:42<01:11,  8.44it/s] 37%|███▋      | 362/966 [00:42<01:11,  8.44it/s] 38%|███▊      | 363/966 [00:42<01:11,  8.45it/s] 38%|███▊      | 364/966 [00:42<01:11,  8.46it/s] 38%|███▊      | 365/966 [00:43<01:10,  8.47it/s] 38%|███▊      | 366/966 [00:43<01:10,  8.47it/s] 38%|███▊      | 367/966 [00:43<01:10,  8.47it/s] 38%|███▊      | 368/966 [00:43<01:10,  8.46it/s] 38%|███▊      | 369/966 [00:43<01:10,  8.44it/s] 38%|███▊      | 370/966 [00:43<01:10,  8.43it/s] 38%|███▊      | 371/966 [00:43<01:10,  8.43it/s] 39%|███▊      | 372/966 [00:43<01:10,  8.44it/s] 39%|███▊      | 373/966 [00:44<01:10,  8.46it/s] 39%|███▊      | 374/966 [00:44<01:09,  8.48it/s] 39%|███▉      | 375/966 [00:44<01:09,  8.47it/s] 39%|███▉      | 376/966 [00:44<01:09,  8.46it/s] 39%|███▉      | 377/966 [00:44<01:09,  8.46it/s] 39%|███▉      | 378/966 [00:44<01:09,  8.47it/s] 39%|███▉      | 379/966 [00:44<01:09,  8.48it/s] 39%|███▉      | 380/966 [00:44<01:09,  8.48it/s] 39%|███▉      | 381/966 [00:44<01:09,  8.47it/s] 40%|███▉      | 382/966 [00:45<01:08,  8.46it/s] 40%|███▉      | 383/966 [00:45<01:08,  8.45it/s] 40%|███▉      | 384/966 [00:45<01:08,  8.46it/s] 40%|███▉      | 385/966 [00:45<01:08,  8.47it/s] 40%|███▉      | 386/966 [00:45<01:08,  8.48it/s] 40%|████      | 387/966 [00:45<01:08,  8.46it/s] 40%|████      | 388/966 [00:45<01:08,  8.47it/s] 40%|████      | 389/966 [00:45<01:08,  8.48it/s] 40%|████      | 390/966 [00:46<01:08,  8.47it/s] 40%|████      | 391/966 [00:46<01:08,  8.45it/s] 41%|████      | 392/966 [00:46<01:08,  8.44it/s] 41%|████      | 393/966 [00:46<01:07,  8.43it/s] 41%|████      | 394/966 [00:46<01:07,  8.44it/s] 41%|████      | 395/966 [00:46<01:07,  8.46it/s] 41%|████      | 396/966 [00:46<01:07,  8.46it/s] 41%|████      | 397/966 [00:46<01:07,  8.45it/s] 41%|████      | 398/966 [00:46<01:07,  8.45it/s] 41%|████▏     | 399/966 [00:47<01:07,  8.45it/s] 41%|████▏     | 400/966 [00:47<01:07,  8.43it/s] 42%|████▏     | 401/966 [00:47<01:06,  8.45it/s] 42%|████▏     | 402/966 [00:47<01:06,  8.45it/s] 42%|████▏     | 403/966 [00:47<01:06,  8.44it/s] 42%|████▏     | 404/966 [00:47<01:06,  8.45it/s] 42%|████▏     | 405/966 [00:47<01:06,  8.46it/s] 42%|████▏     | 406/966 [00:47<01:06,  8.45it/s] 42%|████▏     | 407/966 [00:48<01:06,  8.44it/s] 42%|████▏     | 408/966 [00:48<01:06,  8.45it/s] 42%|████▏     | 409/966 [00:48<01:05,  8.46it/s] 42%|████▏     | 410/966 [00:48<01:05,  8.45it/s] 43%|████▎     | 411/966 [00:48<01:05,  8.47it/s] 43%|████▎     | 412/966 [00:48<01:05,  8.47it/s] 43%|████▎     | 413/966 [00:48<01:05,  8.47it/s] 43%|████▎     | 414/966 [00:48<01:05,  8.48it/s] 43%|████▎     | 415/966 [00:48<01:04,  8.49it/s] 43%|████▎     | 416/966 [00:49<01:04,  8.48it/s] 43%|████▎     | 417/966 [00:49<01:04,  8.47it/s] 43%|████▎     | 418/966 [00:49<01:04,  8.47it/s] 43%|████▎     | 419/966 [00:49<01:04,  8.45it/s] 43%|████▎     | 420/966 [00:49<01:04,  8.47it/s] 44%|████▎     | 421/966 [00:49<01:04,  8.48it/s] 44%|████▎     | 422/966 [00:49<01:04,  8.49it/s] 44%|████▍     | 423/966 [00:49<01:03,  8.49it/s] 44%|████▍     | 424/966 [00:50<01:03,  8.48it/s] 44%|████▍     | 425/966 [00:50<01:03,  8.49it/s] 44%|████▍     | 426/966 [00:50<01:03,  8.49it/s] 44%|████▍     | 427/966 [00:50<01:03,  8.48it/s] 44%|████▍     | 428/966 [00:50<01:03,  8.47it/s] 44%|████▍     | 429/966 [00:50<01:03,  8.46it/s] 45%|████▍     | 430/966 [00:50<01:03,  8.48it/s] 45%|████▍     | 431/966 [00:50<01:03,  8.47it/s] 45%|████▍     | 432/966 [00:51<01:03,  8.46it/s] 45%|████▍     | 433/966 [00:51<01:03,  8.46it/s] 45%|████▍     | 434/966 [00:51<01:02,  8.46it/s] 45%|████▌     | 435/966 [00:51<01:02,  8.46it/s] 45%|████▌     | 436/966 [00:51<01:02,  8.48it/s] 45%|████▌     | 437/966 [00:51<01:02,  8.48it/s] 45%|████▌     | 438/966 [00:51<01:02,  8.47it/s] 45%|████▌     | 439/966 [00:51<01:02,  8.45it/s] 46%|████▌     | 440/966 [00:51<01:02,  8.44it/s] 46%|████▌     | 441/966 [00:52<01:02,  8.45it/s] 46%|████▌     | 442/966 [00:52<01:02,  8.44it/s] 46%|████▌     | 443/966 [00:52<01:01,  8.45it/s] 46%|████▌     | 444/966 [00:52<01:01,  8.47it/s] 46%|████▌     | 445/966 [00:52<01:01,  8.46it/s] 46%|████▌     | 446/966 [00:52<01:01,  8.44it/s] 46%|████▋     | 447/966 [00:52<01:01,  8.45it/s] 46%|████▋     | 448/966 [00:52<01:01,  8.46it/s] 46%|████▋     | 449/966 [00:53<01:01,  8.45it/s] 47%|████▋     | 450/966 [00:53<01:01,  8.45it/s] 47%|████▋     | 451/966 [00:53<01:01,  8.44it/s] 47%|████▋     | 452/966 [00:53<01:00,  8.45it/s] 47%|████▋     | 453/966 [00:53<01:00,  8.46it/s] 47%|████▋     | 454/966 [00:53<01:00,  8.47it/s] 47%|████▋     | 455/966 [00:53<01:00,  8.46it/s] 47%|████▋     | 456/966 [00:53<01:00,  8.46it/s] 47%|████▋     | 457/966 [00:53<01:00,  8.46it/s] 47%|████▋     | 458/966 [00:54<00:59,  8.47it/s] 48%|████▊     | 459/966 [00:54<00:59,  8.45it/s] 48%|████▊     | 460/966 [00:54<00:59,  8.45it/s] 48%|████▊     | 461/966 [00:54<00:59,  8.45it/s] 48%|████▊     | 462/966 [00:54<00:59,  8.46it/s] 48%|████▊     | 463/966 [00:54<00:59,  8.48it/s] 48%|████▊     | 464/966 [00:54<00:59,  8.49it/s] 48%|████▊     | 465/966 [00:54<00:59,  8.48it/s] 48%|████▊     | 466/966 [00:55<00:59,  8.47it/s] 48%|████▊     | 467/966 [00:55<00:58,  8.47it/s] 48%|████▊     | 468/966 [00:55<00:58,  8.47it/s] 49%|████▊     | 469/966 [00:55<00:58,  8.48it/s] 49%|████▊     | 470/966 [00:55<00:58,  8.50it/s] 49%|████▉     | 471/966 [00:55<00:58,  8.48it/s] 49%|████▉     | 472/966 [00:55<00:58,  8.47it/s] 49%|████▉     | 473/966 [00:55<00:58,  8.46it/s] 49%|████▉     | 474/966 [00:55<00:58,  8.45it/s] 49%|████▉     | 475/966 [00:56<00:58,  8.45it/s] 49%|████▉     | 476/966 [00:56<00:57,  8.46it/s] 49%|████▉     | 477/966 [00:56<00:57,  8.46it/s] 49%|████▉     | 478/966 [00:56<00:57,  8.46it/s] 50%|████▉     | 479/966 [00:56<00:57,  8.45it/s] 50%|████▉     | 480/966 [00:56<00:57,  8.45it/s] 50%|████▉     | 481/966 [00:56<00:57,  8.45it/s] 50%|████▉     | 482/966 [00:56<00:57,  8.44it/s] 50%|█████     | 483/966 [00:57<00:57,  8.44it/s] 50%|█████     | 484/966 [00:57<00:57,  8.44it/s] 50%|█████     | 485/966 [00:57<00:57,  8.43it/s] 50%|█████     | 486/966 [00:57<00:56,  8.43it/s] 50%|█████     | 487/966 [00:57<00:56,  8.43it/s] 51%|█████     | 488/966 [00:57<00:56,  8.43it/s] 51%|█████     | 489/966 [00:57<00:56,  8.43it/s] 51%|█████     | 490/966 [00:57<00:56,  8.42it/s] 51%|█████     | 491/966 [00:57<00:56,  8.43it/s] 51%|█████     | 492/966 [00:58<00:56,  8.43it/s] 51%|█████     | 493/966 [00:58<00:56,  8.42it/s] 51%|█████     | 494/966 [00:58<00:56,  8.42it/s] 51%|█████     | 495/966 [00:58<00:55,  8.43it/s] 51%|█████▏    | 496/966 [00:58<00:55,  8.45it/s] 51%|█████▏    | 497/966 [00:58<00:55,  8.46it/s] 52%|█████▏    | 498/966 [00:58<00:55,  8.46it/s] 52%|█████▏    | 499/966 [00:58<00:55,  8.46it/s] 52%|█████▏    | 500/966 [00:59<00:54,  8.47it/s] 52%|█████▏    | 501/966 [00:59<00:54,  8.46it/s] 52%|█████▏    | 502/966 [00:59<00:54,  8.46it/s] 52%|█████▏    | 503/966 [00:59<00:54,  8.45it/s] 52%|█████▏    | 504/966 [00:59<00:54,  8.46it/s] 52%|█████▏    | 505/966 [00:59<00:54,  8.47it/s] 52%|█████▏    | 506/966 [00:59<00:54,  8.49it/s] 52%|█████▏    | 507/966 [00:59<00:54,  8.48it/s] 53%|█████▎    | 508/966 [00:59<00:54,  8.48it/s] 53%|█████▎    | 509/966 [01:00<00:53,  8.48it/s] 53%|█████▎    | 510/966 [01:00<00:53,  8.48it/s] 53%|█████▎    | 511/966 [01:00<00:53,  8.49it/s] 53%|█████▎    | 512/966 [01:00<00:53,  8.50it/s] 53%|█████▎    | 513/966 [01:00<00:53,  8.48it/s] 53%|█████▎    | 514/966 [01:00<00:53,  8.47it/s] 53%|█████▎    | 515/966 [01:00<00:53,  8.45it/s] 53%|█████▎    | 516/966 [01:00<00:53,  8.44it/s] 54%|█████▎    | 517/966 [01:01<00:53,  8.44it/s] 54%|█████▎    | 518/966 [01:01<00:53,  8.43it/s] 54%|█████▎    | 519/966 [01:01<00:53,  8.43it/s] 54%|█████▍    | 520/966 [01:01<00:52,  8.44it/s] 54%|█████▍    | 521/966 [01:01<00:52,  8.44it/s] 54%|█████▍    | 522/966 [01:01<00:52,  8.44it/s] 54%|█████▍    | 523/966 [01:01<00:52,  8.44it/s] 54%|█████▍    | 524/966 [01:01<00:52,  8.42it/s] 54%|█████▍    | 525/966 [01:02<00:52,  8.43it/s] 54%|█████▍    | 526/966 [01:02<00:52,  8.43it/s] 55%|█████▍    | 527/966 [01:02<00:52,  8.42it/s] 55%|█████▍    | 528/966 [01:02<00:51,  8.42it/s] 55%|█████▍    | 529/966 [01:02<00:51,  8.43it/s] 55%|█████▍    | 530/966 [01:02<00:51,  8.43it/s] 55%|█████▍    | 531/966 [01:02<00:51,  8.44it/s] 55%|█████▌    | 532/966 [01:02<00:51,  8.44it/s] 55%|█████▌    | 533/966 [01:02<00:51,  8.43it/s] 55%|█████▌    | 534/966 [01:03<00:51,  8.44it/s] 55%|█████▌    | 535/966 [01:03<00:51,  8.44it/s] 55%|█████▌    | 536/966 [01:03<00:50,  8.44it/s] 56%|█████▌    | 537/966 [01:03<00:50,  8.45it/s] 56%|█████▌    | 538/966 [01:03<00:50,  8.45it/s] 56%|█████▌    | 539/966 [01:03<00:50,  8.45it/s] 56%|█████▌    | 540/966 [01:03<00:50,  8.44it/s] 56%|█████▌    | 541/966 [01:03<00:50,  8.45it/s] 56%|█████▌    | 542/966 [01:04<00:50,  8.45it/s] 56%|█████▌    | 543/966 [01:04<00:49,  8.46it/s] 56%|█████▋    | 544/966 [01:04<00:49,  8.46it/s] 56%|█████▋    | 545/966 [01:04<00:49,  8.45it/s] 57%|█████▋    | 546/966 [01:04<00:49,  8.44it/s] 57%|█████▋    | 547/966 [01:04<00:49,  8.45it/s] 57%|█████▋    | 548/966 [01:04<00:49,  8.47it/s] 57%|█████▋    | 549/966 [01:04<00:49,  8.47it/s] 57%|█████▋    | 550/966 [01:04<00:49,  8.48it/s] 57%|█████▋    | 551/966 [01:05<00:49,  8.46it/s] 57%|█████▋    | 552/966 [01:05<00:48,  8.45it/s] 57%|█████▋    | 553/966 [01:05<00:48,  8.45it/s] 57%|█████▋    | 554/966 [01:05<00:48,  8.45it/s] 57%|█████▋    | 555/966 [01:05<00:48,  8.46it/s] 58%|█████▊    | 556/966 [01:05<00:48,  8.45it/s] 58%|█████▊    | 557/966 [01:05<00:48,  8.45it/s] 58%|█████▊    | 558/966 [01:05<00:48,  8.45it/s] 58%|█████▊    | 559/966 [01:06<00:48,  8.44it/s] 58%|█████▊    | 560/966 [01:06<00:48,  8.44it/s] 58%|█████▊    | 561/966 [01:06<00:48,  8.43it/s] 58%|█████▊    | 562/966 [01:06<00:47,  8.44it/s] 58%|█████▊    | 563/966 [01:06<00:47,  8.44it/s] 58%|█████▊    | 564/966 [01:06<00:47,  8.44it/s] 58%|█████▊    | 565/966 [01:06<00:47,  8.44it/s] 59%|█████▊    | 566/966 [01:06<00:47,  8.43it/s] 59%|█████▊    | 567/966 [01:06<00:47,  8.43it/s] 59%|█████▉    | 568/966 [01:07<00:47,  8.44it/s] 59%|█████▉    | 569/966 [01:07<00:47,  8.44it/s] 59%|█████▉    | 570/966 [01:07<00:46,  8.45it/s] 59%|█████▉    | 571/966 [01:07<00:46,  8.46it/s] 59%|█████▉    | 572/966 [01:07<00:46,  8.46it/s] 59%|█████▉    | 573/966 [01:07<00:46,  8.47it/s] 59%|█████▉    | 574/966 [01:07<00:46,  8.45it/s] 60%|█████▉    | 575/966 [01:07<00:46,  8.45it/s] 60%|█████▉    | 576/966 [01:08<00:46,  8.45it/s] 60%|█████▉    | 577/966 [01:08<00:45,  8.46it/s] 60%|█████▉    | 578/966 [01:08<00:45,  8.47it/s] 60%|█████▉    | 579/966 [01:08<00:45,  8.46it/s] 60%|██████    | 580/966 [01:08<00:45,  8.45it/s] 60%|██████    | 581/966 [01:08<00:45,  8.44it/s] 60%|██████    | 582/966 [01:08<00:45,  8.44it/s] 60%|██████    | 583/966 [01:08<00:45,  8.43it/s] 60%|██████    | 584/966 [01:08<00:45,  8.43it/s] 61%|██████    | 585/966 [01:09<00:45,  8.44it/s] 61%|██████    | 586/966 [01:09<00:44,  8.45it/s] 61%|██████    | 587/966 [01:09<00:44,  8.46it/s] 61%|██████    | 588/966 [01:09<00:44,  8.47it/s] 61%|██████    | 589/966 [01:09<00:44,  8.46it/s] 61%|██████    | 590/966 [01:09<00:44,  8.47it/s] 61%|██████    | 591/966 [01:09<00:44,  8.47it/s] 61%|██████▏   | 592/966 [01:09<00:44,  8.47it/s] 61%|██████▏   | 593/966 [01:10<00:44,  8.46it/s] 61%|██████▏   | 594/966 [01:10<00:43,  8.47it/s] 62%|██████▏   | 595/966 [01:10<00:43,  8.48it/s] 62%|██████▏   | 596/966 [01:10<00:43,  8.46it/s] 62%|██████▏   | 597/966 [01:10<00:43,  8.48it/s] 62%|██████▏   | 598/966 [01:10<00:43,  8.48it/s] 62%|██████▏   | 599/966 [01:10<00:43,  8.47it/s] 62%|██████▏   | 600/966 [01:10<00:43,  8.46it/s] 62%|██████▏   | 601/966 [01:10<00:43,  8.44it/s] 62%|██████▏   | 602/966 [01:11<00:43,  8.43it/s] 62%|██████▏   | 603/966 [01:11<00:43,  8.43it/s] 63%|██████▎   | 604/966 [01:11<00:42,  8.43it/s] 63%|██████▎   | 605/966 [01:11<00:42,  8.44it/s] 63%|██████▎   | 606/966 [01:11<00:42,  8.44it/s] 63%|██████▎   | 607/966 [01:11<00:42,  8.46it/s] 63%|██████▎   | 608/966 [01:11<00:42,  8.45it/s] 63%|██████▎   | 609/966 [01:11<00:42,  8.45it/s] 63%|██████▎   | 610/966 [01:12<00:42,  8.45it/s] 63%|██████▎   | 611/966 [01:12<00:41,  8.46it/s] 63%|██████▎   | 612/966 [01:12<00:41,  8.46it/s] 63%|██████▎   | 613/966 [01:12<00:41,  8.46it/s] 64%|██████▎   | 614/966 [01:12<00:41,  8.47it/s] 64%|██████▎   | 615/966 [01:12<00:41,  8.47it/s] 64%|██████▍   | 616/966 [01:12<00:41,  8.45it/s] 64%|██████▍   | 617/966 [01:12<00:41,  8.45it/s] 64%|██████▍   | 618/966 [01:13<00:41,  8.44it/s] 64%|██████▍   | 619/966 [01:13<00:41,  8.44it/s] 64%|██████▍   | 620/966 [01:13<00:40,  8.45it/s] 64%|██████▍   | 621/966 [01:13<00:40,  8.44it/s] 64%|██████▍   | 622/966 [01:13<00:40,  8.44it/s] 64%|██████▍   | 623/966 [01:13<00:40,  8.44it/s] 65%|██████▍   | 624/966 [01:13<00:40,  8.44it/s] 65%|██████▍   | 625/966 [01:13<00:40,  8.45it/s] 65%|██████▍   | 626/966 [01:13<00:40,  8.46it/s] 65%|██████▍   | 627/966 [01:14<00:40,  8.45it/s] 65%|██████▌   | 628/966 [01:14<00:39,  8.45it/s] 65%|██████▌   | 629/966 [01:14<00:39,  8.45it/s] 65%|██████▌   | 630/966 [01:14<00:39,  8.46it/s] 65%|██████▌   | 631/966 [01:14<00:39,  8.47it/s] 65%|██████▌   | 632/966 [01:14<00:39,  8.48it/s] 66%|██████▌   | 633/966 [01:14<00:39,  8.48it/s] 66%|██████▌   | 634/966 [01:14<00:39,  8.47it/s] 66%|██████▌   | 635/966 [01:15<00:39,  8.45it/s] 66%|██████▌   | 636/966 [01:15<00:39,  8.45it/s] 66%|██████▌   | 637/966 [01:15<00:38,  8.45it/s] 66%|██████▌   | 638/966 [01:15<00:38,  8.45it/s] 66%|██████▌   | 639/966 [01:15<00:38,  8.45it/s] 66%|██████▋   | 640/966 [01:15<00:38,  8.45it/s] 66%|██████▋   | 641/966 [01:15<00:38,  8.46it/s] 66%|██████▋   | 642/966 [01:15<00:38,  8.47it/s] 67%|██████▋   | 643/966 [01:15<00:38,  8.46it/s] 67%|██████▋   | 644/966 [01:16<00:38,  8.45it/s] 67%|██████▋   | 645/966 [01:16<00:38,  8.44it/s] 67%|██████▋   | 646/966 [01:16<00:37,  8.44it/s] 67%|██████▋   | 647/966 [01:16<00:37,  8.44it/s] 67%|██████▋   | 648/966 [01:16<00:37,  8.45it/s] 67%|██████▋   | 649/966 [01:16<00:37,  8.46it/s] 67%|██████▋   | 650/966 [01:16<00:37,  8.45it/s] 67%|██████▋   | 651/966 [01:16<00:37,  8.45it/s] 67%|██████▋   | 652/966 [01:17<00:37,  8.45it/s] 68%|██████▊   | 653/966 [01:17<00:37,  8.46it/s] 68%|██████▊   | 654/966 [01:17<00:36,  8.47it/s] 68%|██████▊   | 655/966 [01:17<00:36,  8.47it/s] 68%|██████▊   | 656/966 [01:17<00:36,  8.45it/s] 68%|██████▊   | 657/966 [01:17<00:36,  8.44it/s] 68%|██████▊   | 658/966 [01:17<00:36,  8.45it/s] 68%|██████▊   | 659/966 [01:17<00:36,  8.44it/s] 68%|██████▊   | 660/966 [01:17<00:36,  8.44it/s] 68%|██████▊   | 661/966 [01:18<00:36,  8.44it/s] 69%|██████▊   | 662/966 [01:18<00:36,  8.44it/s] 69%|██████▊   | 663/966 [01:18<00:35,  8.44it/s] 69%|██████▊   | 664/966 [01:18<00:35,  8.45it/s] 69%|██████▉   | 665/966 [01:18<00:35,  8.46it/s] 69%|██████▉   | 666/966 [01:18<00:35,  8.47it/s] 69%|██████▉   | 667/966 [01:18<00:35,  8.49it/s] 69%|██████▉   | 668/966 [01:18<00:35,  8.49it/s] 69%|██████▉   | 669/966 [01:19<00:35,  8.48it/s] 69%|██████▉   | 670/966 [01:19<00:34,  8.47it/s] 69%|██████▉   | 671/966 [01:19<00:34,  8.48it/s] 70%|██████▉   | 672/966 [01:19<00:34,  8.48it/s] 70%|██████▉   | 673/966 [01:19<00:34,  8.49it/s] 70%|██████▉   | 674/966 [01:19<00:34,  8.49it/s] 70%|██████▉   | 675/966 [01:19<00:34,  8.50it/s] 70%|██████▉   | 676/966 [01:19<00:34,  8.48it/s] 70%|███████   | 677/966 [01:19<00:34,  8.46it/s] 70%|███████   | 678/966 [01:20<00:33,  8.47it/s] 70%|███████   | 679/966 [01:20<00:33,  8.47it/s] 70%|███████   | 680/966 [01:20<00:33,  8.46it/s] 70%|███████   | 681/966 [01:20<00:33,  8.47it/s] 71%|███████   | 682/966 [01:20<00:33,  8.47it/s] 71%|███████   | 683/966 [01:20<00:33,  8.46it/s] 71%|███████   | 684/966 [01:20<00:33,  8.47it/s] 71%|███████   | 685/966 [01:20<00:33,  8.46it/s] 71%|███████   | 686/966 [01:21<00:33,  8.45it/s] 71%|███████   | 687/966 [01:21<00:32,  8.46it/s] 71%|███████   | 688/966 [01:21<00:32,  8.46it/s] 71%|███████▏  | 689/966 [01:21<00:32,  8.47it/s] 71%|███████▏  | 690/966 [01:21<00:32,  8.48it/s] 72%|███████▏  | 691/966 [01:21<00:32,  8.48it/s] 72%|███████▏  | 692/966 [01:21<00:32,  8.47it/s] 72%|███████▏  | 693/966 [01:21<00:32,  8.46it/s] 72%|███████▏  | 694/966 [01:21<00:32,  8.45it/s] 72%|███████▏  | 695/966 [01:22<00:32,  8.44it/s] 72%|███████▏  | 696/966 [01:22<00:31,  8.44it/s] 72%|███████▏  | 697/966 [01:22<00:31,  8.43it/s] 72%|███████▏  | 698/966 [01:22<00:31,  8.44it/s] 72%|███████▏  | 699/966 [01:22<00:31,  8.43it/s] 72%|███████▏  | 700/966 [01:22<00:31,  8.43it/s] 73%|███████▎  | 701/966 [01:22<00:31,  8.44it/s] 73%|███████▎  | 702/966 [01:22<00:31,  8.45it/s] 73%|███████▎  | 703/966 [01:23<00:31,  8.47it/s] 73%|███████▎  | 704/966 [01:23<00:30,  8.47it/s] 73%|███████▎  | 705/966 [01:23<00:30,  8.46it/s] 73%|███████▎  | 706/966 [01:23<00:30,  8.45it/s] 73%|███████▎  | 707/966 [01:23<00:30,  8.45it/s] 73%|███████▎  | 708/966 [01:23<00:30,  8.44it/s] 73%|███████▎  | 709/966 [01:23<00:30,  8.44it/s] 73%|███████▎  | 710/966 [01:23<00:30,  8.46it/s] 74%|███████▎  | 711/966 [01:24<00:30,  8.46it/s] 74%|███████▎  | 712/966 [01:24<00:30,  8.45it/s] 74%|███████▍  | 713/966 [01:24<00:29,  8.45it/s] 74%|███████▍  | 714/966 [01:24<00:29,  8.45it/s] 74%|███████▍  | 715/966 [01:24<00:29,  8.44it/s] 74%|███████▍  | 716/966 [01:24<00:29,  8.44it/s] 74%|███████▍  | 717/966 [01:24<00:29,  8.44it/s] 74%|███████▍  | 718/966 [01:24<00:29,  8.44it/s] 74%|███████▍  | 719/966 [01:24<00:29,  8.43it/s] 75%|███████▍  | 720/966 [01:25<00:29,  8.43it/s] 75%|███████▍  | 721/966 [01:25<00:28,  8.46it/s] 75%|███████▍  | 722/966 [01:25<00:28,  8.49it/s] 75%|███████▍  | 723/966 [01:25<00:28,  8.49it/s] 75%|███████▍  | 724/966 [01:25<00:28,  8.48it/s] 75%|███████▌  | 725/966 [01:25<00:28,  8.49it/s] 75%|███████▌  | 726/966 [01:25<00:28,  8.49it/s] 75%|███████▌  | 727/966 [01:25<00:28,  8.48it/s] 75%|███████▌  | 728/966 [01:26<00:28,  8.47it/s] 75%|███████▌  | 729/966 [01:26<00:28,  8.46it/s] 76%|███████▌  | 730/966 [01:26<00:27,  8.45it/s] 76%|███████▌  | 731/966 [01:26<00:27,  8.44it/s] 76%|███████▌  | 732/966 [01:26<00:27,  8.45it/s] 76%|███████▌  | 733/966 [01:26<00:27,  8.45it/s] 76%|███████▌  | 734/966 [01:26<00:27,  8.44it/s] 76%|███████▌  | 735/966 [01:26<00:27,  8.44it/s] 76%|███████▌  | 736/966 [01:26<00:27,  8.44it/s] 76%|███████▋  | 737/966 [01:27<00:27,  8.45it/s] 76%|███████▋  | 738/966 [01:27<00:26,  8.45it/s] 77%|███████▋  | 739/966 [01:27<00:26,  8.45it/s] 77%|███████▋  | 740/966 [01:27<00:26,  8.44it/s] 77%|███████▋  | 741/966 [01:27<00:26,  8.43it/s] 77%|███████▋  | 742/966 [01:27<00:26,  8.43it/s] 77%|███████▋  | 743/966 [01:27<00:26,  8.43it/s] 77%|███████▋  | 744/966 [01:27<00:26,  8.43it/s] 77%|███████▋  | 745/966 [01:28<00:26,  8.43it/s] 77%|███████▋  | 746/966 [01:28<00:26,  8.43it/s] 77%|███████▋  | 747/966 [01:28<00:25,  8.43it/s] 77%|███████▋  | 748/966 [01:28<00:25,  8.45it/s] 78%|███████▊  | 749/966 [01:28<00:25,  8.45it/s] 78%|███████▊  | 750/966 [01:28<00:25,  8.45it/s] 78%|███████▊  | 751/966 [01:28<00:25,  8.48it/s] 78%|███████▊  | 752/966 [01:28<00:25,  8.48it/s] 78%|███████▊  | 753/966 [01:28<00:25,  8.47it/s] 78%|███████▊  | 754/966 [01:29<00:25,  8.46it/s] 78%|███████▊  | 755/966 [01:29<00:24,  8.45it/s] 78%|███████▊  | 756/966 [01:29<00:24,  8.45it/s] 78%|███████▊  | 757/966 [01:29<00:24,  8.45it/s] 78%|███████▊  | 758/966 [01:29<00:24,  8.46it/s] 79%|███████▊  | 759/966 [01:29<00:24,  8.48it/s] 79%|███████▊  | 760/966 [01:29<00:24,  8.47it/s] 79%|███████▉  | 761/966 [01:29<00:24,  8.47it/s] 79%|███████▉  | 762/966 [01:30<00:24,  8.48it/s] 79%|███████▉  | 763/966 [01:30<00:23,  8.48it/s] 79%|███████▉  | 764/966 [01:30<00:23,  8.49it/s] 79%|███████▉  | 765/966 [01:30<00:23,  8.50it/s] 79%|███████▉  | 766/966 [01:30<00:23,  8.49it/s] 79%|███████▉  | 767/966 [01:30<00:23,  8.49it/s] 80%|███████▉  | 768/966 [01:30<00:23,  8.48it/s] 80%|███████▉  | 769/966 [01:30<00:23,  8.46it/s] 80%|███████▉  | 770/966 [01:30<00:23,  8.46it/s] 80%|███████▉  | 771/966 [01:31<00:23,  8.45it/s] 80%|███████▉  | 772/966 [01:31<00:22,  8.46it/s] 80%|████████  | 773/966 [01:31<00:22,  8.47it/s] 80%|████████  | 774/966 [01:31<00:22,  8.48it/s] 80%|████████  | 775/966 [01:31<00:22,  8.47it/s] 80%|████████  | 776/966 [01:31<00:22,  8.47it/s] 80%|████████  | 777/966 [01:31<00:22,  8.46it/s] 81%|████████  | 778/966 [01:31<00:22,  8.46it/s] 81%|████████  | 779/966 [01:32<00:22,  8.46it/s] 81%|████████  | 780/966 [01:32<00:22,  8.45it/s] 81%|████████  | 781/966 [01:32<00:21,  8.46it/s] 81%|████████  | 782/966 [01:32<00:21,  8.47it/s] 81%|████████  | 783/966 [01:32<00:21,  8.48it/s] 81%|████████  | 784/966 [01:32<00:21,  8.47it/s] 81%|████████▏ | 785/966 [01:32<00:21,  8.47it/s] 81%|████████▏ | 786/966 [01:32<00:21,  8.46it/s] 81%|████████▏ | 787/966 [01:32<00:21,  8.47it/s] 82%|████████▏ | 788/966 [01:33<00:21,  8.48it/s] 82%|████████▏ | 789/966 [01:33<00:20,  8.48it/s] 82%|████████▏ | 790/966 [01:33<00:20,  8.46it/s] 82%|████████▏ | 791/966 [01:33<00:20,  8.45it/s] 82%|████████▏ | 792/966 [01:33<00:20,  8.45it/s] 82%|████████▏ | 793/966 [01:33<00:20,  8.44it/s] 82%|████████▏ | 794/966 [01:33<00:20,  8.44it/s] 82%|████████▏ | 795/966 [01:33<00:20,  8.43it/s] 82%|████████▏ | 796/966 [01:34<00:20,  8.44it/s] 83%|████████▎ | 797/966 [01:34<00:20,  8.44it/s] 83%|████████▎ | 798/966 [01:34<00:19,  8.44it/s] 83%|████████▎ | 799/966 [01:34<00:19,  8.46it/s] 83%|████████▎ | 800/966 [01:34<00:19,  8.47it/s] 83%|████████▎ | 801/966 [01:34<00:19,  8.48it/s] 83%|████████▎ | 802/966 [01:34<00:19,  8.48it/s] 83%|████████▎ | 803/966 [01:34<00:19,  8.47it/s] 83%|████████▎ | 804/966 [01:35<00:19,  8.46it/s] 83%|████████▎ | 805/966 [01:35<00:19,  8.47it/s] 83%|████████▎ | 806/966 [01:35<00:18,  8.48it/s] 84%|████████▎ | 807/966 [01:35<00:18,  8.47it/s] 84%|████████▎ | 808/966 [01:35<00:18,  8.47it/s] 84%|████████▎ | 809/966 [01:35<00:18,  8.46it/s] 84%|████████▍ | 810/966 [01:35<00:18,  8.46it/s] 84%|████████▍ | 811/966 [01:35<00:18,  8.45it/s] 84%|████████▍ | 812/966 [01:35<00:18,  8.46it/s] 84%|████████▍ | 813/966 [01:36<00:18,  8.46it/s] 84%|████████▍ | 814/966 [01:36<00:17,  8.47it/s] 84%|████████▍ | 815/966 [01:36<00:17,  8.46it/s] 84%|████████▍ | 816/966 [01:36<00:17,  8.46it/s] 85%|████████▍ | 817/966 [01:36<00:17,  8.44it/s] 85%|████████▍ | 818/966 [01:36<00:17,  8.44it/s] 85%|████████▍ | 819/966 [01:36<00:17,  8.44it/s] 85%|████████▍ | 820/966 [01:36<00:17,  8.43it/s] 85%|████████▍ | 821/966 [01:37<00:17,  8.43it/s] 85%|████████▌ | 822/966 [01:37<00:17,  8.44it/s] 85%|████████▌ | 823/966 [01:37<00:16,  8.43it/s] 85%|████████▌ | 824/966 [01:37<00:16,  8.43it/s] 85%|████████▌ | 825/966 [01:37<00:16,  8.43it/s] 86%|████████▌ | 826/966 [01:37<00:16,  8.42it/s] 86%|████████▌ | 827/966 [01:37<00:16,  8.42it/s] 86%|████████▌ | 828/966 [01:37<00:16,  8.43it/s] 86%|████████▌ | 829/966 [01:37<00:16,  8.44it/s] 86%|████████▌ | 830/966 [01:38<00:16,  8.45it/s] 86%|████████▌ | 831/966 [01:38<00:15,  8.46it/s] 86%|████████▌ | 832/966 [01:38<00:15,  8.46it/s] 86%|████████▌ | 833/966 [01:38<00:15,  8.46it/s] 86%|████████▋ | 834/966 [01:38<00:15,  8.47it/s] 86%|████████▋ | 835/966 [01:38<00:15,  8.50it/s] 87%|████████▋ | 836/966 [01:38<00:15,  8.48it/s] 87%|████████▋ | 837/966 [01:38<00:15,  8.48it/s] 87%|████████▋ | 838/966 [01:39<00:15,  8.47it/s] 87%|████████▋ | 839/966 [01:39<00:15,  8.45it/s] 87%|████████▋ | 840/966 [01:39<00:14,  8.44it/s] 87%|████████▋ | 841/966 [01:39<00:14,  8.43it/s] 87%|████████▋ | 842/966 [01:39<00:14,  8.45it/s] 87%|████████▋ | 843/966 [01:39<00:14,  8.44it/s] 87%|████████▋ | 844/966 [01:39<00:14,  8.44it/s] 87%|████████▋ | 845/966 [01:39<00:14,  8.45it/s] 88%|████████▊ | 846/966 [01:39<00:14,  8.45it/s] 88%|████████▊ | 847/966 [01:40<00:14,  8.46it/s] 88%|████████▊ | 848/966 [01:40<00:13,  8.47it/s] 88%|████████▊ | 849/966 [01:40<00:13,  8.47it/s] 88%|████████▊ | 850/966 [01:40<00:13,  8.46it/s] 88%|████████▊ | 851/966 [01:40<00:13,  8.46it/s] 88%|████████▊ | 852/966 [01:40<00:13,  8.46it/s] 88%|████████▊ | 853/966 [01:40<00:13,  8.45it/s] 88%|████████▊ | 854/966 [01:40<00:13,  8.44it/s] 89%|████████▊ | 855/966 [01:41<00:13,  8.45it/s] 89%|████████▊ | 856/966 [01:41<00:13,  8.45it/s] 89%|████████▊ | 857/966 [01:41<00:12,  8.45it/s] 89%|████████▉ | 858/966 [01:41<00:12,  8.44it/s] 89%|████████▉ | 859/966 [01:41<00:12,  8.45it/s] 89%|████████▉ | 860/966 [01:41<00:12,  8.44it/s] 89%|████████▉ | 861/966 [01:41<00:12,  8.44it/s] 89%|████████▉ | 862/966 [01:41<00:12,  8.43it/s] 89%|████████▉ | 863/966 [01:41<00:12,  8.44it/s] 89%|████████▉ | 864/966 [01:42<00:12,  8.43it/s] 90%|████████▉ | 865/966 [01:42<00:11,  8.44it/s] 90%|████████▉ | 866/966 [01:42<00:11,  8.44it/s] 90%|████████▉ | 867/966 [01:42<00:11,  8.46it/s] 90%|████████▉ | 868/966 [01:42<00:11,  8.46it/s] 90%|████████▉ | 869/966 [01:42<00:11,  8.46it/s] 90%|█████████ | 870/966 [01:42<00:11,  8.47it/s] 90%|█████████ | 871/966 [01:42<00:11,  8.48it/s] 90%|█████████ | 872/966 [01:43<00:11,  8.46it/s] 90%|█████████ | 873/966 [01:43<00:10,  8.46it/s] 90%|█████████ | 874/966 [01:43<00:10,  8.46it/s] 91%|█████████ | 875/966 [01:43<00:10,  8.44it/s] 91%|█████████ | 876/966 [01:43<00:10,  8.44it/s] 91%|█████████ | 877/966 [01:43<00:10,  8.46it/s] 91%|█████████ | 878/966 [01:43<00:10,  8.47it/s] 91%|█████████ | 879/966 [01:43<00:10,  8.45it/s] 91%|█████████ | 880/966 [01:43<00:10,  8.45it/s] 91%|█████████ | 881/966 [01:44<00:10,  8.44it/s] 91%|█████████▏| 882/966 [01:44<00:09,  8.45it/s] 91%|█████████▏| 883/966 [01:44<00:09,  8.46it/s] 92%|█████████▏| 884/966 [01:44<00:09,  8.47it/s] 92%|█████████▏| 885/966 [01:44<00:09,  8.46it/s] 92%|█████████▏| 886/966 [01:44<00:09,  8.45it/s] 92%|█████████▏| 887/966 [01:44<00:09,  8.45it/s] 92%|█████████▏| 888/966 [01:44<00:09,  8.46it/s] 92%|█████████▏| 889/966 [01:45<00:09,  8.47it/s] 92%|█████████▏| 890/966 [01:45<00:08,  8.45it/s] 92%|█████████▏| 891/966 [01:45<00:08,  8.46it/s] 92%|█████████▏| 892/966 [01:45<00:08,  8.46it/s] 92%|█████████▏| 893/966 [01:45<00:08,  8.46it/s] 93%|█████████▎| 894/966 [01:45<00:08,  8.47it/s] 93%|█████████▎| 895/966 [01:45<00:08,  8.45it/s] 93%|█████████▎| 896/966 [01:45<00:08,  8.45it/s] 93%|█████████▎| 897/966 [01:46<00:08,  8.44it/s] 93%|█████████▎| 898/966 [01:46<00:08,  8.45it/s] 93%|█████████▎| 899/966 [01:46<00:07,  8.46it/s] 93%|█████████▎| 900/966 [01:46<00:07,  8.47it/s] 93%|█████████▎| 901/966 [01:46<00:07,  8.47it/s] 93%|█████████▎| 902/966 [01:46<00:07,  8.48it/s] 93%|█████████▎| 903/966 [01:46<00:07,  8.46it/s] 94%|█████████▎| 904/966 [01:46<00:07,  8.45it/s] 94%|█████████▎| 905/966 [01:46<00:07,  8.44it/s] 94%|█████████▍| 906/966 [01:47<00:07,  8.44it/s] 94%|█████████▍| 907/966 [01:47<00:06,  8.45it/s] 94%|█████████▍| 908/966 [01:47<00:06,  8.44it/s] 94%|█████████▍| 909/966 [01:47<00:06,  8.44it/s] 94%|█████████▍| 910/966 [01:47<00:06,  8.44it/s] 94%|█████████▍| 911/966 [01:47<00:06,  8.45it/s] 94%|█████████▍| 912/966 [01:47<00:06,  8.45it/s] 95%|█████████▍| 913/966 [01:47<00:06,  8.45it/s] 95%|█████████▍| 914/966 [01:48<00:06,  8.46it/s] 95%|█████████▍| 915/966 [01:48<00:06,  8.45it/s] 95%|█████████▍| 916/966 [01:48<00:05,  8.44it/s] 95%|█████████▍| 917/966 [01:48<00:05,  8.44it/s] 95%|█████████▌| 918/966 [01:48<00:05,  8.44it/s] 95%|█████████▌| 919/966 [01:48<00:05,  8.45it/s] 95%|█████████▌| 920/966 [01:48<00:05,  8.46it/s] 95%|█████████▌| 921/966 [01:48<00:05,  8.47it/s] 95%|█████████▌| 922/966 [01:48<00:05,  8.46it/s] 96%|█████████▌| 923/966 [01:49<00:05,  8.47it/s] 96%|█████████▌| 924/966 [01:49<00:04,  8.47it/s] 96%|█████████▌| 925/966 [01:49<00:04,  8.48it/s] 96%|█████████▌| 926/966 [01:49<00:04,  8.51it/s] 96%|█████████▌| 927/966 [01:49<00:04,  8.51it/s] 96%|█████████▌| 928/966 [01:49<00:04,  8.49it/s] 96%|█████████▌| 929/966 [01:49<00:04,  8.46it/s] 96%|█████████▋| 930/966 [01:49<00:04,  8.44it/s] 96%|█████████▋| 931/966 [01:50<00:04,  8.45it/s] 96%|█████████▋| 932/966 [01:50<00:04,  8.46it/s] 97%|█████████▋| 933/966 [01:50<00:03,  8.47it/s] 97%|█████████▋| 934/966 [01:50<00:03,  8.47it/s] 97%|█████████▋| 935/966 [01:50<00:03,  8.46it/s] 97%|█████████▋| 936/966 [01:50<00:03,  8.46it/s] 97%|█████████▋| 937/966 [01:50<00:03,  8.45it/s] 97%|█████████▋| 938/966 [01:50<00:03,  8.45it/s] 97%|█████████▋| 939/966 [01:50<00:03,  8.45it/s] 97%|█████████▋| 940/966 [01:51<00:03,  8.46it/s] 97%|█████████▋| 941/966 [01:51<00:02,  8.46it/s] 98%|█████████▊| 942/966 [01:51<00:02,  8.47it/s] 98%|█████████▊| 943/966 [01:51<00:02,  8.45it/s] 98%|█████████▊| 944/966 [01:51<00:02,  8.43it/s] 98%|█████████▊| 945/966 [01:51<00:02,  8.44it/s] 98%|█████████▊| 946/966 [01:51<00:02,  8.43it/s] 98%|█████████▊| 947/966 [01:51<00:02,  8.45it/s] 98%|█████████▊| 948/966 [01:52<00:02,  8.45it/s] 98%|█████████▊| 949/966 [01:52<00:02,  8.46it/s] 98%|█████████▊| 950/966 [01:52<00:01,  8.45it/s] 98%|█████████▊| 951/966 [01:52<00:01,  8.44it/s] 99%|█████████▊| 952/966 [01:52<00:01,  8.44it/s] 99%|█████████▊| 953/966 [01:52<00:01,  8.44it/s] 99%|█████████▉| 954/966 [01:52<00:01,  8.44it/s] 99%|█████████▉| 955/966 [01:52<00:01,  8.44it/s] 99%|█████████▉| 956/966 [01:52<00:01,  8.45it/s] 99%|█████████▉| 957/966 [01:53<00:01,  8.46it/s] 99%|█████████▉| 958/966 [01:53<00:00,  8.45it/s] 99%|█████████▉| 959/966 [01:53<00:00,  8.45it/s] 99%|█████████▉| 960/966 [01:53<00:00,  8.47it/s] 99%|█████████▉| 961/966 [01:53<00:00,  8.48it/s]100%|█████████▉| 962/966 [01:53<00:00,  8.48it/s]100%|█████████▉| 963/966 [01:53<00:00,  8.48it/s]100%|█████████▉| 964/966 [01:53<00:00,  8.47it/s]100%|█████████▉| 965/966 [01:54<00:00,  8.47it/s]100%|██████████| 966/966 [01:54<00:00,  8.48it/s]100%|██████████| 966/966 [01:54<00:00,  8.46it/s]
sending off prediction to background worker for resampling and export
done with 706-005
