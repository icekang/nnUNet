/home/gridsan/nchutisilp/.conda/envs/nnunet/bin/python
wandb: Tracking run with wandb version 0.16.6
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2024-05-09 19:24:55.458773: do_dummy_2d_data_aug: True
2024-05-09 19:24:55.463038: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset302_Calcium_OCTv2/splits_final.json
2024-05-09 19:24:55.465603: The split file contains 3 splits.
2024-05-09 19:24:55.467485: Desired fold for training: 1
2024-05-09 19:24:55.469450: This split has 4 training and 2 validation cases.
using pin_memory on device 0
using pin_memory on device 0
2024-05-09 19:25:10.022579: Using torch.compile...
/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "

This is the configuration used by this training:
Configuration name: 3d_32x512x512_b2
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [32, 512, 512], 'median_image_size_in_voxels': [375.0, 498.0, 498.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'inherits_from': '3d_fullres'} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset302_Calcium_OCTv2', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.4977976381778717, 'mean': 0.13332499563694, 'median': 0.08871842920780182, 'min': 0.0, 'percentile_00_5': 0.014754901640117168, 'percentile_99_5': 0.4977976381778717, 'std': 0.12022686749696732}}} 

2024-05-09 19:25:20.946204: unpacking dataset...
2024-05-09 19:25:25.835166: unpacking done...
2024-05-09 19:25:26.117979: Unable to plot network architecture: nnUNet_compile is enabled!
2024-05-09 19:25:26.210704: 
2024-05-09 19:25:26.212435: Epoch 0
2024-05-09 19:25:26.214310: Current learning rate: 0.01
2024-05-09 19:31:46.404848: Validation loss improved from 1000.00000 to -0.27852! Patience: 0/50
2024-05-09 19:31:46.406715: train_loss -0.2048
2024-05-09 19:31:46.408151: val_loss -0.2785
2024-05-09 19:31:46.409382: Pseudo dice [0.4894]
2024-05-09 19:31:46.410692: Epoch time: 380.2 s
2024-05-09 19:31:46.411800: Yayy! New best EMA pseudo Dice: 0.4894
2024-05-09 19:31:48.360733: 
2024-05-09 19:31:48.362463: Epoch 1
2024-05-09 19:31:48.363910: Current learning rate: 0.00999
2024-05-09 19:36:07.508515: Validation loss improved from -0.27852 to -0.35851! Patience: 0/50
2024-05-09 19:36:07.510183: train_loss -0.3183
2024-05-09 19:36:07.511530: val_loss -0.3585
2024-05-09 19:36:07.512799: Pseudo dice [0.5348]
2024-05-09 19:36:07.514046: Epoch time: 259.15 s
2024-05-09 19:36:07.515181: Yayy! New best EMA pseudo Dice: 0.4939
2024-05-09 19:36:09.396488: 
2024-05-09 19:36:09.398436: Epoch 2
2024-05-09 19:36:09.399728: Current learning rate: 0.00998
2024-05-09 19:40:27.982735: Validation loss improved from -0.35851 to -0.37103! Patience: 0/50
2024-05-09 19:40:27.984258: train_loss -0.3563
2024-05-09 19:40:27.985588: val_loss -0.371
2024-05-09 19:40:27.986750: Pseudo dice [0.5465]
2024-05-09 19:40:27.987848: Epoch time: 258.59 s
2024-05-09 19:40:27.988859: Yayy! New best EMA pseudo Dice: 0.4992
2024-05-09 19:40:29.986092: 
2024-05-09 19:40:29.987875: Epoch 3
2024-05-09 19:40:29.988984: Current learning rate: 0.00997
2024-05-09 19:44:54.558981: Validation loss improved from -0.37103 to -0.38328! Patience: 0/50
2024-05-09 19:44:54.560436: train_loss -0.4025
2024-05-09 19:44:54.561610: val_loss -0.3833
2024-05-09 19:44:54.562708: Pseudo dice [0.5885]
2024-05-09 19:44:54.563688: Epoch time: 264.58 s
2024-05-09 19:44:54.564584: Yayy! New best EMA pseudo Dice: 0.5081
2024-05-09 19:44:56.405358: 
2024-05-09 19:44:56.406999: Epoch 4
2024-05-09 19:44:56.408197: Current learning rate: 0.00996
2024-05-09 19:49:19.229362: Validation loss did not improve from -0.38328. Patience: 1/50
2024-05-09 19:49:19.231165: train_loss -0.4308
2024-05-09 19:49:19.232814: val_loss -0.3378
2024-05-09 19:49:19.234033: Pseudo dice [0.5419]
2024-05-09 19:49:19.235608: Epoch time: 262.83 s
2024-05-09 19:49:19.594339: Yayy! New best EMA pseudo Dice: 0.5115
2024-05-09 19:49:21.537554: 
2024-05-09 19:49:21.539249: Epoch 5
2024-05-09 19:49:21.540351: Current learning rate: 0.00995
2024-05-09 19:53:44.588303: Validation loss improved from -0.38328 to -0.39188! Patience: 1/50
2024-05-09 19:53:44.589626: train_loss -0.4738
2024-05-09 19:53:44.591095: val_loss -0.3919
2024-05-09 19:53:44.592170: Pseudo dice [0.5836]
2024-05-09 19:53:44.593194: Epoch time: 263.05 s
2024-05-09 19:53:44.594368: Yayy! New best EMA pseudo Dice: 0.5187
2024-05-09 19:53:46.354439: 
2024-05-09 19:53:46.356179: Epoch 6
2024-05-09 19:53:46.357378: Current learning rate: 0.00995
2024-05-09 19:58:15.283244: Validation loss improved from -0.39188 to -0.40680! Patience: 0/50
2024-05-09 19:58:15.284572: train_loss -0.5122
2024-05-09 19:58:15.285645: val_loss -0.4068
2024-05-09 19:58:15.286607: Pseudo dice [0.603]
2024-05-09 19:58:15.287568: Epoch time: 268.93 s
2024-05-09 19:58:15.288718: Yayy! New best EMA pseudo Dice: 0.5271
2024-05-09 19:58:17.078463: 
2024-05-09 19:58:17.080060: Epoch 7
2024-05-09 19:58:17.081155: Current learning rate: 0.00994
2024-05-09 20:02:34.789358: Validation loss did not improve from -0.40680. Patience: 1/50
2024-05-09 20:02:34.790912: train_loss -0.5322
2024-05-09 20:02:34.792247: val_loss -0.3637
2024-05-09 20:02:34.793493: Pseudo dice [0.5601]
2024-05-09 20:02:34.794704: Epoch time: 257.71 s
2024-05-09 20:02:34.795785: Yayy! New best EMA pseudo Dice: 0.5304
2024-05-09 20:02:37.076804: 
2024-05-09 20:02:37.078279: Epoch 8
2024-05-09 20:02:37.079312: Current learning rate: 0.00993
2024-05-09 20:07:07.454415: Validation loss improved from -0.40680 to -0.49848! Patience: 1/50
2024-05-09 20:07:07.457425: train_loss -0.5099
2024-05-09 20:07:07.458861: val_loss -0.4985
2024-05-09 20:07:07.460038: Pseudo dice [0.6629]
2024-05-09 20:07:07.461272: Epoch time: 270.38 s
2024-05-09 20:07:07.462362: Yayy! New best EMA pseudo Dice: 0.5437
2024-05-09 20:07:09.434415: 
2024-05-09 20:07:09.437984: Epoch 9
2024-05-09 20:07:09.439333: Current learning rate: 0.00992
2024-05-09 20:11:37.591611: Validation loss did not improve from -0.49848. Patience: 1/50
2024-05-09 20:11:37.593153: train_loss -0.5597
2024-05-09 20:11:37.594611: val_loss -0.4939
2024-05-09 20:11:37.595861: Pseudo dice [0.6651]
2024-05-09 20:11:37.597212: Epoch time: 268.17 s
2024-05-09 20:11:38.045684: Yayy! New best EMA pseudo Dice: 0.5558
2024-05-09 20:11:39.811938: 
2024-05-09 20:11:39.813677: Epoch 10
2024-05-09 20:11:39.814844: Current learning rate: 0.00991
2024-05-09 20:16:09.026823: Validation loss improved from -0.49848 to -0.50915! Patience: 1/50
2024-05-09 20:16:09.028574: train_loss -0.5465
2024-05-09 20:16:09.030012: val_loss -0.5091
2024-05-09 20:16:09.031268: Pseudo dice [0.6785]
2024-05-09 20:16:09.032441: Epoch time: 269.22 s
2024-05-09 20:16:09.033674: Yayy! New best EMA pseudo Dice: 0.5681
2024-05-09 20:16:10.815679: 
2024-05-09 20:16:10.817323: Epoch 11
2024-05-09 20:16:10.818458: Current learning rate: 0.0099
2024-05-09 20:20:40.487425: Validation loss improved from -0.50915 to -0.51936! Patience: 0/50
2024-05-09 20:20:40.489113: train_loss -0.5696
2024-05-09 20:20:40.490358: val_loss -0.5194
2024-05-09 20:20:40.491343: Pseudo dice [0.668]
2024-05-09 20:20:40.492553: Epoch time: 269.68 s
2024-05-09 20:20:40.493613: Yayy! New best EMA pseudo Dice: 0.5781
2024-05-09 20:20:42.330199: 
2024-05-09 20:20:42.331787: Epoch 12
2024-05-09 20:20:42.332955: Current learning rate: 0.00989
2024-05-09 20:25:10.942170: Validation loss did not improve from -0.51936. Patience: 1/50
2024-05-09 20:25:10.944039: train_loss -0.5785
2024-05-09 20:25:10.945230: val_loss -0.486
2024-05-09 20:25:10.946492: Pseudo dice [0.6335]
2024-05-09 20:25:10.947535: Epoch time: 268.62 s
2024-05-09 20:25:10.948708: Yayy! New best EMA pseudo Dice: 0.5836
2024-05-09 20:25:12.759405: 
2024-05-09 20:25:12.761259: Epoch 13
2024-05-09 20:25:12.762345: Current learning rate: 0.00988
2024-05-09 20:29:40.370526: Validation loss did not improve from -0.51936. Patience: 2/50
2024-05-09 20:29:40.372320: train_loss -0.6181
2024-05-09 20:29:40.373632: val_loss -0.4553
2024-05-09 20:29:40.374689: Pseudo dice [0.6349]
2024-05-09 20:29:40.375701: Epoch time: 267.61 s
2024-05-09 20:29:40.376728: Yayy! New best EMA pseudo Dice: 0.5888
2024-05-09 20:29:42.132078: 
2024-05-09 20:29:42.178189: Epoch 14
2024-05-09 20:29:42.179235: Current learning rate: 0.00987
2024-05-09 20:34:03.765796: Validation loss did not improve from -0.51936. Patience: 3/50
2024-05-09 20:34:03.768269: train_loss -0.6121
2024-05-09 20:34:03.769626: val_loss -0.4653
2024-05-09 20:34:03.770715: Pseudo dice [0.6445]
2024-05-09 20:34:03.771657: Epoch time: 261.64 s
2024-05-09 20:34:04.454793: Yayy! New best EMA pseudo Dice: 0.5943
2024-05-09 20:34:06.271904: 
2024-05-09 20:34:06.273361: Epoch 15
2024-05-09 20:34:06.274507: Current learning rate: 0.00986
2024-05-09 20:38:26.835103: Validation loss did not improve from -0.51936. Patience: 4/50
2024-05-09 20:38:26.836646: train_loss -0.6093
2024-05-09 20:38:26.838058: val_loss -0.5001
2024-05-09 20:38:26.839354: Pseudo dice [0.6709]
2024-05-09 20:38:26.840412: Epoch time: 260.57 s
2024-05-09 20:38:26.841465: Yayy! New best EMA pseudo Dice: 0.602
2024-05-09 20:38:28.667264: 
2024-05-09 20:38:28.669051: Epoch 16
2024-05-09 20:38:28.670392: Current learning rate: 0.00986
2024-05-09 20:42:48.629561: Validation loss did not improve from -0.51936. Patience: 5/50
2024-05-09 20:42:48.631319: train_loss -0.6143
2024-05-09 20:42:48.632597: val_loss -0.436
2024-05-09 20:42:48.633744: Pseudo dice [0.6377]
2024-05-09 20:42:48.634822: Epoch time: 259.97 s
2024-05-09 20:42:48.636067: Yayy! New best EMA pseudo Dice: 0.6056
2024-05-09 20:42:50.574159: 
2024-05-09 20:42:50.576361: Epoch 17
2024-05-09 20:42:50.577668: Current learning rate: 0.00985
2024-05-09 20:46:57.777197: Validation loss did not improve from -0.51936. Patience: 6/50
2024-05-09 20:46:57.778728: train_loss -0.6435
2024-05-09 20:46:57.780165: val_loss -0.4587
2024-05-09 20:46:57.781439: Pseudo dice [0.6505]
2024-05-09 20:46:57.782668: Epoch time: 247.21 s
2024-05-09 20:46:57.783827: Yayy! New best EMA pseudo Dice: 0.6101
2024-05-09 20:46:59.616490: 
2024-05-09 20:46:59.618108: Epoch 18
2024-05-09 20:46:59.619297: Current learning rate: 0.00984
2024-05-09 20:51:22.451087: Validation loss improved from -0.51936 to -0.52498! Patience: 6/50
2024-05-09 20:51:22.453172: train_loss -0.6464
2024-05-09 20:51:22.454648: val_loss -0.525
2024-05-09 20:51:22.455937: Pseudo dice [0.6789]
2024-05-09 20:51:22.457318: Epoch time: 262.84 s
2024-05-09 20:51:22.458376: Yayy! New best EMA pseudo Dice: 0.6169
2024-05-09 20:51:26.042890: 
2024-05-09 20:51:26.044682: Epoch 19
2024-05-09 20:51:26.045941: Current learning rate: 0.00983
2024-05-09 20:55:49.400796: Validation loss did not improve from -0.52498. Patience: 1/50
2024-05-09 20:55:49.402376: train_loss -0.6647
2024-05-09 20:55:49.403684: val_loss -0.4235
2024-05-09 20:55:49.404663: Pseudo dice [0.6217]
2024-05-09 20:55:49.405731: Epoch time: 263.36 s
2024-05-09 20:55:49.808603: Yayy! New best EMA pseudo Dice: 0.6174
2024-05-09 20:55:51.632639: 
2024-05-09 20:55:51.634099: Epoch 20
2024-05-09 20:55:51.635284: Current learning rate: 0.00982
2024-05-09 21:00:20.816394: Validation loss improved from -0.52498 to -0.54636! Patience: 1/50
2024-05-09 21:00:20.817868: train_loss -0.658
2024-05-09 21:00:20.818965: val_loss -0.5464
2024-05-09 21:00:20.819907: Pseudo dice [0.6976]
2024-05-09 21:00:20.820910: Epoch time: 269.19 s
2024-05-09 21:00:20.821861: Yayy! New best EMA pseudo Dice: 0.6254
2024-05-09 21:00:22.703644: 
2024-05-09 21:00:22.705179: Epoch 21
2024-05-09 21:00:22.706165: Current learning rate: 0.00981
2024-05-09 21:04:51.624590: Validation loss did not improve from -0.54636. Patience: 1/50
2024-05-09 21:04:51.625938: train_loss -0.6632
2024-05-09 21:04:51.626972: val_loss -0.4885
2024-05-09 21:04:51.627934: Pseudo dice [0.6506]
2024-05-09 21:04:51.628878: Epoch time: 268.92 s
2024-05-09 21:04:51.629760: Yayy! New best EMA pseudo Dice: 0.628
2024-05-09 21:04:53.343728: 
2024-05-09 21:04:53.345308: Epoch 22
2024-05-09 21:04:53.346314: Current learning rate: 0.0098
2024-05-09 21:09:20.614286: Validation loss did not improve from -0.54636. Patience: 2/50
2024-05-09 21:09:20.615787: train_loss -0.6676
2024-05-09 21:09:20.617116: val_loss -0.4692
2024-05-09 21:09:20.618269: Pseudo dice [0.6439]
2024-05-09 21:09:20.619456: Epoch time: 267.27 s
2024-05-09 21:09:20.620584: Yayy! New best EMA pseudo Dice: 0.6295
2024-05-09 21:09:22.359902: 
2024-05-09 21:09:22.361842: Epoch 23
2024-05-09 21:09:22.362808: Current learning rate: 0.00979
2024-05-09 21:13:51.038321: Validation loss did not improve from -0.54636. Patience: 3/50
2024-05-09 21:13:51.039888: train_loss -0.6825
2024-05-09 21:13:51.041086: val_loss -0.4998
2024-05-09 21:13:51.042226: Pseudo dice [0.672]
2024-05-09 21:13:51.043315: Epoch time: 268.68 s
2024-05-09 21:13:51.044411: Yayy! New best EMA pseudo Dice: 0.6338
2024-05-09 21:13:52.837380: 
2024-05-09 21:13:52.839360: Epoch 24
2024-05-09 21:13:52.840387: Current learning rate: 0.00978
2024-05-09 21:18:14.939123: Validation loss did not improve from -0.54636. Patience: 4/50
2024-05-09 21:18:14.940587: train_loss -0.6864
2024-05-09 21:18:14.941808: val_loss -0.4772
2024-05-09 21:18:14.942829: Pseudo dice [0.6864]
2024-05-09 21:18:14.943900: Epoch time: 262.1 s
2024-05-09 21:18:15.369616: Yayy! New best EMA pseudo Dice: 0.6391
2024-05-09 21:18:17.189528: 
2024-05-09 21:18:17.191035: Epoch 25
2024-05-09 21:18:17.192210: Current learning rate: 0.00977
2024-05-09 21:22:43.318895: Validation loss did not improve from -0.54636. Patience: 5/50
2024-05-09 21:22:43.320571: train_loss -0.6754
2024-05-09 21:22:43.321688: val_loss -0.5243
2024-05-09 21:22:43.322799: Pseudo dice [0.6702]
2024-05-09 21:22:43.324057: Epoch time: 266.13 s
2024-05-09 21:22:43.325253: Yayy! New best EMA pseudo Dice: 0.6422
2024-05-09 21:22:45.103102: 
2024-05-09 21:22:45.104595: Epoch 26
2024-05-09 21:22:45.105661: Current learning rate: 0.00977
2024-05-09 21:27:18.610873: Validation loss did not improve from -0.54636. Patience: 6/50
2024-05-09 21:27:18.614445: train_loss -0.6941
2024-05-09 21:27:18.617011: val_loss -0.4917
2024-05-09 21:27:18.618033: Pseudo dice [0.658]
2024-05-09 21:27:18.619367: Epoch time: 273.51 s
2024-05-09 21:27:18.620257: Yayy! New best EMA pseudo Dice: 0.6438
2024-05-09 21:27:20.520143: 
2024-05-09 21:27:20.521567: Epoch 27
2024-05-09 21:27:20.522626: Current learning rate: 0.00976
2024-05-09 21:31:43.668163: Validation loss did not improve from -0.54636. Patience: 7/50
2024-05-09 21:31:43.670093: train_loss -0.6871
2024-05-09 21:31:43.671246: val_loss -0.511
2024-05-09 21:31:43.672326: Pseudo dice [0.6872]
2024-05-09 21:31:43.673358: Epoch time: 263.15 s
2024-05-09 21:31:43.674230: Yayy! New best EMA pseudo Dice: 0.6481
2024-05-09 21:31:45.419138: 
2024-05-09 21:31:45.420861: Epoch 28
2024-05-09 21:31:45.421859: Current learning rate: 0.00975
2024-05-09 21:36:14.978858: Validation loss improved from -0.54636 to -0.54990! Patience: 7/50
2024-05-09 21:36:14.980577: train_loss -0.6968
2024-05-09 21:36:14.981808: val_loss -0.5499
2024-05-09 21:36:14.982794: Pseudo dice [0.6893]
2024-05-09 21:36:14.984045: Epoch time: 269.56 s
2024-05-09 21:36:14.985177: Yayy! New best EMA pseudo Dice: 0.6522
2024-05-09 21:36:16.741632: 
2024-05-09 21:36:16.743311: Epoch 29
2024-05-09 21:36:16.744412: Current learning rate: 0.00974
2024-05-09 21:40:50.150389: Validation loss did not improve from -0.54990. Patience: 1/50
2024-05-09 21:40:50.152451: train_loss -0.7046
2024-05-09 21:40:50.153982: val_loss -0.5332
2024-05-09 21:40:50.155291: Pseudo dice [0.6925]
2024-05-09 21:40:50.156741: Epoch time: 273.41 s
2024-05-09 21:40:50.550920: Yayy! New best EMA pseudo Dice: 0.6562
2024-05-09 21:40:52.332185: 
2024-05-09 21:40:52.334186: Epoch 30
2024-05-09 21:40:52.335543: Current learning rate: 0.00973
2024-05-09 21:45:00.810033: Validation loss did not improve from -0.54990. Patience: 2/50
2024-05-09 21:45:00.811543: train_loss -0.7013
2024-05-09 21:45:00.812957: val_loss -0.4736
2024-05-09 21:45:00.814497: Pseudo dice [0.6448]
2024-05-09 21:45:00.815876: Epoch time: 248.48 s
2024-05-09 21:45:03.158275: 
2024-05-09 21:45:03.159939: Epoch 31
2024-05-09 21:45:03.161106: Current learning rate: 0.00972
2024-05-09 21:49:21.932834: Validation loss did not improve from -0.54990. Patience: 3/50
2024-05-09 21:49:21.934520: train_loss -0.6941
2024-05-09 21:49:21.935861: val_loss -0.5278
2024-05-09 21:49:21.936975: Pseudo dice [0.6778]
2024-05-09 21:49:21.938043: Epoch time: 258.78 s
2024-05-09 21:49:21.939011: Yayy! New best EMA pseudo Dice: 0.6574
2024-05-09 21:49:23.920492: 
2024-05-09 21:49:23.921962: Epoch 32
2024-05-09 21:49:23.923045: Current learning rate: 0.00971
2024-05-09 21:53:53.066801: Validation loss improved from -0.54990 to -0.56554! Patience: 3/50
2024-05-09 21:53:53.068279: train_loss -0.7195
2024-05-09 21:53:53.069340: val_loss -0.5655
2024-05-09 21:53:53.070307: Pseudo dice [0.7016]
2024-05-09 21:53:53.071345: Epoch time: 269.15 s
2024-05-09 21:53:53.072423: Yayy! New best EMA pseudo Dice: 0.6618
2024-05-09 21:53:54.855257: 
2024-05-09 21:53:54.856869: Epoch 33
2024-05-09 21:53:54.857864: Current learning rate: 0.0097
2024-05-09 21:58:24.316695: Validation loss improved from -0.56554 to -0.58949! Patience: 0/50
2024-05-09 21:58:24.319705: train_loss -0.7207
2024-05-09 21:58:24.320931: val_loss -0.5895
2024-05-09 21:58:24.324893: Pseudo dice [0.7352]
2024-05-09 21:58:24.326233: Epoch time: 269.47 s
2024-05-09 21:58:24.327338: Yayy! New best EMA pseudo Dice: 0.6691
2024-05-09 21:58:26.071422: 
2024-05-09 21:58:26.073087: Epoch 34
2024-05-09 21:58:26.074250: Current learning rate: 0.00969
2024-05-09 22:02:50.350788: Validation loss did not improve from -0.58949. Patience: 1/50
2024-05-09 22:02:50.352212: train_loss -0.7171
2024-05-09 22:02:50.353687: val_loss -0.4625
2024-05-09 22:02:50.354784: Pseudo dice [0.632]
2024-05-09 22:02:50.355957: Epoch time: 264.28 s
2024-05-09 22:02:52.166222: 
2024-05-09 22:02:52.167886: Epoch 35
2024-05-09 22:02:52.169186: Current learning rate: 0.00968
2024-05-09 22:07:19.144889: Validation loss did not improve from -0.58949. Patience: 2/50
2024-05-09 22:07:19.146214: train_loss -0.7208
2024-05-09 22:07:19.147513: val_loss -0.5356
2024-05-09 22:07:19.148751: Pseudo dice [0.6866]
2024-05-09 22:07:19.149915: Epoch time: 266.98 s
2024-05-09 22:07:20.603703: 
2024-05-09 22:07:20.605104: Epoch 36
2024-05-09 22:07:20.606277: Current learning rate: 0.00968
2024-05-09 22:11:48.037640: Validation loss did not improve from -0.58949. Patience: 3/50
2024-05-09 22:11:48.039042: train_loss -0.7274
2024-05-09 22:11:48.040137: val_loss -0.5358
2024-05-09 22:11:48.041104: Pseudo dice [0.6866]
2024-05-09 22:11:48.042061: Epoch time: 267.44 s
2024-05-09 22:11:48.043138: Yayy! New best EMA pseudo Dice: 0.6694
2024-05-09 22:11:49.846386: 
2024-05-09 22:11:49.847864: Epoch 37
2024-05-09 22:11:49.848808: Current learning rate: 0.00967
2024-05-09 22:16:24.821097: Validation loss did not improve from -0.58949. Patience: 4/50
2024-05-09 22:16:24.822545: train_loss -0.7184
2024-05-09 22:16:24.823648: val_loss -0.5623
2024-05-09 22:16:24.824729: Pseudo dice [0.7144]
2024-05-09 22:16:24.825696: Epoch time: 274.98 s
2024-05-09 22:16:24.826752: Yayy! New best EMA pseudo Dice: 0.6739
2024-05-09 22:16:26.647584: 
2024-05-09 22:16:26.649358: Epoch 38
2024-05-09 22:16:26.650445: Current learning rate: 0.00966
2024-05-09 22:20:58.592979: Validation loss did not improve from -0.58949. Patience: 5/50
2024-05-09 22:20:58.594210: train_loss -0.7291
2024-05-09 22:20:58.595302: val_loss -0.5621
2024-05-09 22:20:58.596514: Pseudo dice [0.717]
2024-05-09 22:20:58.597752: Epoch time: 271.95 s
2024-05-09 22:20:58.598798: Yayy! New best EMA pseudo Dice: 0.6782
2024-05-09 22:21:00.410173: 
2024-05-09 22:21:00.411706: Epoch 39
2024-05-09 22:21:00.412844: Current learning rate: 0.00965
2024-05-09 22:25:12.303576: Validation loss did not improve from -0.58949. Patience: 6/50
2024-05-09 22:25:12.305196: train_loss -0.726
2024-05-09 22:25:12.306432: val_loss -0.5175
2024-05-09 22:25:12.307394: Pseudo dice [0.6882]
2024-05-09 22:25:12.308396: Epoch time: 251.9 s
2024-05-09 22:25:12.704738: Yayy! New best EMA pseudo Dice: 0.6792
2024-05-09 22:25:15.866059: 
2024-05-09 22:25:15.867839: Epoch 40
2024-05-09 22:25:15.868930: Current learning rate: 0.00964
2024-05-09 22:29:28.121267: Validation loss did not improve from -0.58949. Patience: 7/50
2024-05-09 22:29:28.122955: train_loss -0.7385
2024-05-09 22:29:28.124064: val_loss -0.521
2024-05-09 22:29:28.125288: Pseudo dice [0.6854]
2024-05-09 22:29:28.126356: Epoch time: 252.26 s
2024-05-09 22:29:28.127451: Yayy! New best EMA pseudo Dice: 0.6799
2024-05-09 22:29:29.996581: 
2024-05-09 22:29:29.998306: Epoch 41
2024-05-09 22:29:29.999444: Current learning rate: 0.00963
2024-05-09 22:33:44.283303: Validation loss did not improve from -0.58949. Patience: 8/50
2024-05-09 22:33:44.286471: train_loss -0.7252
2024-05-09 22:33:44.288854: val_loss -0.5614
2024-05-09 22:33:44.290146: Pseudo dice [0.7129]
2024-05-09 22:33:44.291502: Epoch time: 254.29 s
2024-05-09 22:33:44.292685: Yayy! New best EMA pseudo Dice: 0.6832
2024-05-09 22:33:46.955545: 
2024-05-09 22:33:46.957042: Epoch 42
2024-05-09 22:33:46.958246: Current learning rate: 0.00962
2024-05-09 22:38:02.961917: Validation loss did not improve from -0.58949. Patience: 9/50
2024-05-09 22:38:02.963549: train_loss -0.7389
2024-05-09 22:38:02.964812: val_loss -0.5247
2024-05-09 22:38:02.965971: Pseudo dice [0.6997]
2024-05-09 22:38:02.966999: Epoch time: 256.01 s
2024-05-09 22:38:02.967996: Yayy! New best EMA pseudo Dice: 0.6848
2024-05-09 22:38:04.766452: 
2024-05-09 22:38:04.768061: Epoch 43
2024-05-09 22:38:04.769084: Current learning rate: 0.00961
2024-05-09 22:42:18.259865: Validation loss did not improve from -0.58949. Patience: 10/50
2024-05-09 22:42:18.261730: train_loss -0.7348
2024-05-09 22:42:18.263176: val_loss -0.4895
2024-05-09 22:42:18.264286: Pseudo dice [0.6789]
2024-05-09 22:42:18.265413: Epoch time: 253.5 s
2024-05-09 22:42:19.682596: 
2024-05-09 22:42:19.684413: Epoch 44
2024-05-09 22:42:19.685717: Current learning rate: 0.0096
2024-05-09 22:46:36.710832: Validation loss did not improve from -0.58949. Patience: 11/50
2024-05-09 22:46:36.712811: train_loss -0.7501
2024-05-09 22:46:36.714211: val_loss -0.5399
2024-05-09 22:46:36.715433: Pseudo dice [0.7066]
2024-05-09 22:46:36.716588: Epoch time: 257.03 s
2024-05-09 22:46:37.078907: Yayy! New best EMA pseudo Dice: 0.6865
2024-05-09 22:46:38.796850: 
2024-05-09 22:46:38.798512: Epoch 45
2024-05-09 22:46:38.799706: Current learning rate: 0.00959
2024-05-09 22:50:56.197215: Validation loss did not improve from -0.58949. Patience: 12/50
2024-05-09 22:50:56.198762: train_loss -0.7152
2024-05-09 22:50:56.200127: val_loss -0.5135
2024-05-09 22:50:56.201314: Pseudo dice [0.6749]
2024-05-09 22:50:56.202433: Epoch time: 257.4 s
2024-05-09 22:50:57.549466: 
2024-05-09 22:50:57.551301: Epoch 46
2024-05-09 22:50:57.552420: Current learning rate: 0.00959
2024-05-09 22:55:12.843306: Validation loss did not improve from -0.58949. Patience: 13/50
2024-05-09 22:55:12.844970: train_loss -0.7277
2024-05-09 22:55:12.846283: val_loss -0.5453
2024-05-09 22:55:12.847313: Pseudo dice [0.6999]
2024-05-09 22:55:12.848400: Epoch time: 255.3 s
2024-05-09 22:55:12.849452: Yayy! New best EMA pseudo Dice: 0.6868
2024-05-09 22:55:14.579300: 
2024-05-09 22:55:14.580979: Epoch 47
2024-05-09 22:55:14.582473: Current learning rate: 0.00958
2024-05-09 22:59:24.403593: Validation loss did not improve from -0.58949. Patience: 14/50
2024-05-09 22:59:24.405067: train_loss -0.7394
2024-05-09 22:59:24.406331: val_loss -0.5386
2024-05-09 22:59:24.407535: Pseudo dice [0.6838]
2024-05-09 22:59:24.408912: Epoch time: 249.83 s
2024-05-09 22:59:25.749034: 
2024-05-09 22:59:25.750979: Epoch 48
2024-05-09 22:59:25.752231: Current learning rate: 0.00957
2024-05-09 23:03:34.999050: Validation loss did not improve from -0.58949. Patience: 15/50
2024-05-09 23:03:35.000986: train_loss -0.745
2024-05-09 23:03:35.002263: val_loss -0.5279
2024-05-09 23:03:35.003453: Pseudo dice [0.6814]
2024-05-09 23:03:35.004531: Epoch time: 249.25 s
2024-05-09 23:03:36.358014: 
2024-05-09 23:03:36.360105: Epoch 49
2024-05-09 23:03:36.361380: Current learning rate: 0.00956
2024-05-09 23:07:42.743697: Validation loss did not improve from -0.58949. Patience: 16/50
2024-05-09 23:07:42.745091: train_loss -0.7461
2024-05-09 23:07:42.746228: val_loss -0.5702
2024-05-09 23:07:42.747184: Pseudo dice [0.7219]
2024-05-09 23:07:42.748307: Epoch time: 246.39 s
2024-05-09 23:07:43.209590: Yayy! New best EMA pseudo Dice: 0.6896
2024-05-09 23:07:44.919890: 
2024-05-09 23:07:44.921742: Epoch 50
2024-05-09 23:07:44.922989: Current learning rate: 0.00955
2024-05-09 23:11:55.813702: Validation loss did not improve from -0.58949. Patience: 17/50
2024-05-09 23:11:55.815184: train_loss -0.7474
2024-05-09 23:11:55.816165: val_loss -0.5156
2024-05-09 23:11:55.817101: Pseudo dice [0.6794]
2024-05-09 23:11:55.818041: Epoch time: 250.9 s
2024-05-09 23:11:57.236501: 
2024-05-09 23:11:57.238031: Epoch 51
2024-05-09 23:11:57.239036: Current learning rate: 0.00954
2024-05-09 23:16:08.090621: Validation loss did not improve from -0.58949. Patience: 18/50
2024-05-09 23:16:08.092535: train_loss -0.7438
2024-05-09 23:16:08.094142: val_loss -0.5266
2024-05-09 23:16:08.095236: Pseudo dice [0.6973]
2024-05-09 23:16:08.096182: Epoch time: 250.86 s
2024-05-09 23:16:09.462516: 
2024-05-09 23:16:09.463898: Epoch 52
2024-05-09 23:16:09.465207: Current learning rate: 0.00953
2024-05-09 23:20:30.705279: Validation loss did not improve from -0.58949. Patience: 19/50
2024-05-09 23:20:30.706873: train_loss -0.757
2024-05-09 23:20:30.708114: val_loss -0.5214
2024-05-09 23:20:30.709196: Pseudo dice [0.688]
2024-05-09 23:20:30.710419: Epoch time: 261.25 s
2024-05-09 23:20:33.634836: 
2024-05-09 23:20:33.636581: Epoch 53
2024-05-09 23:20:33.637944: Current learning rate: 0.00952
2024-05-09 23:24:51.237724: Validation loss did not improve from -0.58949. Patience: 20/50
2024-05-09 23:24:51.239173: train_loss -0.7708
2024-05-09 23:24:51.240442: val_loss -0.564
2024-05-09 23:24:51.241546: Pseudo dice [0.71]
2024-05-09 23:24:51.242619: Epoch time: 257.61 s
2024-05-09 23:24:51.243687: Yayy! New best EMA pseudo Dice: 0.6914
2024-05-09 23:24:53.066637: 
2024-05-09 23:24:53.068204: Epoch 54
2024-05-09 23:24:53.069343: Current learning rate: 0.00951
2024-05-09 23:29:10.435030: Validation loss did not improve from -0.58949. Patience: 21/50
2024-05-09 23:29:10.436665: train_loss -0.7506
2024-05-09 23:29:10.437853: val_loss -0.5297
2024-05-09 23:29:10.439024: Pseudo dice [0.6929]
2024-05-09 23:29:10.440244: Epoch time: 257.37 s
2024-05-09 23:29:10.907913: Yayy! New best EMA pseudo Dice: 0.6915
2024-05-09 23:29:12.690432: 
2024-05-09 23:29:12.692216: Epoch 55
2024-05-09 23:29:12.693236: Current learning rate: 0.0095
2024-05-09 23:33:36.117456: Validation loss did not improve from -0.58949. Patience: 22/50
2024-05-09 23:33:36.118827: train_loss -0.7567
2024-05-09 23:33:36.120233: val_loss -0.5484
2024-05-09 23:33:36.121439: Pseudo dice [0.7031]
2024-05-09 23:33:36.122645: Epoch time: 263.43 s
2024-05-09 23:33:36.123741: Yayy! New best EMA pseudo Dice: 0.6927
2024-05-09 23:33:37.926980: 
2024-05-09 23:33:37.928663: Epoch 56
2024-05-09 23:33:37.929893: Current learning rate: 0.00949
2024-05-09 23:37:50.148413: Validation loss did not improve from -0.58949. Patience: 23/50
2024-05-09 23:37:50.151169: train_loss -0.772
2024-05-09 23:37:50.155217: val_loss -0.5033
2024-05-09 23:37:50.156435: Pseudo dice [0.6772]
2024-05-09 23:37:50.157564: Epoch time: 252.23 s
2024-05-09 23:37:51.560644: 
2024-05-09 23:37:51.562287: Epoch 57
2024-05-09 23:37:51.563261: Current learning rate: 0.00949
2024-05-09 23:42:09.317811: Validation loss did not improve from -0.58949. Patience: 24/50
2024-05-09 23:42:09.319663: train_loss -0.7656
2024-05-09 23:42:09.321341: val_loss -0.5601
2024-05-09 23:42:09.322793: Pseudo dice [0.7148]
2024-05-09 23:42:09.323827: Epoch time: 257.76 s
2024-05-09 23:42:09.324820: Yayy! New best EMA pseudo Dice: 0.6935
2024-05-09 23:42:11.112256: 
2024-05-09 23:42:11.114203: Epoch 58
2024-05-09 23:42:11.115244: Current learning rate: 0.00948
2024-05-09 23:46:23.174317: Validation loss did not improve from -0.58949. Patience: 25/50
2024-05-09 23:46:23.175846: train_loss -0.7678
2024-05-09 23:46:23.176913: val_loss -0.5185
2024-05-09 23:46:23.178102: Pseudo dice [0.6802]
2024-05-09 23:46:23.179240: Epoch time: 252.07 s
2024-05-09 23:46:24.586205: 
2024-05-09 23:46:24.587879: Epoch 59
2024-05-09 23:46:24.588876: Current learning rate: 0.00947
2024-05-09 23:50:39.512009: Validation loss did not improve from -0.58949. Patience: 26/50
2024-05-09 23:50:39.513520: train_loss -0.7613
2024-05-09 23:50:39.514717: val_loss -0.5463
2024-05-09 23:50:39.515877: Pseudo dice [0.7071]
2024-05-09 23:50:39.517053: Epoch time: 254.93 s
2024-05-09 23:50:39.900897: Yayy! New best EMA pseudo Dice: 0.6937
2024-05-09 23:50:41.690502: 
2024-05-09 23:50:41.692342: Epoch 60
2024-05-09 23:50:41.693321: Current learning rate: 0.00946
2024-05-09 23:54:59.548553: Validation loss did not improve from -0.58949. Patience: 27/50
2024-05-09 23:54:59.550122: train_loss -0.7631
2024-05-09 23:54:59.551337: val_loss -0.526
2024-05-09 23:54:59.552504: Pseudo dice [0.6912]
2024-05-09 23:54:59.553690: Epoch time: 257.86 s
2024-05-09 23:55:00.939623: 
2024-05-09 23:55:00.941206: Epoch 61
2024-05-09 23:55:00.942261: Current learning rate: 0.00945
2024-05-09 23:59:22.583704: Validation loss did not improve from -0.58949. Patience: 28/50
2024-05-09 23:59:22.585366: train_loss -0.7524
2024-05-09 23:59:22.586526: val_loss -0.5252
2024-05-09 23:59:22.587529: Pseudo dice [0.6877]
2024-05-09 23:59:22.588685: Epoch time: 261.65 s
2024-05-09 23:59:23.971799: 
2024-05-09 23:59:23.973507: Epoch 62
2024-05-09 23:59:23.974566: Current learning rate: 0.00944
2024-05-10 00:03:37.636702: Validation loss did not improve from -0.58949. Patience: 29/50
2024-05-10 00:03:37.638402: train_loss -0.7545
2024-05-10 00:03:37.639544: val_loss -0.5339
2024-05-10 00:03:37.640651: Pseudo dice [0.6911]
2024-05-10 00:03:37.641820: Epoch time: 253.67 s
2024-05-10 00:03:39.047400: 
2024-05-10 00:03:39.049177: Epoch 63
2024-05-10 00:03:39.050137: Current learning rate: 0.00943
2024-05-10 00:07:55.531947: Validation loss did not improve from -0.58949. Patience: 30/50
2024-05-10 00:07:55.533892: train_loss -0.7604
2024-05-10 00:07:55.535300: val_loss -0.5595
2024-05-10 00:07:55.536572: Pseudo dice [0.7175]
2024-05-10 00:07:55.537900: Epoch time: 256.49 s
2024-05-10 00:07:55.539049: Yayy! New best EMA pseudo Dice: 0.6951
2024-05-10 00:07:57.425168: 
2024-05-10 00:07:57.426908: Epoch 64
2024-05-10 00:07:57.428379: Current learning rate: 0.00942
2024-05-10 00:12:14.157988: Validation loss did not improve from -0.58949. Patience: 31/50
2024-05-10 00:12:14.159626: train_loss -0.7602
2024-05-10 00:12:14.160882: val_loss -0.5235
2024-05-10 00:12:14.162050: Pseudo dice [0.689]
2024-05-10 00:12:14.163105: Epoch time: 256.74 s
2024-05-10 00:12:18.524002: 
2024-05-10 00:12:18.525664: Epoch 65
2024-05-10 00:12:18.526971: Current learning rate: 0.00941
2024-05-10 00:16:31.043879: Validation loss did not improve from -0.58949. Patience: 32/50
2024-05-10 00:16:31.045434: train_loss -0.77
2024-05-10 00:16:31.046702: val_loss -0.5552
2024-05-10 00:16:31.047822: Pseudo dice [0.718]
2024-05-10 00:16:31.049070: Epoch time: 252.52 s
2024-05-10 00:16:31.050236: Yayy! New best EMA pseudo Dice: 0.6969
2024-05-10 00:16:32.823780: 
2024-05-10 00:16:32.826226: Epoch 66
2024-05-10 00:16:32.827982: Current learning rate: 0.0094
2024-05-10 00:20:44.097013: Validation loss did not improve from -0.58949. Patience: 33/50
2024-05-10 00:20:44.098601: train_loss -0.77
2024-05-10 00:20:44.099970: val_loss -0.4195
2024-05-10 00:20:44.101077: Pseudo dice [0.6145]
2024-05-10 00:20:44.102226: Epoch time: 251.28 s
2024-05-10 00:20:45.488065: 
2024-05-10 00:20:45.490288: Epoch 67
2024-05-10 00:20:45.491851: Current learning rate: 0.00939
2024-05-10 00:24:52.874215: Validation loss improved from -0.58949 to -0.60360! Patience: 33/50
2024-05-10 00:24:52.875642: train_loss -0.7567
2024-05-10 00:24:52.876933: val_loss -0.6036
2024-05-10 00:24:52.877925: Pseudo dice [0.734]
2024-05-10 00:24:52.878912: Epoch time: 247.39 s
2024-05-10 00:24:54.298624: 
2024-05-10 00:24:54.300234: Epoch 68
2024-05-10 00:24:54.301492: Current learning rate: 0.00939
2024-05-10 00:29:02.188151: Validation loss did not improve from -0.60360. Patience: 1/50
2024-05-10 00:29:02.189743: train_loss -0.7673
2024-05-10 00:29:02.190931: val_loss -0.5557
2024-05-10 00:29:02.191876: Pseudo dice [0.7215]
2024-05-10 00:29:02.192824: Epoch time: 247.89 s
2024-05-10 00:29:03.643089: 
2024-05-10 00:29:03.644886: Epoch 69
2024-05-10 00:29:03.646101: Current learning rate: 0.00938
2024-05-10 00:33:20.356331: Validation loss did not improve from -0.60360. Patience: 2/50
2024-05-10 00:33:20.357739: train_loss -0.7778
2024-05-10 00:33:20.358772: val_loss -0.5332
2024-05-10 00:33:20.359768: Pseudo dice [0.7182]
2024-05-10 00:33:20.360771: Epoch time: 256.72 s
2024-05-10 00:33:20.780069: Yayy! New best EMA pseudo Dice: 0.6982
2024-05-10 00:33:22.612203: 
2024-05-10 00:33:22.613847: Epoch 70
2024-05-10 00:33:22.614944: Current learning rate: 0.00937
2024-05-10 00:37:40.839067: Validation loss did not improve from -0.60360. Patience: 3/50
2024-05-10 00:37:40.840534: train_loss -0.7654
2024-05-10 00:37:40.841828: val_loss -0.5391
2024-05-10 00:37:40.842791: Pseudo dice [0.7114]
2024-05-10 00:37:40.843912: Epoch time: 258.23 s
2024-05-10 00:37:40.844873: Yayy! New best EMA pseudo Dice: 0.6995
2024-05-10 00:37:42.682402: 
2024-05-10 00:37:42.684268: Epoch 71
2024-05-10 00:37:42.685404: Current learning rate: 0.00936
2024-05-10 00:41:57.908475: Validation loss did not improve from -0.60360. Patience: 4/50
2024-05-10 00:41:57.911241: train_loss -0.7698
2024-05-10 00:41:57.913699: val_loss -0.5677
2024-05-10 00:41:57.915242: Pseudo dice [0.7076]
2024-05-10 00:41:57.917129: Epoch time: 255.23 s
2024-05-10 00:41:57.918719: Yayy! New best EMA pseudo Dice: 0.7004
2024-05-10 00:41:59.804403: 
2024-05-10 00:41:59.806176: Epoch 72
2024-05-10 00:41:59.807538: Current learning rate: 0.00935
2024-05-10 00:46:15.885745: Validation loss did not improve from -0.60360. Patience: 5/50
2024-05-10 00:46:15.887791: train_loss -0.78
2024-05-10 00:46:15.888923: val_loss -0.5625
2024-05-10 00:46:15.890081: Pseudo dice [0.7107]
2024-05-10 00:46:15.891136: Epoch time: 256.08 s
2024-05-10 00:46:15.892144: Yayy! New best EMA pseudo Dice: 0.7014
2024-05-10 00:46:17.685914: 
2024-05-10 00:46:17.687333: Epoch 73
2024-05-10 00:46:17.688423: Current learning rate: 0.00934
2024-05-10 00:50:32.940334: Validation loss did not improve from -0.60360. Patience: 6/50
2024-05-10 00:50:32.941828: train_loss -0.7871
2024-05-10 00:50:32.943190: val_loss -0.583
2024-05-10 00:50:32.944323: Pseudo dice [0.7275]
2024-05-10 00:50:32.945397: Epoch time: 255.26 s
2024-05-10 00:50:32.946527: Yayy! New best EMA pseudo Dice: 0.704
2024-05-10 00:50:34.788428: 
2024-05-10 00:50:34.790383: Epoch 74
2024-05-10 00:50:34.791653: Current learning rate: 0.00933
2024-05-10 00:54:53.744777: Validation loss did not improve from -0.60360. Patience: 7/50
2024-05-10 00:54:53.746202: train_loss -0.7834
2024-05-10 00:54:53.747459: val_loss -0.5613
2024-05-10 00:54:53.748600: Pseudo dice [0.7095]
2024-05-10 00:54:53.749761: Epoch time: 258.96 s
2024-05-10 00:54:54.123984: Yayy! New best EMA pseudo Dice: 0.7046
2024-05-10 00:54:55.940292: 
2024-05-10 00:54:55.941780: Epoch 75
2024-05-10 00:54:55.942899: Current learning rate: 0.00932
2024-05-10 00:59:08.284357: Validation loss did not improve from -0.60360. Patience: 8/50
2024-05-10 00:59:08.285877: train_loss -0.7849
2024-05-10 00:59:08.287012: val_loss -0.4872
2024-05-10 00:59:08.288059: Pseudo dice [0.6525]
2024-05-10 00:59:08.289087: Epoch time: 252.35 s
2024-05-10 00:59:10.946538: 
2024-05-10 00:59:10.948431: Epoch 76
2024-05-10 00:59:10.949746: Current learning rate: 0.00931
2024-05-10 01:03:27.945867: Validation loss did not improve from -0.60360. Patience: 9/50
2024-05-10 01:03:27.947405: train_loss -0.7893
2024-05-10 01:03:27.948697: val_loss -0.5552
2024-05-10 01:03:27.949843: Pseudo dice [0.7157]
2024-05-10 01:03:27.951075: Epoch time: 257.0 s
2024-05-10 01:03:29.408435: 
2024-05-10 01:03:29.410480: Epoch 77
2024-05-10 01:03:29.411670: Current learning rate: 0.0093
2024-05-10 01:07:50.145455: Validation loss did not improve from -0.60360. Patience: 10/50
2024-05-10 01:07:50.147041: train_loss -0.7803
2024-05-10 01:07:50.148196: val_loss -0.5407
2024-05-10 01:07:50.149454: Pseudo dice [0.7145]
2024-05-10 01:07:50.150529: Epoch time: 260.74 s
2024-05-10 01:07:51.629812: 
2024-05-10 01:07:51.631796: Epoch 78
2024-05-10 01:07:51.632919: Current learning rate: 0.0093
2024-05-10 01:12:13.708329: Validation loss did not improve from -0.60360. Patience: 11/50
2024-05-10 01:12:13.710639: train_loss -0.7933
2024-05-10 01:12:13.712334: val_loss -0.5252
2024-05-10 01:12:13.713946: Pseudo dice [0.6918]
2024-05-10 01:12:13.715551: Epoch time: 262.08 s
2024-05-10 01:12:15.190502: 
2024-05-10 01:12:15.193023: Epoch 79
2024-05-10 01:12:15.194616: Current learning rate: 0.00929
2024-05-10 01:16:32.115140: Validation loss did not improve from -0.60360. Patience: 12/50
2024-05-10 01:16:32.116663: train_loss -0.7856
2024-05-10 01:16:32.117797: val_loss -0.5199
2024-05-10 01:16:32.118850: Pseudo dice [0.6857]
2024-05-10 01:16:32.119876: Epoch time: 256.93 s
2024-05-10 01:16:33.999331: 
2024-05-10 01:16:34.001169: Epoch 80
2024-05-10 01:16:34.002507: Current learning rate: 0.00928
2024-05-10 01:20:53.143424: Validation loss did not improve from -0.60360. Patience: 13/50
2024-05-10 01:20:53.145030: train_loss -0.7825
2024-05-10 01:20:53.146174: val_loss -0.5893
2024-05-10 01:20:53.147305: Pseudo dice [0.7335]
2024-05-10 01:20:53.148277: Epoch time: 259.15 s
2024-05-10 01:20:54.604213: 
2024-05-10 01:20:54.606239: Epoch 81
2024-05-10 01:20:54.607442: Current learning rate: 0.00927
2024-05-10 01:25:14.935183: Validation loss did not improve from -0.60360. Patience: 14/50
2024-05-10 01:25:14.936754: train_loss -0.7872
2024-05-10 01:25:14.938192: val_loss -0.5786
2024-05-10 01:25:14.939227: Pseudo dice [0.7346]
2024-05-10 01:25:14.940529: Epoch time: 260.33 s
2024-05-10 01:25:14.941736: Yayy! New best EMA pseudo Dice: 0.7062
2024-05-10 01:25:16.801073: 
2024-05-10 01:25:16.802904: Epoch 82
2024-05-10 01:25:16.804094: Current learning rate: 0.00926
2024-05-10 01:29:31.452152: Validation loss did not improve from -0.60360. Patience: 15/50
2024-05-10 01:29:31.453719: train_loss -0.7843
2024-05-10 01:29:31.454907: val_loss -0.5241
2024-05-10 01:29:31.455920: Pseudo dice [0.704]
2024-05-10 01:29:31.457096: Epoch time: 254.65 s
2024-05-10 01:29:32.805571: 
2024-05-10 01:29:32.807993: Epoch 83
2024-05-10 01:29:32.809442: Current learning rate: 0.00925
2024-05-10 01:33:38.953033: Validation loss did not improve from -0.60360. Patience: 16/50
2024-05-10 01:33:38.954570: train_loss -0.7934
2024-05-10 01:33:38.955810: val_loss -0.5078
2024-05-10 01:33:38.956777: Pseudo dice [0.6818]
2024-05-10 01:33:38.957845: Epoch time: 246.15 s
2024-05-10 01:33:40.203954: 
2024-05-10 01:33:40.206944: Epoch 84
2024-05-10 01:33:40.208205: Current learning rate: 0.00924
2024-05-10 01:37:45.142927: Validation loss did not improve from -0.60360. Patience: 17/50
2024-05-10 01:37:45.144578: train_loss -0.7865
2024-05-10 01:37:45.146047: val_loss -0.4968
2024-05-10 01:37:45.147374: Pseudo dice [0.6732]
2024-05-10 01:37:45.148540: Epoch time: 244.94 s
2024-05-10 01:37:46.878401: 
2024-05-10 01:37:46.880515: Epoch 85
2024-05-10 01:37:46.881918: Current learning rate: 0.00923
2024-05-10 01:41:52.851845: Validation loss did not improve from -0.60360. Patience: 18/50
2024-05-10 01:41:52.853410: train_loss -0.7952
2024-05-10 01:41:52.854592: val_loss -0.5167
2024-05-10 01:41:52.855767: Pseudo dice [0.6984]
2024-05-10 01:41:52.856803: Epoch time: 245.98 s
2024-05-10 01:41:54.223341: 
2024-05-10 01:41:54.225037: Epoch 86
2024-05-10 01:41:54.226207: Current learning rate: 0.00922
2024-05-10 01:46:05.382879: Validation loss did not improve from -0.60360. Patience: 19/50
2024-05-10 01:46:05.384541: train_loss -0.7945
2024-05-10 01:46:05.385665: val_loss -0.512
2024-05-10 01:46:05.386674: Pseudo dice [0.6986]
2024-05-10 01:46:05.387748: Epoch time: 251.16 s
2024-05-10 01:46:06.754196: 
2024-05-10 01:46:06.755703: Epoch 87
2024-05-10 01:46:06.756888: Current learning rate: 0.00921
2024-05-10 01:50:23.742414: Validation loss did not improve from -0.60360. Patience: 20/50
2024-05-10 01:50:23.746109: train_loss -0.7888
2024-05-10 01:50:23.748359: val_loss -0.5043
2024-05-10 01:50:23.749632: Pseudo dice [0.6779]
2024-05-10 01:50:23.750961: Epoch time: 256.99 s
2024-05-10 01:50:25.146613: 
2024-05-10 01:50:25.148723: Epoch 88
2024-05-10 01:50:25.149977: Current learning rate: 0.0092
2024-05-10 01:54:40.484513: Validation loss did not improve from -0.60360. Patience: 21/50
2024-05-10 01:54:40.486315: train_loss -0.7786
2024-05-10 01:54:40.547828: val_loss -0.537
2024-05-10 01:54:40.549495: Pseudo dice [0.7069]
2024-05-10 01:54:40.554443: Epoch time: 255.34 s
2024-05-10 01:54:42.074823: 
2024-05-10 01:54:42.078970: Epoch 89
2024-05-10 01:54:42.080508: Current learning rate: 0.0092
2024-05-10 01:58:53.376842: Validation loss did not improve from -0.60360. Patience: 22/50
2024-05-10 01:58:53.378947: train_loss -0.7705
2024-05-10 01:58:53.380162: val_loss -0.5835
2024-05-10 01:58:53.381106: Pseudo dice [0.7297]
2024-05-10 01:58:53.382029: Epoch time: 251.31 s
2024-05-10 01:58:55.189219: 
2024-05-10 01:58:55.190974: Epoch 90
2024-05-10 01:58:55.191934: Current learning rate: 0.00919
2024-05-10 02:03:14.479298: Validation loss did not improve from -0.60360. Patience: 23/50
2024-05-10 02:03:14.482901: train_loss -0.7821
2024-05-10 02:03:14.484493: val_loss -0.5187
2024-05-10 02:03:14.485666: Pseudo dice [0.6886]
2024-05-10 02:03:14.486861: Epoch time: 259.29 s
2024-05-10 02:03:15.861708: 
2024-05-10 02:03:15.863605: Epoch 91
2024-05-10 02:03:15.865040: Current learning rate: 0.00918
2024-05-10 02:07:29.315058: Validation loss did not improve from -0.60360. Patience: 24/50
2024-05-10 02:07:29.316616: train_loss -0.796
2024-05-10 02:07:29.317698: val_loss -0.5768
2024-05-10 02:07:29.318683: Pseudo dice [0.7188]
2024-05-10 02:07:29.319723: Epoch time: 253.46 s
2024-05-10 02:07:30.673136: 
2024-05-10 02:07:30.675670: Epoch 92
2024-05-10 02:07:30.676795: Current learning rate: 0.00917
2024-05-10 02:11:48.295204: Validation loss did not improve from -0.60360. Patience: 25/50
2024-05-10 02:11:48.296685: train_loss -0.7938
2024-05-10 02:11:48.297915: val_loss -0.5632
2024-05-10 02:11:48.298919: Pseudo dice [0.7291]
2024-05-10 02:11:48.300000: Epoch time: 257.63 s
2024-05-10 02:11:49.665193: 
2024-05-10 02:11:49.667630: Epoch 93
2024-05-10 02:11:49.668792: Current learning rate: 0.00916
2024-05-10 02:16:06.432212: Validation loss did not improve from -0.60360. Patience: 26/50
2024-05-10 02:16:06.433676: train_loss -0.7845
2024-05-10 02:16:06.434753: val_loss -0.4431
2024-05-10 02:16:06.435793: Pseudo dice [0.6372]
2024-05-10 02:16:06.436779: Epoch time: 256.77 s
2024-05-10 02:16:07.813075: 
2024-05-10 02:16:07.815115: Epoch 94
2024-05-10 02:16:07.816246: Current learning rate: 0.00915
2024-05-10 02:20:30.626499: Validation loss did not improve from -0.60360. Patience: 27/50
2024-05-10 02:20:30.629092: train_loss -0.7214
2024-05-10 02:20:30.630669: val_loss -0.4995
2024-05-10 02:20:30.631904: Pseudo dice [0.6702]
2024-05-10 02:20:30.632966: Epoch time: 262.82 s
2024-05-10 02:20:32.380679: 
2024-05-10 02:20:32.382766: Epoch 95
2024-05-10 02:20:32.383843: Current learning rate: 0.00914
2024-05-10 02:24:53.936227: Validation loss did not improve from -0.60360. Patience: 28/50
2024-05-10 02:24:53.938030: train_loss -0.7669
2024-05-10 02:24:53.939589: val_loss -0.49
2024-05-10 02:24:53.940637: Pseudo dice [0.6699]
2024-05-10 02:24:53.941824: Epoch time: 261.56 s
2024-05-10 02:24:55.332631: 
2024-05-10 02:24:55.334747: Epoch 96
2024-05-10 02:24:55.336201: Current learning rate: 0.00913
2024-05-10 02:29:15.054977: Validation loss did not improve from -0.60360. Patience: 29/50
2024-05-10 02:29:15.056483: train_loss -0.7787
2024-05-10 02:29:15.057872: val_loss -0.5312
2024-05-10 02:29:15.059007: Pseudo dice [0.6865]
2024-05-10 02:29:15.060159: Epoch time: 259.73 s
2024-05-10 02:29:16.442941: 
2024-05-10 02:29:16.445007: Epoch 97
2024-05-10 02:29:16.446221: Current learning rate: 0.00912
2024-05-10 02:33:35.820808: Validation loss did not improve from -0.60360. Patience: 30/50
2024-05-10 02:33:35.822293: train_loss -0.792
2024-05-10 02:33:35.823344: val_loss -0.4928
2024-05-10 02:33:35.824325: Pseudo dice [0.6692]
2024-05-10 02:33:35.825336: Epoch time: 259.38 s
2024-05-10 02:33:37.200117: 
2024-05-10 02:33:37.202019: Epoch 98
2024-05-10 02:33:37.203042: Current learning rate: 0.00911
2024-05-10 02:37:58.326682: Validation loss did not improve from -0.60360. Patience: 31/50
2024-05-10 02:37:58.328109: train_loss -0.784
2024-05-10 02:37:58.329303: val_loss -0.5498
2024-05-10 02:37:58.330398: Pseudo dice [0.6926]
2024-05-10 02:37:58.331460: Epoch time: 261.13 s
2024-05-10 02:37:59.772217: 
2024-05-10 02:37:59.774320: Epoch 99
2024-05-10 02:37:59.775536: Current learning rate: 0.0091
2024-05-10 02:42:12.945451: Validation loss did not improve from -0.60360. Patience: 32/50
2024-05-10 02:42:12.947098: train_loss -0.7883
2024-05-10 02:42:12.948188: val_loss -0.549
2024-05-10 02:42:12.949122: Pseudo dice [0.714]
2024-05-10 02:42:12.950242: Epoch time: 253.18 s
2024-05-10 02:42:14.728715: 
2024-05-10 02:42:14.730944: Epoch 100
2024-05-10 02:42:14.732246: Current learning rate: 0.0091
2024-05-10 02:46:23.853868: Validation loss did not improve from -0.60360. Patience: 33/50
2024-05-10 02:46:23.855350: train_loss -0.7982
2024-05-10 02:46:23.856635: val_loss -0.5093
2024-05-10 02:46:23.857852: Pseudo dice [0.681]
2024-05-10 02:46:23.859082: Epoch time: 249.13 s
2024-05-10 02:46:25.255187: 
2024-05-10 02:46:25.257798: Epoch 101
2024-05-10 02:46:25.259411: Current learning rate: 0.00909
2024-05-10 02:50:29.556039: Validation loss did not improve from -0.60360. Patience: 34/50
2024-05-10 02:50:29.557549: train_loss -0.7973
2024-05-10 02:50:29.558984: val_loss -0.4827
2024-05-10 02:50:29.560207: Pseudo dice [0.6855]
2024-05-10 02:50:29.561473: Epoch time: 244.3 s
2024-05-10 02:50:30.957161: 
2024-05-10 02:50:30.959653: Epoch 102
2024-05-10 02:50:30.961327: Current learning rate: 0.00908
2024-05-10 02:54:40.462153: Validation loss did not improve from -0.60360. Patience: 35/50
2024-05-10 02:54:40.465359: train_loss -0.8
2024-05-10 02:54:40.467450: val_loss -0.5949
2024-05-10 02:54:40.468670: Pseudo dice [0.7429]
2024-05-10 02:54:40.469919: Epoch time: 249.51 s
2024-05-10 02:54:41.877988: 
2024-05-10 02:54:41.880178: Epoch 103
2024-05-10 02:54:41.881574: Current learning rate: 0.00907
2024-05-10 02:58:52.269925: Validation loss did not improve from -0.60360. Patience: 36/50
2024-05-10 02:58:52.271435: train_loss -0.806
2024-05-10 02:58:52.272755: val_loss -0.5815
2024-05-10 02:58:52.273983: Pseudo dice [0.7267]
2024-05-10 02:58:52.275219: Epoch time: 250.39 s
2024-05-10 02:58:53.660414: 
2024-05-10 02:58:53.662390: Epoch 104
2024-05-10 02:58:53.663476: Current learning rate: 0.00906
2024-05-10 03:03:03.946566: Validation loss did not improve from -0.60360. Patience: 37/50
2024-05-10 03:03:03.948312: train_loss -0.8142
2024-05-10 03:03:03.949687: val_loss -0.46
2024-05-10 03:03:03.951036: Pseudo dice [0.6656]
2024-05-10 03:03:03.952310: Epoch time: 250.29 s
2024-05-10 03:03:05.978121: 
2024-05-10 03:03:05.980029: Epoch 105
2024-05-10 03:03:05.981202: Current learning rate: 0.00905
2024-05-10 03:07:20.809030: Validation loss did not improve from -0.60360. Patience: 38/50
2024-05-10 03:07:20.810490: train_loss -0.8124
2024-05-10 03:07:20.811607: val_loss -0.5647
2024-05-10 03:07:20.812663: Pseudo dice [0.7151]
2024-05-10 03:07:20.813678: Epoch time: 254.83 s
2024-05-10 03:07:22.204295: 
2024-05-10 03:07:22.206170: Epoch 106
2024-05-10 03:07:22.207185: Current learning rate: 0.00904
2024-05-10 03:11:31.669240: Validation loss did not improve from -0.60360. Patience: 39/50
2024-05-10 03:11:31.670895: train_loss -0.8121
2024-05-10 03:11:31.672311: val_loss -0.5438
2024-05-10 03:11:31.673689: Pseudo dice [0.719]
2024-05-10 03:11:31.674986: Epoch time: 249.47 s
2024-05-10 03:11:33.081385: 
2024-05-10 03:11:33.082958: Epoch 107
2024-05-10 03:11:33.084575: Current learning rate: 0.00903
2024-05-10 03:15:39.851472: Validation loss did not improve from -0.60360. Patience: 40/50
2024-05-10 03:15:39.853263: train_loss -0.8157
2024-05-10 03:15:39.854365: val_loss -0.4792
2024-05-10 03:15:39.855369: Pseudo dice [0.6867]
2024-05-10 03:15:39.858185: Epoch time: 246.77 s
2024-05-10 03:15:41.258911: 
2024-05-10 03:15:41.260600: Epoch 108
2024-05-10 03:15:41.261614: Current learning rate: 0.00902
2024-05-10 03:19:51.326540: Validation loss did not improve from -0.60360. Patience: 41/50
2024-05-10 03:19:51.328094: train_loss -0.8128
2024-05-10 03:19:51.329336: val_loss -0.5614
2024-05-10 03:19:51.330522: Pseudo dice [0.7217]
2024-05-10 03:19:51.331819: Epoch time: 250.07 s
2024-05-10 03:19:52.726388: 
2024-05-10 03:19:52.728115: Epoch 109
2024-05-10 03:19:52.729138: Current learning rate: 0.00901
2024-05-10 03:24:04.572325: Validation loss did not improve from -0.60360. Patience: 42/50
2024-05-10 03:24:04.574218: train_loss -0.8138
2024-05-10 03:24:04.575612: val_loss -0.5447
2024-05-10 03:24:04.576728: Pseudo dice [0.7026]
2024-05-10 03:24:04.577800: Epoch time: 251.85 s
2024-05-10 03:24:06.364921: 
2024-05-10 03:24:06.366425: Epoch 110
2024-05-10 03:24:06.367535: Current learning rate: 0.009
2024-05-10 03:28:17.454895: Validation loss did not improve from -0.60360. Patience: 43/50
2024-05-10 03:28:17.456490: train_loss -0.8138
2024-05-10 03:28:17.457784: val_loss -0.5199
2024-05-10 03:28:17.458903: Pseudo dice [0.6857]
2024-05-10 03:28:17.460138: Epoch time: 251.09 s
2024-05-10 03:28:19.722169: 
2024-05-10 03:28:19.724228: Epoch 111
2024-05-10 03:28:19.725606: Current learning rate: 0.009
2024-05-10 03:32:30.756654: Validation loss did not improve from -0.60360. Patience: 44/50
2024-05-10 03:32:30.758361: train_loss -0.8099
2024-05-10 03:32:30.759781: val_loss -0.5842
2024-05-10 03:32:30.760850: Pseudo dice [0.7365]
2024-05-10 03:32:30.761929: Epoch time: 251.04 s
2024-05-10 03:32:32.166243: 
2024-05-10 03:32:32.168364: Epoch 112
2024-05-10 03:32:32.169555: Current learning rate: 0.00899
2024-05-10 03:36:31.261944: Validation loss did not improve from -0.60360. Patience: 45/50
2024-05-10 03:36:31.263781: train_loss -0.8174
2024-05-10 03:36:31.265511: val_loss -0.5339
2024-05-10 03:36:31.266980: Pseudo dice [0.7177]
2024-05-10 03:36:31.268237: Epoch time: 239.1 s
2024-05-10 03:36:32.453222: 
2024-05-10 03:36:32.455753: Epoch 113
2024-05-10 03:36:32.457373: Current learning rate: 0.00898
2024-05-10 03:40:32.495778: Validation loss did not improve from -0.60360. Patience: 46/50
2024-05-10 03:40:32.497804: train_loss -0.8147
2024-05-10 03:40:32.499816: val_loss -0.5645
2024-05-10 03:40:32.500901: Pseudo dice [0.7294]
2024-05-10 03:40:32.501937: Epoch time: 240.05 s
2024-05-10 03:40:32.502836: Yayy! New best EMA pseudo Dice: 0.7071
2024-05-10 03:40:34.075846: 
2024-05-10 03:40:34.078096: Epoch 114
2024-05-10 03:40:34.079355: Current learning rate: 0.00897
2024-05-10 03:44:34.239556: Validation loss did not improve from -0.60360. Patience: 47/50
2024-05-10 03:44:34.241312: train_loss -0.8133
2024-05-10 03:44:34.242668: val_loss -0.5578
2024-05-10 03:44:34.243788: Pseudo dice [0.7135]
2024-05-10 03:44:34.244767: Epoch time: 240.17 s
2024-05-10 03:44:34.568277: Yayy! New best EMA pseudo Dice: 0.7078
2024-05-10 03:44:36.135504: 
2024-05-10 03:44:36.138423: Epoch 115
2024-05-10 03:44:36.139815: Current learning rate: 0.00896
2024-05-10 03:48:36.866549: Validation loss did not improve from -0.60360. Patience: 48/50
2024-05-10 03:48:36.868243: train_loss -0.8056
2024-05-10 03:48:36.869647: val_loss -0.5438
2024-05-10 03:48:36.870813: Pseudo dice [0.7037]
2024-05-10 03:48:36.871994: Epoch time: 240.73 s
2024-05-10 03:48:38.135739: 
2024-05-10 03:48:38.138203: Epoch 116
2024-05-10 03:48:38.139351: Current learning rate: 0.00895
2024-05-10 03:52:38.172662: Validation loss did not improve from -0.60360. Patience: 49/50
2024-05-10 03:52:38.174317: train_loss -0.8166
2024-05-10 03:52:38.176172: val_loss -0.4938
2024-05-10 03:52:38.177580: Pseudo dice [0.6811]
2024-05-10 03:52:38.178985: Epoch time: 240.04 s
2024-05-10 03:52:39.444786: 
2024-05-10 03:52:39.447569: Epoch 117
2024-05-10 03:52:39.448947: Current learning rate: 0.00894
2024-05-10 03:56:40.677545: Validation loss did not improve from -0.60360. Patience: 50/50
2024-05-10 03:56:40.679715: train_loss -0.8128
2024-05-10 03:56:40.681361: val_loss -0.5689
2024-05-10 03:56:40.682468: Pseudo dice [0.7185]
2024-05-10 03:56:40.683679: Epoch time: 241.24 s
2024-05-10 03:56:42.117466: Patience reached. Stopping training.
2024-05-10 03:56:42.542025: Training done.
2024-05-10 03:56:43.300847: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset302_Calcium_OCTv2/splits_final.json
2024-05-10 03:56:43.303765: The split file contains 3 splits.
2024-05-10 03:56:43.304689: Desired fold for training: 1
2024-05-10 03:56:43.305593: This split has 4 training and 2 validation cases.
2024-05-10 03:56:43.306969: predicting 101-044
2024-05-10 03:56:43.444637: 101-044, shape torch.Size([1, 404, 498, 498]), rank 0
2024-05-10 03:57:51.949622: predicting 106-002
2024-05-10 03:57:51.976279: 106-002, shape torch.Size([1, 539, 498, 498]), rank 0
2024-05-10 03:59:36.698069: Validation complete
2024-05-10 03:59:36.699507: Mean Validation Dice:  0.6852001407717186
wandb: 
wandb: Run history:
wandb:            ema_fg_dice ▁▂▂▃▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇███▇█████████████████
wandb:   epoch_end_timestamps ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███
wandb: epoch_start_timestamps ▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███
wandb:                    lrs ███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:           mean_fg_dice ▁▄▄▆▅▆▆▅▆▆▅█▆▆▇▆▆▇▇▇▇▇▄▇▇▆▇█▆▆▇▅▆▇█▇▇█▇▇
wandb:           train_losses █▆▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_losses █▆▅▃▃▃▃▃▄▃▄▁▂▃▃▃▂▃▂▂▃▂▅▂▂▃▃▁▃▃▃▄▂▂▁▂▂▁▂▂
wandb: 
wandb: Run summary:
wandb:            ema_fg_dice 0.7061
wandb:   epoch_end_timestamps 1715327800.6791
wandb: epoch_start_timestamps 1715327559.44324
wandb:                    lrs 0.00894
wandb:           mean_fg_dice 0.71853
wandb:           train_losses -0.81284
wandb:             val_losses -0.56887
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset302_Calcium_OCTv2/nnUNetTrainer__nnUNetPlans__3d_32x512x512_b2/fold_1/wandb/offline-run-20240509_192447-7ve15vp0
wandb: Find logs at: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset302_Calcium_OCTv2/nnUNetTrainer__nnUNetPlans__3d_32x512x512_b2/fold_1/wandb/offline-run-20240509_192447-7ve15vp0/logs
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fa3119f3eb0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fa314037e20>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fa3191d40a0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fa23dbc6460>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fa3140b36a0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fa30f11c550>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
FOLD 1 CONFIG 3d_32x512x512_b2 TRAINER nnUNetTrainer

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 2 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 2 cases that I would like to predict

Predicting 101-045:
perform_everything_on_device: True
  0%|          | 0/23 [00:00<?, ?it/s]  4%|▍         | 1/23 [00:44<16:15, 44.35s/it]  9%|▊         | 2/23 [00:45<06:41, 19.14s/it] 13%|█▎        | 3/23 [00:47<03:41, 11.08s/it] 17%|█▋        | 4/23 [00:48<02:18,  7.29s/it] 22%|██▏       | 5/23 [00:50<01:33,  5.20s/it] 26%|██▌       | 6/23 [00:51<01:06,  3.93s/it] 30%|███       | 7/23 [00:53<00:50,  3.13s/it] 35%|███▍      | 8/23 [00:54<00:39,  2.61s/it] 39%|███▉      | 9/23 [00:56<00:31,  2.26s/it] 43%|████▎     | 10/23 [00:57<00:26,  2.02s/it] 48%|████▊     | 11/23 [00:59<00:22,  1.86s/it] 52%|█████▏    | 12/23 [01:00<00:19,  1.75s/it] 57%|█████▋    | 13/23 [01:02<00:16,  1.67s/it] 61%|██████    | 14/23 [01:03<00:14,  1.61s/it] 65%|██████▌   | 15/23 [01:05<00:12,  1.58s/it] 70%|██████▉   | 16/23 [01:06<00:10,  1.55s/it] 74%|███████▍  | 17/23 [01:08<00:09,  1.53s/it] 78%|███████▊  | 18/23 [01:09<00:07,  1.52s/it] 83%|████████▎ | 19/23 [01:11<00:06,  1.51s/it] 87%|████████▋ | 20/23 [01:12<00:04,  1.50s/it] 91%|█████████▏| 21/23 [01:14<00:03,  1.50s/it] 96%|█████████▌| 22/23 [01:15<00:01,  1.50s/it]100%|██████████| 23/23 [01:17<00:00,  1.50s/it]100%|██████████| 23/23 [01:17<00:00,  3.35s/it]
sending off prediction to background worker for resampling and export
done with 101-045

Predicting 706-005:
perform_everything_on_device: True
  0%|          | 0/23 [00:00<?, ?it/s]  4%|▍         | 1/23 [00:00<00:17,  1.24it/s]  9%|▊         | 2/23 [00:02<00:25,  1.21s/it] 13%|█▎        | 3/23 [00:03<00:26,  1.34s/it] 17%|█▋        | 4/23 [00:05<00:26,  1.40s/it] 22%|██▏       | 5/23 [00:06<00:25,  1.44s/it] 26%|██▌       | 6/23 [00:08<00:24,  1.46s/it] 30%|███       | 7/23 [00:09<00:23,  1.47s/it] 35%|███▍      | 8/23 [00:11<00:22,  1.48s/it] 39%|███▉      | 9/23 [00:12<00:20,  1.49s/it] 43%|████▎     | 10/23 [00:14<00:19,  1.49s/it] 48%|████▊     | 11/23 [00:15<00:17,  1.49s/it] 52%|█████▏    | 12/23 [00:17<00:16,  1.50s/it] 57%|█████▋    | 13/23 [00:18<00:14,  1.50s/it] 61%|██████    | 14/23 [00:20<00:13,  1.50s/it] 65%|██████▌   | 15/23 [00:21<00:11,  1.50s/it] 70%|██████▉   | 16/23 [00:23<00:10,  1.50s/it] 74%|███████▍  | 17/23 [00:24<00:09,  1.50s/it] 78%|███████▊  | 18/23 [00:26<00:07,  1.50s/it] 83%|████████▎ | 19/23 [00:27<00:06,  1.50s/it] 87%|████████▋ | 20/23 [00:29<00:04,  1.50s/it] 91%|█████████▏| 21/23 [00:30<00:03,  1.50s/it] 96%|█████████▌| 22/23 [00:32<00:01,  1.50s/it]100%|██████████| 23/23 [00:33<00:00,  1.50s/it]100%|██████████| 23/23 [00:33<00:00,  1.47s/it]
sending off prediction to background worker for resampling and export
done with 706-005
Completed FOLD 1 CONFIG 3d_32x512x512_b2 TRAINER nnUNetTrainer
