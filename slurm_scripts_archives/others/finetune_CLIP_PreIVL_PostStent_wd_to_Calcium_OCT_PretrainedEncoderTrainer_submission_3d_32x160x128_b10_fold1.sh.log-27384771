/home/gridsan/nchutisilp/.conda/envs/nnunet/bin/python
wandb: Tracking run with wandb version 0.16.6
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2024-11-15 06:51:24.780334: Using torch.compile...
/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
################### Loading pretrained weights from file  /home/gridsan/nchutisilp/projects/OpenAI-CLIP/logs/CLIP_PreIVL_PostStent_wd/nnunet.pt ###################
Below is the list of overlapping blocks in pretrained model and nnUNet architecture:
encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])
encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])
encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])
encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])
encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])
encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])
encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])
encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])
encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])
encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])
encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])
encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])
encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])
encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])
encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])
encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])
encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])
encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])
encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])
encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])
encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])
encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])
encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])
encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])
encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])
encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])
encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])
decoder.encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])
decoder.encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])
decoder.encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])
decoder.encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])
decoder.encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])
decoder.encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])
decoder.encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])
decoder.encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])
decoder.encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])
decoder.encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])
decoder.encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])
decoder.encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])
decoder.encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])
decoder.encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.stages.0.convs.0.conv.weight shape torch.Size([320, 640, 3, 3, 3])
decoder.stages.0.convs.0.conv.bias shape torch.Size([320])
decoder.stages.0.convs.0.norm.weight shape torch.Size([320])
decoder.stages.0.convs.0.norm.bias shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.0.weight shape torch.Size([320, 640, 3, 3, 3])
decoder.stages.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.stages.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.stages.0.convs.1.conv.bias shape torch.Size([320])
decoder.stages.0.convs.1.norm.weight shape torch.Size([320])
decoder.stages.0.convs.1.norm.bias shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.stages.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.stages.1.convs.0.conv.weight shape torch.Size([256, 512, 3, 3, 3])
decoder.stages.1.convs.0.conv.bias shape torch.Size([256])
decoder.stages.1.convs.0.norm.weight shape torch.Size([256])
decoder.stages.1.convs.0.norm.bias shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.0.weight shape torch.Size([256, 512, 3, 3, 3])
decoder.stages.1.convs.0.all_modules.0.bias shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.1.weight shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.1.bias shape torch.Size([256])
decoder.stages.1.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.stages.1.convs.1.conv.bias shape torch.Size([256])
decoder.stages.1.convs.1.norm.weight shape torch.Size([256])
decoder.stages.1.convs.1.norm.bias shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.stages.1.convs.1.all_modules.0.bias shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.1.weight shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.1.bias shape torch.Size([256])
decoder.stages.2.convs.0.conv.weight shape torch.Size([128, 256, 3, 3, 3])
decoder.stages.2.convs.0.conv.bias shape torch.Size([128])
decoder.stages.2.convs.0.norm.weight shape torch.Size([128])
decoder.stages.2.convs.0.norm.bias shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.0.weight shape torch.Size([128, 256, 3, 3, 3])
decoder.stages.2.convs.0.all_modules.0.bias shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.1.weight shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.1.bias shape torch.Size([128])
decoder.stages.2.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.stages.2.convs.1.conv.bias shape torch.Size([128])
decoder.stages.2.convs.1.norm.weight shape torch.Size([128])
decoder.stages.2.convs.1.norm.bias shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.stages.2.convs.1.all_modules.0.bias shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.1.weight shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.1.bias shape torch.Size([128])
decoder.stages.3.convs.0.conv.weight shape torch.Size([64, 128, 3, 3, 3])
decoder.stages.3.convs.0.conv.bias shape torch.Size([64])
decoder.stages.3.convs.0.norm.weight shape torch.Size([64])
decoder.stages.3.convs.0.norm.bias shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.0.weight shape torch.Size([64, 128, 3, 3, 3])
decoder.stages.3.convs.0.all_modules.0.bias shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.1.weight shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.1.bias shape torch.Size([64])
decoder.stages.3.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.stages.3.convs.1.conv.bias shape torch.Size([64])
decoder.stages.3.convs.1.norm.weight shape torch.Size([64])
decoder.stages.3.convs.1.norm.bias shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.stages.3.convs.1.all_modules.0.bias shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.1.weight shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.1.bias shape torch.Size([64])
decoder.stages.4.convs.0.conv.weight shape torch.Size([32, 64, 3, 3, 3])
decoder.stages.4.convs.0.conv.bias shape torch.Size([32])
decoder.stages.4.convs.0.norm.weight shape torch.Size([32])
decoder.stages.4.convs.0.norm.bias shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.0.weight shape torch.Size([32, 64, 3, 3, 3])
decoder.stages.4.convs.0.all_modules.0.bias shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.1.weight shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.1.bias shape torch.Size([32])
decoder.stages.4.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.stages.4.convs.1.conv.bias shape torch.Size([32])
decoder.stages.4.convs.1.norm.weight shape torch.Size([32])
decoder.stages.4.convs.1.norm.bias shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.stages.4.convs.1.all_modules.0.bias shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.1.weight shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.1.bias shape torch.Size([32])
decoder.transpconvs.0.weight shape torch.Size([320, 320, 1, 2, 2])
decoder.transpconvs.0.bias shape torch.Size([320])
decoder.transpconvs.1.weight shape torch.Size([320, 256, 2, 2, 2])
decoder.transpconvs.1.bias shape torch.Size([256])
decoder.transpconvs.2.weight shape torch.Size([256, 128, 2, 2, 2])
decoder.transpconvs.2.bias shape torch.Size([128])
decoder.transpconvs.3.weight shape torch.Size([128, 64, 2, 2, 2])
decoder.transpconvs.3.bias shape torch.Size([64])
decoder.transpconvs.4.weight shape torch.Size([64, 32, 2, 2, 2])
decoder.transpconvs.4.bias shape torch.Size([32])
################### Done ###################
2024-11-15 06:51:28.199185: do_dummy_2d_data_aug: True
2024-11-15 06:51:28.203335: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset302_Calcium_OCTv2/splits_final.json
2024-11-15 06:51:28.205709: The split file contains 3 splits.
2024-11-15 06:51:28.206560: Desired fold for training: 1
2024-11-15 06:51:28.207354: This split has 4 training and 2 validation cases.
using pin_memory on device 0
using pin_memory on device 0

This is the configuration used by this training:
Configuration name: 3d_32x160x128_b10
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 10, 'patch_size': [32, 160, 128], 'median_image_size_in_voxels': [375.0, 498.0, 498.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'inherits_from': '3d_fullres'} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset302_Calcium_OCTv2', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.4977976381778717, 'mean': 0.13332499563694, 'median': 0.08871842920780182, 'min': 0.0, 'percentile_00_5': 0.014754901640117168, 'percentile_99_5': 0.4977976381778717, 'std': 0.12022686749696732}}} 

2024-11-15 06:51:41.108206: unpacking dataset...
2024-11-15 06:51:46.798903: unpacking done...
2024-11-15 06:51:46.813679: Unable to plot network architecture: nnUNet_compile is enabled!
2024-11-15 06:51:46.902012: 
2024-11-15 06:51:46.903399: Epoch 0
2024-11-15 06:51:46.904672: Current learning rate: 0.0
2024-11-15 06:51:46.905850: encoder learning rate: 0.0
2024-11-15 06:51:46.906751: decoder.stages learning rate: 0.01
2024-11-15 06:51:46.907588: decoder.transpconvs learning rate: 0.01
2024-11-15 06:51:46.908395: decoder.seg_layers learning rate: 0.01
2024-11-15 06:54:57.013885: Validation loss improved from 1000.00000 to -0.19254! Patience: 0/50
2024-11-15 06:54:57.015138: train_loss -0.023
2024-11-15 06:54:57.016074: val_loss -0.1925
2024-11-15 06:54:57.016904: Pseudo dice [0.5758]
2024-11-15 06:54:57.017862: Epoch time: 190.11 s
2024-11-15 06:54:57.018717: Yayy! New best EMA pseudo Dice: 0.5758
2024-11-15 06:54:58.709895: 
2024-11-15 06:54:58.711222: Epoch 1
2024-11-15 06:54:58.712085: Current learning rate: 0.0
2024-11-15 06:54:58.713164: encoder learning rate: 0.0
2024-11-15 06:54:58.714097: decoder.stages learning rate: 0.00992
2024-11-15 06:54:58.714894: decoder.transpconvs learning rate: 0.00992
2024-11-15 06:54:58.715738: decoder.seg_layers learning rate: 0.00992
2024-11-15 06:57:01.105205: Validation loss improved from -0.19254 to -0.24927! Patience: 0/50
2024-11-15 06:57:01.106466: train_loss -0.1921
2024-11-15 06:57:01.107566: val_loss -0.2493
2024-11-15 06:57:01.108553: Pseudo dice [0.6132]
2024-11-15 06:57:01.109648: Epoch time: 122.4 s
2024-11-15 06:57:01.110367: Yayy! New best EMA pseudo Dice: 0.5796
2024-11-15 06:57:02.814438: 
2024-11-15 06:57:02.815879: Epoch 2
2024-11-15 06:57:02.816839: Current learning rate: 0.0
2024-11-15 06:57:02.817753: encoder learning rate: 0.0
2024-11-15 06:57:02.818622: decoder.stages learning rate: 0.00985
2024-11-15 06:57:02.819522: decoder.transpconvs learning rate: 0.00985
2024-11-15 06:57:02.820351: decoder.seg_layers learning rate: 0.00985
2024-11-15 06:59:03.092950: Validation loss improved from -0.24927 to -0.27955! Patience: 0/50
2024-11-15 06:59:03.094002: train_loss -0.2412
2024-11-15 06:59:03.095028: val_loss -0.2796
2024-11-15 06:59:03.095959: Pseudo dice [0.6226]
2024-11-15 06:59:03.096910: Epoch time: 120.28 s
2024-11-15 06:59:03.097887: Yayy! New best EMA pseudo Dice: 0.5839
2024-11-15 06:59:04.922414: 
2024-11-15 06:59:04.924143: Epoch 3
2024-11-15 06:59:04.925322: Current learning rate: 0.0
2024-11-15 06:59:04.926387: encoder learning rate: 0.0
2024-11-15 06:59:04.927307: decoder.stages learning rate: 0.00977
2024-11-15 06:59:04.928152: decoder.transpconvs learning rate: 0.00977
2024-11-15 06:59:04.928979: decoder.seg_layers learning rate: 0.00977
2024-11-15 07:01:14.308599: Validation loss improved from -0.27955 to -0.29274! Patience: 0/50
2024-11-15 07:01:14.310152: train_loss -0.2592
2024-11-15 07:01:14.311334: val_loss -0.2927
2024-11-15 07:01:14.312311: Pseudo dice [0.6445]
2024-11-15 07:01:14.313360: Epoch time: 129.39 s
2024-11-15 07:01:14.314214: Yayy! New best EMA pseudo Dice: 0.5899
2024-11-15 07:01:16.117181: 
2024-11-15 07:01:16.118728: Epoch 4
2024-11-15 07:01:16.122073: Current learning rate: 0.0
2024-11-15 07:01:16.123818: encoder learning rate: 0.0
2024-11-15 07:01:16.124858: decoder.stages learning rate: 0.0097
2024-11-15 07:01:16.125758: decoder.transpconvs learning rate: 0.0097
2024-11-15 07:01:16.126602: decoder.seg_layers learning rate: 0.0097
2024-11-15 07:03:21.658770: Validation loss did not improve from -0.29274. Patience: 1/50
2024-11-15 07:03:21.660210: train_loss -0.2787
2024-11-15 07:03:21.661521: val_loss -0.2839
2024-11-15 07:03:21.662619: Pseudo dice [0.6227]
2024-11-15 07:03:21.663906: Epoch time: 125.54 s
2024-11-15 07:03:22.664172: Yayy! New best EMA pseudo Dice: 0.5932
2024-11-15 07:03:24.638719: 
2024-11-15 07:03:24.640433: Epoch 5
2024-11-15 07:03:24.641499: Current learning rate: 0.0
2024-11-15 07:03:24.642731: encoder learning rate: 0.0
2024-11-15 07:03:24.643787: decoder.stages learning rate: 0.00962
2024-11-15 07:03:24.644758: decoder.transpconvs learning rate: 0.00962
2024-11-15 07:03:24.645556: decoder.seg_layers learning rate: 0.00962
2024-11-15 07:05:28.827254: Validation loss improved from -0.29274 to -0.30453! Patience: 1/50
2024-11-15 07:05:28.828567: train_loss -0.2928
2024-11-15 07:05:28.829755: val_loss -0.3045
2024-11-15 07:05:28.831049: Pseudo dice [0.6268]
2024-11-15 07:05:28.832187: Epoch time: 124.19 s
2024-11-15 07:05:28.833169: Yayy! New best EMA pseudo Dice: 0.5966
2024-11-15 07:05:30.574549: 
2024-11-15 07:05:30.577141: Epoch 6
2024-11-15 07:05:30.578470: Current learning rate: 0.0
2024-11-15 07:05:30.579783: encoder learning rate: 0.0
2024-11-15 07:05:30.580868: decoder.stages learning rate: 0.00955
2024-11-15 07:05:30.581869: decoder.transpconvs learning rate: 0.00955
2024-11-15 07:05:30.582840: decoder.seg_layers learning rate: 0.00955
2024-11-15 07:07:38.453329: Validation loss did not improve from -0.30453. Patience: 1/50
2024-11-15 07:07:38.454766: train_loss -0.3109
2024-11-15 07:07:38.456180: val_loss -0.2979
2024-11-15 07:07:38.457247: Pseudo dice [0.6557]
2024-11-15 07:07:38.458315: Epoch time: 127.88 s
2024-11-15 07:07:38.459352: Yayy! New best EMA pseudo Dice: 0.6025
2024-11-15 07:07:40.193424: 
2024-11-15 07:07:40.194821: Epoch 7
2024-11-15 07:07:40.196171: Current learning rate: 0.0
2024-11-15 07:07:40.197332: encoder learning rate: 0.0
2024-11-15 07:07:40.198408: decoder.stages learning rate: 0.00947
2024-11-15 07:07:40.199426: decoder.transpconvs learning rate: 0.00947
2024-11-15 07:07:40.200272: decoder.seg_layers learning rate: 0.00947
2024-11-15 07:09:31.086344: Validation loss improved from -0.30453 to -0.33063! Patience: 1/50
2024-11-15 07:09:31.087786: train_loss -0.3261
2024-11-15 07:09:31.088903: val_loss -0.3306
2024-11-15 07:09:31.089802: Pseudo dice [0.6656]
2024-11-15 07:09:31.090893: Epoch time: 110.9 s
2024-11-15 07:09:31.091812: Yayy! New best EMA pseudo Dice: 0.6088
2024-11-15 07:09:33.115707: 
2024-11-15 07:09:33.117408: Epoch 8
2024-11-15 07:09:33.118674: Current learning rate: 0.0
2024-11-15 07:09:33.119933: encoder learning rate: 0.0
2024-11-15 07:09:33.121115: decoder.stages learning rate: 0.0094
2024-11-15 07:09:33.122276: decoder.transpconvs learning rate: 0.0094
2024-11-15 07:09:33.123455: decoder.seg_layers learning rate: 0.0094
2024-11-15 07:11:36.570915: Validation loss did not improve from -0.33063. Patience: 1/50
2024-11-15 07:11:36.572211: train_loss -0.3407
2024-11-15 07:11:36.573385: val_loss -0.3151
2024-11-15 07:11:36.574338: Pseudo dice [0.6374]
2024-11-15 07:11:36.575295: Epoch time: 123.46 s
2024-11-15 07:11:36.576125: Yayy! New best EMA pseudo Dice: 0.6117
2024-11-15 07:11:38.856344: 
2024-11-15 07:11:38.857735: Epoch 9
2024-11-15 07:11:38.858491: Current learning rate: 0.0
2024-11-15 07:11:38.859472: encoder learning rate: 0.0
2024-11-15 07:11:38.860169: decoder.stages learning rate: 0.00932
2024-11-15 07:11:38.861042: decoder.transpconvs learning rate: 0.00932
2024-11-15 07:11:38.861748: decoder.seg_layers learning rate: 0.00932
2024-11-15 07:13:39.598150: Validation loss did not improve from -0.33063. Patience: 2/50
2024-11-15 07:13:39.599455: train_loss -0.334
2024-11-15 07:13:39.600338: val_loss -0.3206
2024-11-15 07:13:39.601151: Pseudo dice [0.6574]
2024-11-15 07:13:39.602071: Epoch time: 120.74 s
2024-11-15 07:13:40.026378: Yayy! New best EMA pseudo Dice: 0.6162
2024-11-15 07:13:41.702889: 
2024-11-15 07:13:41.704252: Epoch 10
2024-11-15 07:13:41.705055: Current learning rate: 0.0
2024-11-15 07:13:41.705969: encoder learning rate: 0.0
2024-11-15 07:13:41.706794: decoder.stages learning rate: 0.00925
2024-11-15 07:13:41.707573: decoder.transpconvs learning rate: 0.00925
2024-11-15 07:13:41.708345: decoder.seg_layers learning rate: 0.00925
2024-11-15 07:15:40.267658: Validation loss improved from -0.33063 to -0.33676! Patience: 2/50
2024-11-15 07:15:40.268951: train_loss -0.3483
2024-11-15 07:15:40.270028: val_loss -0.3368
2024-11-15 07:15:40.270960: Pseudo dice [0.6616]
2024-11-15 07:15:40.271768: Epoch time: 118.57 s
2024-11-15 07:15:40.272766: Yayy! New best EMA pseudo Dice: 0.6208
2024-11-15 07:15:41.953674: 
2024-11-15 07:15:41.955354: Epoch 11
2024-11-15 07:15:41.956465: Current learning rate: 0.0
2024-11-15 07:15:41.957566: encoder learning rate: 0.0
2024-11-15 07:15:41.958502: decoder.stages learning rate: 0.00917
2024-11-15 07:15:41.959295: decoder.transpconvs learning rate: 0.00917
2024-11-15 07:15:41.960114: decoder.seg_layers learning rate: 0.00917
2024-11-15 07:17:49.795729: Validation loss did not improve from -0.33676. Patience: 1/50
2024-11-15 07:17:49.796955: train_loss -0.3638
2024-11-15 07:17:49.797818: val_loss -0.3251
2024-11-15 07:17:49.798615: Pseudo dice [0.642]
2024-11-15 07:17:49.799423: Epoch time: 127.84 s
2024-11-15 07:17:49.800235: Yayy! New best EMA pseudo Dice: 0.6229
2024-11-15 07:17:51.510210: 
2024-11-15 07:17:51.511697: Epoch 12
2024-11-15 07:17:51.512563: Current learning rate: 0.0
2024-11-15 07:17:51.513554: encoder learning rate: 0.0
2024-11-15 07:17:51.514379: decoder.stages learning rate: 0.0091
2024-11-15 07:17:51.515136: decoder.transpconvs learning rate: 0.0091
2024-11-15 07:17:51.515833: decoder.seg_layers learning rate: 0.0091
2024-11-15 07:19:45.545965: Validation loss improved from -0.33676 to -0.34437! Patience: 1/50
2024-11-15 07:19:45.547299: train_loss -0.3533
2024-11-15 07:19:45.548574: val_loss -0.3444
2024-11-15 07:19:45.549657: Pseudo dice [0.6542]
2024-11-15 07:19:45.550725: Epoch time: 114.04 s
2024-11-15 07:19:45.551710: Yayy! New best EMA pseudo Dice: 0.626
2024-11-15 07:19:47.285910: 
2024-11-15 07:19:47.287305: Epoch 13
2024-11-15 07:19:47.288281: Current learning rate: 0.0
2024-11-15 07:19:47.289280: encoder learning rate: 0.0
2024-11-15 07:19:47.290033: decoder.stages learning rate: 0.00902
2024-11-15 07:19:47.290859: decoder.transpconvs learning rate: 0.00902
2024-11-15 07:19:47.291781: decoder.seg_layers learning rate: 0.00902
2024-11-15 07:21:55.382232: Validation loss did not improve from -0.34437. Patience: 1/50
2024-11-15 07:21:55.383694: train_loss -0.366
2024-11-15 07:21:55.384651: val_loss -0.3409
2024-11-15 07:21:55.385504: Pseudo dice [0.6483]
2024-11-15 07:21:55.386477: Epoch time: 128.1 s
2024-11-15 07:21:55.387346: Yayy! New best EMA pseudo Dice: 0.6283
2024-11-15 07:21:57.170062: 
2024-11-15 07:21:57.171116: Epoch 14
2024-11-15 07:21:57.171935: Current learning rate: 0.0
2024-11-15 07:21:57.172759: encoder learning rate: 0.0
2024-11-15 07:21:57.173638: decoder.stages learning rate: 0.00894
2024-11-15 07:21:57.174344: decoder.transpconvs learning rate: 0.00894
2024-11-15 07:21:57.175220: decoder.seg_layers learning rate: 0.00894
2024-11-15 07:23:59.946239: Validation loss did not improve from -0.34437. Patience: 2/50
2024-11-15 07:23:59.947472: train_loss -0.3733
2024-11-15 07:23:59.948533: val_loss -0.3414
2024-11-15 07:23:59.949362: Pseudo dice [0.6687]
2024-11-15 07:23:59.950267: Epoch time: 122.78 s
2024-11-15 07:24:00.353727: Yayy! New best EMA pseudo Dice: 0.6323
2024-11-15 07:24:02.082123: 
2024-11-15 07:24:02.083744: Epoch 15
2024-11-15 07:24:02.084769: Current learning rate: 0.0
2024-11-15 07:24:02.085798: encoder learning rate: 0.0
2024-11-15 07:24:02.087010: decoder.stages learning rate: 0.00887
2024-11-15 07:24:02.087999: decoder.transpconvs learning rate: 0.00887
2024-11-15 07:24:02.089003: decoder.seg_layers learning rate: 0.00887
2024-11-15 07:26:07.746772: Validation loss improved from -0.34437 to -0.36735! Patience: 2/50
2024-11-15 07:26:07.747787: train_loss -0.3782
2024-11-15 07:26:07.748681: val_loss -0.3673
2024-11-15 07:26:07.749475: Pseudo dice [0.6633]
2024-11-15 07:26:07.750337: Epoch time: 125.67 s
2024-11-15 07:26:07.751052: Yayy! New best EMA pseudo Dice: 0.6354
2024-11-15 07:26:09.518829: 
2024-11-15 07:26:09.520305: Epoch 16
2024-11-15 07:26:09.521382: Current learning rate: 0.0
2024-11-15 07:26:09.522377: encoder learning rate: 0.0
2024-11-15 07:26:09.523278: decoder.stages learning rate: 0.00879
2024-11-15 07:26:09.524229: decoder.transpconvs learning rate: 0.00879
2024-11-15 07:26:09.525015: decoder.seg_layers learning rate: 0.00879
2024-11-15 07:28:15.769517: Validation loss did not improve from -0.36735. Patience: 1/50
2024-11-15 07:28:15.770682: train_loss -0.3801
2024-11-15 07:28:15.771722: val_loss -0.3589
2024-11-15 07:28:15.772601: Pseudo dice [0.6715]
2024-11-15 07:28:15.773633: Epoch time: 126.25 s
2024-11-15 07:28:15.774657: Yayy! New best EMA pseudo Dice: 0.639
2024-11-15 07:28:17.552481: 
2024-11-15 07:28:17.554075: Epoch 17
2024-11-15 07:28:17.555120: Current learning rate: 0.0
2024-11-15 07:28:17.556112: encoder learning rate: 0.0
2024-11-15 07:28:17.557136: decoder.stages learning rate: 0.00872
2024-11-15 07:28:17.557998: decoder.transpconvs learning rate: 0.00872
2024-11-15 07:28:17.558744: decoder.seg_layers learning rate: 0.00872
2024-11-15 07:30:09.724210: Validation loss did not improve from -0.36735. Patience: 2/50
2024-11-15 07:30:09.725492: train_loss -0.3926
2024-11-15 07:30:09.726468: val_loss -0.3659
2024-11-15 07:30:09.727373: Pseudo dice [0.6794]
2024-11-15 07:30:09.728087: Epoch time: 112.17 s
2024-11-15 07:30:09.728849: Yayy! New best EMA pseudo Dice: 0.643
2024-11-15 07:30:11.486934: 
2024-11-15 07:30:11.488723: Epoch 18
2024-11-15 07:30:11.489760: Current learning rate: 0.0
2024-11-15 07:30:11.490605: encoder learning rate: 0.0
2024-11-15 07:30:11.491520: decoder.stages learning rate: 0.00864
2024-11-15 07:30:11.492253: decoder.transpconvs learning rate: 0.00864
2024-11-15 07:30:11.493160: decoder.seg_layers learning rate: 0.00864
2024-11-15 07:32:18.205434: Validation loss improved from -0.36735 to -0.37356! Patience: 2/50
2024-11-15 07:32:18.206845: train_loss -0.3967
2024-11-15 07:32:18.208104: val_loss -0.3736
2024-11-15 07:32:18.209283: Pseudo dice [0.6838]
2024-11-15 07:32:18.210498: Epoch time: 126.72 s
2024-11-15 07:32:18.211620: Yayy! New best EMA pseudo Dice: 0.6471
2024-11-15 07:32:20.001484: 
2024-11-15 07:32:20.002901: Epoch 19
2024-11-15 07:32:20.003913: Current learning rate: 0.0
2024-11-15 07:32:20.004928: encoder learning rate: 0.0
2024-11-15 07:32:20.005996: decoder.stages learning rate: 0.00856
2024-11-15 07:32:20.006850: decoder.transpconvs learning rate: 0.00856
2024-11-15 07:32:20.007586: decoder.seg_layers learning rate: 0.00856
2024-11-15 07:34:26.218066: Validation loss did not improve from -0.37356. Patience: 1/50
2024-11-15 07:34:26.219179: train_loss -0.3975
2024-11-15 07:34:26.220174: val_loss -0.3559
2024-11-15 07:34:26.221015: Pseudo dice [0.6693]
2024-11-15 07:34:26.221817: Epoch time: 126.22 s
2024-11-15 07:34:26.636250: Yayy! New best EMA pseudo Dice: 0.6493
2024-11-15 07:34:28.881106: 
2024-11-15 07:34:28.882582: Epoch 20
2024-11-15 07:34:28.883594: Current learning rate: 0.00849
2024-11-15 07:34:28.884620: encoder learning rate: 0.00849
2024-11-15 07:34:28.885514: decoder.stages learning rate: 0.00849
2024-11-15 07:34:28.886363: decoder.transpconvs learning rate: 0.00849
2024-11-15 07:34:28.887209: decoder.seg_layers learning rate: 0.00849
2024-11-15 07:36:35.752040: Validation loss did not improve from -0.37356. Patience: 2/50
2024-11-15 07:36:35.753266: train_loss -0.2547
2024-11-15 07:36:35.754417: val_loss -0.3542
2024-11-15 07:36:35.755388: Pseudo dice [0.6557]
2024-11-15 07:36:35.756258: Epoch time: 126.87 s
2024-11-15 07:36:35.757127: Yayy! New best EMA pseudo Dice: 0.65
2024-11-15 07:36:37.593814: 
2024-11-15 07:36:37.595474: Epoch 21
2024-11-15 07:36:37.596827: Current learning rate: 0.00841
2024-11-15 07:36:37.598184: encoder learning rate: 0.00841
2024-11-15 07:36:37.599397: decoder.stages learning rate: 0.00841
2024-11-15 07:36:37.600518: decoder.transpconvs learning rate: 0.00841
2024-11-15 07:36:37.601393: decoder.seg_layers learning rate: 0.00841
2024-11-15 07:38:41.375549: Validation loss did not improve from -0.37356. Patience: 3/50
2024-11-15 07:38:41.376854: train_loss -0.3645
2024-11-15 07:38:41.377990: val_loss -0.3176
2024-11-15 07:38:41.378951: Pseudo dice [0.6205]
2024-11-15 07:38:41.380000: Epoch time: 123.78 s
2024-11-15 07:38:42.761886: 
2024-11-15 07:38:42.764604: Epoch 22
2024-11-15 07:38:42.765869: Current learning rate: 0.00833
2024-11-15 07:38:42.767248: encoder learning rate: 0.00833
2024-11-15 07:38:42.768138: decoder.stages learning rate: 0.00833
2024-11-15 07:38:42.769210: decoder.transpconvs learning rate: 0.00833
2024-11-15 07:38:42.769985: decoder.seg_layers learning rate: 0.00833
2024-11-15 07:40:36.797057: Validation loss did not improve from -0.37356. Patience: 4/50
2024-11-15 07:40:36.798392: train_loss -0.4006
2024-11-15 07:40:36.799622: val_loss -0.3698
2024-11-15 07:40:36.800596: Pseudo dice [0.6602]
2024-11-15 07:40:36.801714: Epoch time: 114.04 s
2024-11-15 07:40:38.155072: 
2024-11-15 07:40:38.157760: Epoch 23
2024-11-15 07:40:38.159061: Current learning rate: 0.00826
2024-11-15 07:40:38.160377: encoder learning rate: 0.00826
2024-11-15 07:40:38.161379: decoder.stages learning rate: 0.00826
2024-11-15 07:40:38.162516: decoder.transpconvs learning rate: 0.00826
2024-11-15 07:40:38.163452: decoder.seg_layers learning rate: 0.00826
2024-11-15 07:42:48.730789: Validation loss did not improve from -0.37356. Patience: 5/50
2024-11-15 07:42:48.732014: train_loss -0.4316
2024-11-15 07:42:48.732990: val_loss -0.3311
2024-11-15 07:42:48.733962: Pseudo dice [0.6428]
2024-11-15 07:42:48.734905: Epoch time: 130.58 s
2024-11-15 07:42:50.104235: 
2024-11-15 07:42:50.105645: Epoch 24
2024-11-15 07:42:50.106834: Current learning rate: 0.00818
2024-11-15 07:42:50.108003: encoder learning rate: 0.00818
2024-11-15 07:42:50.109033: decoder.stages learning rate: 0.00818
2024-11-15 07:42:50.110073: decoder.transpconvs learning rate: 0.00818
2024-11-15 07:42:50.110979: decoder.seg_layers learning rate: 0.00818
2024-11-15 07:44:51.823744: Validation loss did not improve from -0.37356. Patience: 6/50
2024-11-15 07:44:51.825016: train_loss -0.4534
2024-11-15 07:44:51.826470: val_loss -0.3044
2024-11-15 07:44:51.827605: Pseudo dice [0.6244]
2024-11-15 07:44:51.828663: Epoch time: 121.72 s
2024-11-15 07:44:53.590428: 
2024-11-15 07:44:53.591733: Epoch 25
2024-11-15 07:44:53.592488: Current learning rate: 0.0081
2024-11-15 07:44:53.593410: encoder learning rate: 0.0081
2024-11-15 07:44:53.594249: decoder.stages learning rate: 0.0081
2024-11-15 07:44:53.595055: decoder.transpconvs learning rate: 0.0081
2024-11-15 07:44:53.595790: decoder.seg_layers learning rate: 0.0081
2024-11-15 07:46:44.947233: Validation loss improved from -0.37356 to -0.39785! Patience: 6/50
2024-11-15 07:46:44.948488: train_loss -0.4575
2024-11-15 07:46:44.949744: val_loss -0.3979
2024-11-15 07:46:44.950652: Pseudo dice [0.6917]
2024-11-15 07:46:44.951435: Epoch time: 111.36 s
2024-11-15 07:46:44.952177: Yayy! New best EMA pseudo Dice: 0.6501
2024-11-15 07:46:46.767751: 
2024-11-15 07:46:46.769253: Epoch 26
2024-11-15 07:46:46.770273: Current learning rate: 0.00803
2024-11-15 07:46:46.771176: encoder learning rate: 0.00803
2024-11-15 07:46:46.771920: decoder.stages learning rate: 0.00803
2024-11-15 07:46:46.772662: decoder.transpconvs learning rate: 0.00803
2024-11-15 07:46:46.773545: decoder.seg_layers learning rate: 0.00803
2024-11-15 07:48:54.175737: Validation loss did not improve from -0.39785. Patience: 1/50
2024-11-15 07:48:54.176999: train_loss -0.4728
2024-11-15 07:48:54.178089: val_loss -0.2869
2024-11-15 07:48:54.179030: Pseudo dice [0.6041]
2024-11-15 07:48:54.179924: Epoch time: 127.41 s
2024-11-15 07:48:55.550868: 
2024-11-15 07:48:55.552342: Epoch 27
2024-11-15 07:48:55.553587: Current learning rate: 0.00795
2024-11-15 07:48:55.554643: encoder learning rate: 0.00795
2024-11-15 07:48:55.555711: decoder.stages learning rate: 0.00795
2024-11-15 07:48:55.556550: decoder.transpconvs learning rate: 0.00795
2024-11-15 07:48:55.557726: decoder.seg_layers learning rate: 0.00795
2024-11-15 07:51:00.035608: Validation loss did not improve from -0.39785. Patience: 2/50
2024-11-15 07:51:00.036858: train_loss -0.4881
2024-11-15 07:51:00.037863: val_loss -0.2561
2024-11-15 07:51:00.038680: Pseudo dice [0.6077]
2024-11-15 07:51:00.039513: Epoch time: 124.49 s
2024-11-15 07:51:01.421931: 
2024-11-15 07:51:01.423363: Epoch 28
2024-11-15 07:51:01.424148: Current learning rate: 0.00787
2024-11-15 07:51:01.425086: encoder learning rate: 0.00787
2024-11-15 07:51:01.425899: decoder.stages learning rate: 0.00787
2024-11-15 07:51:01.426745: decoder.transpconvs learning rate: 0.00787
2024-11-15 07:51:01.427423: decoder.seg_layers learning rate: 0.00787
2024-11-15 07:53:08.590780: Validation loss did not improve from -0.39785. Patience: 3/50
2024-11-15 07:53:08.593770: train_loss -0.4977
2024-11-15 07:53:08.595693: val_loss -0.3161
2024-11-15 07:53:08.596811: Pseudo dice [0.6112]
2024-11-15 07:53:08.598004: Epoch time: 127.17 s
2024-11-15 07:53:10.024023: 
2024-11-15 07:53:10.025714: Epoch 29
2024-11-15 07:53:10.027083: Current learning rate: 0.0078
2024-11-15 07:53:10.028297: encoder learning rate: 0.0078
2024-11-15 07:53:10.029397: decoder.stages learning rate: 0.0078
2024-11-15 07:53:10.030268: decoder.transpconvs learning rate: 0.0078
2024-11-15 07:53:10.031159: decoder.seg_layers learning rate: 0.0078
2024-11-15 07:55:12.683290: Validation loss improved from -0.39785 to -0.42593! Patience: 3/50
2024-11-15 07:55:12.684546: train_loss -0.5232
2024-11-15 07:55:12.685625: val_loss -0.4259
2024-11-15 07:55:12.686695: Pseudo dice [0.6914]
2024-11-15 07:55:12.687938: Epoch time: 122.66 s
2024-11-15 07:55:14.452183: 
2024-11-15 07:55:14.453666: Epoch 30
2024-11-15 07:55:14.454983: Current learning rate: 0.00772
2024-11-15 07:55:14.456277: encoder learning rate: 0.00772
2024-11-15 07:55:14.457193: decoder.stages learning rate: 0.00772
2024-11-15 07:55:14.458061: decoder.transpconvs learning rate: 0.00772
2024-11-15 07:55:14.459189: decoder.seg_layers learning rate: 0.00772
2024-11-15 07:57:08.961142: Validation loss did not improve from -0.42593. Patience: 1/50
2024-11-15 07:57:08.962472: train_loss -0.5146
2024-11-15 07:57:08.967872: val_loss -0.3448
2024-11-15 07:57:08.968920: Pseudo dice [0.6337]
2024-11-15 07:57:08.969768: Epoch time: 114.51 s
2024-11-15 07:57:10.362717: 
2024-11-15 07:57:10.364401: Epoch 31
2024-11-15 07:57:10.365476: Current learning rate: 0.00764
2024-11-15 07:57:10.366477: encoder learning rate: 0.00764
2024-11-15 07:57:10.367329: decoder.stages learning rate: 0.00764
2024-11-15 07:57:10.368015: decoder.transpconvs learning rate: 0.00764
2024-11-15 07:57:10.368710: decoder.seg_layers learning rate: 0.00764
2024-11-15 07:59:15.523633: Validation loss improved from -0.42593 to -0.42910! Patience: 1/50
2024-11-15 07:59:15.524961: train_loss -0.5335
2024-11-15 07:59:15.526213: val_loss -0.4291
2024-11-15 07:59:15.527277: Pseudo dice [0.6983]
2024-11-15 07:59:15.528460: Epoch time: 125.16 s
2024-11-15 07:59:17.449481: 
2024-11-15 07:59:17.451048: Epoch 32
2024-11-15 07:59:17.451985: Current learning rate: 0.00756
2024-11-15 07:59:17.453002: encoder learning rate: 0.00756
2024-11-15 07:59:17.453941: decoder.stages learning rate: 0.00756
2024-11-15 07:59:17.454845: decoder.transpconvs learning rate: 0.00756
2024-11-15 07:59:17.455751: decoder.seg_layers learning rate: 0.00756
2024-11-15 08:01:21.300272: Validation loss improved from -0.42910 to -0.43131! Patience: 0/50
2024-11-15 08:01:21.301976: train_loss -0.5378
2024-11-15 08:01:21.303169: val_loss -0.4313
2024-11-15 08:01:21.304071: Pseudo dice [0.6816]
2024-11-15 08:01:21.304940: Epoch time: 123.85 s
2024-11-15 08:01:21.305733: Yayy! New best EMA pseudo Dice: 0.6518
2024-11-15 08:01:23.159860: 
2024-11-15 08:01:23.161395: Epoch 33
2024-11-15 08:01:23.162260: Current learning rate: 0.00749
2024-11-15 08:01:23.163333: encoder learning rate: 0.00749
2024-11-15 08:01:23.164143: decoder.stages learning rate: 0.00749
2024-11-15 08:01:23.165052: decoder.transpconvs learning rate: 0.00749
2024-11-15 08:01:23.165799: decoder.seg_layers learning rate: 0.00749
2024-11-15 08:03:17.604994: Validation loss improved from -0.43131 to -0.48104! Patience: 0/50
2024-11-15 08:03:17.606295: train_loss -0.5378
2024-11-15 08:03:17.607569: val_loss -0.481
2024-11-15 08:03:17.608507: Pseudo dice [0.7313]
2024-11-15 08:03:17.609552: Epoch time: 114.45 s
2024-11-15 08:03:17.610403: Yayy! New best EMA pseudo Dice: 0.6597
2024-11-15 08:03:19.426130: 
2024-11-15 08:03:19.427666: Epoch 34
2024-11-15 08:03:19.428732: Current learning rate: 0.00741
2024-11-15 08:03:19.429837: encoder learning rate: 0.00741
2024-11-15 08:03:19.430789: decoder.stages learning rate: 0.00741
2024-11-15 08:03:19.431718: decoder.transpconvs learning rate: 0.00741
2024-11-15 08:03:19.432503: decoder.seg_layers learning rate: 0.00741
2024-11-15 08:05:26.547401: Validation loss did not improve from -0.48104. Patience: 1/50
2024-11-15 08:05:26.548737: train_loss -0.5449
2024-11-15 08:05:26.549796: val_loss -0.3841
2024-11-15 08:05:26.550722: Pseudo dice [0.6508]
2024-11-15 08:05:26.551576: Epoch time: 127.12 s
2024-11-15 08:05:28.417600: 
2024-11-15 08:05:28.419141: Epoch 35
2024-11-15 08:05:28.420065: Current learning rate: 0.00733
2024-11-15 08:05:28.421242: encoder learning rate: 0.00733
2024-11-15 08:05:28.422169: decoder.stages learning rate: 0.00733
2024-11-15 08:05:28.423094: decoder.transpconvs learning rate: 0.00733
2024-11-15 08:05:28.423960: decoder.seg_layers learning rate: 0.00733
2024-11-15 08:07:33.385460: Validation loss did not improve from -0.48104. Patience: 2/50
2024-11-15 08:07:33.386699: train_loss -0.5549
2024-11-15 08:07:33.387887: val_loss -0.409
2024-11-15 08:07:33.388874: Pseudo dice [0.664]
2024-11-15 08:07:33.389931: Epoch time: 124.97 s
2024-11-15 08:07:34.823432: 
2024-11-15 08:07:34.824922: Epoch 36
2024-11-15 08:07:34.825871: Current learning rate: 0.00725
2024-11-15 08:07:34.826882: encoder learning rate: 0.00725
2024-11-15 08:07:34.827812: decoder.stages learning rate: 0.00725
2024-11-15 08:07:34.828705: decoder.transpconvs learning rate: 0.00725
2024-11-15 08:07:34.829852: decoder.seg_layers learning rate: 0.00725
2024-11-15 08:09:52.305113: Validation loss did not improve from -0.48104. Patience: 3/50
2024-11-15 08:09:52.306308: train_loss -0.5556
2024-11-15 08:09:52.307271: val_loss -0.4065
2024-11-15 08:09:52.308139: Pseudo dice [0.678]
2024-11-15 08:09:52.309040: Epoch time: 137.48 s
2024-11-15 08:09:52.309996: Yayy! New best EMA pseudo Dice: 0.6612
2024-11-15 08:09:54.187147: 
2024-11-15 08:09:54.188670: Epoch 37
2024-11-15 08:09:54.189482: Current learning rate: 0.00718
2024-11-15 08:09:54.190437: encoder learning rate: 0.00718
2024-11-15 08:09:54.191308: decoder.stages learning rate: 0.00718
2024-11-15 08:09:54.192162: decoder.transpconvs learning rate: 0.00718
2024-11-15 08:09:54.192864: decoder.seg_layers learning rate: 0.00718
2024-11-15 08:11:57.054573: Validation loss did not improve from -0.48104. Patience: 4/50
2024-11-15 08:11:57.055990: train_loss -0.5665
2024-11-15 08:11:57.057007: val_loss -0.377
2024-11-15 08:11:57.058162: Pseudo dice [0.6528]
2024-11-15 08:11:57.059216: Epoch time: 122.87 s
2024-11-15 08:11:58.481004: 
2024-11-15 08:11:58.482371: Epoch 38
2024-11-15 08:11:58.483527: Current learning rate: 0.0071
2024-11-15 08:11:58.484778: encoder learning rate: 0.0071
2024-11-15 08:11:58.485785: decoder.stages learning rate: 0.0071
2024-11-15 08:11:58.486788: decoder.transpconvs learning rate: 0.0071
2024-11-15 08:11:58.487833: decoder.seg_layers learning rate: 0.0071
2024-11-15 08:13:52.764104: Validation loss did not improve from -0.48104. Patience: 5/50
2024-11-15 08:13:52.765082: train_loss -0.5774
2024-11-15 08:13:52.765980: val_loss -0.4486
2024-11-15 08:13:52.766829: Pseudo dice [0.7026]
2024-11-15 08:13:52.767644: Epoch time: 114.29 s
2024-11-15 08:13:52.768392: Yayy! New best EMA pseudo Dice: 0.6646
2024-11-15 08:13:54.592643: 
2024-11-15 08:13:54.594136: Epoch 39
2024-11-15 08:13:54.595087: Current learning rate: 0.00702
2024-11-15 08:13:54.595961: encoder learning rate: 0.00702
2024-11-15 08:13:54.596810: decoder.stages learning rate: 0.00702
2024-11-15 08:13:54.597754: decoder.transpconvs learning rate: 0.00702
2024-11-15 08:13:54.598666: decoder.seg_layers learning rate: 0.00702
2024-11-15 08:16:05.371587: Validation loss did not improve from -0.48104. Patience: 6/50
2024-11-15 08:16:05.372861: train_loss -0.5751
2024-11-15 08:16:05.374185: val_loss -0.4218
2024-11-15 08:16:05.375252: Pseudo dice [0.6962]
2024-11-15 08:16:05.376321: Epoch time: 130.78 s
2024-11-15 08:16:05.786500: Yayy! New best EMA pseudo Dice: 0.6677
2024-11-15 08:16:07.713614: 
2024-11-15 08:16:07.715223: Epoch 40
2024-11-15 08:16:07.716483: Current learning rate: 0.00694
2024-11-15 08:16:07.717772: encoder learning rate: 0.00694
2024-11-15 08:16:07.718813: decoder.stages learning rate: 0.00694
2024-11-15 08:16:07.719944: decoder.transpconvs learning rate: 0.00694
2024-11-15 08:16:07.721039: decoder.seg_layers learning rate: 0.00694
2024-11-15 08:18:18.601757: Validation loss did not improve from -0.48104. Patience: 7/50
2024-11-15 08:18:18.603066: train_loss -0.5782
2024-11-15 08:18:18.604115: val_loss -0.4052
2024-11-15 08:18:18.605055: Pseudo dice [0.6798]
2024-11-15 08:18:18.605979: Epoch time: 130.89 s
2024-11-15 08:18:18.606907: Yayy! New best EMA pseudo Dice: 0.669
2024-11-15 08:18:20.529245: 
2024-11-15 08:18:20.530710: Epoch 41
2024-11-15 08:18:20.531588: Current learning rate: 0.00686
2024-11-15 08:18:20.532501: encoder learning rate: 0.00686
2024-11-15 08:18:20.533412: decoder.stages learning rate: 0.00686
2024-11-15 08:18:20.534302: decoder.transpconvs learning rate: 0.00686
2024-11-15 08:18:20.535129: decoder.seg_layers learning rate: 0.00686
2024-11-15 08:20:25.888628: Validation loss did not improve from -0.48104. Patience: 8/50
2024-11-15 08:20:25.889841: train_loss -0.5867
2024-11-15 08:20:25.890903: val_loss -0.3723
2024-11-15 08:20:25.891822: Pseudo dice [0.6511]
2024-11-15 08:20:25.892582: Epoch time: 125.36 s
2024-11-15 08:20:27.258097: 
2024-11-15 08:20:27.259565: Epoch 42
2024-11-15 08:20:27.260484: Current learning rate: 0.00679
2024-11-15 08:20:27.261452: encoder learning rate: 0.00679
2024-11-15 08:20:27.262273: decoder.stages learning rate: 0.00679
2024-11-15 08:20:27.263013: decoder.transpconvs learning rate: 0.00679
2024-11-15 08:20:27.263834: decoder.seg_layers learning rate: 0.00679
2024-11-15 08:22:37.341907: Validation loss did not improve from -0.48104. Patience: 9/50
2024-11-15 08:22:37.343200: train_loss -0.5954
2024-11-15 08:22:37.344288: val_loss -0.4257
2024-11-15 08:22:37.345376: Pseudo dice [0.6907]
2024-11-15 08:22:37.346276: Epoch time: 130.09 s
2024-11-15 08:22:37.347091: Yayy! New best EMA pseudo Dice: 0.6695
2024-11-15 08:22:39.520925: 
2024-11-15 08:22:39.522367: Epoch 43
2024-11-15 08:22:39.523228: Current learning rate: 0.00671
2024-11-15 08:22:39.524280: encoder learning rate: 0.00671
2024-11-15 08:22:39.525053: decoder.stages learning rate: 0.00671
2024-11-15 08:22:39.525885: decoder.transpconvs learning rate: 0.00671
2024-11-15 08:22:39.526716: decoder.seg_layers learning rate: 0.00671
2024-11-15 08:24:36.839578: Validation loss did not improve from -0.48104. Patience: 10/50
2024-11-15 08:24:36.840755: train_loss -0.6016
2024-11-15 08:24:36.841715: val_loss -0.4139
2024-11-15 08:24:36.842635: Pseudo dice [0.6991]
2024-11-15 08:24:36.843392: Epoch time: 117.32 s
2024-11-15 08:24:36.844104: Yayy! New best EMA pseudo Dice: 0.6725
2024-11-15 08:24:38.595997: 
2024-11-15 08:24:38.597425: Epoch 44
2024-11-15 08:24:38.598677: Current learning rate: 0.00663
2024-11-15 08:24:38.599728: encoder learning rate: 0.00663
2024-11-15 08:24:38.600598: decoder.stages learning rate: 0.00663
2024-11-15 08:24:38.601545: decoder.transpconvs learning rate: 0.00663
2024-11-15 08:24:38.602396: decoder.seg_layers learning rate: 0.00663
2024-11-15 08:26:48.326610: Validation loss did not improve from -0.48104. Patience: 11/50
2024-11-15 08:26:48.327847: train_loss -0.6045
2024-11-15 08:26:48.328982: val_loss -0.4472
2024-11-15 08:26:48.329909: Pseudo dice [0.71]
2024-11-15 08:26:48.330800: Epoch time: 129.73 s
2024-11-15 08:26:48.748992: Yayy! New best EMA pseudo Dice: 0.6762
2024-11-15 08:26:50.570274: 
2024-11-15 08:26:50.571599: Epoch 45
2024-11-15 08:26:50.572508: Current learning rate: 0.00655
2024-11-15 08:26:50.573474: encoder learning rate: 0.00655
2024-11-15 08:26:50.574239: decoder.stages learning rate: 0.00655
2024-11-15 08:26:50.575189: decoder.transpconvs learning rate: 0.00655
2024-11-15 08:26:50.575943: decoder.seg_layers learning rate: 0.00655
2024-11-15 08:28:55.409253: Validation loss did not improve from -0.48104. Patience: 12/50
2024-11-15 08:28:55.410529: train_loss -0.6006
2024-11-15 08:28:55.411500: val_loss -0.3895
2024-11-15 08:28:55.412371: Pseudo dice [0.6526]
2024-11-15 08:28:55.413253: Epoch time: 124.84 s
2024-11-15 08:28:56.791113: 
2024-11-15 08:28:56.792351: Epoch 46
2024-11-15 08:28:56.793185: Current learning rate: 0.00647
2024-11-15 08:28:56.794126: encoder learning rate: 0.00647
2024-11-15 08:28:56.794863: decoder.stages learning rate: 0.00647
2024-11-15 08:28:56.795633: decoder.transpconvs learning rate: 0.00647
2024-11-15 08:28:56.796490: decoder.seg_layers learning rate: 0.00647
2024-11-15 08:31:02.463388: Validation loss did not improve from -0.48104. Patience: 13/50
2024-11-15 08:31:02.467406: train_loss -0.6034
2024-11-15 08:31:02.469237: val_loss -0.3917
2024-11-15 08:31:02.470185: Pseudo dice [0.676]
2024-11-15 08:31:02.471253: Epoch time: 125.68 s
2024-11-15 08:31:03.929740: 
2024-11-15 08:31:03.931144: Epoch 47
2024-11-15 08:31:03.932050: Current learning rate: 0.00639
2024-11-15 08:31:03.932990: encoder learning rate: 0.00639
2024-11-15 08:31:03.933861: decoder.stages learning rate: 0.00639
2024-11-15 08:31:03.934677: decoder.transpconvs learning rate: 0.00639
2024-11-15 08:31:03.935527: decoder.seg_layers learning rate: 0.00639
2024-11-15 08:33:12.142569: Validation loss did not improve from -0.48104. Patience: 14/50
2024-11-15 08:33:12.143810: train_loss -0.6116
2024-11-15 08:33:12.145190: val_loss -0.4009
2024-11-15 08:33:12.146306: Pseudo dice [0.6763]
2024-11-15 08:33:12.147385: Epoch time: 128.22 s
2024-11-15 08:33:13.534397: 
2024-11-15 08:33:13.536177: Epoch 48
2024-11-15 08:33:13.537419: Current learning rate: 0.00631
2024-11-15 08:33:13.538509: encoder learning rate: 0.00631
2024-11-15 08:33:13.539394: decoder.stages learning rate: 0.00631
2024-11-15 08:33:13.540275: decoder.transpconvs learning rate: 0.00631
2024-11-15 08:33:13.541157: decoder.seg_layers learning rate: 0.00631
2024-11-15 08:35:18.456484: Validation loss improved from -0.48104 to -0.48706! Patience: 14/50
2024-11-15 08:35:18.458484: train_loss -0.6188
2024-11-15 08:35:18.459925: val_loss -0.4871
2024-11-15 08:35:18.460955: Pseudo dice [0.7251]
2024-11-15 08:35:18.461987: Epoch time: 124.93 s
2024-11-15 08:35:18.462935: Yayy! New best EMA pseudo Dice: 0.6794
2024-11-15 08:35:20.281288: 
2024-11-15 08:35:20.283067: Epoch 49
2024-11-15 08:35:20.284349: Current learning rate: 0.00624
2024-11-15 08:35:20.285607: encoder learning rate: 0.00624
2024-11-15 08:35:20.286535: decoder.stages learning rate: 0.00624
2024-11-15 08:35:20.287362: decoder.transpconvs learning rate: 0.00624
2024-11-15 08:35:20.288298: decoder.seg_layers learning rate: 0.00624
2024-11-15 08:37:26.150636: Validation loss did not improve from -0.48706. Patience: 1/50
2024-11-15 08:37:26.151871: train_loss -0.6215
2024-11-15 08:37:26.152795: val_loss -0.4563
2024-11-15 08:37:26.153638: Pseudo dice [0.7085]
2024-11-15 08:37:26.154575: Epoch time: 125.87 s
2024-11-15 08:37:26.556832: Yayy! New best EMA pseudo Dice: 0.6823
2024-11-15 08:37:28.367946: 
2024-11-15 08:37:28.369502: Epoch 50
2024-11-15 08:37:28.370654: Current learning rate: 0.00616
2024-11-15 08:37:28.371692: encoder learning rate: 0.00616
2024-11-15 08:37:28.372572: decoder.stages learning rate: 0.00616
2024-11-15 08:37:28.373358: decoder.transpconvs learning rate: 0.00616
2024-11-15 08:37:28.374199: decoder.seg_layers learning rate: 0.00616
2024-11-15 08:39:33.905453: Validation loss did not improve from -0.48706. Patience: 2/50
2024-11-15 08:39:33.906716: train_loss -0.6279
2024-11-15 08:39:33.907781: val_loss -0.3896
2024-11-15 08:39:33.908691: Pseudo dice [0.6677]
2024-11-15 08:39:33.909579: Epoch time: 125.54 s
2024-11-15 08:39:35.320744: 
2024-11-15 08:39:35.322263: Epoch 51
2024-11-15 08:39:35.323627: Current learning rate: 0.00608
2024-11-15 08:39:35.324918: encoder learning rate: 0.00608
2024-11-15 08:39:35.325997: decoder.stages learning rate: 0.00608
2024-11-15 08:39:35.327089: decoder.transpconvs learning rate: 0.00608
2024-11-15 08:39:35.328329: decoder.seg_layers learning rate: 0.00608
2024-11-15 08:41:33.543516: Validation loss did not improve from -0.48706. Patience: 3/50
2024-11-15 08:41:33.544880: train_loss -0.6377
2024-11-15 08:41:33.546053: val_loss -0.4322
2024-11-15 08:41:33.547105: Pseudo dice [0.7115]
2024-11-15 08:41:33.547997: Epoch time: 118.23 s
2024-11-15 08:41:33.548980: Yayy! New best EMA pseudo Dice: 0.6839
2024-11-15 08:41:35.337691: 
2024-11-15 08:41:35.339035: Epoch 52
2024-11-15 08:41:35.340196: Current learning rate: 0.006
2024-11-15 08:41:35.341520: encoder learning rate: 0.006
2024-11-15 08:41:35.342530: decoder.stages learning rate: 0.006
2024-11-15 08:41:35.343611: decoder.transpconvs learning rate: 0.006
2024-11-15 08:41:35.344667: decoder.seg_layers learning rate: 0.006
2024-11-15 08:43:43.935686: Validation loss did not improve from -0.48706. Patience: 4/50
2024-11-15 08:43:43.936980: train_loss -0.6387
2024-11-15 08:43:43.938114: val_loss -0.4366
2024-11-15 08:43:43.939105: Pseudo dice [0.7134]
2024-11-15 08:43:43.940041: Epoch time: 128.6 s
2024-11-15 08:43:43.940840: Yayy! New best EMA pseudo Dice: 0.6868
2024-11-15 08:43:45.746590: 
2024-11-15 08:43:45.748158: Epoch 53
2024-11-15 08:43:45.749269: Current learning rate: 0.00592
2024-11-15 08:43:45.750345: encoder learning rate: 0.00592
2024-11-15 08:43:45.751379: decoder.stages learning rate: 0.00592
2024-11-15 08:43:45.752266: decoder.transpconvs learning rate: 0.00592
2024-11-15 08:43:45.753195: decoder.seg_layers learning rate: 0.00592
2024-11-15 08:45:51.159084: Validation loss did not improve from -0.48706. Patience: 5/50
2024-11-15 08:45:51.160547: train_loss -0.6314
2024-11-15 08:45:51.161947: val_loss -0.4727
2024-11-15 08:45:51.163096: Pseudo dice [0.719]
2024-11-15 08:45:51.164264: Epoch time: 125.42 s
2024-11-15 08:45:51.165302: Yayy! New best EMA pseudo Dice: 0.6901
2024-11-15 08:45:52.990036: 
2024-11-15 08:45:52.991512: Epoch 54
2024-11-15 08:45:52.992477: Current learning rate: 0.00584
2024-11-15 08:45:52.993517: encoder learning rate: 0.00584
2024-11-15 08:45:52.994498: decoder.stages learning rate: 0.00584
2024-11-15 08:45:52.995305: decoder.transpconvs learning rate: 0.00584
2024-11-15 08:45:52.996035: decoder.seg_layers learning rate: 0.00584
2024-11-15 08:47:56.341127: Validation loss did not improve from -0.48706. Patience: 6/50
2024-11-15 08:47:56.342543: train_loss -0.6365
2024-11-15 08:47:56.343796: val_loss -0.4796
2024-11-15 08:47:56.344960: Pseudo dice [0.7254]
2024-11-15 08:47:56.346039: Epoch time: 123.35 s
2024-11-15 08:47:56.761883: Yayy! New best EMA pseudo Dice: 0.6936
2024-11-15 08:47:58.972129: 
2024-11-15 08:47:58.973753: Epoch 55
2024-11-15 08:47:58.974873: Current learning rate: 0.00576
2024-11-15 08:47:58.976093: encoder learning rate: 0.00576
2024-11-15 08:47:58.977146: decoder.stages learning rate: 0.00576
2024-11-15 08:47:58.978142: decoder.transpconvs learning rate: 0.00576
2024-11-15 08:47:58.979182: decoder.seg_layers learning rate: 0.00576
2024-11-15 08:50:05.871486: Validation loss did not improve from -0.48706. Patience: 7/50
2024-11-15 08:50:05.872743: train_loss -0.6432
2024-11-15 08:50:05.873861: val_loss -0.4561
2024-11-15 08:50:05.874677: Pseudo dice [0.7203]
2024-11-15 08:50:05.875639: Epoch time: 126.9 s
2024-11-15 08:50:05.876365: Yayy! New best EMA pseudo Dice: 0.6963
2024-11-15 08:50:07.678723: 
2024-11-15 08:50:07.680197: Epoch 56
2024-11-15 08:50:07.681193: Current learning rate: 0.00568
2024-11-15 08:50:07.682219: encoder learning rate: 0.00568
2024-11-15 08:50:07.683100: decoder.stages learning rate: 0.00568
2024-11-15 08:50:07.683977: decoder.transpconvs learning rate: 0.00568
2024-11-15 08:50:07.684964: decoder.seg_layers learning rate: 0.00568
2024-11-15 08:52:12.037861: Validation loss did not improve from -0.48706. Patience: 8/50
2024-11-15 08:52:12.039115: train_loss -0.6431
2024-11-15 08:52:12.040267: val_loss -0.4634
2024-11-15 08:52:12.041107: Pseudo dice [0.7163]
2024-11-15 08:52:12.041957: Epoch time: 124.36 s
2024-11-15 08:52:12.042780: Yayy! New best EMA pseudo Dice: 0.6983
2024-11-15 08:52:13.860841: 
2024-11-15 08:52:13.862516: Epoch 57
2024-11-15 08:52:13.863730: Current learning rate: 0.0056
2024-11-15 08:52:13.864879: encoder learning rate: 0.0056
2024-11-15 08:52:13.865798: decoder.stages learning rate: 0.0056
2024-11-15 08:52:13.866606: decoder.transpconvs learning rate: 0.0056
2024-11-15 08:52:13.867405: decoder.seg_layers learning rate: 0.0056
2024-11-15 08:54:21.500532: Validation loss did not improve from -0.48706. Patience: 9/50
2024-11-15 08:54:21.501865: train_loss -0.6507
2024-11-15 08:54:21.503054: val_loss -0.3739
2024-11-15 08:54:21.504083: Pseudo dice [0.6706]
2024-11-15 08:54:21.505189: Epoch time: 127.64 s
2024-11-15 08:54:22.932405: 
2024-11-15 08:54:22.933653: Epoch 58
2024-11-15 08:54:22.934663: Current learning rate: 0.00552
2024-11-15 08:54:22.935771: encoder learning rate: 0.00552
2024-11-15 08:54:22.936690: decoder.stages learning rate: 0.00552
2024-11-15 08:54:22.937551: decoder.transpconvs learning rate: 0.00552
2024-11-15 08:54:22.938359: decoder.seg_layers learning rate: 0.00552
2024-11-15 08:56:28.153624: Validation loss did not improve from -0.48706. Patience: 10/50
2024-11-15 08:56:28.154831: train_loss -0.6595
2024-11-15 08:56:28.155859: val_loss -0.4432
2024-11-15 08:56:28.156928: Pseudo dice [0.7201]
2024-11-15 08:56:28.157890: Epoch time: 125.22 s
2024-11-15 08:56:29.568089: 
2024-11-15 08:56:29.569551: Epoch 59
2024-11-15 08:56:29.570627: Current learning rate: 0.00544
2024-11-15 08:56:29.571583: encoder learning rate: 0.00544
2024-11-15 08:56:29.572444: decoder.stages learning rate: 0.00544
2024-11-15 08:56:29.573271: decoder.transpconvs learning rate: 0.00544
2024-11-15 08:56:29.574073: decoder.seg_layers learning rate: 0.00544
2024-11-15 08:58:25.731403: Validation loss did not improve from -0.48706. Patience: 11/50
2024-11-15 08:58:25.732749: train_loss -0.6649
2024-11-15 08:58:25.733819: val_loss -0.4538
2024-11-15 08:58:25.734763: Pseudo dice [0.7149]
2024-11-15 08:58:25.735749: Epoch time: 116.17 s
2024-11-15 08:58:26.225773: Yayy! New best EMA pseudo Dice: 0.6997
2024-11-15 08:58:28.082011: 
2024-11-15 08:58:28.083562: Epoch 60
2024-11-15 08:58:28.084486: Current learning rate: 0.00536
2024-11-15 08:58:28.085444: encoder learning rate: 0.00536
2024-11-15 08:58:28.086514: decoder.stages learning rate: 0.00536
2024-11-15 08:58:28.087381: decoder.transpconvs learning rate: 0.00536
2024-11-15 08:58:28.088140: decoder.seg_layers learning rate: 0.00536
2024-11-15 09:00:35.299300: Validation loss did not improve from -0.48706. Patience: 12/50
2024-11-15 09:00:35.300510: train_loss -0.6459
2024-11-15 09:00:35.314943: val_loss -0.3944
2024-11-15 09:00:35.318196: Pseudo dice [0.6852]
2024-11-15 09:00:35.320029: Epoch time: 127.22 s
2024-11-15 09:00:36.872595: 
2024-11-15 09:00:36.873655: Epoch 61
2024-11-15 09:00:36.874629: Current learning rate: 0.00528
2024-11-15 09:00:36.875642: encoder learning rate: 0.00528
2024-11-15 09:00:36.876594: decoder.stages learning rate: 0.00528
2024-11-15 09:00:36.877554: decoder.transpconvs learning rate: 0.00528
2024-11-15 09:00:36.878346: decoder.seg_layers learning rate: 0.00528
2024-11-15 09:02:50.385310: Validation loss did not improve from -0.48706. Patience: 13/50
2024-11-15 09:02:50.387260: train_loss -0.6627
2024-11-15 09:02:50.388332: val_loss -0.4395
2024-11-15 09:02:50.389214: Pseudo dice [0.7018]
2024-11-15 09:02:50.390200: Epoch time: 133.52 s
2024-11-15 09:02:51.869407: 
2024-11-15 09:02:51.871200: Epoch 62
2024-11-15 09:02:51.872402: Current learning rate: 0.0052
2024-11-15 09:02:51.873479: encoder learning rate: 0.0052
2024-11-15 09:02:51.874590: decoder.stages learning rate: 0.0052
2024-11-15 09:02:51.875571: decoder.transpconvs learning rate: 0.0052
2024-11-15 09:02:51.876587: decoder.seg_layers learning rate: 0.0052
2024-11-15 09:04:54.295205: Validation loss improved from -0.48706 to -0.49013! Patience: 13/50
2024-11-15 09:04:54.296372: train_loss -0.6711
2024-11-15 09:04:54.297626: val_loss -0.4901
2024-11-15 09:04:54.298664: Pseudo dice [0.7401]
2024-11-15 09:04:54.299809: Epoch time: 122.43 s
2024-11-15 09:04:54.300762: Yayy! New best EMA pseudo Dice: 0.7027
2024-11-15 09:04:56.162486: 
2024-11-15 09:04:56.163901: Epoch 63
2024-11-15 09:04:56.164892: Current learning rate: 0.00512
2024-11-15 09:04:56.166024: encoder learning rate: 0.00512
2024-11-15 09:04:56.167189: decoder.stages learning rate: 0.00512
2024-11-15 09:04:56.168143: decoder.transpconvs learning rate: 0.00512
2024-11-15 09:04:56.169037: decoder.seg_layers learning rate: 0.00512
2024-11-15 09:07:04.136586: Validation loss did not improve from -0.49013. Patience: 1/50
2024-11-15 09:07:04.137907: train_loss -0.6591
2024-11-15 09:07:04.139064: val_loss -0.4179
2024-11-15 09:07:04.140034: Pseudo dice [0.6947]
2024-11-15 09:07:04.140810: Epoch time: 127.98 s
2024-11-15 09:07:05.694492: 
2024-11-15 09:07:05.695760: Epoch 64
2024-11-15 09:07:05.696735: Current learning rate: 0.00504
2024-11-15 09:07:05.697643: encoder learning rate: 0.00504
2024-11-15 09:07:05.698448: decoder.stages learning rate: 0.00504
2024-11-15 09:07:05.699289: decoder.transpconvs learning rate: 0.00504
2024-11-15 09:07:05.699968: decoder.seg_layers learning rate: 0.00504
2024-11-15 09:09:14.834916: Validation loss did not improve from -0.49013. Patience: 2/50
2024-11-15 09:09:14.836142: train_loss -0.6704
2024-11-15 09:09:14.837218: val_loss -0.4708
2024-11-15 09:09:14.838143: Pseudo dice [0.7162]
2024-11-15 09:09:14.839183: Epoch time: 129.14 s
2024-11-15 09:09:15.213109: Yayy! New best EMA pseudo Dice: 0.7034
2024-11-15 09:09:17.038560: 
2024-11-15 09:09:17.040145: Epoch 65
2024-11-15 09:09:17.041363: Current learning rate: 0.00496
2024-11-15 09:09:17.042631: encoder learning rate: 0.00496
2024-11-15 09:09:17.043709: decoder.stages learning rate: 0.00496
2024-11-15 09:09:17.044703: decoder.transpconvs learning rate: 0.00496
2024-11-15 09:09:17.045762: decoder.seg_layers learning rate: 0.00496
2024-11-15 09:11:37.782781: Validation loss did not improve from -0.49013. Patience: 3/50
2024-11-15 09:11:37.784046: train_loss -0.6753
2024-11-15 09:11:37.785141: val_loss -0.4145
2024-11-15 09:11:37.786127: Pseudo dice [0.7054]
2024-11-15 09:11:37.787138: Epoch time: 140.75 s
2024-11-15 09:11:37.787910: Yayy! New best EMA pseudo Dice: 0.7036
2024-11-15 09:11:39.632085: 
2024-11-15 09:11:39.633064: Epoch 66
2024-11-15 09:11:39.633880: Current learning rate: 0.00487
2024-11-15 09:11:39.634737: encoder learning rate: 0.00487
2024-11-15 09:11:39.635509: decoder.stages learning rate: 0.00487
2024-11-15 09:11:39.636293: decoder.transpconvs learning rate: 0.00487
2024-11-15 09:11:39.637138: decoder.seg_layers learning rate: 0.00487
2024-11-15 09:13:48.059208: Validation loss did not improve from -0.49013. Patience: 4/50
2024-11-15 09:13:48.060468: train_loss -0.6775
2024-11-15 09:13:48.061472: val_loss -0.4426
2024-11-15 09:13:48.062320: Pseudo dice [0.7137]
2024-11-15 09:13:48.063073: Epoch time: 128.43 s
2024-11-15 09:13:48.063767: Yayy! New best EMA pseudo Dice: 0.7046
2024-11-15 09:13:50.391056: 
2024-11-15 09:13:50.392721: Epoch 67
2024-11-15 09:13:50.393777: Current learning rate: 0.00479
2024-11-15 09:13:50.394720: encoder learning rate: 0.00479
2024-11-15 09:13:50.395686: decoder.stages learning rate: 0.00479
2024-11-15 09:13:50.396578: decoder.transpconvs learning rate: 0.00479
2024-11-15 09:13:50.397293: decoder.seg_layers learning rate: 0.00479
2024-11-15 09:15:49.422860: Validation loss did not improve from -0.49013. Patience: 5/50
2024-11-15 09:15:49.424071: train_loss -0.679
2024-11-15 09:15:49.425195: val_loss -0.4328
2024-11-15 09:15:49.426044: Pseudo dice [0.6948]
2024-11-15 09:15:49.427067: Epoch time: 119.03 s
2024-11-15 09:15:50.881902: 
2024-11-15 09:15:50.883368: Epoch 68
2024-11-15 09:15:50.884304: Current learning rate: 0.00471
2024-11-15 09:15:50.885322: encoder learning rate: 0.00471
2024-11-15 09:15:50.886129: decoder.stages learning rate: 0.00471
2024-11-15 09:15:50.886962: decoder.transpconvs learning rate: 0.00471
2024-11-15 09:15:50.887742: decoder.seg_layers learning rate: 0.00471
2024-11-15 09:18:00.638789: Validation loss did not improve from -0.49013. Patience: 6/50
2024-11-15 09:18:00.640134: train_loss -0.6695
2024-11-15 09:18:00.641507: val_loss -0.4873
2024-11-15 09:18:00.642719: Pseudo dice [0.7398]
2024-11-15 09:18:00.643886: Epoch time: 129.76 s
2024-11-15 09:18:00.645055: Yayy! New best EMA pseudo Dice: 0.7072
2024-11-15 09:18:02.523672: 
2024-11-15 09:18:02.525274: Epoch 69
2024-11-15 09:18:02.526297: Current learning rate: 0.00463
2024-11-15 09:18:02.527265: encoder learning rate: 0.00463
2024-11-15 09:18:02.527979: decoder.stages learning rate: 0.00463
2024-11-15 09:18:02.528902: decoder.transpconvs learning rate: 0.00463
2024-11-15 09:18:02.529643: decoder.seg_layers learning rate: 0.00463
2024-11-15 09:20:10.536778: Validation loss did not improve from -0.49013. Patience: 7/50
2024-11-15 09:20:10.538169: train_loss -0.6823
2024-11-15 09:20:10.539180: val_loss -0.4674
2024-11-15 09:20:10.540138: Pseudo dice [0.7187]
2024-11-15 09:20:10.541094: Epoch time: 128.02 s
2024-11-15 09:20:10.961115: Yayy! New best EMA pseudo Dice: 0.7084
2024-11-15 09:20:12.851011: 
2024-11-15 09:20:12.853633: Epoch 70
2024-11-15 09:20:12.854818: Current learning rate: 0.00455
2024-11-15 09:20:12.856052: encoder learning rate: 0.00455
2024-11-15 09:20:12.856960: decoder.stages learning rate: 0.00455
2024-11-15 09:20:12.857733: decoder.transpconvs learning rate: 0.00455
2024-11-15 09:20:12.858508: decoder.seg_layers learning rate: 0.00455
2024-11-15 09:22:26.339923: Validation loss improved from -0.49013 to -0.50826! Patience: 7/50
2024-11-15 09:22:26.341352: train_loss -0.6847
2024-11-15 09:22:26.342308: val_loss -0.5083
2024-11-15 09:22:26.343242: Pseudo dice [0.7496]
2024-11-15 09:22:26.344158: Epoch time: 133.49 s
2024-11-15 09:22:26.344926: Yayy! New best EMA pseudo Dice: 0.7125
2024-11-15 09:22:28.228353: 
2024-11-15 09:22:28.230044: Epoch 71
2024-11-15 09:22:28.231039: Current learning rate: 0.00447
2024-11-15 09:22:28.232046: encoder learning rate: 0.00447
2024-11-15 09:22:28.232991: decoder.stages learning rate: 0.00447
2024-11-15 09:22:28.233957: decoder.transpconvs learning rate: 0.00447
2024-11-15 09:22:28.236409: decoder.seg_layers learning rate: 0.00447
2024-11-15 09:24:37.985186: Validation loss did not improve from -0.50826. Patience: 1/50
2024-11-15 09:24:37.986383: train_loss -0.693
2024-11-15 09:24:37.987494: val_loss -0.41
2024-11-15 09:24:37.988380: Pseudo dice [0.6956]
2024-11-15 09:24:37.989445: Epoch time: 129.76 s
2024-11-15 09:24:39.449102: 
2024-11-15 09:24:39.450736: Epoch 72
2024-11-15 09:24:39.451814: Current learning rate: 0.00438
2024-11-15 09:24:39.452919: encoder learning rate: 0.00438
2024-11-15 09:24:39.453855: decoder.stages learning rate: 0.00438
2024-11-15 09:24:39.454873: decoder.transpconvs learning rate: 0.00438
2024-11-15 09:24:39.456239: decoder.seg_layers learning rate: 0.00438
2024-11-15 09:26:41.836862: Validation loss did not improve from -0.50826. Patience: 2/50
2024-11-15 09:26:41.838234: train_loss -0.6868
2024-11-15 09:26:41.839431: val_loss -0.4716
2024-11-15 09:26:41.840464: Pseudo dice [0.7241]
2024-11-15 09:26:41.841492: Epoch time: 122.39 s
2024-11-15 09:26:43.315369: 
2024-11-15 09:26:43.317056: Epoch 73
2024-11-15 09:26:43.318414: Current learning rate: 0.0043
2024-11-15 09:26:43.319867: encoder learning rate: 0.0043
2024-11-15 09:26:43.321073: decoder.stages learning rate: 0.0043
2024-11-15 09:26:43.322529: decoder.transpconvs learning rate: 0.0043
2024-11-15 09:26:43.323765: decoder.seg_layers learning rate: 0.0043
2024-11-15 09:28:54.593867: Validation loss did not improve from -0.50826. Patience: 3/50
2024-11-15 09:28:54.595548: train_loss -0.6968
2024-11-15 09:28:54.596919: val_loss -0.4262
2024-11-15 09:28:54.597862: Pseudo dice [0.7092]
2024-11-15 09:28:54.598728: Epoch time: 131.28 s
2024-11-15 09:28:56.092776: 
2024-11-15 09:28:56.094275: Epoch 74
2024-11-15 09:28:56.095257: Current learning rate: 0.00422
2024-11-15 09:28:56.096147: encoder learning rate: 0.00422
2024-11-15 09:28:56.097085: decoder.stages learning rate: 0.00422
2024-11-15 09:28:56.097969: decoder.transpconvs learning rate: 0.00422
2024-11-15 09:28:56.098683: decoder.seg_layers learning rate: 0.00422
2024-11-15 09:31:07.416603: Validation loss did not improve from -0.50826. Patience: 4/50
2024-11-15 09:31:07.417940: train_loss -0.6984
2024-11-15 09:31:07.419037: val_loss -0.4476
2024-11-15 09:31:07.419932: Pseudo dice [0.7169]
2024-11-15 09:31:07.420728: Epoch time: 131.33 s
2024-11-15 09:31:09.366923: 
2024-11-15 09:31:09.368522: Epoch 75
2024-11-15 09:31:09.370863: Current learning rate: 0.00414
2024-11-15 09:31:09.372516: encoder learning rate: 0.00414
2024-11-15 09:31:09.373647: decoder.stages learning rate: 0.00414
2024-11-15 09:31:09.374461: decoder.transpconvs learning rate: 0.00414
2024-11-15 09:31:09.375211: decoder.seg_layers learning rate: 0.00414
2024-11-15 09:33:18.077996: Validation loss did not improve from -0.50826. Patience: 5/50
2024-11-15 09:33:18.079208: train_loss -0.7005
2024-11-15 09:33:18.080421: val_loss -0.3838
2024-11-15 09:33:18.081377: Pseudo dice [0.6821]
2024-11-15 09:33:18.082285: Epoch time: 128.72 s
2024-11-15 09:33:19.563622: 
2024-11-15 09:33:19.564776: Epoch 76
2024-11-15 09:33:19.565741: Current learning rate: 0.00405
2024-11-15 09:33:19.566771: encoder learning rate: 0.00405
2024-11-15 09:33:19.567730: decoder.stages learning rate: 0.00405
2024-11-15 09:33:19.568571: decoder.transpconvs learning rate: 0.00405
2024-11-15 09:33:19.569460: decoder.seg_layers learning rate: 0.00405
2024-11-15 09:35:31.561204: Validation loss did not improve from -0.50826. Patience: 6/50
2024-11-15 09:35:31.562515: train_loss -0.7012
2024-11-15 09:35:31.563727: val_loss -0.4466
2024-11-15 09:35:31.564764: Pseudo dice [0.7157]
2024-11-15 09:35:31.565756: Epoch time: 132.0 s
2024-11-15 09:35:33.205995: 
2024-11-15 09:35:33.207402: Epoch 77
2024-11-15 09:35:33.208546: Current learning rate: 0.00397
2024-11-15 09:35:33.209703: encoder learning rate: 0.00397
2024-11-15 09:35:33.210955: decoder.stages learning rate: 0.00397
2024-11-15 09:35:33.211767: decoder.transpconvs learning rate: 0.00397
2024-11-15 09:35:33.212656: decoder.seg_layers learning rate: 0.00397
2024-11-15 09:37:36.369864: Validation loss did not improve from -0.50826. Patience: 7/50
2024-11-15 09:37:36.371000: train_loss -0.701
2024-11-15 09:37:36.372024: val_loss -0.401
2024-11-15 09:37:36.373117: Pseudo dice [0.7033]
2024-11-15 09:37:36.373959: Epoch time: 123.17 s
2024-11-15 09:37:38.364978: 
2024-11-15 09:37:38.366576: Epoch 78
2024-11-15 09:37:38.367733: Current learning rate: 0.00389
2024-11-15 09:37:38.368841: encoder learning rate: 0.00389
2024-11-15 09:37:38.369735: decoder.stages learning rate: 0.00389
2024-11-15 09:37:38.370754: decoder.transpconvs learning rate: 0.00389
2024-11-15 09:37:38.371797: decoder.seg_layers learning rate: 0.00389
2024-11-15 09:39:53.206283: Validation loss did not improve from -0.50826. Patience: 8/50
2024-11-15 09:39:53.207708: train_loss -0.7033
2024-11-15 09:39:53.208821: val_loss -0.4861
2024-11-15 09:39:53.209664: Pseudo dice [0.7363]
2024-11-15 09:39:53.210402: Epoch time: 134.84 s
2024-11-15 09:39:54.706946: 
2024-11-15 09:39:54.708505: Epoch 79
2024-11-15 09:39:54.709285: Current learning rate: 0.0038
2024-11-15 09:39:54.710193: encoder learning rate: 0.0038
2024-11-15 09:39:54.711029: decoder.stages learning rate: 0.0038
2024-11-15 09:39:54.711836: decoder.transpconvs learning rate: 0.0038
2024-11-15 09:39:54.712538: decoder.seg_layers learning rate: 0.0038
2024-11-15 09:42:04.221912: Validation loss did not improve from -0.50826. Patience: 9/50
2024-11-15 09:42:04.223273: train_loss -0.7088
2024-11-15 09:42:04.224572: val_loss -0.4831
2024-11-15 09:42:04.225647: Pseudo dice [0.7362]
2024-11-15 09:42:04.226565: Epoch time: 129.52 s
2024-11-15 09:42:04.784179: Yayy! New best EMA pseudo Dice: 0.7144
2024-11-15 09:42:06.997585: 
2024-11-15 09:42:06.999157: Epoch 80
2024-11-15 09:42:07.000177: Current learning rate: 0.00372
2024-11-15 09:42:07.001212: encoder learning rate: 0.00372
2024-11-15 09:42:07.002200: decoder.stages learning rate: 0.00372
2024-11-15 09:42:07.003132: decoder.transpconvs learning rate: 0.00372
2024-11-15 09:42:07.003999: decoder.seg_layers learning rate: 0.00372
2024-11-15 09:44:05.772154: Validation loss did not improve from -0.50826. Patience: 10/50
2024-11-15 09:44:05.773237: train_loss -0.7081
2024-11-15 09:44:05.774154: val_loss -0.4302
2024-11-15 09:44:05.775060: Pseudo dice [0.6989]
2024-11-15 09:44:05.775940: Epoch time: 118.78 s
2024-11-15 09:44:07.337871: 
2024-11-15 09:44:07.352844: Epoch 81
2024-11-15 09:44:07.354129: Current learning rate: 0.00364
2024-11-15 09:44:07.355198: encoder learning rate: 0.00364
2024-11-15 09:44:07.356046: decoder.stages learning rate: 0.00364
2024-11-15 09:44:07.356922: decoder.transpconvs learning rate: 0.00364
2024-11-15 09:44:07.384374: decoder.seg_layers learning rate: 0.00364
2024-11-15 09:46:18.532927: Validation loss did not improve from -0.50826. Patience: 11/50
2024-11-15 09:46:18.534216: train_loss -0.7045
2024-11-15 09:46:18.535508: val_loss -0.4647
2024-11-15 09:46:18.536697: Pseudo dice [0.7331]
2024-11-15 09:46:18.537794: Epoch time: 131.2 s
2024-11-15 09:46:18.538738: Yayy! New best EMA pseudo Dice: 0.7149
2024-11-15 09:46:20.441380: 
2024-11-15 09:46:20.442874: Epoch 82
2024-11-15 09:46:20.443862: Current learning rate: 0.00355
2024-11-15 09:46:20.444908: encoder learning rate: 0.00355
2024-11-15 09:46:20.445939: decoder.stages learning rate: 0.00355
2024-11-15 09:46:20.446927: decoder.transpconvs learning rate: 0.00355
2024-11-15 09:46:20.447802: decoder.seg_layers learning rate: 0.00355
2024-11-15 09:48:33.006555: Validation loss did not improve from -0.50826. Patience: 12/50
2024-11-15 09:48:33.007943: train_loss -0.7148
2024-11-15 09:48:33.008945: val_loss -0.4658
2024-11-15 09:48:33.009940: Pseudo dice [0.7149]
2024-11-15 09:48:33.010870: Epoch time: 132.57 s
2024-11-15 09:48:33.011658: Yayy! New best EMA pseudo Dice: 0.7149
2024-11-15 09:48:34.833824: 
2024-11-15 09:48:34.835184: Epoch 83
2024-11-15 09:48:34.836275: Current learning rate: 0.00347
2024-11-15 09:48:34.837319: encoder learning rate: 0.00347
2024-11-15 09:48:34.838218: decoder.stages learning rate: 0.00347
2024-11-15 09:48:34.839019: decoder.transpconvs learning rate: 0.00347
2024-11-15 09:48:34.839844: decoder.seg_layers learning rate: 0.00347
2024-11-15 09:50:42.003087: Validation loss did not improve from -0.50826. Patience: 13/50
2024-11-15 09:50:42.004251: train_loss -0.7121
2024-11-15 09:50:42.005519: val_loss -0.4376
2024-11-15 09:50:42.006609: Pseudo dice [0.7146]
2024-11-15 09:50:42.007720: Epoch time: 127.17 s
2024-11-15 09:50:43.531219: 
2024-11-15 09:50:43.532724: Epoch 84
2024-11-15 09:50:43.533848: Current learning rate: 0.00338
2024-11-15 09:50:43.534965: encoder learning rate: 0.00338
2024-11-15 09:50:43.536146: decoder.stages learning rate: 0.00338
2024-11-15 09:50:43.537084: decoder.transpconvs learning rate: 0.00338
2024-11-15 09:50:43.538059: decoder.seg_layers learning rate: 0.00338
2024-11-15 09:52:59.742671: Validation loss did not improve from -0.50826. Patience: 14/50
2024-11-15 09:52:59.744793: train_loss -0.7186
2024-11-15 09:52:59.746335: val_loss -0.4559
2024-11-15 09:52:59.747354: Pseudo dice [0.7205]
2024-11-15 09:52:59.748312: Epoch time: 136.21 s
2024-11-15 09:53:00.143835: Yayy! New best EMA pseudo Dice: 0.7154
2024-11-15 09:53:01.877909: 
2024-11-15 09:53:01.879305: Epoch 85
2024-11-15 09:53:01.880382: Current learning rate: 0.0033
2024-11-15 09:53:01.881469: encoder learning rate: 0.0033
2024-11-15 09:53:01.882335: decoder.stages learning rate: 0.0033
2024-11-15 09:53:01.883221: decoder.transpconvs learning rate: 0.0033
2024-11-15 09:53:01.884122: decoder.seg_layers learning rate: 0.0033
2024-11-15 09:55:01.456313: Validation loss did not improve from -0.50826. Patience: 15/50
2024-11-15 09:55:01.457661: train_loss -0.7161
2024-11-15 09:55:01.458974: val_loss -0.4304
2024-11-15 09:55:01.459959: Pseudo dice [0.7042]
2024-11-15 09:55:01.461018: Epoch time: 119.58 s
2024-11-15 09:55:02.865570: 
2024-11-15 09:55:02.867527: Epoch 86
2024-11-15 09:55:02.868842: Current learning rate: 0.00321
2024-11-15 09:55:02.869911: encoder learning rate: 0.00321
2024-11-15 09:55:02.871170: decoder.stages learning rate: 0.00321
2024-11-15 09:55:02.872314: decoder.transpconvs learning rate: 0.00321
2024-11-15 09:55:02.873217: decoder.seg_layers learning rate: 0.00321
2024-11-15 09:57:20.572381: Validation loss did not improve from -0.50826. Patience: 16/50
2024-11-15 09:57:20.573778: train_loss -0.719
2024-11-15 09:57:20.574734: val_loss -0.4199
2024-11-15 09:57:20.575707: Pseudo dice [0.7073]
2024-11-15 09:57:20.576509: Epoch time: 137.71 s
2024-11-15 09:57:21.998379: 
2024-11-15 09:57:22.000045: Epoch 87
2024-11-15 09:57:22.001121: Current learning rate: 0.00313
2024-11-15 09:57:22.002079: encoder learning rate: 0.00313
2024-11-15 09:57:22.002959: decoder.stages learning rate: 0.00313
2024-11-15 09:57:22.003649: decoder.transpconvs learning rate: 0.00313
2024-11-15 09:57:22.004342: decoder.seg_layers learning rate: 0.00313
2024-11-15 09:59:32.195339: Validation loss did not improve from -0.50826. Patience: 17/50
2024-11-15 09:59:32.196466: train_loss -0.7168
2024-11-15 09:59:32.197495: val_loss -0.4339
2024-11-15 09:59:32.198383: Pseudo dice [0.7114]
2024-11-15 09:59:32.199295: Epoch time: 130.2 s
2024-11-15 09:59:33.581152: 
2024-11-15 09:59:33.582522: Epoch 88
2024-11-15 09:59:33.583613: Current learning rate: 0.00304
2024-11-15 09:59:33.584577: encoder learning rate: 0.00304
2024-11-15 09:59:33.585404: decoder.stages learning rate: 0.00304
2024-11-15 09:59:33.586232: decoder.transpconvs learning rate: 0.00304
2024-11-15 09:59:33.587118: decoder.seg_layers learning rate: 0.00304
2024-11-15 10:01:32.090416: Validation loss did not improve from -0.50826. Patience: 18/50
2024-11-15 10:01:32.091624: train_loss -0.723
2024-11-15 10:01:32.092674: val_loss -0.4216
2024-11-15 10:01:32.093528: Pseudo dice [0.7078]
2024-11-15 10:01:32.094461: Epoch time: 118.51 s
2024-11-15 10:01:33.891037: 
2024-11-15 10:01:33.892640: Epoch 89
2024-11-15 10:01:33.893780: Current learning rate: 0.00296
2024-11-15 10:01:33.895001: encoder learning rate: 0.00296
2024-11-15 10:01:33.895978: decoder.stages learning rate: 0.00296
2024-11-15 10:01:33.896985: decoder.transpconvs learning rate: 0.00296
2024-11-15 10:01:33.898044: decoder.seg_layers learning rate: 0.00296
2024-11-15 10:03:45.595940: Validation loss did not improve from -0.50826. Patience: 19/50
2024-11-15 10:03:45.597581: train_loss -0.7268
2024-11-15 10:03:45.599052: val_loss -0.344
2024-11-15 10:03:45.600162: Pseudo dice [0.6714]
2024-11-15 10:03:45.601473: Epoch time: 131.71 s
2024-11-15 10:03:47.438157: 
2024-11-15 10:03:47.439499: Epoch 90
2024-11-15 10:03:47.440503: Current learning rate: 0.00287
2024-11-15 10:03:47.441514: encoder learning rate: 0.00287
2024-11-15 10:03:47.442554: decoder.stages learning rate: 0.00287
2024-11-15 10:03:47.443343: decoder.transpconvs learning rate: 0.00287
2024-11-15 10:03:47.444090: decoder.seg_layers learning rate: 0.00287
2024-11-15 10:05:57.894966: Validation loss did not improve from -0.50826. Patience: 20/50
2024-11-15 10:05:57.916959: train_loss -0.7256
2024-11-15 10:05:57.965211: val_loss -0.393
2024-11-15 10:05:57.966476: Pseudo dice [0.7029]
2024-11-15 10:05:57.969306: Epoch time: 130.46 s
2024-11-15 10:06:00.071945: 
2024-11-15 10:06:00.075412: Epoch 91
2024-11-15 10:06:00.077044: Current learning rate: 0.00279
2024-11-15 10:06:00.078297: encoder learning rate: 0.00279
2024-11-15 10:06:00.079255: decoder.stages learning rate: 0.00279
2024-11-15 10:06:00.080062: decoder.transpconvs learning rate: 0.00279
2024-11-15 10:06:00.080896: decoder.seg_layers learning rate: 0.00279
2024-11-15 10:08:04.781309: Validation loss did not improve from -0.50826. Patience: 21/50
2024-11-15 10:08:04.784228: train_loss -0.7305
2024-11-15 10:08:04.785968: val_loss -0.4627
2024-11-15 10:08:04.787284: Pseudo dice [0.7294]
2024-11-15 10:08:04.788461: Epoch time: 124.71 s
2024-11-15 10:08:06.213747: 
2024-11-15 10:08:06.215383: Epoch 92
2024-11-15 10:08:06.216567: Current learning rate: 0.0027
2024-11-15 10:08:06.217824: encoder learning rate: 0.0027
2024-11-15 10:08:06.219053: decoder.stages learning rate: 0.0027
2024-11-15 10:08:06.220021: decoder.transpconvs learning rate: 0.0027
2024-11-15 10:08:06.221204: decoder.seg_layers learning rate: 0.0027
2024-11-15 10:10:23.306187: Validation loss did not improve from -0.50826. Patience: 22/50
2024-11-15 10:10:23.307422: train_loss -0.7247
2024-11-15 10:10:23.308336: val_loss -0.4016
2024-11-15 10:10:23.309155: Pseudo dice [0.7018]
2024-11-15 10:10:23.310007: Epoch time: 137.1 s
2024-11-15 10:10:24.748423: 
2024-11-15 10:10:24.749758: Epoch 93
2024-11-15 10:10:24.750489: Current learning rate: 0.00261
2024-11-15 10:10:24.751451: encoder learning rate: 0.00261
2024-11-15 10:10:24.752255: decoder.stages learning rate: 0.00261
2024-11-15 10:10:24.752954: decoder.transpconvs learning rate: 0.00261
2024-11-15 10:10:24.753634: decoder.seg_layers learning rate: 0.00261
2024-11-15 10:12:40.182085: Validation loss did not improve from -0.50826. Patience: 23/50
2024-11-15 10:12:40.183441: train_loss -0.7254
2024-11-15 10:12:40.184573: val_loss -0.478
2024-11-15 10:12:40.185420: Pseudo dice [0.7431]
2024-11-15 10:12:40.186239: Epoch time: 135.44 s
2024-11-15 10:12:41.610279: 
2024-11-15 10:12:41.611643: Epoch 94
2024-11-15 10:12:41.612709: Current learning rate: 0.00252
2024-11-15 10:12:41.613570: encoder learning rate: 0.00252
2024-11-15 10:12:41.614437: decoder.stages learning rate: 0.00252
2024-11-15 10:12:41.615178: decoder.transpconvs learning rate: 0.00252
2024-11-15 10:12:41.615844: decoder.seg_layers learning rate: 0.00252
2024-11-15 10:14:48.913956: Validation loss did not improve from -0.50826. Patience: 24/50
2024-11-15 10:14:48.915141: train_loss -0.7301
2024-11-15 10:14:48.916291: val_loss -0.4203
2024-11-15 10:14:48.917300: Pseudo dice [0.7027]
2024-11-15 10:14:48.918238: Epoch time: 127.31 s
2024-11-15 10:14:50.752037: 
2024-11-15 10:14:50.753192: Epoch 95
2024-11-15 10:14:50.754069: Current learning rate: 0.00244
2024-11-15 10:14:50.754978: encoder learning rate: 0.00244
2024-11-15 10:14:50.755838: decoder.stages learning rate: 0.00244
2024-11-15 10:14:50.756584: decoder.transpconvs learning rate: 0.00244
2024-11-15 10:14:50.757490: decoder.seg_layers learning rate: 0.00244
2024-11-15 10:17:07.984813: Validation loss did not improve from -0.50826. Patience: 25/50
2024-11-15 10:17:07.986096: train_loss -0.7355
2024-11-15 10:17:07.987221: val_loss -0.4664
2024-11-15 10:17:07.988192: Pseudo dice [0.735]
2024-11-15 10:17:07.989001: Epoch time: 137.24 s
2024-11-15 10:17:09.380874: 
2024-11-15 10:17:09.382246: Epoch 96
2024-11-15 10:17:09.383292: Current learning rate: 0.00235
2024-11-15 10:17:09.384170: encoder learning rate: 0.00235
2024-11-15 10:17:09.385005: decoder.stages learning rate: 0.00235
2024-11-15 10:17:09.385745: decoder.transpconvs learning rate: 0.00235
2024-11-15 10:17:09.386498: decoder.seg_layers learning rate: 0.00235
2024-11-15 10:19:13.963955: Validation loss did not improve from -0.50826. Patience: 26/50
2024-11-15 10:19:13.965277: train_loss -0.7359
2024-11-15 10:19:13.966165: val_loss -0.3768
2024-11-15 10:19:13.967061: Pseudo dice [0.6865]
2024-11-15 10:19:13.967898: Epoch time: 124.59 s
2024-11-15 10:19:15.440127: 
2024-11-15 10:19:15.441435: Epoch 97
2024-11-15 10:19:15.442269: Current learning rate: 0.00226
2024-11-15 10:19:15.443244: encoder learning rate: 0.00226
2024-11-15 10:19:15.443982: decoder.stages learning rate: 0.00226
2024-11-15 10:19:15.444686: decoder.transpconvs learning rate: 0.00226
2024-11-15 10:19:15.445480: decoder.seg_layers learning rate: 0.00226
2024-11-15 10:21:30.603434: Validation loss did not improve from -0.50826. Patience: 27/50
2024-11-15 10:21:30.604623: train_loss -0.7361
2024-11-15 10:21:30.605627: val_loss -0.4162
2024-11-15 10:21:30.606452: Pseudo dice [0.7028]
2024-11-15 10:21:30.607344: Epoch time: 135.17 s
2024-11-15 10:21:32.073896: 
2024-11-15 10:21:32.075253: Epoch 98
2024-11-15 10:21:32.076019: Current learning rate: 0.00217
2024-11-15 10:21:32.076928: encoder learning rate: 0.00217
2024-11-15 10:21:32.077693: decoder.stages learning rate: 0.00217
2024-11-15 10:21:32.078529: decoder.transpconvs learning rate: 0.00217
2024-11-15 10:21:32.079297: decoder.seg_layers learning rate: 0.00217
2024-11-15 10:23:46.106242: Validation loss did not improve from -0.50826. Patience: 28/50
2024-11-15 10:23:46.107655: train_loss -0.7416
2024-11-15 10:23:46.108770: val_loss -0.3716
2024-11-15 10:23:46.109665: Pseudo dice [0.6848]
2024-11-15 10:23:46.110793: Epoch time: 134.04 s
2024-11-15 10:23:47.589177: 
2024-11-15 10:23:47.590831: Epoch 99
2024-11-15 10:23:47.591921: Current learning rate: 0.00208
2024-11-15 10:23:47.592981: encoder learning rate: 0.00208
2024-11-15 10:23:47.593936: decoder.stages learning rate: 0.00208
2024-11-15 10:23:47.594779: decoder.transpconvs learning rate: 0.00208
2024-11-15 10:23:47.595646: decoder.seg_layers learning rate: 0.00208
2024-11-15 10:25:50.181445: Validation loss did not improve from -0.50826. Patience: 29/50
2024-11-15 10:25:50.183396: train_loss -0.7387
2024-11-15 10:25:50.184621: val_loss -0.4447
2024-11-15 10:25:50.185621: Pseudo dice [0.7194]
2024-11-15 10:25:50.186560: Epoch time: 122.6 s
2024-11-15 10:25:52.591874: 
2024-11-15 10:25:52.593664: Epoch 100
2024-11-15 10:25:52.594746: Current learning rate: 0.00199
2024-11-15 10:25:52.595853: encoder learning rate: 0.00199
2024-11-15 10:25:52.596754: decoder.stages learning rate: 0.00199
2024-11-15 10:25:52.597586: decoder.transpconvs learning rate: 0.00199
2024-11-15 10:25:52.598358: decoder.seg_layers learning rate: 0.00199
2024-11-15 10:28:08.261249: Validation loss did not improve from -0.50826. Patience: 30/50
2024-11-15 10:28:08.262628: train_loss -0.7427
2024-11-15 10:28:08.263994: val_loss -0.4825
2024-11-15 10:28:08.265153: Pseudo dice [0.737]
2024-11-15 10:28:08.266439: Epoch time: 135.67 s
2024-11-15 10:28:09.721829: 
2024-11-15 10:28:09.723373: Epoch 101
2024-11-15 10:28:09.724204: Current learning rate: 0.0019
2024-11-15 10:28:09.725260: encoder learning rate: 0.0019
2024-11-15 10:28:09.726128: decoder.stages learning rate: 0.0019
2024-11-15 10:28:09.726974: decoder.transpconvs learning rate: 0.0019
2024-11-15 10:28:09.727771: decoder.seg_layers learning rate: 0.0019
2024-11-15 10:30:26.898203: Validation loss did not improve from -0.50826. Patience: 31/50
2024-11-15 10:30:26.899477: train_loss -0.7443
2024-11-15 10:30:26.900528: val_loss -0.3782
2024-11-15 10:30:26.901450: Pseudo dice [0.6725]
2024-11-15 10:30:26.902267: Epoch time: 137.18 s
2024-11-15 10:30:28.327106: 
2024-11-15 10:30:28.328655: Epoch 102
2024-11-15 10:30:28.329564: Current learning rate: 0.00181
2024-11-15 10:30:28.330706: encoder learning rate: 0.00181
2024-11-15 10:30:28.331651: decoder.stages learning rate: 0.00181
2024-11-15 10:30:28.332556: decoder.transpconvs learning rate: 0.00181
2024-11-15 10:30:28.333306: decoder.seg_layers learning rate: 0.00181
2024-11-15 10:32:40.201324: Validation loss did not improve from -0.50826. Patience: 32/50
2024-11-15 10:32:40.202466: train_loss -0.7424
2024-11-15 10:32:40.203760: val_loss -0.4246
2024-11-15 10:32:40.204866: Pseudo dice [0.7123]
2024-11-15 10:32:40.205879: Epoch time: 131.88 s
2024-11-15 10:32:41.654294: 
2024-11-15 10:32:41.655510: Epoch 103
2024-11-15 10:32:41.656394: Current learning rate: 0.00172
2024-11-15 10:32:41.657449: encoder learning rate: 0.00172
2024-11-15 10:32:41.658328: decoder.stages learning rate: 0.00172
2024-11-15 10:32:41.659202: decoder.transpconvs learning rate: 0.00172
2024-11-15 10:32:41.660007: decoder.seg_layers learning rate: 0.00172
2024-11-15 10:34:55.714351: Validation loss did not improve from -0.50826. Patience: 33/50
2024-11-15 10:34:55.715551: train_loss -0.7413
2024-11-15 10:34:55.716716: val_loss -0.417
2024-11-15 10:34:55.717920: Pseudo dice [0.7043]
2024-11-15 10:34:55.719072: Epoch time: 134.06 s
2024-11-15 10:34:57.151419: 
2024-11-15 10:34:57.152449: Epoch 104
2024-11-15 10:34:57.153434: Current learning rate: 0.00163
2024-11-15 10:34:57.154585: encoder learning rate: 0.00163
2024-11-15 10:34:57.155607: decoder.stages learning rate: 0.00163
2024-11-15 10:34:57.158930: decoder.transpconvs learning rate: 0.00163
2024-11-15 10:34:57.160276: decoder.seg_layers learning rate: 0.00163
2024-11-15 10:37:09.809193: Validation loss did not improve from -0.50826. Patience: 34/50
2024-11-15 10:37:09.810478: train_loss -0.7466
2024-11-15 10:37:09.811454: val_loss -0.3317
2024-11-15 10:37:09.812324: Pseudo dice [0.6667]
2024-11-15 10:37:09.813154: Epoch time: 132.66 s
2024-11-15 10:37:11.979235: 
2024-11-15 10:37:11.980622: Epoch 105
2024-11-15 10:37:11.981483: Current learning rate: 0.00154
2024-11-15 10:37:11.982424: encoder learning rate: 0.00154
2024-11-15 10:37:11.983213: decoder.stages learning rate: 0.00154
2024-11-15 10:37:11.984058: decoder.transpconvs learning rate: 0.00154
2024-11-15 10:37:11.984863: decoder.seg_layers learning rate: 0.00154
2024-11-15 10:39:31.843581: Validation loss did not improve from -0.50826. Patience: 35/50
2024-11-15 10:39:31.845325: train_loss -0.7502
2024-11-15 10:39:31.846471: val_loss -0.4523
2024-11-15 10:39:31.847308: Pseudo dice [0.7263]
2024-11-15 10:39:31.848283: Epoch time: 139.87 s
2024-11-15 10:39:33.307579: 
2024-11-15 10:39:33.309233: Epoch 106
2024-11-15 10:39:33.310258: Current learning rate: 0.00145
2024-11-15 10:39:33.311230: encoder learning rate: 0.00145
2024-11-15 10:39:33.312074: decoder.stages learning rate: 0.00145
2024-11-15 10:39:33.312928: decoder.transpconvs learning rate: 0.00145
2024-11-15 10:39:33.313674: decoder.seg_layers learning rate: 0.00145
2024-11-15 10:41:45.222978: Validation loss did not improve from -0.50826. Patience: 36/50
2024-11-15 10:41:45.224550: train_loss -0.7459
2024-11-15 10:41:45.225730: val_loss -0.4193
2024-11-15 10:41:45.226987: Pseudo dice [0.7129]
2024-11-15 10:41:45.227983: Epoch time: 131.92 s
2024-11-15 10:41:46.718766: 
2024-11-15 10:41:46.720121: Epoch 107
2024-11-15 10:41:46.721066: Current learning rate: 0.00135
2024-11-15 10:41:46.721949: encoder learning rate: 0.00135
2024-11-15 10:41:46.722707: decoder.stages learning rate: 0.00135
2024-11-15 10:41:46.723388: decoder.transpconvs learning rate: 0.00135
2024-11-15 10:41:46.724293: decoder.seg_layers learning rate: 0.00135
2024-11-15 10:43:43.547713: Validation loss did not improve from -0.50826. Patience: 37/50
2024-11-15 10:43:43.549085: train_loss -0.7535
2024-11-15 10:43:43.550446: val_loss -0.4147
2024-11-15 10:43:43.551651: Pseudo dice [0.7108]
2024-11-15 10:43:43.552726: Epoch time: 116.83 s
2024-11-15 10:43:44.978066: 
2024-11-15 10:43:44.979716: Epoch 108
2024-11-15 10:43:44.988974: Current learning rate: 0.00126
2024-11-15 10:43:44.990240: encoder learning rate: 0.00126
2024-11-15 10:43:44.991355: decoder.stages learning rate: 0.00126
2024-11-15 10:43:44.992601: decoder.transpconvs learning rate: 0.00126
2024-11-15 10:43:44.993731: decoder.seg_layers learning rate: 0.00126
2024-11-15 10:45:58.477255: Validation loss did not improve from -0.50826. Patience: 38/50
2024-11-15 10:45:58.478338: train_loss -0.7494
2024-11-15 10:45:58.479289: val_loss -0.4557
2024-11-15 10:45:58.480236: Pseudo dice [0.7304]
2024-11-15 10:45:58.481185: Epoch time: 133.5 s
2024-11-15 10:45:59.903494: 
2024-11-15 10:45:59.904904: Epoch 109
2024-11-15 10:45:59.905892: Current learning rate: 0.00116
2024-11-15 10:45:59.906986: encoder learning rate: 0.00116
2024-11-15 10:45:59.907949: decoder.stages learning rate: 0.00116
2024-11-15 10:45:59.908864: decoder.transpconvs learning rate: 0.00116
2024-11-15 10:45:59.909572: decoder.seg_layers learning rate: 0.00116
2024-11-15 10:48:15.599990: Validation loss did not improve from -0.50826. Patience: 39/50
2024-11-15 10:48:15.601165: train_loss -0.7543
2024-11-15 10:48:15.602309: val_loss -0.4651
2024-11-15 10:48:15.603387: Pseudo dice [0.724]
2024-11-15 10:48:15.604381: Epoch time: 135.7 s
2024-11-15 10:48:17.442370: 
2024-11-15 10:48:17.443749: Epoch 110
2024-11-15 10:48:17.444643: Current learning rate: 0.00107
2024-11-15 10:48:17.445705: encoder learning rate: 0.00107
2024-11-15 10:48:17.446520: decoder.stages learning rate: 0.00107
2024-11-15 10:48:17.447401: decoder.transpconvs learning rate: 0.00107
2024-11-15 10:48:17.448253: decoder.seg_layers learning rate: 0.00107
2024-11-15 10:50:24.143584: Validation loss did not improve from -0.50826. Patience: 40/50
2024-11-15 10:50:24.144511: train_loss -0.7508
2024-11-15 10:50:24.145722: val_loss -0.4685
2024-11-15 10:50:24.146846: Pseudo dice [0.7225]
2024-11-15 10:50:24.148033: Epoch time: 126.7 s
2024-11-15 10:50:25.597905: 
2024-11-15 10:50:25.599180: Epoch 111
2024-11-15 10:50:25.600119: Current learning rate: 0.00097
2024-11-15 10:50:25.601113: encoder learning rate: 0.00097
2024-11-15 10:50:25.602046: decoder.stages learning rate: 0.00097
2024-11-15 10:50:25.602918: decoder.transpconvs learning rate: 0.00097
2024-11-15 10:50:25.603732: decoder.seg_layers learning rate: 0.00097
2024-11-15 10:52:40.451866: Validation loss did not improve from -0.50826. Patience: 41/50
2024-11-15 10:52:40.452834: train_loss -0.7517
2024-11-15 10:52:40.453789: val_loss -0.465
2024-11-15 10:52:40.454809: Pseudo dice [0.7357]
2024-11-15 10:52:40.455761: Epoch time: 134.86 s
2024-11-15 10:52:42.320364: 
2024-11-15 10:52:42.321536: Epoch 112
2024-11-15 10:52:42.322452: Current learning rate: 0.00087
2024-11-15 10:52:42.323428: encoder learning rate: 0.00087
2024-11-15 10:52:42.324330: decoder.stages learning rate: 0.00087
2024-11-15 10:52:42.325215: decoder.transpconvs learning rate: 0.00087
2024-11-15 10:52:42.326118: decoder.seg_layers learning rate: 0.00087
2024-11-15 10:54:53.577298: Validation loss did not improve from -0.50826. Patience: 42/50
2024-11-15 10:54:53.578442: train_loss -0.7543
2024-11-15 10:54:53.579470: val_loss -0.4682
2024-11-15 10:54:53.580457: Pseudo dice [0.7255]
2024-11-15 10:54:53.581441: Epoch time: 131.26 s
2024-11-15 10:54:53.582379: Yayy! New best EMA pseudo Dice: 0.7156
2024-11-15 10:54:55.488190: 
2024-11-15 10:54:55.489261: Epoch 113
2024-11-15 10:54:55.490120: Current learning rate: 0.00078
2024-11-15 10:54:55.491074: encoder learning rate: 0.00078
2024-11-15 10:54:55.491924: decoder.stages learning rate: 0.00078
2024-11-15 10:54:55.492804: decoder.transpconvs learning rate: 0.00078
2024-11-15 10:54:55.493612: decoder.seg_layers learning rate: 0.00078
2024-11-15 10:57:10.924443: Validation loss did not improve from -0.50826. Patience: 43/50
2024-11-15 10:57:10.925650: train_loss -0.7565
2024-11-15 10:57:10.926968: val_loss -0.4165
2024-11-15 10:57:10.927955: Pseudo dice [0.7079]
2024-11-15 10:57:10.929100: Epoch time: 135.44 s
2024-11-15 10:57:12.351454: 
2024-11-15 10:57:12.352855: Epoch 114
2024-11-15 10:57:12.353836: Current learning rate: 0.00067
2024-11-15 10:57:12.354934: encoder learning rate: 0.00067
2024-11-15 10:57:12.355882: decoder.stages learning rate: 0.00067
2024-11-15 10:57:12.356706: decoder.transpconvs learning rate: 0.00067
2024-11-15 10:57:12.357583: decoder.seg_layers learning rate: 0.00067
2024-11-15 10:59:26.357703: Validation loss did not improve from -0.50826. Patience: 44/50
2024-11-15 10:59:26.358911: train_loss -0.7557
2024-11-15 10:59:26.359936: val_loss -0.3973
2024-11-15 10:59:26.360778: Pseudo dice [0.6965]
2024-11-15 10:59:26.361567: Epoch time: 134.01 s
2024-11-15 10:59:28.288020: 
2024-11-15 10:59:28.289611: Epoch 115
2024-11-15 10:59:28.290654: Current learning rate: 0.00057
2024-11-15 10:59:28.291703: encoder learning rate: 0.00057
2024-11-15 10:59:28.292424: decoder.stages learning rate: 0.00057
2024-11-15 10:59:28.293155: decoder.transpconvs learning rate: 0.00057
2024-11-15 10:59:28.293882: decoder.seg_layers learning rate: 0.00057
2024-11-15 11:01:30.957065: Validation loss did not improve from -0.50826. Patience: 45/50
2024-11-15 11:01:30.958419: train_loss -0.7534
2024-11-15 11:01:30.959452: val_loss -0.431
2024-11-15 11:01:30.960341: Pseudo dice [0.7166]
2024-11-15 11:01:30.961327: Epoch time: 122.67 s
2024-11-15 11:01:32.430290: 
2024-11-15 11:01:32.431821: Epoch 116
2024-11-15 11:01:32.433041: Current learning rate: 0.00047
2024-11-15 11:01:32.434079: encoder learning rate: 0.00047
2024-11-15 11:01:32.435122: decoder.stages learning rate: 0.00047
2024-11-15 11:01:32.436061: decoder.transpconvs learning rate: 0.00047
2024-11-15 11:01:32.437133: decoder.seg_layers learning rate: 0.00047
2024-11-15 11:03:52.958011: Validation loss did not improve from -0.50826. Patience: 46/50
2024-11-15 11:03:52.959349: train_loss -0.7592
2024-11-15 11:03:52.960380: val_loss -0.4678
2024-11-15 11:03:52.961146: Pseudo dice [0.7338]
2024-11-15 11:03:52.961941: Epoch time: 140.53 s
2024-11-15 11:03:54.955481: 
2024-11-15 11:03:54.956546: Epoch 117
2024-11-15 11:03:54.957430: Current learning rate: 0.00036
2024-11-15 11:03:54.958378: encoder learning rate: 0.00036
2024-11-15 11:03:54.959102: decoder.stages learning rate: 0.00036
2024-11-15 11:03:54.959821: decoder.transpconvs learning rate: 0.00036
2024-11-15 11:03:54.960592: decoder.seg_layers learning rate: 0.00036
2024-11-15 11:06:10.712864: Validation loss did not improve from -0.50826. Patience: 47/50
2024-11-15 11:06:10.714440: train_loss -0.7573
2024-11-15 11:06:10.715617: val_loss -0.4054
2024-11-15 11:06:10.716649: Pseudo dice [0.698]
2024-11-15 11:06:10.717708: Epoch time: 135.76 s
2024-11-15 11:06:12.170680: 
2024-11-15 11:06:12.172191: Epoch 118
2024-11-15 11:06:12.173264: Current learning rate: 0.00025
2024-11-15 11:06:12.174270: encoder learning rate: 0.00025
2024-11-15 11:06:12.175058: decoder.stages learning rate: 0.00025
2024-11-15 11:06:12.175936: decoder.transpconvs learning rate: 0.00025
2024-11-15 11:06:12.176876: decoder.seg_layers learning rate: 0.00025
2024-11-15 11:08:24.783337: Validation loss did not improve from -0.50826. Patience: 48/50
2024-11-15 11:08:24.784408: train_loss -0.7607
2024-11-15 11:08:24.785414: val_loss -0.4445
2024-11-15 11:08:24.786287: Pseudo dice [0.719]
2024-11-15 11:08:24.789217: Epoch time: 132.62 s
2024-11-15 11:08:26.253911: 
2024-11-15 11:08:26.254978: Epoch 119
2024-11-15 11:08:26.255895: Current learning rate: 0.00013
2024-11-15 11:08:26.256848: encoder learning rate: 0.00013
2024-11-15 11:08:26.257694: decoder.stages learning rate: 0.00013
2024-11-15 11:08:26.258727: decoder.transpconvs learning rate: 0.00013
2024-11-15 11:08:26.259625: decoder.seg_layers learning rate: 0.00013
2024-11-15 11:10:41.412568: Validation loss did not improve from -0.50826. Patience: 49/50
2024-11-15 11:10:41.413895: train_loss -0.7618
2024-11-15 11:10:41.456034: val_loss -0.4194
2024-11-15 11:10:41.457059: Pseudo dice [0.7106]
2024-11-15 11:10:41.458543: Epoch time: 135.16 s
2024-11-15 11:10:43.700326: 
2024-11-15 11:10:43.701632: Epoch 120
2024-11-15 11:10:43.702576: Current learning rate: 0.0
2024-11-15 11:10:43.703528: encoder learning rate: 0.0
2024-11-15 11:10:43.704359: decoder.stages learning rate: 0.0
2024-11-15 11:10:43.705246: decoder.transpconvs learning rate: 0.0
2024-11-15 11:10:43.706122: decoder.seg_layers learning rate: 0.0
2024-11-15 11:12:56.665813: Validation loss did not improve from -0.50826. Patience: 50/50
2024-11-15 11:12:56.667989: train_loss -0.7624
2024-11-15 11:12:56.669328: val_loss -0.4235
2024-11-15 11:12:56.670370: Pseudo dice [0.715]
2024-11-15 11:12:56.671556: Epoch time: 132.97 s
2024-11-15 11:12:58.099770: Patience reached. Stopping training.
2024-11-15 11:12:58.516936: Training done.
2024-11-15 11:12:58.844700: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset302_Calcium_OCTv2/splits_final.json
2024-11-15 11:12:58.857175: The split file contains 3 splits.
2024-11-15 11:12:58.858254: Desired fold for training: 1
2024-11-15 11:12:58.859165: This split has 4 training and 2 validation cases.
2024-11-15 11:12:58.860219: predicting 101-044
2024-11-15 11:12:58.933080: 101-044, shape torch.Size([1, 404, 498, 498]), rank 0
2024-11-15 11:16:02.874325: predicting 106-002
2024-11-15 11:16:02.914045: 106-002, shape torch.Size([1, 539, 498, 498]), rank 0
2024-11-15 11:19:37.501267: Validation complete
2024-11-15 11:19:37.502868: Mean Validation Dice:  0.6933174805741715
wandb: 
wandb: Run history:
wandb:            ema_fg_dice ▁▂▂▃▄▄▅▅▄▄▄▅▅▆▆▆▆▇▇▇▇▇▇███████████▇█████
wandb:   epoch_end_timestamps ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb: epoch_start_timestamps ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:                    lrs ▁▁▁▁▁▁▁███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁
wandb:           mean_fg_dice ▁▄▄▄▄▅▅▃▃▂▃▇▅▅▆▅▆▇▇▇▆▇▆█▆▇▆▇▆▅▆▇▅▅▅▆▇▆▇▇
wandb:           train_losses █▆▅▅▅▅▄▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_losses █▆▆▅▅▄▄▅▆▇▅▂▃▃▃▄▂▃▂▂▃▂▃▁▃▂▃▃▃▅▃▂▄▄▅▃▂▃▂▃
wandb: 
wandb: Run summary:
wandb:            ema_fg_dice 0.71394
wandb:   epoch_end_timestamps 1731687176.66784
wandb: epoch_start_timestamps 1731687043.69888
wandb:                    lrs 0.0
wandb:           mean_fg_dice 0.71498
wandb:           train_losses -0.76243
wandb:             val_losses -0.4235
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset302_Calcium_OCTv2/nnUNetTrainer4PretrainedEncoder__nnUNetPlans__3d_32x160x128_b10/fold_1/wandb/offline-run-20241115_065119-6rv5frca
wandb: Find logs at: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset302_Calcium_OCTv2/nnUNetTrainer4PretrainedEncoder__nnUNetPlans__3d_32x160x128_b10/fold_1/wandb/offline-run-20241115_065119-6rv5frca/logs
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f61ed25efa0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f62508ab610>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6250a4a7c0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f61ecf21310>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f61eceed850>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f61eceedc10>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
FOLD 1 CONFIG 3d_32x160x128_b10 TRAINER nnUNetTrainer4PretrainedEncoder

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 2 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 2 cases that I would like to predict

Predicting 101-045:
perform_everything_on_device: True
  0%|          | 0/966 [00:00<?, ?it/s]  0%|          | 1/966 [00:01<17:08,  1.07s/it]  0%|          | 3/966 [00:01<05:30,  2.91it/s]  0%|          | 4/966 [00:01<04:15,  3.77it/s]  1%|          | 5/966 [00:01<03:28,  4.62it/s]  1%|          | 6/966 [00:01<02:57,  5.41it/s]  1%|          | 7/966 [00:01<02:36,  6.11it/s]  1%|          | 8/966 [00:01<02:22,  6.71it/s]  1%|          | 9/966 [00:01<02:13,  7.18it/s]  1%|          | 10/966 [00:02<02:06,  7.54it/s]  1%|          | 11/966 [00:02<02:02,  7.80it/s]  1%|          | 12/966 [00:02<01:59,  8.01it/s]  1%|▏         | 13/966 [00:02<01:56,  8.18it/s]  1%|▏         | 14/966 [00:02<01:55,  8.27it/s]  2%|▏         | 15/966 [00:02<01:54,  8.33it/s]  2%|▏         | 16/966 [00:02<01:53,  8.39it/s]  2%|▏         | 17/966 [00:02<01:52,  8.43it/s]  2%|▏         | 18/966 [00:03<01:52,  8.45it/s]  2%|▏         | 19/966 [00:03<01:52,  8.45it/s]  2%|▏         | 20/966 [00:03<01:51,  8.47it/s]  2%|▏         | 21/966 [00:03<01:51,  8.49it/s]  2%|▏         | 22/966 [00:03<01:51,  8.47it/s]  2%|▏         | 23/966 [00:03<01:51,  8.45it/s]  2%|▏         | 24/966 [00:03<01:51,  8.43it/s]  3%|▎         | 25/966 [00:03<01:51,  8.44it/s]  3%|▎         | 26/966 [00:03<01:51,  8.43it/s]  3%|▎         | 27/966 [00:04<01:51,  8.44it/s]  3%|▎         | 28/966 [00:04<01:50,  8.47it/s]  3%|▎         | 29/966 [00:04<01:50,  8.46it/s]  3%|▎         | 30/966 [00:04<01:50,  8.47it/s]  3%|▎         | 31/966 [00:04<01:50,  8.46it/s]  3%|▎         | 32/966 [00:04<01:50,  8.42it/s]  3%|▎         | 33/966 [00:04<01:50,  8.43it/s]  4%|▎         | 34/966 [00:04<01:50,  8.45it/s]  4%|▎         | 35/966 [00:05<01:50,  8.46it/s]  4%|▎         | 36/966 [00:05<01:49,  8.48it/s]  4%|▍         | 37/966 [00:05<01:49,  8.50it/s]  4%|▍         | 38/966 [00:05<01:49,  8.49it/s]  4%|▍         | 39/966 [00:05<01:49,  8.49it/s]  4%|▍         | 40/966 [00:05<01:49,  8.49it/s]  4%|▍         | 41/966 [00:05<01:48,  8.49it/s]  4%|▍         | 42/966 [00:05<01:48,  8.52it/s]  4%|▍         | 43/966 [00:05<01:48,  8.52it/s]  5%|▍         | 44/966 [00:06<01:48,  8.53it/s]  5%|▍         | 45/966 [00:06<01:48,  8.52it/s]  5%|▍         | 46/966 [00:06<01:48,  8.51it/s]  5%|▍         | 47/966 [00:06<01:48,  8.50it/s]  5%|▍         | 48/966 [00:06<01:47,  8.50it/s]  5%|▌         | 49/966 [00:06<01:48,  8.49it/s]  5%|▌         | 50/966 [00:06<01:47,  8.48it/s]  5%|▌         | 51/966 [00:06<01:47,  8.49it/s]  5%|▌         | 52/966 [00:07<01:47,  8.49it/s]  5%|▌         | 53/966 [00:07<01:47,  8.49it/s]  6%|▌         | 54/966 [00:07<01:47,  8.48it/s]  6%|▌         | 55/966 [00:07<01:47,  8.47it/s]  6%|▌         | 56/966 [00:07<01:47,  8.46it/s]  6%|▌         | 57/966 [00:07<01:47,  8.48it/s]  6%|▌         | 58/966 [00:07<01:46,  8.49it/s]  6%|▌         | 59/966 [00:07<01:46,  8.48it/s]  6%|▌         | 60/966 [00:07<01:46,  8.48it/s]  6%|▋         | 61/966 [00:08<01:47,  8.45it/s]  6%|▋         | 62/966 [00:08<01:46,  8.46it/s]  7%|▋         | 63/966 [00:08<01:46,  8.47it/s]  7%|▋         | 64/966 [00:08<01:46,  8.47it/s]  7%|▋         | 65/966 [00:08<01:46,  8.46it/s]  7%|▋         | 66/966 [00:08<01:46,  8.48it/s]  7%|▋         | 67/966 [00:08<01:45,  8.49it/s]  7%|▋         | 68/966 [00:08<01:45,  8.50it/s]  7%|▋         | 69/966 [00:09<01:45,  8.50it/s]  7%|▋         | 70/966 [00:09<01:45,  8.48it/s]  7%|▋         | 71/966 [00:09<01:45,  8.46it/s]  7%|▋         | 72/966 [00:09<01:45,  8.47it/s]  8%|▊         | 73/966 [00:09<01:45,  8.49it/s]  8%|▊         | 74/966 [00:09<01:45,  8.49it/s]  8%|▊         | 75/966 [00:09<01:44,  8.49it/s]  8%|▊         | 76/966 [00:09<01:44,  8.48it/s]  8%|▊         | 77/966 [00:09<01:44,  8.49it/s]  8%|▊         | 78/966 [00:10<01:44,  8.49it/s]  8%|▊         | 79/966 [00:10<01:44,  8.49it/s]  8%|▊         | 80/966 [00:10<01:44,  8.50it/s]  8%|▊         | 81/966 [00:10<01:44,  8.49it/s]  8%|▊         | 82/966 [00:10<01:44,  8.48it/s]  9%|▊         | 83/966 [00:10<01:44,  8.48it/s]  9%|▊         | 84/966 [00:10<01:43,  8.49it/s]  9%|▉         | 85/966 [00:10<01:43,  8.52it/s]  9%|▉         | 86/966 [00:11<01:43,  8.52it/s]  9%|▉         | 87/966 [00:11<01:43,  8.51it/s]  9%|▉         | 88/966 [00:11<01:43,  8.50it/s]  9%|▉         | 89/966 [00:11<01:43,  8.49it/s]  9%|▉         | 90/966 [00:11<01:43,  8.49it/s]  9%|▉         | 91/966 [00:11<01:42,  8.50it/s] 10%|▉         | 92/966 [00:11<01:42,  8.51it/s] 10%|▉         | 93/966 [00:11<01:42,  8.50it/s] 10%|▉         | 94/966 [00:11<01:42,  8.47it/s] 10%|▉         | 95/966 [00:12<01:42,  8.46it/s] 10%|▉         | 96/966 [00:12<01:42,  8.48it/s] 10%|█         | 97/966 [00:12<01:42,  8.46it/s] 10%|█         | 98/966 [00:12<01:42,  8.47it/s] 10%|█         | 99/966 [00:12<01:42,  8.47it/s] 10%|█         | 100/966 [00:12<01:42,  8.46it/s] 10%|█         | 101/966 [00:12<01:42,  8.45it/s] 11%|█         | 102/966 [00:12<01:42,  8.44it/s] 11%|█         | 103/966 [00:13<01:42,  8.43it/s] 11%|█         | 104/966 [00:13<01:42,  8.41it/s] 11%|█         | 105/966 [00:13<01:42,  8.44it/s] 11%|█         | 106/966 [00:13<01:41,  8.45it/s] 11%|█         | 107/966 [00:13<01:41,  8.46it/s] 11%|█         | 108/966 [00:13<01:41,  8.46it/s] 11%|█▏        | 109/966 [00:13<01:41,  8.46it/s] 11%|█▏        | 110/966 [00:13<01:41,  8.46it/s] 11%|█▏        | 111/966 [00:13<01:41,  8.45it/s] 12%|█▏        | 112/966 [00:14<01:41,  8.45it/s] 12%|█▏        | 113/966 [00:14<01:40,  8.46it/s] 12%|█▏        | 114/966 [00:14<01:40,  8.44it/s] 12%|█▏        | 115/966 [00:14<01:40,  8.45it/s] 12%|█▏        | 116/966 [00:14<01:40,  8.46it/s] 12%|█▏        | 117/966 [00:14<01:40,  8.47it/s] 12%|█▏        | 118/966 [00:14<01:39,  8.49it/s] 12%|█▏        | 119/966 [00:14<01:39,  8.49it/s] 12%|█▏        | 120/966 [00:15<01:39,  8.49it/s] 13%|█▎        | 121/966 [00:15<01:39,  8.51it/s] 13%|█▎        | 122/966 [00:15<01:39,  8.52it/s] 13%|█▎        | 123/966 [00:15<01:38,  8.52it/s] 13%|█▎        | 124/966 [00:15<01:39,  8.49it/s] 13%|█▎        | 125/966 [00:15<01:39,  8.46it/s] 13%|█▎        | 126/966 [00:15<01:39,  8.47it/s] 13%|█▎        | 127/966 [00:15<01:38,  8.48it/s] 13%|█▎        | 128/966 [00:15<01:38,  8.50it/s] 13%|█▎        | 129/966 [00:16<01:38,  8.51it/s] 13%|█▎        | 130/966 [00:16<01:38,  8.50it/s] 14%|█▎        | 131/966 [00:16<01:38,  8.50it/s] 14%|█▎        | 132/966 [00:16<01:38,  8.49it/s] 14%|█▍        | 133/966 [00:16<01:38,  8.49it/s] 14%|█▍        | 134/966 [00:16<01:38,  8.48it/s] 14%|█▍        | 135/966 [00:16<01:38,  8.47it/s] 14%|█▍        | 136/966 [00:16<01:37,  8.47it/s] 14%|█▍        | 137/966 [00:17<01:37,  8.47it/s] 14%|█▍        | 138/966 [00:17<01:37,  8.48it/s] 14%|█▍        | 139/966 [00:17<01:37,  8.48it/s] 14%|█▍        | 140/966 [00:17<01:37,  8.47it/s] 15%|█▍        | 141/966 [00:17<01:37,  8.47it/s] 15%|█▍        | 142/966 [00:17<01:37,  8.46it/s] 15%|█▍        | 143/966 [00:17<01:37,  8.45it/s] 15%|█▍        | 144/966 [00:17<01:37,  8.44it/s] 15%|█▌        | 145/966 [00:17<01:37,  8.44it/s] 15%|█▌        | 146/966 [00:18<01:37,  8.42it/s] 15%|█▌        | 147/966 [00:18<01:37,  8.43it/s] 15%|█▌        | 148/966 [00:18<01:36,  8.46it/s] 15%|█▌        | 149/966 [00:18<01:36,  8.46it/s] 16%|█▌        | 150/966 [00:18<01:36,  8.46it/s] 16%|█▌        | 151/966 [00:18<01:36,  8.44it/s] 16%|█▌        | 152/966 [00:18<01:36,  8.46it/s] 16%|█▌        | 153/966 [00:18<01:36,  8.47it/s] 16%|█▌        | 154/966 [00:19<01:36,  8.44it/s] 16%|█▌        | 155/966 [00:19<01:36,  8.44it/s] 16%|█▌        | 156/966 [00:19<01:35,  8.46it/s] 16%|█▋        | 157/966 [00:19<01:35,  8.47it/s] 16%|█▋        | 158/966 [00:19<01:35,  8.46it/s] 16%|█▋        | 159/966 [00:19<01:35,  8.44it/s] 17%|█▋        | 160/966 [00:19<01:35,  8.44it/s] 17%|█▋        | 161/966 [00:19<01:35,  8.46it/s] 17%|█▋        | 162/966 [00:20<01:35,  8.43it/s] 17%|█▋        | 163/966 [00:20<01:35,  8.45it/s] 17%|█▋        | 164/966 [00:20<01:34,  8.48it/s] 17%|█▋        | 165/966 [00:20<01:34,  8.48it/s] 17%|█▋        | 166/966 [00:20<01:34,  8.49it/s] 17%|█▋        | 167/966 [00:20<01:34,  8.47it/s] 17%|█▋        | 168/966 [00:20<01:34,  8.45it/s] 17%|█▋        | 169/966 [00:20<01:34,  8.45it/s] 18%|█▊        | 170/966 [00:20<01:34,  8.44it/s] 18%|█▊        | 171/966 [00:21<01:34,  8.43it/s] 18%|█▊        | 172/966 [00:21<01:34,  8.44it/s] 18%|█▊        | 173/966 [00:21<01:33,  8.47it/s] 18%|█▊        | 174/966 [00:21<01:33,  8.48it/s] 18%|█▊        | 175/966 [00:21<01:33,  8.48it/s] 18%|█▊        | 176/966 [00:21<01:33,  8.47it/s] 18%|█▊        | 177/966 [00:21<01:33,  8.45it/s] 18%|█▊        | 178/966 [00:21<01:33,  8.45it/s] 19%|█▊        | 179/966 [00:22<01:33,  8.43it/s] 19%|█▊        | 180/966 [00:22<01:33,  8.43it/s] 19%|█▊        | 181/966 [00:22<01:33,  8.44it/s] 19%|█▉        | 182/966 [00:22<01:32,  8.44it/s] 19%|█▉        | 183/966 [00:22<01:32,  8.43it/s] 19%|█▉        | 184/966 [00:22<01:32,  8.43it/s] 19%|█▉        | 185/966 [00:22<01:32,  8.43it/s] 19%|█▉        | 186/966 [00:22<01:32,  8.43it/s] 19%|█▉        | 187/966 [00:22<01:32,  8.43it/s] 19%|█▉        | 188/966 [00:23<01:32,  8.43it/s] 20%|█▉        | 189/966 [00:23<01:32,  8.42it/s] 20%|█▉        | 190/966 [00:23<01:32,  8.42it/s] 20%|█▉        | 191/966 [00:23<01:31,  8.44it/s] 20%|█▉        | 192/966 [00:23<01:31,  8.45it/s] 20%|█▉        | 193/966 [00:23<01:31,  8.44it/s] 20%|██        | 194/966 [00:23<01:31,  8.42it/s] 20%|██        | 195/966 [00:23<01:31,  8.44it/s] 20%|██        | 196/966 [00:24<01:31,  8.42it/s] 20%|██        | 197/966 [00:24<01:31,  8.42it/s] 20%|██        | 198/966 [00:24<01:31,  8.44it/s] 21%|██        | 199/966 [00:24<01:30,  8.46it/s] 21%|██        | 200/966 [00:24<01:30,  8.47it/s] 21%|██        | 201/966 [00:24<01:30,  8.47it/s] 21%|██        | 202/966 [00:24<01:30,  8.47it/s] 21%|██        | 203/966 [00:24<01:30,  8.48it/s] 21%|██        | 204/966 [00:24<01:29,  8.50it/s] 21%|██        | 205/966 [00:25<01:29,  8.51it/s] 21%|██▏       | 206/966 [00:25<01:29,  8.50it/s] 21%|██▏       | 207/966 [00:25<01:29,  8.50it/s] 22%|██▏       | 208/966 [00:25<01:29,  8.50it/s] 22%|██▏       | 209/966 [00:25<01:29,  8.50it/s] 22%|██▏       | 210/966 [00:25<01:29,  8.49it/s] 22%|██▏       | 211/966 [00:25<01:28,  8.50it/s] 22%|██▏       | 212/966 [00:25<01:28,  8.49it/s] 22%|██▏       | 213/966 [00:26<01:28,  8.48it/s] 22%|██▏       | 214/966 [00:26<01:28,  8.45it/s] 22%|██▏       | 215/966 [00:26<01:28,  8.44it/s] 22%|██▏       | 216/966 [00:26<01:28,  8.45it/s] 22%|██▏       | 217/966 [00:26<01:28,  8.48it/s] 23%|██▎       | 218/966 [00:26<01:28,  8.49it/s] 23%|██▎       | 219/966 [00:26<01:28,  8.48it/s] 23%|██▎       | 220/966 [00:26<01:27,  8.48it/s] 23%|██▎       | 221/966 [00:26<01:28,  8.45it/s] 23%|██▎       | 222/966 [00:27<01:27,  8.46it/s] 23%|██▎       | 223/966 [00:27<01:27,  8.46it/s] 23%|██▎       | 224/966 [00:27<01:27,  8.44it/s] 23%|██▎       | 225/966 [00:27<01:27,  8.45it/s] 23%|██▎       | 226/966 [00:27<01:27,  8.46it/s] 23%|██▎       | 227/966 [00:27<01:27,  8.45it/s] 24%|██▎       | 228/966 [00:27<01:27,  8.46it/s] 24%|██▎       | 229/966 [00:27<01:27,  8.46it/s] 24%|██▍       | 230/966 [00:28<01:26,  8.48it/s] 24%|██▍       | 231/966 [00:28<01:26,  8.47it/s] 24%|██▍       | 232/966 [00:28<01:26,  8.48it/s] 24%|██▍       | 233/966 [00:28<01:26,  8.47it/s] 24%|██▍       | 234/966 [00:28<01:26,  8.48it/s] 24%|██▍       | 235/966 [00:28<01:26,  8.46it/s] 24%|██▍       | 236/966 [00:28<01:26,  8.45it/s] 25%|██▍       | 237/966 [00:28<01:26,  8.44it/s] 25%|██▍       | 238/966 [00:28<01:26,  8.45it/s] 25%|██▍       | 239/966 [00:29<01:26,  8.43it/s] 25%|██▍       | 240/966 [00:29<01:25,  8.44it/s] 25%|██▍       | 241/966 [00:29<01:25,  8.46it/s] 25%|██▌       | 242/966 [00:29<01:25,  8.47it/s] 25%|██▌       | 243/966 [00:29<01:25,  8.47it/s] 25%|██▌       | 244/966 [00:29<01:25,  8.47it/s] 25%|██▌       | 245/966 [00:29<01:25,  8.45it/s] 25%|██▌       | 246/966 [00:29<01:25,  8.46it/s] 26%|██▌       | 247/966 [00:30<01:24,  8.47it/s] 26%|██▌       | 248/966 [00:30<01:24,  8.48it/s] 26%|██▌       | 249/966 [00:30<01:24,  8.49it/s] 26%|██▌       | 250/966 [00:30<01:24,  8.46it/s] 26%|██▌       | 251/966 [00:30<01:24,  8.44it/s] 26%|██▌       | 252/966 [00:30<01:24,  8.45it/s] 26%|██▌       | 253/966 [00:30<01:24,  8.47it/s] 26%|██▋       | 254/966 [00:30<01:23,  8.48it/s] 26%|██▋       | 255/966 [00:30<01:23,  8.48it/s] 27%|██▋       | 256/966 [00:31<01:23,  8.48it/s] 27%|██▋       | 257/966 [00:31<01:23,  8.46it/s] 27%|██▋       | 258/966 [00:31<01:23,  8.44it/s] 27%|██▋       | 259/966 [00:31<01:23,  8.42it/s] 27%|██▋       | 260/966 [00:31<01:23,  8.42it/s] 27%|██▋       | 261/966 [00:31<01:23,  8.43it/s] 27%|██▋       | 262/966 [00:31<01:23,  8.43it/s] 27%|██▋       | 263/966 [00:31<01:23,  8.43it/s] 27%|██▋       | 264/966 [00:32<01:23,  8.41it/s] 27%|██▋       | 265/966 [00:32<01:23,  8.43it/s] 28%|██▊       | 266/966 [00:32<01:23,  8.42it/s] 28%|██▊       | 267/966 [00:32<01:23,  8.42it/s] 28%|██▊       | 268/966 [00:32<01:22,  8.43it/s] 28%|██▊       | 269/966 [00:32<01:22,  8.42it/s] 28%|██▊       | 270/966 [00:32<01:22,  8.43it/s] 28%|██▊       | 271/966 [00:32<01:22,  8.42it/s] 28%|██▊       | 272/966 [00:33<01:22,  8.42it/s] 28%|██▊       | 273/966 [00:33<01:22,  8.42it/s] 28%|██▊       | 274/966 [00:33<01:22,  8.44it/s] 28%|██▊       | 275/966 [00:33<01:21,  8.45it/s] 29%|██▊       | 276/966 [00:33<01:21,  8.45it/s] 29%|██▊       | 277/966 [00:33<01:21,  8.46it/s] 29%|██▉       | 278/966 [00:33<01:21,  8.46it/s] 29%|██▉       | 279/966 [00:33<01:21,  8.44it/s] 29%|██▉       | 280/966 [00:33<01:21,  8.42it/s] 29%|██▉       | 281/966 [00:34<01:21,  8.42it/s] 29%|██▉       | 282/966 [00:34<01:21,  8.43it/s] 29%|██▉       | 283/966 [00:34<01:21,  8.41it/s] 29%|██▉       | 284/966 [00:34<01:21,  8.41it/s] 30%|██▉       | 285/966 [00:34<01:20,  8.41it/s] 30%|██▉       | 286/966 [00:34<01:20,  8.40it/s] 30%|██▉       | 287/966 [00:34<01:20,  8.40it/s] 30%|██▉       | 288/966 [00:34<01:20,  8.43it/s] 30%|██▉       | 289/966 [00:35<01:20,  8.43it/s] 30%|███       | 290/966 [00:35<01:20,  8.43it/s] 30%|███       | 291/966 [00:35<01:19,  8.46it/s] 30%|███       | 292/966 [00:35<01:19,  8.46it/s] 30%|███       | 293/966 [00:35<01:19,  8.44it/s] 30%|███       | 294/966 [00:35<01:19,  8.43it/s] 31%|███       | 295/966 [00:35<01:19,  8.42it/s] 31%|███       | 296/966 [00:35<01:19,  8.45it/s] 31%|███       | 297/966 [00:35<01:19,  8.44it/s] 31%|███       | 298/966 [00:36<01:19,  8.43it/s] 31%|███       | 299/966 [00:36<01:19,  8.44it/s] 31%|███       | 300/966 [00:36<01:18,  8.46it/s] 31%|███       | 301/966 [00:36<01:18,  8.47it/s] 31%|███▏      | 302/966 [00:36<01:18,  8.47it/s] 31%|███▏      | 303/966 [00:36<01:18,  8.45it/s] 31%|███▏      | 304/966 [00:36<01:18,  8.43it/s] 32%|███▏      | 305/966 [00:36<01:18,  8.42it/s] 32%|███▏      | 306/966 [00:37<01:18,  8.43it/s] 32%|███▏      | 307/966 [00:37<01:18,  8.44it/s] 32%|███▏      | 308/966 [00:37<01:17,  8.45it/s] 32%|███▏      | 309/966 [00:37<01:17,  8.43it/s] 32%|███▏      | 310/966 [00:37<01:17,  8.44it/s] 32%|███▏      | 311/966 [00:37<01:17,  8.42it/s] 32%|███▏      | 312/966 [00:37<01:17,  8.41it/s] 32%|███▏      | 313/966 [00:37<01:17,  8.41it/s] 33%|███▎      | 314/966 [00:37<01:17,  8.42it/s] 33%|███▎      | 315/966 [00:38<01:17,  8.42it/s] 33%|███▎      | 316/966 [00:38<01:17,  8.42it/s] 33%|███▎      | 317/966 [00:38<01:16,  8.43it/s] 33%|███▎      | 318/966 [00:38<01:16,  8.42it/s] 33%|███▎      | 319/966 [00:38<01:16,  8.41it/s] 33%|███▎      | 320/966 [00:38<01:16,  8.39it/s] 33%|███▎      | 321/966 [00:38<01:16,  8.41it/s] 33%|███▎      | 322/966 [00:38<01:16,  8.40it/s] 33%|███▎      | 323/966 [00:39<01:16,  8.42it/s] 34%|███▎      | 324/966 [00:39<01:16,  8.41it/s] 34%|███▎      | 325/966 [00:39<01:16,  8.42it/s] 34%|███▎      | 326/966 [00:39<01:16,  8.42it/s] 34%|███▍      | 327/966 [00:39<01:15,  8.42it/s] 34%|███▍      | 328/966 [00:39<01:15,  8.44it/s] 34%|███▍      | 329/966 [00:39<01:15,  8.45it/s] 34%|███▍      | 330/966 [00:39<01:15,  8.43it/s] 34%|███▍      | 331/966 [00:40<01:15,  8.43it/s] 34%|███▍      | 332/966 [00:40<01:15,  8.42it/s] 34%|███▍      | 333/966 [00:40<01:14,  8.44it/s] 35%|███▍      | 334/966 [00:40<01:14,  8.46it/s] 35%|███▍      | 335/966 [00:40<01:14,  8.45it/s] 35%|███▍      | 336/966 [00:40<01:14,  8.43it/s] 35%|███▍      | 337/966 [00:40<01:14,  8.44it/s] 35%|███▍      | 338/966 [00:40<01:14,  8.45it/s] 35%|███▌      | 339/966 [00:40<01:14,  8.45it/s] 35%|███▌      | 340/966 [00:41<01:14,  8.44it/s] 35%|███▌      | 341/966 [00:41<01:14,  8.44it/s] 35%|███▌      | 342/966 [00:41<01:13,  8.45it/s] 36%|███▌      | 343/966 [00:41<01:13,  8.47it/s] 36%|███▌      | 344/966 [00:41<01:13,  8.48it/s] 36%|███▌      | 345/966 [00:41<01:13,  8.47it/s] 36%|███▌      | 346/966 [00:41<01:13,  8.45it/s] 36%|███▌      | 347/966 [00:41<01:13,  8.46it/s] 36%|███▌      | 348/966 [00:42<01:13,  8.45it/s] 36%|███▌      | 349/966 [00:42<01:13,  8.44it/s] 36%|███▌      | 350/966 [00:42<01:13,  8.44it/s] 36%|███▋      | 351/966 [00:42<01:12,  8.44it/s] 36%|███▋      | 352/966 [00:42<01:12,  8.42it/s] 37%|███▋      | 353/966 [00:42<01:12,  8.43it/s] 37%|███▋      | 354/966 [00:42<01:12,  8.42it/s] 37%|███▋      | 355/966 [00:42<01:12,  8.42it/s] 37%|███▋      | 356/966 [00:42<01:12,  8.42it/s] 37%|███▋      | 357/966 [00:43<01:12,  8.41it/s] 37%|███▋      | 358/966 [00:43<01:12,  8.41it/s] 37%|███▋      | 359/966 [00:43<01:12,  8.41it/s] 37%|███▋      | 360/966 [00:43<01:11,  8.43it/s] 37%|███▋      | 361/966 [00:43<01:11,  8.43it/s] 37%|███▋      | 362/966 [00:43<01:11,  8.42it/s] 38%|███▊      | 363/966 [00:43<01:11,  8.40it/s] 38%|███▊      | 364/966 [00:43<01:11,  8.42it/s] 38%|███▊      | 365/966 [00:44<01:11,  8.42it/s] 38%|███▊      | 366/966 [00:44<01:11,  8.42it/s] 38%|███▊      | 367/966 [00:44<01:11,  8.40it/s] 38%|███▊      | 368/966 [00:44<01:11,  8.41it/s] 38%|███▊      | 369/966 [00:44<01:10,  8.41it/s] 38%|███▊      | 370/966 [00:44<01:10,  8.40it/s] 38%|███▊      | 371/966 [00:44<01:10,  8.41it/s] 39%|███▊      | 372/966 [00:44<01:10,  8.42it/s] 39%|███▊      | 373/966 [00:44<01:10,  8.45it/s] 39%|███▊      | 374/966 [00:45<01:10,  8.45it/s] 39%|███▉      | 375/966 [00:45<01:09,  8.46it/s] 39%|███▉      | 376/966 [00:45<01:09,  8.45it/s] 39%|███▉      | 377/966 [00:45<01:09,  8.44it/s] 39%|███▉      | 378/966 [00:45<01:09,  8.45it/s] 39%|███▉      | 379/966 [00:45<01:09,  8.46it/s] 39%|███▉      | 380/966 [00:45<01:09,  8.48it/s] 39%|███▉      | 381/966 [00:45<01:09,  8.46it/s] 40%|███▉      | 382/966 [00:46<01:09,  8.44it/s] 40%|███▉      | 383/966 [00:46<01:08,  8.46it/s] 40%|███▉      | 384/966 [00:46<01:08,  8.48it/s] 40%|███▉      | 385/966 [00:46<01:08,  8.49it/s] 40%|███▉      | 386/966 [00:46<01:08,  8.50it/s] 40%|████      | 387/966 [00:46<01:08,  8.49it/s] 40%|████      | 388/966 [00:46<01:08,  8.48it/s] 40%|████      | 389/966 [00:46<01:08,  8.46it/s] 40%|████      | 390/966 [00:47<01:08,  8.45it/s] 40%|████      | 391/966 [00:47<01:08,  8.45it/s] 41%|████      | 392/966 [00:47<01:07,  8.46it/s] 41%|████      | 393/966 [00:47<01:07,  8.46it/s] 41%|████      | 394/966 [00:47<01:07,  8.45it/s] 41%|████      | 395/966 [00:47<01:07,  8.43it/s] 41%|████      | 396/966 [00:47<01:07,  8.42it/s] 41%|████      | 397/966 [00:47<01:07,  8.40it/s] 41%|████      | 398/966 [00:47<01:07,  8.40it/s] 41%|████▏     | 399/966 [00:48<01:07,  8.40it/s] 41%|████▏     | 400/966 [00:48<01:07,  8.41it/s] 42%|████▏     | 401/966 [00:48<01:07,  8.41it/s] 42%|████▏     | 402/966 [00:48<01:07,  8.41it/s] 42%|████▏     | 403/966 [00:48<01:06,  8.43it/s] 42%|████▏     | 404/966 [00:48<01:06,  8.42it/s] 42%|████▏     | 405/966 [00:48<01:06,  8.41it/s] 42%|████▏     | 406/966 [00:48<01:06,  8.41it/s] 42%|████▏     | 407/966 [00:49<01:06,  8.42it/s] 42%|████▏     | 408/966 [00:49<01:06,  8.42it/s] 42%|████▏     | 409/966 [00:49<01:06,  8.40it/s] 42%|████▏     | 410/966 [00:49<01:06,  8.42it/s] 43%|████▎     | 411/966 [00:49<01:05,  8.42it/s] 43%|████▎     | 412/966 [00:49<01:05,  8.40it/s] 43%|████▎     | 413/966 [00:49<01:05,  8.40it/s] 43%|████▎     | 414/966 [00:49<01:05,  8.41it/s] 43%|████▎     | 415/966 [00:49<01:05,  8.42it/s] 43%|████▎     | 416/966 [00:50<01:05,  8.43it/s] 43%|████▎     | 417/966 [00:50<01:05,  8.43it/s] 43%|████▎     | 418/966 [00:50<01:05,  8.41it/s] 43%|████▎     | 419/966 [00:50<01:05,  8.41it/s] 43%|████▎     | 420/966 [00:50<01:04,  8.41it/s] 44%|████▎     | 421/966 [00:50<01:04,  8.42it/s] 44%|████▎     | 422/966 [00:50<01:04,  8.44it/s] 44%|████▍     | 423/966 [00:50<01:04,  8.45it/s] 44%|████▍     | 424/966 [00:51<01:04,  8.42it/s] 44%|████▍     | 425/966 [00:51<01:04,  8.41it/s] 44%|████▍     | 426/966 [00:51<01:04,  8.41it/s] 44%|████▍     | 427/966 [00:51<01:03,  8.42it/s] 44%|████▍     | 428/966 [00:51<01:03,  8.44it/s] 44%|████▍     | 429/966 [00:51<01:03,  8.44it/s] 45%|████▍     | 430/966 [00:51<01:03,  8.43it/s] 45%|████▍     | 431/966 [00:51<01:03,  8.43it/s] 45%|████▍     | 432/966 [00:51<01:03,  8.43it/s] 45%|████▍     | 433/966 [00:52<01:03,  8.43it/s] 45%|████▍     | 434/966 [00:52<01:03,  8.43it/s] 45%|████▌     | 435/966 [00:52<01:03,  8.43it/s] 45%|████▌     | 436/966 [00:52<01:02,  8.44it/s] 45%|████▌     | 437/966 [00:52<01:02,  8.43it/s] 45%|████▌     | 438/966 [00:52<01:02,  8.43it/s] 45%|████▌     | 439/966 [00:52<01:02,  8.45it/s] 46%|████▌     | 440/966 [00:52<01:02,  8.43it/s] 46%|████▌     | 441/966 [00:53<01:02,  8.41it/s] 46%|████▌     | 442/966 [00:53<01:02,  8.41it/s] 46%|████▌     | 443/966 [00:53<01:02,  8.43it/s] 46%|████▌     | 444/966 [00:53<01:01,  8.42it/s] 46%|████▌     | 445/966 [00:53<01:02,  8.39it/s] 46%|████▌     | 446/966 [00:53<01:01,  8.39it/s] 46%|████▋     | 447/966 [00:53<01:01,  8.39it/s] 46%|████▋     | 448/966 [00:53<01:01,  8.40it/s] 46%|████▋     | 449/966 [00:54<01:01,  8.39it/s] 47%|████▋     | 450/966 [00:54<01:01,  8.41it/s] 47%|████▋     | 451/966 [00:54<01:01,  8.41it/s] 47%|████▋     | 452/966 [00:54<01:01,  8.41it/s] 47%|████▋     | 453/966 [00:54<01:01,  8.40it/s] 47%|████▋     | 454/966 [00:54<01:00,  8.41it/s] 47%|████▋     | 455/966 [00:54<01:00,  8.41it/s] 47%|████▋     | 456/966 [00:54<01:00,  8.41it/s] 47%|████▋     | 457/966 [00:54<01:00,  8.43it/s] 47%|████▋     | 458/966 [00:55<01:00,  8.42it/s] 48%|████▊     | 459/966 [00:55<01:00,  8.43it/s] 48%|████▊     | 460/966 [00:55<00:59,  8.44it/s] 48%|████▊     | 461/966 [00:55<00:59,  8.44it/s] 48%|████▊     | 462/966 [00:55<00:59,  8.45it/s] 48%|████▊     | 463/966 [00:55<00:59,  8.47it/s] 48%|████▊     | 464/966 [00:55<00:59,  8.48it/s] 48%|████▊     | 465/966 [00:55<00:59,  8.45it/s] 48%|████▊     | 466/966 [00:56<00:59,  8.44it/s] 48%|████▊     | 467/966 [00:56<00:59,  8.42it/s] 48%|████▊     | 468/966 [00:56<00:59,  8.43it/s] 49%|████▊     | 469/966 [00:56<00:58,  8.43it/s] 49%|████▊     | 470/966 [00:56<00:58,  8.42it/s] 49%|████▉     | 471/966 [00:56<00:58,  8.43it/s] 49%|████▉     | 472/966 [00:56<00:58,  8.42it/s] 49%|████▉     | 473/966 [00:56<00:58,  8.42it/s] 49%|████▉     | 474/966 [00:56<00:58,  8.41it/s] 49%|████▉     | 475/966 [00:57<00:58,  8.41it/s] 49%|████▉     | 476/966 [00:57<00:58,  8.41it/s] 49%|████▉     | 477/966 [00:57<00:58,  8.41it/s] 49%|████▉     | 478/966 [00:57<00:57,  8.42it/s] 50%|████▉     | 479/966 [00:57<00:57,  8.43it/s] 50%|████▉     | 480/966 [00:57<00:57,  8.40it/s] 50%|████▉     | 481/966 [00:57<00:57,  8.41it/s] 50%|████▉     | 482/966 [00:57<00:57,  8.43it/s] 50%|█████     | 483/966 [00:58<00:57,  8.44it/s] 50%|█████     | 484/966 [00:58<00:57,  8.44it/s] 50%|█████     | 485/966 [00:58<00:57,  8.42it/s] 50%|█████     | 486/966 [00:58<00:56,  8.42it/s] 50%|█████     | 487/966 [00:58<00:56,  8.42it/s] 51%|█████     | 488/966 [00:58<00:56,  8.40it/s] 51%|█████     | 489/966 [00:58<00:56,  8.40it/s] 51%|█████     | 490/966 [00:58<00:56,  8.41it/s] 51%|█████     | 491/966 [00:58<00:56,  8.42it/s] 51%|█████     | 492/966 [00:59<00:56,  8.41it/s] 51%|█████     | 493/966 [00:59<00:56,  8.42it/s] 51%|█████     | 494/966 [00:59<00:56,  8.43it/s] 51%|█████     | 495/966 [00:59<00:55,  8.44it/s] 51%|█████▏    | 496/966 [00:59<00:55,  8.42it/s] 51%|█████▏    | 497/966 [00:59<00:55,  8.45it/s] 52%|█████▏    | 498/966 [00:59<00:55,  8.47it/s] 52%|█████▏    | 499/966 [00:59<00:55,  8.47it/s] 52%|█████▏    | 500/966 [01:00<00:55,  8.44it/s] 52%|█████▏    | 501/966 [01:00<00:55,  8.44it/s] 52%|█████▏    | 502/966 [01:00<00:55,  8.44it/s] 52%|█████▏    | 503/966 [01:00<00:55,  8.41it/s] 52%|█████▏    | 504/966 [01:00<00:54,  8.44it/s] 52%|█████▏    | 505/966 [01:00<00:54,  8.45it/s] 52%|█████▏    | 506/966 [01:00<00:54,  8.45it/s] 52%|█████▏    | 507/966 [01:00<00:54,  8.44it/s] 53%|█████▎    | 508/966 [01:01<00:54,  8.42it/s] 53%|█████▎    | 509/966 [01:01<00:54,  8.42it/s] 53%|█████▎    | 510/966 [01:01<00:54,  8.43it/s] 53%|█████▎    | 511/966 [01:01<00:54,  8.42it/s] 53%|█████▎    | 512/966 [01:01<00:53,  8.42it/s] 53%|█████▎    | 513/966 [01:01<00:53,  8.41it/s] 53%|█████▎    | 514/966 [01:01<00:53,  8.41it/s] 53%|█████▎    | 515/966 [01:01<00:53,  8.41it/s] 53%|█████▎    | 516/966 [01:01<00:53,  8.41it/s] 54%|█████▎    | 517/966 [01:02<00:53,  8.41it/s] 54%|█████▎    | 518/966 [01:02<00:53,  8.41it/s] 54%|█████▎    | 519/966 [01:02<00:53,  8.40it/s] 54%|█████▍    | 520/966 [01:02<00:53,  8.38it/s] 54%|█████▍    | 521/966 [01:02<00:53,  8.39it/s] 54%|█████▍    | 522/966 [01:02<00:52,  8.40it/s] 54%|█████▍    | 523/966 [01:02<00:52,  8.39it/s] 54%|█████▍    | 524/966 [01:02<00:52,  8.39it/s] 54%|█████▍    | 525/966 [01:03<00:52,  8.39it/s] 54%|█████▍    | 526/966 [01:03<00:52,  8.39it/s] 55%|█████▍    | 527/966 [01:03<00:52,  8.39it/s] 55%|█████▍    | 528/966 [01:03<00:52,  8.39it/s] 55%|█████▍    | 529/966 [01:03<00:52,  8.40it/s] 55%|█████▍    | 530/966 [01:03<00:51,  8.40it/s] 55%|█████▍    | 531/966 [01:03<00:51,  8.42it/s] 55%|█████▌    | 532/966 [01:03<00:51,  8.43it/s] 55%|█████▌    | 533/966 [01:03<00:51,  8.42it/s] 55%|█████▌    | 534/966 [01:04<00:51,  8.42it/s] 55%|█████▌    | 535/966 [01:04<00:51,  8.41it/s] 55%|█████▌    | 536/966 [01:04<00:51,  8.41it/s] 56%|█████▌    | 537/966 [01:04<00:51,  8.40it/s] 56%|█████▌    | 538/966 [01:04<00:50,  8.40it/s] 56%|█████▌    | 539/966 [01:04<00:50,  8.40it/s] 56%|█████▌    | 540/966 [01:04<00:50,  8.40it/s] 56%|█████▌    | 541/966 [01:04<00:50,  8.43it/s] 56%|█████▌    | 542/966 [01:05<00:50,  8.44it/s] 56%|█████▌    | 543/966 [01:05<00:50,  8.43it/s] 56%|█████▋    | 544/966 [01:05<00:50,  8.42it/s] 56%|█████▋    | 545/966 [01:05<00:50,  8.41it/s] 57%|█████▋    | 546/966 [01:05<00:49,  8.41it/s] 57%|█████▋    | 547/966 [01:05<00:49,  8.41it/s] 57%|█████▋    | 548/966 [01:05<00:49,  8.41it/s] 57%|█████▋    | 549/966 [01:05<00:49,  8.41it/s] 57%|█████▋    | 550/966 [01:06<00:49,  8.41it/s] 57%|█████▋    | 551/966 [01:06<00:49,  8.41it/s] 57%|█████▋    | 552/966 [01:06<00:49,  8.41it/s] 57%|█████▋    | 553/966 [01:06<00:49,  8.40it/s] 57%|█████▋    | 554/966 [01:06<00:48,  8.42it/s] 57%|█████▋    | 555/966 [01:06<00:48,  8.41it/s] 58%|█████▊    | 556/966 [01:06<00:48,  8.41it/s] 58%|█████▊    | 557/966 [01:06<00:48,  8.43it/s] 58%|█████▊    | 558/966 [01:06<00:48,  8.41it/s] 58%|█████▊    | 559/966 [01:07<00:48,  8.40it/s] 58%|█████▊    | 560/966 [01:07<00:48,  8.41it/s] 58%|█████▊    | 561/966 [01:07<00:48,  8.40it/s] 58%|█████▊    | 562/966 [01:07<00:48,  8.40it/s] 58%|█████▊    | 563/966 [01:07<00:47,  8.40it/s] 58%|█████▊    | 564/966 [01:07<00:47,  8.41it/s] 58%|█████▊    | 565/966 [01:07<00:47,  8.43it/s] 59%|█████▊    | 566/966 [01:07<00:47,  8.41it/s] 59%|█████▊    | 567/966 [01:08<00:47,  8.42it/s] 59%|█████▉    | 568/966 [01:08<00:47,  8.40it/s] 59%|█████▉    | 569/966 [01:08<00:47,  8.39it/s] 59%|█████▉    | 570/966 [01:08<00:47,  8.39it/s] 59%|█████▉    | 571/966 [01:08<00:47,  8.39it/s] 59%|█████▉    | 572/966 [01:08<00:46,  8.38it/s] 59%|█████▉    | 573/966 [01:08<00:46,  8.40it/s] 59%|█████▉    | 574/966 [01:08<00:46,  8.41it/s] 60%|█████▉    | 575/966 [01:08<00:46,  8.41it/s] 60%|█████▉    | 576/966 [01:09<00:46,  8.42it/s] 60%|█████▉    | 577/966 [01:09<00:46,  8.41it/s] 60%|█████▉    | 578/966 [01:09<00:46,  8.41it/s] 60%|█████▉    | 579/966 [01:09<00:45,  8.41it/s] 60%|██████    | 580/966 [01:09<00:45,  8.41it/s] 60%|██████    | 581/966 [01:09<00:45,  8.40it/s] 60%|██████    | 582/966 [01:09<00:45,  8.41it/s] 60%|██████    | 583/966 [01:09<00:45,  8.41it/s] 60%|██████    | 584/966 [01:10<00:45,  8.40it/s] 61%|██████    | 585/966 [01:10<00:45,  8.40it/s] 61%|██████    | 586/966 [01:10<00:45,  8.39it/s] 61%|██████    | 587/966 [01:10<00:45,  8.40it/s] 61%|██████    | 588/966 [01:10<00:44,  8.41it/s] 61%|██████    | 589/966 [01:10<00:44,  8.40it/s] 61%|██████    | 590/966 [01:10<00:44,  8.41it/s] 61%|██████    | 591/966 [01:10<00:44,  8.42it/s] 61%|██████▏   | 592/966 [01:10<00:44,  8.43it/s] 61%|██████▏   | 593/966 [01:11<00:44,  8.44it/s] 61%|██████▏   | 594/966 [01:11<00:44,  8.43it/s] 62%|██████▏   | 595/966 [01:11<00:44,  8.42it/s] 62%|██████▏   | 596/966 [01:11<00:44,  8.41it/s] 62%|██████▏   | 597/966 [01:11<00:43,  8.40it/s] 62%|██████▏   | 598/966 [01:11<00:43,  8.40it/s] 62%|██████▏   | 599/966 [01:11<00:43,  8.40it/s] 62%|██████▏   | 600/966 [01:11<00:43,  8.40it/s] 62%|██████▏   | 601/966 [01:12<00:43,  8.38it/s] 62%|██████▏   | 602/966 [01:12<00:43,  8.40it/s] 62%|██████▏   | 603/966 [01:12<00:43,  8.41it/s] 63%|██████▎   | 604/966 [01:12<00:43,  8.40it/s] 63%|██████▎   | 605/966 [01:12<00:43,  8.39it/s] 63%|██████▎   | 606/966 [01:12<00:42,  8.39it/s] 63%|██████▎   | 607/966 [01:12<00:42,  8.39it/s] 63%|██████▎   | 608/966 [01:12<00:42,  8.38it/s] 63%|██████▎   | 609/966 [01:13<00:42,  8.39it/s] 63%|██████▎   | 610/966 [01:13<00:42,  8.39it/s] 63%|██████▎   | 611/966 [01:13<00:42,  8.39it/s] 63%|██████▎   | 612/966 [01:13<00:42,  8.40it/s] 63%|██████▎   | 613/966 [01:13<00:41,  8.41it/s] 64%|██████▎   | 614/966 [01:13<00:41,  8.41it/s] 64%|██████▎   | 615/966 [01:13<00:41,  8.41it/s] 64%|██████▍   | 616/966 [01:13<00:41,  8.40it/s] 64%|██████▍   | 617/966 [01:13<00:41,  8.40it/s] 64%|██████▍   | 618/966 [01:14<00:41,  8.42it/s] 64%|██████▍   | 619/966 [01:14<00:41,  8.42it/s] 64%|██████▍   | 620/966 [01:14<00:41,  8.42it/s] 64%|██████▍   | 621/966 [01:14<00:41,  8.40it/s] 64%|██████▍   | 622/966 [01:14<00:41,  8.39it/s] 64%|██████▍   | 623/966 [01:14<00:40,  8.38it/s] 65%|██████▍   | 624/966 [01:14<00:40,  8.39it/s] 65%|██████▍   | 625/966 [01:14<00:40,  8.41it/s] 65%|██████▍   | 626/966 [01:15<00:40,  8.39it/s] 65%|██████▍   | 627/966 [01:15<00:40,  8.41it/s] 65%|██████▌   | 628/966 [01:15<00:40,  8.41it/s] 65%|██████▌   | 629/966 [01:15<00:40,  8.40it/s] 65%|██████▌   | 630/966 [01:15<00:40,  8.39it/s] 65%|██████▌   | 631/966 [01:15<00:39,  8.40it/s] 65%|██████▌   | 632/966 [01:15<00:39,  8.41it/s] 66%|██████▌   | 633/966 [01:15<00:39,  8.42it/s] 66%|██████▌   | 634/966 [01:15<00:39,  8.41it/s] 66%|██████▌   | 635/966 [01:16<00:39,  8.43it/s] 66%|██████▌   | 636/966 [01:16<00:39,  8.44it/s] 66%|██████▌   | 637/966 [01:16<00:39,  8.42it/s] 66%|██████▌   | 638/966 [01:16<00:38,  8.43it/s] 66%|██████▌   | 639/966 [01:16<00:38,  8.44it/s] 66%|██████▋   | 640/966 [01:16<00:38,  8.43it/s] 66%|██████▋   | 641/966 [01:16<00:38,  8.41it/s] 66%|██████▋   | 642/966 [01:16<00:38,  8.41it/s] 67%|██████▋   | 643/966 [01:17<00:38,  8.39it/s] 67%|██████▋   | 644/966 [01:17<00:38,  8.40it/s] 67%|██████▋   | 645/966 [01:17<00:38,  8.39it/s] 67%|██████▋   | 646/966 [01:17<00:38,  8.39it/s] 67%|██████▋   | 647/966 [01:17<00:38,  8.39it/s] 67%|██████▋   | 648/966 [01:17<00:37,  8.39it/s] 67%|██████▋   | 649/966 [01:17<00:37,  8.41it/s] 67%|██████▋   | 650/966 [01:17<00:37,  8.41it/s] 67%|██████▋   | 651/966 [01:18<00:37,  8.41it/s] 67%|██████▋   | 652/966 [01:18<00:37,  8.40it/s] 68%|██████▊   | 653/966 [01:18<00:37,  8.41it/s] 68%|██████▊   | 654/966 [01:18<00:37,  8.42it/s] 68%|██████▊   | 655/966 [01:18<00:36,  8.41it/s] 68%|██████▊   | 656/966 [01:18<00:36,  8.39it/s] 68%|██████▊   | 657/966 [01:18<00:36,  8.40it/s] 68%|██████▊   | 658/966 [01:18<00:36,  8.40it/s] 68%|██████▊   | 659/966 [01:18<00:36,  8.39it/s] 68%|██████▊   | 660/966 [01:19<00:36,  8.40it/s] 68%|██████▊   | 661/966 [01:19<00:36,  8.39it/s] 69%|██████▊   | 662/966 [01:19<00:36,  8.41it/s] 69%|██████▊   | 663/966 [01:19<00:36,  8.41it/s] 69%|██████▊   | 664/966 [01:19<00:35,  8.40it/s] 69%|██████▉   | 665/966 [01:19<00:35,  8.39it/s] 69%|██████▉   | 666/966 [01:19<00:35,  8.40it/s] 69%|██████▉   | 667/966 [01:19<00:35,  8.41it/s] 69%|██████▉   | 668/966 [01:20<00:35,  8.39it/s] 69%|██████▉   | 669/966 [01:20<00:35,  8.39it/s] 69%|██████▉   | 670/966 [01:20<00:35,  8.40it/s] 69%|██████▉   | 671/966 [01:20<00:35,  8.40it/s] 70%|██████▉   | 672/966 [01:20<00:34,  8.40it/s] 70%|██████▉   | 673/966 [01:20<00:34,  8.41it/s] 70%|██████▉   | 674/966 [01:20<00:34,  8.41it/s] 70%|██████▉   | 675/966 [01:20<00:34,  8.40it/s] 70%|██████▉   | 676/966 [01:20<00:34,  8.39it/s] 70%|███████   | 677/966 [01:21<00:34,  8.39it/s] 70%|███████   | 678/966 [01:21<00:34,  8.40it/s] 70%|███████   | 679/966 [01:21<00:34,  8.39it/s] 70%|███████   | 680/966 [01:21<00:34,  8.40it/s] 70%|███████   | 681/966 [01:21<00:33,  8.39it/s] 71%|███████   | 682/966 [01:21<00:33,  8.40it/s] 71%|███████   | 683/966 [01:21<00:33,  8.40it/s] 71%|███████   | 684/966 [01:21<00:33,  8.39it/s] 71%|███████   | 685/966 [01:22<00:33,  8.39it/s] 71%|███████   | 686/966 [01:22<00:33,  8.38it/s] 71%|███████   | 687/966 [01:22<00:33,  8.38it/s] 71%|███████   | 688/966 [01:22<00:33,  8.37it/s] 71%|███████▏  | 689/966 [01:22<00:33,  8.37it/s] 71%|███████▏  | 690/966 [01:22<00:32,  8.38it/s] 72%|███████▏  | 691/966 [01:22<00:32,  8.38it/s] 72%|███████▏  | 692/966 [01:22<00:32,  8.38it/s] 72%|███████▏  | 693/966 [01:23<00:32,  8.38it/s] 72%|███████▏  | 694/966 [01:23<00:32,  8.37it/s] 72%|███████▏  | 695/966 [01:23<00:32,  8.37it/s] 72%|███████▏  | 696/966 [01:23<00:32,  8.41it/s] 72%|███████▏  | 697/966 [01:23<00:32,  8.39it/s] 72%|███████▏  | 698/966 [01:23<00:31,  8.39it/s] 72%|███████▏  | 699/966 [01:23<00:31,  8.42it/s] 72%|███████▏  | 700/966 [01:23<00:31,  8.42it/s] 73%|███████▎  | 701/966 [01:23<00:31,  8.41it/s] 73%|███████▎  | 702/966 [01:24<00:31,  8.41it/s] 73%|███████▎  | 703/966 [01:24<00:31,  8.41it/s] 73%|███████▎  | 704/966 [01:24<00:31,  8.41it/s] 73%|███████▎  | 705/966 [01:24<00:31,  8.41it/s] 73%|███████▎  | 706/966 [01:24<00:30,  8.41it/s] 73%|███████▎  | 707/966 [01:24<00:30,  8.41it/s] 73%|███████▎  | 708/966 [01:24<00:30,  8.39it/s] 73%|███████▎  | 709/966 [01:24<00:30,  8.39it/s] 73%|███████▎  | 710/966 [01:25<00:30,  8.40it/s] 74%|███████▎  | 711/966 [01:25<00:30,  8.40it/s] 74%|███████▎  | 712/966 [01:25<00:30,  8.40it/s] 74%|███████▍  | 713/966 [01:25<00:30,  8.39it/s] 74%|███████▍  | 714/966 [01:25<00:30,  8.40it/s] 74%|███████▍  | 715/966 [01:25<00:29,  8.40it/s] 74%|███████▍  | 716/966 [01:25<00:29,  8.42it/s] 74%|███████▍  | 717/966 [01:25<00:29,  8.41it/s] 74%|███████▍  | 718/966 [01:25<00:29,  8.40it/s] 74%|███████▍  | 719/966 [01:26<00:29,  8.38it/s] 75%|███████▍  | 720/966 [01:26<00:29,  8.38it/s] 75%|███████▍  | 721/966 [01:26<00:29,  8.38it/s] 75%|███████▍  | 722/966 [01:26<00:29,  8.38it/s] 75%|███████▍  | 723/966 [01:26<00:28,  8.40it/s] 75%|███████▍  | 724/966 [01:26<00:28,  8.40it/s] 75%|███████▌  | 725/966 [01:26<00:28,  8.41it/s] 75%|███████▌  | 726/966 [01:26<00:28,  8.41it/s] 75%|███████▌  | 727/966 [01:27<00:28,  8.41it/s] 75%|███████▌  | 728/966 [01:27<00:28,  8.39it/s] 75%|███████▌  | 729/966 [01:27<00:28,  8.39it/s] 76%|███████▌  | 730/966 [01:27<00:28,  8.40it/s] 76%|███████▌  | 731/966 [01:27<00:27,  8.43it/s] 76%|███████▌  | 732/966 [01:27<00:27,  8.44it/s] 76%|███████▌  | 733/966 [01:27<00:27,  8.42it/s] 76%|███████▌  | 734/966 [01:27<00:27,  8.42it/s] 76%|███████▌  | 735/966 [01:28<00:27,  8.41it/s] 76%|███████▌  | 736/966 [01:28<00:27,  8.42it/s] 76%|███████▋  | 737/966 [01:28<00:27,  8.44it/s] 76%|███████▋  | 738/966 [01:28<00:27,  8.44it/s] 77%|███████▋  | 739/966 [01:28<00:26,  8.44it/s] 77%|███████▋  | 740/966 [01:28<00:26,  8.44it/s] 77%|███████▋  | 741/966 [01:28<00:26,  8.44it/s] 77%|███████▋  | 742/966 [01:28<00:26,  8.43it/s] 77%|███████▋  | 743/966 [01:28<00:26,  8.42it/s] 77%|███████▋  | 744/966 [01:29<00:26,  8.42it/s] 77%|███████▋  | 745/966 [01:29<00:26,  8.42it/s] 77%|███████▋  | 746/966 [01:29<00:26,  8.42it/s] 77%|███████▋  | 747/966 [01:29<00:25,  8.44it/s] 77%|███████▋  | 748/966 [01:29<00:25,  8.44it/s] 78%|███████▊  | 749/966 [01:29<00:25,  8.42it/s] 78%|███████▊  | 750/966 [01:29<00:25,  8.42it/s] 78%|███████▊  | 751/966 [01:29<00:25,  8.43it/s] 78%|███████▊  | 752/966 [01:30<00:25,  8.42it/s] 78%|███████▊  | 753/966 [01:30<00:25,  8.42it/s] 78%|███████▊  | 754/966 [01:30<00:25,  8.40it/s] 78%|███████▊  | 755/966 [01:30<00:25,  8.42it/s] 78%|███████▊  | 756/966 [01:30<00:24,  8.42it/s] 78%|███████▊  | 757/966 [01:30<00:24,  8.43it/s] 78%|███████▊  | 758/966 [01:30<00:24,  8.42it/s] 79%|███████▊  | 759/966 [01:30<00:24,  8.40it/s] 79%|███████▊  | 760/966 [01:30<00:24,  8.39it/s] 79%|███████▉  | 761/966 [01:31<00:24,  8.39it/s] 79%|███████▉  | 762/966 [01:31<00:24,  8.39it/s] 79%|███████▉  | 763/966 [01:31<00:24,  8.40it/s] 79%|███████▉  | 764/966 [01:31<00:23,  8.42it/s] 79%|███████▉  | 765/966 [01:31<00:23,  8.41it/s] 79%|███████▉  | 766/966 [01:31<00:23,  8.40it/s] 79%|███████▉  | 767/966 [01:31<00:23,  8.40it/s] 80%|███████▉  | 768/966 [01:31<00:23,  8.40it/s] 80%|███████▉  | 769/966 [01:32<00:23,  8.40it/s] 80%|███████▉  | 770/966 [01:32<00:23,  8.41it/s] 80%|███████▉  | 771/966 [01:32<00:23,  8.40it/s] 80%|███████▉  | 772/966 [01:32<00:23,  8.41it/s] 80%|████████  | 773/966 [01:32<00:22,  8.41it/s] 80%|████████  | 774/966 [01:32<00:22,  8.42it/s] 80%|████████  | 775/966 [01:32<00:22,  8.41it/s] 80%|████████  | 776/966 [01:32<00:22,  8.42it/s] 80%|████████  | 777/966 [01:33<00:22,  8.42it/s] 81%|████████  | 778/966 [01:33<00:22,  8.41it/s] 81%|████████  | 779/966 [01:33<00:22,  8.41it/s] 81%|████████  | 780/966 [01:33<00:22,  8.40it/s] 81%|████████  | 781/966 [01:33<00:22,  8.40it/s] 81%|████████  | 782/966 [01:33<00:21,  8.41it/s] 81%|████████  | 783/966 [01:33<00:21,  8.42it/s] 81%|████████  | 784/966 [01:33<00:21,  8.42it/s] 81%|████████▏ | 785/966 [01:33<00:21,  8.40it/s] 81%|████████▏ | 786/966 [01:34<00:21,  8.41it/s] 81%|████████▏ | 787/966 [01:34<00:21,  8.41it/s] 82%|████████▏ | 788/966 [01:34<00:21,  8.41it/s] 82%|████████▏ | 789/966 [01:34<00:21,  8.40it/s] 82%|████████▏ | 790/966 [01:34<00:20,  8.40it/s] 82%|████████▏ | 791/966 [01:34<00:20,  8.39it/s] 82%|████████▏ | 792/966 [01:34<00:20,  8.39it/s] 82%|████████▏ | 793/966 [01:34<00:20,  8.40it/s] 82%|████████▏ | 794/966 [01:35<00:20,  8.41it/s] 82%|████████▏ | 795/966 [01:35<00:20,  8.39it/s] 82%|████████▏ | 796/966 [01:35<00:20,  8.39it/s] 83%|████████▎ | 797/966 [01:35<00:20,  8.40it/s] 83%|████████▎ | 798/966 [01:35<00:19,  8.41it/s] 83%|████████▎ | 799/966 [01:35<00:19,  8.39it/s] 83%|████████▎ | 800/966 [01:35<00:19,  8.41it/s] 83%|████████▎ | 801/966 [01:35<00:19,  8.42it/s] 83%|████████▎ | 802/966 [01:35<00:19,  8.41it/s] 83%|████████▎ | 803/966 [01:36<00:19,  8.40it/s] 83%|████████▎ | 804/966 [01:36<00:19,  8.41it/s] 83%|████████▎ | 805/966 [01:36<00:19,  8.42it/s] 83%|████████▎ | 806/966 [01:36<00:18,  8.43it/s] 84%|████████▎ | 807/966 [01:36<00:18,  8.42it/s] 84%|████████▎ | 808/966 [01:36<00:18,  8.41it/s] 84%|████████▎ | 809/966 [01:36<00:18,  8.41it/s] 84%|████████▍ | 810/966 [01:36<00:18,  8.41it/s] 84%|████████▍ | 811/966 [01:37<00:18,  8.41it/s] 84%|████████▍ | 812/966 [01:37<00:18,  8.42it/s] 84%|████████▍ | 813/966 [01:37<00:18,  8.43it/s] 84%|████████▍ | 814/966 [01:37<00:18,  8.42it/s] 84%|████████▍ | 815/966 [01:37<00:17,  8.41it/s] 84%|████████▍ | 816/966 [01:37<00:17,  8.42it/s] 85%|████████▍ | 817/966 [01:37<00:17,  8.40it/s] 85%|████████▍ | 818/966 [01:37<00:17,  8.39it/s] 85%|████████▍ | 819/966 [01:38<00:17,  8.39it/s] 85%|████████▍ | 820/966 [01:38<00:17,  8.39it/s] 85%|████████▍ | 821/966 [01:38<00:17,  8.39it/s] 85%|████████▌ | 822/966 [01:38<00:17,  8.40it/s] 85%|████████▌ | 823/966 [01:38<00:17,  8.41it/s] 85%|████████▌ | 824/966 [01:38<00:16,  8.39it/s] 85%|████████▌ | 825/966 [01:38<00:16,  8.41it/s] 86%|████████▌ | 826/966 [01:38<00:16,  8.40it/s] 86%|████████▌ | 827/966 [01:38<00:16,  8.40it/s] 86%|████████▌ | 828/966 [01:39<00:16,  8.40it/s] 86%|████████▌ | 829/966 [01:39<00:16,  8.40it/s] 86%|████████▌ | 830/966 [01:39<00:16,  8.41it/s] 86%|████████▌ | 831/966 [01:39<00:16,  8.42it/s] 86%|████████▌ | 832/966 [01:39<00:15,  8.42it/s] 86%|████████▌ | 833/966 [01:39<00:15,  8.40it/s] 86%|████████▋ | 834/966 [01:39<00:15,  8.40it/s] 86%|████████▋ | 835/966 [01:39<00:15,  8.39it/s] 87%|████████▋ | 836/966 [01:40<00:15,  8.39it/s] 87%|████████▋ | 837/966 [01:40<00:15,  8.40it/s] 87%|████████▋ | 838/966 [01:40<00:15,  8.42it/s] 87%|████████▋ | 839/966 [01:40<00:15,  8.41it/s] 87%|████████▋ | 840/966 [01:40<00:14,  8.40it/s] 87%|████████▋ | 841/966 [01:40<00:14,  8.41it/s] 87%|████████▋ | 842/966 [01:40<00:14,  8.42it/s] 87%|████████▋ | 843/966 [01:40<00:14,  8.41it/s] 87%|████████▋ | 844/966 [01:40<00:14,  8.41it/s] 87%|████████▋ | 845/966 [01:41<00:14,  8.41it/s] 88%|████████▊ | 846/966 [01:41<00:14,  8.39it/s] 88%|████████▊ | 847/966 [01:41<00:14,  8.40it/s] 88%|████████▊ | 848/966 [01:41<00:14,  8.40it/s] 88%|████████▊ | 849/966 [01:41<00:13,  8.41it/s] 88%|████████▊ | 850/966 [01:41<00:13,  8.40it/s] 88%|████████▊ | 851/966 [01:41<00:13,  8.41it/s] 88%|████████▊ | 852/966 [01:41<00:13,  8.40it/s] 88%|████████▊ | 853/966 [01:42<00:13,  8.38it/s] 88%|████████▊ | 854/966 [01:42<00:13,  8.38it/s] 89%|████████▊ | 855/966 [01:42<00:13,  8.38it/s] 89%|████████▊ | 856/966 [01:42<00:13,  8.38it/s] 89%|████████▊ | 857/966 [01:42<00:12,  8.40it/s] 89%|████████▉ | 858/966 [01:42<00:12,  8.38it/s] 89%|████████▉ | 859/966 [01:42<00:12,  8.39it/s] 89%|████████▉ | 860/966 [01:42<00:12,  8.37it/s] 89%|████████▉ | 861/966 [01:43<00:12,  8.38it/s] 89%|████████▉ | 862/966 [01:43<00:12,  8.39it/s] 89%|████████▉ | 863/966 [01:43<00:12,  8.39it/s] 89%|████████▉ | 864/966 [01:43<00:12,  8.39it/s] 90%|████████▉ | 865/966 [01:43<00:12,  8.38it/s] 90%|████████▉ | 866/966 [01:43<00:11,  8.39it/s] 90%|████████▉ | 867/966 [01:43<00:11,  8.38it/s] 90%|████████▉ | 868/966 [01:43<00:11,  8.39it/s] 90%|████████▉ | 869/966 [01:43<00:11,  8.37it/s] 90%|█████████ | 870/966 [01:44<00:11,  8.36it/s] 90%|█████████ | 871/966 [01:44<00:11,  8.37it/s] 90%|█████████ | 872/966 [01:44<00:11,  8.38it/s] 90%|█████████ | 873/966 [01:44<00:11,  8.39it/s] 90%|█████████ | 874/966 [01:44<00:10,  8.38it/s] 91%|█████████ | 875/966 [01:44<00:10,  8.37it/s] 91%|█████████ | 876/966 [01:44<00:10,  8.38it/s] 91%|█████████ | 877/966 [01:44<00:10,  8.40it/s] 91%|█████████ | 878/966 [01:45<00:10,  8.40it/s] 91%|█████████ | 879/966 [01:45<00:10,  8.41it/s] 91%|█████████ | 880/966 [01:45<00:10,  8.40it/s] 91%|█████████ | 881/966 [01:45<00:10,  8.39it/s] 91%|█████████▏| 882/966 [01:45<00:10,  8.38it/s] 91%|█████████▏| 883/966 [01:45<00:09,  8.38it/s] 92%|█████████▏| 884/966 [01:45<00:09,  8.40it/s] 92%|█████████▏| 885/966 [01:45<00:09,  8.41it/s] 92%|█████████▏| 886/966 [01:45<00:09,  8.41it/s] 92%|█████████▏| 887/966 [01:46<00:09,  8.42it/s] 92%|█████████▏| 888/966 [01:46<00:09,  8.42it/s] 92%|█████████▏| 889/966 [01:46<00:09,  8.41it/s] 92%|█████████▏| 890/966 [01:46<00:09,  8.42it/s] 92%|█████████▏| 891/966 [01:46<00:08,  8.42it/s] 92%|█████████▏| 892/966 [01:46<00:08,  8.40it/s] 92%|█████████▏| 893/966 [01:46<00:08,  8.40it/s] 93%|█████████▎| 894/966 [01:46<00:08,  8.41it/s] 93%|█████████▎| 895/966 [01:47<00:08,  8.42it/s] 93%|█████████▎| 896/966 [01:47<00:08,  8.40it/s] 93%|█████████▎| 897/966 [01:47<00:08,  8.39it/s] 93%|█████████▎| 898/966 [01:47<00:08,  8.39it/s] 93%|█████████▎| 899/966 [01:47<00:07,  8.40it/s] 93%|█████████▎| 900/966 [01:47<00:07,  8.40it/s] 93%|█████████▎| 901/966 [01:47<00:07,  8.41it/s] 93%|█████████▎| 902/966 [01:47<00:07,  8.42it/s] 93%|█████████▎| 903/966 [01:48<00:07,  8.42it/s] 94%|█████████▎| 904/966 [01:48<00:07,  8.40it/s] 94%|█████████▎| 905/966 [01:48<00:07,  8.41it/s] 94%|█████████▍| 906/966 [01:48<00:07,  8.40it/s] 94%|█████████▍| 907/966 [01:48<00:07,  8.42it/s] 94%|█████████▍| 908/966 [01:48<00:06,  8.44it/s] 94%|█████████▍| 909/966 [01:48<00:06,  8.42it/s] 94%|█████████▍| 910/966 [01:48<00:06,  8.42it/s] 94%|█████████▍| 911/966 [01:48<00:06,  8.42it/s] 94%|█████████▍| 912/966 [01:49<00:06,  8.42it/s] 95%|█████████▍| 913/966 [01:49<00:06,  8.43it/s] 95%|█████████▍| 914/966 [01:49<00:06,  8.43it/s] 95%|█████████▍| 915/966 [01:49<00:06,  8.44it/s] 95%|█████████▍| 916/966 [01:49<00:05,  8.43it/s] 95%|█████████▍| 917/966 [01:49<00:05,  8.41it/s] 95%|█████████▌| 918/966 [01:49<00:05,  8.42it/s] 95%|█████████▌| 919/966 [01:49<00:05,  8.44it/s] 95%|█████████▌| 920/966 [01:50<00:05,  8.42it/s] 95%|█████████▌| 921/966 [01:50<00:05,  8.41it/s] 95%|█████████▌| 922/966 [01:50<00:05,  8.41it/s] 96%|█████████▌| 923/966 [01:50<00:05,  8.40it/s] 96%|█████████▌| 924/966 [01:50<00:04,  8.41it/s] 96%|█████████▌| 925/966 [01:50<00:04,  8.42it/s] 96%|█████████▌| 926/966 [01:50<00:04,  8.41it/s] 96%|█████████▌| 927/966 [01:50<00:04,  8.39it/s] 96%|█████████▌| 928/966 [01:50<00:04,  8.39it/s] 96%|█████████▌| 929/966 [01:51<00:04,  8.38it/s] 96%|█████████▋| 930/966 [01:51<00:04,  8.39it/s] 96%|█████████▋| 931/966 [01:51<00:04,  8.38it/s] 96%|█████████▋| 932/966 [01:51<00:04,  8.39it/s] 97%|█████████▋| 933/966 [01:51<00:03,  8.40it/s] 97%|█████████▋| 934/966 [01:51<00:03,  8.42it/s] 97%|█████████▋| 935/966 [01:51<00:03,  8.45it/s] 97%|█████████▋| 936/966 [01:51<00:03,  8.43it/s] 97%|█████████▋| 937/966 [01:52<00:03,  8.44it/s] 97%|█████████▋| 938/966 [01:52<00:03,  8.43it/s] 97%|█████████▋| 939/966 [01:52<00:03,  8.42it/s] 97%|█████████▋| 940/966 [01:52<00:03,  8.40it/s] 97%|█████████▋| 941/966 [01:52<00:02,  8.39it/s] 98%|█████████▊| 942/966 [01:52<00:02,  8.40it/s] 98%|█████████▊| 943/966 [01:52<00:02,  8.39it/s] 98%|█████████▊| 944/966 [01:52<00:02,  8.40it/s] 98%|█████████▊| 945/966 [01:53<00:02,  8.41it/s] 98%|█████████▊| 946/966 [01:53<00:02,  8.40it/s] 98%|█████████▊| 947/966 [01:53<00:02,  8.39it/s] 98%|█████████▊| 948/966 [01:53<00:02,  8.39it/s] 98%|█████████▊| 949/966 [01:53<00:02,  8.39it/s] 98%|█████████▊| 950/966 [01:53<00:01,  8.40it/s] 98%|█████████▊| 951/966 [01:53<00:01,  8.40it/s] 99%|█████████▊| 952/966 [01:53<00:01,  8.41it/s] 99%|█████████▊| 953/966 [01:53<00:01,  8.41it/s] 99%|█████████▉| 954/966 [01:54<00:01,  8.40it/s] 99%|█████████▉| 955/966 [01:54<00:01,  8.40it/s] 99%|█████████▉| 956/966 [01:54<00:01,  8.41it/s] 99%|█████████▉| 957/966 [01:54<00:01,  8.41it/s] 99%|█████████▉| 958/966 [01:54<00:00,  8.40it/s] 99%|█████████▉| 959/966 [01:54<00:00,  8.39it/s] 99%|█████████▉| 960/966 [01:54<00:00,  8.38it/s] 99%|█████████▉| 961/966 [01:54<00:00,  8.40it/s]100%|█████████▉| 962/966 [01:55<00:00,  8.42it/s]100%|█████████▉| 963/966 [01:55<00:00,  8.41it/s]100%|█████████▉| 964/966 [01:55<00:00,  8.40it/s]100%|█████████▉| 965/966 [01:55<00:00,  8.40it/s]100%|██████████| 966/966 [01:55<00:00,  8.39it/s]100%|██████████| 966/966 [01:55<00:00,  8.36it/s]
sending off prediction to background worker for resampling and export
done with 101-045

Predicting 706-005:
perform_everything_on_device: True
  0%|          | 0/966 [00:00<?, ?it/s]  0%|          | 2/966 [00:00<01:26, 11.15it/s]  0%|          | 4/966 [00:00<01:42,  9.38it/s]  1%|          | 5/966 [00:00<01:45,  9.07it/s]  1%|          | 6/966 [00:00<01:48,  8.86it/s]  1%|          | 7/966 [00:00<01:50,  8.71it/s]  1%|          | 8/966 [00:00<01:50,  8.65it/s]  1%|          | 9/966 [00:01<01:51,  8.59it/s]  1%|          | 10/966 [00:01<01:52,  8.52it/s]  1%|          | 11/966 [00:01<01:52,  8.49it/s]  1%|          | 12/966 [00:01<01:52,  8.46it/s]  1%|▏         | 13/966 [00:01<01:52,  8.45it/s]  1%|▏         | 14/966 [00:01<01:52,  8.43it/s]  2%|▏         | 15/966 [00:01<01:52,  8.42it/s]  2%|▏         | 16/966 [00:01<01:52,  8.42it/s]  2%|▏         | 17/966 [00:01<01:52,  8.42it/s]  2%|▏         | 18/966 [00:02<01:52,  8.42it/s]  2%|▏         | 19/966 [00:02<01:52,  8.41it/s]  2%|▏         | 20/966 [00:02<01:52,  8.40it/s]  2%|▏         | 21/966 [00:02<01:52,  8.42it/s]  2%|▏         | 22/966 [00:02<01:52,  8.42it/s]  2%|▏         | 23/966 [00:02<01:52,  8.40it/s]  2%|▏         | 24/966 [00:02<01:51,  8.43it/s]  3%|▎         | 25/966 [00:02<01:51,  8.41it/s]  3%|▎         | 26/966 [00:03<01:51,  8.40it/s]  3%|▎         | 27/966 [00:03<01:51,  8.39it/s]  3%|▎         | 28/966 [00:03<01:51,  8.38it/s]  3%|▎         | 29/966 [00:03<01:51,  8.40it/s]  3%|▎         | 30/966 [00:03<01:51,  8.39it/s]  3%|▎         | 31/966 [00:03<01:51,  8.39it/s]  3%|▎         | 32/966 [00:03<01:51,  8.39it/s]  3%|▎         | 33/966 [00:03<01:51,  8.39it/s]  4%|▎         | 34/966 [00:03<01:51,  8.39it/s]  4%|▎         | 35/966 [00:04<01:50,  8.41it/s]  4%|▎         | 36/966 [00:04<01:50,  8.41it/s]  4%|▍         | 37/966 [00:04<01:50,  8.42it/s]  4%|▍         | 38/966 [00:04<01:50,  8.43it/s]  4%|▍         | 39/966 [00:04<01:50,  8.42it/s]  4%|▍         | 40/966 [00:04<01:50,  8.42it/s]  4%|▍         | 41/966 [00:04<01:49,  8.41it/s]  4%|▍         | 42/966 [00:04<01:49,  8.43it/s]  4%|▍         | 43/966 [00:05<01:49,  8.44it/s]  5%|▍         | 44/966 [00:05<01:49,  8.45it/s]  5%|▍         | 45/966 [00:05<01:49,  8.43it/s]  5%|▍         | 46/966 [00:05<01:49,  8.43it/s]  5%|▍         | 47/966 [00:05<01:49,  8.42it/s]  5%|▍         | 48/966 [00:05<01:48,  8.44it/s]  5%|▌         | 49/966 [00:05<01:48,  8.43it/s]  5%|▌         | 50/966 [00:05<01:48,  8.43it/s]  5%|▌         | 51/966 [00:06<01:48,  8.44it/s]  5%|▌         | 52/966 [00:06<01:48,  8.44it/s]  5%|▌         | 53/966 [00:06<01:48,  8.43it/s]  6%|▌         | 54/966 [00:06<01:48,  8.43it/s]  6%|▌         | 55/966 [00:06<01:48,  8.41it/s]  6%|▌         | 56/966 [00:06<01:48,  8.39it/s]  6%|▌         | 57/966 [00:06<01:48,  8.39it/s]  6%|▌         | 58/966 [00:06<01:48,  8.39it/s]  6%|▌         | 59/966 [00:06<01:48,  8.39it/s]  6%|▌         | 60/966 [00:07<01:47,  8.39it/s]  6%|▋         | 61/966 [00:07<01:47,  8.39it/s]  6%|▋         | 62/966 [00:07<01:47,  8.41it/s]  7%|▋         | 63/966 [00:07<01:47,  8.41it/s]  7%|▋         | 64/966 [00:07<01:47,  8.40it/s]  7%|▋         | 65/966 [00:07<01:47,  8.39it/s]  7%|▋         | 66/966 [00:07<01:47,  8.40it/s]  7%|▋         | 67/966 [00:07<01:47,  8.39it/s]  7%|▋         | 68/966 [00:08<01:47,  8.39it/s]  7%|▋         | 69/966 [00:08<01:46,  8.40it/s]  7%|▋         | 70/966 [00:08<01:46,  8.40it/s]  7%|▋         | 71/966 [00:08<01:46,  8.41it/s]  7%|▋         | 72/966 [00:08<01:46,  8.39it/s]  8%|▊         | 73/966 [00:08<01:46,  8.39it/s]  8%|▊         | 74/966 [00:08<01:46,  8.39it/s]  8%|▊         | 75/966 [00:08<01:46,  8.39it/s]  8%|▊         | 76/966 [00:08<01:46,  8.38it/s]  8%|▊         | 77/966 [00:09<01:45,  8.39it/s]  8%|▊         | 78/966 [00:09<01:45,  8.41it/s]  8%|▊         | 79/966 [00:09<01:45,  8.43it/s]  8%|▊         | 80/966 [00:09<01:45,  8.42it/s]  8%|▊         | 81/966 [00:09<01:45,  8.42it/s]  8%|▊         | 82/966 [00:09<01:45,  8.40it/s]  9%|▊         | 83/966 [00:09<01:45,  8.40it/s]  9%|▊         | 84/966 [00:09<01:44,  8.41it/s]  9%|▉         | 85/966 [00:10<01:44,  8.43it/s]  9%|▉         | 86/966 [00:10<01:44,  8.44it/s]  9%|▉         | 87/966 [00:10<01:44,  8.43it/s]  9%|▉         | 88/966 [00:10<01:44,  8.42it/s]  9%|▉         | 89/966 [00:10<01:44,  8.41it/s]  9%|▉         | 90/966 [00:10<01:44,  8.40it/s]  9%|▉         | 91/966 [00:10<01:44,  8.40it/s] 10%|▉         | 92/966 [00:10<01:43,  8.42it/s] 10%|▉         | 93/966 [00:10<01:43,  8.42it/s] 10%|▉         | 94/966 [00:11<01:43,  8.41it/s] 10%|▉         | 95/966 [00:11<01:43,  8.41it/s] 10%|▉         | 96/966 [00:11<01:43,  8.40it/s] 10%|█         | 97/966 [00:11<01:43,  8.38it/s] 10%|█         | 98/966 [00:11<01:43,  8.39it/s] 10%|█         | 99/966 [00:11<01:43,  8.41it/s] 10%|█         | 100/966 [00:11<01:43,  8.40it/s] 10%|█         | 101/966 [00:11<01:42,  8.40it/s] 11%|█         | 102/966 [00:12<01:42,  8.40it/s] 11%|█         | 103/966 [00:12<01:42,  8.40it/s] 11%|█         | 104/966 [00:12<01:42,  8.39it/s] 11%|█         | 105/966 [00:12<01:42,  8.39it/s] 11%|█         | 106/966 [00:12<01:42,  8.41it/s] 11%|█         | 107/966 [00:12<01:42,  8.41it/s] 11%|█         | 108/966 [00:12<01:42,  8.41it/s] 11%|█▏        | 109/966 [00:12<01:41,  8.40it/s] 11%|█▏        | 110/966 [00:13<01:41,  8.40it/s] 11%|█▏        | 111/966 [00:13<01:41,  8.39it/s] 12%|█▏        | 112/966 [00:13<01:41,  8.38it/s] 12%|█▏        | 113/966 [00:13<01:41,  8.37it/s] 12%|█▏        | 114/966 [00:13<01:41,  8.39it/s] 12%|█▏        | 115/966 [00:13<01:41,  8.40it/s] 12%|█▏        | 116/966 [00:13<01:41,  8.40it/s] 12%|█▏        | 117/966 [00:13<01:41,  8.40it/s] 12%|█▏        | 118/966 [00:13<01:40,  8.41it/s] 12%|█▏        | 119/966 [00:14<01:40,  8.39it/s] 12%|█▏        | 120/966 [00:14<01:40,  8.40it/s] 13%|█▎        | 121/966 [00:14<01:40,  8.40it/s] 13%|█▎        | 122/966 [00:14<01:40,  8.41it/s] 13%|█▎        | 123/966 [00:14<01:40,  8.40it/s] 13%|█▎        | 124/966 [00:14<01:40,  8.41it/s] 13%|█▎        | 125/966 [00:14<01:40,  8.41it/s] 13%|█▎        | 126/966 [00:14<01:40,  8.40it/s] 13%|█▎        | 127/966 [00:15<01:39,  8.39it/s] 13%|█▎        | 128/966 [00:15<01:39,  8.41it/s] 13%|█▎        | 129/966 [00:15<01:39,  8.41it/s] 13%|█▎        | 130/966 [00:15<01:39,  8.41it/s] 14%|█▎        | 131/966 [00:15<01:39,  8.40it/s] 14%|█▎        | 132/966 [00:15<01:39,  8.40it/s] 14%|█▍        | 133/966 [00:15<01:39,  8.41it/s] 14%|█▍        | 134/966 [00:15<01:38,  8.44it/s] 14%|█▍        | 135/966 [00:15<01:38,  8.42it/s] 14%|█▍        | 136/966 [00:16<01:38,  8.41it/s] 14%|█▍        | 137/966 [00:16<01:38,  8.42it/s] 14%|█▍        | 138/966 [00:16<01:38,  8.42it/s] 14%|█▍        | 139/966 [00:16<01:38,  8.42it/s] 14%|█▍        | 140/966 [00:16<01:38,  8.40it/s] 15%|█▍        | 141/966 [00:16<01:38,  8.41it/s] 15%|█▍        | 142/966 [00:16<01:38,  8.39it/s] 15%|█▍        | 143/966 [00:16<01:38,  8.39it/s] 15%|█▍        | 144/966 [00:17<01:37,  8.39it/s] 15%|█▌        | 145/966 [00:17<01:37,  8.40it/s] 15%|█▌        | 146/966 [00:17<01:37,  8.41it/s] 15%|█▌        | 147/966 [00:17<01:37,  8.41it/s] 15%|█▌        | 148/966 [00:17<01:37,  8.41it/s] 15%|█▌        | 149/966 [00:17<01:37,  8.39it/s] 16%|█▌        | 150/966 [00:17<01:37,  8.39it/s] 16%|█▌        | 151/966 [00:17<01:37,  8.40it/s] 16%|█▌        | 152/966 [00:18<01:37,  8.39it/s] 16%|█▌        | 153/966 [00:18<01:36,  8.40it/s] 16%|█▌        | 154/966 [00:18<01:36,  8.40it/s] 16%|█▌        | 155/966 [00:18<01:36,  8.40it/s] 16%|█▌        | 156/966 [00:18<01:36,  8.41it/s] 16%|█▋        | 157/966 [00:18<01:36,  8.40it/s] 16%|█▋        | 158/966 [00:18<01:36,  8.38it/s] 16%|█▋        | 159/966 [00:18<01:36,  8.39it/s] 17%|█▋        | 160/966 [00:18<01:36,  8.39it/s] 17%|█▋        | 161/966 [00:19<01:35,  8.40it/s] 17%|█▋        | 162/966 [00:19<01:35,  8.41it/s] 17%|█▋        | 163/966 [00:19<01:35,  8.43it/s] 17%|█▋        | 164/966 [00:19<01:35,  8.42it/s] 17%|█▋        | 165/966 [00:19<01:35,  8.41it/s] 17%|█▋        | 166/966 [00:19<01:34,  8.43it/s] 17%|█▋        | 167/966 [00:19<01:34,  8.43it/s] 17%|█▋        | 168/966 [00:19<01:34,  8.44it/s] 17%|█▋        | 169/966 [00:20<01:34,  8.44it/s] 18%|█▊        | 170/966 [00:20<01:34,  8.43it/s] 18%|█▊        | 171/966 [00:20<01:34,  8.42it/s] 18%|█▊        | 172/966 [00:20<01:34,  8.41it/s] 18%|█▊        | 173/966 [00:20<01:34,  8.40it/s] 18%|█▊        | 174/966 [00:20<01:34,  8.40it/s] 18%|█▊        | 175/966 [00:20<01:34,  8.40it/s] 18%|█▊        | 176/966 [00:20<01:34,  8.40it/s] 18%|█▊        | 177/966 [00:20<01:34,  8.39it/s] 18%|█▊        | 178/966 [00:21<01:33,  8.39it/s] 19%|█▊        | 179/966 [00:21<01:33,  8.38it/s] 19%|█▊        | 180/966 [00:21<01:33,  8.40it/s] 19%|█▊        | 181/966 [00:21<01:33,  8.40it/s] 19%|█▉        | 182/966 [00:21<01:33,  8.40it/s] 19%|█▉        | 183/966 [00:21<01:33,  8.41it/s] 19%|█▉        | 184/966 [00:21<01:33,  8.41it/s] 19%|█▉        | 185/966 [00:21<01:32,  8.41it/s] 19%|█▉        | 186/966 [00:22<01:32,  8.40it/s] 19%|█▉        | 187/966 [00:22<01:32,  8.38it/s] 19%|█▉        | 188/966 [00:22<01:32,  8.39it/s] 20%|█▉        | 189/966 [00:22<01:32,  8.42it/s] 20%|█▉        | 190/966 [00:22<01:32,  8.40it/s] 20%|█▉        | 191/966 [00:22<01:32,  8.40it/s] 20%|█▉        | 192/966 [00:22<01:32,  8.40it/s] 20%|█▉        | 193/966 [00:22<01:32,  8.39it/s] 20%|██        | 194/966 [00:23<01:32,  8.38it/s] 20%|██        | 195/966 [00:23<01:31,  8.39it/s] 20%|██        | 196/966 [00:23<01:32,  8.37it/s] 20%|██        | 197/966 [00:23<01:31,  8.37it/s] 20%|██        | 198/966 [00:23<01:31,  8.37it/s] 21%|██        | 199/966 [00:23<01:31,  8.38it/s] 21%|██        | 200/966 [00:23<01:31,  8.37it/s] 21%|██        | 201/966 [00:23<01:31,  8.38it/s] 21%|██        | 202/966 [00:23<01:31,  8.37it/s] 21%|██        | 203/966 [00:24<01:31,  8.38it/s] 21%|██        | 204/966 [00:24<01:30,  8.38it/s] 21%|██        | 205/966 [00:24<01:30,  8.39it/s] 21%|██▏       | 206/966 [00:24<01:30,  8.39it/s] 21%|██▏       | 207/966 [00:24<01:30,  8.37it/s] 22%|██▏       | 208/966 [00:24<01:30,  8.38it/s] 22%|██▏       | 209/966 [00:24<01:30,  8.38it/s] 22%|██▏       | 210/966 [00:24<01:30,  8.39it/s] 22%|██▏       | 211/966 [00:25<01:29,  8.40it/s] 22%|██▏       | 212/966 [00:25<01:29,  8.43it/s] 22%|██▏       | 213/966 [00:25<01:29,  8.40it/s] 22%|██▏       | 214/966 [00:25<01:29,  8.40it/s] 22%|██▏       | 215/966 [00:25<01:29,  8.40it/s] 22%|██▏       | 216/966 [00:25<01:29,  8.42it/s] 22%|██▏       | 217/966 [00:25<01:29,  8.41it/s] 23%|██▎       | 218/966 [00:25<01:28,  8.41it/s] 23%|██▎       | 219/966 [00:25<01:28,  8.40it/s] 23%|██▎       | 220/966 [00:26<01:28,  8.39it/s] 23%|██▎       | 221/966 [00:26<01:28,  8.38it/s] 23%|██▎       | 222/966 [00:26<01:28,  8.38it/s] 23%|██▎       | 223/966 [00:26<01:28,  8.37it/s] 23%|██▎       | 224/966 [00:26<01:28,  8.37it/s] 23%|██▎       | 225/966 [00:26<01:28,  8.39it/s] 23%|██▎       | 226/966 [00:26<01:28,  8.39it/s] 23%|██▎       | 227/966 [00:26<01:27,  8.41it/s] 24%|██▎       | 228/966 [00:27<01:27,  8.41it/s] 24%|██▎       | 229/966 [00:27<01:27,  8.40it/s] 24%|██▍       | 230/966 [00:27<01:27,  8.38it/s] 24%|██▍       | 231/966 [00:27<01:27,  8.38it/s] 24%|██▍       | 232/966 [00:27<01:27,  8.39it/s] 24%|██▍       | 233/966 [00:27<01:27,  8.41it/s] 24%|██▍       | 234/966 [00:27<01:27,  8.40it/s] 24%|██▍       | 235/966 [00:27<01:27,  8.39it/s] 24%|██▍       | 236/966 [00:28<01:27,  8.38it/s] 25%|██▍       | 237/966 [00:28<01:26,  8.40it/s] 25%|██▍       | 238/966 [00:28<01:26,  8.40it/s] 25%|██▍       | 239/966 [00:28<01:26,  8.39it/s] 25%|██▍       | 240/966 [00:28<01:26,  8.41it/s] 25%|██▍       | 241/966 [00:28<01:26,  8.39it/s] 25%|██▌       | 242/966 [00:28<01:26,  8.39it/s] 25%|██▌       | 243/966 [00:28<01:26,  8.40it/s] 25%|██▌       | 244/966 [00:28<01:26,  8.37it/s] 25%|██▌       | 245/966 [00:29<01:26,  8.38it/s] 25%|██▌       | 246/966 [00:29<01:25,  8.39it/s] 26%|██▌       | 247/966 [00:29<01:25,  8.43it/s] 26%|██▌       | 248/966 [00:29<01:25,  8.42it/s] 26%|██▌       | 249/966 [00:29<01:25,  8.40it/s] 26%|██▌       | 250/966 [00:29<01:25,  8.41it/s] 26%|██▌       | 251/966 [00:29<01:25,  8.41it/s] 26%|██▌       | 252/966 [00:29<01:24,  8.41it/s] 26%|██▌       | 253/966 [00:30<01:24,  8.41it/s] 26%|██▋       | 254/966 [00:30<01:24,  8.41it/s] 26%|██▋       | 255/966 [00:30<01:24,  8.40it/s] 27%|██▋       | 256/966 [00:30<01:24,  8.39it/s] 27%|██▋       | 257/966 [00:30<01:24,  8.41it/s] 27%|██▋       | 258/966 [00:30<01:24,  8.41it/s] 27%|██▋       | 259/966 [00:30<01:24,  8.41it/s] 27%|██▋       | 260/966 [00:30<01:24,  8.40it/s] 27%|██▋       | 261/966 [00:31<01:23,  8.40it/s] 27%|██▋       | 262/966 [00:31<01:23,  8.40it/s] 27%|██▋       | 263/966 [00:31<01:23,  8.40it/s] 27%|██▋       | 264/966 [00:31<01:23,  8.40it/s] 27%|██▋       | 265/966 [00:31<01:23,  8.40it/s] 28%|██▊       | 266/966 [00:31<01:23,  8.40it/s] 28%|██▊       | 267/966 [00:31<01:23,  8.39it/s] 28%|██▊       | 268/966 [00:31<01:23,  8.39it/s] 28%|██▊       | 269/966 [00:31<01:23,  8.38it/s] 28%|██▊       | 270/966 [00:32<01:23,  8.37it/s] 28%|██▊       | 271/966 [00:32<01:22,  8.39it/s] 28%|██▊       | 272/966 [00:32<01:22,  8.38it/s] 28%|██▊       | 273/966 [00:32<01:22,  8.38it/s] 28%|██▊       | 274/966 [00:32<01:22,  8.38it/s] 28%|██▊       | 275/966 [00:32<01:22,  8.37it/s] 29%|██▊       | 276/966 [00:32<01:22,  8.37it/s] 29%|██▊       | 277/966 [00:32<01:22,  8.38it/s] 29%|██▉       | 278/966 [00:33<01:22,  8.38it/s] 29%|██▉       | 279/966 [00:33<01:21,  8.38it/s] 29%|██▉       | 280/966 [00:33<01:21,  8.37it/s] 29%|██▉       | 281/966 [00:33<01:21,  8.39it/s] 29%|██▉       | 282/966 [00:33<01:21,  8.39it/s] 29%|██▉       | 283/966 [00:33<01:21,  8.39it/s] 29%|██▉       | 284/966 [00:33<01:21,  8.39it/s] 30%|██▉       | 285/966 [00:33<01:21,  8.38it/s] 30%|██▉       | 286/966 [00:33<01:21,  8.38it/s] 30%|██▉       | 287/966 [00:34<01:21,  8.38it/s] 30%|██▉       | 288/966 [00:34<01:20,  8.39it/s] 30%|██▉       | 289/966 [00:34<01:20,  8.42it/s] 30%|███       | 290/966 [00:34<01:20,  8.43it/s] 30%|███       | 291/966 [00:34<01:20,  8.43it/s] 30%|███       | 292/966 [00:34<01:20,  8.42it/s] 30%|███       | 293/966 [00:34<01:20,  8.41it/s] 30%|███       | 294/966 [00:34<01:19,  8.42it/s] 31%|███       | 295/966 [00:35<01:19,  8.43it/s] 31%|███       | 296/966 [00:35<01:19,  8.44it/s] 31%|███       | 297/966 [00:35<01:19,  8.46it/s] 31%|███       | 298/966 [00:35<01:19,  8.44it/s] 31%|███       | 299/966 [00:35<01:19,  8.42it/s] 31%|███       | 300/966 [00:35<01:19,  8.41it/s] 31%|███       | 301/966 [00:35<01:19,  8.40it/s] 31%|███▏      | 302/966 [00:35<01:19,  8.39it/s] 31%|███▏      | 303/966 [00:36<01:18,  8.40it/s] 31%|███▏      | 304/966 [00:36<01:18,  8.41it/s] 32%|███▏      | 305/966 [00:36<01:18,  8.41it/s] 32%|███▏      | 306/966 [00:36<01:18,  8.42it/s] 32%|███▏      | 307/966 [00:36<01:18,  8.41it/s] 32%|███▏      | 308/966 [00:36<01:18,  8.40it/s] 32%|███▏      | 309/966 [00:36<01:18,  8.41it/s] 32%|███▏      | 310/966 [00:36<01:18,  8.41it/s] 32%|███▏      | 311/966 [00:36<01:17,  8.40it/s] 32%|███▏      | 312/966 [00:37<01:17,  8.40it/s] 32%|███▏      | 313/966 [00:37<01:17,  8.39it/s] 33%|███▎      | 314/966 [00:37<01:17,  8.38it/s] 33%|███▎      | 315/966 [00:37<01:17,  8.39it/s] 33%|███▎      | 316/966 [00:37<01:17,  8.39it/s] 33%|███▎      | 317/966 [00:37<01:17,  8.38it/s] 33%|███▎      | 318/966 [00:37<01:17,  8.38it/s] 33%|███▎      | 319/966 [00:37<01:17,  8.37it/s] 33%|███▎      | 320/966 [00:38<01:17,  8.38it/s] 33%|███▎      | 321/966 [00:38<01:16,  8.39it/s] 33%|███▎      | 322/966 [00:38<01:16,  8.39it/s] 33%|███▎      | 323/966 [00:38<01:16,  8.39it/s] 34%|███▎      | 324/966 [00:38<01:16,  8.41it/s] 34%|███▎      | 325/966 [00:38<01:16,  8.41it/s] 34%|███▎      | 326/966 [00:38<01:16,  8.41it/s] 34%|███▍      | 327/966 [00:38<01:15,  8.41it/s] 34%|███▍      | 328/966 [00:38<01:15,  8.42it/s] 34%|███▍      | 329/966 [00:39<01:15,  8.40it/s] 34%|███▍      | 330/966 [00:39<01:15,  8.40it/s] 34%|███▍      | 331/966 [00:39<01:15,  8.38it/s] 34%|███▍      | 332/966 [00:39<01:15,  8.38it/s] 34%|███▍      | 333/966 [00:39<01:15,  8.40it/s] 35%|███▍      | 334/966 [00:39<01:15,  8.39it/s] 35%|███▍      | 335/966 [00:39<01:15,  8.38it/s] 35%|███▍      | 336/966 [00:39<01:15,  8.40it/s] 35%|███▍      | 337/966 [00:40<01:14,  8.41it/s] 35%|███▍      | 338/966 [00:40<01:14,  8.41it/s] 35%|███▌      | 339/966 [00:40<01:14,  8.40it/s] 35%|███▌      | 340/966 [00:40<01:14,  8.40it/s] 35%|███▌      | 341/966 [00:40<01:14,  8.41it/s] 35%|███▌      | 342/966 [00:40<01:14,  8.41it/s] 36%|███▌      | 343/966 [00:40<01:14,  8.40it/s] 36%|███▌      | 344/966 [00:40<01:13,  8.41it/s] 36%|███▌      | 345/966 [00:41<01:13,  8.42it/s] 36%|███▌      | 346/966 [00:41<01:13,  8.42it/s] 36%|███▌      | 347/966 [00:41<01:13,  8.42it/s] 36%|███▌      | 348/966 [00:41<01:13,  8.43it/s] 36%|███▌      | 349/966 [00:41<01:13,  8.43it/s] 36%|███▌      | 350/966 [00:41<01:13,  8.43it/s] 36%|███▋      | 351/966 [00:41<01:13,  8.42it/s] 36%|███▋      | 352/966 [00:41<01:13,  8.41it/s] 37%|███▋      | 353/966 [00:41<01:12,  8.41it/s] 37%|███▋      | 354/966 [00:42<01:12,  8.41it/s] 37%|███▋      | 355/966 [00:42<01:12,  8.40it/s] 37%|███▋      | 356/966 [00:42<01:12,  8.38it/s] 37%|███▋      | 357/966 [00:42<01:12,  8.39it/s] 37%|███▋      | 358/966 [00:42<01:12,  8.38it/s] 37%|███▋      | 359/966 [00:42<01:12,  8.39it/s] 37%|███▋      | 360/966 [00:42<01:12,  8.39it/s] 37%|███▋      | 361/966 [00:42<01:12,  8.38it/s] 37%|███▋      | 362/966 [00:43<01:12,  8.37it/s] 38%|███▊      | 363/966 [00:43<01:11,  8.38it/s] 38%|███▊      | 364/966 [00:43<01:11,  8.38it/s] 38%|███▊      | 365/966 [00:43<01:11,  8.38it/s] 38%|███▊      | 366/966 [00:43<01:11,  8.38it/s] 38%|███▊      | 367/966 [00:43<01:11,  8.37it/s] 38%|███▊      | 368/966 [00:43<01:11,  8.38it/s] 38%|███▊      | 369/966 [00:43<01:11,  8.39it/s] 38%|███▊      | 370/966 [00:43<01:10,  8.41it/s] 38%|███▊      | 371/966 [00:44<01:10,  8.41it/s] 39%|███▊      | 372/966 [00:44<01:10,  8.41it/s] 39%|███▊      | 373/966 [00:44<01:10,  8.42it/s] 39%|███▊      | 374/966 [00:44<01:10,  8.40it/s] 39%|███▉      | 375/966 [00:44<01:10,  8.40it/s] 39%|███▉      | 376/966 [00:44<01:10,  8.41it/s] 39%|███▉      | 377/966 [00:44<01:10,  8.41it/s] 39%|███▉      | 378/966 [00:44<01:09,  8.41it/s] 39%|███▉      | 379/966 [00:45<01:09,  8.41it/s] 39%|███▉      | 380/966 [00:45<01:09,  8.42it/s] 39%|███▉      | 381/966 [00:45<01:09,  8.41it/s] 40%|███▉      | 382/966 [00:45<01:09,  8.41it/s] 40%|███▉      | 383/966 [00:45<01:09,  8.40it/s] 40%|███▉      | 384/966 [00:45<01:09,  8.41it/s] 40%|███▉      | 385/966 [00:45<01:09,  8.41it/s] 40%|███▉      | 386/966 [00:45<01:08,  8.41it/s] 40%|████      | 387/966 [00:46<01:08,  8.42it/s] 40%|████      | 388/966 [00:46<01:08,  8.41it/s] 40%|████      | 389/966 [00:46<01:08,  8.40it/s] 40%|████      | 390/966 [00:46<01:08,  8.40it/s] 40%|████      | 391/966 [00:46<01:08,  8.40it/s] 41%|████      | 392/966 [00:46<01:08,  8.39it/s] 41%|████      | 393/966 [00:46<01:08,  8.39it/s] 41%|████      | 394/966 [00:46<01:08,  8.39it/s] 41%|████      | 395/966 [00:46<01:08,  8.39it/s] 41%|████      | 396/966 [00:47<01:07,  8.39it/s] 41%|████      | 397/966 [00:47<01:07,  8.39it/s] 41%|████      | 398/966 [00:47<01:07,  8.40it/s] 41%|████▏     | 399/966 [00:47<01:07,  8.38it/s] 41%|████▏     | 400/966 [00:47<01:07,  8.39it/s] 42%|████▏     | 401/966 [00:47<01:07,  8.40it/s] 42%|████▏     | 402/966 [00:47<01:07,  8.41it/s] 42%|████▏     | 403/966 [00:47<01:06,  8.41it/s] 42%|████▏     | 404/966 [00:48<01:06,  8.40it/s] 42%|████▏     | 405/966 [00:48<01:06,  8.38it/s] 42%|████▏     | 406/966 [00:48<01:06,  8.38it/s] 42%|████▏     | 407/966 [00:48<01:06,  8.38it/s] 42%|████▏     | 408/966 [00:48<01:06,  8.39it/s] 42%|████▏     | 409/966 [00:48<01:06,  8.38it/s] 42%|████▏     | 410/966 [00:48<01:06,  8.40it/s] 43%|████▎     | 411/966 [00:48<01:06,  8.40it/s] 43%|████▎     | 412/966 [00:48<01:05,  8.40it/s] 43%|████▎     | 413/966 [00:49<01:05,  8.40it/s] 43%|████▎     | 414/966 [00:49<01:05,  8.41it/s] 43%|████▎     | 415/966 [00:49<01:05,  8.39it/s] 43%|████▎     | 416/966 [00:49<01:05,  8.39it/s] 43%|████▎     | 417/966 [00:49<01:05,  8.40it/s] 43%|████▎     | 418/966 [00:49<01:05,  8.40it/s] 43%|████▎     | 419/966 [00:49<01:05,  8.40it/s] 43%|████▎     | 420/966 [00:49<01:05,  8.40it/s] 44%|████▎     | 421/966 [00:50<01:04,  8.43it/s] 44%|████▎     | 422/966 [00:50<01:04,  8.45it/s] 44%|████▍     | 423/966 [00:50<01:04,  8.46it/s] 44%|████▍     | 424/966 [00:50<01:04,  8.46it/s] 44%|████▍     | 425/966 [00:50<01:04,  8.43it/s] 44%|████▍     | 426/966 [00:50<01:04,  8.41it/s] 44%|████▍     | 427/966 [00:50<01:03,  8.43it/s] 44%|████▍     | 428/966 [00:50<01:03,  8.43it/s] 44%|████▍     | 429/966 [00:50<01:03,  8.42it/s] 45%|████▍     | 430/966 [00:51<01:03,  8.43it/s] 45%|████▍     | 431/966 [00:51<01:03,  8.43it/s] 45%|████▍     | 432/966 [00:51<01:03,  8.44it/s] 45%|████▍     | 433/966 [00:51<01:03,  8.43it/s] 45%|████▍     | 434/966 [00:51<01:03,  8.42it/s] 45%|████▌     | 435/966 [00:51<01:03,  8.42it/s] 45%|████▌     | 436/966 [00:51<01:03,  8.40it/s] 45%|████▌     | 437/966 [00:51<01:03,  8.39it/s] 45%|████▌     | 438/966 [00:52<01:02,  8.39it/s] 45%|████▌     | 439/966 [00:52<01:02,  8.39it/s] 46%|████▌     | 440/966 [00:52<01:02,  8.38it/s] 46%|████▌     | 441/966 [00:52<01:02,  8.38it/s] 46%|████▌     | 442/966 [00:52<01:02,  8.38it/s] 46%|████▌     | 443/966 [00:52<01:02,  8.41it/s] 46%|████▌     | 444/966 [00:52<01:02,  8.40it/s] 46%|████▌     | 445/966 [00:52<01:02,  8.40it/s] 46%|████▌     | 446/966 [00:53<01:01,  8.40it/s] 46%|████▋     | 447/966 [00:53<01:01,  8.40it/s] 46%|████▋     | 448/966 [00:53<01:01,  8.38it/s] 46%|████▋     | 449/966 [00:53<01:01,  8.38it/s] 47%|████▋     | 450/966 [00:53<01:01,  8.38it/s] 47%|████▋     | 451/966 [00:53<01:01,  8.38it/s] 47%|████▋     | 452/966 [00:53<01:01,  8.39it/s] 47%|████▋     | 453/966 [00:53<01:01,  8.38it/s] 47%|████▋     | 454/966 [00:53<01:01,  8.38it/s] 47%|████▋     | 455/966 [00:54<01:00,  8.39it/s] 47%|████▋     | 456/966 [00:54<01:00,  8.39it/s] 47%|████▋     | 457/966 [00:54<01:00,  8.42it/s] 47%|████▋     | 458/966 [00:54<01:00,  8.41it/s] 48%|████▊     | 459/966 [00:54<01:00,  8.41it/s] 48%|████▊     | 460/966 [00:54<01:00,  8.40it/s] 48%|████▊     | 461/966 [00:54<01:00,  8.39it/s] 48%|████▊     | 462/966 [00:54<01:00,  8.39it/s] 48%|████▊     | 463/966 [00:55<00:59,  8.39it/s] 48%|████▊     | 464/966 [00:55<00:59,  8.40it/s] 48%|████▊     | 465/966 [00:55<00:59,  8.39it/s] 48%|████▊     | 466/966 [00:55<00:59,  8.38it/s] 48%|████▊     | 467/966 [00:55<00:59,  8.38it/s] 48%|████▊     | 468/966 [00:55<00:59,  8.38it/s] 49%|████▊     | 469/966 [00:55<00:59,  8.40it/s] 49%|████▊     | 470/966 [00:55<00:58,  8.42it/s] 49%|████▉     | 471/966 [00:56<00:58,  8.41it/s] 49%|████▉     | 472/966 [00:56<00:58,  8.41it/s] 49%|████▉     | 473/966 [00:56<00:58,  8.40it/s] 49%|████▉     | 474/966 [00:56<00:58,  8.40it/s] 49%|████▉     | 475/966 [00:56<00:58,  8.40it/s] 49%|████▉     | 476/966 [00:56<00:58,  8.41it/s] 49%|████▉     | 477/966 [00:56<00:58,  8.40it/s] 49%|████▉     | 478/966 [00:56<00:57,  8.43it/s] 50%|████▉     | 479/966 [00:56<00:57,  8.43it/s] 50%|████▉     | 480/966 [00:57<00:57,  8.42it/s] 50%|████▉     | 481/966 [00:57<00:57,  8.43it/s] 50%|████▉     | 482/966 [00:57<00:57,  8.42it/s] 50%|█████     | 483/966 [00:57<00:57,  8.42it/s] 50%|█████     | 484/966 [00:57<00:57,  8.41it/s] 50%|█████     | 485/966 [00:57<00:57,  8.39it/s] 50%|█████     | 486/966 [00:57<00:57,  8.39it/s] 50%|█████     | 487/966 [00:57<00:57,  8.40it/s] 51%|█████     | 488/966 [00:58<00:56,  8.40it/s] 51%|█████     | 489/966 [00:58<00:56,  8.39it/s] 51%|█████     | 490/966 [00:58<00:56,  8.40it/s] 51%|█████     | 491/966 [00:58<00:56,  8.41it/s] 51%|█████     | 492/966 [00:58<00:56,  8.40it/s] 51%|█████     | 493/966 [00:58<00:56,  8.40it/s] 51%|█████     | 494/966 [00:58<00:56,  8.39it/s] 51%|█████     | 495/966 [00:58<00:56,  8.41it/s] 51%|█████▏    | 496/966 [00:58<00:55,  8.41it/s] 51%|█████▏    | 497/966 [00:59<00:55,  8.41it/s] 52%|█████▏    | 498/966 [00:59<00:55,  8.41it/s] 52%|█████▏    | 499/966 [00:59<00:55,  8.40it/s] 52%|█████▏    | 500/966 [00:59<00:55,  8.39it/s] 52%|█████▏    | 501/966 [00:59<00:55,  8.39it/s] 52%|█████▏    | 502/966 [00:59<00:55,  8.40it/s] 52%|█████▏    | 503/966 [00:59<00:55,  8.41it/s] 52%|█████▏    | 504/966 [00:59<00:54,  8.41it/s] 52%|█████▏    | 505/966 [01:00<00:54,  8.41it/s] 52%|█████▏    | 506/966 [01:00<00:54,  8.42it/s] 52%|█████▏    | 507/966 [01:00<00:54,  8.43it/s] 53%|█████▎    | 508/966 [01:00<00:54,  8.41it/s] 53%|█████▎    | 509/966 [01:00<00:54,  8.41it/s] 53%|█████▎    | 510/966 [01:00<00:54,  8.40it/s] 53%|█████▎    | 511/966 [01:00<00:54,  8.41it/s] 53%|█████▎    | 512/966 [01:00<00:54,  8.40it/s] 53%|█████▎    | 513/966 [01:00<00:53,  8.40it/s] 53%|█████▎    | 514/966 [01:01<00:53,  8.41it/s] 53%|█████▎    | 515/966 [01:01<00:53,  8.41it/s] 53%|█████▎    | 516/966 [01:01<00:53,  8.42it/s] 54%|█████▎    | 517/966 [01:01<00:53,  8.41it/s] 54%|█████▎    | 518/966 [01:01<00:53,  8.42it/s] 54%|█████▎    | 519/966 [01:01<00:53,  8.41it/s] 54%|█████▍    | 520/966 [01:01<00:53,  8.41it/s] 54%|█████▍    | 521/966 [01:01<00:53,  8.39it/s] 54%|█████▍    | 522/966 [01:02<00:52,  8.40it/s] 54%|█████▍    | 523/966 [01:02<00:52,  8.38it/s] 54%|█████▍    | 524/966 [01:02<00:52,  8.39it/s] 54%|█████▍    | 525/966 [01:02<00:52,  8.40it/s] 54%|█████▍    | 526/966 [01:02<00:52,  8.38it/s] 55%|█████▍    | 527/966 [01:02<00:52,  8.39it/s] 55%|█████▍    | 528/966 [01:02<00:52,  8.39it/s] 55%|█████▍    | 529/966 [01:02<00:52,  8.39it/s] 55%|█████▍    | 530/966 [01:03<00:51,  8.39it/s] 55%|█████▍    | 531/966 [01:03<00:51,  8.38it/s] 55%|█████▌    | 532/966 [01:03<00:51,  8.38it/s] 55%|█████▌    | 533/966 [01:03<00:51,  8.38it/s] 55%|█████▌    | 534/966 [01:03<00:51,  8.39it/s] 55%|█████▌    | 535/966 [01:03<00:51,  8.40it/s] 55%|█████▌    | 536/966 [01:03<00:51,  8.40it/s] 56%|█████▌    | 537/966 [01:03<00:51,  8.39it/s] 56%|█████▌    | 538/966 [01:03<00:50,  8.40it/s] 56%|█████▌    | 539/966 [01:04<00:50,  8.38it/s] 56%|█████▌    | 540/966 [01:04<00:50,  8.40it/s] 56%|█████▌    | 541/966 [01:04<00:50,  8.40it/s] 56%|█████▌    | 542/966 [01:04<00:50,  8.39it/s] 56%|█████▌    | 543/966 [01:04<00:50,  8.39it/s] 56%|█████▋    | 544/966 [01:04<00:50,  8.39it/s] 56%|█████▋    | 545/966 [01:04<00:50,  8.39it/s] 57%|█████▋    | 546/966 [01:04<00:49,  8.40it/s] 57%|█████▋    | 547/966 [01:05<00:49,  8.40it/s] 57%|█████▋    | 548/966 [01:05<00:49,  8.41it/s] 57%|█████▋    | 549/966 [01:05<00:49,  8.42it/s] 57%|█████▋    | 550/966 [01:05<00:49,  8.42it/s] 57%|█████▋    | 551/966 [01:05<00:49,  8.41it/s] 57%|█████▋    | 552/966 [01:05<00:49,  8.44it/s] 57%|█████▋    | 553/966 [01:05<00:48,  8.44it/s] 57%|█████▋    | 554/966 [01:05<00:48,  8.44it/s] 57%|█████▋    | 555/966 [01:05<00:48,  8.43it/s] 58%|█████▊    | 556/966 [01:06<00:48,  8.42it/s] 58%|█████▊    | 557/966 [01:06<00:48,  8.42it/s] 58%|█████▊    | 558/966 [01:06<00:48,  8.41it/s] 58%|█████▊    | 559/966 [01:06<00:48,  8.40it/s] 58%|█████▊    | 560/966 [01:06<00:48,  8.40it/s] 58%|█████▊    | 561/966 [01:06<00:48,  8.40it/s] 58%|█████▊    | 562/966 [01:06<00:48,  8.41it/s] 58%|█████▊    | 563/966 [01:06<00:47,  8.41it/s] 58%|█████▊    | 564/966 [01:07<00:47,  8.41it/s] 58%|█████▊    | 565/966 [01:07<00:47,  8.42it/s] 59%|█████▊    | 566/966 [01:07<00:47,  8.40it/s] 59%|█████▊    | 567/966 [01:07<00:47,  8.39it/s] 59%|█████▉    | 568/966 [01:07<00:47,  8.39it/s] 59%|█████▉    | 569/966 [01:07<00:47,  8.41it/s] 59%|█████▉    | 570/966 [01:07<00:47,  8.41it/s] 59%|█████▉    | 571/966 [01:07<00:47,  8.40it/s] 59%|█████▉    | 572/966 [01:08<00:46,  8.40it/s] 59%|█████▉    | 573/966 [01:08<00:46,  8.39it/s] 59%|█████▉    | 574/966 [01:08<00:46,  8.40it/s] 60%|█████▉    | 575/966 [01:08<00:46,  8.39it/s] 60%|█████▉    | 576/966 [01:08<00:46,  8.39it/s] 60%|█████▉    | 577/966 [01:08<00:46,  8.39it/s] 60%|█████▉    | 578/966 [01:08<00:46,  8.39it/s] 60%|█████▉    | 579/966 [01:08<00:46,  8.39it/s] 60%|██████    | 580/966 [01:08<00:46,  8.38it/s] 60%|██████    | 581/966 [01:09<00:45,  8.39it/s] 60%|██████    | 582/966 [01:09<00:45,  8.39it/s] 60%|██████    | 583/966 [01:09<00:45,  8.38it/s] 60%|██████    | 584/966 [01:09<00:45,  8.40it/s] 61%|██████    | 585/966 [01:09<00:45,  8.40it/s] 61%|██████    | 586/966 [01:09<00:45,  8.40it/s] 61%|██████    | 587/966 [01:09<00:45,  8.41it/s] 61%|██████    | 588/966 [01:09<00:44,  8.42it/s] 61%|██████    | 589/966 [01:10<00:44,  8.43it/s] 61%|██████    | 590/966 [01:10<00:44,  8.44it/s] 61%|██████    | 591/966 [01:10<00:44,  8.45it/s] 61%|██████▏   | 592/966 [01:10<00:44,  8.43it/s] 61%|██████▏   | 593/966 [01:10<00:44,  8.41it/s] 61%|██████▏   | 594/966 [01:10<00:44,  8.40it/s] 62%|██████▏   | 595/966 [01:10<00:43,  8.44it/s] 62%|██████▏   | 596/966 [01:10<00:43,  8.45it/s] 62%|██████▏   | 597/966 [01:10<00:43,  8.44it/s] 62%|██████▏   | 598/966 [01:11<00:43,  8.43it/s] 62%|██████▏   | 599/966 [01:11<00:43,  8.41it/s] 62%|██████▏   | 600/966 [01:11<00:43,  8.41it/s] 62%|██████▏   | 601/966 [01:11<00:43,  8.40it/s] 62%|██████▏   | 602/966 [01:11<00:43,  8.41it/s] 62%|██████▏   | 603/966 [01:11<00:43,  8.40it/s] 63%|██████▎   | 604/966 [01:11<00:43,  8.40it/s] 63%|██████▎   | 605/966 [01:11<00:42,  8.43it/s] 63%|██████▎   | 606/966 [01:12<00:42,  8.42it/s] 63%|██████▎   | 607/966 [01:12<00:42,  8.41it/s] 63%|██████▎   | 608/966 [01:12<00:42,  8.41it/s] 63%|██████▎   | 609/966 [01:12<00:42,  8.39it/s] 63%|██████▎   | 610/966 [01:12<00:42,  8.40it/s] 63%|██████▎   | 611/966 [01:12<00:42,  8.39it/s] 63%|██████▎   | 612/966 [01:12<00:42,  8.39it/s] 63%|██████▎   | 613/966 [01:12<00:41,  8.41it/s] 64%|██████▎   | 614/966 [01:13<00:41,  8.41it/s] 64%|██████▎   | 615/966 [01:13<00:41,  8.41it/s] 64%|██████▍   | 616/966 [01:13<00:41,  8.42it/s] 64%|██████▍   | 617/966 [01:13<00:41,  8.41it/s] 64%|██████▍   | 618/966 [01:13<00:41,  8.40it/s] 64%|██████▍   | 619/966 [01:13<00:41,  8.40it/s] 64%|██████▍   | 620/966 [01:13<00:41,  8.40it/s] 64%|██████▍   | 621/966 [01:13<00:41,  8.41it/s] 64%|██████▍   | 622/966 [01:13<00:40,  8.40it/s] 64%|██████▍   | 623/966 [01:14<00:40,  8.38it/s] 65%|██████▍   | 624/966 [01:14<00:40,  8.38it/s] 65%|██████▍   | 625/966 [01:14<00:40,  8.39it/s] 65%|██████▍   | 626/966 [01:14<00:40,  8.38it/s] 65%|██████▍   | 627/966 [01:14<00:40,  8.38it/s] 65%|██████▌   | 628/966 [01:14<00:40,  8.38it/s] 65%|██████▌   | 629/966 [01:14<00:40,  8.38it/s] 65%|██████▌   | 630/966 [01:14<00:40,  8.38it/s] 65%|██████▌   | 631/966 [01:15<00:39,  8.39it/s] 65%|██████▌   | 632/966 [01:15<00:39,  8.41it/s] 66%|██████▌   | 633/966 [01:15<00:39,  8.42it/s] 66%|██████▌   | 634/966 [01:15<00:39,  8.40it/s] 66%|██████▌   | 635/966 [01:15<00:39,  8.39it/s] 66%|██████▌   | 636/966 [01:15<00:39,  8.41it/s] 66%|██████▌   | 637/966 [01:15<00:39,  8.42it/s] 66%|██████▌   | 638/966 [01:15<00:39,  8.40it/s] 66%|██████▌   | 639/966 [01:15<00:38,  8.39it/s] 66%|██████▋   | 640/966 [01:16<00:38,  8.41it/s] 66%|██████▋   | 641/966 [01:16<00:38,  8.42it/s] 66%|██████▋   | 642/966 [01:16<00:38,  8.41it/s] 67%|██████▋   | 643/966 [01:16<00:38,  8.40it/s] 67%|██████▋   | 644/966 [01:16<00:38,  8.41it/s] 67%|██████▋   | 645/966 [01:16<00:38,  8.40it/s] 67%|██████▋   | 646/966 [01:16<00:38,  8.40it/s] 67%|██████▋   | 647/966 [01:16<00:38,  8.39it/s] 67%|██████▋   | 648/966 [01:17<00:37,  8.39it/s] 67%|██████▋   | 649/966 [01:17<00:37,  8.39it/s] 67%|██████▋   | 650/966 [01:17<00:37,  8.40it/s] 67%|██████▋   | 651/966 [01:17<00:37,  8.40it/s] 67%|██████▋   | 652/966 [01:17<00:37,  8.40it/s] 68%|██████▊   | 653/966 [01:17<00:37,  8.40it/s] 68%|██████▊   | 654/966 [01:17<00:37,  8.41it/s] 68%|██████▊   | 655/966 [01:17<00:36,  8.43it/s] 68%|██████▊   | 656/966 [01:18<00:36,  8.41it/s] 68%|██████▊   | 657/966 [01:18<00:36,  8.39it/s] 68%|██████▊   | 658/966 [01:18<00:36,  8.40it/s] 68%|██████▊   | 659/966 [01:18<00:36,  8.39it/s] 68%|██████▊   | 660/966 [01:18<00:36,  8.41it/s] 68%|██████▊   | 661/966 [01:18<00:36,  8.41it/s] 69%|██████▊   | 662/966 [01:18<00:36,  8.40it/s] 69%|██████▊   | 663/966 [01:18<00:35,  8.42it/s] 69%|██████▊   | 664/966 [01:18<00:35,  8.42it/s] 69%|██████▉   | 665/966 [01:19<00:35,  8.40it/s] 69%|██████▉   | 666/966 [01:19<00:35,  8.41it/s] 69%|██████▉   | 667/966 [01:19<00:35,  8.42it/s] 69%|██████▉   | 668/966 [01:19<00:35,  8.41it/s] 69%|██████▉   | 669/966 [01:19<00:35,  8.41it/s] 69%|██████▉   | 670/966 [01:19<00:35,  8.40it/s] 69%|██████▉   | 671/966 [01:19<00:35,  8.40it/s] 70%|██████▉   | 672/966 [01:19<00:34,  8.40it/s] 70%|██████▉   | 673/966 [01:20<00:34,  8.41it/s] 70%|██████▉   | 674/966 [01:20<00:34,  8.41it/s] 70%|██████▉   | 675/966 [01:20<00:34,  8.41it/s] 70%|██████▉   | 676/966 [01:20<00:34,  8.41it/s] 70%|███████   | 677/966 [01:20<00:34,  8.40it/s] 70%|███████   | 678/966 [01:20<00:34,  8.40it/s] 70%|███████   | 679/966 [01:20<00:34,  8.40it/s] 70%|███████   | 680/966 [01:20<00:33,  8.42it/s] 70%|███████   | 681/966 [01:20<00:33,  8.42it/s] 71%|███████   | 682/966 [01:21<00:33,  8.43it/s] 71%|███████   | 683/966 [01:21<00:33,  8.42it/s] 71%|███████   | 684/966 [01:21<00:33,  8.40it/s] 71%|███████   | 685/966 [01:21<00:33,  8.40it/s] 71%|███████   | 686/966 [01:21<00:33,  8.40it/s] 71%|███████   | 687/966 [01:21<00:33,  8.42it/s] 71%|███████   | 688/966 [01:21<00:33,  8.40it/s] 71%|███████▏  | 689/966 [01:21<00:32,  8.41it/s] 71%|███████▏  | 690/966 [01:22<00:32,  8.40it/s] 72%|███████▏  | 691/966 [01:22<00:32,  8.43it/s] 72%|███████▏  | 692/966 [01:22<00:32,  8.42it/s] 72%|███████▏  | 693/966 [01:22<00:32,  8.41it/s] 72%|███████▏  | 694/966 [01:22<00:32,  8.41it/s] 72%|███████▏  | 695/966 [01:22<00:32,  8.42it/s] 72%|███████▏  | 696/966 [01:22<00:32,  8.40it/s] 72%|███████▏  | 697/966 [01:22<00:32,  8.39it/s] 72%|███████▏  | 698/966 [01:23<00:31,  8.39it/s] 72%|███████▏  | 699/966 [01:23<00:31,  8.39it/s] 72%|███████▏  | 700/966 [01:23<00:31,  8.42it/s] 73%|███████▎  | 701/966 [01:23<00:31,  8.41it/s] 73%|███████▎  | 702/966 [01:23<00:31,  8.39it/s] 73%|███████▎  | 703/966 [01:23<00:31,  8.39it/s] 73%|███████▎  | 704/966 [01:23<00:31,  8.38it/s] 73%|███████▎  | 705/966 [01:23<00:31,  8.37it/s] 73%|███████▎  | 706/966 [01:23<00:31,  8.39it/s] 73%|███████▎  | 707/966 [01:24<00:30,  8.38it/s] 73%|███████▎  | 708/966 [01:24<00:30,  8.40it/s] 73%|███████▎  | 709/966 [01:24<00:30,  8.40it/s] 73%|███████▎  | 710/966 [01:24<00:30,  8.40it/s] 74%|███████▎  | 711/966 [01:24<00:30,  8.39it/s] 74%|███████▎  | 712/966 [01:24<00:30,  8.40it/s] 74%|███████▍  | 713/966 [01:24<00:30,  8.40it/s] 74%|███████▍  | 714/966 [01:24<00:29,  8.42it/s] 74%|███████▍  | 715/966 [01:25<00:29,  8.43it/s] 74%|███████▍  | 716/966 [01:25<00:29,  8.43it/s] 74%|███████▍  | 717/966 [01:25<00:29,  8.44it/s] 74%|███████▍  | 718/966 [01:25<00:29,  8.42it/s] 74%|███████▍  | 719/966 [01:25<00:29,  8.42it/s] 75%|███████▍  | 720/966 [01:25<00:29,  8.43it/s] 75%|███████▍  | 721/966 [01:25<00:29,  8.43it/s] 75%|███████▍  | 722/966 [01:25<00:28,  8.43it/s] 75%|███████▍  | 723/966 [01:25<00:28,  8.43it/s] 75%|███████▍  | 724/966 [01:26<00:28,  8.43it/s] 75%|███████▌  | 725/966 [01:26<00:28,  8.43it/s] 75%|███████▌  | 726/966 [01:26<00:28,  8.42it/s] 75%|███████▌  | 727/966 [01:26<00:28,  8.42it/s] 75%|███████▌  | 728/966 [01:26<00:28,  8.43it/s] 75%|███████▌  | 729/966 [01:26<00:28,  8.43it/s] 76%|███████▌  | 730/966 [01:26<00:28,  8.42it/s] 76%|███████▌  | 731/966 [01:26<00:27,  8.41it/s] 76%|███████▌  | 732/966 [01:27<00:27,  8.40it/s] 76%|███████▌  | 733/966 [01:27<00:27,  8.39it/s] 76%|███████▌  | 734/966 [01:27<00:27,  8.38it/s] 76%|███████▌  | 735/966 [01:27<00:27,  8.38it/s] 76%|███████▌  | 736/966 [01:27<00:27,  8.40it/s] 76%|███████▋  | 737/966 [01:27<00:27,  8.41it/s] 76%|███████▋  | 738/966 [01:27<00:27,  8.40it/s] 77%|███████▋  | 739/966 [01:27<00:27,  8.40it/s] 77%|███████▋  | 740/966 [01:28<00:26,  8.40it/s] 77%|███████▋  | 741/966 [01:28<00:26,  8.41it/s] 77%|███████▋  | 742/966 [01:28<00:26,  8.40it/s] 77%|███████▋  | 743/966 [01:28<00:26,  8.40it/s] 77%|███████▋  | 744/966 [01:28<00:26,  8.38it/s] 77%|███████▋  | 745/966 [01:28<00:26,  8.40it/s] 77%|███████▋  | 746/966 [01:28<00:26,  8.40it/s] 77%|███████▋  | 747/966 [01:28<00:26,  8.41it/s] 77%|███████▋  | 748/966 [01:28<00:25,  8.40it/s] 78%|███████▊  | 749/966 [01:29<00:25,  8.41it/s] 78%|███████▊  | 750/966 [01:29<00:25,  8.41it/s] 78%|███████▊  | 751/966 [01:29<00:25,  8.43it/s] 78%|███████▊  | 752/966 [01:29<00:25,  8.42it/s] 78%|███████▊  | 753/966 [01:29<00:25,  8.41it/s] 78%|███████▊  | 754/966 [01:29<00:25,  8.42it/s] 78%|███████▊  | 755/966 [01:29<00:25,  8.42it/s] 78%|███████▊  | 756/966 [01:29<00:24,  8.43it/s] 78%|███████▊  | 757/966 [01:30<00:24,  8.44it/s] 78%|███████▊  | 758/966 [01:30<00:24,  8.46it/s] 79%|███████▊  | 759/966 [01:30<00:24,  8.46it/s] 79%|███████▊  | 760/966 [01:30<00:24,  8.44it/s] 79%|███████▉  | 761/966 [01:30<00:24,  8.45it/s] 79%|███████▉  | 762/966 [01:30<00:24,  8.43it/s] 79%|███████▉  | 763/966 [01:30<00:24,  8.43it/s] 79%|███████▉  | 764/966 [01:30<00:23,  8.44it/s] 79%|███████▉  | 765/966 [01:30<00:23,  8.44it/s] 79%|███████▉  | 766/966 [01:31<00:23,  8.42it/s] 79%|███████▉  | 767/966 [01:31<00:23,  8.40it/s] 80%|███████▉  | 768/966 [01:31<00:23,  8.40it/s] 80%|███████▉  | 769/966 [01:31<00:23,  8.41it/s] 80%|███████▉  | 770/966 [01:31<00:23,  8.40it/s] 80%|███████▉  | 771/966 [01:31<00:23,  8.41it/s] 80%|███████▉  | 772/966 [01:31<00:23,  8.41it/s] 80%|████████  | 773/966 [01:31<00:22,  8.40it/s] 80%|████████  | 774/966 [01:32<00:22,  8.38it/s] 80%|████████  | 775/966 [01:32<00:22,  8.38it/s] 80%|████████  | 776/966 [01:32<00:22,  8.39it/s] 80%|████████  | 777/966 [01:32<00:22,  8.38it/s] 81%|████████  | 778/966 [01:32<00:22,  8.36it/s] 81%|████████  | 779/966 [01:32<00:22,  8.36it/s] 81%|████████  | 780/966 [01:32<00:22,  8.38it/s] 81%|████████  | 781/966 [01:32<00:22,  8.37it/s] 81%|████████  | 782/966 [01:33<00:22,  8.36it/s] 81%|████████  | 783/966 [01:33<00:21,  8.36it/s] 81%|████████  | 784/966 [01:33<00:21,  8.36it/s] 81%|████████▏ | 785/966 [01:33<00:21,  8.37it/s] 81%|████████▏ | 786/966 [01:33<00:21,  8.37it/s] 81%|████████▏ | 787/966 [01:33<00:21,  8.36it/s] 82%|████████▏ | 788/966 [01:33<00:21,  8.36it/s] 82%|████████▏ | 789/966 [01:33<00:21,  8.37it/s] 82%|████████▏ | 790/966 [01:33<00:21,  8.37it/s] 82%|████████▏ | 791/966 [01:34<00:20,  8.37it/s] 82%|████████▏ | 792/966 [01:34<00:20,  8.37it/s] 82%|████████▏ | 793/966 [01:34<00:20,  8.37it/s] 82%|████████▏ | 794/966 [01:34<00:20,  8.37it/s] 82%|████████▏ | 795/966 [01:34<00:20,  8.38it/s] 82%|████████▏ | 796/966 [01:34<00:20,  8.39it/s] 83%|████████▎ | 797/966 [01:34<00:20,  8.41it/s] 83%|████████▎ | 798/966 [01:34<00:19,  8.41it/s] 83%|████████▎ | 799/966 [01:35<00:19,  8.42it/s] 83%|████████▎ | 800/966 [01:35<00:19,  8.43it/s] 83%|████████▎ | 801/966 [01:35<00:19,  8.42it/s] 83%|████████▎ | 802/966 [01:35<00:19,  8.40it/s] 83%|████████▎ | 803/966 [01:35<00:19,  8.38it/s] 83%|████████▎ | 804/966 [01:35<00:19,  8.38it/s] 83%|████████▎ | 805/966 [01:35<00:19,  8.40it/s] 83%|████████▎ | 806/966 [01:35<00:19,  8.40it/s] 84%|████████▎ | 807/966 [01:35<00:18,  8.40it/s] 84%|████████▎ | 808/966 [01:36<00:18,  8.39it/s] 84%|████████▎ | 809/966 [01:36<00:18,  8.39it/s] 84%|████████▍ | 810/966 [01:36<00:18,  8.38it/s] 84%|████████▍ | 811/966 [01:36<00:18,  8.40it/s] 84%|████████▍ | 812/966 [01:36<00:18,  8.41it/s] 84%|████████▍ | 813/966 [01:36<00:18,  8.40it/s] 84%|████████▍ | 814/966 [01:36<00:18,  8.39it/s] 84%|████████▍ | 815/966 [01:36<00:17,  8.40it/s] 84%|████████▍ | 816/966 [01:37<00:17,  8.41it/s] 85%|████████▍ | 817/966 [01:37<00:17,  8.41it/s] 85%|████████▍ | 818/966 [01:37<00:17,  8.42it/s] 85%|████████▍ | 819/966 [01:37<00:17,  8.41it/s] 85%|████████▍ | 820/966 [01:37<00:17,  8.41it/s] 85%|████████▍ | 821/966 [01:37<00:17,  8.40it/s] 85%|████████▌ | 822/966 [01:37<00:17,  8.39it/s] 85%|████████▌ | 823/966 [01:37<00:17,  8.38it/s] 85%|████████▌ | 824/966 [01:38<00:16,  8.38it/s] 85%|████████▌ | 825/966 [01:38<00:16,  8.38it/s] 86%|████████▌ | 826/966 [01:38<00:16,  8.38it/s] 86%|████████▌ | 827/966 [01:38<00:16,  8.38it/s] 86%|████████▌ | 828/966 [01:38<00:16,  8.37it/s] 86%|████████▌ | 829/966 [01:38<00:16,  8.38it/s] 86%|████████▌ | 830/966 [01:38<00:16,  8.39it/s] 86%|████████▌ | 831/966 [01:38<00:16,  8.40it/s] 86%|████████▌ | 832/966 [01:38<00:15,  8.38it/s] 86%|████████▌ | 833/966 [01:39<00:15,  8.39it/s] 86%|████████▋ | 834/966 [01:39<00:15,  8.40it/s] 86%|████████▋ | 835/966 [01:39<00:15,  8.41it/s] 87%|████████▋ | 836/966 [01:39<00:15,  8.39it/s] 87%|████████▋ | 837/966 [01:39<00:15,  8.38it/s] 87%|████████▋ | 838/966 [01:39<00:15,  8.38it/s] 87%|████████▋ | 839/966 [01:39<00:15,  8.40it/s] 87%|████████▋ | 840/966 [01:39<00:14,  8.41it/s] 87%|████████▋ | 841/966 [01:40<00:14,  8.44it/s] 87%|████████▋ | 842/966 [01:40<00:14,  8.45it/s] 87%|████████▋ | 843/966 [01:40<00:14,  8.43it/s] 87%|████████▋ | 844/966 [01:40<00:14,  8.41it/s] 87%|████████▋ | 845/966 [01:40<00:14,  8.39it/s] 88%|████████▊ | 846/966 [01:40<00:14,  8.39it/s] 88%|████████▊ | 847/966 [01:40<00:14,  8.40it/s] 88%|████████▊ | 848/966 [01:40<00:14,  8.41it/s] 88%|████████▊ | 849/966 [01:40<00:13,  8.40it/s] 88%|████████▊ | 850/966 [01:41<00:13,  8.40it/s] 88%|████████▊ | 851/966 [01:41<00:13,  8.39it/s] 88%|████████▊ | 852/966 [01:41<00:13,  8.39it/s] 88%|████████▊ | 853/966 [01:41<00:13,  8.39it/s] 88%|████████▊ | 854/966 [01:41<00:13,  8.38it/s] 89%|████████▊ | 855/966 [01:41<00:13,  8.39it/s] 89%|████████▊ | 856/966 [01:41<00:13,  8.39it/s] 89%|████████▊ | 857/966 [01:41<00:13,  8.38it/s] 89%|████████▉ | 858/966 [01:42<00:12,  8.37it/s] 89%|████████▉ | 859/966 [01:42<00:12,  8.38it/s] 89%|████████▉ | 860/966 [01:42<00:12,  8.39it/s] 89%|████████▉ | 861/966 [01:42<00:12,  8.39it/s] 89%|████████▉ | 862/966 [01:42<00:12,  8.38it/s] 89%|████████▉ | 863/966 [01:42<00:12,  8.37it/s] 89%|████████▉ | 864/966 [01:42<00:12,  8.36it/s] 90%|████████▉ | 865/966 [01:42<00:12,  8.38it/s] 90%|████████▉ | 866/966 [01:43<00:11,  8.38it/s] 90%|████████▉ | 867/966 [01:43<00:11,  8.39it/s] 90%|████████▉ | 868/966 [01:43<00:11,  8.40it/s] 90%|████████▉ | 869/966 [01:43<00:11,  8.40it/s] 90%|█████████ | 870/966 [01:43<00:11,  8.38it/s] 90%|█████████ | 871/966 [01:43<00:11,  8.37it/s] 90%|█████████ | 872/966 [01:43<00:11,  8.38it/s] 90%|█████████ | 873/966 [01:43<00:11,  8.38it/s] 90%|█████████ | 874/966 [01:43<00:10,  8.38it/s] 91%|█████████ | 875/966 [01:44<00:10,  8.38it/s] 91%|█████████ | 876/966 [01:44<00:10,  8.39it/s] 91%|█████████ | 877/966 [01:44<00:10,  8.40it/s] 91%|█████████ | 878/966 [01:44<00:10,  8.42it/s] 91%|█████████ | 879/966 [01:44<00:10,  8.40it/s] 91%|█████████ | 880/966 [01:44<00:10,  8.39it/s] 91%|█████████ | 881/966 [01:44<00:10,  8.38it/s] 91%|█████████▏| 882/966 [01:44<00:10,  8.39it/s] 91%|█████████▏| 883/966 [01:45<00:09,  8.40it/s] 92%|█████████▏| 884/966 [01:45<00:09,  8.42it/s] 92%|█████████▏| 885/966 [01:45<00:09,  8.41it/s] 92%|█████████▏| 886/966 [01:45<00:09,  8.39it/s] 92%|█████████▏| 887/966 [01:45<00:09,  8.38it/s] 92%|█████████▏| 888/966 [01:45<00:09,  8.38it/s] 92%|█████████▏| 889/966 [01:45<00:09,  8.37it/s] 92%|█████████▏| 890/966 [01:45<00:09,  8.37it/s] 92%|█████████▏| 891/966 [01:45<00:08,  8.41it/s] 92%|█████████▏| 892/966 [01:46<00:08,  8.42it/s] 92%|█████████▏| 893/966 [01:46<00:08,  8.40it/s] 93%|█████████▎| 894/966 [01:46<00:08,  8.40it/s] 93%|█████████▎| 895/966 [01:46<00:08,  8.38it/s] 93%|█████████▎| 896/966 [01:46<00:08,  8.39it/s] 93%|█████████▎| 897/966 [01:46<00:08,  8.41it/s] 93%|█████████▎| 898/966 [01:46<00:08,  8.41it/s] 93%|█████████▎| 899/966 [01:46<00:07,  8.42it/s] 93%|█████████▎| 900/966 [01:47<00:07,  8.41it/s] 93%|█████████▎| 901/966 [01:47<00:07,  8.41it/s] 93%|█████████▎| 902/966 [01:47<00:07,  8.40it/s] 93%|█████████▎| 903/966 [01:47<00:07,  8.41it/s] 94%|█████████▎| 904/966 [01:47<00:07,  8.41it/s] 94%|█████████▎| 905/966 [01:47<00:07,  8.42it/s] 94%|█████████▍| 906/966 [01:47<00:07,  8.42it/s] 94%|█████████▍| 907/966 [01:47<00:07,  8.41it/s] 94%|█████████▍| 908/966 [01:48<00:06,  8.41it/s] 94%|█████████▍| 909/966 [01:48<00:06,  8.39it/s] 94%|█████████▍| 910/966 [01:48<00:06,  8.41it/s] 94%|█████████▍| 911/966 [01:48<00:06,  8.42it/s] 94%|█████████▍| 912/966 [01:48<00:06,  8.43it/s] 95%|█████████▍| 913/966 [01:48<00:06,  8.42it/s] 95%|█████████▍| 914/966 [01:48<00:06,  8.42it/s] 95%|█████████▍| 915/966 [01:48<00:06,  8.41it/s] 95%|█████████▍| 916/966 [01:48<00:05,  8.40it/s] 95%|█████████▍| 917/966 [01:49<00:05,  8.40it/s] 95%|█████████▌| 918/966 [01:49<00:05,  8.41it/s] 95%|█████████▌| 919/966 [01:49<00:05,  8.44it/s] 95%|█████████▌| 920/966 [01:49<00:05,  8.42it/s] 95%|█████████▌| 921/966 [01:49<00:05,  8.43it/s] 95%|█████████▌| 922/966 [01:49<00:05,  8.40it/s] 96%|█████████▌| 923/966 [01:49<00:05,  8.42it/s] 96%|█████████▌| 924/966 [01:49<00:04,  8.43it/s] 96%|█████████▌| 925/966 [01:50<00:04,  8.44it/s] 96%|█████████▌| 926/966 [01:50<00:04,  8.45it/s] 96%|█████████▌| 927/966 [01:50<00:04,  8.45it/s] 96%|█████████▌| 928/966 [01:50<00:04,  8.44it/s] 96%|█████████▌| 929/966 [01:50<00:04,  8.42it/s] 96%|█████████▋| 930/966 [01:50<00:04,  8.42it/s] 96%|█████████▋| 931/966 [01:50<00:04,  8.43it/s] 96%|█████████▋| 932/966 [01:50<00:04,  8.43it/s] 97%|█████████▋| 933/966 [01:50<00:03,  8.41it/s] 97%|█████████▋| 934/966 [01:51<00:03,  8.42it/s] 97%|█████████▋| 935/966 [01:51<00:03,  8.43it/s] 97%|█████████▋| 936/966 [01:51<00:03,  8.41it/s] 97%|█████████▋| 937/966 [01:51<00:03,  8.41it/s] 97%|█████████▋| 938/966 [01:51<00:03,  8.40it/s] 97%|█████████▋| 939/966 [01:51<00:03,  8.42it/s] 97%|█████████▋| 940/966 [01:51<00:03,  8.41it/s] 97%|█████████▋| 941/966 [01:51<00:02,  8.41it/s] 98%|█████████▊| 942/966 [01:52<00:02,  8.40it/s] 98%|█████████▊| 943/966 [01:52<00:02,  8.40it/s] 98%|█████████▊| 944/966 [01:52<00:02,  8.40it/s] 98%|█████████▊| 945/966 [01:52<00:02,  8.39it/s] 98%|█████████▊| 946/966 [01:52<00:02,  8.38it/s] 98%|█████████▊| 947/966 [01:52<00:02,  8.40it/s] 98%|█████████▊| 948/966 [01:52<00:02,  8.40it/s] 98%|█████████▊| 949/966 [01:52<00:02,  8.41it/s] 98%|█████████▊| 950/966 [01:53<00:01,  8.39it/s] 98%|█████████▊| 951/966 [01:53<00:01,  8.39it/s] 99%|█████████▊| 952/966 [01:53<00:01,  8.39it/s] 99%|█████████▊| 953/966 [01:53<00:01,  8.39it/s] 99%|█████████▉| 954/966 [01:53<00:01,  8.38it/s] 99%|█████████▉| 955/966 [01:53<00:01,  8.39it/s] 99%|█████████▉| 956/966 [01:53<00:01,  8.40it/s] 99%|█████████▉| 957/966 [01:53<00:01,  8.40it/s] 99%|█████████▉| 958/966 [01:53<00:00,  8.39it/s] 99%|█████████▉| 959/966 [01:54<00:00,  8.39it/s] 99%|█████████▉| 960/966 [01:54<00:00,  8.40it/s] 99%|█████████▉| 961/966 [01:54<00:00,  8.41it/s]100%|█████████▉| 962/966 [01:54<00:00,  8.41it/s]100%|█████████▉| 963/966 [01:54<00:00,  8.42it/s]100%|█████████▉| 964/966 [01:54<00:00,  8.41it/s]100%|█████████▉| 965/966 [01:54<00:00,  8.40it/s]100%|██████████| 966/966 [01:54<00:00,  8.41it/s]100%|██████████| 966/966 [01:54<00:00,  8.41it/s]
sending off prediction to background worker for resampling and export
done with 706-005
