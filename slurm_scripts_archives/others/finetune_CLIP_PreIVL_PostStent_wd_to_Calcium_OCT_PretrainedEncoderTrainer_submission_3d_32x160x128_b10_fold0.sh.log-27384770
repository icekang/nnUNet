/home/gridsan/nchutisilp/.conda/envs/nnunet/bin/python
wandb: Tracking run with wandb version 0.16.6
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2024-11-15 06:51:24.773049: Using torch.compile...
/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
################### Loading pretrained weights from file  /home/gridsan/nchutisilp/projects/OpenAI-CLIP/logs/CLIP_PreIVL_PostStent_wd/nnunet.pt ###################
Below is the list of overlapping blocks in pretrained model and nnUNet architecture:
encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])
encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])
encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])
encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])
encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])
encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])
encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])
encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])
encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])
encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])
encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])
encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])
encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])
encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])
encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])
encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])
encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])
encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])
encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])
encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])
encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])
encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])
encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])
encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])
encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])
encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])
encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])
decoder.encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])
decoder.encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])
decoder.encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])
decoder.encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])
decoder.encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])
decoder.encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])
decoder.encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])
decoder.encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])
decoder.encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])
decoder.encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])
decoder.encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])
decoder.encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])
decoder.encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])
decoder.encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.stages.0.convs.0.conv.weight shape torch.Size([320, 640, 3, 3, 3])
decoder.stages.0.convs.0.conv.bias shape torch.Size([320])
decoder.stages.0.convs.0.norm.weight shape torch.Size([320])
decoder.stages.0.convs.0.norm.bias shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.0.weight shape torch.Size([320, 640, 3, 3, 3])
decoder.stages.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.stages.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.stages.0.convs.1.conv.bias shape torch.Size([320])
decoder.stages.0.convs.1.norm.weight shape torch.Size([320])
decoder.stages.0.convs.1.norm.bias shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.stages.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.stages.1.convs.0.conv.weight shape torch.Size([256, 512, 3, 3, 3])
decoder.stages.1.convs.0.conv.bias shape torch.Size([256])
decoder.stages.1.convs.0.norm.weight shape torch.Size([256])
decoder.stages.1.convs.0.norm.bias shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.0.weight shape torch.Size([256, 512, 3, 3, 3])
decoder.stages.1.convs.0.all_modules.0.bias shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.1.weight shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.1.bias shape torch.Size([256])
decoder.stages.1.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.stages.1.convs.1.conv.bias shape torch.Size([256])
decoder.stages.1.convs.1.norm.weight shape torch.Size([256])
decoder.stages.1.convs.1.norm.bias shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.stages.1.convs.1.all_modules.0.bias shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.1.weight shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.1.bias shape torch.Size([256])
decoder.stages.2.convs.0.conv.weight shape torch.Size([128, 256, 3, 3, 3])
decoder.stages.2.convs.0.conv.bias shape torch.Size([128])
decoder.stages.2.convs.0.norm.weight shape torch.Size([128])
decoder.stages.2.convs.0.norm.bias shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.0.weight shape torch.Size([128, 256, 3, 3, 3])
decoder.stages.2.convs.0.all_modules.0.bias shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.1.weight shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.1.bias shape torch.Size([128])
decoder.stages.2.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.stages.2.convs.1.conv.bias shape torch.Size([128])
decoder.stages.2.convs.1.norm.weight shape torch.Size([128])
decoder.stages.2.convs.1.norm.bias shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.stages.2.convs.1.all_modules.0.bias shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.1.weight shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.1.bias shape torch.Size([128])
decoder.stages.3.convs.0.conv.weight shape torch.Size([64, 128, 3, 3, 3])
decoder.stages.3.convs.0.conv.bias shape torch.Size([64])
decoder.stages.3.convs.0.norm.weight shape torch.Size([64])
decoder.stages.3.convs.0.norm.bias shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.0.weight shape torch.Size([64, 128, 3, 3, 3])
decoder.stages.3.convs.0.all_modules.0.bias shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.1.weight shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.1.bias shape torch.Size([64])
decoder.stages.3.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.stages.3.convs.1.conv.bias shape torch.Size([64])
decoder.stages.3.convs.1.norm.weight shape torch.Size([64])
decoder.stages.3.convs.1.norm.bias shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.stages.3.convs.1.all_modules.0.bias shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.1.weight shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.1.bias shape torch.Size([64])
decoder.stages.4.convs.0.conv.weight shape torch.Size([32, 64, 3, 3, 3])
decoder.stages.4.convs.0.conv.bias shape torch.Size([32])
decoder.stages.4.convs.0.norm.weight shape torch.Size([32])
decoder.stages.4.convs.0.norm.bias shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.0.weight shape torch.Size([32, 64, 3, 3, 3])
decoder.stages.4.convs.0.all_modules.0.bias shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.1.weight shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.1.bias shape torch.Size([32])
decoder.stages.4.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.stages.4.convs.1.conv.bias shape torch.Size([32])
decoder.stages.4.convs.1.norm.weight shape torch.Size([32])
decoder.stages.4.convs.1.norm.bias shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.stages.4.convs.1.all_modules.0.bias shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.1.weight shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.1.bias shape torch.Size([32])
decoder.transpconvs.0.weight shape torch.Size([320, 320, 1, 2, 2])
decoder.transpconvs.0.bias shape torch.Size([320])
decoder.transpconvs.1.weight shape torch.Size([320, 256, 2, 2, 2])
decoder.transpconvs.1.bias shape torch.Size([256])
decoder.transpconvs.2.weight shape torch.Size([256, 128, 2, 2, 2])
decoder.transpconvs.2.bias shape torch.Size([128])
decoder.transpconvs.3.weight shape torch.Size([128, 64, 2, 2, 2])
decoder.transpconvs.3.bias shape torch.Size([64])
decoder.transpconvs.4.weight shape torch.Size([64, 32, 2, 2, 2])
decoder.transpconvs.4.bias shape torch.Size([32])
################### Done ###################
2024-11-15 06:51:28.199197: do_dummy_2d_data_aug: True
2024-11-15 06:51:28.203331: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset302_Calcium_OCTv2/splits_final.json
2024-11-15 06:51:28.205580: The split file contains 3 splits.
2024-11-15 06:51:28.206530: Desired fold for training: 0
2024-11-15 06:51:28.207396: This split has 4 training and 2 validation cases.
using pin_memory on device 0
using pin_memory on device 0

This is the configuration used by this training:
Configuration name: 3d_32x160x128_b10
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 10, 'patch_size': [32, 160, 128], 'median_image_size_in_voxels': [375.0, 498.0, 498.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'inherits_from': '3d_fullres'} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset302_Calcium_OCTv2', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.4977976381778717, 'mean': 0.13332499563694, 'median': 0.08871842920780182, 'min': 0.0, 'percentile_00_5': 0.014754901640117168, 'percentile_99_5': 0.4977976381778717, 'std': 0.12022686749696732}}} 

2024-11-15 06:51:40.300054: unpacking dataset...
2024-11-15 06:51:46.801323: unpacking done...
2024-11-15 06:51:46.813929: Unable to plot network architecture: nnUNet_compile is enabled!
2024-11-15 06:51:46.884297: 
2024-11-15 06:51:46.885362: Epoch 0
2024-11-15 06:51:46.886453: Current learning rate: 0.0
2024-11-15 06:51:46.887368: encoder learning rate: 0.0
2024-11-15 06:51:46.888152: decoder.stages learning rate: 0.01
2024-11-15 06:51:46.888932: decoder.transpconvs learning rate: 0.01
2024-11-15 06:51:46.889771: decoder.seg_layers learning rate: 0.01
2024-11-15 06:54:49.592090: Validation loss improved from 1000.00000 to -0.12500! Patience: 0/50
2024-11-15 06:54:49.595315: train_loss -0.0462
2024-11-15 06:54:49.597214: val_loss -0.125
2024-11-15 06:54:49.598130: Pseudo dice [0.4703]
2024-11-15 06:54:49.599108: Epoch time: 182.71 s
2024-11-15 06:54:49.599946: Yayy! New best EMA pseudo Dice: 0.4703
2024-11-15 06:54:51.347272: 
2024-11-15 06:54:51.350442: Epoch 1
2024-11-15 06:54:51.351428: Current learning rate: 0.0
2024-11-15 06:54:51.352438: encoder learning rate: 0.0
2024-11-15 06:54:51.353247: decoder.stages learning rate: 0.00992
2024-11-15 06:54:51.354005: decoder.transpconvs learning rate: 0.00992
2024-11-15 06:54:51.354710: decoder.seg_layers learning rate: 0.00992
2024-11-15 06:56:44.653311: Validation loss improved from -0.12500 to -0.22936! Patience: 0/50
2024-11-15 06:56:44.655761: train_loss -0.2009
2024-11-15 06:56:44.657480: val_loss -0.2294
2024-11-15 06:56:44.658425: Pseudo dice [0.5684]
2024-11-15 06:56:44.659417: Epoch time: 113.31 s
2024-11-15 06:56:44.660284: Yayy! New best EMA pseudo Dice: 0.4801
2024-11-15 06:56:46.359668: 
2024-11-15 06:56:46.362767: Epoch 2
2024-11-15 06:56:46.363819: Current learning rate: 0.0
2024-11-15 06:56:46.364778: encoder learning rate: 0.0
2024-11-15 06:56:46.365612: decoder.stages learning rate: 0.00985
2024-11-15 06:56:46.366473: decoder.transpconvs learning rate: 0.00985
2024-11-15 06:56:46.367351: decoder.seg_layers learning rate: 0.00985
2024-11-15 06:58:40.009943: Validation loss did not improve from -0.22936. Patience: 1/50
2024-11-15 06:58:40.012634: train_loss -0.2604
2024-11-15 06:58:40.014107: val_loss -0.2249
2024-11-15 06:58:40.015081: Pseudo dice [0.5654]
2024-11-15 06:58:40.015996: Epoch time: 113.65 s
2024-11-15 06:58:40.016910: Yayy! New best EMA pseudo Dice: 0.4886
2024-11-15 06:58:41.756611: 
2024-11-15 06:58:41.759562: Epoch 3
2024-11-15 06:58:41.760462: Current learning rate: 0.0
2024-11-15 06:58:41.761510: encoder learning rate: 0.0
2024-11-15 06:58:41.762391: decoder.stages learning rate: 0.00977
2024-11-15 06:58:41.763258: decoder.transpconvs learning rate: 0.00977
2024-11-15 06:58:41.764018: decoder.seg_layers learning rate: 0.00977
2024-11-15 07:00:40.674871: Validation loss improved from -0.22936 to -0.24633! Patience: 1/50
2024-11-15 07:00:40.677485: train_loss -0.2889
2024-11-15 07:00:40.679116: val_loss -0.2463
2024-11-15 07:00:40.679943: Pseudo dice [0.5784]
2024-11-15 07:00:40.680825: Epoch time: 118.92 s
2024-11-15 07:00:40.681592: Yayy! New best EMA pseudo Dice: 0.4976
2024-11-15 07:00:42.406159: 
2024-11-15 07:00:42.409468: Epoch 4
2024-11-15 07:00:42.413626: Current learning rate: 0.0
2024-11-15 07:00:42.415274: encoder learning rate: 0.0
2024-11-15 07:00:42.416319: decoder.stages learning rate: 0.0097
2024-11-15 07:00:42.417211: decoder.transpconvs learning rate: 0.0097
2024-11-15 07:00:42.418205: decoder.seg_layers learning rate: 0.0097
2024-11-15 07:02:37.018531: Validation loss improved from -0.24633 to -0.25677! Patience: 0/50
2024-11-15 07:02:37.021034: train_loss -0.3143
2024-11-15 07:02:37.022679: val_loss -0.2568
2024-11-15 07:02:37.023537: Pseudo dice [0.5725]
2024-11-15 07:02:37.024493: Epoch time: 114.62 s
2024-11-15 07:02:37.441194: Yayy! New best EMA pseudo Dice: 0.5051
2024-11-15 07:02:39.262220: 
2024-11-15 07:02:39.265255: Epoch 5
2024-11-15 07:02:39.266257: Current learning rate: 0.0
2024-11-15 07:02:39.267375: encoder learning rate: 0.0
2024-11-15 07:02:39.268268: decoder.stages learning rate: 0.00962
2024-11-15 07:02:39.269076: decoder.transpconvs learning rate: 0.00962
2024-11-15 07:02:39.269926: decoder.seg_layers learning rate: 0.00962
2024-11-15 07:04:33.898677: Validation loss did not improve from -0.25677. Patience: 1/50
2024-11-15 07:04:33.901459: train_loss -0.3075
2024-11-15 07:04:33.903210: val_loss -0.2274
2024-11-15 07:04:33.904194: Pseudo dice [0.5627]
2024-11-15 07:04:33.905132: Epoch time: 114.64 s
2024-11-15 07:04:33.905979: Yayy! New best EMA pseudo Dice: 0.5109
2024-11-15 07:04:35.620600: 
2024-11-15 07:04:35.624177: Epoch 6
2024-11-15 07:04:35.625359: Current learning rate: 0.0
2024-11-15 07:04:35.626518: encoder learning rate: 0.0
2024-11-15 07:04:35.627434: decoder.stages learning rate: 0.00955
2024-11-15 07:04:35.628491: decoder.transpconvs learning rate: 0.00955
2024-11-15 07:04:35.629528: decoder.seg_layers learning rate: 0.00955
2024-11-15 07:06:32.060036: Validation loss did not improve from -0.25677. Patience: 2/50
2024-11-15 07:06:32.063121: train_loss -0.3258
2024-11-15 07:06:32.065032: val_loss -0.2547
2024-11-15 07:06:32.066132: Pseudo dice [0.575]
2024-11-15 07:06:32.067257: Epoch time: 116.44 s
2024-11-15 07:06:32.068204: Yayy! New best EMA pseudo Dice: 0.5173
2024-11-15 07:06:33.940569: 
2024-11-15 07:06:33.943649: Epoch 7
2024-11-15 07:06:33.944692: Current learning rate: 0.0
2024-11-15 07:06:33.945761: encoder learning rate: 0.0
2024-11-15 07:06:33.946677: decoder.stages learning rate: 0.00947
2024-11-15 07:06:33.947524: decoder.transpconvs learning rate: 0.00947
2024-11-15 07:06:33.948339: decoder.seg_layers learning rate: 0.00947
2024-11-15 07:08:31.653353: Validation loss improved from -0.25677 to -0.26374! Patience: 2/50
2024-11-15 07:08:31.657632: train_loss -0.352
2024-11-15 07:08:31.659368: val_loss -0.2637
2024-11-15 07:08:31.660714: Pseudo dice [0.5808]
2024-11-15 07:08:31.662074: Epoch time: 117.72 s
2024-11-15 07:08:31.663213: Yayy! New best EMA pseudo Dice: 0.5236
2024-11-15 07:08:33.482964: 
2024-11-15 07:08:33.544368: Epoch 8
2024-11-15 07:08:33.546303: Current learning rate: 0.0
2024-11-15 07:08:33.547620: encoder learning rate: 0.0
2024-11-15 07:08:33.549022: decoder.stages learning rate: 0.0094
2024-11-15 07:08:33.550179: decoder.transpconvs learning rate: 0.0094
2024-11-15 07:08:33.551364: decoder.seg_layers learning rate: 0.0094
2024-11-15 07:10:35.354008: Validation loss improved from -0.26374 to -0.27047! Patience: 0/50
2024-11-15 07:10:35.356451: train_loss -0.3333
2024-11-15 07:10:35.357986: val_loss -0.2705
2024-11-15 07:10:35.358931: Pseudo dice [0.5907]
2024-11-15 07:10:35.359880: Epoch time: 121.88 s
2024-11-15 07:10:35.360657: Yayy! New best EMA pseudo Dice: 0.5303
2024-11-15 07:10:37.620929: 
2024-11-15 07:10:37.624354: Epoch 9
2024-11-15 07:10:37.625499: Current learning rate: 0.0
2024-11-15 07:10:37.626405: encoder learning rate: 0.0
2024-11-15 07:10:37.627303: decoder.stages learning rate: 0.00932
2024-11-15 07:10:37.628067: decoder.transpconvs learning rate: 0.00932
2024-11-15 07:10:37.628807: decoder.seg_layers learning rate: 0.00932
2024-11-15 07:12:36.430552: Validation loss improved from -0.27047 to -0.28177! Patience: 0/50
2024-11-15 07:12:36.440912: train_loss -0.3389
2024-11-15 07:12:36.443019: val_loss -0.2818
2024-11-15 07:12:36.444429: Pseudo dice [0.5744]
2024-11-15 07:12:36.445787: Epoch time: 118.82 s
2024-11-15 07:12:36.866390: Yayy! New best EMA pseudo Dice: 0.5347
2024-11-15 07:12:38.556669: 
2024-11-15 07:12:38.559838: Epoch 10
2024-11-15 07:12:38.561112: Current learning rate: 0.0
2024-11-15 07:12:38.562458: encoder learning rate: 0.0
2024-11-15 07:12:38.563707: decoder.stages learning rate: 0.00925
2024-11-15 07:12:38.564813: decoder.transpconvs learning rate: 0.00925
2024-11-15 07:12:38.565902: decoder.seg_layers learning rate: 0.00925
2024-11-15 07:14:33.242079: Validation loss improved from -0.28177 to -0.30886! Patience: 0/50
2024-11-15 07:14:33.244633: train_loss -0.3666
2024-11-15 07:14:33.246469: val_loss -0.3089
2024-11-15 07:14:33.247665: Pseudo dice [0.6217]
2024-11-15 07:14:33.248867: Epoch time: 114.69 s
2024-11-15 07:14:33.249954: Yayy! New best EMA pseudo Dice: 0.5434
2024-11-15 07:14:34.947758: 
2024-11-15 07:14:34.951517: Epoch 11
2024-11-15 07:14:34.952969: Current learning rate: 0.0
2024-11-15 07:14:34.954292: encoder learning rate: 0.0
2024-11-15 07:14:34.955386: decoder.stages learning rate: 0.00917
2024-11-15 07:14:34.956411: decoder.transpconvs learning rate: 0.00917
2024-11-15 07:14:34.957278: decoder.seg_layers learning rate: 0.00917
2024-11-15 07:16:32.035910: Validation loss improved from -0.30886 to -0.34560! Patience: 0/50
2024-11-15 07:16:32.038379: train_loss -0.3833
2024-11-15 07:16:32.039953: val_loss -0.3456
2024-11-15 07:16:32.041000: Pseudo dice [0.6364]
2024-11-15 07:16:32.041912: Epoch time: 117.09 s
2024-11-15 07:16:32.042634: Yayy! New best EMA pseudo Dice: 0.5527
2024-11-15 07:16:33.777356: 
2024-11-15 07:16:33.779946: Epoch 12
2024-11-15 07:16:33.780799: Current learning rate: 0.0
2024-11-15 07:16:33.781639: encoder learning rate: 0.0
2024-11-15 07:16:33.782475: decoder.stages learning rate: 0.0091
2024-11-15 07:16:33.783189: decoder.transpconvs learning rate: 0.0091
2024-11-15 07:16:33.784113: decoder.seg_layers learning rate: 0.0091
2024-11-15 07:18:33.200502: Validation loss did not improve from -0.34560. Patience: 1/50
2024-11-15 07:18:33.203288: train_loss -0.3782
2024-11-15 07:18:33.205089: val_loss -0.3139
2024-11-15 07:18:33.205994: Pseudo dice [0.6172]
2024-11-15 07:18:33.206770: Epoch time: 119.43 s
2024-11-15 07:18:33.207551: Yayy! New best EMA pseudo Dice: 0.5592
2024-11-15 07:18:34.987573: 
2024-11-15 07:18:34.990968: Epoch 13
2024-11-15 07:18:34.991839: Current learning rate: 0.0
2024-11-15 07:18:34.992822: encoder learning rate: 0.0
2024-11-15 07:18:34.993672: decoder.stages learning rate: 0.00902
2024-11-15 07:18:34.994455: decoder.transpconvs learning rate: 0.00902
2024-11-15 07:18:34.995210: decoder.seg_layers learning rate: 0.00902
2024-11-15 07:20:30.908993: Validation loss did not improve from -0.34560. Patience: 2/50
2024-11-15 07:20:30.911578: train_loss -0.3692
2024-11-15 07:20:30.913384: val_loss -0.297
2024-11-15 07:20:30.914394: Pseudo dice [0.5983]
2024-11-15 07:20:30.915228: Epoch time: 115.93 s
2024-11-15 07:20:30.916175: Yayy! New best EMA pseudo Dice: 0.5631
2024-11-15 07:20:32.749656: 
2024-11-15 07:20:32.752751: Epoch 14
2024-11-15 07:20:32.753859: Current learning rate: 0.0
2024-11-15 07:20:32.754854: encoder learning rate: 0.0
2024-11-15 07:20:32.755720: decoder.stages learning rate: 0.00894
2024-11-15 07:20:32.756544: decoder.transpconvs learning rate: 0.00894
2024-11-15 07:20:32.757386: decoder.seg_layers learning rate: 0.00894
2024-11-15 07:22:33.613764: Validation loss improved from -0.34560 to -0.34803! Patience: 2/50
2024-11-15 07:22:33.616308: train_loss -0.396
2024-11-15 07:22:33.617843: val_loss -0.348
2024-11-15 07:22:33.618745: Pseudo dice [0.6251]
2024-11-15 07:22:33.619662: Epoch time: 120.87 s
2024-11-15 07:22:34.035344: Yayy! New best EMA pseudo Dice: 0.5693
2024-11-15 07:22:35.813271: 
2024-11-15 07:22:35.816187: Epoch 15
2024-11-15 07:22:35.817129: Current learning rate: 0.0
2024-11-15 07:22:35.818186: encoder learning rate: 0.0
2024-11-15 07:22:35.819046: decoder.stages learning rate: 0.00887
2024-11-15 07:22:35.819984: decoder.transpconvs learning rate: 0.00887
2024-11-15 07:22:35.820869: decoder.seg_layers learning rate: 0.00887
2024-11-15 07:24:37.115455: Validation loss did not improve from -0.34803. Patience: 1/50
2024-11-15 07:24:37.117925: train_loss -0.3973
2024-11-15 07:24:37.119632: val_loss -0.3244
2024-11-15 07:24:37.120845: Pseudo dice [0.6296]
2024-11-15 07:24:37.121926: Epoch time: 121.31 s
2024-11-15 07:24:37.123008: Yayy! New best EMA pseudo Dice: 0.5753
2024-11-15 07:24:38.915752: 
2024-11-15 07:24:38.918676: Epoch 16
2024-11-15 07:24:38.919884: Current learning rate: 0.0
2024-11-15 07:24:38.921099: encoder learning rate: 0.0
2024-11-15 07:24:38.922263: decoder.stages learning rate: 0.00879
2024-11-15 07:24:38.923410: decoder.transpconvs learning rate: 0.00879
2024-11-15 07:24:38.924563: decoder.seg_layers learning rate: 0.00879
2024-11-15 07:26:40.886704: Validation loss did not improve from -0.34803. Patience: 2/50
2024-11-15 07:26:40.889427: train_loss -0.4001
2024-11-15 07:26:40.891044: val_loss -0.3073
2024-11-15 07:26:40.891891: Pseudo dice [0.6089]
2024-11-15 07:26:40.892754: Epoch time: 121.98 s
2024-11-15 07:26:40.893621: Yayy! New best EMA pseudo Dice: 0.5787
2024-11-15 07:26:42.715887: 
2024-11-15 07:26:42.719115: Epoch 17
2024-11-15 07:26:42.720082: Current learning rate: 0.0
2024-11-15 07:26:42.721114: encoder learning rate: 0.0
2024-11-15 07:26:42.721963: decoder.stages learning rate: 0.00872
2024-11-15 07:26:42.722748: decoder.transpconvs learning rate: 0.00872
2024-11-15 07:26:42.723421: decoder.seg_layers learning rate: 0.00872
2024-11-15 07:28:50.882983: Validation loss did not improve from -0.34803. Patience: 3/50
2024-11-15 07:28:50.885415: train_loss -0.4057
2024-11-15 07:28:50.887133: val_loss -0.3298
2024-11-15 07:28:50.888056: Pseudo dice [0.6292]
2024-11-15 07:28:50.889014: Epoch time: 128.17 s
2024-11-15 07:28:50.889924: Yayy! New best EMA pseudo Dice: 0.5837
2024-11-15 07:28:52.698164: 
2024-11-15 07:28:52.701921: Epoch 18
2024-11-15 07:28:52.703041: Current learning rate: 0.0
2024-11-15 07:28:52.704061: encoder learning rate: 0.0
2024-11-15 07:28:52.705018: decoder.stages learning rate: 0.00864
2024-11-15 07:28:52.705830: decoder.transpconvs learning rate: 0.00864
2024-11-15 07:28:52.706695: decoder.seg_layers learning rate: 0.00864
2024-11-15 07:30:55.593977: Validation loss did not improve from -0.34803. Patience: 4/50
2024-11-15 07:30:55.596243: train_loss -0.4066
2024-11-15 07:30:55.597883: val_loss -0.3281
2024-11-15 07:30:55.598885: Pseudo dice [0.6237]
2024-11-15 07:30:55.599792: Epoch time: 122.9 s
2024-11-15 07:30:55.600705: Yayy! New best EMA pseudo Dice: 0.5877
2024-11-15 07:30:57.850513: 
2024-11-15 07:30:57.853981: Epoch 19
2024-11-15 07:30:57.854979: Current learning rate: 0.0
2024-11-15 07:30:57.855995: encoder learning rate: 0.0
2024-11-15 07:30:57.856786: decoder.stages learning rate: 0.00856
2024-11-15 07:30:57.857591: decoder.transpconvs learning rate: 0.00856
2024-11-15 07:30:57.858414: decoder.seg_layers learning rate: 0.00856
2024-11-15 07:33:00.434439: Validation loss did not improve from -0.34803. Patience: 5/50
2024-11-15 07:33:00.437077: train_loss -0.4187
2024-11-15 07:33:00.438629: val_loss -0.3447
2024-11-15 07:33:00.439507: Pseudo dice [0.635]
2024-11-15 07:33:00.440356: Epoch time: 122.59 s
2024-11-15 07:33:00.850189: Yayy! New best EMA pseudo Dice: 0.5925
2024-11-15 07:33:02.595907: 
2024-11-15 07:33:02.599019: Epoch 20
2024-11-15 07:33:02.600047: Current learning rate: 0.00849
2024-11-15 07:33:02.601115: encoder learning rate: 0.00849
2024-11-15 07:33:02.601967: decoder.stages learning rate: 0.00849
2024-11-15 07:33:02.602844: decoder.transpconvs learning rate: 0.00849
2024-11-15 07:33:02.603627: decoder.seg_layers learning rate: 0.00849
2024-11-15 07:34:58.891165: Validation loss did not improve from -0.34803. Patience: 6/50
2024-11-15 07:34:58.893574: train_loss -0.163
2024-11-15 07:34:58.895123: val_loss -0.2178
2024-11-15 07:34:58.896172: Pseudo dice [0.5325]
2024-11-15 07:34:58.897142: Epoch time: 116.3 s
2024-11-15 07:35:00.349056: 
2024-11-15 07:35:00.352298: Epoch 21
2024-11-15 07:35:00.353616: Current learning rate: 0.00841
2024-11-15 07:35:00.354641: encoder learning rate: 0.00841
2024-11-15 07:35:00.355497: decoder.stages learning rate: 0.00841
2024-11-15 07:35:00.356460: decoder.transpconvs learning rate: 0.00841
2024-11-15 07:35:00.357295: decoder.seg_layers learning rate: 0.00841
2024-11-15 07:37:01.722829: Validation loss did not improve from -0.34803. Patience: 7/50
2024-11-15 07:37:01.725464: train_loss -0.2992
2024-11-15 07:37:01.727031: val_loss -0.233
2024-11-15 07:37:01.727986: Pseudo dice [0.5643]
2024-11-15 07:37:01.728914: Epoch time: 121.38 s
2024-11-15 07:37:03.064875: 
2024-11-15 07:37:03.068509: Epoch 22
2024-11-15 07:37:03.069696: Current learning rate: 0.00833
2024-11-15 07:37:03.070717: encoder learning rate: 0.00833
2024-11-15 07:37:03.071570: decoder.stages learning rate: 0.00833
2024-11-15 07:37:03.072316: decoder.transpconvs learning rate: 0.00833
2024-11-15 07:37:03.073385: decoder.seg_layers learning rate: 0.00833
2024-11-15 07:39:10.020398: Validation loss did not improve from -0.34803. Patience: 8/50
2024-11-15 07:39:10.023063: train_loss -0.3272
2024-11-15 07:39:10.024599: val_loss -0.2991
2024-11-15 07:39:10.025606: Pseudo dice [0.585]
2024-11-15 07:39:10.026522: Epoch time: 126.96 s
2024-11-15 07:39:11.422407: 
2024-11-15 07:39:11.426165: Epoch 23
2024-11-15 07:39:11.427421: Current learning rate: 0.00826
2024-11-15 07:39:11.428529: encoder learning rate: 0.00826
2024-11-15 07:39:11.429454: decoder.stages learning rate: 0.00826
2024-11-15 07:39:11.430434: decoder.transpconvs learning rate: 0.00826
2024-11-15 07:39:11.431326: decoder.seg_layers learning rate: 0.00826
2024-11-15 07:41:10.882688: Validation loss did not improve from -0.34803. Patience: 9/50
2024-11-15 07:41:10.885190: train_loss -0.3725
2024-11-15 07:41:10.886792: val_loss -0.2394
2024-11-15 07:41:10.887895: Pseudo dice [0.5738]
2024-11-15 07:41:10.888915: Epoch time: 119.46 s
2024-11-15 07:41:12.279605: 
2024-11-15 07:41:12.283226: Epoch 24
2024-11-15 07:41:12.284546: Current learning rate: 0.00818
2024-11-15 07:41:12.285596: encoder learning rate: 0.00818
2024-11-15 07:41:12.286605: decoder.stages learning rate: 0.00818
2024-11-15 07:41:12.287613: decoder.transpconvs learning rate: 0.00818
2024-11-15 07:41:12.288411: decoder.seg_layers learning rate: 0.00818
2024-11-15 07:43:17.155300: Validation loss did not improve from -0.34803. Patience: 10/50
2024-11-15 07:43:17.157811: train_loss -0.3777
2024-11-15 07:43:17.159448: val_loss -0.3433
2024-11-15 07:43:17.160565: Pseudo dice [0.6254]
2024-11-15 07:43:17.161615: Epoch time: 124.88 s
2024-11-15 07:43:18.947419: 
2024-11-15 07:43:18.950671: Epoch 25
2024-11-15 07:43:18.951913: Current learning rate: 0.0081
2024-11-15 07:43:18.953170: encoder learning rate: 0.0081
2024-11-15 07:43:18.954107: decoder.stages learning rate: 0.0081
2024-11-15 07:43:18.955043: decoder.transpconvs learning rate: 0.0081
2024-11-15 07:43:18.955911: decoder.seg_layers learning rate: 0.0081
2024-11-15 07:45:27.266625: Validation loss did not improve from -0.34803. Patience: 11/50
2024-11-15 07:45:27.268785: train_loss -0.3991
2024-11-15 07:45:27.269808: val_loss -0.3219
2024-11-15 07:45:27.270674: Pseudo dice [0.6118]
2024-11-15 07:45:27.271599: Epoch time: 128.32 s
2024-11-15 07:45:28.627704: 
2024-11-15 07:45:28.631087: Epoch 26
2024-11-15 07:45:28.632123: Current learning rate: 0.00803
2024-11-15 07:45:28.633056: encoder learning rate: 0.00803
2024-11-15 07:45:28.633981: decoder.stages learning rate: 0.00803
2024-11-15 07:45:28.634944: decoder.transpconvs learning rate: 0.00803
2024-11-15 07:45:28.635855: decoder.seg_layers learning rate: 0.00803
2024-11-15 07:47:32.087926: Validation loss improved from -0.34803 to -0.35669! Patience: 11/50
2024-11-15 07:47:32.090479: train_loss -0.4257
2024-11-15 07:47:32.091984: val_loss -0.3567
2024-11-15 07:47:32.093034: Pseudo dice [0.6328]
2024-11-15 07:47:32.093828: Epoch time: 123.46 s
2024-11-15 07:47:32.094754: Yayy! New best EMA pseudo Dice: 0.5942
2024-11-15 07:47:33.893446: 
2024-11-15 07:47:33.896721: Epoch 27
2024-11-15 07:47:33.897866: Current learning rate: 0.00795
2024-11-15 07:47:33.898810: encoder learning rate: 0.00795
2024-11-15 07:47:33.899688: decoder.stages learning rate: 0.00795
2024-11-15 07:47:33.900467: decoder.transpconvs learning rate: 0.00795
2024-11-15 07:47:33.901479: decoder.seg_layers learning rate: 0.00795
2024-11-15 07:49:37.409035: Validation loss did not improve from -0.35669. Patience: 1/50
2024-11-15 07:49:37.411498: train_loss -0.4442
2024-11-15 07:49:37.413146: val_loss -0.3535
2024-11-15 07:49:37.414305: Pseudo dice [0.6243]
2024-11-15 07:49:37.415381: Epoch time: 123.52 s
2024-11-15 07:49:37.416338: Yayy! New best EMA pseudo Dice: 0.5972
2024-11-15 07:49:39.235432: 
2024-11-15 07:49:39.238769: Epoch 28
2024-11-15 07:49:39.240173: Current learning rate: 0.00787
2024-11-15 07:49:39.241366: encoder learning rate: 0.00787
2024-11-15 07:49:39.242543: decoder.stages learning rate: 0.00787
2024-11-15 07:49:39.243528: decoder.transpconvs learning rate: 0.00787
2024-11-15 07:49:39.244580: decoder.seg_layers learning rate: 0.00787
2024-11-15 07:51:33.135247: Validation loss did not improve from -0.35669. Patience: 2/50
2024-11-15 07:51:33.137388: train_loss -0.4525
2024-11-15 07:51:33.138646: val_loss -0.3466
2024-11-15 07:51:33.139450: Pseudo dice [0.6241]
2024-11-15 07:51:33.140328: Epoch time: 113.9 s
2024-11-15 07:51:33.141135: Yayy! New best EMA pseudo Dice: 0.5999
2024-11-15 07:51:34.931636: 
2024-11-15 07:51:34.934932: Epoch 29
2024-11-15 07:51:34.936337: Current learning rate: 0.0078
2024-11-15 07:51:34.937498: encoder learning rate: 0.0078
2024-11-15 07:51:34.938555: decoder.stages learning rate: 0.0078
2024-11-15 07:51:34.939487: decoder.transpconvs learning rate: 0.0078
2024-11-15 07:51:34.940416: decoder.seg_layers learning rate: 0.0078
2024-11-15 07:53:41.305139: Validation loss improved from -0.35669 to -0.36261! Patience: 2/50
2024-11-15 07:53:41.307145: train_loss -0.4699
2024-11-15 07:53:41.308593: val_loss -0.3626
2024-11-15 07:53:41.309520: Pseudo dice [0.6431]
2024-11-15 07:53:41.310373: Epoch time: 126.38 s
2024-11-15 07:53:41.727395: Yayy! New best EMA pseudo Dice: 0.6042
2024-11-15 07:53:43.956341: 
2024-11-15 07:53:43.959183: Epoch 30
2024-11-15 07:53:43.960237: Current learning rate: 0.00772
2024-11-15 07:53:43.961229: encoder learning rate: 0.00772
2024-11-15 07:53:43.962124: decoder.stages learning rate: 0.00772
2024-11-15 07:53:43.963071: decoder.transpconvs learning rate: 0.00772
2024-11-15 07:53:43.963905: decoder.seg_layers learning rate: 0.00772
2024-11-15 07:55:48.407447: Validation loss improved from -0.36261 to -0.37940! Patience: 0/50
2024-11-15 07:55:48.409520: train_loss -0.486
2024-11-15 07:55:48.411210: val_loss -0.3794
2024-11-15 07:55:48.412293: Pseudo dice [0.6432]
2024-11-15 07:55:48.413275: Epoch time: 124.45 s
2024-11-15 07:55:48.414223: Yayy! New best EMA pseudo Dice: 0.6081
2024-11-15 07:55:50.231801: 
2024-11-15 07:55:50.259610: Epoch 31
2024-11-15 07:55:50.261007: Current learning rate: 0.00764
2024-11-15 07:55:50.262177: encoder learning rate: 0.00764
2024-11-15 07:55:50.263132: decoder.stages learning rate: 0.00764
2024-11-15 07:55:50.264084: decoder.transpconvs learning rate: 0.00764
2024-11-15 07:55:50.264981: decoder.seg_layers learning rate: 0.00764
2024-11-15 07:57:53.740593: Validation loss improved from -0.37940 to -0.41271! Patience: 0/50
2024-11-15 07:57:53.743390: train_loss -0.5
2024-11-15 07:57:53.745195: val_loss -0.4127
2024-11-15 07:57:53.747134: Pseudo dice [0.654]
2024-11-15 07:57:53.748345: Epoch time: 123.51 s
2024-11-15 07:57:53.749417: Yayy! New best EMA pseudo Dice: 0.6127
2024-11-15 07:57:55.545623: 
2024-11-15 07:57:55.548498: Epoch 32
2024-11-15 07:57:55.549523: Current learning rate: 0.00756
2024-11-15 07:57:55.550955: encoder learning rate: 0.00756
2024-11-15 07:57:55.553983: decoder.stages learning rate: 0.00756
2024-11-15 07:57:55.555696: decoder.transpconvs learning rate: 0.00756
2024-11-15 07:57:55.556840: decoder.seg_layers learning rate: 0.00756
2024-11-15 07:59:58.500338: Validation loss did not improve from -0.41271. Patience: 1/50
2024-11-15 07:59:58.503607: train_loss -0.509
2024-11-15 07:59:58.505265: val_loss -0.3935
2024-11-15 07:59:58.506218: Pseudo dice [0.6618]
2024-11-15 07:59:58.507065: Epoch time: 122.96 s
2024-11-15 07:59:58.507853: Yayy! New best EMA pseudo Dice: 0.6176
2024-11-15 08:00:00.483893: 
2024-11-15 08:00:00.487201: Epoch 33
2024-11-15 08:00:00.488396: Current learning rate: 0.00749
2024-11-15 08:00:00.489325: encoder learning rate: 0.00749
2024-11-15 08:00:00.490142: decoder.stages learning rate: 0.00749
2024-11-15 08:00:00.490940: decoder.transpconvs learning rate: 0.00749
2024-11-15 08:00:00.491666: decoder.seg_layers learning rate: 0.00749
2024-11-15 08:02:05.008794: Validation loss improved from -0.41271 to -0.41805! Patience: 1/50
2024-11-15 08:02:05.011581: train_loss -0.5172
2024-11-15 08:02:05.013351: val_loss -0.4181
2024-11-15 08:02:05.014241: Pseudo dice [0.6645]
2024-11-15 08:02:05.015357: Epoch time: 124.53 s
2024-11-15 08:02:05.016136: Yayy! New best EMA pseudo Dice: 0.6223
2024-11-15 08:02:06.868459: 
2024-11-15 08:02:06.871622: Epoch 34
2024-11-15 08:02:06.872594: Current learning rate: 0.00741
2024-11-15 08:02:06.873477: encoder learning rate: 0.00741
2024-11-15 08:02:06.874313: decoder.stages learning rate: 0.00741
2024-11-15 08:02:06.875072: decoder.transpconvs learning rate: 0.00741
2024-11-15 08:02:06.875825: decoder.seg_layers learning rate: 0.00741
2024-11-15 08:04:16.466163: Validation loss did not improve from -0.41805. Patience: 1/50
2024-11-15 08:04:16.468751: train_loss -0.5133
2024-11-15 08:04:16.470261: val_loss -0.4104
2024-11-15 08:04:16.471438: Pseudo dice [0.6689]
2024-11-15 08:04:16.473264: Epoch time: 129.6 s
2024-11-15 08:04:16.886170: Yayy! New best EMA pseudo Dice: 0.627
2024-11-15 08:04:18.763743: 
2024-11-15 08:04:18.767076: Epoch 35
2024-11-15 08:04:18.768442: Current learning rate: 0.00733
2024-11-15 08:04:18.769745: encoder learning rate: 0.00733
2024-11-15 08:04:18.770900: decoder.stages learning rate: 0.00733
2024-11-15 08:04:18.771917: decoder.transpconvs learning rate: 0.00733
2024-11-15 08:04:18.773008: decoder.seg_layers learning rate: 0.00733
2024-11-15 08:06:22.975656: Validation loss improved from -0.41805 to -0.42581! Patience: 1/50
2024-11-15 08:06:22.978137: train_loss -0.5342
2024-11-15 08:06:22.979826: val_loss -0.4258
2024-11-15 08:06:22.980831: Pseudo dice [0.6783]
2024-11-15 08:06:22.981743: Epoch time: 124.22 s
2024-11-15 08:06:22.982803: Yayy! New best EMA pseudo Dice: 0.6321
2024-11-15 08:06:24.818853: 
2024-11-15 08:06:24.822034: Epoch 36
2024-11-15 08:06:24.823162: Current learning rate: 0.00725
2024-11-15 08:06:24.824182: encoder learning rate: 0.00725
2024-11-15 08:06:24.825244: decoder.stages learning rate: 0.00725
2024-11-15 08:06:24.826290: decoder.transpconvs learning rate: 0.00725
2024-11-15 08:06:24.827334: decoder.seg_layers learning rate: 0.00725
2024-11-15 08:08:20.256401: Validation loss did not improve from -0.42581. Patience: 1/50
2024-11-15 08:08:20.259103: train_loss -0.5198
2024-11-15 08:08:20.260907: val_loss -0.408
2024-11-15 08:08:20.261916: Pseudo dice [0.6658]
2024-11-15 08:08:20.262950: Epoch time: 115.44 s
2024-11-15 08:08:20.263939: Yayy! New best EMA pseudo Dice: 0.6355
2024-11-15 08:08:22.087092: 
2024-11-15 08:08:22.089954: Epoch 37
2024-11-15 08:08:22.091161: Current learning rate: 0.00718
2024-11-15 08:08:22.092226: encoder learning rate: 0.00718
2024-11-15 08:08:22.093205: decoder.stages learning rate: 0.00718
2024-11-15 08:08:22.094173: decoder.transpconvs learning rate: 0.00718
2024-11-15 08:08:22.095125: decoder.seg_layers learning rate: 0.00718
2024-11-15 08:10:29.300894: Validation loss did not improve from -0.42581. Patience: 2/50
2024-11-15 08:10:29.303175: train_loss -0.5527
2024-11-15 08:10:29.304888: val_loss -0.3981
2024-11-15 08:10:29.306040: Pseudo dice [0.6568]
2024-11-15 08:10:29.307100: Epoch time: 127.22 s
2024-11-15 08:10:29.308339: Yayy! New best EMA pseudo Dice: 0.6376
2024-11-15 08:10:31.129297: 
2024-11-15 08:10:31.130580: Epoch 38
2024-11-15 08:10:31.131377: Current learning rate: 0.0071
2024-11-15 08:10:31.132247: encoder learning rate: 0.0071
2024-11-15 08:10:31.133019: decoder.stages learning rate: 0.0071
2024-11-15 08:10:31.133707: decoder.transpconvs learning rate: 0.0071
2024-11-15 08:10:31.134489: decoder.seg_layers learning rate: 0.0071
2024-11-15 08:12:41.576653: Validation loss did not improve from -0.42581. Patience: 3/50
2024-11-15 08:12:41.578167: train_loss -0.5484
2024-11-15 08:12:41.579451: val_loss -0.3917
2024-11-15 08:12:41.580771: Pseudo dice [0.6641]
2024-11-15 08:12:41.582266: Epoch time: 130.45 s
2024-11-15 08:12:41.583606: Yayy! New best EMA pseudo Dice: 0.6402
2024-11-15 08:12:43.438120: 
2024-11-15 08:12:43.439982: Epoch 39
2024-11-15 08:12:43.441205: Current learning rate: 0.00702
2024-11-15 08:12:43.442945: encoder learning rate: 0.00702
2024-11-15 08:12:43.444214: decoder.stages learning rate: 0.00702
2024-11-15 08:12:43.445207: decoder.transpconvs learning rate: 0.00702
2024-11-15 08:12:43.446204: decoder.seg_layers learning rate: 0.00702
2024-11-15 08:14:53.422393: Validation loss did not improve from -0.42581. Patience: 4/50
2024-11-15 08:14:53.423631: train_loss -0.5603
2024-11-15 08:14:53.424829: val_loss -0.3842
2024-11-15 08:14:53.425817: Pseudo dice [0.642]
2024-11-15 08:14:53.426887: Epoch time: 129.99 s
2024-11-15 08:14:53.828861: Yayy! New best EMA pseudo Dice: 0.6404
2024-11-15 08:14:55.683488: 
2024-11-15 08:14:55.684722: Epoch 40
2024-11-15 08:14:55.685759: Current learning rate: 0.00694
2024-11-15 08:14:55.686927: encoder learning rate: 0.00694
2024-11-15 08:14:55.687824: decoder.stages learning rate: 0.00694
2024-11-15 08:14:55.688733: decoder.transpconvs learning rate: 0.00694
2024-11-15 08:14:55.689516: decoder.seg_layers learning rate: 0.00694
2024-11-15 08:17:01.247132: Validation loss improved from -0.42581 to -0.47681! Patience: 4/50
2024-11-15 08:17:01.248424: train_loss -0.5574
2024-11-15 08:17:01.249540: val_loss -0.4768
2024-11-15 08:17:01.250339: Pseudo dice [0.6972]
2024-11-15 08:17:01.251298: Epoch time: 125.57 s
2024-11-15 08:17:01.252167: Yayy! New best EMA pseudo Dice: 0.6461
2024-11-15 08:17:03.139473: 
2024-11-15 08:17:03.140880: Epoch 41
2024-11-15 08:17:03.141743: Current learning rate: 0.00686
2024-11-15 08:17:03.142783: encoder learning rate: 0.00686
2024-11-15 08:17:03.143589: decoder.stages learning rate: 0.00686
2024-11-15 08:17:03.144370: decoder.transpconvs learning rate: 0.00686
2024-11-15 08:17:03.145142: decoder.seg_layers learning rate: 0.00686
2024-11-15 08:18:58.873057: Validation loss did not improve from -0.47681. Patience: 1/50
2024-11-15 08:18:58.874385: train_loss -0.5725
2024-11-15 08:18:58.875408: val_loss -0.4336
2024-11-15 08:18:58.876335: Pseudo dice [0.6792]
2024-11-15 08:18:58.877063: Epoch time: 115.74 s
2024-11-15 08:18:58.877768: Yayy! New best EMA pseudo Dice: 0.6494
2024-11-15 08:19:01.199532: 
2024-11-15 08:19:01.200914: Epoch 42
2024-11-15 08:19:01.201885: Current learning rate: 0.00679
2024-11-15 08:19:01.202889: encoder learning rate: 0.00679
2024-11-15 08:19:01.203610: decoder.stages learning rate: 0.00679
2024-11-15 08:19:01.204340: decoder.transpconvs learning rate: 0.00679
2024-11-15 08:19:01.205036: decoder.seg_layers learning rate: 0.00679
2024-11-15 08:21:09.168428: Validation loss did not improve from -0.47681. Patience: 2/50
2024-11-15 08:21:09.169572: train_loss -0.5688
2024-11-15 08:21:09.170534: val_loss -0.4349
2024-11-15 08:21:09.171516: Pseudo dice [0.6739]
2024-11-15 08:21:09.172353: Epoch time: 127.97 s
2024-11-15 08:21:09.173085: Yayy! New best EMA pseudo Dice: 0.6519
2024-11-15 08:21:10.926753: 
2024-11-15 08:21:10.927908: Epoch 43
2024-11-15 08:21:10.928748: Current learning rate: 0.00671
2024-11-15 08:21:10.929809: encoder learning rate: 0.00671
2024-11-15 08:21:10.930687: decoder.stages learning rate: 0.00671
2024-11-15 08:21:10.931602: decoder.transpconvs learning rate: 0.00671
2024-11-15 08:21:10.932305: decoder.seg_layers learning rate: 0.00671
2024-11-15 08:23:20.288050: Validation loss did not improve from -0.47681. Patience: 3/50
2024-11-15 08:23:20.289221: train_loss -0.5704
2024-11-15 08:23:20.290291: val_loss -0.4613
2024-11-15 08:23:20.291160: Pseudo dice [0.6931]
2024-11-15 08:23:20.291978: Epoch time: 129.36 s
2024-11-15 08:23:20.292735: Yayy! New best EMA pseudo Dice: 0.656
2024-11-15 08:23:22.073883: 
2024-11-15 08:23:22.075197: Epoch 44
2024-11-15 08:23:22.076107: Current learning rate: 0.00663
2024-11-15 08:23:22.077157: encoder learning rate: 0.00663
2024-11-15 08:23:22.077857: decoder.stages learning rate: 0.00663
2024-11-15 08:23:22.078761: decoder.transpconvs learning rate: 0.00663
2024-11-15 08:23:22.079691: decoder.seg_layers learning rate: 0.00663
2024-11-15 08:25:31.316175: Validation loss did not improve from -0.47681. Patience: 4/50
2024-11-15 08:25:31.317316: train_loss -0.5931
2024-11-15 08:25:31.318173: val_loss -0.4683
2024-11-15 08:25:31.319074: Pseudo dice [0.6913]
2024-11-15 08:25:31.319831: Epoch time: 129.24 s
2024-11-15 08:25:31.760187: Yayy! New best EMA pseudo Dice: 0.6595
2024-11-15 08:25:33.529794: 
2024-11-15 08:25:33.531237: Epoch 45
2024-11-15 08:25:33.532132: Current learning rate: 0.00655
2024-11-15 08:25:33.533174: encoder learning rate: 0.00655
2024-11-15 08:25:33.534005: decoder.stages learning rate: 0.00655
2024-11-15 08:25:33.534690: decoder.transpconvs learning rate: 0.00655
2024-11-15 08:25:33.535498: decoder.seg_layers learning rate: 0.00655
2024-11-15 08:27:41.501323: Validation loss did not improve from -0.47681. Patience: 5/50
2024-11-15 08:27:41.502601: train_loss -0.5845
2024-11-15 08:27:41.503727: val_loss -0.4668
2024-11-15 08:27:41.504695: Pseudo dice [0.6981]
2024-11-15 08:27:41.505604: Epoch time: 127.98 s
2024-11-15 08:27:41.506480: Yayy! New best EMA pseudo Dice: 0.6634
2024-11-15 08:27:43.264896: 
2024-11-15 08:27:43.266955: Epoch 46
2024-11-15 08:27:43.267947: Current learning rate: 0.00647
2024-11-15 08:27:43.270863: encoder learning rate: 0.00647
2024-11-15 08:27:43.272438: decoder.stages learning rate: 0.00647
2024-11-15 08:27:43.273352: decoder.transpconvs learning rate: 0.00647
2024-11-15 08:27:43.274104: decoder.seg_layers learning rate: 0.00647
2024-11-15 08:29:43.772885: Validation loss did not improve from -0.47681. Patience: 6/50
2024-11-15 08:29:43.774185: train_loss -0.585
2024-11-15 08:29:43.775389: val_loss -0.4561
2024-11-15 08:29:43.776448: Pseudo dice [0.6998]
2024-11-15 08:29:43.777599: Epoch time: 120.51 s
2024-11-15 08:29:43.778465: Yayy! New best EMA pseudo Dice: 0.667
2024-11-15 08:29:45.538194: 
2024-11-15 08:29:45.539919: Epoch 47
2024-11-15 08:29:45.541035: Current learning rate: 0.00639
2024-11-15 08:29:45.542281: encoder learning rate: 0.00639
2024-11-15 08:29:45.543364: decoder.stages learning rate: 0.00639
2024-11-15 08:29:45.544383: decoder.transpconvs learning rate: 0.00639
2024-11-15 08:29:45.545450: decoder.seg_layers learning rate: 0.00639
2024-11-15 08:31:48.283544: Validation loss improved from -0.47681 to -0.47723! Patience: 6/50
2024-11-15 08:31:48.284803: train_loss -0.5914
2024-11-15 08:31:48.285670: val_loss -0.4772
2024-11-15 08:31:48.286525: Pseudo dice [0.7046]
2024-11-15 08:31:48.287450: Epoch time: 122.75 s
2024-11-15 08:31:48.288239: Yayy! New best EMA pseudo Dice: 0.6708
2024-11-15 08:31:50.049130: 
2024-11-15 08:31:50.050563: Epoch 48
2024-11-15 08:31:50.051791: Current learning rate: 0.00631
2024-11-15 08:31:50.052830: encoder learning rate: 0.00631
2024-11-15 08:31:50.053779: decoder.stages learning rate: 0.00631
2024-11-15 08:31:50.054800: decoder.transpconvs learning rate: 0.00631
2024-11-15 08:31:50.055715: decoder.seg_layers learning rate: 0.00631
2024-11-15 08:33:59.047335: Validation loss improved from -0.47723 to -0.49025! Patience: 0/50
2024-11-15 08:33:59.048501: train_loss -0.5881
2024-11-15 08:33:59.049443: val_loss -0.4902
2024-11-15 08:33:59.050481: Pseudo dice [0.7153]
2024-11-15 08:33:59.051392: Epoch time: 129.0 s
2024-11-15 08:33:59.052289: Yayy! New best EMA pseudo Dice: 0.6752
2024-11-15 08:34:00.809559: 
2024-11-15 08:34:00.811077: Epoch 49
2024-11-15 08:34:00.812268: Current learning rate: 0.00624
2024-11-15 08:34:00.813310: encoder learning rate: 0.00624
2024-11-15 08:34:00.814289: decoder.stages learning rate: 0.00624
2024-11-15 08:34:00.815171: decoder.transpconvs learning rate: 0.00624
2024-11-15 08:34:00.816103: decoder.seg_layers learning rate: 0.00624
2024-11-15 08:35:59.475257: Validation loss did not improve from -0.49025. Patience: 1/50
2024-11-15 08:35:59.476598: train_loss -0.6045
2024-11-15 08:35:59.477719: val_loss -0.462
2024-11-15 08:35:59.478543: Pseudo dice [0.6992]
2024-11-15 08:35:59.479326: Epoch time: 118.67 s
2024-11-15 08:35:59.885910: Yayy! New best EMA pseudo Dice: 0.6776
2024-11-15 08:36:01.643841: 
2024-11-15 08:36:01.645122: Epoch 50
2024-11-15 08:36:01.645906: Current learning rate: 0.00616
2024-11-15 08:36:01.646913: encoder learning rate: 0.00616
2024-11-15 08:36:01.647736: decoder.stages learning rate: 0.00616
2024-11-15 08:36:01.648508: decoder.transpconvs learning rate: 0.00616
2024-11-15 08:36:01.649363: decoder.seg_layers learning rate: 0.00616
2024-11-15 08:38:06.794164: Validation loss did not improve from -0.49025. Patience: 2/50
2024-11-15 08:38:06.795306: train_loss -0.6033
2024-11-15 08:38:06.796237: val_loss -0.4766
2024-11-15 08:38:06.797154: Pseudo dice [0.7036]
2024-11-15 08:38:06.798170: Epoch time: 125.15 s
2024-11-15 08:38:06.799081: Yayy! New best EMA pseudo Dice: 0.6802
2024-11-15 08:38:08.628268: 
2024-11-15 08:38:08.629795: Epoch 51
2024-11-15 08:38:08.630783: Current learning rate: 0.00608
2024-11-15 08:38:08.631796: encoder learning rate: 0.00608
2024-11-15 08:38:08.632876: decoder.stages learning rate: 0.00608
2024-11-15 08:38:08.633857: decoder.transpconvs learning rate: 0.00608
2024-11-15 08:38:08.634923: decoder.seg_layers learning rate: 0.00608
2024-11-15 08:40:19.859807: Validation loss did not improve from -0.49025. Patience: 3/50
2024-11-15 08:40:19.861012: train_loss -0.6124
2024-11-15 08:40:19.862254: val_loss -0.4835
2024-11-15 08:40:19.863167: Pseudo dice [0.7079]
2024-11-15 08:40:19.864101: Epoch time: 131.23 s
2024-11-15 08:40:19.865033: Yayy! New best EMA pseudo Dice: 0.683
2024-11-15 08:40:21.685089: 
2024-11-15 08:40:21.686585: Epoch 52
2024-11-15 08:40:21.687570: Current learning rate: 0.006
2024-11-15 08:40:21.688644: encoder learning rate: 0.006
2024-11-15 08:40:21.689561: decoder.stages learning rate: 0.006
2024-11-15 08:40:21.690415: decoder.transpconvs learning rate: 0.006
2024-11-15 08:40:21.691233: decoder.seg_layers learning rate: 0.006
2024-11-15 08:42:37.959482: Validation loss did not improve from -0.49025. Patience: 4/50
2024-11-15 08:42:37.960703: train_loss -0.6182
2024-11-15 08:42:37.961646: val_loss -0.4513
2024-11-15 08:42:37.962865: Pseudo dice [0.6832]
2024-11-15 08:42:37.963957: Epoch time: 136.28 s
2024-11-15 08:42:37.964991: Yayy! New best EMA pseudo Dice: 0.683
2024-11-15 08:42:40.260174: 
2024-11-15 08:42:40.261667: Epoch 53
2024-11-15 08:42:40.262666: Current learning rate: 0.00592
2024-11-15 08:42:40.263730: encoder learning rate: 0.00592
2024-11-15 08:42:40.264654: decoder.stages learning rate: 0.00592
2024-11-15 08:42:40.265489: decoder.transpconvs learning rate: 0.00592
2024-11-15 08:42:40.266257: decoder.seg_layers learning rate: 0.00592
2024-11-15 08:44:44.290144: Validation loss did not improve from -0.49025. Patience: 5/50
2024-11-15 08:44:44.291329: train_loss -0.6247
2024-11-15 08:44:44.292285: val_loss -0.4684
2024-11-15 08:44:44.293131: Pseudo dice [0.6954]
2024-11-15 08:44:44.293979: Epoch time: 124.03 s
2024-11-15 08:44:44.294773: Yayy! New best EMA pseudo Dice: 0.6842
2024-11-15 08:44:46.075958: 
2024-11-15 08:44:46.077538: Epoch 54
2024-11-15 08:44:46.078449: Current learning rate: 0.00584
2024-11-15 08:44:46.079507: encoder learning rate: 0.00584
2024-11-15 08:44:46.080381: decoder.stages learning rate: 0.00584
2024-11-15 08:44:46.081097: decoder.transpconvs learning rate: 0.00584
2024-11-15 08:44:46.081931: decoder.seg_layers learning rate: 0.00584
2024-11-15 08:46:45.782728: Validation loss did not improve from -0.49025. Patience: 6/50
2024-11-15 08:46:45.783905: train_loss -0.6197
2024-11-15 08:46:45.784767: val_loss -0.4194
2024-11-15 08:46:45.785589: Pseudo dice [0.6754]
2024-11-15 08:46:45.786299: Epoch time: 119.71 s
2024-11-15 08:46:47.581057: 
2024-11-15 08:46:47.582632: Epoch 55
2024-11-15 08:46:47.583516: Current learning rate: 0.00576
2024-11-15 08:46:47.584321: encoder learning rate: 0.00576
2024-11-15 08:46:47.585144: decoder.stages learning rate: 0.00576
2024-11-15 08:46:47.585818: decoder.transpconvs learning rate: 0.00576
2024-11-15 08:46:47.586579: decoder.seg_layers learning rate: 0.00576
2024-11-15 08:48:56.037927: Validation loss improved from -0.49025 to -0.49429! Patience: 6/50
2024-11-15 08:48:56.039127: train_loss -0.6326
2024-11-15 08:48:56.040083: val_loss -0.4943
2024-11-15 08:48:56.041061: Pseudo dice [0.7128]
2024-11-15 08:48:56.042094: Epoch time: 128.46 s
2024-11-15 08:48:56.042959: Yayy! New best EMA pseudo Dice: 0.6863
2024-11-15 08:48:57.801221: 
2024-11-15 08:48:57.802551: Epoch 56
2024-11-15 08:48:57.803778: Current learning rate: 0.00568
2024-11-15 08:48:57.804929: encoder learning rate: 0.00568
2024-11-15 08:48:57.805931: decoder.stages learning rate: 0.00568
2024-11-15 08:48:57.806661: decoder.transpconvs learning rate: 0.00568
2024-11-15 08:48:57.807467: decoder.seg_layers learning rate: 0.00568
2024-11-15 08:51:05.767901: Validation loss did not improve from -0.49429. Patience: 1/50
2024-11-15 08:51:05.769068: train_loss -0.6333
2024-11-15 08:51:05.770186: val_loss -0.4916
2024-11-15 08:51:05.771311: Pseudo dice [0.7066]
2024-11-15 08:51:05.772412: Epoch time: 127.97 s
2024-11-15 08:51:05.773416: Yayy! New best EMA pseudo Dice: 0.6883
2024-11-15 08:51:07.584998: 
2024-11-15 08:51:07.586553: Epoch 57
2024-11-15 08:51:07.587667: Current learning rate: 0.0056
2024-11-15 08:51:07.588882: encoder learning rate: 0.0056
2024-11-15 08:51:07.589784: decoder.stages learning rate: 0.0056
2024-11-15 08:51:07.590754: decoder.transpconvs learning rate: 0.0056
2024-11-15 08:51:07.591717: decoder.seg_layers learning rate: 0.0056
2024-11-15 08:53:06.842073: Validation loss did not improve from -0.49429. Patience: 2/50
2024-11-15 08:53:06.843315: train_loss -0.6378
2024-11-15 08:53:06.844454: val_loss -0.4775
2024-11-15 08:53:06.845387: Pseudo dice [0.6966]
2024-11-15 08:53:06.846269: Epoch time: 119.26 s
2024-11-15 08:53:06.847199: Yayy! New best EMA pseudo Dice: 0.6892
2024-11-15 08:53:08.638944: 
2024-11-15 08:53:08.640464: Epoch 58
2024-11-15 08:53:08.641594: Current learning rate: 0.00552
2024-11-15 08:53:08.642707: encoder learning rate: 0.00552
2024-11-15 08:53:08.643695: decoder.stages learning rate: 0.00552
2024-11-15 08:53:08.644737: decoder.transpconvs learning rate: 0.00552
2024-11-15 08:53:08.645664: decoder.seg_layers learning rate: 0.00552
2024-11-15 08:55:16.741593: Validation loss did not improve from -0.49429. Patience: 3/50
2024-11-15 08:55:16.742886: train_loss -0.6321
2024-11-15 08:55:16.743839: val_loss -0.4646
2024-11-15 08:55:16.744732: Pseudo dice [0.704]
2024-11-15 08:55:16.745607: Epoch time: 128.11 s
2024-11-15 08:55:16.746475: Yayy! New best EMA pseudo Dice: 0.6907
2024-11-15 08:55:18.522342: 
2024-11-15 08:55:18.524078: Epoch 59
2024-11-15 08:55:18.525197: Current learning rate: 0.00544
2024-11-15 08:55:18.526356: encoder learning rate: 0.00544
2024-11-15 08:55:18.527332: decoder.stages learning rate: 0.00544
2024-11-15 08:55:18.528300: decoder.transpconvs learning rate: 0.00544
2024-11-15 08:55:18.529162: decoder.seg_layers learning rate: 0.00544
2024-11-15 08:57:30.282239: Validation loss did not improve from -0.49429. Patience: 4/50
2024-11-15 08:57:30.283506: train_loss -0.6367
2024-11-15 08:57:30.284678: val_loss -0.4557
2024-11-15 08:57:30.285882: Pseudo dice [0.6952]
2024-11-15 08:57:30.287230: Epoch time: 131.76 s
2024-11-15 08:57:30.707561: Yayy! New best EMA pseudo Dice: 0.6911
2024-11-15 08:57:32.491064: 
2024-11-15 08:57:32.492611: Epoch 60
2024-11-15 08:57:32.495216: Current learning rate: 0.00536
2024-11-15 08:57:32.497086: encoder learning rate: 0.00536
2024-11-15 08:57:32.498360: decoder.stages learning rate: 0.00536
2024-11-15 08:57:32.499439: decoder.transpconvs learning rate: 0.00536
2024-11-15 08:57:32.500546: decoder.seg_layers learning rate: 0.00536
2024-11-15 08:59:43.648952: Validation loss improved from -0.49429 to -0.49714! Patience: 4/50
2024-11-15 08:59:43.650202: train_loss -0.6472
2024-11-15 08:59:43.651291: val_loss -0.4971
2024-11-15 08:59:43.652374: Pseudo dice [0.722]
2024-11-15 08:59:43.653492: Epoch time: 131.16 s
2024-11-15 08:59:43.654452: Yayy! New best EMA pseudo Dice: 0.6942
2024-11-15 08:59:45.451210: 
2024-11-15 08:59:45.452695: Epoch 61
2024-11-15 08:59:45.453630: Current learning rate: 0.00528
2024-11-15 08:59:45.454721: encoder learning rate: 0.00528
2024-11-15 08:59:45.455753: decoder.stages learning rate: 0.00528
2024-11-15 08:59:45.456660: decoder.transpconvs learning rate: 0.00528
2024-11-15 08:59:45.457551: decoder.seg_layers learning rate: 0.00528
2024-11-15 09:01:55.784414: Validation loss improved from -0.49714 to -0.50083! Patience: 0/50
2024-11-15 09:01:55.786305: train_loss -0.6479
2024-11-15 09:01:55.787694: val_loss -0.5008
2024-11-15 09:01:55.788548: Pseudo dice [0.7166]
2024-11-15 09:01:55.789363: Epoch time: 130.34 s
2024-11-15 09:01:55.790040: Yayy! New best EMA pseudo Dice: 0.6964
2024-11-15 09:01:58.158183: 
2024-11-15 09:01:58.159661: Epoch 62
2024-11-15 09:01:58.160660: Current learning rate: 0.0052
2024-11-15 09:01:58.161570: encoder learning rate: 0.0052
2024-11-15 09:01:58.162413: decoder.stages learning rate: 0.0052
2024-11-15 09:01:58.163177: decoder.transpconvs learning rate: 0.0052
2024-11-15 09:01:58.163942: decoder.seg_layers learning rate: 0.0052
2024-11-15 09:03:59.188218: Validation loss did not improve from -0.50083. Patience: 1/50
2024-11-15 09:03:59.190076: train_loss -0.6431
2024-11-15 09:03:59.191488: val_loss -0.4858
2024-11-15 09:03:59.192546: Pseudo dice [0.7113]
2024-11-15 09:03:59.193603: Epoch time: 121.03 s
2024-11-15 09:03:59.194486: Yayy! New best EMA pseudo Dice: 0.6979
2024-11-15 09:04:01.104647: 
2024-11-15 09:04:01.106037: Epoch 63
2024-11-15 09:04:01.106999: Current learning rate: 0.00512
2024-11-15 09:04:01.107976: encoder learning rate: 0.00512
2024-11-15 09:04:01.108826: decoder.stages learning rate: 0.00512
2024-11-15 09:04:01.109697: decoder.transpconvs learning rate: 0.00512
2024-11-15 09:04:01.110530: decoder.seg_layers learning rate: 0.00512
2024-11-15 09:06:12.676255: Validation loss did not improve from -0.50083. Patience: 2/50
2024-11-15 09:06:12.680364: train_loss -0.6497
2024-11-15 09:06:12.681655: val_loss -0.4567
2024-11-15 09:06:12.682468: Pseudo dice [0.6928]
2024-11-15 09:06:12.683352: Epoch time: 131.57 s
2024-11-15 09:06:14.145076: 
2024-11-15 09:06:14.146703: Epoch 64
2024-11-15 09:06:14.147626: Current learning rate: 0.00504
2024-11-15 09:06:14.148497: encoder learning rate: 0.00504
2024-11-15 09:06:14.149258: decoder.stages learning rate: 0.00504
2024-11-15 09:06:14.150011: decoder.transpconvs learning rate: 0.00504
2024-11-15 09:06:14.150780: decoder.seg_layers learning rate: 0.00504
2024-11-15 09:08:19.294744: Validation loss did not improve from -0.50083. Patience: 3/50
2024-11-15 09:08:19.296310: train_loss -0.6561
2024-11-15 09:08:19.297646: val_loss -0.4712
2024-11-15 09:08:19.298738: Pseudo dice [0.6991]
2024-11-15 09:08:19.299646: Epoch time: 125.15 s
2024-11-15 09:08:23.825908: 
2024-11-15 09:08:23.828269: Epoch 65
2024-11-15 09:08:23.829597: Current learning rate: 0.00496
2024-11-15 09:08:23.830703: encoder learning rate: 0.00496
2024-11-15 09:08:23.831491: decoder.stages learning rate: 0.00496
2024-11-15 09:08:23.832254: decoder.transpconvs learning rate: 0.00496
2024-11-15 09:08:23.833234: decoder.seg_layers learning rate: 0.00496
2024-11-15 09:10:17.805637: Validation loss did not improve from -0.50083. Patience: 4/50
2024-11-15 09:10:17.807027: train_loss -0.647
2024-11-15 09:10:17.808004: val_loss -0.4973
2024-11-15 09:10:17.808834: Pseudo dice [0.7214]
2024-11-15 09:10:17.809627: Epoch time: 113.98 s
2024-11-15 09:10:17.810314: Yayy! New best EMA pseudo Dice: 0.6999
2024-11-15 09:10:19.697946: 
2024-11-15 09:10:19.699526: Epoch 66
2024-11-15 09:10:19.700540: Current learning rate: 0.00487
2024-11-15 09:10:19.701568: encoder learning rate: 0.00487
2024-11-15 09:10:19.702434: decoder.stages learning rate: 0.00487
2024-11-15 09:10:19.703242: decoder.transpconvs learning rate: 0.00487
2024-11-15 09:10:19.703986: decoder.seg_layers learning rate: 0.00487
2024-11-15 09:12:28.689744: Validation loss improved from -0.50083 to -0.50611! Patience: 4/50
2024-11-15 09:12:28.690872: train_loss -0.6645
2024-11-15 09:12:28.691781: val_loss -0.5061
2024-11-15 09:12:28.692579: Pseudo dice [0.7178]
2024-11-15 09:12:28.693485: Epoch time: 128.99 s
2024-11-15 09:12:28.694318: Yayy! New best EMA pseudo Dice: 0.7017
2024-11-15 09:12:30.569642: 
2024-11-15 09:12:30.571177: Epoch 67
2024-11-15 09:12:30.571974: Current learning rate: 0.00479
2024-11-15 09:12:30.572867: encoder learning rate: 0.00479
2024-11-15 09:12:30.573694: decoder.stages learning rate: 0.00479
2024-11-15 09:12:30.574593: decoder.transpconvs learning rate: 0.00479
2024-11-15 09:12:30.575511: decoder.seg_layers learning rate: 0.00479
2024-11-15 09:14:41.742952: Validation loss did not improve from -0.50611. Patience: 1/50
2024-11-15 09:14:41.744224: train_loss -0.6632
2024-11-15 09:14:41.745185: val_loss -0.4999
2024-11-15 09:14:41.746125: Pseudo dice [0.7181]
2024-11-15 09:14:41.747044: Epoch time: 131.18 s
2024-11-15 09:14:41.748020: Yayy! New best EMA pseudo Dice: 0.7034
2024-11-15 09:14:43.610822: 
2024-11-15 09:14:43.612324: Epoch 68
2024-11-15 09:14:43.613363: Current learning rate: 0.00471
2024-11-15 09:14:43.614430: encoder learning rate: 0.00471
2024-11-15 09:14:43.615338: decoder.stages learning rate: 0.00471
2024-11-15 09:14:43.616364: decoder.transpconvs learning rate: 0.00471
2024-11-15 09:14:43.617374: decoder.seg_layers learning rate: 0.00471
2024-11-15 09:17:00.011969: Validation loss did not improve from -0.50611. Patience: 2/50
2024-11-15 09:17:00.013084: train_loss -0.6662
2024-11-15 09:17:00.014143: val_loss -0.4683
2024-11-15 09:17:00.014993: Pseudo dice [0.7008]
2024-11-15 09:17:00.015877: Epoch time: 136.4 s
2024-11-15 09:17:01.495713: 
2024-11-15 09:17:01.497143: Epoch 69
2024-11-15 09:17:01.498236: Current learning rate: 0.00463
2024-11-15 09:17:01.499273: encoder learning rate: 0.00463
2024-11-15 09:17:01.500044: decoder.stages learning rate: 0.00463
2024-11-15 09:17:01.500847: decoder.transpconvs learning rate: 0.00463
2024-11-15 09:17:01.501544: decoder.seg_layers learning rate: 0.00463
2024-11-15 09:19:10.984671: Validation loss improved from -0.50611 to -0.52439! Patience: 2/50
2024-11-15 09:19:10.985950: train_loss -0.6665
2024-11-15 09:19:10.986903: val_loss -0.5244
2024-11-15 09:19:10.987765: Pseudo dice [0.7293]
2024-11-15 09:19:10.988560: Epoch time: 129.49 s
2024-11-15 09:19:11.416900: Yayy! New best EMA pseudo Dice: 0.7057
2024-11-15 09:19:13.321718: 
2024-11-15 09:19:13.323293: Epoch 70
2024-11-15 09:19:13.324242: Current learning rate: 0.00455
2024-11-15 09:19:13.325191: encoder learning rate: 0.00455
2024-11-15 09:19:13.326110: decoder.stages learning rate: 0.00455
2024-11-15 09:19:13.326986: decoder.transpconvs learning rate: 0.00455
2024-11-15 09:19:13.327894: decoder.seg_layers learning rate: 0.00455
2024-11-15 09:21:08.874497: Validation loss did not improve from -0.52439. Patience: 1/50
2024-11-15 09:21:08.875916: train_loss -0.6701
2024-11-15 09:21:08.877151: val_loss -0.4986
2024-11-15 09:21:08.878278: Pseudo dice [0.7148]
2024-11-15 09:21:08.879293: Epoch time: 115.56 s
2024-11-15 09:21:08.880343: Yayy! New best EMA pseudo Dice: 0.7066
2024-11-15 09:21:10.704305: 
2024-11-15 09:21:10.705942: Epoch 71
2024-11-15 09:21:10.707100: Current learning rate: 0.00447
2024-11-15 09:21:10.708160: encoder learning rate: 0.00447
2024-11-15 09:21:10.709104: decoder.stages learning rate: 0.00447
2024-11-15 09:21:10.709913: decoder.transpconvs learning rate: 0.00447
2024-11-15 09:21:10.710937: decoder.seg_layers learning rate: 0.00447
2024-11-15 09:23:19.124808: Validation loss did not improve from -0.52439. Patience: 2/50
2024-11-15 09:23:19.126593: train_loss -0.6722
2024-11-15 09:23:19.127924: val_loss -0.5065
2024-11-15 09:23:19.129004: Pseudo dice [0.7179]
2024-11-15 09:23:19.130031: Epoch time: 128.42 s
2024-11-15 09:23:19.131170: Yayy! New best EMA pseudo Dice: 0.7078
2024-11-15 09:23:21.111897: 
2024-11-15 09:23:21.113659: Epoch 72
2024-11-15 09:23:21.114786: Current learning rate: 0.00438
2024-11-15 09:23:21.115817: encoder learning rate: 0.00438
2024-11-15 09:23:21.116850: decoder.stages learning rate: 0.00438
2024-11-15 09:23:21.117708: decoder.transpconvs learning rate: 0.00438
2024-11-15 09:23:21.118697: decoder.seg_layers learning rate: 0.00438
2024-11-15 09:25:31.901911: Validation loss did not improve from -0.52439. Patience: 3/50
2024-11-15 09:25:31.903438: train_loss -0.6742
2024-11-15 09:25:31.904548: val_loss -0.4927
2024-11-15 09:25:31.905491: Pseudo dice [0.7151]
2024-11-15 09:25:31.906406: Epoch time: 130.79 s
2024-11-15 09:25:31.907129: Yayy! New best EMA pseudo Dice: 0.7085
2024-11-15 09:25:33.780169: 
2024-11-15 09:25:33.781603: Epoch 73
2024-11-15 09:25:33.782643: Current learning rate: 0.0043
2024-11-15 09:25:33.783578: encoder learning rate: 0.0043
2024-11-15 09:25:33.784342: decoder.stages learning rate: 0.0043
2024-11-15 09:25:33.785111: decoder.transpconvs learning rate: 0.0043
2024-11-15 09:25:33.785995: decoder.seg_layers learning rate: 0.0043
2024-11-15 09:27:44.716557: Validation loss did not improve from -0.52439. Patience: 4/50
2024-11-15 09:27:44.717909: train_loss -0.6771
2024-11-15 09:27:44.719260: val_loss -0.5104
2024-11-15 09:27:44.720373: Pseudo dice [0.7211]
2024-11-15 09:27:44.721323: Epoch time: 130.94 s
2024-11-15 09:27:44.722094: Yayy! New best EMA pseudo Dice: 0.7098
2024-11-15 09:27:46.661132: 
2024-11-15 09:27:46.663321: Epoch 74
2024-11-15 09:27:46.664606: Current learning rate: 0.00422
2024-11-15 09:27:46.666849: encoder learning rate: 0.00422
2024-11-15 09:27:46.668391: decoder.stages learning rate: 0.00422
2024-11-15 09:27:46.669261: decoder.transpconvs learning rate: 0.00422
2024-11-15 09:27:46.670040: decoder.seg_layers learning rate: 0.00422
2024-11-15 09:29:57.086685: Validation loss did not improve from -0.52439. Patience: 5/50
2024-11-15 09:29:57.088054: train_loss -0.6732
2024-11-15 09:29:57.089010: val_loss -0.4984
2024-11-15 09:29:57.089960: Pseudo dice [0.7131]
2024-11-15 09:29:57.091012: Epoch time: 130.43 s
2024-11-15 09:29:57.527214: Yayy! New best EMA pseudo Dice: 0.7101
2024-11-15 09:29:59.414776: 
2024-11-15 09:29:59.416439: Epoch 75
2024-11-15 09:29:59.417486: Current learning rate: 0.00414
2024-11-15 09:29:59.418598: encoder learning rate: 0.00414
2024-11-15 09:29:59.419491: decoder.stages learning rate: 0.00414
2024-11-15 09:29:59.420350: decoder.transpconvs learning rate: 0.00414
2024-11-15 09:29:59.421090: decoder.seg_layers learning rate: 0.00414
2024-11-15 09:32:01.377830: Validation loss did not improve from -0.52439. Patience: 6/50
2024-11-15 09:32:01.378880: train_loss -0.6742
2024-11-15 09:32:01.379948: val_loss -0.5068
2024-11-15 09:32:01.380932: Pseudo dice [0.7191]
2024-11-15 09:32:01.381861: Epoch time: 121.97 s
2024-11-15 09:32:01.382644: Yayy! New best EMA pseudo Dice: 0.711
2024-11-15 09:32:03.687472: 
2024-11-15 09:32:03.689129: Epoch 76
2024-11-15 09:32:03.690096: Current learning rate: 0.00405
2024-11-15 09:32:03.691098: encoder learning rate: 0.00405
2024-11-15 09:32:03.691822: decoder.stages learning rate: 0.00405
2024-11-15 09:32:03.692542: decoder.transpconvs learning rate: 0.00405
2024-11-15 09:32:03.693320: decoder.seg_layers learning rate: 0.00405
2024-11-15 09:34:12.976607: Validation loss did not improve from -0.52439. Patience: 7/50
2024-11-15 09:34:12.977817: train_loss -0.6775
2024-11-15 09:34:12.979176: val_loss -0.5074
2024-11-15 09:34:12.980459: Pseudo dice [0.7235]
2024-11-15 09:34:12.981703: Epoch time: 129.29 s
2024-11-15 09:34:12.982859: Yayy! New best EMA pseudo Dice: 0.7122
2024-11-15 09:34:14.838693: 
2024-11-15 09:34:14.840055: Epoch 77
2024-11-15 09:34:14.841176: Current learning rate: 0.00397
2024-11-15 09:34:14.842292: encoder learning rate: 0.00397
2024-11-15 09:34:14.843417: decoder.stages learning rate: 0.00397
2024-11-15 09:34:14.844426: decoder.transpconvs learning rate: 0.00397
2024-11-15 09:34:14.845340: decoder.seg_layers learning rate: 0.00397
2024-11-15 09:36:23.488740: Validation loss did not improve from -0.52439. Patience: 8/50
2024-11-15 09:36:23.490085: train_loss -0.6855
2024-11-15 09:36:23.491535: val_loss -0.4618
2024-11-15 09:36:23.492785: Pseudo dice [0.6953]
2024-11-15 09:36:23.493949: Epoch time: 128.65 s
2024-11-15 09:36:24.981365: 
2024-11-15 09:36:24.982729: Epoch 78
2024-11-15 09:36:24.983772: Current learning rate: 0.00389
2024-11-15 09:36:24.985036: encoder learning rate: 0.00389
2024-11-15 09:36:24.986172: decoder.stages learning rate: 0.00389
2024-11-15 09:36:24.987206: decoder.transpconvs learning rate: 0.00389
2024-11-15 09:36:24.988315: decoder.seg_layers learning rate: 0.00389
2024-11-15 09:38:26.871989: Validation loss improved from -0.52439 to -0.52472! Patience: 8/50
2024-11-15 09:38:26.873366: train_loss -0.6888
2024-11-15 09:38:26.895440: val_loss -0.5247
2024-11-15 09:38:26.896889: Pseudo dice [0.7318]
2024-11-15 09:38:26.898063: Epoch time: 121.89 s
2024-11-15 09:38:26.899030: Yayy! New best EMA pseudo Dice: 0.7127
2024-11-15 09:38:28.797692: 
2024-11-15 09:38:28.799094: Epoch 79
2024-11-15 09:38:28.800028: Current learning rate: 0.0038
2024-11-15 09:38:28.800937: encoder learning rate: 0.0038
2024-11-15 09:38:28.819152: decoder.stages learning rate: 0.0038
2024-11-15 09:38:28.820214: decoder.transpconvs learning rate: 0.0038
2024-11-15 09:38:28.821086: decoder.seg_layers learning rate: 0.0038
2024-11-15 09:40:38.904778: Validation loss improved from -0.52472 to -0.52497! Patience: 0/50
2024-11-15 09:40:38.906041: train_loss -0.6889
2024-11-15 09:40:38.907097: val_loss -0.525
2024-11-15 09:40:38.908130: Pseudo dice [0.7218]
2024-11-15 09:40:38.909081: Epoch time: 130.11 s
2024-11-15 09:40:39.368890: Yayy! New best EMA pseudo Dice: 0.7136
2024-11-15 09:40:41.233894: 
2024-11-15 09:40:41.235316: Epoch 80
2024-11-15 09:40:41.236483: Current learning rate: 0.00372
2024-11-15 09:40:41.237534: encoder learning rate: 0.00372
2024-11-15 09:40:41.238369: decoder.stages learning rate: 0.00372
2024-11-15 09:40:41.239277: decoder.transpconvs learning rate: 0.00372
2024-11-15 09:40:41.240133: decoder.seg_layers learning rate: 0.00372
2024-11-15 09:42:54.674758: Validation loss did not improve from -0.52497. Patience: 1/50
2024-11-15 09:42:54.676056: train_loss -0.6849
2024-11-15 09:42:54.677255: val_loss -0.5086
2024-11-15 09:42:54.678584: Pseudo dice [0.7217]
2024-11-15 09:42:54.679942: Epoch time: 133.44 s
2024-11-15 09:42:54.681388: Yayy! New best EMA pseudo Dice: 0.7144
2024-11-15 09:42:56.562489: 
2024-11-15 09:42:56.564185: Epoch 81
2024-11-15 09:42:56.565563: Current learning rate: 0.00364
2024-11-15 09:42:56.566972: encoder learning rate: 0.00364
2024-11-15 09:42:56.567977: decoder.stages learning rate: 0.00364
2024-11-15 09:42:56.569290: decoder.transpconvs learning rate: 0.00364
2024-11-15 09:42:56.570540: decoder.seg_layers learning rate: 0.00364
2024-11-15 09:45:14.044312: Validation loss did not improve from -0.52497. Patience: 2/50
2024-11-15 09:45:14.045752: train_loss -0.6967
2024-11-15 09:45:14.047163: val_loss -0.4957
2024-11-15 09:45:14.048272: Pseudo dice [0.7251]
2024-11-15 09:45:14.049242: Epoch time: 137.49 s
2024-11-15 09:45:14.050045: Yayy! New best EMA pseudo Dice: 0.7155
2024-11-15 09:45:16.075213: 
2024-11-15 09:45:16.076495: Epoch 82
2024-11-15 09:45:16.077543: Current learning rate: 0.00355
2024-11-15 09:45:16.078643: encoder learning rate: 0.00355
2024-11-15 09:45:16.079595: decoder.stages learning rate: 0.00355
2024-11-15 09:45:16.080437: decoder.transpconvs learning rate: 0.00355
2024-11-15 09:45:16.081335: decoder.seg_layers learning rate: 0.00355
2024-11-15 09:47:22.628752: Validation loss did not improve from -0.52497. Patience: 3/50
2024-11-15 09:47:22.630248: train_loss -0.6957
2024-11-15 09:47:22.631271: val_loss -0.5209
2024-11-15 09:47:22.632225: Pseudo dice [0.7336]
2024-11-15 09:47:22.633188: Epoch time: 126.56 s
2024-11-15 09:47:22.633937: Yayy! New best EMA pseudo Dice: 0.7173
2024-11-15 09:47:24.443432: 
2024-11-15 09:47:24.446695: Epoch 83
2024-11-15 09:47:24.447905: Current learning rate: 0.00347
2024-11-15 09:47:24.449172: encoder learning rate: 0.00347
2024-11-15 09:47:24.450418: decoder.stages learning rate: 0.00347
2024-11-15 09:47:24.451332: decoder.transpconvs learning rate: 0.00347
2024-11-15 09:47:24.452217: decoder.seg_layers learning rate: 0.00347
2024-11-15 09:49:25.168482: Validation loss did not improve from -0.52497. Patience: 4/50
2024-11-15 09:49:25.169877: train_loss -0.6999
2024-11-15 09:49:25.171085: val_loss -0.508
2024-11-15 09:49:25.172130: Pseudo dice [0.7239]
2024-11-15 09:49:25.173276: Epoch time: 120.73 s
2024-11-15 09:49:25.174269: Yayy! New best EMA pseudo Dice: 0.7179
2024-11-15 09:49:26.994751: 
2024-11-15 09:49:26.997495: Epoch 84
2024-11-15 09:49:26.998794: Current learning rate: 0.00338
2024-11-15 09:49:27.000005: encoder learning rate: 0.00338
2024-11-15 09:49:27.000946: decoder.stages learning rate: 0.00338
2024-11-15 09:49:27.001886: decoder.transpconvs learning rate: 0.00338
2024-11-15 09:49:27.002858: decoder.seg_layers learning rate: 0.00338
2024-11-15 09:51:38.155983: Validation loss did not improve from -0.52497. Patience: 5/50
2024-11-15 09:51:38.157955: train_loss -0.6959
2024-11-15 09:51:38.159444: val_loss -0.4886
2024-11-15 09:51:38.160364: Pseudo dice [0.7128]
2024-11-15 09:51:38.161337: Epoch time: 131.16 s
2024-11-15 09:51:40.026572: 
2024-11-15 09:51:40.028688: Epoch 85
2024-11-15 09:51:40.029676: Current learning rate: 0.0033
2024-11-15 09:51:40.030702: encoder learning rate: 0.0033
2024-11-15 09:51:40.031554: decoder.stages learning rate: 0.0033
2024-11-15 09:51:40.032245: decoder.transpconvs learning rate: 0.0033
2024-11-15 09:51:40.032898: decoder.seg_layers learning rate: 0.0033
2024-11-15 09:53:52.075207: Validation loss improved from -0.52497 to -0.53055! Patience: 5/50
2024-11-15 09:53:52.076455: train_loss -0.7042
2024-11-15 09:53:52.077883: val_loss -0.5306
2024-11-15 09:53:52.078662: Pseudo dice [0.7366]
2024-11-15 09:53:52.079760: Epoch time: 132.05 s
2024-11-15 09:53:52.080697: Yayy! New best EMA pseudo Dice: 0.7193
2024-11-15 09:53:53.933595: 
2024-11-15 09:53:53.935345: Epoch 86
2024-11-15 09:53:53.936458: Current learning rate: 0.00321
2024-11-15 09:53:53.937657: encoder learning rate: 0.00321
2024-11-15 09:53:53.938682: decoder.stages learning rate: 0.00321
2024-11-15 09:53:53.939531: decoder.transpconvs learning rate: 0.00321
2024-11-15 09:53:53.940421: decoder.seg_layers learning rate: 0.00321
2024-11-15 09:55:58.438183: Validation loss did not improve from -0.53055. Patience: 1/50
2024-11-15 09:55:58.439727: train_loss -0.701
2024-11-15 09:55:58.440760: val_loss -0.518
2024-11-15 09:55:58.441580: Pseudo dice [0.7281]
2024-11-15 09:55:58.442415: Epoch time: 124.51 s
2024-11-15 09:55:58.443138: Yayy! New best EMA pseudo Dice: 0.7202
2024-11-15 09:56:00.770123: 
2024-11-15 09:56:00.772189: Epoch 87
2024-11-15 09:56:00.772949: Current learning rate: 0.00313
2024-11-15 09:56:00.773942: encoder learning rate: 0.00313
2024-11-15 09:56:00.774810: decoder.stages learning rate: 0.00313
2024-11-15 09:56:00.775594: decoder.transpconvs learning rate: 0.00313
2024-11-15 09:56:00.776332: decoder.seg_layers learning rate: 0.00313
2024-11-15 09:58:19.779750: Validation loss did not improve from -0.53055. Patience: 2/50
2024-11-15 09:58:19.781051: train_loss -0.7004
2024-11-15 09:58:19.782354: val_loss -0.4895
2024-11-15 09:58:19.783362: Pseudo dice [0.7175]
2024-11-15 09:58:19.784261: Epoch time: 139.01 s
2024-11-15 09:58:21.155337: 
2024-11-15 09:58:21.157025: Epoch 88
2024-11-15 09:58:21.157996: Current learning rate: 0.00304
2024-11-15 09:58:21.159046: encoder learning rate: 0.00304
2024-11-15 09:58:21.162716: decoder.stages learning rate: 0.00304
2024-11-15 09:58:21.164230: decoder.transpconvs learning rate: 0.00304
2024-11-15 09:58:21.165280: decoder.seg_layers learning rate: 0.00304
2024-11-15 10:00:34.904118: Validation loss did not improve from -0.53055. Patience: 3/50
2024-11-15 10:00:34.905438: train_loss -0.7041
2024-11-15 10:00:34.906502: val_loss -0.502
2024-11-15 10:00:34.907475: Pseudo dice [0.7248]
2024-11-15 10:00:34.908538: Epoch time: 133.75 s
2024-11-15 10:00:34.909621: Yayy! New best EMA pseudo Dice: 0.7204
2024-11-15 10:00:36.666546: 
2024-11-15 10:00:36.667825: Epoch 89
2024-11-15 10:00:36.668935: Current learning rate: 0.00296
2024-11-15 10:00:36.669855: encoder learning rate: 0.00296
2024-11-15 10:00:36.670730: decoder.stages learning rate: 0.00296
2024-11-15 10:00:36.671598: decoder.transpconvs learning rate: 0.00296
2024-11-15 10:00:36.672468: decoder.seg_layers learning rate: 0.00296
2024-11-15 10:02:50.678284: Validation loss did not improve from -0.53055. Patience: 4/50
2024-11-15 10:02:50.679426: train_loss -0.7047
2024-11-15 10:02:50.680544: val_loss -0.4998
2024-11-15 10:02:50.681377: Pseudo dice [0.718]
2024-11-15 10:02:50.682383: Epoch time: 134.01 s
2024-11-15 10:02:52.485484: 
2024-11-15 10:02:52.486786: Epoch 90
2024-11-15 10:02:52.487604: Current learning rate: 0.00287
2024-11-15 10:02:52.488631: encoder learning rate: 0.00287
2024-11-15 10:02:52.489563: decoder.stages learning rate: 0.00287
2024-11-15 10:02:52.490427: decoder.transpconvs learning rate: 0.00287
2024-11-15 10:02:52.491241: decoder.seg_layers learning rate: 0.00287
2024-11-15 10:05:08.186357: Validation loss did not improve from -0.53055. Patience: 5/50
2024-11-15 10:05:08.187488: train_loss -0.7141
2024-11-15 10:05:08.189068: val_loss -0.5304
2024-11-15 10:05:08.190508: Pseudo dice [0.7349]
2024-11-15 10:05:08.191919: Epoch time: 135.7 s
2024-11-15 10:05:08.193200: Yayy! New best EMA pseudo Dice: 0.7217
2024-11-15 10:05:10.000086: 
2024-11-15 10:05:10.001846: Epoch 91
2024-11-15 10:05:10.003108: Current learning rate: 0.00279
2024-11-15 10:05:10.004514: encoder learning rate: 0.00279
2024-11-15 10:05:10.005610: decoder.stages learning rate: 0.00279
2024-11-15 10:05:10.006747: decoder.transpconvs learning rate: 0.00279
2024-11-15 10:05:10.007817: decoder.seg_layers learning rate: 0.00279
2024-11-15 10:07:13.795280: Validation loss did not improve from -0.53055. Patience: 6/50
2024-11-15 10:07:13.836044: train_loss -0.7168
2024-11-15 10:07:13.864815: val_loss -0.5106
2024-11-15 10:07:13.865998: Pseudo dice [0.7208]
2024-11-15 10:07:13.867031: Epoch time: 123.84 s
2024-11-15 10:07:16.228277: 
2024-11-15 10:07:16.229694: Epoch 92
2024-11-15 10:07:16.230685: Current learning rate: 0.0027
2024-11-15 10:07:16.231683: encoder learning rate: 0.0027
2024-11-15 10:07:16.232491: decoder.stages learning rate: 0.0027
2024-11-15 10:07:16.233356: decoder.transpconvs learning rate: 0.0027
2024-11-15 10:07:16.234210: decoder.seg_layers learning rate: 0.0027
2024-11-15 10:09:31.856777: Validation loss did not improve from -0.53055. Patience: 7/50
2024-11-15 10:09:31.858204: train_loss -0.7099
2024-11-15 10:09:31.859387: val_loss -0.5263
2024-11-15 10:09:31.860536: Pseudo dice [0.7376]
2024-11-15 10:09:31.861928: Epoch time: 135.63 s
2024-11-15 10:09:31.863103: Yayy! New best EMA pseudo Dice: 0.7232
2024-11-15 10:09:33.943256: 
2024-11-15 10:09:33.944792: Epoch 93
2024-11-15 10:09:33.945995: Current learning rate: 0.00261
2024-11-15 10:09:33.947201: encoder learning rate: 0.00261
2024-11-15 10:09:33.948247: decoder.stages learning rate: 0.00261
2024-11-15 10:09:33.949226: decoder.transpconvs learning rate: 0.00261
2024-11-15 10:09:33.950118: decoder.seg_layers learning rate: 0.00261
2024-11-15 10:11:45.856943: Validation loss did not improve from -0.53055. Patience: 8/50
2024-11-15 10:11:45.858397: train_loss -0.715
2024-11-15 10:11:45.859424: val_loss -0.4918
2024-11-15 10:11:45.860259: Pseudo dice [0.7149]
2024-11-15 10:11:45.861313: Epoch time: 131.92 s
2024-11-15 10:11:47.299860: 
2024-11-15 10:11:47.300889: Epoch 94
2024-11-15 10:11:47.301723: Current learning rate: 0.00252
2024-11-15 10:11:47.302602: encoder learning rate: 0.00252
2024-11-15 10:11:47.303343: decoder.stages learning rate: 0.00252
2024-11-15 10:11:47.304108: decoder.transpconvs learning rate: 0.00252
2024-11-15 10:11:47.304878: decoder.seg_layers learning rate: 0.00252
2024-11-15 10:13:47.460788: Validation loss improved from -0.53055 to -0.53459! Patience: 8/50
2024-11-15 10:13:47.462036: train_loss -0.7183
2024-11-15 10:13:47.463116: val_loss -0.5346
2024-11-15 10:13:47.464095: Pseudo dice [0.7348]
2024-11-15 10:13:47.465088: Epoch time: 120.16 s
2024-11-15 10:13:48.016455: Yayy! New best EMA pseudo Dice: 0.7236
2024-11-15 10:13:49.766292: 
2024-11-15 10:13:49.767888: Epoch 95
2024-11-15 10:13:49.769246: Current learning rate: 0.00244
2024-11-15 10:13:49.770511: encoder learning rate: 0.00244
2024-11-15 10:13:49.771727: decoder.stages learning rate: 0.00244
2024-11-15 10:13:49.772820: decoder.transpconvs learning rate: 0.00244
2024-11-15 10:13:49.773947: decoder.seg_layers learning rate: 0.00244
2024-11-15 10:15:59.424491: Validation loss did not improve from -0.53459. Patience: 1/50
2024-11-15 10:15:59.425375: train_loss -0.7206
2024-11-15 10:15:59.426825: val_loss -0.5191
2024-11-15 10:15:59.428026: Pseudo dice [0.7387]
2024-11-15 10:15:59.429116: Epoch time: 129.66 s
2024-11-15 10:15:59.430157: Yayy! New best EMA pseudo Dice: 0.7251
2024-11-15 10:16:01.221574: 
2024-11-15 10:16:01.223334: Epoch 96
2024-11-15 10:16:01.224721: Current learning rate: 0.00235
2024-11-15 10:16:01.225818: encoder learning rate: 0.00235
2024-11-15 10:16:01.226855: decoder.stages learning rate: 0.00235
2024-11-15 10:16:01.227871: decoder.transpconvs learning rate: 0.00235
2024-11-15 10:16:01.228864: decoder.seg_layers learning rate: 0.00235
2024-11-15 10:18:19.297721: Validation loss did not improve from -0.53459. Patience: 2/50
2024-11-15 10:18:19.298994: train_loss -0.7193
2024-11-15 10:18:19.300325: val_loss -0.506
2024-11-15 10:18:19.301339: Pseudo dice [0.724]
2024-11-15 10:18:19.302447: Epoch time: 138.08 s
2024-11-15 10:18:20.756660: 
2024-11-15 10:18:20.758368: Epoch 97
2024-11-15 10:18:20.759410: Current learning rate: 0.00226
2024-11-15 10:18:20.760603: encoder learning rate: 0.00226
2024-11-15 10:18:20.761738: decoder.stages learning rate: 0.00226
2024-11-15 10:18:20.762736: decoder.transpconvs learning rate: 0.00226
2024-11-15 10:18:20.763641: decoder.seg_layers learning rate: 0.00226
2024-11-15 10:20:30.624589: Validation loss improved from -0.53459 to -0.53931! Patience: 2/50
2024-11-15 10:20:30.626897: train_loss -0.7197
2024-11-15 10:20:30.628362: val_loss -0.5393
2024-11-15 10:20:30.629366: Pseudo dice [0.7423]
2024-11-15 10:20:30.630497: Epoch time: 129.87 s
2024-11-15 10:20:30.631338: Yayy! New best EMA pseudo Dice: 0.7267
2024-11-15 10:20:32.618041: 
2024-11-15 10:20:32.620250: Epoch 98
2024-11-15 10:20:32.621189: Current learning rate: 0.00217
2024-11-15 10:20:32.622084: encoder learning rate: 0.00217
2024-11-15 10:20:32.622962: decoder.stages learning rate: 0.00217
2024-11-15 10:20:32.623828: decoder.transpconvs learning rate: 0.00217
2024-11-15 10:20:32.624571: decoder.seg_layers learning rate: 0.00217
2024-11-15 10:22:43.167720: Validation loss did not improve from -0.53931. Patience: 1/50
2024-11-15 10:22:43.168926: train_loss -0.7215
2024-11-15 10:22:43.170014: val_loss -0.4868
2024-11-15 10:22:43.170944: Pseudo dice [0.7135]
2024-11-15 10:22:43.171900: Epoch time: 130.55 s
2024-11-15 10:22:44.609810: 
2024-11-15 10:22:44.611111: Epoch 99
2024-11-15 10:22:44.611998: Current learning rate: 0.00208
2024-11-15 10:22:44.612985: encoder learning rate: 0.00208
2024-11-15 10:22:44.613920: decoder.stages learning rate: 0.00208
2024-11-15 10:22:44.614750: decoder.transpconvs learning rate: 0.00208
2024-11-15 10:22:44.615620: decoder.seg_layers learning rate: 0.00208
2024-11-15 10:24:57.211735: Validation loss did not improve from -0.53931. Patience: 2/50
2024-11-15 10:24:57.213088: train_loss -0.7178
2024-11-15 10:24:57.214207: val_loss -0.5135
2024-11-15 10:24:57.215168: Pseudo dice [0.7339]
2024-11-15 10:24:57.216162: Epoch time: 132.61 s
2024-11-15 10:25:03.042608: 
2024-11-15 10:25:03.044494: Epoch 100
2024-11-15 10:25:03.045414: Current learning rate: 0.00199
2024-11-15 10:25:03.046482: encoder learning rate: 0.00199
2024-11-15 10:25:03.047409: decoder.stages learning rate: 0.00199
2024-11-15 10:25:03.048245: decoder.transpconvs learning rate: 0.00199
2024-11-15 10:25:03.049150: decoder.seg_layers learning rate: 0.00199
2024-11-15 10:27:23.670615: Validation loss did not improve from -0.53931. Patience: 3/50
2024-11-15 10:27:23.671828: train_loss -0.727
2024-11-15 10:27:23.672992: val_loss -0.5309
2024-11-15 10:27:23.673852: Pseudo dice [0.7395]
2024-11-15 10:27:23.674817: Epoch time: 140.63 s
2024-11-15 10:27:23.675619: Yayy! New best EMA pseudo Dice: 0.7276
2024-11-15 10:27:25.558102: 
2024-11-15 10:27:25.559519: Epoch 101
2024-11-15 10:27:25.560610: Current learning rate: 0.0019
2024-11-15 10:27:25.561699: encoder learning rate: 0.0019
2024-11-15 10:27:25.562600: decoder.stages learning rate: 0.0019
2024-11-15 10:27:25.563518: decoder.transpconvs learning rate: 0.0019
2024-11-15 10:27:25.564316: decoder.seg_layers learning rate: 0.0019
2024-11-15 10:29:38.936122: Validation loss did not improve from -0.53931. Patience: 4/50
2024-11-15 10:29:38.937540: train_loss -0.7225
2024-11-15 10:29:38.938959: val_loss -0.5215
2024-11-15 10:29:38.940028: Pseudo dice [0.7345]
2024-11-15 10:29:38.941260: Epoch time: 133.38 s
2024-11-15 10:29:38.942333: Yayy! New best EMA pseudo Dice: 0.7283
2024-11-15 10:29:40.751462: 
2024-11-15 10:29:40.752717: Epoch 102
2024-11-15 10:29:40.753741: Current learning rate: 0.00181
2024-11-15 10:29:40.754671: encoder learning rate: 0.00181
2024-11-15 10:29:40.755429: decoder.stages learning rate: 0.00181
2024-11-15 10:29:40.756259: decoder.transpconvs learning rate: 0.00181
2024-11-15 10:29:40.757011: decoder.seg_layers learning rate: 0.00181
2024-11-15 10:31:37.796273: Validation loss did not improve from -0.53931. Patience: 5/50
2024-11-15 10:31:37.797952: train_loss -0.7283
2024-11-15 10:31:37.799016: val_loss -0.5224
2024-11-15 10:31:37.799872: Pseudo dice [0.735]
2024-11-15 10:31:37.800796: Epoch time: 117.05 s
2024-11-15 10:31:37.801707: Yayy! New best EMA pseudo Dice: 0.7289
2024-11-15 10:31:39.633149: 
2024-11-15 10:31:39.634630: Epoch 103
2024-11-15 10:31:39.635712: Current learning rate: 0.00172
2024-11-15 10:31:39.636844: encoder learning rate: 0.00172
2024-11-15 10:31:39.637682: decoder.stages learning rate: 0.00172
2024-11-15 10:31:39.647391: decoder.transpconvs learning rate: 0.00172
2024-11-15 10:31:39.648460: decoder.seg_layers learning rate: 0.00172
2024-11-15 10:33:53.414705: Validation loss did not improve from -0.53931. Patience: 6/50
2024-11-15 10:33:53.415842: train_loss -0.7286
2024-11-15 10:33:53.417683: val_loss -0.5378
2024-11-15 10:33:53.418843: Pseudo dice [0.7504]
2024-11-15 10:33:53.419794: Epoch time: 133.78 s
2024-11-15 10:33:53.420685: Yayy! New best EMA pseudo Dice: 0.7311
2024-11-15 10:33:55.223653: 
2024-11-15 10:33:55.224793: Epoch 104
2024-11-15 10:33:55.225687: Current learning rate: 0.00163
2024-11-15 10:33:55.226693: encoder learning rate: 0.00163
2024-11-15 10:33:55.227528: decoder.stages learning rate: 0.00163
2024-11-15 10:33:55.228419: decoder.transpconvs learning rate: 0.00163
2024-11-15 10:33:55.229313: decoder.seg_layers learning rate: 0.00163
2024-11-15 10:36:11.432353: Validation loss did not improve from -0.53931. Patience: 7/50
2024-11-15 10:36:11.433443: train_loss -0.728
2024-11-15 10:36:11.434516: val_loss -0.511
2024-11-15 10:36:11.435448: Pseudo dice [0.7324]
2024-11-15 10:36:11.436327: Epoch time: 136.21 s
2024-11-15 10:36:11.970744: Yayy! New best EMA pseudo Dice: 0.7312
2024-11-15 10:36:13.828437: 
2024-11-15 10:36:13.829517: Epoch 105
2024-11-15 10:36:13.830509: Current learning rate: 0.00154
2024-11-15 10:36:13.831495: encoder learning rate: 0.00154
2024-11-15 10:36:13.832370: decoder.stages learning rate: 0.00154
2024-11-15 10:36:13.833212: decoder.transpconvs learning rate: 0.00154
2024-11-15 10:36:13.834150: decoder.seg_layers learning rate: 0.00154
2024-11-15 10:38:15.443654: Validation loss did not improve from -0.53931. Patience: 8/50
2024-11-15 10:38:15.445517: train_loss -0.7289
2024-11-15 10:38:15.446782: val_loss -0.5311
2024-11-15 10:38:15.447922: Pseudo dice [0.7381]
2024-11-15 10:38:15.449103: Epoch time: 121.62 s
2024-11-15 10:38:15.450299: Yayy! New best EMA pseudo Dice: 0.7319
2024-11-15 10:38:17.297797: 
2024-11-15 10:38:17.299143: Epoch 106
2024-11-15 10:38:17.300032: Current learning rate: 0.00145
2024-11-15 10:38:17.301113: encoder learning rate: 0.00145
2024-11-15 10:38:17.302027: decoder.stages learning rate: 0.00145
2024-11-15 10:38:17.302840: decoder.transpconvs learning rate: 0.00145
2024-11-15 10:38:17.303549: decoder.seg_layers learning rate: 0.00145
2024-11-15 10:40:32.741935: Validation loss did not improve from -0.53931. Patience: 9/50
2024-11-15 10:40:32.743805: train_loss -0.7357
2024-11-15 10:40:32.745216: val_loss -0.5248
2024-11-15 10:40:32.746236: Pseudo dice [0.7376]
2024-11-15 10:40:32.747132: Epoch time: 135.45 s
2024-11-15 10:40:32.748054: Yayy! New best EMA pseudo Dice: 0.7325
2024-11-15 10:40:34.599875: 
2024-11-15 10:40:34.601541: Epoch 107
2024-11-15 10:40:34.602629: Current learning rate: 0.00135
2024-11-15 10:40:34.603616: encoder learning rate: 0.00135
2024-11-15 10:40:34.604406: decoder.stages learning rate: 0.00135
2024-11-15 10:40:34.605236: decoder.transpconvs learning rate: 0.00135
2024-11-15 10:40:34.606010: decoder.seg_layers learning rate: 0.00135
2024-11-15 10:42:52.880194: Validation loss improved from -0.53931 to -0.54024! Patience: 9/50
2024-11-15 10:42:52.881182: train_loss -0.7292
2024-11-15 10:42:52.882159: val_loss -0.5402
2024-11-15 10:42:52.882875: Pseudo dice [0.7389]
2024-11-15 10:42:52.883664: Epoch time: 138.28 s
2024-11-15 10:42:52.884338: Yayy! New best EMA pseudo Dice: 0.7331
2024-11-15 10:42:54.667253: 
2024-11-15 10:42:54.668170: Epoch 108
2024-11-15 10:42:54.668971: Current learning rate: 0.00126
2024-11-15 10:42:54.669903: encoder learning rate: 0.00126
2024-11-15 10:42:54.670710: decoder.stages learning rate: 0.00126
2024-11-15 10:42:54.671501: decoder.transpconvs learning rate: 0.00126
2024-11-15 10:42:54.672209: decoder.seg_layers learning rate: 0.00126
2024-11-15 10:45:12.243924: Validation loss did not improve from -0.54024. Patience: 1/50
2024-11-15 10:45:12.245068: train_loss -0.7386
2024-11-15 10:45:12.245946: val_loss -0.5267
2024-11-15 10:45:12.246750: Pseudo dice [0.7358]
2024-11-15 10:45:12.247535: Epoch time: 137.58 s
2024-11-15 10:45:12.248337: Yayy! New best EMA pseudo Dice: 0.7334
2024-11-15 10:45:14.134025: 
2024-11-15 10:45:14.135355: Epoch 109
2024-11-15 10:45:14.136476: Current learning rate: 0.00116
2024-11-15 10:45:14.137367: encoder learning rate: 0.00116
2024-11-15 10:45:14.138230: decoder.stages learning rate: 0.00116
2024-11-15 10:45:14.138940: decoder.transpconvs learning rate: 0.00116
2024-11-15 10:45:14.139648: decoder.seg_layers learning rate: 0.00116
2024-11-15 10:47:23.689526: Validation loss did not improve from -0.54024. Patience: 2/50
2024-11-15 10:47:23.690963: train_loss -0.736
2024-11-15 10:47:23.692313: val_loss -0.4934
2024-11-15 10:47:23.693321: Pseudo dice [0.7234]
2024-11-15 10:47:23.694252: Epoch time: 129.56 s
2024-11-15 10:47:25.574009: 
2024-11-15 10:47:25.575280: Epoch 110
2024-11-15 10:47:25.576205: Current learning rate: 0.00107
2024-11-15 10:47:25.577150: encoder learning rate: 0.00107
2024-11-15 10:47:25.577996: decoder.stages learning rate: 0.00107
2024-11-15 10:47:25.578762: decoder.transpconvs learning rate: 0.00107
2024-11-15 10:47:25.579686: decoder.seg_layers learning rate: 0.00107
2024-11-15 10:49:27.260933: Validation loss did not improve from -0.54024. Patience: 3/50
2024-11-15 10:49:27.262088: train_loss -0.7394
2024-11-15 10:49:27.263337: val_loss -0.5329
2024-11-15 10:49:27.264279: Pseudo dice [0.7407]
2024-11-15 10:49:27.265177: Epoch time: 121.69 s
2024-11-15 10:49:29.094886: 
2024-11-15 10:49:29.096248: Epoch 111
2024-11-15 10:49:29.097056: Current learning rate: 0.00097
2024-11-15 10:49:29.098006: encoder learning rate: 0.00097
2024-11-15 10:49:29.098814: decoder.stages learning rate: 0.00097
2024-11-15 10:49:29.099638: decoder.transpconvs learning rate: 0.00097
2024-11-15 10:49:29.100486: decoder.seg_layers learning rate: 0.00097
2024-11-15 10:51:44.605686: Validation loss did not improve from -0.54024. Patience: 4/50
2024-11-15 10:51:44.606967: train_loss -0.7386
2024-11-15 10:51:44.608016: val_loss -0.5279
2024-11-15 10:51:44.608984: Pseudo dice [0.7396]
2024-11-15 10:51:44.609784: Epoch time: 135.51 s
2024-11-15 10:51:44.610518: Yayy! New best EMA pseudo Dice: 0.7339
2024-11-15 10:51:46.418809: 
2024-11-15 10:51:46.420092: Epoch 112
2024-11-15 10:51:46.421059: Current learning rate: 0.00087
2024-11-15 10:51:46.421926: encoder learning rate: 0.00087
2024-11-15 10:51:46.422784: decoder.stages learning rate: 0.00087
2024-11-15 10:51:46.423497: decoder.transpconvs learning rate: 0.00087
2024-11-15 10:51:46.424262: decoder.seg_layers learning rate: 0.00087
2024-11-15 10:54:03.142046: Validation loss did not improve from -0.54024. Patience: 5/50
2024-11-15 10:54:03.143000: train_loss -0.7401
2024-11-15 10:54:03.143794: val_loss -0.519
2024-11-15 10:54:03.144744: Pseudo dice [0.7321]
2024-11-15 10:54:03.145456: Epoch time: 136.73 s
2024-11-15 10:54:04.519499: 
2024-11-15 10:54:04.520578: Epoch 113
2024-11-15 10:54:04.521388: Current learning rate: 0.00078
2024-11-15 10:54:04.522459: encoder learning rate: 0.00078
2024-11-15 10:54:04.523263: decoder.stages learning rate: 0.00078
2024-11-15 10:54:04.524063: decoder.transpconvs learning rate: 0.00078
2024-11-15 10:54:04.524887: decoder.seg_layers learning rate: 0.00078
2024-11-15 10:56:15.728933: Validation loss did not improve from -0.54024. Patience: 6/50
2024-11-15 10:56:15.729906: train_loss -0.7389
2024-11-15 10:56:15.730762: val_loss -0.5327
2024-11-15 10:56:15.731579: Pseudo dice [0.7365]
2024-11-15 10:56:15.732430: Epoch time: 131.21 s
2024-11-15 10:56:15.733201: Yayy! New best EMA pseudo Dice: 0.734
2024-11-15 10:56:17.535538: 
2024-11-15 10:56:17.536555: Epoch 114
2024-11-15 10:56:17.537370: Current learning rate: 0.00067
2024-11-15 10:56:17.538231: encoder learning rate: 0.00067
2024-11-15 10:56:17.538989: decoder.stages learning rate: 0.00067
2024-11-15 10:56:17.539729: decoder.transpconvs learning rate: 0.00067
2024-11-15 10:56:17.540419: decoder.seg_layers learning rate: 0.00067
2024-11-15 10:58:32.781473: Validation loss did not improve from -0.54024. Patience: 7/50
2024-11-15 10:58:32.782462: train_loss -0.7399
2024-11-15 10:58:32.783310: val_loss -0.5223
2024-11-15 10:58:32.784083: Pseudo dice [0.7304]
2024-11-15 10:58:32.784918: Epoch time: 135.25 s
2024-11-15 10:58:34.593453: 
2024-11-15 10:58:34.594744: Epoch 115
2024-11-15 10:58:34.595550: Current learning rate: 0.00057
2024-11-15 10:58:34.596454: encoder learning rate: 0.00057
2024-11-15 10:58:34.597200: decoder.stages learning rate: 0.00057
2024-11-15 10:58:34.598029: decoder.transpconvs learning rate: 0.00057
2024-11-15 10:58:34.598797: decoder.seg_layers learning rate: 0.00057
2024-11-15 11:00:49.750083: Validation loss did not improve from -0.54024. Patience: 8/50
2024-11-15 11:00:49.751364: train_loss -0.7438
2024-11-15 11:00:49.752401: val_loss -0.5187
2024-11-15 11:00:49.753410: Pseudo dice [0.7328]
2024-11-15 11:00:49.754424: Epoch time: 135.16 s
2024-11-15 11:00:51.160961: 
2024-11-15 11:00:51.162368: Epoch 116
2024-11-15 11:00:51.163442: Current learning rate: 0.00047
2024-11-15 11:00:51.164552: encoder learning rate: 0.00047
2024-11-15 11:00:51.165568: decoder.stages learning rate: 0.00047
2024-11-15 11:00:51.166517: decoder.transpconvs learning rate: 0.00047
2024-11-15 11:00:51.167333: decoder.seg_layers learning rate: 0.00047
2024-11-15 11:03:10.590332: Validation loss did not improve from -0.54024. Patience: 9/50
2024-11-15 11:03:10.593258: train_loss -0.7493
2024-11-15 11:03:10.594961: val_loss -0.5216
2024-11-15 11:03:10.596164: Pseudo dice [0.7301]
2024-11-15 11:03:10.597224: Epoch time: 139.43 s
2024-11-15 11:03:11.983009: 
2024-11-15 11:03:11.984427: Epoch 117
2024-11-15 11:03:11.985530: Current learning rate: 0.00036
2024-11-15 11:03:11.986681: encoder learning rate: 0.00036
2024-11-15 11:03:11.987769: decoder.stages learning rate: 0.00036
2024-11-15 11:03:11.988755: decoder.transpconvs learning rate: 0.00036
2024-11-15 11:03:11.989832: decoder.seg_layers learning rate: 0.00036
2024-11-15 11:05:19.025433: Validation loss did not improve from -0.54024. Patience: 10/50
2024-11-15 11:05:19.026707: train_loss -0.7479
2024-11-15 11:05:19.028043: val_loss -0.5294
2024-11-15 11:05:19.029440: Pseudo dice [0.7356]
2024-11-15 11:05:19.030649: Epoch time: 127.05 s
2024-11-15 11:05:20.456174: 
2024-11-15 11:05:20.457464: Epoch 118
2024-11-15 11:05:20.458480: Current learning rate: 0.00025
2024-11-15 11:05:20.459531: encoder learning rate: 0.00025
2024-11-15 11:05:20.460481: decoder.stages learning rate: 0.00025
2024-11-15 11:05:20.461431: decoder.transpconvs learning rate: 0.00025
2024-11-15 11:05:20.462223: decoder.seg_layers learning rate: 0.00025
2024-11-15 11:07:23.733727: Validation loss did not improve from -0.54024. Patience: 11/50
2024-11-15 11:07:23.735016: train_loss -0.7441
2024-11-15 11:07:23.736043: val_loss -0.5218
2024-11-15 11:07:23.736918: Pseudo dice [0.7312]
2024-11-15 11:07:23.737841: Epoch time: 123.28 s
2024-11-15 11:07:25.152161: 
2024-11-15 11:07:25.153906: Epoch 119
2024-11-15 11:07:25.154902: Current learning rate: 0.00013
2024-11-15 11:07:25.155928: encoder learning rate: 0.00013
2024-11-15 11:07:25.156896: decoder.stages learning rate: 0.00013
2024-11-15 11:07:25.157565: decoder.transpconvs learning rate: 0.00013
2024-11-15 11:07:25.158206: decoder.seg_layers learning rate: 0.00013
2024-11-15 11:09:41.716568: Validation loss did not improve from -0.54024. Patience: 12/50
2024-11-15 11:09:41.717787: train_loss -0.7448
2024-11-15 11:09:41.718790: val_loss -0.5339
2024-11-15 11:09:41.719820: Pseudo dice [0.7339]
2024-11-15 11:09:41.721037: Epoch time: 136.57 s
2024-11-15 11:09:43.625883: 
2024-11-15 11:09:43.627366: Epoch 120
2024-11-15 11:09:43.628463: Current learning rate: 0.0
2024-11-15 11:09:43.629584: encoder learning rate: 0.0
2024-11-15 11:09:43.630586: decoder.stages learning rate: 0.0
2024-11-15 11:09:43.631482: decoder.transpconvs learning rate: 0.0
2024-11-15 11:09:43.632363: decoder.seg_layers learning rate: 0.0
2024-11-15 11:12:00.869941: Validation loss improved from -0.54024 to -0.54923! Patience: 12/50
2024-11-15 11:12:00.889659: train_loss -0.7503
2024-11-15 11:12:00.890875: val_loss -0.5492
2024-11-15 11:12:00.891904: Pseudo dice [0.7544]
2024-11-15 11:12:00.892798: Epoch time: 137.26 s
2024-11-15 11:12:00.893645: Yayy! New best EMA pseudo Dice: 0.7354
2024-11-15 11:12:03.235795: 
2024-11-15 11:12:03.236972: Epoch 121
2024-11-15 11:12:03.238608: Current learning rate: (-0.00013+4e-05j)
Traceback (most recent call last):
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/bin/nnUNetv2_train", line 8, in <module>
    sys.exit(run_training_entry())
  File "/home/gridsan/nchutisilp/projects/nnUNet/nnunetv2/run/run_training.py", line 275, in run_training_entry
    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,
  File "/home/gridsan/nchutisilp/projects/nnUNet/nnunetv2/run/run_training.py", line 211, in run_training
    nnunet_trainer.run_training()
  File "/home/gridsan/nchutisilp/projects/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py", line 1398, in run_training
    self.on_train_epoch_start()
  File "/home/gridsan/nchutisilp/projects/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer4PretrainedEncoder.py", line 19, in on_train_epoch_start
    super().on_train_epoch_start()
  File "/home/gridsan/nchutisilp/projects/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py", line 993, in on_train_epoch_start
    self.logger.log('lrs', self.optimizer.param_groups[0]['lr'], self.current_epoch)
  File "/home/gridsan/nchutisilp/projects/nnUNet/nnunetv2/training/logging/nnunet_logger.py", line 48, in log
    wandb.log({key: value}, step=epoch)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/wandb/sdk/wandb_run.py", line 420, in wrapper
    return func(self, *args, **kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/wandb/sdk/wandb_run.py", line 371, in wrapper_fn
    return func(self, *args, **kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/wandb/sdk/wandb_run.py", line 361, in wrapper
    return func(self, *args, **kwargs)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/wandb/sdk/wandb_run.py", line 1838, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/wandb/sdk/wandb_run.py", line 1602, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/wandb/sdk/wandb_run.py", line 1474, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/wandb/sdk/interface/interface.py", line 596, in publish_partial_history
    item.value_json = json_dumps_safer_history(v)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/wandb/util.py", line 842, in json_dumps_safer_history
    return dumps(obj, cls=WandBHistoryJSONEncoder, **kwargs)
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/json/__init__.py", line 234, in dumps
    return cls(
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/wandb/util.py", line 807, in default
    return json.JSONEncoder.default(self, obj)
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type complex is not JSON serializable
wandb: 
wandb: Run history:
wandb:            ema_fg_dice ▁▂▂▃▃▄▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████████████
wandb:   epoch_end_timestamps ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb: epoch_start_timestamps ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:                    lrs ▁▁▁▁▁▁▁███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁
wandb:           mean_fg_dice ▁▄▄▄▅▅▅▃▅▅▅▆▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇███▇█
wandb:           train_losses █▆▅▅▅▅▄▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             val_losses █▆▆▅▅▅▅▆▄▄▄▃▃▂▂▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:            ema_fg_dice 0.73538
wandb:   epoch_end_timestamps 1731687120.88892
wandb: epoch_start_timestamps 1731687123.23385
wandb:                    lrs 0.0
wandb:           mean_fg_dice 0.7544
wandb:           train_losses -0.75034
wandb:             val_losses -0.54923
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset302_Calcium_OCTv2/nnUNetTrainer4PretrainedEncoder__nnUNetPlans__3d_32x160x128_b10/fold_0/wandb/offline-run-20241115_065119-t4xahytg
wandb: Find logs at: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset302_Calcium_OCTv2/nnUNetTrainer4PretrainedEncoder__nnUNetPlans__3d_32x160x128_b10/fold_0/wandb/offline-run-20241115_065119-t4xahytg/logs
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f32e020f910>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f32ad4d50a0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f32ad0136a0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f32ad013e50>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f32f8f2df40>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f32ad013430>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
Exception in thread Thread-4:
Traceback (most recent call last):
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/threading.py", line 980, in _bootstrap_inner
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/gridsan/nchutisilp/.conda/envs/nnunet/lib/python3.9/threading.py", line 980, in _bootstrap_inner
FOLD 0 CONFIG 3d_32x160x128_b10 TRAINER nnUNetTrainer4PretrainedEncoder

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 2 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 2 cases that I would like to predict

Predicting 101-045:
perform_everything_on_device: True
  0%|          | 0/966 [00:00<?, ?it/s]  0%|          | 1/966 [00:15<4:11:42, 15.65s/it]  0%|          | 3/966 [00:15<1:06:11,  4.12s/it]  1%|          | 5/966 [00:16<33:04,  2.06s/it]    1%|          | 6/966 [00:16<24:40,  1.54s/it]  1%|          | 7/966 [00:16<18:19,  1.15s/it]  1%|          | 8/966 [00:16<13:38,  1.17it/s]  1%|          | 9/966 [00:16<10:14,  1.56it/s]  1%|          | 10/966 [00:16<07:48,  2.04it/s]  1%|          | 11/966 [00:16<06:03,  2.63it/s]  1%|          | 12/966 [00:16<04:49,  3.30it/s]  1%|▏         | 13/966 [00:17<03:56,  4.03it/s]  1%|▏         | 14/966 [00:17<03:19,  4.77it/s]  2%|▏         | 15/966 [00:17<02:53,  5.48it/s]  2%|▏         | 16/966 [00:17<02:34,  6.13it/s]  2%|▏         | 17/966 [00:17<02:22,  6.67it/s]  2%|▏         | 18/966 [00:17<02:13,  7.12it/s]  2%|▏         | 19/966 [00:17<02:06,  7.46it/s]  2%|▏         | 20/966 [00:17<02:02,  7.73it/s]  2%|▏         | 21/966 [00:17<01:59,  7.92it/s]  2%|▏         | 22/966 [00:18<01:57,  8.06it/s]  2%|▏         | 23/966 [00:18<01:55,  8.16it/s]  2%|▏         | 24/966 [00:18<01:54,  8.26it/s]  3%|▎         | 25/966 [00:18<01:53,  8.32it/s]  3%|▎         | 26/966 [00:18<01:52,  8.35it/s]  3%|▎         | 27/966 [00:18<01:51,  8.39it/s]  3%|▎         | 28/966 [00:18<01:51,  8.41it/s]  3%|▎         | 29/966 [00:18<01:51,  8.41it/s]  3%|▎         | 30/966 [00:19<01:51,  8.42it/s]  3%|▎         | 31/966 [00:19<01:50,  8.43it/s]  3%|▎         | 32/966 [00:19<01:50,  8.43it/s]  3%|▎         | 33/966 [00:19<01:50,  8.42it/s]  4%|▎         | 34/966 [00:19<01:50,  8.45it/s]  4%|▎         | 35/966 [00:19<01:50,  8.45it/s]  4%|▎         | 36/966 [00:19<01:49,  8.45it/s]  4%|▍         | 37/966 [00:19<01:49,  8.48it/s]  4%|▍         | 38/966 [00:19<01:49,  8.47it/s]  4%|▍         | 39/966 [00:20<01:49,  8.46it/s]  4%|▍         | 40/966 [00:20<01:49,  8.47it/s]  4%|▍         | 41/966 [00:20<01:49,  8.46it/s]  4%|▍         | 42/966 [00:20<01:49,  8.45it/s]  4%|▍         | 43/966 [00:20<01:49,  8.44it/s]  5%|▍         | 44/966 [00:20<01:49,  8.43it/s]  5%|▍         | 45/966 [00:20<01:49,  8.44it/s]  5%|▍         | 46/966 [00:20<01:48,  8.45it/s]  5%|▍         | 47/966 [00:21<01:48,  8.43it/s]  5%|▍         | 48/966 [00:21<01:48,  8.43it/s]  5%|▌         | 49/966 [00:21<01:48,  8.43it/s]  5%|▌         | 50/966 [00:21<01:48,  8.43it/s]  5%|▌         | 51/966 [00:21<01:48,  8.42it/s]  5%|▌         | 52/966 [00:21<01:48,  8.42it/s]  5%|▌         | 53/966 [00:21<01:48,  8.42it/s]  6%|▌         | 54/966 [00:21<01:48,  8.44it/s]  6%|▌         | 55/966 [00:21<01:47,  8.45it/s]  6%|▌         | 56/966 [00:22<01:47,  8.45it/s]  6%|▌         | 57/966 [00:22<01:47,  8.44it/s]  6%|▌         | 58/966 [00:22<01:47,  8.44it/s]  6%|▌         | 59/966 [00:22<01:47,  8.45it/s]  6%|▌         | 60/966 [00:22<01:47,  8.44it/s]  6%|▋         | 61/966 [00:22<01:47,  8.45it/s]  6%|▋         | 62/966 [00:22<01:47,  8.43it/s]  7%|▋         | 63/966 [00:22<01:47,  8.42it/s]  7%|▋         | 64/966 [00:23<01:47,  8.42it/s]  7%|▋         | 65/966 [00:23<01:47,  8.42it/s]  7%|▋         | 66/966 [00:23<01:46,  8.42it/s]  7%|▋         | 67/966 [00:23<01:46,  8.42it/s]  7%|▋         | 68/966 [00:23<01:46,  8.42it/s]  7%|▋         | 69/966 [00:23<01:46,  8.42it/s]  7%|▋         | 70/966 [00:23<01:46,  8.42it/s]  7%|▋         | 71/966 [00:23<01:46,  8.43it/s]  7%|▋         | 72/966 [00:24<01:45,  8.44it/s]  8%|▊         | 73/966 [00:24<01:45,  8.43it/s]  8%|▊         | 74/966 [00:24<01:45,  8.42it/s]  8%|▊         | 75/966 [00:24<01:45,  8.43it/s]  8%|▊         | 76/966 [00:24<01:45,  8.44it/s]  8%|▊         | 77/966 [00:24<01:45,  8.44it/s]  8%|▊         | 78/966 [00:24<01:45,  8.43it/s]  8%|▊         | 79/966 [00:24<01:45,  8.43it/s]  8%|▊         | 80/966 [00:24<01:45,  8.43it/s]  8%|▊         | 81/966 [00:25<01:44,  8.45it/s]  8%|▊         | 82/966 [00:25<01:44,  8.44it/s]  9%|▊         | 83/966 [00:25<01:44,  8.43it/s]  9%|▊         | 84/966 [00:25<01:44,  8.43it/s]  9%|▉         | 85/966 [00:25<01:44,  8.43it/s]  9%|▉         | 86/966 [00:25<01:44,  8.43it/s]  9%|▉         | 87/966 [00:25<01:44,  8.44it/s]  9%|▉         | 88/966 [00:25<01:44,  8.44it/s]  9%|▉         | 89/966 [00:26<01:44,  8.42it/s]  9%|▉         | 90/966 [00:26<01:44,  8.42it/s]  9%|▉         | 91/966 [00:26<01:43,  8.42it/s] 10%|▉         | 92/966 [00:26<01:43,  8.43it/s] 10%|▉         | 93/966 [00:26<01:43,  8.42it/s] 10%|▉         | 94/966 [00:26<01:43,  8.43it/s] 10%|▉         | 95/966 [00:26<01:43,  8.45it/s] 10%|▉         | 96/966 [00:26<01:43,  8.44it/s] 10%|█         | 97/966 [00:26<01:43,  8.44it/s] 10%|█         | 98/966 [00:27<01:42,  8.44it/s] 10%|█         | 99/966 [00:27<01:42,  8.44it/s] 10%|█         | 100/966 [00:27<01:42,  8.43it/s] 10%|█         | 101/966 [00:27<01:42,  8.43it/s] 11%|█         | 102/966 [00:27<01:42,  8.43it/s] 11%|█         | 103/966 [00:27<01:42,  8.43it/s] 11%|█         | 104/966 [00:27<01:42,  8.44it/s] 11%|█         | 105/966 [00:27<01:42,  8.43it/s] 11%|█         | 106/966 [00:28<01:41,  8.43it/s] 11%|█         | 107/966 [00:28<01:41,  8.44it/s] 11%|█         | 108/966 [00:28<01:41,  8.44it/s] 11%|█▏        | 109/966 [00:28<01:41,  8.43it/s] 11%|█▏        | 110/966 [00:28<01:41,  8.42it/s] 11%|█▏        | 111/966 [00:28<01:41,  8.42it/s] 12%|█▏        | 112/966 [00:28<01:41,  8.43it/s] 12%|█▏        | 113/966 [00:28<01:41,  8.43it/s] 12%|█▏        | 114/966 [00:28<01:41,  8.43it/s] 12%|█▏        | 115/966 [00:29<01:41,  8.41it/s] 12%|█▏        | 116/966 [00:29<01:40,  8.42it/s] 12%|█▏        | 117/966 [00:29<01:40,  8.42it/s] 12%|█▏        | 118/966 [00:29<01:40,  8.42it/s] 12%|█▏        | 119/966 [00:29<01:40,  8.41it/s] 12%|█▏        | 120/966 [00:29<01:40,  8.41it/s] 13%|█▎        | 121/966 [00:29<01:40,  8.43it/s] 13%|█▎        | 122/966 [00:29<01:40,  8.43it/s] 13%|█▎        | 123/966 [00:30<01:39,  8.44it/s] 13%|█▎        | 124/966 [00:30<01:39,  8.45it/s] 13%|█▎        | 125/966 [00:30<01:39,  8.46it/s] 13%|█▎        | 126/966 [00:30<01:39,  8.45it/s] 13%|█▎        | 127/966 [00:30<01:39,  8.46it/s] 13%|█▎        | 128/966 [00:30<01:39,  8.46it/s] 13%|█▎        | 129/966 [00:30<01:39,  8.45it/s] 13%|█▎        | 130/966 [00:30<01:39,  8.43it/s] 14%|█▎        | 131/966 [00:31<01:38,  8.44it/s] 14%|█▎        | 132/966 [00:31<01:39,  8.42it/s] 14%|█▍        | 133/966 [00:31<01:39,  8.41it/s] 14%|█▍        | 134/966 [00:31<01:38,  8.43it/s] 14%|█▍        | 135/966 [00:31<01:38,  8.42it/s] 14%|█▍        | 136/966 [00:31<01:38,  8.43it/s] 14%|█▍        | 137/966 [00:31<01:38,  8.43it/s] 14%|█▍        | 138/966 [00:31<01:38,  8.43it/s] 14%|█▍        | 139/966 [00:31<01:38,  8.42it/s] 14%|█▍        | 140/966 [00:32<01:38,  8.42it/s] 15%|█▍        | 141/966 [00:32<01:38,  8.41it/s] 15%|█▍        | 142/966 [00:32<01:38,  8.41it/s] 15%|█▍        | 143/966 [00:32<01:37,  8.41it/s] 15%|█▍        | 144/966 [00:32<01:37,  8.43it/s] 15%|█▌        | 145/966 [00:32<01:37,  8.41it/s] 15%|█▌        | 146/966 [00:32<01:37,  8.41it/s] 15%|█▌        | 147/966 [00:32<01:37,  8.42it/s] 15%|█▌        | 148/966 [00:33<01:37,  8.41it/s] 15%|█▌        | 149/966 [00:33<01:37,  8.40it/s] 16%|█▌        | 150/966 [00:33<01:37,  8.40it/s] 16%|█▌        | 151/966 [00:33<01:37,  8.40it/s] 16%|█▌        | 152/966 [00:33<01:36,  8.41it/s] 16%|█▌        | 153/966 [00:33<01:36,  8.41it/s] 16%|█▌        | 154/966 [00:33<01:36,  8.42it/s] 16%|█▌        | 155/966 [00:33<01:36,  8.42it/s] 16%|█▌        | 156/966 [00:33<01:36,  8.41it/s] 16%|█▋        | 157/966 [00:34<01:36,  8.41it/s] 16%|█▋        | 158/966 [00:34<01:36,  8.41it/s] 16%|█▋        | 159/966 [00:34<01:35,  8.41it/s] 17%|█▋        | 160/966 [00:34<01:35,  8.41it/s] 17%|█▋        | 161/966 [00:34<01:35,  8.41it/s] 17%|█▋        | 162/966 [00:34<01:35,  8.40it/s] 17%|█▋        | 163/966 [00:34<01:35,  8.41it/s] 17%|█▋        | 164/966 [00:34<01:35,  8.41it/s] 17%|█▋        | 165/966 [00:35<01:35,  8.42it/s] 17%|█▋        | 166/966 [00:35<01:34,  8.42it/s] 17%|█▋        | 167/966 [00:35<01:34,  8.42it/s] 17%|█▋        | 168/966 [00:35<01:34,  8.43it/s] 17%|█▋        | 169/966 [00:35<01:34,  8.45it/s] 18%|█▊        | 170/966 [00:35<01:34,  8.46it/s] 18%|█▊        | 171/966 [00:35<01:34,  8.44it/s] 18%|█▊        | 172/966 [00:35<01:34,  8.44it/s] 18%|█▊        | 173/966 [00:35<01:34,  8.42it/s] 18%|█▊        | 174/966 [00:36<01:34,  8.42it/s] 18%|█▊        | 175/966 [00:36<01:33,  8.43it/s] 18%|█▊        | 176/966 [00:36<01:33,  8.44it/s] 18%|█▊        | 177/966 [00:36<01:33,  8.43it/s] 18%|█▊        | 178/966 [00:36<01:33,  8.42it/s] 19%|█▊        | 179/966 [00:36<01:33,  8.41it/s] 19%|█▊        | 180/966 [00:36<01:33,  8.40it/s] 19%|█▊        | 181/966 [00:36<01:33,  8.40it/s] 19%|█▉        | 182/966 [00:37<01:33,  8.42it/s] 19%|█▉        | 183/966 [00:37<01:33,  8.41it/s] 19%|█▉        | 184/966 [00:37<01:32,  8.43it/s] 19%|█▉        | 185/966 [00:37<01:32,  8.43it/s] 19%|█▉        | 186/966 [00:37<01:32,  8.43it/s] 19%|█▉        | 187/966 [00:37<01:32,  8.41it/s] 19%|█▉        | 188/966 [00:37<01:32,  8.44it/s] 20%|█▉        | 189/966 [00:37<01:32,  8.42it/s] 20%|█▉        | 190/966 [00:38<01:32,  8.42it/s] 20%|█▉        | 191/966 [00:38<01:32,  8.41it/s] 20%|█▉        | 192/966 [00:38<01:32,  8.40it/s] 20%|█▉        | 193/966 [00:38<01:31,  8.41it/s] 20%|██        | 194/966 [00:38<01:31,  8.41it/s] 20%|██        | 195/966 [00:38<01:31,  8.40it/s] 20%|██        | 196/966 [00:38<01:31,  8.40it/s] 20%|██        | 197/966 [00:38<01:31,  8.40it/s] 20%|██        | 198/966 [00:38<01:31,  8.42it/s] 21%|██        | 199/966 [00:39<01:31,  8.42it/s] 21%|██        | 200/966 [00:39<01:30,  8.42it/s] 21%|██        | 201/966 [00:39<01:30,  8.42it/s] 21%|██        | 202/966 [00:39<01:30,  8.42it/s] 21%|██        | 203/966 [00:39<01:30,  8.42it/s] 21%|██        | 204/966 [00:39<01:30,  8.41it/s] 21%|██        | 205/966 [00:39<01:30,  8.41it/s] 21%|██▏       | 206/966 [00:39<01:30,  8.42it/s] 21%|██▏       | 207/966 [00:40<01:30,  8.42it/s] 22%|██▏       | 208/966 [00:40<01:29,  8.42it/s] 22%|██▏       | 209/966 [00:40<01:29,  8.43it/s] 22%|██▏       | 210/966 [00:40<01:29,  8.44it/s] 22%|██▏       | 211/966 [00:40<01:29,  8.46it/s] 22%|██▏       | 212/966 [00:40<01:29,  8.47it/s] 22%|██▏       | 213/966 [00:40<01:28,  8.47it/s] 22%|██▏       | 214/966 [00:40<01:29,  8.45it/s] 22%|██▏       | 215/966 [00:40<01:29,  8.43it/s] 22%|██▏       | 216/966 [00:41<01:29,  8.42it/s] 22%|██▏       | 217/966 [00:41<01:29,  8.41it/s] 23%|██▎       | 218/966 [00:41<01:28,  8.44it/s] 23%|██▎       | 219/966 [00:41<01:28,  8.43it/s] 23%|██▎       | 220/966 [00:41<01:28,  8.43it/s] 23%|██▎       | 221/966 [00:41<01:28,  8.43it/s] 23%|██▎       | 222/966 [00:41<01:28,  8.43it/s] 23%|██▎       | 223/966 [00:41<01:28,  8.43it/s] 23%|██▎       | 224/966 [00:42<01:28,  8.42it/s] 23%|██▎       | 225/966 [00:42<01:28,  8.42it/s] 23%|██▎       | 226/966 [00:42<01:28,  8.41it/s] 23%|██▎       | 227/966 [00:42<01:27,  8.40it/s] 24%|██▎       | 228/966 [00:42<01:27,  8.41it/s] 24%|██▎       | 229/966 [00:42<01:27,  8.41it/s] 24%|██▍       | 230/966 [00:42<01:27,  8.40it/s] 24%|██▍       | 231/966 [00:42<01:27,  8.41it/s] 24%|██▍       | 232/966 [00:42<01:27,  8.42it/s] 24%|██▍       | 233/966 [00:43<01:27,  8.41it/s] 24%|██▍       | 234/966 [00:43<01:27,  8.41it/s] 24%|██▍       | 235/966 [00:43<01:26,  8.42it/s] 24%|██▍       | 236/966 [00:43<01:26,  8.42it/s] 25%|██▍       | 237/966 [00:43<01:26,  8.41it/s] 25%|██▍       | 238/966 [00:43<01:26,  8.42it/s] 25%|██▍       | 239/966 [00:43<01:26,  8.42it/s] 25%|██▍       | 240/966 [00:43<01:26,  8.42it/s] 25%|██▍       | 241/966 [00:44<01:26,  8.41it/s] 25%|██▌       | 242/966 [00:44<01:26,  8.41it/s] 25%|██▌       | 243/966 [00:44<01:26,  8.40it/s] 25%|██▌       | 244/966 [00:44<01:25,  8.42it/s] 25%|██▌       | 245/966 [00:44<01:25,  8.43it/s] 25%|██▌       | 246/966 [00:44<01:25,  8.43it/s] 26%|██▌       | 247/966 [00:44<01:25,  8.44it/s] 26%|██▌       | 248/966 [00:44<01:25,  8.44it/s] 26%|██▌       | 249/966 [00:45<01:24,  8.44it/s] 26%|██▌       | 250/966 [00:45<01:24,  8.45it/s] 26%|██▌       | 251/966 [00:45<01:24,  8.44it/s] 26%|██▌       | 252/966 [00:45<01:24,  8.44it/s] 26%|██▌       | 253/966 [00:45<01:24,  8.44it/s] 26%|██▋       | 254/966 [00:45<01:24,  8.44it/s] 26%|██▋       | 255/966 [00:45<01:24,  8.44it/s] 27%|██▋       | 256/966 [00:45<01:24,  8.44it/s] 27%|██▋       | 257/966 [00:45<01:24,  8.44it/s] 27%|██▋       | 258/966 [00:46<01:23,  8.43it/s] 27%|██▋       | 259/966 [00:46<01:23,  8.42it/s] 27%|██▋       | 260/966 [00:46<01:23,  8.43it/s] 27%|██▋       | 261/966 [00:46<01:23,  8.43it/s] 27%|██▋       | 262/966 [00:46<01:23,  8.43it/s] 27%|██▋       | 263/966 [00:46<01:23,  8.43it/s] 27%|██▋       | 264/966 [00:46<01:23,  8.43it/s] 27%|██▋       | 265/966 [00:46<01:23,  8.42it/s] 28%|██▊       | 266/966 [00:47<01:23,  8.41it/s] 28%|██▊       | 267/966 [00:47<01:23,  8.42it/s] 28%|██▊       | 268/966 [00:47<01:22,  8.41it/s] 28%|██▊       | 269/966 [00:47<01:22,  8.42it/s] 28%|██▊       | 270/966 [00:47<01:22,  8.42it/s] 28%|██▊       | 271/966 [00:47<01:22,  8.42it/s] 28%|██▊       | 272/966 [00:47<01:22,  8.42it/s] 28%|██▊       | 273/966 [00:47<01:22,  8.42it/s] 28%|██▊       | 274/966 [00:47<01:22,  8.41it/s] 28%|██▊       | 275/966 [00:48<01:22,  8.40it/s] 29%|██▊       | 276/966 [00:48<01:22,  8.41it/s] 29%|██▊       | 277/966 [00:48<01:22,  8.40it/s] 29%|██▉       | 278/966 [00:48<01:21,  8.41it/s] 29%|██▉       | 279/966 [00:48<01:21,  8.41it/s] 29%|██▉       | 280/966 [00:48<01:21,  8.40it/s] 29%|██▉       | 281/966 [00:48<01:21,  8.41it/s] 29%|██▉       | 282/966 [00:48<01:21,  8.42it/s] 29%|██▉       | 283/966 [00:49<01:21,  8.42it/s] 29%|██▉       | 284/966 [00:49<01:21,  8.42it/s] 30%|██▉       | 285/966 [00:49<01:20,  8.42it/s] 30%|██▉       | 286/966 [00:49<01:20,  8.42it/s] 30%|██▉       | 287/966 [00:49<01:20,  8.42it/s] 30%|██▉       | 288/966 [00:49<01:20,  8.41it/s] 30%|██▉       | 289/966 [00:49<01:20,  8.43it/s] 30%|███       | 290/966 [00:49<01:20,  8.43it/s] 30%|███       | 291/966 [00:50<01:20,  8.42it/s] 30%|███       | 292/966 [00:50<01:19,  8.43it/s] 30%|███       | 293/966 [00:50<01:19,  8.43it/s] 30%|███       | 294/966 [00:50<01:19,  8.42it/s] 31%|███       | 295/966 [00:50<01:19,  8.42it/s] 31%|███       | 296/966 [00:50<01:19,  8.42it/s] 31%|███       | 297/966 [00:50<01:19,  8.42it/s] 31%|███       | 298/966 [00:50<01:19,  8.43it/s] 31%|███       | 299/966 [00:50<01:19,  8.42it/s] 31%|███       | 300/966 [00:51<01:19,  8.42it/s] 31%|███       | 301/966 [00:51<01:19,  8.41it/s] 31%|███▏      | 302/966 [00:51<01:18,  8.43it/s] 31%|███▏      | 303/966 [00:51<01:18,  8.44it/s] 31%|███▏      | 304/966 [00:51<01:18,  8.43it/s] 32%|███▏      | 305/966 [00:51<01:18,  8.42it/s] 32%|███▏      | 306/966 [00:51<01:18,  8.41it/s] 32%|███▏      | 307/966 [00:51<01:18,  8.41it/s] 32%|███▏      | 308/966 [00:52<01:18,  8.41it/s] 32%|███▏      | 309/966 [00:52<01:18,  8.40it/s] 32%|███▏      | 310/966 [00:52<01:18,  8.40it/s] 32%|███▏      | 311/966 [00:52<01:17,  8.40it/s] 32%|███▏      | 312/966 [00:52<01:17,  8.40it/s] 32%|███▏      | 313/966 [00:52<01:17,  8.41it/s] 33%|███▎      | 314/966 [00:52<01:17,  8.40it/s] 33%|███▎      | 315/966 [00:52<01:17,  8.40it/s] 33%|███▎      | 316/966 [00:52<01:17,  8.41it/s] 33%|███▎      | 317/966 [00:53<01:17,  8.40it/s] 33%|███▎      | 318/966 [00:53<01:17,  8.41it/s] 33%|███▎      | 319/966 [00:53<01:16,  8.40it/s] 33%|███▎      | 320/966 [00:53<01:16,  8.40it/s] 33%|███▎      | 321/966 [00:53<01:16,  8.41it/s] 33%|███▎      | 322/966 [00:53<01:16,  8.41it/s] 33%|███▎      | 323/966 [00:53<01:16,  8.41it/s] 34%|███▎      | 324/966 [00:53<01:16,  8.42it/s] 34%|███▎      | 325/966 [00:54<01:16,  8.42it/s] 34%|███▎      | 326/966 [00:54<01:16,  8.41it/s] 34%|███▍      | 327/966 [00:54<01:16,  8.41it/s] 34%|███▍      | 328/966 [00:54<01:15,  8.41it/s] 34%|███▍      | 329/966 [00:54<01:15,  8.41it/s] 34%|███▍      | 330/966 [00:54<01:15,  8.41it/s] 34%|███▍      | 331/966 [00:54<01:15,  8.42it/s] 34%|███▍      | 332/966 [00:54<01:15,  8.42it/s] 34%|███▍      | 333/966 [00:54<01:15,  8.42it/s] 35%|███▍      | 334/966 [00:55<01:15,  8.42it/s] 35%|███▍      | 335/966 [00:55<01:14,  8.42it/s] 35%|███▍      | 336/966 [00:55<01:14,  8.41it/s] 35%|███▍      | 337/966 [00:55<01:14,  8.42it/s] 35%|███▍      | 338/966 [00:55<01:14,  8.42it/s] 35%|███▌      | 339/966 [00:55<01:14,  8.42it/s] 35%|███▌      | 340/966 [00:55<01:14,  8.42it/s] 35%|███▌      | 341/966 [00:55<01:14,  8.43it/s] 35%|███▌      | 342/966 [00:56<01:14,  8.43it/s] 36%|███▌      | 343/966 [00:56<01:13,  8.42it/s] 36%|███▌      | 344/966 [00:56<01:13,  8.42it/s] 36%|███▌      | 345/966 [00:56<01:13,  8.42it/s] 36%|███▌      | 346/966 [00:56<01:13,  8.42it/s] 36%|███▌      | 347/966 [00:56<01:13,  8.41it/s] 36%|███▌      | 348/966 [00:56<01:13,  8.42it/s] 36%|███▌      | 349/966 [00:56<01:13,  8.42it/s] 36%|███▌      | 350/966 [00:57<01:13,  8.43it/s] 36%|███▋      | 351/966 [00:57<01:13,  8.42it/s] 36%|███▋      | 352/966 [00:57<01:12,  8.42it/s] 37%|███▋      | 353/966 [00:57<01:12,  8.41it/s] 37%|███▋      | 354/966 [00:57<01:12,  8.42it/s] 37%|███▋      | 355/966 [00:57<01:12,  8.41it/s] 37%|███▋      | 356/966 [00:57<01:12,  8.41it/s] 37%|███▋      | 357/966 [00:57<01:12,  8.40it/s] 37%|███▋      | 358/966 [00:57<01:12,  8.40it/s] 37%|███▋      | 359/966 [00:58<01:12,  8.40it/s] 37%|███▋      | 360/966 [00:58<01:11,  8.42it/s] 37%|███▋      | 361/966 [00:58<01:11,  8.41it/s] 37%|███▋      | 362/966 [00:58<01:11,  8.41it/s] 38%|███▊      | 363/966 [00:58<01:11,  8.41it/s] 38%|███▊      | 364/966 [00:58<01:11,  8.41it/s] 38%|███▊      | 365/966 [00:58<01:11,  8.40it/s] 38%|███▊      | 366/966 [00:58<01:11,  8.41it/s] 38%|███▊      | 367/966 [00:59<01:11,  8.42it/s] 38%|███▊      | 368/966 [00:59<01:11,  8.42it/s] 38%|███▊      | 369/966 [00:59<01:10,  8.41it/s] 38%|███▊      | 370/966 [00:59<01:10,  8.41it/s] 38%|███▊      | 371/966 [00:59<01:10,  8.41it/s] 39%|███▊      | 372/966 [00:59<01:10,  8.40it/s] 39%|███▊      | 373/966 [00:59<01:10,  8.41it/s] 39%|███▊      | 374/966 [00:59<01:10,  8.42it/s] 39%|███▉      | 375/966 [00:59<01:10,  8.42it/s] 39%|███▉      | 376/966 [01:00<01:10,  8.41it/s] 39%|███▉      | 377/966 [01:00<01:10,  8.41it/s] 39%|███▉      | 378/966 [01:00<01:09,  8.41it/s] 39%|███▉      | 379/966 [01:00<01:09,  8.41it/s] 39%|███▉      | 380/966 [01:00<01:09,  8.41it/s] 39%|███▉      | 381/966 [01:00<01:09,  8.41it/s] 40%|███▉      | 382/966 [01:00<01:09,  8.40it/s] 40%|███▉      | 383/966 [01:00<01:09,  8.40it/s] 40%|███▉      | 384/966 [01:01<01:09,  8.40it/s] 40%|███▉      | 385/966 [01:01<01:09,  8.41it/s] 40%|███▉      | 386/966 [01:01<01:08,  8.42it/s] 40%|████      | 387/966 [01:01<01:08,  8.42it/s] 40%|████      | 388/966 [01:01<01:08,  8.42it/s] 40%|████      | 389/966 [01:01<01:08,  8.42it/s] 40%|████      | 390/966 [01:01<01:08,  8.43it/s] 40%|████      | 391/966 [01:01<01:08,  8.43it/s] 41%|████      | 392/966 [01:02<01:08,  8.43it/s] 41%|████      | 393/966 [01:02<01:08,  8.42it/s] 41%|████      | 394/966 [01:02<01:08,  8.41it/s] 41%|████      | 395/966 [01:02<01:07,  8.41it/s] 41%|████      | 396/966 [01:02<01:07,  8.40it/s] 41%|████      | 397/966 [01:02<01:07,  8.40it/s] 41%|████      | 398/966 [01:02<01:07,  8.41it/s] 41%|████▏     | 399/966 [01:02<01:07,  8.40it/s] 41%|████▏     | 400/966 [01:02<01:07,  8.40it/s] 42%|████▏     | 401/966 [01:03<01:07,  8.41it/s] 42%|████▏     | 402/966 [01:03<01:07,  8.41it/s] 42%|████▏     | 403/966 [01:03<01:06,  8.41it/s] 42%|████▏     | 404/966 [01:03<01:06,  8.42it/s] 42%|████▏     | 405/966 [01:03<01:06,  8.42it/s] 42%|████▏     | 406/966 [01:03<01:06,  8.41it/s] 42%|████▏     | 407/966 [01:03<01:06,  8.41it/s] 42%|████▏     | 408/966 [01:03<01:06,  8.41it/s] 42%|████▏     | 409/966 [01:04<01:06,  8.41it/s] 42%|████▏     | 410/966 [01:04<01:06,  8.41it/s] 43%|████▎     | 411/966 [01:04<01:05,  8.43it/s] 43%|████▎     | 412/966 [01:04<01:05,  8.42it/s] 43%|████▎     | 413/966 [01:04<01:05,  8.41it/s] 43%|████▎     | 414/966 [01:04<01:05,  8.42it/s] 43%|████▎     | 415/966 [01:04<01:05,  8.41it/s] 43%|████▎     | 416/966 [01:04<01:05,  8.41it/s] 43%|████▎     | 417/966 [01:04<01:05,  8.41it/s] 43%|████▎     | 418/966 [01:05<01:05,  8.41it/s] 43%|████▎     | 419/966 [01:05<01:05,  8.41it/s] 43%|████▎     | 420/966 [01:05<01:04,  8.40it/s] 44%|████▎     | 421/966 [01:05<01:04,  8.41it/s] 44%|████▎     | 422/966 [01:05<01:04,  8.41it/s] 44%|████▍     | 423/966 [01:05<01:04,  8.41it/s] 44%|████▍     | 424/966 [01:05<01:04,  8.40it/s] 44%|████▍     | 425/966 [01:05<01:04,  8.41it/s] 44%|████▍     | 426/966 [01:06<01:04,  8.40it/s] 44%|████▍     | 427/966 [01:06<01:04,  8.41it/s] 44%|████▍     | 428/966 [01:06<01:03,  8.41it/s] 44%|████▍     | 429/966 [01:06<01:03,  8.41it/s] 45%|████▍     | 430/966 [01:06<01:03,  8.40it/s] 45%|████▍     | 431/966 [01:06<01:03,  8.42it/s] 45%|████▍     | 432/966 [01:06<01:03,  8.43it/s] 45%|████▍     | 433/966 [01:06<01:03,  8.44it/s] 45%|████▍     | 434/966 [01:06<01:03,  8.42it/s] 45%|████▌     | 435/966 [01:07<01:03,  8.42it/s] 45%|████▌     | 436/966 [01:07<01:02,  8.42it/s] 45%|████▌     | 437/966 [01:07<01:02,  8.42it/s] 45%|████▌     | 438/966 [01:07<01:02,  8.41it/s] 45%|████▌     | 439/966 [01:07<01:02,  8.40it/s] 46%|████▌     | 440/966 [01:07<01:02,  8.40it/s] 46%|████▌     | 441/966 [01:07<01:02,  8.40it/s] 46%|████▌     | 442/966 [01:07<01:02,  8.40it/s] 46%|████▌     | 443/966 [01:08<01:02,  8.40it/s] 46%|████▌     | 444/966 [01:08<01:02,  8.40it/s] 46%|████▌     | 445/966 [01:08<01:01,  8.41it/s] 46%|████▌     | 446/966 [01:08<01:01,  8.41it/s] 46%|████▋     | 447/966 [01:08<01:01,  8.41it/s] 46%|████▋     | 448/966 [01:08<01:01,  8.41it/s] 46%|████▋     | 449/966 [01:08<01:01,  8.41it/s] 47%|████▋     | 450/966 [01:08<01:01,  8.40it/s] 47%|████▋     | 451/966 [01:09<01:01,  8.41it/s] 47%|████▋     | 452/966 [01:09<01:01,  8.41it/s] 47%|████▋     | 453/966 [01:09<01:01,  8.40it/s] 47%|████▋     | 454/966 [01:09<01:00,  8.40it/s] 47%|████▋     | 455/966 [01:09<01:00,  8.40it/s] 47%|████▋     | 456/966 [01:09<01:00,  8.41it/s] 47%|████▋     | 457/966 [01:09<01:00,  8.42it/s] 47%|████▋     | 458/966 [01:09<01:00,  8.43it/s] 48%|████▊     | 459/966 [01:09<01:00,  8.43it/s] 48%|████▊     | 460/966 [01:10<01:00,  8.41it/s] 48%|████▊     | 461/966 [01:10<01:00,  8.39it/s] 48%|████▊     | 462/966 [01:10<00:59,  8.41it/s] 48%|████▊     | 463/966 [01:10<00:59,  8.42it/s] 48%|████▊     | 464/966 [01:10<00:59,  8.43it/s] 48%|████▊     | 465/966 [01:10<00:59,  8.44it/s] 48%|████▊     | 466/966 [01:10<00:59,  8.43it/s] 48%|████▊     | 467/966 [01:10<00:59,  8.43it/s] 48%|████▊     | 468/966 [01:11<00:59,  8.42it/s] 49%|████▊     | 469/966 [01:11<00:58,  8.43it/s] 49%|████▊     | 470/966 [01:11<00:58,  8.43it/s] 49%|████▉     | 471/966 [01:11<00:58,  8.41it/s] 49%|████▉     | 472/966 [01:11<00:58,  8.42it/s] 49%|████▉     | 473/966 [01:11<00:58,  8.42it/s] 49%|████▉     | 474/966 [01:11<00:58,  8.40it/s] 49%|████▉     | 475/966 [01:11<00:58,  8.40it/s] 49%|████▉     | 476/966 [01:11<00:58,  8.40it/s] 49%|████▉     | 477/966 [01:12<00:58,  8.41it/s] 49%|████▉     | 478/966 [01:12<00:58,  8.41it/s] 50%|████▉     | 479/966 [01:12<00:57,  8.40it/s] 50%|████▉     | 480/966 [01:12<00:57,  8.41it/s] 50%|████▉     | 481/966 [01:12<00:57,  8.40it/s] 50%|████▉     | 482/966 [01:12<00:57,  8.40it/s] 50%|█████     | 483/966 [01:12<00:57,  8.40it/s] 50%|█████     | 484/966 [01:12<00:57,  8.41it/s] 50%|█████     | 485/966 [01:13<00:57,  8.41it/s] 50%|█████     | 486/966 [01:13<00:57,  8.40it/s] 50%|█████     | 487/966 [01:13<00:57,  8.39it/s] 51%|█████     | 488/966 [01:13<00:56,  8.40it/s] 51%|█████     | 489/966 [01:13<00:56,  8.40it/s] 51%|█████     | 490/966 [01:13<00:56,  8.40it/s] 51%|█████     | 491/966 [01:13<00:56,  8.40it/s] 51%|█████     | 492/966 [01:13<00:56,  8.40it/s] 51%|█████     | 493/966 [01:14<00:56,  8.41it/s] 51%|█████     | 494/966 [01:14<00:56,  8.40it/s] 51%|█████     | 495/966 [01:14<00:55,  8.41it/s] 51%|█████▏    | 496/966 [01:14<00:55,  8.41it/s] 51%|█████▏    | 497/966 [01:14<00:55,  8.40it/s] 52%|█████▏    | 498/966 [01:14<00:55,  8.39it/s] 52%|█████▏    | 499/966 [01:14<00:55,  8.40it/s] 52%|█████▏    | 500/966 [01:14<00:55,  8.40it/s] 52%|█████▏    | 501/966 [01:14<00:55,  8.40it/s] 52%|█████▏    | 502/966 [01:15<00:55,  8.41it/s] 52%|█████▏    | 503/966 [01:15<00:55,  8.39it/s] 52%|█████▏    | 504/966 [01:15<00:54,  8.40it/s] 52%|█████▏    | 505/966 [01:15<00:54,  8.40it/s] 52%|█████▏    | 506/966 [01:15<00:54,  8.40it/s] 52%|█████▏    | 507/966 [01:15<00:54,  8.40it/s] 53%|█████▎    | 508/966 [01:15<00:54,  8.41it/s] 53%|█████▎    | 509/966 [01:15<00:54,  8.41it/s] 53%|█████▎    | 510/966 [01:16<00:54,  8.40it/s] 53%|█████▎    | 511/966 [01:16<00:54,  8.40it/s] 53%|█████▎    | 512/966 [01:16<00:53,  8.42it/s] 53%|█████▎    | 513/966 [01:16<00:53,  8.42it/s] 53%|█████▎    | 514/966 [01:16<00:53,  8.42it/s] 53%|█████▎    | 515/966 [01:16<00:53,  8.41it/s] 53%|█████▎    | 516/966 [01:16<00:53,  8.40it/s] 54%|█████▎    | 517/966 [01:16<00:53,  8.41it/s] 54%|█████▎    | 518/966 [01:16<00:53,  8.40it/s] 54%|█████▎    | 519/966 [01:17<00:53,  8.40it/s] 54%|█████▍    | 520/966 [01:17<00:53,  8.40it/s] 54%|█████▍    | 521/966 [01:17<00:52,  8.40it/s] 54%|█████▍    | 522/966 [01:17<00:52,  8.40it/s] 54%|█████▍    | 523/966 [01:17<00:52,  8.40it/s] 54%|█████▍    | 524/966 [01:17<00:52,  8.40it/s] 54%|█████▍    | 525/966 [01:17<00:52,  8.39it/s] 54%|█████▍    | 526/966 [01:17<00:52,  8.40it/s] 55%|█████▍    | 527/966 [01:18<00:52,  8.40it/s] 55%|█████▍    | 528/966 [01:18<00:52,  8.39it/s] 55%|█████▍    | 529/966 [01:18<00:52,  8.39it/s] 55%|█████▍    | 530/966 [01:18<00:51,  8.40it/s] 55%|█████▍    | 531/966 [01:18<00:51,  8.40it/s] 55%|█████▌    | 532/966 [01:18<00:51,  8.40it/s] 55%|█████▌    | 533/966 [01:18<00:51,  8.39it/s] 55%|█████▌    | 534/966 [01:18<00:51,  8.39it/s] 55%|█████▌    | 535/966 [01:19<00:51,  8.40it/s] 55%|█████▌    | 536/966 [01:19<00:51,  8.39it/s] 56%|█████▌    | 537/966 [01:19<00:51,  8.40it/s] 56%|█████▌    | 538/966 [01:19<00:50,  8.41it/s] 56%|█████▌    | 539/966 [01:19<00:50,  8.40it/s] 56%|█████▌    | 540/966 [01:19<00:50,  8.41it/s] 56%|█████▌    | 541/966 [01:19<00:50,  8.43it/s] 56%|█████▌    | 542/966 [01:19<00:50,  8.41it/s] 56%|█████▌    | 543/966 [01:19<00:50,  8.40it/s] 56%|█████▋    | 544/966 [01:20<00:50,  8.40it/s] 56%|█████▋    | 545/966 [01:20<00:50,  8.40it/s] 57%|█████▋    | 546/966 [01:20<00:50,  8.40it/s] 57%|█████▋    | 547/966 [01:20<00:49,  8.41it/s] 57%|█████▋    | 548/966 [01:20<00:49,  8.41it/s] 57%|█████▋    | 549/966 [01:20<00:49,  8.42it/s] 57%|█████▋    | 550/966 [01:20<00:49,  8.41it/s] 57%|█████▋    | 551/966 [01:20<00:49,  8.41it/s] 57%|█████▋    | 552/966 [01:21<00:49,  8.41it/s] 57%|█████▋    | 553/966 [01:21<00:49,  8.41it/s] 57%|█████▋    | 554/966 [01:21<00:48,  8.41it/s] 57%|█████▋    | 555/966 [01:21<00:48,  8.41it/s] 58%|█████▊    | 556/966 [01:21<00:48,  8.41it/s] 58%|█████▊    | 557/966 [01:21<00:48,  8.40it/s] 58%|█████▊    | 558/966 [01:21<00:48,  8.41it/s] 58%|█████▊    | 559/966 [01:21<00:48,  8.41it/s] 58%|█████▊    | 560/966 [01:21<00:48,  8.41it/s] 58%|█████▊    | 561/966 [01:22<00:48,  8.41it/s] 58%|█████▊    | 562/966 [01:22<00:48,  8.41it/s] 58%|█████▊    | 563/966 [01:22<00:47,  8.40it/s] 58%|█████▊    | 564/966 [01:22<00:47,  8.39it/s] 58%|█████▊    | 565/966 [01:22<00:47,  8.40it/s] 59%|█████▊    | 566/966 [01:22<00:47,  8.40it/s] 59%|█████▊    | 567/966 [01:22<00:47,  8.39it/s] 59%|█████▉    | 568/966 [01:22<00:47,  8.39it/s] 59%|█████▉    | 569/966 [01:23<00:47,  8.40it/s] 59%|█████▉    | 570/966 [01:23<00:47,  8.40it/s] 59%|█████▉    | 571/966 [01:23<00:47,  8.40it/s] 59%|█████▉    | 572/966 [01:23<00:46,  8.40it/s] 59%|█████▉    | 573/966 [01:23<00:46,  8.40it/s] 59%|█████▉    | 574/966 [01:23<00:46,  8.40it/s] 60%|█████▉    | 575/966 [01:23<00:46,  8.39it/s] 60%|█████▉    | 576/966 [01:23<00:46,  8.39it/s] 60%|█████▉    | 577/966 [01:24<00:46,  8.40it/s] 60%|█████▉    | 578/966 [01:24<00:46,  8.40it/s] 60%|█████▉    | 579/966 [01:24<00:46,  8.39it/s] 60%|██████    | 580/966 [01:24<00:45,  8.40it/s] 60%|██████    | 581/966 [01:24<00:45,  8.40it/s] 60%|██████    | 582/966 [01:24<00:45,  8.40it/s] 60%|██████    | 583/966 [01:24<00:45,  8.40it/s] 60%|██████    | 584/966 [01:24<00:45,  8.41it/s] 61%|██████    | 585/966 [01:24<00:45,  8.40it/s] 61%|██████    | 586/966 [01:25<00:45,  8.40it/s] 61%|██████    | 587/966 [01:25<00:45,  8.41it/s] 61%|██████    | 588/966 [01:25<00:44,  8.41it/s] 61%|██████    | 589/966 [01:25<00:44,  8.41it/s] 61%|██████    | 590/966 [01:25<00:44,  8.41it/s] 61%|██████    | 591/966 [01:25<00:44,  8.40it/s] 61%|██████▏   | 592/966 [01:25<00:44,  8.40it/s] 61%|██████▏   | 593/966 [01:25<00:44,  8.40it/s] 61%|██████▏   | 594/966 [01:26<00:44,  8.40it/s] 62%|██████▏   | 595/966 [01:26<00:44,  8.40it/s] 62%|██████▏   | 596/966 [01:26<00:43,  8.41it/s] 62%|██████▏   | 597/966 [01:26<00:43,  8.41it/s] 62%|██████▏   | 598/966 [01:26<00:43,  8.39it/s] 62%|██████▏   | 599/966 [01:26<00:43,  8.39it/s] 62%|██████▏   | 600/966 [01:26<00:43,  8.39it/s] 62%|██████▏   | 601/966 [01:26<00:43,  8.39it/s] 62%|██████▏   | 602/966 [01:26<00:43,  8.40it/s] 62%|██████▏   | 603/966 [01:27<00:43,  8.39it/s] 63%|██████▎   | 604/966 [01:27<00:43,  8.40it/s] 63%|██████▎   | 605/966 [01:27<00:43,  8.39it/s] 63%|██████▎   | 606/966 [01:27<00:42,  8.39it/s] 63%|██████▎   | 607/966 [01:27<00:42,  8.39it/s] 63%|██████▎   | 608/966 [01:27<00:42,  8.39it/s] 63%|██████▎   | 609/966 [01:27<00:42,  8.40it/s] 63%|██████▎   | 610/966 [01:27<00:42,  8.39it/s] 63%|██████▎   | 611/966 [01:28<00:42,  8.38it/s] 63%|██████▎   | 612/966 [01:28<00:42,  8.39it/s] 63%|██████▎   | 613/966 [01:28<00:42,  8.39it/s] 64%|██████▎   | 614/966 [01:28<00:41,  8.39it/s] 64%|██████▎   | 615/966 [01:28<00:41,  8.38it/s] 64%|██████▍   | 616/966 [01:28<00:41,  8.39it/s] 64%|██████▍   | 617/966 [01:28<00:41,  8.39it/s] 64%|██████▍   | 618/966 [01:28<00:41,  8.40it/s] 64%|██████▍   | 619/966 [01:29<00:41,  8.39it/s] 64%|██████▍   | 620/966 [01:29<00:41,  8.39it/s] 64%|██████▍   | 621/966 [01:29<00:41,  8.39it/s] 64%|██████▍   | 622/966 [01:29<00:41,  8.39it/s] 64%|██████▍   | 623/966 [01:29<00:40,  8.38it/s] 65%|██████▍   | 624/966 [01:29<00:40,  8.39it/s] 65%|██████▍   | 625/966 [01:29<00:40,  8.41it/s] 65%|██████▍   | 626/966 [01:29<00:40,  8.41it/s] 65%|██████▍   | 627/966 [01:29<00:40,  8.41it/s] 65%|██████▌   | 628/966 [01:30<00:40,  8.41it/s] 65%|██████▌   | 629/966 [01:30<00:40,  8.41it/s] 65%|██████▌   | 630/966 [01:30<00:39,  8.40it/s] 65%|██████▌   | 631/966 [01:30<00:39,  8.40it/s] 65%|██████▌   | 632/966 [01:30<00:39,  8.40it/s] 66%|██████▌   | 633/966 [01:30<00:39,  8.39it/s] 66%|██████▌   | 634/966 [01:30<00:39,  8.39it/s] 66%|██████▌   | 635/966 [01:30<00:39,  8.39it/s] 66%|██████▌   | 636/966 [01:31<00:39,  8.39it/s] 66%|██████▌   | 637/966 [01:31<00:39,  8.39it/s] 66%|██████▌   | 638/966 [01:31<00:39,  8.39it/s] 66%|██████▌   | 639/966 [01:31<00:38,  8.40it/s] 66%|██████▋   | 640/966 [01:31<00:38,  8.39it/s] 66%|██████▋   | 641/966 [01:31<00:38,  8.39it/s] 66%|██████▋   | 642/966 [01:31<00:38,  8.40it/s] 67%|██████▋   | 643/966 [01:31<00:38,  8.39it/s] 67%|██████▋   | 644/966 [01:31<00:38,  8.40it/s] 67%|██████▋   | 645/966 [01:32<00:38,  8.40it/s] 67%|██████▋   | 646/966 [01:32<00:38,  8.40it/s] 67%|██████▋   | 647/966 [01:32<00:37,  8.40it/s] 67%|██████▋   | 648/966 [01:32<00:37,  8.40it/s] 67%|██████▋   | 649/966 [01:32<00:37,  8.40it/s] 67%|██████▋   | 650/966 [01:32<00:37,  8.39it/s] 67%|██████▋   | 651/966 [01:32<00:37,  8.40it/s] 67%|██████▋   | 652/966 [01:32<00:37,  8.40it/s] 68%|██████▊   | 653/966 [01:33<00:37,  8.38it/s] 68%|██████▊   | 654/966 [01:33<00:37,  8.38it/s] 68%|██████▊   | 655/966 [01:33<00:37,  8.39it/s] 68%|██████▊   | 656/966 [01:33<00:36,  8.39it/s] 68%|██████▊   | 657/966 [01:33<00:36,  8.39it/s] 68%|██████▊   | 658/966 [01:33<00:36,  8.39it/s] 68%|██████▊   | 659/966 [01:33<00:36,  8.39it/s] 68%|██████▊   | 660/966 [01:33<00:36,  8.39it/s] 68%|██████▊   | 661/966 [01:34<00:36,  8.39it/s] 69%|██████▊   | 662/966 [01:34<00:36,  8.39it/s] 69%|██████▊   | 663/966 [01:34<00:36,  8.39it/s] 69%|██████▊   | 664/966 [01:34<00:36,  8.39it/s] 69%|██████▉   | 665/966 [01:34<00:35,  8.39it/s] 69%|██████▉   | 666/966 [01:34<00:35,  8.40it/s] 69%|██████▉   | 667/966 [01:34<00:35,  8.42it/s] 69%|██████▉   | 668/966 [01:34<00:35,  8.40it/s] 69%|██████▉   | 669/966 [01:34<00:35,  8.40it/s] 69%|██████▉   | 670/966 [01:35<00:35,  8.39it/s] 69%|██████▉   | 671/966 [01:35<00:35,  8.39it/s] 70%|██████▉   | 672/966 [01:35<00:35,  8.40it/s] 70%|██████▉   | 673/966 [01:35<00:34,  8.40it/s] 70%|██████▉   | 674/966 [01:35<00:34,  8.40it/s] 70%|██████▉   | 675/966 [01:35<00:34,  8.40it/s] 70%|██████▉   | 676/966 [01:35<00:34,  8.40it/s] 70%|███████   | 677/966 [01:35<00:34,  8.39it/s] 70%|███████   | 678/966 [01:36<00:34,  8.39it/s] 70%|███████   | 679/966 [01:36<00:34,  8.40it/s] 70%|███████   | 680/966 [01:36<00:34,  8.40it/s] 70%|███████   | 681/966 [01:36<00:33,  8.39it/s] 71%|███████   | 682/966 [01:36<00:33,  8.39it/s] 71%|███████   | 683/966 [01:36<00:33,  8.40it/s] 71%|███████   | 684/966 [01:36<00:33,  8.41it/s] 71%|███████   | 685/966 [01:36<00:33,  8.40it/s] 71%|███████   | 686/966 [01:36<00:33,  8.39it/s] 71%|███████   | 687/966 [01:37<00:33,  8.39it/s] 71%|███████   | 688/966 [01:37<00:33,  8.39it/s] 71%|███████▏  | 689/966 [01:37<00:33,  8.38it/s] 71%|███████▏  | 690/966 [01:37<00:32,  8.38it/s] 72%|███████▏  | 691/966 [01:37<00:32,  8.38it/s] 72%|███████▏  | 692/966 [01:37<00:32,  8.39it/s] 72%|███████▏  | 693/966 [01:37<00:32,  8.38it/s] 72%|███████▏  | 694/966 [01:37<00:32,  8.38it/s] 72%|███████▏  | 695/966 [01:38<00:32,  8.38it/s] 72%|███████▏  | 696/966 [01:38<00:32,  8.38it/s] 72%|███████▏  | 697/966 [01:38<00:32,  8.39it/s] 72%|███████▏  | 698/966 [01:38<00:31,  8.39it/s] 72%|███████▏  | 699/966 [01:38<00:31,  8.38it/s] 72%|███████▏  | 700/966 [01:38<00:31,  8.38it/s] 73%|███████▎  | 701/966 [01:38<00:31,  8.39it/s] 73%|███████▎  | 702/966 [01:38<00:31,  8.39it/s] 73%|███████▎  | 703/966 [01:39<00:31,  8.38it/s] 73%|███████▎  | 704/966 [01:39<00:31,  8.40it/s] 73%|███████▎  | 705/966 [01:39<00:31,  8.40it/s] 73%|███████▎  | 706/966 [01:39<00:30,  8.40it/s] 73%|███████▎  | 707/966 [01:39<00:30,  8.39it/s] 73%|███████▎  | 708/966 [01:39<00:30,  8.39it/s] 73%|███████▎  | 709/966 [01:39<00:30,  8.40it/s] 73%|███████▎  | 710/966 [01:39<00:30,  8.40it/s] 74%|███████▎  | 711/966 [01:39<00:30,  8.40it/s] 74%|███████▎  | 712/966 [01:40<00:30,  8.38it/s] 74%|███████▍  | 713/966 [01:40<00:30,  8.38it/s] 74%|███████▍  | 714/966 [01:40<00:30,  8.39it/s] 74%|███████▍  | 715/966 [01:40<00:29,  8.40it/s] 74%|███████▍  | 716/966 [01:40<00:29,  8.40it/s] 74%|███████▍  | 717/966 [01:40<00:29,  8.40it/s] 74%|███████▍  | 718/966 [01:40<00:29,  8.39it/s] 74%|███████▍  | 719/966 [01:40<00:29,  8.38it/s] 75%|███████▍  | 720/966 [01:41<00:29,  8.38it/s] 75%|███████▍  | 721/966 [01:41<00:29,  8.39it/s] 75%|███████▍  | 722/966 [01:41<00:29,  8.39it/s] 75%|███████▍  | 723/966 [01:41<00:28,  8.39it/s] 75%|███████▍  | 724/966 [01:41<00:28,  8.39it/s] 75%|███████▌  | 725/966 [01:41<00:28,  8.39it/s] 75%|███████▌  | 726/966 [01:41<00:28,  8.39it/s] 75%|███████▌  | 727/966 [01:41<00:28,  8.38it/s] 75%|███████▌  | 728/966 [01:42<00:28,  8.38it/s] 75%|███████▌  | 729/966 [01:42<00:28,  8.38it/s] 76%|███████▌  | 730/966 [01:42<00:28,  8.38it/s] 76%|███████▌  | 731/966 [01:42<00:28,  8.38it/s] 76%|███████▌  | 732/966 [01:42<00:27,  8.39it/s] 76%|███████▌  | 733/966 [01:42<00:27,  8.39it/s] 76%|███████▌  | 734/966 [01:42<00:27,  8.39it/s] 76%|███████▌  | 735/966 [01:42<00:27,  8.38it/s] 76%|███████▌  | 736/966 [01:42<00:27,  8.38it/s] 76%|███████▋  | 737/966 [01:43<00:27,  8.39it/s] 76%|███████▋  | 738/966 [01:43<00:27,  8.38it/s] 77%|███████▋  | 739/966 [01:43<00:27,  8.39it/s] 77%|███████▋  | 740/966 [01:43<00:26,  8.38it/s] 77%|███████▋  | 741/966 [01:43<00:26,  8.38it/s] 77%|███████▋  | 742/966 [01:43<00:26,  8.38it/s] 77%|███████▋  | 743/966 [01:43<00:26,  8.38it/s] 77%|███████▋  | 744/966 [01:43<00:26,  8.39it/s] 77%|███████▋  | 745/966 [01:44<00:26,  8.39it/s] 77%|███████▋  | 746/966 [01:44<00:26,  8.39it/s] 77%|███████▋  | 747/966 [01:44<00:26,  8.40it/s] 77%|███████▋  | 748/966 [01:44<00:25,  8.39it/s] 78%|███████▊  | 749/966 [01:44<00:25,  8.38it/s] 78%|███████▊  | 750/966 [01:44<00:25,  8.39it/s] 78%|███████▊  | 751/966 [01:44<00:25,  8.39it/s] 78%|███████▊  | 752/966 [01:44<00:25,  8.39it/s] 78%|███████▊  | 753/966 [01:44<00:25,  8.39it/s] 78%|███████▊  | 754/966 [01:45<00:25,  8.40it/s] 78%|███████▊  | 755/966 [01:45<00:25,  8.39it/s] 78%|███████▊  | 756/966 [01:45<00:25,  8.38it/s] 78%|███████▊  | 757/966 [01:45<00:24,  8.40it/s] 78%|███████▊  | 758/966 [01:45<00:24,  8.40it/s] 79%|███████▊  | 759/966 [01:45<00:24,  8.41it/s] 79%|███████▊  | 760/966 [01:45<00:24,  8.40it/s] 79%|███████▉  | 761/966 [01:45<00:24,  8.39it/s] 79%|███████▉  | 762/966 [01:46<00:24,  8.39it/s] 79%|███████▉  | 763/966 [01:46<00:24,  8.39it/s] 79%|███████▉  | 764/966 [01:46<00:24,  8.39it/s] 79%|███████▉  | 765/966 [01:46<00:23,  8.39it/s] 79%|███████▉  | 766/966 [01:46<00:23,  8.38it/s] 79%|███████▉  | 767/966 [01:46<00:23,  8.39it/s] 80%|███████▉  | 768/966 [01:46<00:23,  8.38it/s] 80%|███████▉  | 769/966 [01:46<00:23,  8.39it/s] 80%|███████▉  | 770/966 [01:47<00:23,  8.39it/s] 80%|███████▉  | 771/966 [01:47<00:23,  8.39it/s] 80%|███████▉  | 772/966 [01:47<00:23,  8.39it/s] 80%|████████  | 773/966 [01:47<00:23,  8.39it/s] 80%|████████  | 774/966 [01:47<00:22,  8.38it/s] 80%|████████  | 775/966 [01:47<00:22,  8.38it/s] 80%|████████  | 776/966 [01:47<00:22,  8.38it/s] 80%|████████  | 777/966 [01:47<00:22,  8.39it/s] 81%|████████  | 778/966 [01:47<00:22,  8.38it/s] 81%|████████  | 779/966 [01:48<00:22,  8.38it/s] 81%|████████  | 780/966 [01:48<00:22,  8.39it/s] 81%|████████  | 781/966 [01:48<00:22,  8.38it/s] 81%|████████  | 782/966 [01:48<00:21,  8.38it/s] 81%|████████  | 783/966 [01:48<00:21,  8.38it/s] 81%|████████  | 784/966 [01:48<00:21,  8.38it/s] 81%|████████▏ | 785/966 [01:48<00:21,  8.38it/s] 81%|████████▏ | 786/966 [01:48<00:21,  8.38it/s] 81%|████████▏ | 787/966 [01:49<00:21,  8.38it/s] 82%|████████▏ | 788/966 [01:49<00:21,  8.38it/s] 82%|████████▏ | 789/966 [01:49<00:21,  8.38it/s] 82%|████████▏ | 790/966 [01:49<00:20,  8.39it/s] 82%|████████▏ | 791/966 [01:49<00:20,  8.40it/s] 82%|████████▏ | 792/966 [01:49<00:20,  8.39it/s] 82%|████████▏ | 793/966 [01:49<00:20,  8.41it/s] 82%|████████▏ | 794/966 [01:49<00:20,  8.40it/s] 82%|████████▏ | 795/966 [01:49<00:20,  8.39it/s] 82%|████████▏ | 796/966 [01:50<00:20,  8.38it/s] 83%|████████▎ | 797/966 [01:50<00:20,  8.38it/s] 83%|████████▎ | 798/966 [01:50<00:20,  8.39it/s] 83%|████████▎ | 799/966 [01:50<00:19,  8.39it/s] 83%|████████▎ | 800/966 [01:50<00:19,  8.40it/s] 83%|████████▎ | 801/966 [01:50<00:19,  8.40it/s] 83%|████████▎ | 802/966 [01:50<00:19,  8.40it/s] 83%|████████▎ | 803/966 [01:50<00:19,  8.40it/s] 83%|████████▎ | 804/966 [01:51<00:19,  8.40it/s] 83%|████████▎ | 805/966 [01:51<00:19,  8.39it/s] 83%|████████▎ | 806/966 [01:51<00:19,  8.39it/s] 84%|████████▎ | 807/966 [01:51<00:18,  8.39it/s] 84%|████████▎ | 808/966 [01:51<00:18,  8.39it/s] 84%|████████▎ | 809/966 [01:51<00:18,  8.39it/s] 84%|████████▍ | 810/966 [01:51<00:18,  8.39it/s] 84%|████████▍ | 811/966 [01:51<00:18,  8.39it/s] 84%|████████▍ | 812/966 [01:52<00:18,  8.39it/s] 84%|████████▍ | 813/966 [01:52<00:18,  8.39it/s] 84%|████████▍ | 814/966 [01:52<00:18,  8.40it/s] 84%|████████▍ | 815/966 [01:52<00:17,  8.40it/s] 84%|████████▍ | 816/966 [01:52<00:17,  8.40it/s] 85%|████████▍ | 817/966 [01:52<00:17,  8.39it/s] 85%|████████▍ | 818/966 [01:52<00:17,  8.39it/s] 85%|████████▍ | 819/966 [01:52<00:17,  8.39it/s] 85%|████████▍ | 820/966 [01:52<00:17,  8.38it/s] 85%|████████▍ | 821/966 [01:53<00:17,  8.38it/s] 85%|████████▌ | 822/966 [01:53<00:17,  8.39it/s] 85%|████████▌ | 823/966 [01:53<00:17,  8.39it/s] 85%|████████▌ | 824/966 [01:53<00:16,  8.38it/s] 85%|████████▌ | 825/966 [01:53<00:16,  8.38it/s] 86%|████████▌ | 826/966 [01:53<00:16,  8.38it/s] 86%|████████▌ | 827/966 [01:53<00:16,  8.38it/s] 86%|████████▌ | 828/966 [01:53<00:16,  8.38it/s] 86%|████████▌ | 829/966 [01:54<00:16,  8.39it/s] 86%|████████▌ | 830/966 [01:54<00:16,  8.39it/s] 86%|████████▌ | 831/966 [01:54<00:16,  8.39it/s] 86%|████████▌ | 832/966 [01:54<00:15,  8.38it/s] 86%|████████▌ | 833/966 [01:54<00:15,  8.38it/s] 86%|████████▋ | 834/966 [01:54<00:15,  8.39it/s] 86%|████████▋ | 835/966 [01:54<00:15,  8.41it/s] 87%|████████▋ | 836/966 [01:54<00:15,  8.41it/s] 87%|████████▋ | 837/966 [01:54<00:15,  8.40it/s] 87%|████████▋ | 838/966 [01:55<00:15,  8.40it/s] 87%|████████▋ | 839/966 [01:55<00:15,  8.39it/s] 87%|████████▋ | 840/966 [01:55<00:15,  8.39it/s] 87%|████████▋ | 841/966 [01:55<00:14,  8.40it/s] 87%|████████▋ | 842/966 [01:55<00:14,  8.41it/s] 87%|████████▋ | 843/966 [01:55<00:14,  8.41it/s] 87%|████████▋ | 844/966 [01:55<00:14,  8.41it/s] 87%|████████▋ | 845/966 [01:55<00:14,  8.41it/s] 88%|████████▊ | 846/966 [01:56<00:14,  8.40it/s] 88%|████████▊ | 847/966 [01:56<00:14,  8.41it/s] 88%|████████▊ | 848/966 [01:56<00:14,  8.41it/s] 88%|████████▊ | 849/966 [01:56<00:13,  8.39it/s] 88%|████████▊ | 850/966 [01:56<00:13,  8.38it/s] 88%|████████▊ | 851/966 [01:56<00:13,  8.39it/s] 88%|████████▊ | 852/966 [01:56<00:13,  8.39it/s] 88%|████████▊ | 853/966 [01:56<00:13,  8.39it/s] 88%|████████▊ | 854/966 [01:57<00:13,  8.39it/s] 89%|████████▊ | 855/966 [01:57<00:13,  8.38it/s] 89%|████████▊ | 856/966 [01:57<00:13,  8.38it/s] 89%|████████▊ | 857/966 [01:57<00:13,  8.38it/s] 89%|████████▉ | 858/966 [01:57<00:12,  8.38it/s] 89%|████████▉ | 859/966 [01:57<00:12,  8.37it/s] 89%|████████▉ | 860/966 [01:57<00:12,  8.37it/s] 89%|████████▉ | 861/966 [01:57<00:12,  8.38it/s] 89%|████████▉ | 862/966 [01:57<00:12,  8.39it/s] 89%|████████▉ | 863/966 [01:58<00:12,  8.38it/s] 89%|████████▉ | 864/966 [01:58<00:12,  8.40it/s] 90%|████████▉ | 865/966 [01:58<00:12,  8.39it/s] 90%|████████▉ | 866/966 [01:58<00:11,  8.39it/s] 90%|████████▉ | 867/966 [01:58<00:11,  8.37it/s] 90%|████████▉ | 868/966 [01:58<00:11,  8.37it/s] 90%|████████▉ | 869/966 [01:58<00:11,  8.37it/s] 90%|█████████ | 870/966 [01:58<00:11,  8.38it/s] 90%|█████████ | 871/966 [01:59<00:11,  8.38it/s] 90%|█████████ | 872/966 [01:59<00:11,  8.39it/s] 90%|█████████ | 873/966 [01:59<00:11,  8.39it/s] 90%|█████████ | 874/966 [01:59<00:10,  8.39it/s] 91%|█████████ | 875/966 [01:59<00:10,  8.39it/s] 91%|█████████ | 876/966 [01:59<00:10,  8.39it/s] 91%|█████████ | 877/966 [01:59<00:10,  8.39it/s] 91%|█████████ | 878/966 [01:59<00:10,  8.39it/s] 91%|█████████ | 879/966 [02:00<00:10,  8.39it/s] 91%|█████████ | 880/966 [02:00<00:10,  8.38it/s] 91%|█████████ | 881/966 [02:00<00:10,  8.39it/s] 91%|█████████▏| 882/966 [02:00<00:10,  8.38it/s] 91%|█████████▏| 883/966 [02:00<00:09,  8.40it/s] 92%|█████████▏| 884/966 [02:00<00:09,  8.40it/s] 92%|█████████▏| 885/966 [02:00<00:09,  8.39it/s] 92%|█████████▏| 886/966 [02:00<00:09,  8.40it/s] 92%|█████████▏| 887/966 [02:00<00:09,  8.39it/s] 92%|█████████▏| 888/966 [02:01<00:09,  8.39it/s] 92%|█████████▏| 889/966 [02:01<00:09,  8.40it/s] 92%|█████████▏| 890/966 [02:01<00:09,  8.40it/s] 92%|█████████▏| 891/966 [02:01<00:08,  8.39it/s] 92%|█████████▏| 892/966 [02:01<00:08,  8.39it/s] 92%|█████████▏| 893/966 [02:01<00:08,  8.39it/s] 93%|█████████▎| 894/966 [02:01<00:08,  8.39it/s] 93%|█████████▎| 895/966 [02:01<00:08,  8.39it/s] 93%|█████████▎| 896/966 [02:02<00:08,  8.38it/s] 93%|█████████▎| 897/966 [02:02<00:08,  8.38it/s] 93%|█████████▎| 898/966 [02:02<00:08,  8.38it/s] 93%|█████████▎| 899/966 [02:02<00:07,  8.38it/s] 93%|█████████▎| 900/966 [02:02<00:07,  8.38it/s] 93%|█████████▎| 901/966 [02:02<00:07,  8.38it/s] 93%|█████████▎| 902/966 [02:02<00:07,  8.37it/s] 93%|█████████▎| 903/966 [02:02<00:07,  8.38it/s] 94%|█████████▎| 904/966 [02:02<00:07,  8.38it/s] 94%|█████████▎| 905/966 [02:03<00:07,  8.37it/s] 94%|█████████▍| 906/966 [02:03<00:07,  8.38it/s] 94%|█████████▍| 907/966 [02:03<00:07,  8.39it/s] 94%|█████████▍| 908/966 [02:03<00:06,  8.38it/s] 94%|█████████▍| 909/966 [02:03<00:06,  8.38it/s] 94%|█████████▍| 910/966 [02:03<00:06,  8.39it/s] 94%|█████████▍| 911/966 [02:03<00:06,  8.38it/s] 94%|█████████▍| 912/966 [02:03<00:06,  8.38it/s] 95%|█████████▍| 913/966 [02:04<00:06,  8.39it/s] 95%|█████████▍| 914/966 [02:04<00:06,  8.38it/s] 95%|█████████▍| 915/966 [02:04<00:06,  8.40it/s] 95%|█████████▍| 916/966 [02:04<00:05,  8.38it/s] 95%|█████████▍| 917/966 [02:04<00:05,  8.39it/s] 95%|█████████▌| 918/966 [02:04<00:05,  8.38it/s] 95%|█████████▌| 919/966 [02:04<00:05,  8.40it/s] 95%|█████████▌| 920/966 [02:04<00:05,  8.39it/s] 95%|█████████▌| 921/966 [02:05<00:05,  8.39it/s] 95%|█████████▌| 922/966 [02:05<00:05,  8.39it/s] 96%|█████████▌| 923/966 [02:05<00:05,  8.39it/s] 96%|█████████▌| 924/966 [02:05<00:05,  8.39it/s] 96%|█████████▌| 925/966 [02:05<00:04,  8.40it/s] 96%|█████████▌| 926/966 [02:05<00:04,  8.40it/s] 96%|█████████▌| 927/966 [02:05<00:04,  8.39it/s] 96%|█████████▌| 928/966 [02:05<00:04,  8.39it/s] 96%|█████████▌| 929/966 [02:05<00:04,  8.39it/s] 96%|█████████▋| 930/966 [02:06<00:04,  8.39it/s] 96%|█████████▋| 931/966 [02:06<00:04,  8.39it/s] 96%|█████████▋| 932/966 [02:06<00:04,  8.39it/s] 97%|█████████▋| 933/966 [02:06<00:03,  8.40it/s] 97%|█████████▋| 934/966 [02:06<00:03,  8.39it/s] 97%|█████████▋| 935/966 [02:06<00:03,  8.39it/s] 97%|█████████▋| 936/966 [02:06<00:03,  8.40it/s] 97%|█████████▋| 937/966 [02:06<00:03,  8.39it/s] 97%|█████████▋| 938/966 [02:07<00:03,  8.40it/s] 97%|█████████▋| 939/966 [02:07<00:03,  8.39it/s] 97%|█████████▋| 940/966 [02:07<00:03,  8.38it/s] 97%|█████████▋| 941/966 [02:07<00:02,  8.37it/s] 98%|█████████▊| 942/966 [02:07<00:02,  8.38it/s] 98%|█████████▊| 943/966 [02:07<00:02,  8.37it/s] 98%|█████████▊| 944/966 [02:07<00:02,  8.37it/s] 98%|█████████▊| 945/966 [02:07<00:02,  8.37it/s] 98%|█████████▊| 946/966 [02:07<00:02,  8.38it/s] 98%|█████████▊| 947/966 [02:08<00:02,  8.37it/s] 98%|█████████▊| 948/966 [02:08<00:02,  8.37it/s] 98%|█████████▊| 949/966 [02:08<00:02,  8.36it/s] 98%|█████████▊| 950/966 [02:08<00:01,  8.36it/s] 98%|█████████▊| 951/966 [02:08<00:01,  8.38it/s] 99%|█████████▊| 952/966 [02:08<00:01,  8.37it/s] 99%|█████████▊| 953/966 [02:08<00:01,  8.37it/s] 99%|█████████▉| 954/966 [02:08<00:01,  8.37it/s] 99%|█████████▉| 955/966 [02:09<00:01,  8.38it/s] 99%|█████████▉| 956/966 [02:09<00:01,  8.39it/s] 99%|█████████▉| 957/966 [02:09<00:01,  8.38it/s] 99%|█████████▉| 958/966 [02:09<00:00,  8.38it/s] 99%|█████████▉| 959/966 [02:09<00:00,  8.38it/s] 99%|█████████▉| 960/966 [02:09<00:00,  8.38it/s] 99%|█████████▉| 961/966 [02:09<00:00,  8.39it/s]100%|█████████▉| 962/966 [02:09<00:00,  8.40it/s]100%|█████████▉| 963/966 [02:10<00:00,  8.38it/s]100%|█████████▉| 964/966 [02:10<00:00,  8.37it/s]100%|█████████▉| 965/966 [02:10<00:00,  8.38it/s]100%|██████████| 966/966 [02:10<00:00,  8.40it/s]100%|██████████| 966/966 [02:10<00:00,  7.41it/s]
sending off prediction to background worker for resampling and export
done with 101-045

Predicting 706-005:
perform_everything_on_device: True
  0%|          | 0/966 [00:00<?, ?it/s]  0%|          | 2/966 [00:00<01:28, 10.94it/s]  0%|          | 4/966 [00:00<01:43,  9.29it/s]  1%|          | 5/966 [00:00<01:46,  9.00it/s]  1%|          | 6/966 [00:00<01:48,  8.81it/s]  1%|          | 7/966 [00:00<01:50,  8.69it/s]  1%|          | 8/966 [00:00<01:51,  8.60it/s]  1%|          | 9/966 [00:01<01:52,  8.54it/s]  1%|          | 10/966 [00:01<01:52,  8.50it/s]  1%|          | 11/966 [00:01<01:52,  8.47it/s]  1%|          | 12/966 [00:01<01:52,  8.46it/s]  1%|▏         | 13/966 [00:01<01:52,  8.44it/s]  1%|▏         | 14/966 [00:01<01:53,  8.42it/s]  2%|▏         | 15/966 [00:01<01:53,  8.41it/s]  2%|▏         | 16/966 [00:01<01:53,  8.40it/s]  2%|▏         | 17/966 [00:01<01:53,  8.39it/s]  2%|▏         | 18/966 [00:02<01:53,  8.38it/s]  2%|▏         | 19/966 [00:02<01:52,  8.39it/s]  2%|▏         | 20/966 [00:02<01:52,  8.41it/s]  2%|▏         | 21/966 [00:02<01:52,  8.40it/s]  2%|▏         | 22/966 [00:02<01:52,  8.39it/s]  2%|▏         | 23/966 [00:02<01:52,  8.40it/s]  2%|▏         | 24/966 [00:02<01:52,  8.39it/s]  3%|▎         | 25/966 [00:02<01:52,  8.38it/s]  3%|▎         | 26/966 [00:03<01:52,  8.39it/s]  3%|▎         | 27/966 [00:03<01:51,  8.40it/s]  3%|▎         | 28/966 [00:03<01:51,  8.39it/s]  3%|▎         | 29/966 [00:03<01:51,  8.38it/s]  3%|▎         | 30/966 [00:03<01:51,  8.38it/s]  3%|▎         | 31/966 [00:03<01:51,  8.39it/s]  3%|▎         | 32/966 [00:03<01:51,  8.38it/s]  3%|▎         | 33/966 [00:03<01:51,  8.39it/s]  4%|▎         | 34/966 [00:03<01:51,  8.38it/s]  4%|▎         | 35/966 [00:04<01:50,  8.39it/s]  4%|▎         | 36/966 [00:04<01:50,  8.39it/s]  4%|▍         | 37/966 [00:04<01:50,  8.39it/s]  4%|▍         | 38/966 [00:04<01:50,  8.39it/s]  4%|▍         | 39/966 [00:04<01:50,  8.39it/s]  4%|▍         | 40/966 [00:04<01:50,  8.40it/s]  4%|▍         | 41/966 [00:04<01:50,  8.40it/s]  4%|▍         | 42/966 [00:04<01:49,  8.40it/s]  4%|▍         | 43/966 [00:05<01:49,  8.41it/s]  5%|▍         | 44/966 [00:05<01:49,  8.41it/s]  5%|▍         | 45/966 [00:05<01:49,  8.40it/s]  5%|▍         | 46/966 [00:05<01:49,  8.40it/s]  5%|▍         | 47/966 [00:05<01:49,  8.39it/s]  5%|▍         | 48/966 [00:05<01:49,  8.39it/s]  5%|▌         | 49/966 [00:05<01:49,  8.40it/s]  5%|▌         | 50/966 [00:05<01:48,  8.41it/s]  5%|▌         | 51/966 [00:06<01:48,  8.41it/s]  5%|▌         | 52/966 [00:06<01:48,  8.41it/s]  5%|▌         | 53/966 [00:06<01:48,  8.41it/s]  6%|▌         | 54/966 [00:06<01:48,  8.40it/s]  6%|▌         | 55/966 [00:06<01:48,  8.39it/s]  6%|▌         | 56/966 [00:06<01:48,  8.40it/s]  6%|▌         | 57/966 [00:06<01:48,  8.39it/s]  6%|▌         | 58/966 [00:06<01:48,  8.39it/s]  6%|▌         | 59/966 [00:06<01:48,  8.40it/s]  6%|▌         | 60/966 [00:07<01:47,  8.39it/s]  6%|▋         | 61/966 [00:07<01:47,  8.39it/s]  6%|▋         | 62/966 [00:07<01:47,  8.39it/s]  7%|▋         | 63/966 [00:07<01:47,  8.38it/s]  7%|▋         | 64/966 [00:07<01:47,  8.38it/s]  7%|▋         | 65/966 [00:07<01:47,  8.38it/s]  7%|▋         | 66/966 [00:07<01:47,  8.38it/s]  7%|▋         | 67/966 [00:07<01:47,  8.38it/s]  7%|▋         | 68/966 [00:08<01:47,  8.38it/s]  7%|▋         | 69/966 [00:08<01:46,  8.39it/s]  7%|▋         | 70/966 [00:08<01:46,  8.39it/s]  7%|▋         | 71/966 [00:08<01:46,  8.39it/s]  7%|▋         | 72/966 [00:08<01:46,  8.38it/s]  8%|▊         | 73/966 [00:08<01:46,  8.39it/s]  8%|▊         | 74/966 [00:08<01:46,  8.39it/s]  8%|▊         | 75/966 [00:08<01:46,  8.38it/s]  8%|▊         | 76/966 [00:09<01:46,  8.38it/s]  8%|▊         | 77/966 [00:09<01:46,  8.38it/s]  8%|▊         | 78/966 [00:09<01:45,  8.39it/s]  8%|▊         | 79/966 [00:09<01:45,  8.39it/s]  8%|▊         | 80/966 [00:09<01:45,  8.39it/s]  8%|▊         | 81/966 [00:09<01:45,  8.39it/s]  8%|▊         | 82/966 [00:09<01:45,  8.39it/s]  9%|▊         | 83/966 [00:09<01:45,  8.39it/s]  9%|▊         | 84/966 [00:09<01:45,  8.39it/s]  9%|▉         | 85/966 [00:10<01:44,  8.40it/s]  9%|▉         | 86/966 [00:10<01:44,  8.42it/s]  9%|▉         | 87/966 [00:10<01:44,  8.41it/s]  9%|▉         | 88/966 [00:10<01:44,  8.40it/s]  9%|▉         | 89/966 [00:10<01:44,  8.40it/s]  9%|▉         | 90/966 [00:10<01:44,  8.39it/s]  9%|▉         | 91/966 [00:10<01:44,  8.39it/s] 10%|▉         | 92/966 [00:10<01:44,  8.39it/s] 10%|▉         | 93/966 [00:11<01:43,  8.40it/s] 10%|▉         | 94/966 [00:11<01:43,  8.39it/s] 10%|▉         | 95/966 [00:11<01:43,  8.39it/s] 10%|▉         | 96/966 [00:11<01:43,  8.40it/s] 10%|█         | 97/966 [00:11<01:43,  8.40it/s] 10%|█         | 98/966 [00:11<01:43,  8.39it/s] 10%|█         | 99/966 [00:11<01:43,  8.40it/s] 10%|█         | 100/966 [00:11<01:43,  8.38it/s] 10%|█         | 101/966 [00:11<01:43,  8.38it/s] 11%|█         | 102/966 [00:12<01:43,  8.38it/s] 11%|█         | 103/966 [00:12<01:43,  8.37it/s] 11%|█         | 104/966 [00:12<01:42,  8.38it/s] 11%|█         | 105/966 [00:12<01:42,  8.39it/s] 11%|█         | 106/966 [00:12<01:42,  8.38it/s] 11%|█         | 107/966 [00:12<01:42,  8.39it/s] 11%|█         | 108/966 [00:12<01:42,  8.38it/s] 11%|█▏        | 109/966 [00:12<01:42,  8.38it/s] 11%|█▏        | 110/966 [00:13<01:42,  8.38it/s] 11%|█▏        | 111/966 [00:13<01:42,  8.38it/s] 12%|█▏        | 112/966 [00:13<01:42,  8.37it/s] 12%|█▏        | 113/966 [00:13<01:41,  8.37it/s] 12%|█▏        | 114/966 [00:13<01:41,  8.38it/s] 12%|█▏        | 115/966 [00:13<01:41,  8.39it/s] 12%|█▏        | 116/966 [00:13<01:41,  8.38it/s] 12%|█▏        | 117/966 [00:13<01:41,  8.39it/s] 12%|█▏        | 118/966 [00:14<01:40,  8.40it/s] 12%|█▏        | 119/966 [00:14<01:40,  8.39it/s] 12%|█▏        | 120/966 [00:14<01:40,  8.39it/s] 13%|█▎        | 121/966 [00:14<01:40,  8.40it/s] 13%|█▎        | 122/966 [00:14<01:40,  8.39it/s] 13%|█▎        | 123/966 [00:14<01:40,  8.39it/s] 13%|█▎        | 124/966 [00:14<01:40,  8.40it/s] 13%|█▎        | 125/966 [00:14<01:40,  8.39it/s] 13%|█▎        | 126/966 [00:14<01:40,  8.40it/s] 13%|█▎        | 127/966 [00:15<01:39,  8.41it/s] 13%|█▎        | 128/966 [00:15<01:39,  8.41it/s] 13%|█▎        | 129/966 [00:15<01:39,  8.40it/s] 13%|█▎        | 130/966 [00:15<01:39,  8.40it/s] 14%|█▎        | 131/966 [00:15<01:39,  8.39it/s] 14%|█▎        | 132/966 [00:15<01:39,  8.39it/s] 14%|█▍        | 133/966 [00:15<01:39,  8.38it/s] 14%|█▍        | 134/966 [00:15<01:39,  8.39it/s] 14%|█▍        | 135/966 [00:16<01:39,  8.39it/s] 14%|█▍        | 136/966 [00:16<01:38,  8.40it/s] 14%|█▍        | 137/966 [00:16<01:38,  8.38it/s] 14%|█▍        | 138/966 [00:16<01:38,  8.38it/s] 14%|█▍        | 139/966 [00:16<01:38,  8.39it/s] 14%|█▍        | 140/966 [00:16<01:38,  8.39it/s] 15%|█▍        | 141/966 [00:16<01:38,  8.38it/s] 15%|█▍        | 142/966 [00:16<01:38,  8.38it/s] 15%|█▍        | 143/966 [00:16<01:38,  8.38it/s] 15%|█▍        | 144/966 [00:17<01:38,  8.38it/s] 15%|█▌        | 145/966 [00:17<01:37,  8.39it/s] 15%|█▌        | 146/966 [00:17<01:37,  8.38it/s] 15%|█▌        | 147/966 [00:17<01:37,  8.38it/s] 15%|█▌        | 148/966 [00:17<01:37,  8.38it/s] 15%|█▌        | 149/966 [00:17<01:37,  8.39it/s] 16%|█▌        | 150/966 [00:17<01:37,  8.38it/s] 16%|█▌        | 151/966 [00:17<01:37,  8.38it/s] 16%|█▌        | 152/966 [00:18<01:37,  8.37it/s] 16%|█▌        | 153/966 [00:18<01:37,  8.38it/s] 16%|█▌        | 154/966 [00:18<01:36,  8.38it/s] 16%|█▌        | 155/966 [00:18<01:36,  8.38it/s] 16%|█▌        | 156/966 [00:18<01:36,  8.38it/s] 16%|█▋        | 157/966 [00:18<01:36,  8.38it/s] 16%|█▋        | 158/966 [00:18<01:36,  8.39it/s] 16%|█▋        | 159/966 [00:18<01:36,  8.39it/s] 17%|█▋        | 160/966 [00:19<01:36,  8.39it/s] 17%|█▋        | 161/966 [00:19<01:35,  8.39it/s] 17%|█▋        | 162/966 [00:19<01:35,  8.40it/s] 17%|█▋        | 163/966 [00:19<01:35,  8.40it/s] 17%|█▋        | 164/966 [00:19<01:35,  8.40it/s] 17%|█▋        | 165/966 [00:19<01:35,  8.40it/s] 17%|█▋        | 166/966 [00:19<01:35,  8.40it/s] 17%|█▋        | 167/966 [00:19<01:35,  8.41it/s] 17%|█▋        | 168/966 [00:19<01:34,  8.41it/s] 17%|█▋        | 169/966 [00:20<01:34,  8.41it/s] 18%|█▊        | 170/966 [00:20<01:34,  8.41it/s] 18%|█▊        | 171/966 [00:20<01:34,  8.41it/s] 18%|█▊        | 172/966 [00:20<01:34,  8.39it/s] 18%|█▊        | 173/966 [00:20<01:34,  8.39it/s] 18%|█▊        | 174/966 [00:20<01:34,  8.38it/s] 18%|█▊        | 175/966 [00:20<01:34,  8.39it/s] 18%|█▊        | 176/966 [00:20<01:34,  8.40it/s] 18%|█▊        | 177/966 [00:21<01:33,  8.40it/s] 18%|█▊        | 178/966 [00:21<01:33,  8.40it/s] 19%|█▊        | 179/966 [00:21<01:33,  8.39it/s] 19%|█▊        | 180/966 [00:21<01:33,  8.40it/s] 19%|█▊        | 181/966 [00:21<01:33,  8.41it/s] 19%|█▉        | 182/966 [00:21<01:33,  8.40it/s] 19%|█▉        | 183/966 [00:21<01:33,  8.40it/s] 19%|█▉        | 184/966 [00:21<01:33,  8.38it/s] 19%|█▉        | 185/966 [00:21<01:33,  8.38it/s] 19%|█▉        | 186/966 [00:22<01:32,  8.39it/s] 19%|█▉        | 187/966 [00:22<01:32,  8.38it/s] 19%|█▉        | 188/966 [00:22<01:32,  8.38it/s] 20%|█▉        | 189/966 [00:22<01:32,  8.39it/s] 20%|█▉        | 190/966 [00:22<01:32,  8.39it/s] 20%|█▉        | 191/966 [00:22<01:32,  8.38it/s] 20%|█▉        | 192/966 [00:22<01:32,  8.38it/s] 20%|█▉        | 193/966 [00:22<01:32,  8.38it/s] 20%|██        | 194/966 [00:23<01:32,  8.39it/s] 20%|██        | 195/966 [00:23<01:32,  8.37it/s] 20%|██        | 196/966 [00:23<01:31,  8.37it/s] 20%|██        | 197/966 [00:23<01:31,  8.36it/s] 20%|██        | 198/966 [00:23<01:31,  8.37it/s] 21%|██        | 199/966 [00:23<01:31,  8.38it/s] 21%|██        | 200/966 [00:23<01:31,  8.37it/s] 21%|██        | 201/966 [00:23<01:31,  8.37it/s] 21%|██        | 202/966 [00:24<01:31,  8.38it/s] 21%|██        | 203/966 [00:24<01:30,  8.39it/s] 21%|██        | 204/966 [00:24<01:30,  8.39it/s] 21%|██        | 205/966 [00:24<01:30,  8.40it/s] 21%|██▏       | 206/966 [00:24<01:30,  8.41it/s] 21%|██▏       | 207/966 [00:24<01:30,  8.41it/s] 22%|██▏       | 208/966 [00:24<01:30,  8.40it/s] 22%|██▏       | 209/966 [00:24<01:30,  8.39it/s] 22%|██▏       | 210/966 [00:24<01:29,  8.40it/s] 22%|██▏       | 211/966 [00:25<01:29,  8.40it/s] 22%|██▏       | 212/966 [00:25<01:29,  8.40it/s] 22%|██▏       | 213/966 [00:25<01:29,  8.40it/s] 22%|██▏       | 214/966 [00:25<01:29,  8.40it/s] 22%|██▏       | 215/966 [00:25<01:29,  8.39it/s] 22%|██▏       | 216/966 [00:25<01:29,  8.40it/s] 22%|██▏       | 217/966 [00:25<01:29,  8.41it/s] 23%|██▎       | 218/966 [00:25<01:28,  8.41it/s] 23%|██▎       | 219/966 [00:26<01:28,  8.41it/s] 23%|██▎       | 220/966 [00:26<01:28,  8.39it/s] 23%|██▎       | 221/966 [00:26<01:28,  8.39it/s] 23%|██▎       | 222/966 [00:26<01:28,  8.38it/s] 23%|██▎       | 223/966 [00:26<01:28,  8.38it/s] 23%|██▎       | 224/966 [00:26<01:28,  8.39it/s] 23%|██▎       | 225/966 [00:26<01:28,  8.39it/s] 23%|██▎       | 226/966 [00:26<01:28,  8.39it/s] 23%|██▎       | 227/966 [00:26<01:27,  8.40it/s] 24%|██▎       | 228/966 [00:27<01:27,  8.40it/s] 24%|██▎       | 229/966 [00:27<01:27,  8.39it/s] 24%|██▍       | 230/966 [00:27<01:27,  8.39it/s] 24%|██▍       | 231/966 [00:27<01:27,  8.38it/s] 24%|██▍       | 232/966 [00:27<01:27,  8.38it/s] 24%|██▍       | 233/966 [00:27<01:27,  8.38it/s] 24%|██▍       | 234/966 [00:27<01:27,  8.39it/s] 24%|██▍       | 235/966 [00:27<01:27,  8.38it/s] 24%|██▍       | 236/966 [00:28<01:27,  8.38it/s] 25%|██▍       | 237/966 [00:28<01:26,  8.39it/s] 25%|██▍       | 238/966 [00:28<01:26,  8.38it/s] 25%|██▍       | 239/966 [00:28<01:26,  8.37it/s] 25%|██▍       | 240/966 [00:28<01:26,  8.38it/s] 25%|██▍       | 241/966 [00:28<01:26,  8.38it/s] 25%|██▌       | 242/966 [00:28<01:26,  8.38it/s] 25%|██▌       | 243/966 [00:28<01:26,  8.38it/s] 25%|██▌       | 244/966 [00:29<01:26,  8.39it/s] 25%|██▌       | 245/966 [00:29<01:26,  8.38it/s] 25%|██▌       | 246/966 [00:29<01:25,  8.39it/s] 26%|██▌       | 247/966 [00:29<01:25,  8.41it/s] 26%|██▌       | 248/966 [00:29<01:25,  8.41it/s] 26%|██▌       | 249/966 [00:29<01:25,  8.40it/s] 26%|██▌       | 250/966 [00:29<01:25,  8.41it/s] 26%|██▌       | 251/966 [00:29<01:25,  8.41it/s] 26%|██▌       | 252/966 [00:29<01:25,  8.40it/s] 26%|██▌       | 253/966 [00:30<01:24,  8.40it/s] 26%|██▋       | 254/966 [00:30<01:24,  8.40it/s] 26%|██▋       | 255/966 [00:30<01:24,  8.40it/s] 27%|██▋       | 256/966 [00:30<01:24,  8.40it/s] 27%|██▋       | 257/966 [00:30<01:24,  8.41it/s] 27%|██▋       | 258/966 [00:30<01:24,  8.41it/s] 27%|██▋       | 259/966 [00:30<01:23,  8.42it/s] 27%|██▋       | 260/966 [00:30<01:23,  8.42it/s] 27%|██▋       | 261/966 [00:31<01:23,  8.41it/s] 27%|██▋       | 262/966 [00:31<01:23,  8.40it/s] 27%|██▋       | 263/966 [00:31<01:23,  8.39it/s] 27%|██▋       | 264/966 [00:31<01:23,  8.38it/s] 27%|██▋       | 265/966 [00:31<01:23,  8.39it/s] 28%|██▊       | 266/966 [00:31<01:23,  8.38it/s] 28%|██▊       | 267/966 [00:31<01:23,  8.39it/s] 28%|██▊       | 268/966 [00:31<01:23,  8.40it/s] 28%|██▊       | 269/966 [00:32<01:23,  8.39it/s] 28%|██▊       | 270/966 [00:32<01:22,  8.39it/s] 28%|██▊       | 271/966 [00:32<01:22,  8.39it/s] 28%|██▊       | 272/966 [00:32<01:22,  8.38it/s] 28%|██▊       | 273/966 [00:32<01:22,  8.37it/s] 28%|██▊       | 274/966 [00:32<01:22,  8.37it/s] 28%|██▊       | 275/966 [00:32<01:22,  8.38it/s] 29%|██▊       | 276/966 [00:32<01:22,  8.38it/s] 29%|██▊       | 277/966 [00:32<01:22,  8.37it/s] 29%|██▉       | 278/966 [00:33<01:22,  8.39it/s] 29%|██▉       | 279/966 [00:33<01:21,  8.39it/s] 29%|██▉       | 280/966 [00:33<01:21,  8.38it/s] 29%|██▉       | 281/966 [00:33<01:21,  8.37it/s] 29%|██▉       | 282/966 [00:33<01:21,  8.37it/s] 29%|██▉       | 283/966 [00:33<01:21,  8.38it/s] 29%|██▉       | 284/966 [00:33<01:21,  8.38it/s] 30%|██▉       | 285/966 [00:33<01:21,  8.38it/s] 30%|██▉       | 286/966 [00:34<01:21,  8.38it/s] 30%|██▉       | 287/966 [00:34<01:21,  8.38it/s] 30%|██▉       | 288/966 [00:34<01:20,  8.37it/s] 30%|██▉       | 289/966 [00:34<01:20,  8.39it/s] 30%|███       | 290/966 [00:34<01:20,  8.39it/s] 30%|███       | 291/966 [00:34<01:20,  8.41it/s] 30%|███       | 292/966 [00:34<01:20,  8.40it/s] 30%|███       | 293/966 [00:34<01:20,  8.40it/s] 30%|███       | 294/966 [00:34<01:19,  8.41it/s] 31%|███       | 295/966 [00:35<01:19,  8.41it/s] 31%|███       | 296/966 [00:35<01:19,  8.40it/s] 31%|███       | 297/966 [00:35<01:19,  8.40it/s] 31%|███       | 298/966 [00:35<01:19,  8.40it/s] 31%|███       | 299/966 [00:35<01:19,  8.40it/s] 31%|███       | 300/966 [00:35<01:19,  8.39it/s] 31%|███       | 301/966 [00:35<01:19,  8.40it/s] 31%|███▏      | 302/966 [00:35<01:19,  8.40it/s] 31%|███▏      | 303/966 [00:36<01:18,  8.40it/s] 31%|███▏      | 304/966 [00:36<01:18,  8.40it/s] 32%|███▏      | 305/966 [00:36<01:18,  8.40it/s] 32%|███▏      | 306/966 [00:36<01:18,  8.40it/s] 32%|███▏      | 307/966 [00:36<01:18,  8.39it/s] 32%|███▏      | 308/966 [00:36<01:18,  8.39it/s] 32%|███▏      | 309/966 [00:36<01:18,  8.39it/s] 32%|███▏      | 310/966 [00:36<01:18,  8.39it/s] 32%|███▏      | 311/966 [00:37<01:18,  8.39it/s] 32%|███▏      | 312/966 [00:37<01:17,  8.39it/s] 32%|███▏      | 313/966 [00:37<01:17,  8.38it/s] 33%|███▎      | 314/966 [00:37<01:17,  8.38it/s] 33%|███▎      | 315/966 [00:37<01:17,  8.39it/s] 33%|███▎      | 316/966 [00:37<01:17,  8.37it/s] 33%|███▎      | 317/966 [00:37<01:17,  8.38it/s] 33%|███▎      | 318/966 [00:37<01:17,  8.38it/s] 33%|███▎      | 319/966 [00:37<01:17,  8.37it/s] 33%|███▎      | 320/966 [00:38<01:17,  8.38it/s] 33%|███▎      | 321/966 [00:38<01:17,  8.37it/s] 33%|███▎      | 322/966 [00:38<01:16,  8.38it/s] 33%|███▎      | 323/966 [00:38<01:16,  8.37it/s] 34%|███▎      | 324/966 [00:38<01:16,  8.38it/s] 34%|███▎      | 325/966 [00:38<01:16,  8.38it/s] 34%|███▎      | 326/966 [00:38<01:16,  8.39it/s] 34%|███▍      | 327/966 [00:38<01:16,  8.39it/s] 34%|███▍      | 328/966 [00:39<01:16,  8.39it/s] 34%|███▍      | 329/966 [00:39<01:15,  8.40it/s] 34%|███▍      | 330/966 [00:39<01:15,  8.39it/s] 34%|███▍      | 331/966 [00:39<01:15,  8.39it/s] 34%|███▍      | 332/966 [00:39<01:15,  8.38it/s] 34%|███▍      | 333/966 [00:39<01:15,  8.38it/s] 35%|███▍      | 334/966 [00:39<01:15,  8.39it/s] 35%|███▍      | 335/966 [00:39<01:15,  8.38it/s] 35%|███▍      | 336/966 [00:39<01:15,  8.39it/s] 35%|███▍      | 337/966 [00:40<01:14,  8.40it/s] 35%|███▍      | 338/966 [00:40<01:14,  8.40it/s] 35%|███▌      | 339/966 [00:40<01:14,  8.40it/s] 35%|███▌      | 340/966 [00:40<01:14,  8.40it/s] 35%|███▌      | 341/966 [00:40<01:14,  8.40it/s] 35%|███▌      | 342/966 [00:40<01:14,  8.39it/s] 36%|███▌      | 343/966 [00:40<01:14,  8.40it/s] 36%|███▌      | 344/966 [00:40<01:14,  8.39it/s] 36%|███▌      | 345/966 [00:41<01:14,  8.39it/s] 36%|███▌      | 346/966 [00:41<01:13,  8.39it/s] 36%|███▌      | 347/966 [00:41<01:13,  8.38it/s] 36%|███▌      | 348/966 [00:41<01:13,  8.38it/s] 36%|███▌      | 349/966 [00:41<01:13,  8.38it/s] 36%|███▌      | 350/966 [00:41<01:13,  8.39it/s] 36%|███▋      | 351/966 [00:41<01:13,  8.39it/s] 36%|███▋      | 352/966 [00:41<01:13,  8.38it/s] 37%|███▋      | 353/966 [00:42<01:13,  8.38it/s] 37%|███▋      | 354/966 [00:42<01:12,  8.39it/s] 37%|███▋      | 355/966 [00:42<01:12,  8.38it/s] 37%|███▋      | 356/966 [00:42<01:12,  8.38it/s] 37%|███▋      | 357/966 [00:42<01:12,  8.38it/s] 37%|███▋      | 358/966 [00:42<01:12,  8.39it/s] 37%|███▋      | 359/966 [00:42<01:12,  8.37it/s] 37%|███▋      | 360/966 [00:42<01:12,  8.37it/s] 37%|███▋      | 361/966 [00:42<01:12,  8.38it/s] 37%|███▋      | 362/966 [00:43<01:12,  8.38it/s] 38%|███▊      | 363/966 [00:43<01:11,  8.38it/s] 38%|███▊      | 364/966 [00:43<01:11,  8.38it/s] 38%|███▊      | 365/966 [00:43<01:11,  8.39it/s] 38%|███▊      | 366/966 [00:43<01:11,  8.38it/s] 38%|███▊      | 367/966 [00:43<01:11,  8.38it/s] 38%|███▊      | 368/966 [00:43<01:11,  8.38it/s] 38%|███▊      | 369/966 [00:43<01:11,  8.38it/s] 38%|███▊      | 370/966 [00:44<01:11,  8.38it/s] 38%|███▊      | 371/966 [00:44<01:10,  8.39it/s] 39%|███▊      | 372/966 [00:44<01:10,  8.39it/s] 39%|███▊      | 373/966 [00:44<01:10,  8.39it/s] 39%|███▊      | 374/966 [00:44<01:10,  8.39it/s] 39%|███▉      | 375/966 [00:44<01:10,  8.40it/s] 39%|███▉      | 376/966 [00:44<01:10,  8.39it/s] 39%|███▉      | 377/966 [00:44<01:10,  8.38it/s] 39%|███▉      | 378/966 [00:44<01:10,  8.40it/s] 39%|███▉      | 379/966 [00:45<01:09,  8.40it/s] 39%|███▉      | 380/966 [00:45<01:09,  8.40it/s] 39%|███▉      | 381/966 [00:45<01:09,  8.40it/s] 40%|███▉      | 382/966 [00:45<01:09,  8.40it/s] 40%|███▉      | 383/966 [00:45<01:09,  8.41it/s] 40%|███▉      | 384/966 [00:45<01:09,  8.40it/s] 40%|███▉      | 385/966 [00:45<01:09,  8.40it/s] 40%|███▉      | 386/966 [00:45<01:09,  8.40it/s] 40%|████      | 387/966 [00:46<01:08,  8.40it/s] 40%|████      | 388/966 [00:46<01:08,  8.41it/s] 40%|████      | 389/966 [00:46<01:08,  8.40it/s] 40%|████      | 390/966 [00:46<01:08,  8.40it/s] 40%|████      | 391/966 [00:46<01:08,  8.39it/s] 41%|████      | 392/966 [00:46<01:08,  8.39it/s] 41%|████      | 393/966 [00:46<01:08,  8.40it/s] 41%|████      | 394/966 [00:46<01:08,  8.40it/s] 41%|████      | 395/966 [00:47<01:08,  8.39it/s] 41%|████      | 396/966 [00:47<01:07,  8.39it/s] 41%|████      | 397/966 [00:47<01:07,  8.38it/s] 41%|████      | 398/966 [00:47<01:07,  8.37it/s] 41%|████▏     | 399/966 [00:47<01:07,  8.38it/s] 41%|████▏     | 400/966 [00:47<01:07,  8.38it/s] 42%|████▏     | 401/966 [00:47<01:07,  8.37it/s] 42%|████▏     | 402/966 [00:47<01:07,  8.38it/s] 42%|████▏     | 403/966 [00:47<01:07,  8.38it/s] 42%|████▏     | 404/966 [00:48<01:06,  8.39it/s] 42%|████▏     | 405/966 [00:48<01:06,  8.38it/s] 42%|████▏     | 406/966 [00:48<01:06,  8.38it/s] 42%|████▏     | 407/966 [00:48<01:06,  8.38it/s] 42%|████▏     | 408/966 [00:48<01:06,  8.38it/s] 42%|████▏     | 409/966 [00:48<01:06,  8.38it/s] 42%|████▏     | 410/966 [00:48<01:06,  8.39it/s] 43%|████▎     | 411/966 [00:48<01:06,  8.38it/s] 43%|████▎     | 412/966 [00:49<01:05,  8.40it/s] 43%|████▎     | 413/966 [00:49<01:05,  8.39it/s] 43%|████▎     | 414/966 [00:49<01:05,  8.40it/s] 43%|████▎     | 415/966 [00:49<01:05,  8.39it/s] 43%|████▎     | 416/966 [00:49<01:05,  8.38it/s] 43%|████▎     | 417/966 [00:49<01:05,  8.38it/s] 43%|████▎     | 418/966 [00:49<01:05,  8.39it/s] 43%|████▎     | 419/966 [00:49<01:05,  8.40it/s] 43%|████▎     | 420/966 [00:50<01:04,  8.40it/s] 44%|████▎     | 421/966 [00:50<01:04,  8.41it/s] 44%|████▎     | 422/966 [00:50<01:04,  8.41it/s] 44%|████▍     | 423/966 [00:50<01:04,  8.40it/s] 44%|████▍     | 424/966 [00:50<01:04,  8.39it/s] 44%|████▍     | 425/966 [00:50<01:04,  8.40it/s] 44%|████▍     | 426/966 [00:50<01:04,  8.40it/s] 44%|████▍     | 427/966 [00:50<01:04,  8.40it/s] 44%|████▍     | 428/966 [00:50<01:04,  8.40it/s] 44%|████▍     | 429/966 [00:51<01:03,  8.40it/s] 45%|████▍     | 430/966 [00:51<01:03,  8.41it/s] 45%|████▍     | 431/966 [00:51<01:03,  8.40it/s] 45%|████▍     | 432/966 [00:51<01:03,  8.40it/s] 45%|████▍     | 433/966 [00:51<01:03,  8.39it/s] 45%|████▍     | 434/966 [00:51<01:03,  8.39it/s] 45%|████▌     | 435/966 [00:51<01:03,  8.39it/s] 45%|████▌     | 436/966 [00:51<01:03,  8.39it/s] 45%|████▌     | 437/966 [00:52<01:03,  8.39it/s] 45%|████▌     | 438/966 [00:52<01:02,  8.39it/s] 45%|████▌     | 439/966 [00:52<01:02,  8.39it/s] 46%|████▌     | 440/966 [00:52<01:02,  8.39it/s] 46%|████▌     | 441/966 [00:52<01:02,  8.39it/s] 46%|████▌     | 442/966 [00:52<01:02,  8.39it/s] 46%|████▌     | 443/966 [00:52<01:02,  8.38it/s] 46%|████▌     | 444/966 [00:52<01:02,  8.38it/s] 46%|████▌     | 445/966 [00:52<01:02,  8.38it/s] 46%|████▌     | 446/966 [00:53<01:02,  8.38it/s] 46%|████▋     | 447/966 [00:53<01:01,  8.38it/s] 46%|████▋     | 448/966 [00:53<01:01,  8.38it/s] 46%|████▋     | 449/966 [00:53<01:01,  8.39it/s] 47%|████▋     | 450/966 [00:53<01:01,  8.39it/s] 47%|████▋     | 451/966 [00:53<01:01,  8.38it/s] 47%|████▋     | 452/966 [00:53<01:01,  8.39it/s] 47%|████▋     | 453/966 [00:53<01:01,  8.38it/s] 47%|████▋     | 454/966 [00:54<01:01,  8.38it/s] 47%|████▋     | 455/966 [00:54<01:00,  8.38it/s] 47%|████▋     | 456/966 [00:54<01:00,  8.38it/s] 47%|████▋     | 457/966 [00:54<01:00,  8.40it/s] 47%|████▋     | 458/966 [00:54<01:00,  8.40it/s] 48%|████▊     | 459/966 [00:54<01:00,  8.40it/s] 48%|████▊     | 460/966 [00:54<01:00,  8.39it/s] 48%|████▊     | 461/966 [00:54<01:00,  8.39it/s] 48%|████▊     | 462/966 [00:55<01:00,  8.39it/s] 48%|████▊     | 463/966 [00:55<00:59,  8.39it/s] 48%|████▊     | 464/966 [00:55<00:59,  8.40it/s] 48%|████▊     | 465/966 [00:55<00:59,  8.40it/s] 48%|████▊     | 466/966 [00:55<00:59,  8.40it/s] 48%|████▊     | 467/966 [00:55<00:59,  8.39it/s] 48%|████▊     | 468/966 [00:55<00:59,  8.40it/s] 49%|████▊     | 469/966 [00:55<00:59,  8.40it/s] 49%|████▊     | 470/966 [00:55<00:59,  8.40it/s] 49%|████▉     | 471/966 [00:56<00:58,  8.40it/s] 49%|████▉     | 472/966 [00:56<00:58,  8.40it/s] 49%|████▉     | 473/966 [00:56<00:58,  8.38it/s] 49%|████▉     | 474/966 [00:56<00:58,  8.38it/s] 49%|████▉     | 475/966 [00:56<00:58,  8.38it/s] 49%|████▉     | 476/966 [00:56<00:58,  8.39it/s] 49%|████▉     | 477/966 [00:56<00:58,  8.38it/s] 49%|████▉     | 478/966 [00:56<00:58,  8.38it/s] 50%|████▉     | 479/966 [00:57<00:58,  8.39it/s] 50%|████▉     | 480/966 [00:57<00:57,  8.39it/s] 50%|████▉     | 481/966 [00:57<00:57,  8.37it/s] 50%|████▉     | 482/966 [00:57<00:57,  8.38it/s] 50%|█████     | 483/966 [00:57<00:57,  8.38it/s] 50%|█████     | 484/966 [00:57<00:57,  8.38it/s] 50%|█████     | 485/966 [00:57<00:57,  8.38it/s] 50%|█████     | 486/966 [00:57<00:57,  8.38it/s] 50%|█████     | 487/966 [00:57<00:57,  8.38it/s] 51%|█████     | 488/966 [00:58<00:57,  8.38it/s] 51%|█████     | 489/966 [00:58<00:56,  8.39it/s] 51%|█████     | 490/966 [00:58<00:56,  8.38it/s] 51%|█████     | 491/966 [00:58<00:56,  8.38it/s] 51%|█████     | 492/966 [00:58<00:56,  8.38it/s] 51%|█████     | 493/966 [00:58<00:56,  8.38it/s] 51%|█████     | 494/966 [00:58<00:56,  8.38it/s] 51%|█████     | 495/966 [00:58<00:56,  8.39it/s] 51%|█████▏    | 496/966 [00:59<00:56,  8.38it/s] 51%|█████▏    | 497/966 [00:59<00:55,  8.39it/s] 52%|█████▏    | 498/966 [00:59<00:55,  8.39it/s] 52%|█████▏    | 499/966 [00:59<00:55,  8.39it/s] 52%|█████▏    | 500/966 [00:59<00:55,  8.39it/s] 52%|█████▏    | 501/966 [00:59<00:55,  8.39it/s] 52%|█████▏    | 502/966 [00:59<00:55,  8.38it/s] 52%|█████▏    | 503/966 [00:59<00:55,  8.39it/s] 52%|█████▏    | 504/966 [01:00<00:55,  8.38it/s] 52%|█████▏    | 505/966 [01:00<00:54,  8.41it/s] 52%|█████▏    | 506/966 [01:00<00:54,  8.41it/s] 52%|█████▏    | 507/966 [01:00<00:54,  8.40it/s] 53%|█████▎    | 508/966 [01:00<00:54,  8.40it/s] 53%|█████▎    | 509/966 [01:00<00:54,  8.40it/s] 53%|█████▎    | 510/966 [01:00<00:54,  8.40it/s] 53%|█████▎    | 511/966 [01:00<00:54,  8.40it/s] 53%|█████▎    | 512/966 [01:00<00:54,  8.40it/s] 53%|█████▎    | 513/966 [01:01<00:53,  8.41it/s] 53%|█████▎    | 514/966 [01:01<00:53,  8.40it/s] 53%|█████▎    | 515/966 [01:01<00:53,  8.40it/s] 53%|█████▎    | 516/966 [01:01<00:53,  8.39it/s] 54%|█████▎    | 517/966 [01:01<00:53,  8.39it/s] 54%|█████▎    | 518/966 [01:01<00:53,  8.39it/s] 54%|█████▎    | 519/966 [01:01<00:53,  8.39it/s] 54%|█████▍    | 520/966 [01:01<00:53,  8.39it/s] 54%|█████▍    | 521/966 [01:02<00:53,  8.38it/s] 54%|█████▍    | 522/966 [01:02<00:52,  8.38it/s] 54%|█████▍    | 523/966 [01:02<00:52,  8.38it/s] 54%|█████▍    | 524/966 [01:02<00:52,  8.37it/s] 54%|█████▍    | 525/966 [01:02<00:52,  8.37it/s] 54%|█████▍    | 526/966 [01:02<00:52,  8.37it/s] 55%|█████▍    | 527/966 [01:02<00:52,  8.37it/s] 55%|█████▍    | 528/966 [01:02<00:52,  8.39it/s] 55%|█████▍    | 529/966 [01:02<00:52,  8.38it/s] 55%|█████▍    | 530/966 [01:03<00:52,  8.37it/s] 55%|█████▍    | 531/966 [01:03<00:51,  8.38it/s] 55%|█████▌    | 532/966 [01:03<00:51,  8.39it/s] 55%|█████▌    | 533/966 [01:03<00:51,  8.38it/s] 55%|█████▌    | 534/966 [01:03<00:51,  8.38it/s] 55%|█████▌    | 535/966 [01:03<00:51,  8.38it/s] 55%|█████▌    | 536/966 [01:03<00:51,  8.39it/s] 56%|█████▌    | 537/966 [01:03<00:51,  8.39it/s] 56%|█████▌    | 538/966 [01:04<00:51,  8.38it/s] 56%|█████▌    | 539/966 [01:04<00:50,  8.38it/s] 56%|█████▌    | 540/966 [01:04<00:50,  8.39it/s] 56%|█████▌    | 541/966 [01:04<00:50,  8.40it/s] 56%|█████▌    | 542/966 [01:04<00:50,  8.41it/s] 56%|█████▌    | 543/966 [01:04<00:50,  8.40it/s] 56%|█████▋    | 544/966 [01:04<00:50,  8.39it/s] 56%|█████▋    | 545/966 [01:04<00:50,  8.39it/s] 57%|█████▋    | 546/966 [01:05<00:50,  8.39it/s] 57%|█████▋    | 547/966 [01:05<00:49,  8.39it/s] 57%|█████▋    | 548/966 [01:05<00:49,  8.40it/s] 57%|█████▋    | 549/966 [01:05<00:49,  8.40it/s] 57%|█████▋    | 550/966 [01:05<00:49,  8.39it/s] 57%|█████▋    | 551/966 [01:05<00:49,  8.39it/s] 57%|█████▋    | 552/966 [01:05<00:49,  8.39it/s] 57%|█████▋    | 553/966 [01:05<00:49,  8.40it/s] 57%|█████▋    | 554/966 [01:05<00:49,  8.40it/s] 57%|█████▋    | 555/966 [01:06<00:48,  8.39it/s] 58%|█████▊    | 556/966 [01:06<00:48,  8.39it/s] 58%|█████▊    | 557/966 [01:06<00:48,  8.39it/s] 58%|█████▊    | 558/966 [01:06<00:48,  8.39it/s] 58%|█████▊    | 559/966 [01:06<00:48,  8.39it/s] 58%|█████▊    | 560/966 [01:06<00:48,  8.38it/s] 58%|█████▊    | 561/966 [01:06<00:48,  8.38it/s] 58%|█████▊    | 562/966 [01:06<00:48,  8.38it/s] 58%|█████▊    | 563/966 [01:07<00:48,  8.38it/s] 58%|█████▊    | 564/966 [01:07<00:47,  8.38it/s] 58%|█████▊    | 565/966 [01:07<00:47,  8.37it/s] 59%|█████▊    | 566/966 [01:07<00:47,  8.38it/s] 59%|█████▊    | 567/966 [01:07<00:47,  8.38it/s] 59%|█████▉    | 568/966 [01:07<00:47,  8.38it/s] 59%|█████▉    | 569/966 [01:07<00:47,  8.37it/s] 59%|█████▉    | 570/966 [01:07<00:47,  8.38it/s] 59%|█████▉    | 571/966 [01:08<00:47,  8.38it/s] 59%|█████▉    | 572/966 [01:08<00:46,  8.39it/s] 59%|█████▉    | 573/966 [01:08<00:46,  8.37it/s] 59%|█████▉    | 574/966 [01:08<00:46,  8.37it/s] 60%|█████▉    | 575/966 [01:08<00:46,  8.37it/s] 60%|█████▉    | 576/966 [01:08<00:46,  8.38it/s] 60%|█████▉    | 577/966 [01:08<00:46,  8.39it/s] 60%|█████▉    | 578/966 [01:08<00:46,  8.39it/s] 60%|█████▉    | 579/966 [01:08<00:46,  8.38it/s] 60%|██████    | 580/966 [01:09<00:46,  8.38it/s] 60%|██████    | 581/966 [01:09<00:45,  8.38it/s] 60%|██████    | 582/966 [01:09<00:45,  8.38it/s] 60%|██████    | 583/966 [01:09<00:45,  8.40it/s] 60%|██████    | 584/966 [01:09<00:45,  8.40it/s] 61%|██████    | 585/966 [01:09<00:45,  8.40it/s] 61%|██████    | 586/966 [01:09<00:45,  8.39it/s] 61%|██████    | 587/966 [01:09<00:45,  8.39it/s] 61%|██████    | 588/966 [01:10<00:45,  8.38it/s] 61%|██████    | 589/966 [01:10<00:44,  8.39it/s] 61%|██████    | 590/966 [01:10<00:44,  8.40it/s] 61%|██████    | 591/966 [01:10<00:44,  8.40it/s] 61%|██████▏   | 592/966 [01:10<00:44,  8.39it/s] 61%|██████▏   | 593/966 [01:10<00:44,  8.39it/s] 61%|██████▏   | 594/966 [01:10<00:44,  8.39it/s] 62%|██████▏   | 595/966 [01:10<00:44,  8.39it/s] 62%|██████▏   | 596/966 [01:10<00:44,  8.39it/s] 62%|██████▏   | 597/966 [01:11<00:43,  8.40it/s] 62%|██████▏   | 598/966 [01:11<00:43,  8.40it/s] 62%|██████▏   | 599/966 [01:11<00:43,  8.40it/s] 62%|██████▏   | 600/966 [01:11<00:43,  8.40it/s] 62%|██████▏   | 601/966 [01:11<00:43,  8.40it/s] 62%|██████▏   | 602/966 [01:11<00:43,  8.39it/s] 62%|██████▏   | 603/966 [01:11<00:43,  8.38it/s] 63%|██████▎   | 604/966 [01:11<00:43,  8.38it/s] 63%|██████▎   | 605/966 [01:12<00:43,  8.38it/s] 63%|██████▎   | 606/966 [01:12<00:42,  8.38it/s] 63%|██████▎   | 607/966 [01:12<00:42,  8.39it/s] 63%|██████▎   | 608/966 [01:12<00:42,  8.38it/s] 63%|██████▎   | 609/966 [01:12<00:42,  8.38it/s] 63%|██████▎   | 610/966 [01:12<00:42,  8.38it/s] 63%|██████▎   | 611/966 [01:12<00:42,  8.38it/s] 63%|██████▎   | 612/966 [01:12<00:42,  8.38it/s] 63%|██████▎   | 613/966 [01:13<00:42,  8.37it/s] 64%|██████▎   | 614/966 [01:13<00:42,  8.38it/s] 64%|██████▎   | 615/966 [01:13<00:41,  8.38it/s] 64%|██████▍   | 616/966 [01:13<00:41,  8.37it/s] 64%|██████▍   | 617/966 [01:13<00:41,  8.38it/s] 64%|██████▍   | 618/966 [01:13<00:41,  8.38it/s] 64%|██████▍   | 619/966 [01:13<00:41,  8.38it/s] 64%|██████▍   | 620/966 [01:13<00:41,  8.40it/s] 64%|██████▍   | 621/966 [01:13<00:41,  8.38it/s] 64%|██████▍   | 622/966 [01:14<00:41,  8.38it/s] 64%|██████▍   | 623/966 [01:14<00:40,  8.39it/s] 65%|██████▍   | 624/966 [01:14<00:40,  8.39it/s] 65%|██████▍   | 625/966 [01:14<00:40,  8.39it/s] 65%|██████▍   | 626/966 [01:14<00:40,  8.40it/s] 65%|██████▍   | 627/966 [01:14<00:40,  8.39it/s] 65%|██████▌   | 628/966 [01:14<00:40,  8.39it/s] 65%|██████▌   | 629/966 [01:14<00:40,  8.40it/s] 65%|██████▌   | 630/966 [01:15<00:40,  8.40it/s] 65%|██████▌   | 631/966 [01:15<00:39,  8.39it/s] 65%|██████▌   | 632/966 [01:15<00:39,  8.40it/s] 66%|██████▌   | 633/966 [01:15<00:39,  8.40it/s] 66%|██████▌   | 634/966 [01:15<00:39,  8.39it/s] 66%|██████▌   | 635/966 [01:15<00:39,  8.39it/s] 66%|██████▌   | 636/966 [01:15<00:39,  8.40it/s] 66%|██████▌   | 637/966 [01:15<00:39,  8.41it/s] 66%|██████▌   | 638/966 [01:15<00:39,  8.41it/s] 66%|██████▌   | 639/966 [01:16<00:38,  8.40it/s] 66%|██████▋   | 640/966 [01:16<00:38,  8.39it/s] 66%|██████▋   | 641/966 [01:16<00:38,  8.38it/s] 66%|██████▋   | 642/966 [01:16<00:38,  8.39it/s] 67%|██████▋   | 643/966 [01:16<00:38,  8.39it/s] 67%|██████▋   | 644/966 [01:16<00:38,  8.38it/s] 67%|██████▋   | 645/966 [01:16<00:38,  8.38it/s] 67%|██████▋   | 646/966 [01:16<00:38,  8.38it/s] 67%|██████▋   | 647/966 [01:17<00:38,  8.38it/s] 67%|██████▋   | 648/966 [01:17<00:37,  8.38it/s] 67%|██████▋   | 649/966 [01:17<00:37,  8.38it/s] 67%|██████▋   | 650/966 [01:17<00:37,  8.37it/s] 67%|██████▋   | 651/966 [01:17<00:37,  8.39it/s] 67%|██████▋   | 652/966 [01:17<00:37,  8.39it/s] 68%|██████▊   | 653/966 [01:17<00:37,  8.38it/s] 68%|██████▊   | 654/966 [01:17<00:37,  8.38it/s] 68%|██████▊   | 655/966 [01:18<00:37,  8.39it/s] 68%|██████▊   | 656/966 [01:18<00:37,  8.38it/s] 68%|██████▊   | 657/966 [01:18<00:36,  8.37it/s] 68%|██████▊   | 658/966 [01:18<00:36,  8.37it/s] 68%|██████▊   | 659/966 [01:18<00:36,  8.38it/s] 68%|██████▊   | 660/966 [01:18<00:36,  8.39it/s] 68%|██████▊   | 661/966 [01:18<00:36,  8.38it/s] 69%|██████▊   | 662/966 [01:18<00:36,  8.39it/s] 69%|██████▊   | 663/966 [01:18<00:36,  8.38it/s] 69%|██████▊   | 664/966 [01:19<00:36,  8.38it/s] 69%|██████▉   | 665/966 [01:19<00:35,  8.38it/s] 69%|██████▉   | 666/966 [01:19<00:35,  8.38it/s] 69%|██████▉   | 667/966 [01:19<00:35,  8.38it/s] 69%|██████▉   | 668/966 [01:19<00:35,  8.39it/s] 69%|██████▉   | 669/966 [01:19<00:35,  8.39it/s] 69%|██████▉   | 670/966 [01:19<00:35,  8.39it/s] 69%|██████▉   | 671/966 [01:19<00:35,  8.39it/s] 70%|██████▉   | 672/966 [01:20<00:35,  8.39it/s] 70%|██████▉   | 673/966 [01:20<00:34,  8.39it/s] 70%|██████▉   | 674/966 [01:20<00:34,  8.39it/s] 70%|██████▉   | 675/966 [01:20<00:34,  8.39it/s] 70%|██████▉   | 676/966 [01:20<00:34,  8.39it/s] 70%|███████   | 677/966 [01:20<00:34,  8.40it/s] 70%|███████   | 678/966 [01:20<00:34,  8.40it/s] 70%|███████   | 679/966 [01:20<00:34,  8.40it/s] 70%|███████   | 680/966 [01:21<00:34,  8.41it/s] 70%|███████   | 681/966 [01:21<00:33,  8.39it/s] 71%|███████   | 682/966 [01:21<00:33,  8.38it/s] 71%|███████   | 683/966 [01:21<00:33,  8.38it/s] 71%|███████   | 684/966 [01:21<00:33,  8.38it/s] 71%|███████   | 685/966 [01:21<00:33,  8.39it/s] 71%|███████   | 686/966 [01:21<00:33,  8.39it/s] 71%|███████   | 687/966 [01:21<00:33,  8.39it/s] 71%|███████   | 688/966 [01:21<00:33,  8.40it/s] 71%|███████▏  | 689/966 [01:22<00:33,  8.39it/s] 71%|███████▏  | 690/966 [01:22<00:32,  8.39it/s] 72%|███████▏  | 691/966 [01:22<00:32,  8.38it/s] 72%|███████▏  | 692/966 [01:22<00:32,  8.38it/s] 72%|███████▏  | 693/966 [01:22<00:32,  8.37it/s] 72%|███████▏  | 694/966 [01:22<00:32,  8.37it/s] 72%|███████▏  | 695/966 [01:22<00:32,  8.37it/s] 72%|███████▏  | 696/966 [01:22<00:32,  8.39it/s] 72%|███████▏  | 697/966 [01:23<00:32,  8.38it/s] 72%|███████▏  | 698/966 [01:23<00:32,  8.37it/s] 72%|███████▏  | 699/966 [01:23<00:31,  8.36it/s] 72%|███████▏  | 700/966 [01:23<00:31,  8.37it/s] 73%|███████▎  | 701/966 [01:23<00:31,  8.37it/s] 73%|███████▎  | 702/966 [01:23<00:31,  8.36it/s] 73%|███████▎  | 703/966 [01:23<00:31,  8.37it/s] 73%|███████▎  | 704/966 [01:23<00:31,  8.38it/s] 73%|███████▎  | 705/966 [01:23<00:31,  8.38it/s] 73%|███████▎  | 706/966 [01:24<00:30,  8.39it/s] 73%|███████▎  | 707/966 [01:24<00:30,  8.39it/s] 73%|███████▎  | 708/966 [01:24<00:30,  8.39it/s] 73%|███████▎  | 709/966 [01:24<00:30,  8.41it/s] 73%|███████▎  | 710/966 [01:24<00:30,  8.40it/s] 74%|███████▎  | 711/966 [01:24<00:30,  8.40it/s] 74%|███████▎  | 712/966 [01:24<00:30,  8.39it/s] 74%|███████▍  | 713/966 [01:24<00:30,  8.39it/s] 74%|███████▍  | 714/966 [01:25<00:30,  8.40it/s] 74%|███████▍  | 715/966 [01:25<00:29,  8.40it/s] 74%|███████▍  | 716/966 [01:25<00:29,  8.40it/s] 74%|███████▍  | 717/966 [01:25<00:29,  8.41it/s] 74%|███████▍  | 718/966 [01:25<00:29,  8.41it/s] 74%|███████▍  | 719/966 [01:25<00:29,  8.40it/s] 75%|███████▍  | 720/966 [01:25<00:29,  8.40it/s] 75%|███████▍  | 721/966 [01:25<00:29,  8.42it/s] 75%|███████▍  | 722/966 [01:26<00:28,  8.42it/s] 75%|███████▍  | 723/966 [01:26<00:28,  8.40it/s] 75%|███████▍  | 724/966 [01:26<00:28,  8.40it/s] 75%|███████▌  | 725/966 [01:26<00:28,  8.38it/s] 75%|███████▌  | 726/966 [01:26<00:28,  8.38it/s] 75%|███████▌  | 727/966 [01:26<00:28,  8.39it/s] 75%|███████▌  | 728/966 [01:26<00:28,  8.38it/s] 75%|███████▌  | 729/966 [01:26<00:28,  8.39it/s] 76%|███████▌  | 730/966 [01:26<00:28,  8.39it/s] 76%|███████▌  | 731/966 [01:27<00:28,  8.38it/s] 76%|███████▌  | 732/966 [01:27<00:27,  8.38it/s] 76%|███████▌  | 733/966 [01:27<00:27,  8.37it/s] 76%|███████▌  | 734/966 [01:27<00:27,  8.38it/s] 76%|███████▌  | 735/966 [01:27<00:27,  8.37it/s] 76%|███████▌  | 736/966 [01:27<00:27,  8.38it/s] 76%|███████▋  | 737/966 [01:27<00:27,  8.38it/s] 76%|███████▋  | 738/966 [01:27<00:27,  8.38it/s] 77%|███████▋  | 739/966 [01:28<00:27,  8.38it/s] 77%|███████▋  | 740/966 [01:28<00:26,  8.39it/s] 77%|███████▋  | 741/966 [01:28<00:26,  8.37it/s] 77%|███████▋  | 742/966 [01:28<00:26,  8.37it/s] 77%|███████▋  | 743/966 [01:28<00:26,  8.38it/s] 77%|███████▋  | 744/966 [01:28<00:26,  8.37it/s] 77%|███████▋  | 745/966 [01:28<00:26,  8.38it/s] 77%|███████▋  | 746/966 [01:28<00:26,  8.38it/s] 77%|███████▋  | 747/966 [01:28<00:26,  8.38it/s] 77%|███████▋  | 748/966 [01:29<00:25,  8.39it/s] 78%|███████▊  | 749/966 [01:29<00:25,  8.39it/s] 78%|███████▊  | 750/966 [01:29<00:25,  8.39it/s] 78%|███████▊  | 751/966 [01:29<00:25,  8.39it/s] 78%|███████▊  | 752/966 [01:29<00:25,  8.39it/s] 78%|███████▊  | 753/966 [01:29<00:25,  8.40it/s] 78%|███████▊  | 754/966 [01:29<00:25,  8.39it/s] 78%|███████▊  | 755/966 [01:29<00:25,  8.39it/s] 78%|███████▊  | 756/966 [01:30<00:25,  8.40it/s] 78%|███████▊  | 757/966 [01:30<00:24,  8.40it/s] 78%|███████▊  | 758/966 [01:30<00:24,  8.41it/s] 79%|███████▊  | 759/966 [01:30<00:24,  8.40it/s] 79%|███████▊  | 760/966 [01:30<00:24,  8.40it/s] 79%|███████▉  | 761/966 [01:30<00:24,  8.40it/s] 79%|███████▉  | 762/966 [01:30<00:24,  8.39it/s] 79%|███████▉  | 763/966 [01:30<00:24,  8.39it/s] 79%|███████▉  | 764/966 [01:31<00:24,  8.40it/s] 79%|███████▉  | 765/966 [01:31<00:23,  8.39it/s] 79%|███████▉  | 766/966 [01:31<00:23,  8.40it/s] 79%|███████▉  | 767/966 [01:31<00:23,  8.39it/s] 80%|███████▉  | 768/966 [01:31<00:23,  8.39it/s] 80%|███████▉  | 769/966 [01:31<00:23,  8.39it/s] 80%|███████▉  | 770/966 [01:31<00:23,  8.39it/s] 80%|███████▉  | 771/966 [01:31<00:23,  8.38it/s] 80%|███████▉  | 772/966 [01:31<00:23,  8.37it/s] 80%|████████  | 773/966 [01:32<00:23,  8.38it/s] 80%|████████  | 774/966 [01:32<00:22,  8.39it/s] 80%|████████  | 775/966 [01:32<00:22,  8.38it/s] 80%|████████  | 776/966 [01:32<00:22,  8.38it/s] 80%|████████  | 777/966 [01:32<00:22,  8.39it/s] 81%|████████  | 778/966 [01:32<00:22,  8.39it/s] 81%|████████  | 779/966 [01:32<00:22,  8.38it/s] 81%|████████  | 780/966 [01:32<00:22,  8.37it/s] 81%|████████  | 781/966 [01:33<00:22,  8.38it/s] 81%|████████  | 782/966 [01:33<00:21,  8.39it/s] 81%|████████  | 783/966 [01:33<00:21,  8.39it/s] 81%|████████  | 784/966 [01:33<00:21,  8.38it/s] 81%|████████▏ | 785/966 [01:33<00:21,  8.39it/s] 81%|████████▏ | 786/966 [01:33<00:21,  8.39it/s] 81%|████████▏ | 787/966 [01:33<00:21,  8.38it/s] 82%|████████▏ | 788/966 [01:33<00:21,  8.38it/s] 82%|████████▏ | 789/966 [01:33<00:21,  8.38it/s] 82%|████████▏ | 790/966 [01:34<00:20,  8.39it/s] 82%|████████▏ | 791/966 [01:34<00:20,  8.39it/s] 82%|████████▏ | 792/966 [01:34<00:20,  8.39it/s] 82%|████████▏ | 793/966 [01:34<00:20,  8.40it/s] 82%|████████▏ | 794/966 [01:34<00:20,  8.41it/s] 82%|████████▏ | 795/966 [01:34<00:20,  8.40it/s] 82%|████████▏ | 796/966 [01:34<00:20,  8.39it/s] 83%|████████▎ | 797/966 [01:34<00:20,  8.39it/s] 83%|████████▎ | 798/966 [01:35<00:20,  8.39it/s] 83%|████████▎ | 799/966 [01:35<00:19,  8.41it/s] 83%|████████▎ | 800/966 [01:35<00:19,  8.43it/s] 83%|████████▎ | 801/966 [01:35<00:19,  8.42it/s] 83%|████████▎ | 802/966 [01:35<00:19,  8.41it/s] 83%|████████▎ | 803/966 [01:35<00:19,  8.40it/s] 83%|████████▎ | 804/966 [01:35<00:19,  8.41it/s] 83%|████████▎ | 805/966 [01:35<00:19,  8.40it/s] 83%|████████▎ | 806/966 [01:36<00:19,  8.40it/s] 84%|████████▎ | 807/966 [01:36<00:18,  8.40it/s] 84%|████████▎ | 808/966 [01:36<00:18,  8.40it/s] 84%|████████▎ | 809/966 [01:36<00:18,  8.38it/s] 84%|████████▍ | 810/966 [01:36<00:18,  8.39it/s] 84%|████████▍ | 811/966 [01:36<00:18,  8.39it/s] 84%|████████▍ | 812/966 [01:36<00:18,  8.39it/s] 84%|████████▍ | 813/966 [01:36<00:18,  8.38it/s] 84%|████████▍ | 814/966 [01:36<00:18,  8.37it/s] 84%|████████▍ | 815/966 [01:37<00:18,  8.38it/s] 84%|████████▍ | 816/966 [01:37<00:17,  8.38it/s] 85%|████████▍ | 817/966 [01:37<00:17,  8.37it/s] 85%|████████▍ | 818/966 [01:37<00:17,  8.38it/s] 85%|████████▍ | 819/966 [01:37<00:17,  8.38it/s] 85%|████████▍ | 820/966 [01:37<00:17,  8.38it/s] 85%|████████▍ | 821/966 [01:37<00:17,  8.38it/s] 85%|████████▌ | 822/966 [01:37<00:17,  8.37it/s] 85%|████████▌ | 823/966 [01:38<00:17,  8.37it/s] 85%|████████▌ | 824/966 [01:38<00:16,  8.37it/s] 85%|████████▌ | 825/966 [01:38<00:16,  8.37it/s] 86%|████████▌ | 826/966 [01:38<00:16,  8.38it/s] 86%|████████▌ | 827/966 [01:38<00:16,  8.38it/s] 86%|████████▌ | 828/966 [01:38<00:16,  8.38it/s] 86%|████████▌ | 829/966 [01:38<00:16,  8.38it/s] 86%|████████▌ | 830/966 [01:38<00:16,  8.39it/s] 86%|████████▌ | 831/966 [01:39<00:16,  8.38it/s] 86%|████████▌ | 832/966 [01:39<00:15,  8.38it/s] 86%|████████▌ | 833/966 [01:39<00:15,  8.38it/s] 86%|████████▋ | 834/966 [01:39<00:15,  8.38it/s] 86%|████████▋ | 835/966 [01:39<00:15,  8.39it/s] 87%|████████▋ | 836/966 [01:39<00:15,  8.38it/s] 87%|████████▋ | 837/966 [01:39<00:15,  8.38it/s] 87%|████████▋ | 838/966 [01:39<00:15,  8.39it/s] 87%|████████▋ | 839/966 [01:39<00:15,  8.39it/s] 87%|████████▋ | 840/966 [01:40<00:15,  8.38it/s] 87%|████████▋ | 841/966 [01:40<00:14,  8.39it/s] 87%|████████▋ | 842/966 [01:40<00:14,  8.40it/s] 87%|████████▋ | 843/966 [01:40<00:14,  8.39it/s] 87%|████████▋ | 844/966 [01:40<00:14,  8.39it/s] 87%|████████▋ | 845/966 [01:40<00:14,  8.39it/s] 88%|████████▊ | 846/966 [01:40<00:14,  8.39it/s] 88%|████████▊ | 847/966 [01:40<00:14,  8.39it/s] 88%|████████▊ | 848/966 [01:41<00:14,  8.40it/s] 88%|████████▊ | 849/966 [01:41<00:13,  8.38it/s] 88%|████████▊ | 850/966 [01:41<00:13,  8.38it/s] 88%|████████▊ | 851/966 [01:41<00:13,  8.38it/s] 88%|████████▊ | 852/966 [01:41<00:13,  8.38it/s] 88%|████████▊ | 853/966 [01:41<00:13,  8.38it/s] 88%|████████▊ | 854/966 [01:41<00:13,  8.38it/s] 89%|████████▊ | 855/966 [01:41<00:13,  8.38it/s] 89%|████████▊ | 856/966 [01:41<00:13,  8.38it/s] 89%|████████▊ | 857/966 [01:42<00:13,  8.38it/s] 89%|████████▉ | 858/966 [01:42<00:12,  8.37it/s] 89%|████████▉ | 859/966 [01:42<00:12,  8.37it/s] 89%|████████▉ | 860/966 [01:42<00:12,  8.38it/s] 89%|████████▉ | 861/966 [01:42<00:12,  8.38it/s] 89%|████████▉ | 862/966 [01:42<00:12,  8.37it/s] 89%|████████▉ | 863/966 [01:42<00:12,  8.37it/s] 89%|████████▉ | 864/966 [01:42<00:12,  8.37it/s] 90%|████████▉ | 865/966 [01:43<00:12,  8.37it/s] 90%|████████▉ | 866/966 [01:43<00:11,  8.37it/s] 90%|████████▉ | 867/966 [01:43<00:11,  8.37it/s] 90%|████████▉ | 868/966 [01:43<00:11,  8.37it/s] 90%|████████▉ | 869/966 [01:43<00:11,  8.37it/s] 90%|█████████ | 870/966 [01:43<00:11,  8.37it/s] 90%|█████████ | 871/966 [01:43<00:11,  8.37it/s] 90%|█████████ | 872/966 [01:43<00:11,  8.38it/s] 90%|█████████ | 873/966 [01:44<00:11,  8.38it/s] 90%|█████████ | 874/966 [01:44<00:10,  8.38it/s] 91%|█████████ | 875/966 [01:44<00:10,  8.37it/s] 91%|█████████ | 876/966 [01:44<00:10,  8.38it/s] 91%|█████████ | 877/966 [01:44<00:10,  8.39it/s] 91%|█████████ | 878/966 [01:44<00:10,  8.39it/s] 91%|█████████ | 879/966 [01:44<00:10,  8.39it/s] 91%|█████████ | 880/966 [01:44<00:10,  8.38it/s] 91%|█████████ | 881/966 [01:44<00:10,  8.39it/s] 91%|█████████▏| 882/966 [01:45<00:10,  8.40it/s] 91%|█████████▏| 883/966 [01:45<00:09,  8.41it/s] 92%|█████████▏| 884/966 [01:45<00:09,  8.41it/s] 92%|█████████▏| 885/966 [01:45<00:09,  8.40it/s] 92%|█████████▏| 886/966 [01:45<00:09,  8.39it/s] 92%|█████████▏| 887/966 [01:45<00:09,  8.39it/s] 92%|█████████▏| 888/966 [01:45<00:09,  8.39it/s] 92%|█████████▏| 889/966 [01:45<00:09,  8.38it/s] 92%|█████████▏| 890/966 [01:46<00:09,  8.38it/s] 92%|█████████▏| 891/966 [01:46<00:08,  8.40it/s] 92%|█████████▏| 892/966 [01:46<00:08,  8.39it/s] 92%|█████████▏| 893/966 [01:46<00:08,  8.39it/s] 93%|█████████▎| 894/966 [01:46<00:08,  8.40it/s] 93%|█████████▎| 895/966 [01:46<00:08,  8.39it/s] 93%|█████████▎| 896/966 [01:46<00:08,  8.39it/s] 93%|█████████▎| 897/966 [01:46<00:08,  8.38it/s] 93%|█████████▎| 898/966 [01:46<00:08,  8.38it/s] 93%|█████████▎| 899/966 [01:47<00:07,  8.38it/s] 93%|█████████▎| 900/966 [01:47<00:07,  8.38it/s] 93%|█████████▎| 901/966 [01:47<00:07,  8.38it/s] 93%|█████████▎| 902/966 [01:47<00:07,  8.37it/s] 93%|█████████▎| 903/966 [01:47<00:07,  8.37it/s] 94%|█████████▎| 904/966 [01:47<00:07,  8.38it/s] 94%|█████████▎| 905/966 [01:47<00:07,  8.38it/s] 94%|█████████▍| 906/966 [01:47<00:07,  8.38it/s] 94%|█████████▍| 907/966 [01:48<00:07,  8.38it/s] 94%|█████████▍| 908/966 [01:48<00:06,  8.38it/s] 94%|█████████▍| 909/966 [01:48<00:06,  8.38it/s] 94%|█████████▍| 910/966 [01:48<00:06,  8.37it/s] 94%|█████████▍| 911/966 [01:48<00:06,  8.38it/s] 94%|█████████▍| 912/966 [01:48<00:06,  8.38it/s] 95%|█████████▍| 913/966 [01:48<00:06,  8.38it/s] 95%|█████████▍| 914/966 [01:48<00:06,  8.39it/s] 95%|█████████▍| 915/966 [01:49<00:06,  8.38it/s] 95%|█████████▍| 916/966 [01:49<00:05,  8.38it/s] 95%|█████████▍| 917/966 [01:49<00:05,  8.38it/s] 95%|█████████▌| 918/966 [01:49<00:05,  8.37it/s] 95%|█████████▌| 919/966 [01:49<00:05,  8.38it/s] 95%|█████████▌| 920/966 [01:49<00:05,  8.37it/s] 95%|█████████▌| 921/966 [01:49<00:05,  8.38it/s] 95%|█████████▌| 922/966 [01:49<00:05,  8.38it/s] 96%|█████████▌| 923/966 [01:49<00:05,  8.38it/s] 96%|█████████▌| 924/966 [01:50<00:05,  8.39it/s] 96%|█████████▌| 925/966 [01:50<00:04,  8.39it/s] 96%|█████████▌| 926/966 [01:50<00:04,  8.40it/s] 96%|█████████▌| 927/966 [01:50<00:04,  8.39it/s] 96%|█████████▌| 928/966 [01:50<00:04,  8.39it/s] 96%|█████████▌| 929/966 [01:50<00:04,  8.40it/s] 96%|█████████▋| 930/966 [01:50<00:04,  8.40it/s] 96%|█████████▋| 931/966 [01:50<00:04,  8.40it/s] 96%|█████████▋| 932/966 [01:51<00:04,  8.40it/s] 97%|█████████▋| 933/966 [01:51<00:03,  8.39it/s] 97%|█████████▋| 934/966 [01:51<00:03,  8.40it/s] 97%|█████████▋| 935/966 [01:51<00:03,  8.40it/s] 97%|█████████▋| 936/966 [01:51<00:03,  8.39it/s] 97%|█████████▋| 937/966 [01:51<00:03,  8.38it/s] 97%|█████████▋| 938/966 [01:51<00:03,  8.37it/s] 97%|█████████▋| 939/966 [01:51<00:03,  8.38it/s] 97%|█████████▋| 940/966 [01:52<00:03,  8.37it/s] 97%|█████████▋| 941/966 [01:52<00:02,  8.37it/s] 98%|█████████▊| 942/966 [01:52<00:02,  8.37it/s] 98%|█████████▊| 943/966 [01:52<00:02,  8.37it/s] 98%|█████████▊| 944/966 [01:52<00:02,  8.38it/s] 98%|█████████▊| 945/966 [01:52<00:02,  8.38it/s] 98%|█████████▊| 946/966 [01:52<00:02,  8.38it/s] 98%|█████████▊| 947/966 [01:52<00:02,  8.38it/s] 98%|█████████▊| 948/966 [01:52<00:02,  8.38it/s] 98%|█████████▊| 949/966 [01:53<00:02,  8.38it/s] 98%|█████████▊| 950/966 [01:53<00:01,  8.38it/s] 98%|█████████▊| 951/966 [01:53<00:01,  8.38it/s] 99%|█████████▊| 952/966 [01:53<00:01,  8.38it/s] 99%|█████████▊| 953/966 [01:53<00:01,  8.38it/s] 99%|█████████▉| 954/966 [01:53<00:01,  8.37it/s] 99%|█████████▉| 955/966 [01:53<00:01,  8.37it/s] 99%|█████████▉| 956/966 [01:53<00:01,  8.37it/s] 99%|█████████▉| 957/966 [01:54<00:01,  8.38it/s] 99%|█████████▉| 958/966 [01:54<00:00,  8.38it/s] 99%|█████████▉| 959/966 [01:54<00:00,  8.38it/s] 99%|█████████▉| 960/966 [01:54<00:00,  8.39it/s] 99%|█████████▉| 961/966 [01:54<00:00,  8.39it/s]100%|█████████▉| 962/966 [01:54<00:00,  8.41it/s]100%|█████████▉| 963/966 [01:54<00:00,  8.40it/s]100%|█████████▉| 964/966 [01:54<00:00,  8.39it/s]100%|█████████▉| 965/966 [01:54<00:00,  8.40it/s]100%|██████████| 966/966 [01:55<00:00,  8.39it/s]100%|██████████| 966/966 [01:55<00:00,  8.39it/s]
sending off prediction to background worker for resampling and export
done with 706-005
mv: cannot move '/home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset302_Calcium_OCTv2/nnUNetTrainer4PretrainedEncoder__nnUNetPlans__3d_32x160x128_b10/fold_0' to '/home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset302_Calcium_OCTv2/nnUNetTrainer4PretrainedEncoder__nnUNetPlans__3d_32x160x128_b10/fold_0_pretrained_with_CLIP_PreIVL_PostStent_wd/fold_0': Directory not empty
