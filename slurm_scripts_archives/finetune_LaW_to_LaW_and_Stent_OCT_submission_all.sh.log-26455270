/home/gridsan/nchutisilp/.conda/envs/nnunet/bin/python
wandb: Tracking run with wandb version 0.16.6
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2024-07-05 22:12:51.358568: Using torch.compile...
/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
################### Loading pretrained weights from file  /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset300_Lumen_and_Wall_OCT/nnUNetTrainer__nnUNetPreprocessPlans__3d_fullres/fold_all/checkpoint_best.pth ###################
Below is the list of overlapping blocks in pretrained model and nnUNet architecture:
encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])
encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])
encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])
encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])
encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])
encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])
encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])
encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])
encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])
encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])
encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])
encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])
encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])
encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])
encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])
encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])
encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])
encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])
encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])
encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])
encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])
encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])
encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])
encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])
encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])
encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])
encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])
encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])
encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])
encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])
encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])
encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])
encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])
encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])
encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])
encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])
encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])
encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])
encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.0.0.convs.0.conv.weight shape torch.Size([32, 1, 3, 3, 3])
decoder.encoder.stages.0.0.convs.0.conv.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.norm.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.norm.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.0.weight shape torch.Size([32, 1, 3, 3, 3])
decoder.encoder.stages.0.0.convs.0.all_modules.0.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.1.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.0.all_modules.1.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.encoder.stages.0.0.convs.1.conv.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.norm.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.norm.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.encoder.stages.0.0.convs.1.all_modules.0.bias shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.1.weight shape torch.Size([32])
decoder.encoder.stages.0.0.convs.1.all_modules.1.bias shape torch.Size([32])
decoder.encoder.stages.1.0.convs.0.conv.weight shape torch.Size([64, 32, 3, 3, 3])
decoder.encoder.stages.1.0.convs.0.conv.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.norm.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.norm.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.0.weight shape torch.Size([64, 32, 3, 3, 3])
decoder.encoder.stages.1.0.convs.0.all_modules.0.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.1.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.0.all_modules.1.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.encoder.stages.1.0.convs.1.conv.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.norm.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.norm.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.encoder.stages.1.0.convs.1.all_modules.0.bias shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.1.weight shape torch.Size([64])
decoder.encoder.stages.1.0.convs.1.all_modules.1.bias shape torch.Size([64])
decoder.encoder.stages.2.0.convs.0.conv.weight shape torch.Size([128, 64, 3, 3, 3])
decoder.encoder.stages.2.0.convs.0.conv.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.norm.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.norm.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.0.weight shape torch.Size([128, 64, 3, 3, 3])
decoder.encoder.stages.2.0.convs.0.all_modules.0.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.1.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.0.all_modules.1.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.encoder.stages.2.0.convs.1.conv.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.norm.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.norm.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.encoder.stages.2.0.convs.1.all_modules.0.bias shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.1.weight shape torch.Size([128])
decoder.encoder.stages.2.0.convs.1.all_modules.1.bias shape torch.Size([128])
decoder.encoder.stages.3.0.convs.0.conv.weight shape torch.Size([256, 128, 3, 3, 3])
decoder.encoder.stages.3.0.convs.0.conv.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.norm.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.norm.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.0.weight shape torch.Size([256, 128, 3, 3, 3])
decoder.encoder.stages.3.0.convs.0.all_modules.0.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.1.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.0.all_modules.1.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.encoder.stages.3.0.convs.1.conv.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.norm.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.norm.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.encoder.stages.3.0.convs.1.all_modules.0.bias shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.1.weight shape torch.Size([256])
decoder.encoder.stages.3.0.convs.1.all_modules.1.bias shape torch.Size([256])
decoder.encoder.stages.4.0.convs.0.conv.weight shape torch.Size([320, 256, 3, 3, 3])
decoder.encoder.stages.4.0.convs.0.conv.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.norm.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.norm.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.0.weight shape torch.Size([320, 256, 3, 3, 3])
decoder.encoder.stages.4.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.4.0.convs.1.conv.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.norm.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.norm.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.4.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.4.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.0.conv.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.norm.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.norm.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.1.conv.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.norm.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.norm.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.encoder.stages.5.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.encoder.stages.5.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.stages.0.convs.0.conv.weight shape torch.Size([320, 640, 3, 3, 3])
decoder.stages.0.convs.0.conv.bias shape torch.Size([320])
decoder.stages.0.convs.0.norm.weight shape torch.Size([320])
decoder.stages.0.convs.0.norm.bias shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.0.weight shape torch.Size([320, 640, 3, 3, 3])
decoder.stages.0.convs.0.all_modules.0.bias shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.1.weight shape torch.Size([320])
decoder.stages.0.convs.0.all_modules.1.bias shape torch.Size([320])
decoder.stages.0.convs.1.conv.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.stages.0.convs.1.conv.bias shape torch.Size([320])
decoder.stages.0.convs.1.norm.weight shape torch.Size([320])
decoder.stages.0.convs.1.norm.bias shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.0.weight shape torch.Size([320, 320, 3, 3, 3])
decoder.stages.0.convs.1.all_modules.0.bias shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.1.weight shape torch.Size([320])
decoder.stages.0.convs.1.all_modules.1.bias shape torch.Size([320])
decoder.stages.1.convs.0.conv.weight shape torch.Size([256, 512, 3, 3, 3])
decoder.stages.1.convs.0.conv.bias shape torch.Size([256])
decoder.stages.1.convs.0.norm.weight shape torch.Size([256])
decoder.stages.1.convs.0.norm.bias shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.0.weight shape torch.Size([256, 512, 3, 3, 3])
decoder.stages.1.convs.0.all_modules.0.bias shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.1.weight shape torch.Size([256])
decoder.stages.1.convs.0.all_modules.1.bias shape torch.Size([256])
decoder.stages.1.convs.1.conv.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.stages.1.convs.1.conv.bias shape torch.Size([256])
decoder.stages.1.convs.1.norm.weight shape torch.Size([256])
decoder.stages.1.convs.1.norm.bias shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.0.weight shape torch.Size([256, 256, 3, 3, 3])
decoder.stages.1.convs.1.all_modules.0.bias shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.1.weight shape torch.Size([256])
decoder.stages.1.convs.1.all_modules.1.bias shape torch.Size([256])
decoder.stages.2.convs.0.conv.weight shape torch.Size([128, 256, 3, 3, 3])
decoder.stages.2.convs.0.conv.bias shape torch.Size([128])
decoder.stages.2.convs.0.norm.weight shape torch.Size([128])
decoder.stages.2.convs.0.norm.bias shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.0.weight shape torch.Size([128, 256, 3, 3, 3])
decoder.stages.2.convs.0.all_modules.0.bias shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.1.weight shape torch.Size([128])
decoder.stages.2.convs.0.all_modules.1.bias shape torch.Size([128])
decoder.stages.2.convs.1.conv.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.stages.2.convs.1.conv.bias shape torch.Size([128])
decoder.stages.2.convs.1.norm.weight shape torch.Size([128])
decoder.stages.2.convs.1.norm.bias shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.0.weight shape torch.Size([128, 128, 3, 3, 3])
decoder.stages.2.convs.1.all_modules.0.bias shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.1.weight shape torch.Size([128])
decoder.stages.2.convs.1.all_modules.1.bias shape torch.Size([128])
decoder.stages.3.convs.0.conv.weight shape torch.Size([64, 128, 3, 3, 3])
decoder.stages.3.convs.0.conv.bias shape torch.Size([64])
decoder.stages.3.convs.0.norm.weight shape torch.Size([64])
decoder.stages.3.convs.0.norm.bias shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.0.weight shape torch.Size([64, 128, 3, 3, 3])
decoder.stages.3.convs.0.all_modules.0.bias shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.1.weight shape torch.Size([64])
decoder.stages.3.convs.0.all_modules.1.bias shape torch.Size([64])
decoder.stages.3.convs.1.conv.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.stages.3.convs.1.conv.bias shape torch.Size([64])
decoder.stages.3.convs.1.norm.weight shape torch.Size([64])
decoder.stages.3.convs.1.norm.bias shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.0.weight shape torch.Size([64, 64, 3, 3, 3])
decoder.stages.3.convs.1.all_modules.0.bias shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.1.weight shape torch.Size([64])
decoder.stages.3.convs.1.all_modules.1.bias shape torch.Size([64])
decoder.stages.4.convs.0.conv.weight shape torch.Size([32, 64, 3, 3, 3])
decoder.stages.4.convs.0.conv.bias shape torch.Size([32])
decoder.stages.4.convs.0.norm.weight shape torch.Size([32])
decoder.stages.4.convs.0.norm.bias shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.0.weight shape torch.Size([32, 64, 3, 3, 3])
decoder.stages.4.convs.0.all_modules.0.bias shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.1.weight shape torch.Size([32])
decoder.stages.4.convs.0.all_modules.1.bias shape torch.Size([32])
decoder.stages.4.convs.1.conv.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.stages.4.convs.1.conv.bias shape torch.Size([32])
decoder.stages.4.convs.1.norm.weight shape torch.Size([32])
decoder.stages.4.convs.1.norm.bias shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.0.weight shape torch.Size([32, 32, 3, 3, 3])
decoder.stages.4.convs.1.all_modules.0.bias shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.1.weight shape torch.Size([32])
decoder.stages.4.convs.1.all_modules.1.bias shape torch.Size([32])
decoder.transpconvs.0.weight shape torch.Size([320, 320, 1, 2, 2])
decoder.transpconvs.0.bias shape torch.Size([320])
decoder.transpconvs.1.weight shape torch.Size([320, 256, 2, 2, 2])
decoder.transpconvs.1.bias shape torch.Size([256])
decoder.transpconvs.2.weight shape torch.Size([256, 128, 2, 2, 2])
decoder.transpconvs.2.bias shape torch.Size([128])
decoder.transpconvs.3.weight shape torch.Size([128, 64, 2, 2, 2])
decoder.transpconvs.3.bias shape torch.Size([64])
decoder.transpconvs.4.weight shape torch.Size([64, 32, 2, 2, 2])
decoder.transpconvs.4.bias shape torch.Size([32])
################### Done ###################
2024-07-05 22:13:15.698745: do_dummy_2d_data_aug: False
using pin_memory on device 0
using pin_memory on device 0

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [112, 160, 128], 'median_image_size_in_voxels': [374.0, 498.0, 498.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset304_Lumen_and_Wall_OCT', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [374, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 128.0, 'mean': 22.287811279296875, 'median': 7.0, 'min': 0.0, 'percentile_00_5': 0.01953125, 'percentile_99_5': 128.0, 'std': 31.701568603515625}}} 

2024-07-05 22:13:26.259570: unpacking dataset...
2024-07-05 22:13:38.235334: unpacking done...
2024-07-05 22:13:38.279607: Unable to plot network architecture: nnUNet_compile is enabled!
2024-07-05 22:13:38.817345: 
2024-07-05 22:13:38.820283: Epoch 0
2024-07-05 22:13:38.821777: Current learning rate: 0.01
2024-07-05 22:17:38.571556: Validation loss improved from 1000.00000 to -0.68500! Patience: 0/50
2024-07-05 22:17:38.598684: train_loss -0.5284
2024-07-05 22:17:38.622335: val_loss -0.685
2024-07-05 22:17:38.623996: Pseudo dice [0.9572, 0.853]
2024-07-05 22:17:38.625245: Epoch time: 239.76 s
2024-07-05 22:17:38.626317: Yayy! New best EMA pseudo Dice: 0.9051
2024-07-05 22:17:42.058722: 
2024-07-05 22:17:42.060880: Epoch 1
2024-07-05 22:17:42.062711: Current learning rate: 0.00999
2024-07-05 22:18:46.699803: Validation loss did not improve from -0.68500. Patience: 1/50
2024-07-05 22:18:46.701408: train_loss -0.5973
2024-07-05 22:18:46.702611: val_loss -0.6509
2024-07-05 22:18:46.704061: Pseudo dice [0.9548, 0.8329]
2024-07-05 22:18:46.705449: Epoch time: 64.64 s
2024-07-05 22:18:47.908753: 
2024-07-05 22:18:47.910517: Epoch 2
2024-07-05 22:18:47.911973: Current learning rate: 0.00998
2024-07-05 22:19:52.747531: Validation loss improved from -0.68500 to -0.72523! Patience: 1/50
2024-07-05 22:19:52.749144: train_loss -0.6591
2024-07-05 22:19:52.751076: val_loss -0.7252
2024-07-05 22:19:52.752880: Pseudo dice [0.9616, 0.8681]
2024-07-05 22:19:52.754936: Epoch time: 64.84 s
2024-07-05 22:19:54.031339: 
2024-07-05 22:19:54.034438: Epoch 3
2024-07-05 22:19:54.036833: Current learning rate: 0.00997
2024-07-05 22:20:58.915756: Validation loss did not improve from -0.72523. Patience: 1/50
2024-07-05 22:20:58.917373: train_loss -0.6776
2024-07-05 22:20:58.919284: val_loss -0.698
2024-07-05 22:20:58.920890: Pseudo dice [0.9563, 0.8526]
2024-07-05 22:20:58.922462: Epoch time: 64.89 s
2024-07-05 22:21:00.198353: 
2024-07-05 22:21:00.201212: Epoch 4
2024-07-05 22:21:00.202992: Current learning rate: 0.00996
2024-07-05 22:22:05.146300: Validation loss did not improve from -0.72523. Patience: 2/50
2024-07-05 22:22:05.147919: train_loss -0.6715
2024-07-05 22:22:05.150021: val_loss -0.6982
2024-07-05 22:22:05.152307: Pseudo dice [0.95, 0.8576]
2024-07-05 22:22:05.153744: Epoch time: 64.95 s
2024-07-05 22:22:06.899848: 
2024-07-05 22:22:06.902749: Epoch 5
2024-07-05 22:22:06.904594: Current learning rate: 0.00995
2024-07-05 22:23:11.757109: Validation loss improved from -0.72523 to -0.74162! Patience: 2/50
2024-07-05 22:23:11.758740: train_loss -0.7159
2024-07-05 22:23:11.761143: val_loss -0.7416
2024-07-05 22:23:11.763363: Pseudo dice [0.9615, 0.8558]
2024-07-05 22:23:11.766317: Epoch time: 64.86 s
2024-07-05 22:23:11.768020: Yayy! New best EMA pseudo Dice: 0.9053
2024-07-05 22:23:13.318882: 
2024-07-05 22:23:13.322513: Epoch 6
2024-07-05 22:23:13.324547: Current learning rate: 0.00995
2024-07-05 22:24:18.171336: Validation loss did not improve from -0.74162. Patience: 1/50
2024-07-05 22:24:18.173269: train_loss -0.7319
2024-07-05 22:24:18.174871: val_loss -0.7412
2024-07-05 22:24:18.176261: Pseudo dice [0.9604, 0.8709]
2024-07-05 22:24:18.177660: Epoch time: 64.86 s
2024-07-05 22:24:18.178987: Yayy! New best EMA pseudo Dice: 0.9063
2024-07-05 22:24:20.156721: 
2024-07-05 22:24:20.158633: Epoch 7
2024-07-05 22:24:20.160060: Current learning rate: 0.00994
2024-07-05 22:25:24.978087: Validation loss improved from -0.74162 to -0.75439! Patience: 1/50
2024-07-05 22:25:24.980338: train_loss -0.7335
2024-07-05 22:25:24.982391: val_loss -0.7544
2024-07-05 22:25:24.983396: Pseudo dice [0.9669, 0.8714]
2024-07-05 22:25:24.985026: Epoch time: 64.82 s
2024-07-05 22:25:24.986730: Yayy! New best EMA pseudo Dice: 0.9076
2024-07-05 22:25:26.541119: 
2024-07-05 22:25:26.543260: Epoch 8
2024-07-05 22:25:26.544751: Current learning rate: 0.00993
2024-07-05 22:26:31.552497: Validation loss did not improve from -0.75439. Patience: 1/50
2024-07-05 22:26:31.555444: train_loss -0.7281
2024-07-05 22:26:31.557523: val_loss -0.7539
2024-07-05 22:26:31.558851: Pseudo dice [0.9653, 0.8773]
2024-07-05 22:26:31.560576: Epoch time: 65.02 s
2024-07-05 22:26:31.562125: Yayy! New best EMA pseudo Dice: 0.909
2024-07-05 22:26:33.139622: 
2024-07-05 22:26:33.142212: Epoch 9
2024-07-05 22:26:33.144003: Current learning rate: 0.00992
2024-07-05 22:27:38.151714: Validation loss did not improve from -0.75439. Patience: 2/50
2024-07-05 22:27:38.153283: train_loss -0.7336
2024-07-05 22:27:38.154794: val_loss -0.7293
2024-07-05 22:27:38.156317: Pseudo dice [0.962, 0.863]
2024-07-05 22:27:38.157837: Epoch time: 65.01 s
2024-07-05 22:27:38.488181: Yayy! New best EMA pseudo Dice: 0.9093
2024-07-05 22:27:39.950358: 
2024-07-05 22:27:39.952328: Epoch 10
2024-07-05 22:27:39.953844: Current learning rate: 0.00991
2024-07-05 22:28:44.941523: Validation loss improved from -0.75439 to -0.77420! Patience: 2/50
2024-07-05 22:28:44.943085: train_loss -0.733
2024-07-05 22:28:44.944793: val_loss -0.7742
2024-07-05 22:28:44.946563: Pseudo dice [0.9705, 0.8785]
2024-07-05 22:28:44.947805: Epoch time: 64.99 s
2024-07-05 22:28:44.949446: Yayy! New best EMA pseudo Dice: 0.9108
2024-07-05 22:28:46.456158: 
2024-07-05 22:28:46.458771: Epoch 11
2024-07-05 22:28:46.459866: Current learning rate: 0.0099
2024-07-05 22:29:51.479338: Validation loss improved from -0.77420 to -0.77424! Patience: 0/50
2024-07-05 22:29:51.480878: train_loss -0.7504
2024-07-05 22:29:51.482203: val_loss -0.7742
2024-07-05 22:29:51.483135: Pseudo dice [0.9719, 0.8713]
2024-07-05 22:29:51.484027: Epoch time: 65.03 s
2024-07-05 22:29:51.484857: Yayy! New best EMA pseudo Dice: 0.9119
2024-07-05 22:29:52.997300: 
2024-07-05 22:29:52.999665: Epoch 12
2024-07-05 22:29:53.000962: Current learning rate: 0.00989
2024-07-05 22:30:57.980490: Validation loss improved from -0.77424 to -0.77941! Patience: 0/50
2024-07-05 22:30:57.982397: train_loss -0.754
2024-07-05 22:30:57.984476: val_loss -0.7794
2024-07-05 22:30:57.986771: Pseudo dice [0.9684, 0.8835]
2024-07-05 22:30:57.988374: Epoch time: 64.99 s
2024-07-05 22:30:57.989420: Yayy! New best EMA pseudo Dice: 0.9133
2024-07-05 22:30:59.507560: 
2024-07-05 22:30:59.509380: Epoch 13
2024-07-05 22:30:59.510779: Current learning rate: 0.00988
2024-07-05 22:32:04.594540: Validation loss did not improve from -0.77941. Patience: 1/50
2024-07-05 22:32:04.596142: train_loss -0.7276
2024-07-05 22:32:04.597293: val_loss -0.7368
2024-07-05 22:32:04.598265: Pseudo dice [0.9658, 0.8689]
2024-07-05 22:32:04.599196: Epoch time: 65.09 s
2024-07-05 22:32:04.600170: Yayy! New best EMA pseudo Dice: 0.9137
2024-07-05 22:32:06.154140: 
2024-07-05 22:32:06.156727: Epoch 14
2024-07-05 22:32:06.158281: Current learning rate: 0.00987
2024-07-05 22:33:11.298486: Validation loss did not improve from -0.77941. Patience: 2/50
2024-07-05 22:33:11.300004: train_loss -0.6714
2024-07-05 22:33:11.301822: val_loss -0.7072
2024-07-05 22:33:11.303365: Pseudo dice [0.9561, 0.8597]
2024-07-05 22:33:11.305039: Epoch time: 65.15 s
2024-07-05 22:33:12.883412: 
2024-07-05 22:33:12.885646: Epoch 15
2024-07-05 22:33:12.887887: Current learning rate: 0.00986
2024-07-05 22:34:17.965884: Validation loss did not improve from -0.77941. Patience: 3/50
2024-07-05 22:34:17.967894: train_loss -0.7114
2024-07-05 22:34:17.969749: val_loss -0.7219
2024-07-05 22:34:17.971779: Pseudo dice [0.9606, 0.8642]
2024-07-05 22:34:17.973922: Epoch time: 65.09 s
2024-07-05 22:34:19.218826: 
2024-07-05 22:34:19.221033: Epoch 16
2024-07-05 22:34:19.222039: Current learning rate: 0.00986
2024-07-05 22:35:24.489560: Validation loss did not improve from -0.77941. Patience: 4/50
2024-07-05 22:35:24.491138: train_loss -0.7303
2024-07-05 22:35:24.492305: val_loss -0.7622
2024-07-05 22:35:24.493905: Pseudo dice [0.9673, 0.8775]
2024-07-05 22:35:24.495859: Epoch time: 65.27 s
2024-07-05 22:35:24.496907: Yayy! New best EMA pseudo Dice: 0.914
2024-07-05 22:35:26.093777: 
2024-07-05 22:35:26.096428: Epoch 17
2024-07-05 22:35:26.097861: Current learning rate: 0.00985
2024-07-05 22:36:31.329056: Validation loss did not improve from -0.77941. Patience: 5/50
2024-07-05 22:36:31.330923: train_loss -0.7521
2024-07-05 22:36:31.333453: val_loss -0.7382
2024-07-05 22:36:31.335937: Pseudo dice [0.9659, 0.853]
2024-07-05 22:36:31.337619: Epoch time: 65.24 s
2024-07-05 22:36:32.578960: 
2024-07-05 22:36:32.581140: Epoch 18
2024-07-05 22:36:32.583272: Current learning rate: 0.00984
2024-07-05 22:37:37.857280: Validation loss did not improve from -0.77941. Patience: 6/50
2024-07-05 22:37:37.858938: train_loss -0.7501
2024-07-05 22:37:37.860608: val_loss -0.7683
2024-07-05 22:37:37.862103: Pseudo dice [0.9685, 0.8765]
2024-07-05 22:37:37.863172: Epoch time: 65.28 s
2024-07-05 22:37:37.864858: Yayy! New best EMA pseudo Dice: 0.9144
2024-07-05 22:37:39.823162: 
2024-07-05 22:37:39.825286: Epoch 19
2024-07-05 22:37:39.826830: Current learning rate: 0.00983
2024-07-05 22:38:45.050281: Validation loss did not improve from -0.77941. Patience: 7/50
2024-07-05 22:38:45.052154: train_loss -0.7462
2024-07-05 22:38:45.054316: val_loss -0.7762
2024-07-05 22:38:45.056269: Pseudo dice [0.9686, 0.8841]
2024-07-05 22:38:45.057480: Epoch time: 65.23 s
2024-07-05 22:38:45.386119: Yayy! New best EMA pseudo Dice: 0.9156
2024-07-05 22:38:46.937667: 
2024-07-05 22:38:46.939829: Epoch 20
2024-07-05 22:38:46.941498: Current learning rate: 0.00982
2024-07-05 22:39:52.125407: Validation loss did not improve from -0.77941. Patience: 8/50
2024-07-05 22:39:52.128090: train_loss -0.758
2024-07-05 22:39:52.130685: val_loss -0.7409
2024-07-05 22:39:52.132182: Pseudo dice [0.9638, 0.8622]
2024-07-05 22:39:52.133516: Epoch time: 65.19 s
2024-07-05 22:39:53.410821: 
2024-07-05 22:39:53.413804: Epoch 21
2024-07-05 22:39:53.415508: Current learning rate: 0.00981
2024-07-05 22:40:58.630881: Validation loss did not improve from -0.77941. Patience: 9/50
2024-07-05 22:40:58.632963: train_loss -0.7576
2024-07-05 22:40:58.635618: val_loss -0.7719
2024-07-05 22:40:58.637588: Pseudo dice [0.9684, 0.8842]
2024-07-05 22:40:58.639228: Epoch time: 65.22 s
2024-07-05 22:40:58.640316: Yayy! New best EMA pseudo Dice: 0.9165
2024-07-05 22:41:00.301677: 
2024-07-05 22:41:00.303976: Epoch 22
2024-07-05 22:41:00.305338: Current learning rate: 0.0098
2024-07-05 22:42:05.479580: Validation loss did not improve from -0.77941. Patience: 10/50
2024-07-05 22:42:05.481129: train_loss -0.7443
2024-07-05 22:42:05.483091: val_loss -0.762
2024-07-05 22:42:05.485020: Pseudo dice [0.9726, 0.8758]
2024-07-05 22:42:05.486928: Epoch time: 65.18 s
2024-07-05 22:42:05.488025: Yayy! New best EMA pseudo Dice: 0.9172
2024-07-05 22:42:06.976928: 
2024-07-05 22:42:06.979430: Epoch 23
2024-07-05 22:42:06.980752: Current learning rate: 0.00979
2024-07-05 22:43:12.206319: Validation loss did not improve from -0.77941. Patience: 11/50
2024-07-05 22:43:12.208194: train_loss -0.7551
2024-07-05 22:43:12.210003: val_loss -0.7666
2024-07-05 22:43:12.213326: Pseudo dice [0.9726, 0.8752]
2024-07-05 22:43:12.214936: Epoch time: 65.23 s
2024-07-05 22:43:12.215924: Yayy! New best EMA pseudo Dice: 0.9179
2024-07-05 22:43:13.694217: 
2024-07-05 22:43:13.696396: Epoch 24
2024-07-05 22:43:13.697723: Current learning rate: 0.00978
2024-07-05 22:44:19.056520: Validation loss did not improve from -0.77941. Patience: 12/50
2024-07-05 22:44:19.058787: train_loss -0.7567
2024-07-05 22:44:19.060792: val_loss -0.7682
2024-07-05 22:44:19.062385: Pseudo dice [0.9669, 0.8733]
2024-07-05 22:44:19.063963: Epoch time: 65.37 s
2024-07-05 22:44:19.390241: Yayy! New best EMA pseudo Dice: 0.9181
2024-07-05 22:44:20.864718: 
2024-07-05 22:44:20.866904: Epoch 25
2024-07-05 22:44:20.868661: Current learning rate: 0.00977
2024-07-05 22:45:26.217303: Validation loss improved from -0.77941 to -0.78604! Patience: 12/50
2024-07-05 22:45:26.219239: train_loss -0.7599
2024-07-05 22:45:26.221284: val_loss -0.786
2024-07-05 22:45:26.222646: Pseudo dice [0.9703, 0.8795]
2024-07-05 22:45:26.224191: Epoch time: 65.36 s
2024-07-05 22:45:26.225361: Yayy! New best EMA pseudo Dice: 0.9188
2024-07-05 22:45:27.711342: 
2024-07-05 22:45:27.714051: Epoch 26
2024-07-05 22:45:27.715710: Current learning rate: 0.00977
2024-07-05 22:46:33.106315: Validation loss did not improve from -0.78604. Patience: 1/50
2024-07-05 22:46:33.108352: train_loss -0.7542
2024-07-05 22:46:33.110623: val_loss -0.7729
2024-07-05 22:46:33.111984: Pseudo dice [0.9705, 0.8782]
2024-07-05 22:46:33.113842: Epoch time: 65.4 s
2024-07-05 22:46:33.115554: Yayy! New best EMA pseudo Dice: 0.9194
2024-07-05 22:46:34.632595: 
2024-07-05 22:46:34.634615: Epoch 27
2024-07-05 22:46:34.636404: Current learning rate: 0.00976
2024-07-05 22:47:40.151291: Validation loss did not improve from -0.78604. Patience: 2/50
2024-07-05 22:47:40.153045: train_loss -0.7585
2024-07-05 22:47:40.154856: val_loss -0.7633
2024-07-05 22:47:40.156350: Pseudo dice [0.9679, 0.8819]
2024-07-05 22:47:40.157835: Epoch time: 65.52 s
2024-07-05 22:47:40.159220: Yayy! New best EMA pseudo Dice: 0.9199
2024-07-05 22:47:41.666878: 
2024-07-05 22:47:41.669427: Epoch 28
2024-07-05 22:47:41.670779: Current learning rate: 0.00975
2024-07-05 22:48:47.148374: Validation loss did not improve from -0.78604. Patience: 3/50
2024-07-05 22:48:47.150033: train_loss -0.7262
2024-07-05 22:48:47.151703: val_loss -0.762
2024-07-05 22:48:47.153013: Pseudo dice [0.9659, 0.8705]
2024-07-05 22:48:47.154335: Epoch time: 65.48 s
2024-07-05 22:48:48.351023: 
2024-07-05 22:48:48.353889: Epoch 29
2024-07-05 22:48:48.356003: Current learning rate: 0.00974
2024-07-05 22:49:53.820978: Validation loss did not improve from -0.78604. Patience: 4/50
2024-07-05 22:49:53.822764: train_loss -0.7581
2024-07-05 22:49:53.824624: val_loss -0.7688
2024-07-05 22:49:53.826360: Pseudo dice [0.9696, 0.8799]
2024-07-05 22:49:53.827904: Epoch time: 65.47 s
2024-07-05 22:49:54.161426: Yayy! New best EMA pseudo Dice: 0.9202
2024-07-05 22:49:55.644539: 
2024-07-05 22:49:55.647053: Epoch 30
2024-07-05 22:49:55.648756: Current learning rate: 0.00973
2024-07-05 22:51:01.130444: Validation loss did not improve from -0.78604. Patience: 5/50
2024-07-05 22:51:01.132110: train_loss -0.7424
2024-07-05 22:51:01.133430: val_loss -0.7814
2024-07-05 22:51:01.135006: Pseudo dice [0.9695, 0.8942]
2024-07-05 22:51:01.135949: Epoch time: 65.49 s
2024-07-05 22:51:01.136882: Yayy! New best EMA pseudo Dice: 0.9214
2024-07-05 22:51:03.135029: 
2024-07-05 22:51:03.137440: Epoch 31
2024-07-05 22:51:03.138613: Current learning rate: 0.00972
2024-07-05 22:52:08.565781: Validation loss did not improve from -0.78604. Patience: 6/50
2024-07-05 22:52:08.567459: train_loss -0.7482
2024-07-05 22:52:08.569358: val_loss -0.7734
2024-07-05 22:52:08.570757: Pseudo dice [0.9645, 0.8872]
2024-07-05 22:52:08.572073: Epoch time: 65.43 s
2024-07-05 22:52:08.573838: Yayy! New best EMA pseudo Dice: 0.9219
2024-07-05 22:52:10.146380: 
2024-07-05 22:52:10.148865: Epoch 32
2024-07-05 22:52:10.150116: Current learning rate: 0.00971
2024-07-05 22:53:15.566744: Validation loss did not improve from -0.78604. Patience: 7/50
2024-07-05 22:53:15.568884: train_loss -0.7582
2024-07-05 22:53:15.570990: val_loss -0.7778
2024-07-05 22:53:15.572303: Pseudo dice [0.9691, 0.8838]
2024-07-05 22:53:15.573519: Epoch time: 65.42 s
2024-07-05 22:53:15.574502: Yayy! New best EMA pseudo Dice: 0.9223
2024-07-05 22:53:17.130305: 
2024-07-05 22:53:17.132950: Epoch 33
2024-07-05 22:53:17.134001: Current learning rate: 0.0097
2024-07-05 22:54:22.526316: Validation loss did not improve from -0.78604. Patience: 8/50
2024-07-05 22:54:22.528234: train_loss -0.7586
2024-07-05 22:54:22.530412: val_loss -0.7795
2024-07-05 22:54:22.532467: Pseudo dice [0.9677, 0.8816]
2024-07-05 22:54:22.534316: Epoch time: 65.4 s
2024-07-05 22:54:22.535815: Yayy! New best EMA pseudo Dice: 0.9226
2024-07-05 22:54:24.130493: 
2024-07-05 22:54:24.133516: Epoch 34
2024-07-05 22:54:24.135545: Current learning rate: 0.00969
2024-07-05 22:55:29.541473: Validation loss did not improve from -0.78604. Patience: 9/50
2024-07-05 22:55:29.543947: train_loss -0.7589
2024-07-05 22:55:29.545701: val_loss -0.7576
2024-07-05 22:55:29.547107: Pseudo dice [0.9663, 0.8802]
2024-07-05 22:55:29.548659: Epoch time: 65.41 s
2024-07-05 22:55:29.890020: Yayy! New best EMA pseudo Dice: 0.9226
2024-07-05 22:55:31.460486: 
2024-07-05 22:55:31.462372: Epoch 35
2024-07-05 22:55:31.463732: Current learning rate: 0.00968
2024-07-05 22:56:37.273913: Validation loss did not improve from -0.78604. Patience: 10/50
2024-07-05 22:56:37.296098: train_loss -0.7367
2024-07-05 22:56:37.298174: val_loss -0.7595
2024-07-05 22:56:37.299954: Pseudo dice [0.9639, 0.8809]
2024-07-05 22:56:37.302222: Epoch time: 65.84 s
2024-07-05 22:56:38.651240: 
2024-07-05 22:56:38.653728: Epoch 36
2024-07-05 22:56:38.654997: Current learning rate: 0.00968
2024-07-05 22:57:43.781086: Validation loss did not improve from -0.78604. Patience: 11/50
2024-07-05 22:57:43.783090: train_loss -0.7475
2024-07-05 22:57:43.785250: val_loss -0.7561
2024-07-05 22:57:43.786928: Pseudo dice [0.9682, 0.8801]
2024-07-05 22:57:43.788595: Epoch time: 65.13 s
2024-07-05 22:57:43.789670: Yayy! New best EMA pseudo Dice: 0.9228
2024-07-05 22:57:45.500773: 
2024-07-05 22:57:45.502802: Epoch 37
2024-07-05 22:57:45.503738: Current learning rate: 0.00967
2024-07-05 22:58:50.603530: Validation loss did not improve from -0.78604. Patience: 12/50
2024-07-05 22:58:50.605132: train_loss -0.749
2024-07-05 22:58:50.606735: val_loss -0.7805
2024-07-05 22:58:50.608278: Pseudo dice [0.9669, 0.8834]
2024-07-05 22:58:50.609410: Epoch time: 65.11 s
2024-07-05 22:58:50.610428: Yayy! New best EMA pseudo Dice: 0.923
2024-07-05 22:58:52.168880: 
2024-07-05 22:58:52.171042: Epoch 38
2024-07-05 22:58:52.172408: Current learning rate: 0.00966
2024-07-05 22:59:57.367493: Validation loss did not improve from -0.78604. Patience: 13/50
2024-07-05 22:59:57.370000: train_loss -0.7601
2024-07-05 22:59:57.371398: val_loss -0.7641
2024-07-05 22:59:57.372584: Pseudo dice [0.9644, 0.8741]
2024-07-05 22:59:57.373791: Epoch time: 65.2 s
2024-07-05 22:59:58.612118: 
2024-07-05 22:59:58.614718: Epoch 39
2024-07-05 22:59:58.616620: Current learning rate: 0.00965
2024-07-05 23:01:03.922888: Validation loss did not improve from -0.78604. Patience: 14/50
2024-07-05 23:01:03.924688: train_loss -0.7591
2024-07-05 23:01:03.926877: val_loss -0.7687
2024-07-05 23:01:03.928550: Pseudo dice [0.9674, 0.8803]
2024-07-05 23:01:03.930100: Epoch time: 65.31 s
2024-07-05 23:01:05.578966: 
2024-07-05 23:01:05.581939: Epoch 40
2024-07-05 23:01:05.584240: Current learning rate: 0.00964
2024-07-05 23:02:10.769817: Validation loss improved from -0.78604 to -0.79370! Patience: 14/50
2024-07-05 23:02:10.771941: train_loss -0.7685
2024-07-05 23:02:10.773834: val_loss -0.7937
2024-07-05 23:02:10.774785: Pseudo dice [0.9704, 0.8958]
2024-07-05 23:02:10.776510: Epoch time: 65.19 s
2024-07-05 23:02:10.778630: Yayy! New best EMA pseudo Dice: 0.9238
2024-07-05 23:02:12.385802: 
2024-07-05 23:02:12.387969: Epoch 41
2024-07-05 23:02:12.389554: Current learning rate: 0.00963
2024-07-05 23:03:17.571742: Validation loss did not improve from -0.79370. Patience: 1/50
2024-07-05 23:03:17.573754: train_loss -0.7713
2024-07-05 23:03:17.576837: val_loss -0.7769
2024-07-05 23:03:17.579417: Pseudo dice [0.9708, 0.89]
2024-07-05 23:03:17.581177: Epoch time: 65.19 s
2024-07-05 23:03:17.582576: Yayy! New best EMA pseudo Dice: 0.9244
2024-07-05 23:03:19.168563: 
2024-07-05 23:03:19.171141: Epoch 42
2024-07-05 23:03:19.172185: Current learning rate: 0.00962
2024-07-05 23:04:24.271099: Validation loss did not improve from -0.79370. Patience: 2/50
2024-07-05 23:04:24.272817: train_loss -0.7641
2024-07-05 23:04:24.273954: val_loss -0.7697
2024-07-05 23:04:24.275025: Pseudo dice [0.9664, 0.8805]
2024-07-05 23:04:24.276331: Epoch time: 65.11 s
2024-07-05 23:04:26.218398: 
2024-07-05 23:04:26.220418: Epoch 43
2024-07-05 23:04:26.221951: Current learning rate: 0.00961
2024-07-05 23:05:31.428193: Validation loss improved from -0.79370 to -0.79671! Patience: 2/50
2024-07-05 23:05:31.429881: train_loss -0.7627
2024-07-05 23:05:31.431161: val_loss -0.7967
2024-07-05 23:05:31.432377: Pseudo dice [0.9735, 0.8946]
2024-07-05 23:05:31.433621: Epoch time: 65.21 s
2024-07-05 23:05:31.434998: Yayy! New best EMA pseudo Dice: 0.9253
2024-07-05 23:05:32.981079: 
2024-07-05 23:05:32.983872: Epoch 44
2024-07-05 23:05:32.985188: Current learning rate: 0.0096
2024-07-05 23:06:38.268723: Validation loss did not improve from -0.79671. Patience: 1/50
2024-07-05 23:06:38.270650: train_loss -0.776
2024-07-05 23:06:38.272136: val_loss -0.7787
2024-07-05 23:06:38.273369: Pseudo dice [0.9701, 0.8797]
2024-07-05 23:06:38.274608: Epoch time: 65.29 s
2024-07-05 23:06:39.862974: 
2024-07-05 23:06:39.865992: Epoch 45
2024-07-05 23:06:39.867449: Current learning rate: 0.00959
2024-07-05 23:07:45.132470: Validation loss did not improve from -0.79671. Patience: 2/50
2024-07-05 23:07:45.134492: train_loss -0.7727
2024-07-05 23:07:45.136666: val_loss -0.7735
2024-07-05 23:07:45.138092: Pseudo dice [0.9684, 0.8778]
2024-07-05 23:07:45.139441: Epoch time: 65.27 s
2024-07-05 23:07:46.351483: 
2024-07-05 23:07:46.353980: Epoch 46
2024-07-05 23:07:46.355578: Current learning rate: 0.00959
2024-07-05 23:08:51.639401: Validation loss did not improve from -0.79671. Patience: 3/50
2024-07-05 23:08:51.641042: train_loss -0.7784
2024-07-05 23:08:51.642381: val_loss -0.7903
2024-07-05 23:08:51.643564: Pseudo dice [0.9728, 0.892]
2024-07-05 23:08:51.644925: Epoch time: 65.29 s
2024-07-05 23:08:51.646122: Yayy! New best EMA pseudo Dice: 0.9258
2024-07-05 23:08:53.179804: 
2024-07-05 23:08:53.182251: Epoch 47
2024-07-05 23:08:53.184074: Current learning rate: 0.00958
2024-07-05 23:09:58.455158: Validation loss did not improve from -0.79671. Patience: 4/50
2024-07-05 23:09:58.456815: train_loss -0.7814
2024-07-05 23:09:58.459180: val_loss -0.7888
2024-07-05 23:09:58.460726: Pseudo dice [0.972, 0.8861]
2024-07-05 23:09:58.462014: Epoch time: 65.28 s
2024-07-05 23:09:58.463267: Yayy! New best EMA pseudo Dice: 0.9261
2024-07-05 23:09:59.904456: 
2024-07-05 23:09:59.906593: Epoch 48
2024-07-05 23:09:59.907941: Current learning rate: 0.00957
2024-07-05 23:11:05.207556: Validation loss did not improve from -0.79671. Patience: 5/50
2024-07-05 23:11:05.208991: train_loss -0.7747
2024-07-05 23:11:05.210264: val_loss -0.7744
2024-07-05 23:11:05.211859: Pseudo dice [0.9691, 0.8883]
2024-07-05 23:11:05.213350: Epoch time: 65.31 s
2024-07-05 23:11:05.214483: Yayy! New best EMA pseudo Dice: 0.9264
2024-07-05 23:11:06.705727: 
2024-07-05 23:11:06.708361: Epoch 49
2024-07-05 23:11:06.709930: Current learning rate: 0.00956
2024-07-05 23:12:11.965490: Validation loss did not improve from -0.79671. Patience: 6/50
2024-07-05 23:12:11.967356: train_loss -0.7663
2024-07-05 23:12:11.969573: val_loss -0.7763
2024-07-05 23:12:11.971675: Pseudo dice [0.9701, 0.8822]
2024-07-05 23:12:11.973686: Epoch time: 65.26 s
2024-07-05 23:12:13.523607: 
2024-07-05 23:12:13.526012: Epoch 50
2024-07-05 23:12:13.528137: Current learning rate: 0.00955
2024-07-05 23:13:18.853181: Validation loss did not improve from -0.79671. Patience: 7/50
2024-07-05 23:13:18.855806: train_loss -0.7675
2024-07-05 23:13:18.858426: val_loss -0.7862
2024-07-05 23:13:18.860233: Pseudo dice [0.9733, 0.8818]
2024-07-05 23:13:18.861609: Epoch time: 65.33 s
2024-07-05 23:13:18.863523: Yayy! New best EMA pseudo Dice: 0.9265
2024-07-05 23:13:20.412882: 
2024-07-05 23:13:20.416121: Epoch 51
2024-07-05 23:13:20.417652: Current learning rate: 0.00954
2024-07-05 23:14:25.744018: Validation loss did not improve from -0.79671. Patience: 8/50
2024-07-05 23:14:25.746875: train_loss -0.7704
2024-07-05 23:14:25.749452: val_loss -0.796
2024-07-05 23:14:25.750869: Pseudo dice [0.9731, 0.8859]
2024-07-05 23:14:25.752058: Epoch time: 65.33 s
2024-07-05 23:14:25.753012: Yayy! New best EMA pseudo Dice: 0.9268
2024-07-05 23:14:27.293933: 
2024-07-05 23:14:27.297055: Epoch 52
2024-07-05 23:14:27.299232: Current learning rate: 0.00953
2024-07-05 23:15:32.723282: Validation loss did not improve from -0.79671. Patience: 9/50
2024-07-05 23:15:32.726427: train_loss -0.7728
2024-07-05 23:15:32.729142: val_loss -0.7782
2024-07-05 23:15:32.731126: Pseudo dice [0.9693, 0.8848]
2024-07-05 23:15:32.732279: Epoch time: 65.43 s
2024-07-05 23:15:32.733317: Yayy! New best EMA pseudo Dice: 0.9268
2024-07-05 23:15:34.289745: 
2024-07-05 23:15:34.291991: Epoch 53
2024-07-05 23:15:34.293206: Current learning rate: 0.00952
2024-07-05 23:16:39.727142: Validation loss did not improve from -0.79671. Patience: 10/50
2024-07-05 23:16:39.728678: train_loss -0.7817
2024-07-05 23:16:39.730680: val_loss -0.7915
2024-07-05 23:16:39.732010: Pseudo dice [0.9716, 0.8892]
2024-07-05 23:16:39.733032: Epoch time: 65.44 s
2024-07-05 23:16:39.734123: Yayy! New best EMA pseudo Dice: 0.9272
2024-07-05 23:16:41.639137: 
2024-07-05 23:16:41.641022: Epoch 54
2024-07-05 23:16:41.642437: Current learning rate: 0.00951
2024-07-05 23:17:47.840333: Validation loss did not improve from -0.79671. Patience: 11/50
2024-07-05 23:17:47.841704: train_loss -0.7638
2024-07-05 23:17:47.842766: val_loss -0.7937
2024-07-05 23:17:47.843849: Pseudo dice [0.9697, 0.8863]
2024-07-05 23:17:47.844876: Epoch time: 66.2 s
2024-07-05 23:17:48.293713: Yayy! New best EMA pseudo Dice: 0.9273
2024-07-05 23:17:50.009654: 
2024-07-05 23:17:50.012083: Epoch 55
2024-07-05 23:17:50.013515: Current learning rate: 0.0095
2024-07-05 23:18:55.930750: Validation loss did not improve from -0.79671. Patience: 12/50
2024-07-05 23:18:55.932820: train_loss -0.7558
2024-07-05 23:18:55.934679: val_loss -0.7564
2024-07-05 23:18:55.936054: Pseudo dice [0.9632, 0.8757]
2024-07-05 23:18:55.937193: Epoch time: 65.92 s
2024-07-05 23:18:57.323757: 
2024-07-05 23:18:57.327006: Epoch 56
2024-07-05 23:18:57.328870: Current learning rate: 0.00949
2024-07-05 23:20:02.968199: Validation loss did not improve from -0.79671. Patience: 13/50
2024-07-05 23:20:02.969995: train_loss -0.7603
2024-07-05 23:20:02.971490: val_loss -0.7929
2024-07-05 23:20:02.972845: Pseudo dice [0.9733, 0.8906]
2024-07-05 23:20:02.974197: Epoch time: 65.65 s
2024-07-05 23:20:04.185663: 
2024-07-05 23:20:04.188011: Epoch 57
2024-07-05 23:20:04.189472: Current learning rate: 0.00949
2024-07-05 23:21:09.941442: Validation loss did not improve from -0.79671. Patience: 14/50
2024-07-05 23:21:09.964581: train_loss -0.7641
2024-07-05 23:21:10.006827: val_loss -0.7909
2024-07-05 23:21:10.008780: Pseudo dice [0.9725, 0.8846]
2024-07-05 23:21:10.010590: Epoch time: 65.76 s
2024-07-05 23:21:11.931919: 
2024-07-05 23:21:11.934897: Epoch 58
2024-07-05 23:21:11.936856: Current learning rate: 0.00948
2024-07-05 23:22:17.678232: Validation loss did not improve from -0.79671. Patience: 15/50
2024-07-05 23:22:17.679993: train_loss -0.7677
2024-07-05 23:22:17.681490: val_loss -0.7842
2024-07-05 23:22:17.682889: Pseudo dice [0.9702, 0.8861]
2024-07-05 23:22:17.684220: Epoch time: 65.75 s
2024-07-05 23:22:17.685412: Yayy! New best EMA pseudo Dice: 0.9273
2024-07-05 23:22:19.440830: 
2024-07-05 23:22:19.443721: Epoch 59
2024-07-05 23:22:19.445701: Current learning rate: 0.00947
2024-07-05 23:23:26.646886: Validation loss did not improve from -0.79671. Patience: 16/50
2024-07-05 23:23:26.663317: train_loss -0.7718
2024-07-05 23:23:26.665549: val_loss -0.7753
2024-07-05 23:23:26.666935: Pseudo dice [0.9688, 0.887]
2024-07-05 23:23:26.668903: Epoch time: 67.21 s
2024-07-05 23:23:27.077145: Yayy! New best EMA pseudo Dice: 0.9273
2024-07-05 23:23:29.078940: 
2024-07-05 23:23:29.081519: Epoch 60
2024-07-05 23:23:29.083397: Current learning rate: 0.00946
2024-07-05 23:24:34.012435: Validation loss did not improve from -0.79671. Patience: 17/50
2024-07-05 23:24:34.014366: train_loss -0.762
2024-07-05 23:24:34.016113: val_loss -0.7854
2024-07-05 23:24:34.017516: Pseudo dice [0.9697, 0.8899]
2024-07-05 23:24:34.018713: Epoch time: 64.94 s
2024-07-05 23:24:34.019838: Yayy! New best EMA pseudo Dice: 0.9276
2024-07-05 23:24:35.543839: 
2024-07-05 23:24:35.546560: Epoch 61
2024-07-05 23:24:35.548061: Current learning rate: 0.00945
2024-07-05 23:25:40.556883: Validation loss did not improve from -0.79671. Patience: 18/50
2024-07-05 23:25:40.558534: train_loss -0.7727
2024-07-05 23:25:40.560225: val_loss -0.7897
2024-07-05 23:25:40.561480: Pseudo dice [0.9706, 0.8896]
2024-07-05 23:25:40.562564: Epoch time: 65.02 s
2024-07-05 23:25:40.563745: Yayy! New best EMA pseudo Dice: 0.9278
2024-07-05 23:25:42.115378: 
2024-07-05 23:25:42.118222: Epoch 62
2024-07-05 23:25:42.120220: Current learning rate: 0.00944
2024-07-05 23:26:47.298794: Validation loss did not improve from -0.79671. Patience: 19/50
2024-07-05 23:26:47.300410: train_loss -0.6898
2024-07-05 23:26:47.301766: val_loss -0.7411
2024-07-05 23:26:47.302748: Pseudo dice [0.9644, 0.8641]
2024-07-05 23:26:47.303863: Epoch time: 65.19 s
2024-07-05 23:26:48.520643: 
2024-07-05 23:26:48.522941: Epoch 63
2024-07-05 23:26:48.524754: Current learning rate: 0.00943
2024-07-05 23:27:53.697789: Validation loss did not improve from -0.79671. Patience: 20/50
2024-07-05 23:27:53.699755: train_loss -0.7366
2024-07-05 23:27:53.701395: val_loss -0.7859
2024-07-05 23:27:53.702678: Pseudo dice [0.9728, 0.8851]
2024-07-05 23:27:53.703964: Epoch time: 65.18 s
2024-07-05 23:27:54.923094: 
2024-07-05 23:27:54.926078: Epoch 64
2024-07-05 23:27:54.927676: Current learning rate: 0.00942
2024-07-05 23:29:00.116486: Validation loss did not improve from -0.79671. Patience: 21/50
2024-07-05 23:29:00.118676: train_loss -0.7224
2024-07-05 23:29:00.120733: val_loss -0.7552
2024-07-05 23:29:00.121816: Pseudo dice [0.9663, 0.8796]
2024-07-05 23:29:00.122988: Epoch time: 65.2 s
2024-07-05 23:29:01.686332: 
2024-07-05 23:29:01.688589: Epoch 65
2024-07-05 23:29:01.689960: Current learning rate: 0.00941
2024-07-05 23:30:06.947747: Validation loss did not improve from -0.79671. Patience: 22/50
2024-07-05 23:30:06.966891: train_loss -0.7368
2024-07-05 23:30:06.969172: val_loss -0.7516
2024-07-05 23:30:06.970536: Pseudo dice [0.9667, 0.8694]
2024-07-05 23:30:06.971940: Epoch time: 65.28 s
2024-07-05 23:30:11.519854: 
2024-07-05 23:30:11.522631: Epoch 66
2024-07-05 23:30:11.525362: Current learning rate: 0.0094
2024-07-05 23:31:16.434928: Validation loss did not improve from -0.79671. Patience: 23/50
2024-07-05 23:31:16.436628: train_loss -0.7528
2024-07-05 23:31:16.438693: val_loss -0.7738
2024-07-05 23:31:16.440391: Pseudo dice [0.9703, 0.8867]
2024-07-05 23:31:16.441968: Epoch time: 64.92 s
2024-07-05 23:31:17.670613: 
2024-07-05 23:31:17.672903: Epoch 67
2024-07-05 23:31:17.674150: Current learning rate: 0.00939
2024-07-05 23:32:22.789813: Validation loss did not improve from -0.79671. Patience: 24/50
2024-07-05 23:32:22.791402: train_loss -0.7417
2024-07-05 23:32:22.792958: val_loss -0.7722
2024-07-05 23:32:22.794348: Pseudo dice [0.9655, 0.8743]
2024-07-05 23:32:22.795830: Epoch time: 65.12 s
2024-07-05 23:32:24.046551: 
2024-07-05 23:32:24.049234: Epoch 68
2024-07-05 23:32:24.050915: Current learning rate: 0.00939
2024-07-05 23:33:29.306006: Validation loss did not improve from -0.79671. Patience: 25/50
2024-07-05 23:33:29.308504: train_loss -0.7543
2024-07-05 23:33:29.310557: val_loss -0.7602
2024-07-05 23:33:29.311712: Pseudo dice [0.9725, 0.8859]
2024-07-05 23:33:29.312809: Epoch time: 65.26 s
2024-07-05 23:33:30.564402: 
2024-07-05 23:33:30.566367: Epoch 69
2024-07-05 23:33:30.567318: Current learning rate: 0.00938
2024-07-05 23:34:35.772357: Validation loss did not improve from -0.79671. Patience: 26/50
2024-07-05 23:34:35.773944: train_loss -0.7612
2024-07-05 23:34:35.775527: val_loss -0.7788
2024-07-05 23:34:35.776380: Pseudo dice [0.9719, 0.8875]
2024-07-05 23:34:35.777530: Epoch time: 65.21 s
2024-07-05 23:34:37.346361: 
2024-07-05 23:34:37.349155: Epoch 70
2024-07-05 23:34:37.350549: Current learning rate: 0.00937
2024-07-05 23:35:42.602865: Validation loss did not improve from -0.79671. Patience: 27/50
2024-07-05 23:35:42.604650: train_loss -0.7727
2024-07-05 23:35:42.605772: val_loss -0.7722
2024-07-05 23:35:42.606809: Pseudo dice [0.9658, 0.8832]
2024-07-05 23:35:42.607747: Epoch time: 65.26 s
2024-07-05 23:35:43.862698: 
2024-07-05 23:35:43.864934: Epoch 71
2024-07-05 23:35:43.866290: Current learning rate: 0.00936
2024-07-05 23:36:49.175310: Validation loss did not improve from -0.79671. Patience: 28/50
2024-07-05 23:36:49.177455: train_loss -0.7458
2024-07-05 23:36:49.179539: val_loss -0.7135
2024-07-05 23:36:49.181159: Pseudo dice [0.9627, 0.8625]
2024-07-05 23:36:49.182509: Epoch time: 65.32 s
2024-07-05 23:36:50.447736: 
2024-07-05 23:36:50.450214: Epoch 72
2024-07-05 23:36:50.452067: Current learning rate: 0.00935
2024-07-05 23:37:55.735301: Validation loss did not improve from -0.79671. Patience: 29/50
2024-07-05 23:37:55.736942: train_loss -0.7172
2024-07-05 23:37:55.738254: val_loss -0.7592
2024-07-05 23:37:55.740057: Pseudo dice [0.9634, 0.8815]
2024-07-05 23:37:55.742077: Epoch time: 65.29 s
2024-07-05 23:37:57.041811: 
2024-07-05 23:37:57.044929: Epoch 73
2024-07-05 23:37:57.047480: Current learning rate: 0.00934
2024-07-05 23:39:02.256966: Validation loss did not improve from -0.79671. Patience: 30/50
2024-07-05 23:39:02.258675: train_loss -0.7327
2024-07-05 23:39:02.260603: val_loss -0.7584
2024-07-05 23:39:02.261842: Pseudo dice [0.964, 0.8828]
2024-07-05 23:39:02.263097: Epoch time: 65.22 s
2024-07-05 23:39:03.510123: 
2024-07-05 23:39:03.512193: Epoch 74
2024-07-05 23:39:03.513758: Current learning rate: 0.00933
2024-07-05 23:40:08.697206: Validation loss did not improve from -0.79671. Patience: 31/50
2024-07-05 23:40:08.699233: train_loss -0.7426
2024-07-05 23:40:08.700476: val_loss -0.7735
2024-07-05 23:40:08.701825: Pseudo dice [0.9684, 0.8801]
2024-07-05 23:40:08.703022: Epoch time: 65.19 s
2024-07-05 23:40:10.284027: 
2024-07-05 23:40:10.286165: Epoch 75
2024-07-05 23:40:10.287490: Current learning rate: 0.00932
2024-07-05 23:41:15.129525: Validation loss did not improve from -0.79671. Patience: 32/50
2024-07-05 23:41:15.130903: train_loss -0.6999
2024-07-05 23:41:15.132475: val_loss -0.7396
2024-07-05 23:41:15.133558: Pseudo dice [0.9649, 0.8628]
2024-07-05 23:41:15.134669: Epoch time: 64.85 s
2024-07-05 23:41:16.388482: 
2024-07-05 23:41:16.391195: Epoch 76
2024-07-05 23:41:16.392811: Current learning rate: 0.00931
2024-07-05 23:42:21.349264: Validation loss did not improve from -0.79671. Patience: 33/50
2024-07-05 23:42:21.351318: train_loss -0.7137
2024-07-05 23:42:21.353616: val_loss -0.7172
2024-07-05 23:42:21.355579: Pseudo dice [0.9452, 0.8695]
2024-07-05 23:42:21.356844: Epoch time: 64.96 s
2024-07-05 23:42:22.603580: 
2024-07-05 23:42:22.605829: Epoch 77
2024-07-05 23:42:22.607023: Current learning rate: 0.0093
2024-07-05 23:43:27.528980: Validation loss did not improve from -0.79671. Patience: 34/50
2024-07-05 23:43:27.531180: train_loss -0.7255
2024-07-05 23:43:27.532983: val_loss -0.7564
2024-07-05 23:43:27.534186: Pseudo dice [0.9689, 0.8859]
2024-07-05 23:43:27.535372: Epoch time: 64.93 s
2024-07-05 23:43:29.216432: 
2024-07-05 23:43:29.219350: Epoch 78
2024-07-05 23:43:29.221029: Current learning rate: 0.0093
2024-07-05 23:44:34.091313: Validation loss did not improve from -0.79671. Patience: 35/50
2024-07-05 23:44:34.095694: train_loss -0.7374
2024-07-05 23:44:34.097659: val_loss -0.7328
2024-07-05 23:44:34.099222: Pseudo dice [0.9645, 0.8671]
2024-07-05 23:44:34.100437: Epoch time: 64.88 s
2024-07-05 23:44:35.391237: 
2024-07-05 23:44:35.394003: Epoch 79
2024-07-05 23:44:35.396030: Current learning rate: 0.00929
2024-07-05 23:45:40.471010: Validation loss did not improve from -0.79671. Patience: 36/50
2024-07-05 23:45:40.472954: train_loss -0.7271
2024-07-05 23:45:40.474846: val_loss -0.7483
2024-07-05 23:45:40.476499: Pseudo dice [0.9673, 0.8725]
2024-07-05 23:45:40.478525: Epoch time: 65.08 s
2024-07-05 23:45:42.074892: 
2024-07-05 23:45:42.077716: Epoch 80
2024-07-05 23:45:42.079350: Current learning rate: 0.00928
2024-07-05 23:46:47.108489: Validation loss did not improve from -0.79671. Patience: 37/50
2024-07-05 23:46:47.110161: train_loss -0.7454
2024-07-05 23:46:47.111910: val_loss -0.7567
2024-07-05 23:46:47.113040: Pseudo dice [0.9655, 0.8669]
2024-07-05 23:46:47.114357: Epoch time: 65.04 s
2024-07-05 23:46:48.411175: 
2024-07-05 23:46:48.413766: Epoch 81
2024-07-05 23:46:48.415555: Current learning rate: 0.00927
2024-07-05 23:47:53.370518: Validation loss did not improve from -0.79671. Patience: 38/50
2024-07-05 23:47:53.372554: train_loss -0.7564
2024-07-05 23:47:53.373987: val_loss -0.7771
2024-07-05 23:47:53.375134: Pseudo dice [0.9706, 0.8838]
2024-07-05 23:47:53.376183: Epoch time: 64.96 s
2024-07-05 23:47:54.666022: 
2024-07-05 23:47:54.668490: Epoch 82
2024-07-05 23:47:54.669684: Current learning rate: 0.00926
2024-07-05 23:48:59.594401: Validation loss did not improve from -0.79671. Patience: 39/50
2024-07-05 23:48:59.596083: train_loss -0.7687
2024-07-05 23:48:59.597640: val_loss -0.7942
2024-07-05 23:48:59.599258: Pseudo dice [0.9719, 0.8893]
2024-07-05 23:48:59.600818: Epoch time: 64.93 s
2024-07-05 23:49:00.812773: 
2024-07-05 23:49:00.814782: Epoch 83
2024-07-05 23:49:00.816292: Current learning rate: 0.00925
2024-07-05 23:50:05.825787: Validation loss did not improve from -0.79671. Patience: 40/50
2024-07-05 23:50:05.828175: train_loss -0.7634
2024-07-05 23:50:05.830148: val_loss -0.7754
2024-07-05 23:50:05.831708: Pseudo dice [0.9698, 0.8883]
2024-07-05 23:50:05.832852: Epoch time: 65.02 s
2024-07-05 23:50:07.042595: 
2024-07-05 23:50:07.045047: Epoch 84
2024-07-05 23:50:07.046806: Current learning rate: 0.00924
2024-07-05 23:51:12.154464: Validation loss did not improve from -0.79671. Patience: 41/50
2024-07-05 23:51:12.157007: train_loss -0.7739
2024-07-05 23:51:12.159477: val_loss -0.775
2024-07-05 23:51:12.160710: Pseudo dice [0.9655, 0.8777]
2024-07-05 23:51:12.162515: Epoch time: 65.12 s
2024-07-05 23:51:13.669201: 
2024-07-05 23:51:13.670918: Epoch 85
2024-07-05 23:51:13.671944: Current learning rate: 0.00923
2024-07-05 23:52:18.737032: Validation loss did not improve from -0.79671. Patience: 42/50
2024-07-05 23:52:18.738631: train_loss -0.7628
2024-07-05 23:52:18.739823: val_loss -0.7881
2024-07-05 23:52:18.740818: Pseudo dice [0.9708, 0.8901]
2024-07-05 23:52:18.741746: Epoch time: 65.07 s
2024-07-05 23:52:19.940879: 
2024-07-05 23:52:19.943126: Epoch 86
2024-07-05 23:52:19.944480: Current learning rate: 0.00922
2024-07-05 23:53:24.947700: Validation loss did not improve from -0.79671. Patience: 43/50
2024-07-05 23:53:24.949254: train_loss -0.7737
2024-07-05 23:53:24.951249: val_loss -0.79
2024-07-05 23:53:24.953496: Pseudo dice [0.9715, 0.8932]
2024-07-05 23:53:24.954891: Epoch time: 65.01 s
2024-07-05 23:53:26.173399: 
2024-07-05 23:53:26.176134: Epoch 87
2024-07-05 23:53:26.178523: Current learning rate: 0.00921
2024-07-05 23:54:31.337037: Validation loss improved from -0.79671 to -0.79765! Patience: 43/50
2024-07-05 23:54:31.338536: train_loss -0.7715
2024-07-05 23:54:31.339720: val_loss -0.7977
2024-07-05 23:54:31.341383: Pseudo dice [0.9754, 0.8882]
2024-07-05 23:54:31.343144: Epoch time: 65.17 s
2024-07-05 23:54:32.550743: 
2024-07-05 23:54:32.553525: Epoch 88
2024-07-05 23:54:32.555239: Current learning rate: 0.0092
2024-07-05 23:55:37.702341: Validation loss improved from -0.79765 to -0.79787! Patience: 0/50
2024-07-05 23:55:37.704390: train_loss -0.7796
2024-07-05 23:55:37.706765: val_loss -0.7979
2024-07-05 23:55:37.708077: Pseudo dice [0.9737, 0.8956]
2024-07-05 23:55:37.709308: Epoch time: 65.15 s
2024-07-05 23:55:38.910072: 
2024-07-05 23:55:38.912986: Epoch 89
2024-07-05 23:55:38.914824: Current learning rate: 0.0092
2024-07-05 23:56:44.070293: Validation loss improved from -0.79787 to -0.80740! Patience: 0/50
2024-07-05 23:56:44.072753: train_loss -0.7736
2024-07-05 23:56:44.075410: val_loss -0.8074
2024-07-05 23:56:44.077485: Pseudo dice [0.9715, 0.8985]
2024-07-05 23:56:44.079145: Epoch time: 65.16 s
2024-07-05 23:56:45.917947: 
2024-07-05 23:56:45.920616: Epoch 90
2024-07-05 23:56:45.922070: Current learning rate: 0.00919
2024-07-05 23:57:51.084642: Validation loss did not improve from -0.80740. Patience: 1/50
2024-07-05 23:57:51.086958: train_loss -0.7701
2024-07-05 23:57:51.088666: val_loss -0.8066
2024-07-05 23:57:51.089786: Pseudo dice [0.9739, 0.8892]
2024-07-05 23:57:51.090677: Epoch time: 65.17 s
2024-07-05 23:57:52.272283: 
2024-07-05 23:57:52.274225: Epoch 91
2024-07-05 23:57:52.275304: Current learning rate: 0.00918
2024-07-05 23:58:57.580163: Validation loss did not improve from -0.80740. Patience: 2/50
2024-07-05 23:58:57.582523: train_loss -0.7679
2024-07-05 23:58:57.584280: val_loss -0.7996
2024-07-05 23:58:57.585416: Pseudo dice [0.9714, 0.8905]
2024-07-05 23:58:57.586913: Epoch time: 65.31 s
2024-07-05 23:58:57.588394: Yayy! New best EMA pseudo Dice: 0.9279
2024-07-05 23:58:59.109036: 
2024-07-05 23:58:59.111497: Epoch 92
2024-07-05 23:58:59.112841: Current learning rate: 0.00917
2024-07-06 00:00:04.393520: Validation loss did not improve from -0.80740. Patience: 3/50
2024-07-06 00:00:04.395237: train_loss -0.7755
2024-07-06 00:00:04.396860: val_loss -0.7766
2024-07-06 00:00:04.398265: Pseudo dice [0.9703, 0.8893]
2024-07-06 00:00:04.400098: Epoch time: 65.29 s
2024-07-06 00:00:04.401504: Yayy! New best EMA pseudo Dice: 0.9281
2024-07-06 00:00:05.899310: 
2024-07-06 00:00:05.901361: Epoch 93
2024-07-06 00:00:05.902771: Current learning rate: 0.00916
2024-07-06 00:01:11.109234: Validation loss did not improve from -0.80740. Patience: 4/50
2024-07-06 00:01:11.111230: train_loss -0.7657
2024-07-06 00:01:11.113021: val_loss -0.7887
2024-07-06 00:01:11.114354: Pseudo dice [0.9651, 0.8928]
2024-07-06 00:01:11.115863: Epoch time: 65.21 s
2024-07-06 00:01:11.116983: Yayy! New best EMA pseudo Dice: 0.9282
2024-07-06 00:01:12.586916: 
2024-07-06 00:01:12.589935: Epoch 94
2024-07-06 00:01:12.591685: Current learning rate: 0.00915
2024-07-06 00:02:18.333166: Validation loss did not improve from -0.80740. Patience: 5/50
2024-07-06 00:02:18.334833: train_loss -0.7599
2024-07-06 00:02:18.336982: val_loss -0.7663
2024-07-06 00:02:18.338844: Pseudo dice [0.9684, 0.8791]
2024-07-06 00:02:18.340484: Epoch time: 65.75 s
2024-07-06 00:02:19.869612: 
2024-07-06 00:02:19.871991: Epoch 95
2024-07-06 00:02:19.873506: Current learning rate: 0.00914
2024-07-06 00:03:25.160293: Validation loss did not improve from -0.80740. Patience: 6/50
2024-07-06 00:03:25.161930: train_loss -0.7641
2024-07-06 00:03:25.163616: val_loss -0.7823
2024-07-06 00:03:25.165343: Pseudo dice [0.9707, 0.8858]
2024-07-06 00:03:25.167333: Epoch time: 65.29 s
2024-07-06 00:03:26.327884: 
2024-07-06 00:03:26.330007: Epoch 96
2024-07-06 00:03:26.331504: Current learning rate: 0.00913
2024-07-06 00:04:31.656705: Validation loss did not improve from -0.80740. Patience: 7/50
2024-07-06 00:04:31.659060: train_loss -0.7786
2024-07-06 00:04:31.660989: val_loss -0.8016
2024-07-06 00:04:31.662748: Pseudo dice [0.9714, 0.894]
2024-07-06 00:04:31.664238: Epoch time: 65.33 s
2024-07-06 00:04:31.665380: Yayy! New best EMA pseudo Dice: 0.9283
2024-07-06 00:04:33.217199: 
2024-07-06 00:04:33.219219: Epoch 97
2024-07-06 00:04:33.220464: Current learning rate: 0.00912
2024-07-06 00:05:38.545732: Validation loss did not improve from -0.80740. Patience: 8/50
2024-07-06 00:05:38.547873: train_loss -0.7806
2024-07-06 00:05:38.549595: val_loss -0.7998
2024-07-06 00:05:38.551210: Pseudo dice [0.9738, 0.8979]
2024-07-06 00:05:38.553082: Epoch time: 65.33 s
2024-07-06 00:05:38.554421: Yayy! New best EMA pseudo Dice: 0.929
2024-07-06 00:05:40.070647: 
2024-07-06 00:05:40.073152: Epoch 98
2024-07-06 00:05:40.074142: Current learning rate: 0.00911
2024-07-06 00:06:45.900570: Validation loss improved from -0.80740 to -0.80900! Patience: 8/50
2024-07-06 00:06:45.911391: train_loss -0.7922
2024-07-06 00:06:45.913630: val_loss -0.809
2024-07-06 00:06:45.914783: Pseudo dice [0.9743, 0.8936]
2024-07-06 00:06:45.915962: Epoch time: 65.83 s
2024-07-06 00:06:45.917078: Yayy! New best EMA pseudo Dice: 0.9295
2024-07-06 00:06:47.500423: 
2024-07-06 00:06:47.503287: Epoch 99
2024-07-06 00:06:47.505099: Current learning rate: 0.0091
2024-07-06 00:07:53.065992: Validation loss did not improve from -0.80900. Patience: 1/50
2024-07-06 00:07:53.067732: train_loss -0.7787
2024-07-06 00:07:53.069311: val_loss -0.7941
2024-07-06 00:07:53.071293: Pseudo dice [0.9724, 0.8923]
2024-07-06 00:07:53.073358: Epoch time: 65.57 s
2024-07-06 00:07:53.419985: Yayy! New best EMA pseudo Dice: 0.9298
2024-07-06 00:07:54.943927: 
2024-07-06 00:07:54.946695: Epoch 100
2024-07-06 00:07:54.948550: Current learning rate: 0.0091
2024-07-06 00:09:00.599248: Validation loss did not improve from -0.80900. Patience: 2/50
2024-07-06 00:09:00.600441: train_loss -0.7647
2024-07-06 00:09:00.602150: val_loss -0.7832
2024-07-06 00:09:00.603396: Pseudo dice [0.9645, 0.8921]
2024-07-06 00:09:00.604768: Epoch time: 65.66 s
2024-07-06 00:09:01.785207: 
2024-07-06 00:09:01.787906: Epoch 101
2024-07-06 00:09:01.790064: Current learning rate: 0.00909
2024-07-06 00:10:07.711827: Validation loss did not improve from -0.80900. Patience: 3/50
2024-07-06 00:10:07.713874: train_loss -0.7715
2024-07-06 00:10:07.715999: val_loss -0.7921
2024-07-06 00:10:07.717628: Pseudo dice [0.9693, 0.8937]
2024-07-06 00:10:07.718821: Epoch time: 65.93 s
2024-07-06 00:10:07.720135: Yayy! New best EMA pseudo Dice: 0.9298
2024-07-06 00:10:09.833420: 
2024-07-06 00:10:09.835673: Epoch 102
2024-07-06 00:10:09.836960: Current learning rate: 0.00908
2024-07-06 00:11:15.607643: Validation loss did not improve from -0.80900. Patience: 4/50
2024-07-06 00:11:15.609630: train_loss -0.7493
2024-07-06 00:11:15.611265: val_loss -0.7699
2024-07-06 00:11:15.612531: Pseudo dice [0.9713, 0.8753]
2024-07-06 00:11:15.613776: Epoch time: 65.78 s
2024-07-06 00:11:16.795432: 
2024-07-06 00:11:16.798397: Epoch 103
2024-07-06 00:11:16.800644: Current learning rate: 0.00907
2024-07-06 00:12:22.485986: Validation loss did not improve from -0.80900. Patience: 5/50
2024-07-06 00:12:22.488092: train_loss -0.7742
2024-07-06 00:12:22.490461: val_loss -0.8028
2024-07-06 00:12:22.491862: Pseudo dice [0.9743, 0.8955]
2024-07-06 00:12:22.493036: Epoch time: 65.69 s
2024-07-06 00:12:23.672149: 
2024-07-06 00:12:23.674315: Epoch 104
2024-07-06 00:12:23.675451: Current learning rate: 0.00906
2024-07-06 00:13:29.242959: Validation loss did not improve from -0.80900. Patience: 6/50
2024-07-06 00:13:29.244683: train_loss -0.7803
2024-07-06 00:13:29.246095: val_loss -0.7784
2024-07-06 00:13:29.247176: Pseudo dice [0.9698, 0.8823]
2024-07-06 00:13:29.248431: Epoch time: 65.57 s
2024-07-06 00:13:30.765171: 
2024-07-06 00:13:30.767891: Epoch 105
2024-07-06 00:13:30.769624: Current learning rate: 0.00905
2024-07-06 00:14:36.341704: Validation loss did not improve from -0.80900. Patience: 7/50
2024-07-06 00:14:36.343682: train_loss -0.7691
2024-07-06 00:14:36.345265: val_loss -0.7987
2024-07-06 00:14:36.346364: Pseudo dice [0.9722, 0.8992]
2024-07-06 00:14:36.347323: Epoch time: 65.58 s
2024-07-06 00:14:36.348230: Yayy! New best EMA pseudo Dice: 0.93
2024-07-06 00:14:37.870170: 
2024-07-06 00:14:37.872171: Epoch 106
2024-07-06 00:14:37.873276: Current learning rate: 0.00904
2024-07-06 00:15:43.345471: Validation loss did not improve from -0.80900. Patience: 8/50
2024-07-06 00:15:43.346993: train_loss -0.7769
2024-07-06 00:15:43.348900: val_loss -0.7709
2024-07-06 00:15:43.350064: Pseudo dice [0.9751, 0.8783]
2024-07-06 00:15:43.350929: Epoch time: 65.48 s
2024-07-06 00:15:44.536023: 
2024-07-06 00:15:44.538486: Epoch 107
2024-07-06 00:15:44.539717: Current learning rate: 0.00903
2024-07-06 00:16:50.156071: Validation loss did not improve from -0.80900. Patience: 9/50
2024-07-06 00:16:50.158334: train_loss -0.7782
2024-07-06 00:16:50.160364: val_loss -0.7905
2024-07-06 00:16:50.162107: Pseudo dice [0.9708, 0.8905]
2024-07-06 00:16:50.163522: Epoch time: 65.62 s
2024-07-06 00:16:51.361053: 
2024-07-06 00:16:51.363099: Epoch 108
2024-07-06 00:16:51.364404: Current learning rate: 0.00902
2024-07-06 00:17:57.107441: Validation loss did not improve from -0.80900. Patience: 10/50
2024-07-06 00:17:57.109581: train_loss -0.7812
2024-07-06 00:17:57.111522: val_loss -0.8078
2024-07-06 00:17:57.113139: Pseudo dice [0.9741, 0.8998]
2024-07-06 00:17:57.114632: Epoch time: 65.75 s
2024-07-06 00:17:57.115907: Yayy! New best EMA pseudo Dice: 0.9305
2024-07-06 00:17:58.711804: 
2024-07-06 00:17:58.713839: Epoch 109
2024-07-06 00:17:58.715237: Current learning rate: 0.00901
2024-07-06 00:19:04.390630: Validation loss did not improve from -0.80900. Patience: 11/50
2024-07-06 00:19:04.392216: train_loss -0.7782
2024-07-06 00:19:04.394053: val_loss -0.8043
2024-07-06 00:19:04.395462: Pseudo dice [0.9722, 0.8945]
2024-07-06 00:19:04.396645: Epoch time: 65.68 s
2024-07-06 00:19:04.748210: Yayy! New best EMA pseudo Dice: 0.9308
2024-07-06 00:19:06.285340: 
2024-07-06 00:19:06.288256: Epoch 110
2024-07-06 00:19:06.290260: Current learning rate: 0.009
2024-07-06 00:20:11.871660: Validation loss improved from -0.80900 to -0.81014! Patience: 11/50
2024-07-06 00:20:11.873713: train_loss -0.7749
2024-07-06 00:20:11.875675: val_loss -0.8101
2024-07-06 00:20:11.877409: Pseudo dice [0.9734, 0.898]
2024-07-06 00:20:11.878730: Epoch time: 65.59 s
2024-07-06 00:20:11.880012: Yayy! New best EMA pseudo Dice: 0.9313
2024-07-06 00:20:13.408657: 
2024-07-06 00:20:13.410721: Epoch 111
2024-07-06 00:20:13.412014: Current learning rate: 0.009
2024-07-06 00:21:18.862158: Validation loss did not improve from -0.81014. Patience: 1/50
2024-07-06 00:21:18.864051: train_loss -0.7814
2024-07-06 00:21:18.865768: val_loss -0.798
2024-07-06 00:21:18.866714: Pseudo dice [0.9726, 0.8981]
2024-07-06 00:21:18.867738: Epoch time: 65.46 s
2024-07-06 00:21:18.868803: Yayy! New best EMA pseudo Dice: 0.9317
2024-07-06 00:21:20.378437: 
2024-07-06 00:21:20.381513: Epoch 112
2024-07-06 00:21:20.383415: Current learning rate: 0.00899
2024-07-06 00:22:25.755549: Validation loss did not improve from -0.81014. Patience: 2/50
2024-07-06 00:22:25.757412: train_loss -0.7775
2024-07-06 00:22:25.759181: val_loss -0.7903
2024-07-06 00:22:25.761040: Pseudo dice [0.9711, 0.8905]
2024-07-06 00:22:25.763124: Epoch time: 65.38 s
2024-07-06 00:22:26.942222: 
2024-07-06 00:22:26.945209: Epoch 113
2024-07-06 00:22:26.947319: Current learning rate: 0.00898
2024-07-06 00:23:32.553680: Validation loss did not improve from -0.81014. Patience: 3/50
2024-07-06 00:23:32.555331: train_loss -0.7641
2024-07-06 00:23:32.558253: val_loss -0.8037
2024-07-06 00:23:32.560060: Pseudo dice [0.9728, 0.8938]
2024-07-06 00:23:32.562148: Epoch time: 65.61 s
2024-07-06 00:23:32.563759: Yayy! New best EMA pseudo Dice: 0.9318
2024-07-06 00:23:34.769119: 
2024-07-06 00:23:34.770705: Epoch 114
2024-07-06 00:23:34.771729: Current learning rate: 0.00897
2024-07-06 00:24:42.081878: Validation loss did not improve from -0.81014. Patience: 4/50
2024-07-06 00:24:42.083520: train_loss -0.765
2024-07-06 00:24:42.085723: val_loss -0.7873
2024-07-06 00:24:42.087936: Pseudo dice [0.9675, 0.8819]
2024-07-06 00:24:42.090138: Epoch time: 67.32 s
2024-07-06 00:24:44.009070: 
2024-07-06 00:24:44.010923: Epoch 115
2024-07-06 00:24:44.012222: Current learning rate: 0.00896
2024-07-06 00:25:49.405495: Validation loss did not improve from -0.81014. Patience: 5/50
2024-07-06 00:25:49.407001: train_loss -0.759
2024-07-06 00:25:49.408937: val_loss -0.8048
2024-07-06 00:25:49.410909: Pseudo dice [0.9756, 0.8928]
2024-07-06 00:25:49.412565: Epoch time: 65.4 s
2024-07-06 00:25:50.681607: 
2024-07-06 00:25:50.684244: Epoch 116
2024-07-06 00:25:50.685485: Current learning rate: 0.00895
2024-07-06 00:26:56.363441: Validation loss did not improve from -0.81014. Patience: 6/50
2024-07-06 00:26:56.365567: train_loss -0.7835
2024-07-06 00:26:56.367216: val_loss -0.8037
2024-07-06 00:26:56.368373: Pseudo dice [0.9721, 0.8883]
2024-07-06 00:26:56.369495: Epoch time: 65.69 s
2024-07-06 00:26:57.975498: 
2024-07-06 00:26:57.978462: Epoch 117
2024-07-06 00:26:57.980393: Current learning rate: 0.00894
2024-07-06 00:28:06.176092: Validation loss did not improve from -0.81014. Patience: 7/50
2024-07-06 00:28:06.321132: train_loss -0.7834
2024-07-06 00:28:06.323340: val_loss -0.7893
2024-07-06 00:28:06.325361: Pseudo dice [0.9742, 0.8883]
2024-07-06 00:28:06.326624: Epoch time: 68.23 s
2024-07-06 00:28:09.049595: 
2024-07-06 00:28:09.052156: Epoch 118
2024-07-06 00:28:09.054083: Current learning rate: 0.00893
2024-07-06 00:29:14.523464: Validation loss did not improve from -0.81014. Patience: 8/50
2024-07-06 00:29:14.525254: train_loss -0.7702
2024-07-06 00:29:14.527169: val_loss -0.7893
2024-07-06 00:29:14.528626: Pseudo dice [0.9714, 0.8926]
2024-07-06 00:29:14.530669: Epoch time: 65.48 s
2024-07-06 00:29:15.824403: 
2024-07-06 00:29:15.827327: Epoch 119
2024-07-06 00:29:15.829195: Current learning rate: 0.00892
2024-07-06 00:30:21.413139: Validation loss improved from -0.81014 to -0.81309! Patience: 8/50
2024-07-06 00:30:21.414864: train_loss -0.7812
2024-07-06 00:30:21.416516: val_loss -0.8131
2024-07-06 00:30:21.417704: Pseudo dice [0.9697, 0.9005]
2024-07-06 00:30:21.418922: Epoch time: 65.59 s
2024-07-06 00:30:23.154868: 
2024-07-06 00:30:23.157186: Epoch 120
2024-07-06 00:30:23.158988: Current learning rate: 0.00891
2024-07-06 00:31:28.514235: Validation loss did not improve from -0.81309. Patience: 1/50
2024-07-06 00:31:28.517332: train_loss -0.781
2024-07-06 00:31:28.519201: val_loss -0.788
2024-07-06 00:31:28.520275: Pseudo dice [0.9699, 0.8851]
2024-07-06 00:31:28.521721: Epoch time: 65.36 s
2024-07-06 00:31:29.743374: 
2024-07-06 00:31:29.745725: Epoch 121
2024-07-06 00:31:29.747341: Current learning rate: 0.0089
2024-07-06 00:32:35.216648: Validation loss did not improve from -0.81309. Patience: 2/50
2024-07-06 00:32:35.219410: train_loss -0.7728
2024-07-06 00:32:35.221288: val_loss -0.7863
2024-07-06 00:32:35.222744: Pseudo dice [0.9701, 0.8924]
2024-07-06 00:32:35.224270: Epoch time: 65.48 s
2024-07-06 00:32:36.454679: 
2024-07-06 00:32:36.457293: Epoch 122
2024-07-06 00:32:36.459028: Current learning rate: 0.00889
2024-07-06 00:33:41.790228: Validation loss did not improve from -0.81309. Patience: 3/50
2024-07-06 00:33:41.792074: train_loss -0.7569
2024-07-06 00:33:41.793671: val_loss -0.7865
2024-07-06 00:33:41.795306: Pseudo dice [0.9713, 0.8737]
2024-07-06 00:33:41.797354: Epoch time: 65.34 s
2024-07-06 00:33:43.011998: 
2024-07-06 00:33:43.014812: Epoch 123
2024-07-06 00:33:43.016299: Current learning rate: 0.00889
2024-07-06 00:34:48.384768: Validation loss did not improve from -0.81309. Patience: 4/50
2024-07-06 00:34:48.386959: train_loss -0.7336
2024-07-06 00:34:48.389159: val_loss -0.7618
2024-07-06 00:34:48.390993: Pseudo dice [0.9648, 0.8828]
2024-07-06 00:34:48.393058: Epoch time: 65.38 s
2024-07-06 00:34:49.615927: 
2024-07-06 00:34:49.618473: Epoch 124
2024-07-06 00:34:49.620398: Current learning rate: 0.00888
2024-07-06 00:35:57.214395: Validation loss did not improve from -0.81309. Patience: 5/50
2024-07-06 00:35:57.215643: train_loss -0.7435
2024-07-06 00:35:57.216949: val_loss -0.7723
2024-07-06 00:35:57.218184: Pseudo dice [0.9689, 0.887]
2024-07-06 00:35:57.219371: Epoch time: 67.6 s
2024-07-06 00:35:58.769388: 
2024-07-06 00:35:58.771353: Epoch 125
2024-07-06 00:35:58.772817: Current learning rate: 0.00887
2024-07-06 00:37:04.019929: Validation loss did not improve from -0.81309. Patience: 6/50
2024-07-06 00:37:04.021948: train_loss -0.7536
2024-07-06 00:37:04.023996: val_loss -0.7998
2024-07-06 00:37:04.025714: Pseudo dice [0.9755, 0.8993]
2024-07-06 00:37:04.027407: Epoch time: 65.25 s
2024-07-06 00:37:05.264596: 
2024-07-06 00:37:05.267121: Epoch 126
2024-07-06 00:37:05.268360: Current learning rate: 0.00886
2024-07-06 00:38:10.517216: Validation loss did not improve from -0.81309. Patience: 7/50
2024-07-06 00:38:10.519023: train_loss -0.7598
2024-07-06 00:38:10.520562: val_loss -0.7671
2024-07-06 00:38:10.521992: Pseudo dice [0.9698, 0.8863]
2024-07-06 00:38:10.523432: Epoch time: 65.26 s
2024-07-06 00:38:14.431368: 
2024-07-06 00:38:14.433371: Epoch 127
2024-07-06 00:38:14.434635: Current learning rate: 0.00885
2024-07-06 00:39:19.646402: Validation loss did not improve from -0.81309. Patience: 8/50
2024-07-06 00:39:19.648661: train_loss -0.7665
2024-07-06 00:39:19.650370: val_loss -0.7832
2024-07-06 00:39:19.651660: Pseudo dice [0.9699, 0.8836]
2024-07-06 00:39:19.652846: Epoch time: 65.22 s
2024-07-06 00:39:20.882258: 
2024-07-06 00:39:20.884584: Epoch 128
2024-07-06 00:39:20.886129: Current learning rate: 0.00884
2024-07-06 00:40:26.154385: Validation loss did not improve from -0.81309. Patience: 9/50
2024-07-06 00:40:26.156239: train_loss -0.7643
2024-07-06 00:40:26.157878: val_loss -0.7903
2024-07-06 00:40:26.159561: Pseudo dice [0.9709, 0.8923]
2024-07-06 00:40:26.160868: Epoch time: 65.28 s
2024-07-06 00:40:27.392643: 
2024-07-06 00:40:27.394594: Epoch 129
2024-07-06 00:40:27.395678: Current learning rate: 0.00883
2024-07-06 00:41:32.726011: Validation loss did not improve from -0.81309. Patience: 10/50
2024-07-06 00:41:32.728189: train_loss -0.7632
2024-07-06 00:41:32.729859: val_loss -0.7843
2024-07-06 00:41:32.730936: Pseudo dice [0.9712, 0.8928]
2024-07-06 00:41:32.732224: Epoch time: 65.34 s
2024-07-06 00:41:34.257011: 
2024-07-06 00:41:34.259005: Epoch 130
2024-07-06 00:41:34.260555: Current learning rate: 0.00882
2024-07-06 00:42:39.737294: Validation loss did not improve from -0.81309. Patience: 11/50
2024-07-06 00:42:39.738866: train_loss -0.7587
2024-07-06 00:42:39.740125: val_loss -0.7768
2024-07-06 00:42:39.741252: Pseudo dice [0.9726, 0.8884]
2024-07-06 00:42:39.742511: Epoch time: 65.48 s
2024-07-06 00:42:40.979047: 
2024-07-06 00:42:40.981285: Epoch 131
2024-07-06 00:42:40.982663: Current learning rate: 0.00881
2024-07-06 00:43:46.486595: Validation loss did not improve from -0.81309. Patience: 12/50
2024-07-06 00:43:46.488448: train_loss -0.7753
2024-07-06 00:43:46.490439: val_loss -0.8083
2024-07-06 00:43:46.491735: Pseudo dice [0.9711, 0.8938]
2024-07-06 00:43:46.493037: Epoch time: 65.51 s
2024-07-06 00:43:47.722650: 
2024-07-06 00:43:47.724879: Epoch 132
2024-07-06 00:43:47.726427: Current learning rate: 0.0088
2024-07-06 00:44:53.231338: Validation loss did not improve from -0.81309. Patience: 13/50
2024-07-06 00:44:53.233308: train_loss -0.777
2024-07-06 00:44:53.235709: val_loss -0.8123
2024-07-06 00:44:53.237768: Pseudo dice [0.9747, 0.8944]
2024-07-06 00:44:53.239851: Epoch time: 65.51 s
2024-07-06 00:44:54.456750: 
2024-07-06 00:44:54.459264: Epoch 133
2024-07-06 00:44:54.460855: Current learning rate: 0.00879
2024-07-06 00:45:59.891177: Validation loss did not improve from -0.81309. Patience: 14/50
2024-07-06 00:45:59.893192: train_loss -0.7817
2024-07-06 00:45:59.894634: val_loss -0.7883
2024-07-06 00:45:59.895681: Pseudo dice [0.9748, 0.8948]
2024-07-06 00:45:59.896743: Epoch time: 65.44 s
2024-07-06 00:46:01.113375: 
2024-07-06 00:46:01.115666: Epoch 134
2024-07-06 00:46:01.117111: Current learning rate: 0.00879
2024-07-06 00:47:06.617321: Validation loss did not improve from -0.81309. Patience: 15/50
2024-07-06 00:47:06.619190: train_loss -0.7747
2024-07-06 00:47:06.621098: val_loss -0.7841
2024-07-06 00:47:06.623049: Pseudo dice [0.9688, 0.89]
2024-07-06 00:47:06.624302: Epoch time: 65.51 s
2024-07-06 00:47:08.175992: 
2024-07-06 00:47:08.178616: Epoch 135
2024-07-06 00:47:08.180316: Current learning rate: 0.00878
2024-07-06 00:48:13.750293: Validation loss did not improve from -0.81309. Patience: 16/50
2024-07-06 00:48:13.752164: train_loss -0.7763
2024-07-06 00:48:13.753652: val_loss -0.7811
2024-07-06 00:48:13.755024: Pseudo dice [0.9686, 0.8839]
2024-07-06 00:48:13.756313: Epoch time: 65.58 s
2024-07-06 00:48:15.004227: 
2024-07-06 00:48:15.007549: Epoch 136
2024-07-06 00:48:15.009394: Current learning rate: 0.00877
2024-07-06 00:49:20.447232: Validation loss did not improve from -0.81309. Patience: 17/50
2024-07-06 00:49:20.448681: train_loss -0.713
2024-07-06 00:49:20.449821: val_loss -0.7271
2024-07-06 00:49:20.450778: Pseudo dice [0.9572, 0.8511]
2024-07-06 00:49:20.451672: Epoch time: 65.45 s
2024-07-06 00:49:21.702656: 
2024-07-06 00:49:21.705145: Epoch 137
2024-07-06 00:49:21.706509: Current learning rate: 0.00876
2024-07-06 00:50:27.111717: Validation loss did not improve from -0.81309. Patience: 18/50
2024-07-06 00:50:27.113302: train_loss -0.7128
2024-07-06 00:50:27.114988: val_loss -0.7473
2024-07-06 00:50:27.116597: Pseudo dice [0.9613, 0.8701]
2024-07-06 00:50:27.117885: Epoch time: 65.41 s
2024-07-06 00:50:28.355449: 
2024-07-06 00:50:28.358177: Epoch 138
2024-07-06 00:50:28.360766: Current learning rate: 0.00875
2024-07-06 00:51:33.562810: Validation loss did not improve from -0.81309. Patience: 19/50
2024-07-06 00:51:33.564854: train_loss -0.7418
2024-07-06 00:51:33.567262: val_loss -0.7633
2024-07-06 00:51:33.568821: Pseudo dice [0.9662, 0.8807]
2024-07-06 00:51:33.570174: Epoch time: 65.21 s
2024-07-06 00:51:35.197833: 
2024-07-06 00:51:35.199880: Epoch 139
2024-07-06 00:51:35.201102: Current learning rate: 0.00874
2024-07-06 00:52:40.476609: Validation loss did not improve from -0.81309. Patience: 20/50
2024-07-06 00:52:40.478281: train_loss -0.746
2024-07-06 00:52:40.479404: val_loss -0.7558
2024-07-06 00:52:40.480465: Pseudo dice [0.9667, 0.8798]
2024-07-06 00:52:40.481442: Epoch time: 65.28 s
2024-07-06 00:52:42.046590: 
2024-07-06 00:52:42.048640: Epoch 140
2024-07-06 00:52:42.049829: Current learning rate: 0.00873
2024-07-06 00:53:47.234693: Validation loss did not improve from -0.81309. Patience: 21/50
2024-07-06 00:53:47.236902: train_loss -0.757
2024-07-06 00:53:47.238583: val_loss -0.7854
2024-07-06 00:53:47.239907: Pseudo dice [0.9689, 0.8844]
2024-07-06 00:53:47.241086: Epoch time: 65.19 s
2024-07-06 00:53:48.490831: 
2024-07-06 00:53:48.493471: Epoch 141
2024-07-06 00:53:48.494646: Current learning rate: 0.00872
2024-07-06 00:54:53.661967: Validation loss did not improve from -0.81309. Patience: 22/50
2024-07-06 00:54:53.663414: train_loss -0.7656
2024-07-06 00:54:53.664694: val_loss -0.7833
2024-07-06 00:54:53.665613: Pseudo dice [0.9702, 0.8943]
2024-07-06 00:54:53.666666: Epoch time: 65.17 s
2024-07-06 00:54:54.891835: 
2024-07-06 00:54:54.893860: Epoch 142
2024-07-06 00:54:54.895460: Current learning rate: 0.00871
2024-07-06 00:56:00.093410: Validation loss did not improve from -0.81309. Patience: 23/50
2024-07-06 00:56:00.096269: train_loss -0.7758
2024-07-06 00:56:00.098429: val_loss -0.7847
2024-07-06 00:56:00.099530: Pseudo dice [0.9712, 0.8896]
2024-07-06 00:56:00.100800: Epoch time: 65.21 s
2024-07-06 00:56:01.351873: 
2024-07-06 00:56:01.354474: Epoch 143
2024-07-06 00:56:01.356145: Current learning rate: 0.0087
2024-07-06 00:57:06.121986: Validation loss did not improve from -0.81309. Patience: 24/50
2024-07-06 00:57:06.124187: train_loss -0.7729
2024-07-06 00:57:06.126023: val_loss -0.8065
2024-07-06 00:57:06.127426: Pseudo dice [0.9702, 0.8942]
2024-07-06 00:57:06.128446: Epoch time: 64.77 s
2024-07-06 00:57:07.388586: 
2024-07-06 00:57:07.390951: Epoch 144
2024-07-06 00:57:07.392555: Current learning rate: 0.00869
2024-07-06 00:58:12.192172: Validation loss did not improve from -0.81309. Patience: 25/50
2024-07-06 00:58:12.194311: train_loss -0.7805
2024-07-06 00:58:12.195661: val_loss -0.7793
2024-07-06 00:58:12.197551: Pseudo dice [0.9695, 0.8888]
2024-07-06 00:58:12.199435: Epoch time: 64.81 s
2024-07-06 00:58:13.739954: 
2024-07-06 00:58:13.742605: Epoch 145
2024-07-06 00:58:13.743955: Current learning rate: 0.00868
2024-07-06 00:59:18.971985: Validation loss did not improve from -0.81309. Patience: 26/50
2024-07-06 00:59:18.974119: train_loss -0.7582
2024-07-06 00:59:18.975757: val_loss -0.7813
2024-07-06 00:59:18.976935: Pseudo dice [0.9719, 0.8899]
2024-07-06 00:59:18.977911: Epoch time: 65.24 s
2024-07-06 00:59:20.220982: 
2024-07-06 00:59:20.223917: Epoch 146
2024-07-06 00:59:20.225705: Current learning rate: 0.00868
2024-07-06 01:00:25.555522: Validation loss did not improve from -0.81309. Patience: 27/50
2024-07-06 01:00:25.557851: train_loss -0.7676
2024-07-06 01:00:25.560196: val_loss -0.7936
2024-07-06 01:00:25.562041: Pseudo dice [0.972, 0.8922]
2024-07-06 01:00:25.563229: Epoch time: 65.34 s
2024-07-06 01:00:26.797339: 
2024-07-06 01:00:26.799401: Epoch 147
2024-07-06 01:00:26.800810: Current learning rate: 0.00867
2024-07-06 01:01:32.150885: Validation loss did not improve from -0.81309. Patience: 28/50
2024-07-06 01:01:32.152536: train_loss -0.7921
2024-07-06 01:01:32.153758: val_loss -0.8119
2024-07-06 01:01:32.154942: Pseudo dice [0.9726, 0.8985]
2024-07-06 01:01:32.156253: Epoch time: 65.36 s
2024-07-06 01:01:33.392658: 
2024-07-06 01:01:33.394981: Epoch 148
2024-07-06 01:01:33.396214: Current learning rate: 0.00866
2024-07-06 01:02:38.697679: Validation loss did not improve from -0.81309. Patience: 29/50
2024-07-06 01:02:38.699469: train_loss -0.7957
2024-07-06 01:02:38.700918: val_loss -0.8123
2024-07-06 01:02:38.702074: Pseudo dice [0.9734, 0.8936]
2024-07-06 01:02:38.703272: Epoch time: 65.31 s
2024-07-06 01:02:39.912885: 
2024-07-06 01:02:39.915210: Epoch 149
2024-07-06 01:02:39.916349: Current learning rate: 0.00865
2024-07-06 01:03:45.237549: Validation loss did not improve from -0.81309. Patience: 30/50
2024-07-06 01:03:45.239924: train_loss -0.7894
2024-07-06 01:03:45.241979: val_loss -0.8004
2024-07-06 01:03:45.243720: Pseudo dice [0.9733, 0.8857]
2024-07-06 01:03:45.245338: Epoch time: 65.33 s
2024-07-06 01:03:47.106755: 
2024-07-06 01:03:47.109003: Epoch 150
2024-07-06 01:03:47.110700: Current learning rate: 0.00864
2024-07-06 01:04:52.498961: Validation loss did not improve from -0.81309. Patience: 31/50
2024-07-06 01:04:52.500602: train_loss -0.7881
2024-07-06 01:04:52.502143: val_loss -0.8115
2024-07-06 01:04:52.503249: Pseudo dice [0.9746, 0.8929]
2024-07-06 01:04:52.504525: Epoch time: 65.39 s
2024-07-06 01:04:53.761416: 
2024-07-06 01:04:53.810536: Epoch 151
2024-07-06 01:04:53.812979: Current learning rate: 0.00863
2024-07-06 01:05:59.211796: Validation loss did not improve from -0.81309. Patience: 32/50
2024-07-06 01:05:59.213401: train_loss -0.7638
2024-07-06 01:05:59.214720: val_loss -0.7976
2024-07-06 01:05:59.215627: Pseudo dice [0.9685, 0.8914]
2024-07-06 01:05:59.216814: Epoch time: 65.45 s
2024-07-06 01:06:00.473614: 
2024-07-06 01:06:00.475675: Epoch 152
2024-07-06 01:06:00.476702: Current learning rate: 0.00862
2024-07-06 01:07:06.348057: Validation loss did not improve from -0.81309. Patience: 33/50
2024-07-06 01:07:06.349953: train_loss -0.7843
2024-07-06 01:07:06.351387: val_loss -0.7956
2024-07-06 01:07:06.352840: Pseudo dice [0.9722, 0.8913]
2024-07-06 01:07:06.354073: Epoch time: 65.88 s
2024-07-06 01:07:07.606533: 
2024-07-06 01:07:07.609382: Epoch 153
2024-07-06 01:07:07.610675: Current learning rate: 0.00861
2024-07-06 01:08:13.033347: Validation loss did not improve from -0.81309. Patience: 34/50
2024-07-06 01:08:13.035184: train_loss -0.7806
2024-07-06 01:08:13.036640: val_loss -0.7745
2024-07-06 01:08:13.038025: Pseudo dice [0.9716, 0.888]
2024-07-06 01:08:13.039102: Epoch time: 65.43 s
2024-07-06 01:08:14.308453: 
2024-07-06 01:08:14.361175: Epoch 154
2024-07-06 01:08:14.362795: Current learning rate: 0.0086
2024-07-06 01:09:19.895349: Validation loss did not improve from -0.81309. Patience: 35/50
2024-07-06 01:09:19.897068: train_loss -0.7847
2024-07-06 01:09:19.898427: val_loss -0.7952
2024-07-06 01:09:19.899470: Pseudo dice [0.974, 0.8958]
2024-07-06 01:09:19.900532: Epoch time: 65.59 s
2024-07-06 01:09:21.531138: 
2024-07-06 01:09:21.533623: Epoch 155
2024-07-06 01:09:21.534979: Current learning rate: 0.00859
2024-07-06 01:10:26.709361: Validation loss did not improve from -0.81309. Patience: 36/50
2024-07-06 01:10:26.711990: train_loss -0.7875
2024-07-06 01:10:26.714050: val_loss -0.801
2024-07-06 01:10:26.715507: Pseudo dice [0.9716, 0.8932]
2024-07-06 01:10:26.716834: Epoch time: 65.18 s
2024-07-06 01:10:27.996749: 
2024-07-06 01:10:27.999105: Epoch 156
2024-07-06 01:10:28.000911: Current learning rate: 0.00858
2024-07-06 01:11:33.367112: Validation loss did not improve from -0.81309. Patience: 37/50
2024-07-06 01:11:33.409013: train_loss -0.7858
2024-07-06 01:11:33.410701: val_loss -0.8095
2024-07-06 01:11:33.411832: Pseudo dice [0.973, 0.8967]
2024-07-06 01:11:33.412802: Epoch time: 65.37 s
2024-07-06 01:11:34.848389: 
2024-07-06 01:11:34.850400: Epoch 157
2024-07-06 01:11:34.852062: Current learning rate: 0.00858
2024-07-06 01:12:39.996029: Validation loss did not improve from -0.81309. Patience: 38/50
2024-07-06 01:12:39.997673: train_loss -0.7687
2024-07-06 01:12:39.999705: val_loss -0.7941
2024-07-06 01:12:40.001123: Pseudo dice [0.974, 0.8946]
2024-07-06 01:12:40.002144: Epoch time: 65.15 s
2024-07-06 01:12:41.272731: 
2024-07-06 01:12:41.275203: Epoch 158
2024-07-06 01:12:41.276521: Current learning rate: 0.00857
2024-07-06 01:13:46.366894: Validation loss did not improve from -0.81309. Patience: 39/50
2024-07-06 01:13:46.369083: train_loss -0.7819
2024-07-06 01:13:46.371290: val_loss -0.8048
2024-07-06 01:13:46.373379: Pseudo dice [0.9718, 0.8924]
2024-07-06 01:13:46.374784: Epoch time: 65.1 s
2024-07-06 01:13:47.641906: 
2024-07-06 01:13:47.644827: Epoch 159
2024-07-06 01:13:47.646569: Current learning rate: 0.00856
2024-07-06 01:14:52.937838: Validation loss did not improve from -0.81309. Patience: 40/50
2024-07-06 01:14:52.939986: train_loss -0.774
2024-07-06 01:14:52.941351: val_loss -0.8058
2024-07-06 01:14:52.942869: Pseudo dice [0.9733, 0.8897]
2024-07-06 01:14:52.945001: Epoch time: 65.3 s
2024-07-06 01:14:54.525404: 
2024-07-06 01:14:54.527376: Epoch 160
2024-07-06 01:14:54.528893: Current learning rate: 0.00855
2024-07-06 01:15:59.699544: Validation loss did not improve from -0.81309. Patience: 41/50
2024-07-06 01:15:59.701111: train_loss -0.7821
2024-07-06 01:15:59.702481: val_loss -0.7857
2024-07-06 01:15:59.703416: Pseudo dice [0.9729, 0.8864]
2024-07-06 01:15:59.704696: Epoch time: 65.18 s
2024-07-06 01:16:00.979905: 
2024-07-06 01:16:00.981968: Epoch 161
2024-07-06 01:16:00.983278: Current learning rate: 0.00854
2024-07-06 01:17:05.985414: Validation loss did not improve from -0.81309. Patience: 42/50
2024-07-06 01:17:05.986952: train_loss -0.7759
2024-07-06 01:17:05.988171: val_loss -0.7911
2024-07-06 01:17:05.989134: Pseudo dice [0.973, 0.8925]
2024-07-06 01:17:05.990129: Epoch time: 65.01 s
2024-07-06 01:17:07.836292: 
2024-07-06 01:17:07.838959: Epoch 162
2024-07-06 01:17:07.840537: Current learning rate: 0.00853
2024-07-06 01:18:12.842374: Validation loss did not improve from -0.81309. Patience: 43/50
2024-07-06 01:18:12.844862: train_loss -0.7815
2024-07-06 01:18:12.846688: val_loss -0.807
2024-07-06 01:18:12.847872: Pseudo dice [0.9733, 0.89]
2024-07-06 01:18:12.848982: Epoch time: 65.01 s
2024-07-06 01:18:14.105644: 
2024-07-06 01:18:14.107468: Epoch 163
2024-07-06 01:18:14.108440: Current learning rate: 0.00852
2024-07-06 01:19:19.038476: Validation loss did not improve from -0.81309. Patience: 44/50
2024-07-06 01:19:19.040186: train_loss -0.7881
2024-07-06 01:19:19.041782: val_loss -0.8123
2024-07-06 01:19:19.043226: Pseudo dice [0.976, 0.8971]
2024-07-06 01:19:19.044670: Epoch time: 64.94 s
2024-07-06 01:19:19.046079: Yayy! New best EMA pseudo Dice: 0.932
2024-07-06 01:19:20.605033: 
2024-07-06 01:19:20.608047: Epoch 164
2024-07-06 01:19:20.610082: Current learning rate: 0.00851
2024-07-06 01:20:25.601441: Validation loss improved from -0.81309 to -0.81323! Patience: 44/50
2024-07-06 01:20:25.603062: train_loss -0.7927
2024-07-06 01:20:25.604203: val_loss -0.8132
2024-07-06 01:20:25.605237: Pseudo dice [0.9741, 0.8992]
2024-07-06 01:20:25.606619: Epoch time: 65.0 s
2024-07-06 01:20:25.948661: Yayy! New best EMA pseudo Dice: 0.9325
2024-07-06 01:20:28.727749: 
2024-07-06 01:20:28.729809: Epoch 165
2024-07-06 01:20:28.730906: Current learning rate: 0.0085
2024-07-06 01:21:34.103068: Validation loss did not improve from -0.81323. Patience: 1/50
2024-07-06 01:21:34.104931: train_loss -0.7858
2024-07-06 01:21:34.107085: val_loss -0.7924
2024-07-06 01:21:34.109035: Pseudo dice [0.9751, 0.8881]
2024-07-06 01:21:34.110419: Epoch time: 65.38 s
2024-07-06 01:21:35.353889: 
2024-07-06 01:21:35.356602: Epoch 166
2024-07-06 01:21:35.358567: Current learning rate: 0.00849
2024-07-06 01:22:40.777532: Validation loss did not improve from -0.81323. Patience: 2/50
2024-07-06 01:22:40.779105: train_loss -0.7899
2024-07-06 01:22:40.780887: val_loss -0.8113
2024-07-06 01:22:40.782900: Pseudo dice [0.9775, 0.8936]
2024-07-06 01:22:40.784161: Epoch time: 65.43 s
2024-07-06 01:22:40.785255: Yayy! New best EMA pseudo Dice: 0.9327
2024-07-06 01:22:42.330949: 
2024-07-06 01:22:42.332978: Epoch 167
2024-07-06 01:22:42.334046: Current learning rate: 0.00848
2024-07-06 01:23:47.290946: Validation loss did not improve from -0.81323. Patience: 3/50
2024-07-06 01:23:47.292500: train_loss -0.7809
2024-07-06 01:23:47.293707: val_loss -0.8043
2024-07-06 01:23:47.294599: Pseudo dice [0.9726, 0.8944]
2024-07-06 01:23:47.295667: Epoch time: 64.96 s
2024-07-06 01:23:47.296551: Yayy! New best EMA pseudo Dice: 0.9328
2024-07-06 01:23:48.862664: 
2024-07-06 01:23:48.865448: Epoch 168
2024-07-06 01:23:48.867224: Current learning rate: 0.00847
2024-07-06 01:24:53.841295: Validation loss did not improve from -0.81323. Patience: 4/50
2024-07-06 01:24:53.843168: train_loss -0.7636
2024-07-06 01:24:53.845670: val_loss -0.7429
2024-07-06 01:24:53.847182: Pseudo dice [0.9541, 0.8758]
2024-07-06 01:24:53.848549: Epoch time: 64.98 s
2024-07-06 01:24:55.112941: 
2024-07-06 01:24:55.115139: Epoch 169
2024-07-06 01:24:55.116655: Current learning rate: 0.00847
2024-07-06 01:26:00.295601: Validation loss did not improve from -0.81323. Patience: 5/50
2024-07-06 01:26:00.296999: train_loss -0.7453
2024-07-06 01:26:00.298872: val_loss -0.7882
2024-07-06 01:26:00.300289: Pseudo dice [0.9705, 0.8894]
2024-07-06 01:26:00.301424: Epoch time: 65.19 s
2024-07-06 01:26:01.888679: 
2024-07-06 01:26:01.891641: Epoch 170
2024-07-06 01:26:01.893412: Current learning rate: 0.00846
2024-07-06 01:27:07.020520: Validation loss did not improve from -0.81323. Patience: 6/50
2024-07-06 01:27:07.022354: train_loss -0.7538
2024-07-06 01:27:07.023800: val_loss -0.7927
2024-07-06 01:27:07.025529: Pseudo dice [0.9698, 0.8876]
2024-07-06 01:27:07.027838: Epoch time: 65.13 s
2024-07-06 01:27:08.278410: 
2024-07-06 01:27:08.280825: Epoch 171
2024-07-06 01:27:08.282115: Current learning rate: 0.00845
2024-07-06 01:28:14.398794: Validation loss did not improve from -0.81323. Patience: 7/50
2024-07-06 01:28:14.400407: train_loss -0.775
2024-07-06 01:28:14.405162: val_loss -0.8085
2024-07-06 01:28:14.406525: Pseudo dice [0.9763, 0.8938]
2024-07-06 01:28:14.409414: Epoch time: 66.12 s
2024-07-06 01:28:15.747392: 
2024-07-06 01:28:15.750818: Epoch 172
2024-07-06 01:28:15.752674: Current learning rate: 0.00844
2024-07-06 01:29:21.898973: Validation loss did not improve from -0.81323. Patience: 8/50
2024-07-06 01:29:21.901936: train_loss -0.7897
2024-07-06 01:29:21.904288: val_loss -0.8108
2024-07-06 01:29:21.906154: Pseudo dice [0.9745, 0.897]
2024-07-06 01:29:21.907399: Epoch time: 66.16 s
2024-07-06 01:29:23.356850: 
2024-07-06 01:29:23.359659: Epoch 173
2024-07-06 01:29:23.361180: Current learning rate: 0.00843
2024-07-06 01:30:28.699781: Validation loss did not improve from -0.81323. Patience: 9/50
2024-07-06 01:30:28.701760: train_loss -0.7814
2024-07-06 01:30:28.703365: val_loss -0.8065
2024-07-06 01:30:28.704614: Pseudo dice [0.9731, 0.8971]
2024-07-06 01:30:28.706096: Epoch time: 65.35 s
2024-07-06 01:30:31.450252: 
2024-07-06 01:30:31.453244: Epoch 174
2024-07-06 01:30:31.455012: Current learning rate: 0.00842
2024-07-06 01:31:37.420702: Validation loss did not improve from -0.81323. Patience: 10/50
2024-07-06 01:31:37.422355: train_loss -0.7923
2024-07-06 01:31:37.424535: val_loss -0.791
2024-07-06 01:31:37.426340: Pseudo dice [0.9702, 0.8933]
2024-07-06 01:31:37.427581: Epoch time: 65.97 s
2024-07-06 01:31:39.254766: 
2024-07-06 01:31:39.257558: Epoch 175
2024-07-06 01:31:39.259248: Current learning rate: 0.00841
2024-07-06 01:32:47.777968: Validation loss did not improve from -0.81323. Patience: 11/50
2024-07-06 01:32:47.835770: train_loss -0.7809
2024-07-06 01:32:47.837757: val_loss -0.8077
2024-07-06 01:32:47.839251: Pseudo dice [0.9726, 0.8989]
2024-07-06 01:32:47.840570: Epoch time: 68.55 s
2024-07-06 01:32:49.667607: 
2024-07-06 01:32:49.670108: Epoch 176
2024-07-06 01:32:49.671528: Current learning rate: 0.0084
2024-07-06 01:33:55.491799: Validation loss did not improve from -0.81323. Patience: 12/50
2024-07-06 01:33:55.494050: train_loss -0.7914
2024-07-06 01:33:55.495684: val_loss -0.804
2024-07-06 01:33:55.496866: Pseudo dice [0.9713, 0.8968]
2024-07-06 01:33:55.498095: Epoch time: 65.83 s
2024-07-06 01:33:56.821436: 
2024-07-06 01:33:56.823871: Epoch 177
2024-07-06 01:33:56.825511: Current learning rate: 0.00839
2024-07-06 01:35:02.267384: Validation loss did not improve from -0.81323. Patience: 13/50
2024-07-06 01:35:02.269098: train_loss -0.7906
2024-07-06 01:35:02.270298: val_loss -0.8039
2024-07-06 01:35:02.271497: Pseudo dice [0.9748, 0.8914]
2024-07-06 01:35:02.272852: Epoch time: 65.45 s
2024-07-06 01:35:03.501001: 
2024-07-06 01:35:03.503767: Epoch 178
2024-07-06 01:35:03.505242: Current learning rate: 0.00838
2024-07-06 01:36:08.510499: Validation loss did not improve from -0.81323. Patience: 14/50
2024-07-06 01:36:08.512470: train_loss -0.7978
2024-07-06 01:36:08.514457: val_loss -0.8113
2024-07-06 01:36:08.515741: Pseudo dice [0.9758, 0.8972]
2024-07-06 01:36:08.516833: Epoch time: 65.01 s
2024-07-06 01:36:08.517907: Yayy! New best EMA pseudo Dice: 0.9329
2024-07-06 01:36:10.690679: 
2024-07-06 01:36:10.692649: Epoch 179
2024-07-06 01:36:10.693820: Current learning rate: 0.00837
2024-07-06 01:37:16.440148: Validation loss improved from -0.81323 to -0.81701! Patience: 14/50
2024-07-06 01:37:16.441835: train_loss -0.7935
2024-07-06 01:37:16.444319: val_loss -0.817
2024-07-06 01:37:16.446452: Pseudo dice [0.9745, 0.8849]
2024-07-06 01:37:16.448040: Epoch time: 65.75 s
2024-07-06 01:37:18.042597: 
2024-07-06 01:37:18.045571: Epoch 180
2024-07-06 01:37:18.047341: Current learning rate: 0.00836
2024-07-06 01:38:23.075830: Validation loss did not improve from -0.81701. Patience: 1/50
2024-07-06 01:38:23.078380: train_loss -0.785
2024-07-06 01:38:23.080668: val_loss -0.779
2024-07-06 01:38:23.082868: Pseudo dice [0.968, 0.8841]
2024-07-06 01:38:23.085007: Epoch time: 65.04 s
2024-07-06 01:38:24.350831: 
2024-07-06 01:38:24.353430: Epoch 181
2024-07-06 01:38:24.354786: Current learning rate: 0.00836
2024-07-06 01:39:29.452147: Validation loss did not improve from -0.81701. Patience: 2/50
2024-07-06 01:39:29.454153: train_loss -0.7899
2024-07-06 01:39:29.456198: val_loss -0.8151
2024-07-06 01:39:29.457684: Pseudo dice [0.9742, 0.8954]
2024-07-06 01:39:29.458882: Epoch time: 65.1 s
2024-07-06 01:39:30.699303: 
2024-07-06 01:39:30.701583: Epoch 182
2024-07-06 01:39:30.702975: Current learning rate: 0.00835
2024-07-06 01:40:35.860031: Validation loss did not improve from -0.81701. Patience: 3/50
2024-07-06 01:40:35.875807: train_loss -0.8004
2024-07-06 01:40:35.877412: val_loss -0.8095
2024-07-06 01:40:35.878397: Pseudo dice [0.9736, 0.9001]
2024-07-06 01:40:35.879540: Epoch time: 65.18 s
2024-07-06 01:40:37.133993: 
2024-07-06 01:40:37.136851: Epoch 183
2024-07-06 01:40:37.139091: Current learning rate: 0.00834
2024-07-06 01:41:42.305213: Validation loss did not improve from -0.81701. Patience: 4/50
2024-07-06 01:41:42.307365: train_loss -0.7889
2024-07-06 01:41:42.308827: val_loss -0.7974
2024-07-06 01:41:42.309908: Pseudo dice [0.9727, 0.8847]
2024-07-06 01:41:42.310789: Epoch time: 65.17 s
2024-07-06 01:41:43.556874: 
2024-07-06 01:41:43.558961: Epoch 184
2024-07-06 01:41:43.560710: Current learning rate: 0.00833
2024-07-06 01:42:48.809697: Validation loss did not improve from -0.81701. Patience: 5/50
2024-07-06 01:42:48.811518: train_loss -0.7959
2024-07-06 01:42:48.813087: val_loss -0.8054
2024-07-06 01:42:48.814514: Pseudo dice [0.9722, 0.8981]
2024-07-06 01:42:48.815708: Epoch time: 65.26 s
2024-07-06 01:42:50.454180: 
2024-07-06 01:42:50.456836: Epoch 185
2024-07-06 01:42:50.458710: Current learning rate: 0.00832
2024-07-06 01:43:55.886037: Validation loss did not improve from -0.81701. Patience: 6/50
2024-07-06 01:43:55.888013: train_loss -0.7916
2024-07-06 01:43:55.889678: val_loss -0.8126
2024-07-06 01:43:55.891222: Pseudo dice [0.9753, 0.9016]
2024-07-06 01:43:55.892761: Epoch time: 65.44 s
2024-07-06 01:43:55.894137: Yayy! New best EMA pseudo Dice: 0.9332
2024-07-06 01:43:59.647669: 
2024-07-06 01:43:59.650151: Epoch 186
2024-07-06 01:43:59.651726: Current learning rate: 0.00831
2024-07-06 01:45:04.994361: Validation loss did not improve from -0.81701. Patience: 7/50
2024-07-06 01:45:04.996169: train_loss -0.7936
2024-07-06 01:45:04.998324: val_loss -0.8156
2024-07-06 01:45:04.999966: Pseudo dice [0.9762, 0.8983]
2024-07-06 01:45:05.001115: Epoch time: 65.35 s
2024-07-06 01:45:05.002065: Yayy! New best EMA pseudo Dice: 0.9336
2024-07-06 01:45:06.550576: 
2024-07-06 01:45:06.552875: Epoch 187
2024-07-06 01:45:06.554121: Current learning rate: 0.0083
2024-07-06 01:46:11.750775: Validation loss did not improve from -0.81701. Patience: 8/50
2024-07-06 01:46:11.752716: train_loss -0.7893
2024-07-06 01:46:11.754745: val_loss -0.8021
2024-07-06 01:46:11.756037: Pseudo dice [0.9754, 0.8914]
2024-07-06 01:46:11.757356: Epoch time: 65.2 s
2024-07-06 01:46:13.024570: 
2024-07-06 01:46:13.027080: Epoch 188
2024-07-06 01:46:13.028563: Current learning rate: 0.00829
2024-07-06 01:47:18.274786: Validation loss did not improve from -0.81701. Patience: 9/50
2024-07-06 01:47:18.276561: train_loss -0.7931
2024-07-06 01:47:18.277979: val_loss -0.8142
2024-07-06 01:47:18.279225: Pseudo dice [0.972, 0.9004]
2024-07-06 01:47:18.280482: Epoch time: 65.25 s
2024-07-06 01:47:18.281740: Yayy! New best EMA pseudo Dice: 0.9338
2024-07-06 01:47:19.857875: 
2024-07-06 01:47:19.860596: Epoch 189
2024-07-06 01:47:19.862557: Current learning rate: 0.00828
2024-07-06 01:48:25.124746: Validation loss did not improve from -0.81701. Patience: 10/50
2024-07-06 01:48:25.127033: train_loss -0.7838
2024-07-06 01:48:25.129529: val_loss -0.8115
2024-07-06 01:48:25.131471: Pseudo dice [0.973, 0.8978]
2024-07-06 01:48:25.132670: Epoch time: 65.27 s
2024-07-06 01:48:25.473004: Yayy! New best EMA pseudo Dice: 0.934
2024-07-06 01:48:26.990487: 
2024-07-06 01:48:26.993198: Epoch 190
2024-07-06 01:48:26.994927: Current learning rate: 0.00827
2024-07-06 01:49:32.227819: Validation loss did not improve from -0.81701. Patience: 11/50
2024-07-06 01:49:32.229516: train_loss -0.7873
2024-07-06 01:49:32.230755: val_loss -0.7856
2024-07-06 01:49:32.232109: Pseudo dice [0.9719, 0.8953]
2024-07-06 01:49:32.233100: Epoch time: 65.24 s
2024-07-06 01:49:33.492951: 
2024-07-06 01:49:33.495776: Epoch 191
2024-07-06 01:49:33.497932: Current learning rate: 0.00826
2024-07-06 01:50:38.841567: Validation loss did not improve from -0.81701. Patience: 12/50
2024-07-06 01:50:38.843073: train_loss -0.7708
2024-07-06 01:50:38.844408: val_loss -0.8028
2024-07-06 01:50:38.845875: Pseudo dice [0.9725, 0.8965]
2024-07-06 01:50:38.847029: Epoch time: 65.35 s
2024-07-06 01:50:38.848064: Yayy! New best EMA pseudo Dice: 0.934
2024-07-06 01:50:40.449931: 
2024-07-06 01:50:40.452294: Epoch 192
2024-07-06 01:50:40.453835: Current learning rate: 0.00825
2024-07-06 01:51:45.610310: Validation loss did not improve from -0.81701. Patience: 13/50
2024-07-06 01:51:45.612254: train_loss -0.7782
2024-07-06 01:51:45.613448: val_loss -0.8031
2024-07-06 01:51:45.614441: Pseudo dice [0.9744, 0.8873]
2024-07-06 01:51:45.615642: Epoch time: 65.16 s
2024-07-06 01:51:46.894706: 
2024-07-06 01:51:46.896812: Epoch 193
2024-07-06 01:51:46.898331: Current learning rate: 0.00824
2024-07-06 01:52:52.054507: Validation loss did not improve from -0.81701. Patience: 14/50
2024-07-06 01:52:52.057495: train_loss -0.7921
2024-07-06 01:52:52.059582: val_loss -0.8023
2024-07-06 01:52:52.060902: Pseudo dice [0.9747, 0.8991]
2024-07-06 01:52:52.062284: Epoch time: 65.16 s
2024-07-06 01:52:52.063405: Yayy! New best EMA pseudo Dice: 0.934
2024-07-06 01:52:53.659218: 
2024-07-06 01:52:53.660911: Epoch 194
2024-07-06 01:52:53.662216: Current learning rate: 0.00824
2024-07-06 01:53:58.692940: Validation loss did not improve from -0.81701. Patience: 15/50
2024-07-06 01:53:58.694495: train_loss -0.7932
2024-07-06 01:53:58.696140: val_loss -0.8037
2024-07-06 01:53:58.697513: Pseudo dice [0.9726, 0.9009]
2024-07-06 01:53:58.699403: Epoch time: 65.04 s
2024-07-06 01:53:59.042440: Yayy! New best EMA pseudo Dice: 0.9343
2024-07-06 01:54:00.596785: 
2024-07-06 01:54:00.599485: Epoch 195
2024-07-06 01:54:00.600809: Current learning rate: 0.00823
2024-07-06 01:55:05.637906: Validation loss did not improve from -0.81701. Patience: 16/50
2024-07-06 01:55:05.639630: train_loss -0.7686
2024-07-06 01:55:05.641473: val_loss -0.7879
2024-07-06 01:55:05.643265: Pseudo dice [0.9687, 0.8905]
2024-07-06 01:55:05.644834: Epoch time: 65.04 s
2024-07-06 01:55:06.911336: 
2024-07-06 01:55:06.913891: Epoch 196
2024-07-06 01:55:06.915179: Current learning rate: 0.00822
2024-07-06 01:56:11.983993: Validation loss did not improve from -0.81701. Patience: 17/50
2024-07-06 01:56:11.985881: train_loss -0.7846
2024-07-06 01:56:11.987447: val_loss -0.8103
2024-07-06 01:56:11.989107: Pseudo dice [0.9738, 0.8973]
2024-07-06 01:56:11.990634: Epoch time: 65.08 s
2024-07-06 01:56:13.663392: 
2024-07-06 01:56:13.665309: Epoch 197
2024-07-06 01:56:13.666680: Current learning rate: 0.00821
2024-07-06 01:57:18.695075: Validation loss did not improve from -0.81701. Patience: 18/50
2024-07-06 01:57:18.696599: train_loss -0.7949
2024-07-06 01:57:18.698018: val_loss -0.7954
2024-07-06 01:57:18.699280: Pseudo dice [0.9722, 0.8878]
2024-07-06 01:57:18.700527: Epoch time: 65.03 s
2024-07-06 01:57:19.974048: 
2024-07-06 01:57:19.977036: Epoch 198
2024-07-06 01:57:19.978695: Current learning rate: 0.0082
2024-07-06 01:58:25.017741: Validation loss did not improve from -0.81701. Patience: 19/50
2024-07-06 01:58:25.019997: train_loss -0.7895
2024-07-06 01:58:25.022428: val_loss -0.7867
2024-07-06 01:58:25.024046: Pseudo dice [0.9665, 0.8897]
2024-07-06 01:58:25.025172: Epoch time: 65.05 s
2024-07-06 01:58:26.300320: 
2024-07-06 01:58:26.302319: Epoch 199
2024-07-06 01:58:26.303597: Current learning rate: 0.00819
2024-07-06 01:59:31.348682: Validation loss did not improve from -0.81701. Patience: 20/50
2024-07-06 01:59:31.350272: train_loss -0.77
2024-07-06 01:59:31.351791: val_loss -0.8008
2024-07-06 01:59:31.353393: Pseudo dice [0.9757, 0.8975]
2024-07-06 01:59:31.354701: Epoch time: 65.05 s
2024-07-06 01:59:32.934836: 
2024-07-06 01:59:32.937862: Epoch 200
2024-07-06 01:59:32.939256: Current learning rate: 0.00818
2024-07-06 02:00:37.837701: Validation loss did not improve from -0.81701. Patience: 21/50
2024-07-06 02:00:37.839723: train_loss -0.7794
2024-07-06 02:00:37.841671: val_loss -0.8162
2024-07-06 02:00:37.843196: Pseudo dice [0.9766, 0.8938]
2024-07-06 02:00:37.844536: Epoch time: 64.91 s
2024-07-06 02:00:39.131762: 
2024-07-06 02:00:39.134323: Epoch 201
2024-07-06 02:00:39.135774: Current learning rate: 0.00817
2024-07-06 02:01:44.067666: Validation loss did not improve from -0.81701. Patience: 22/50
2024-07-06 02:01:44.069467: train_loss -0.7876
2024-07-06 02:01:44.071417: val_loss -0.7868
2024-07-06 02:01:44.073127: Pseudo dice [0.9755, 0.8948]
2024-07-06 02:01:44.074698: Epoch time: 64.94 s
2024-07-06 02:01:45.367036: 
2024-07-06 02:01:45.369636: Epoch 202
2024-07-06 02:01:45.371340: Current learning rate: 0.00816
2024-07-06 02:02:50.304283: Validation loss improved from -0.81701 to -0.81844! Patience: 22/50
2024-07-06 02:02:50.306551: train_loss -0.7814
2024-07-06 02:02:50.308522: val_loss -0.8184
2024-07-06 02:02:50.309901: Pseudo dice [0.976, 0.9011]
2024-07-06 02:02:50.310913: Epoch time: 64.94 s
2024-07-06 02:02:51.584594: 
2024-07-06 02:02:51.587361: Epoch 203
2024-07-06 02:02:51.589048: Current learning rate: 0.00815
2024-07-06 02:03:56.490763: Validation loss did not improve from -0.81844. Patience: 1/50
2024-07-06 02:03:56.492572: train_loss -0.7893
2024-07-06 02:03:56.494484: val_loss -0.8092
2024-07-06 02:03:56.496544: Pseudo dice [0.9728, 0.8988]
2024-07-06 02:03:56.498491: Epoch time: 64.91 s
2024-07-06 02:03:56.499778: Yayy! New best EMA pseudo Dice: 0.9344
2024-07-06 02:03:58.114701: 
2024-07-06 02:03:58.117164: Epoch 204
2024-07-06 02:03:58.118623: Current learning rate: 0.00814
2024-07-06 02:05:03.012362: Validation loss did not improve from -0.81844. Patience: 2/50
2024-07-06 02:05:03.014892: train_loss -0.7989
2024-07-06 02:05:03.016877: val_loss -0.8137
2024-07-06 02:05:03.018208: Pseudo dice [0.9736, 0.9019]
2024-07-06 02:05:03.019528: Epoch time: 64.9 s
2024-07-06 02:05:03.366651: Yayy! New best EMA pseudo Dice: 0.9347
2024-07-06 02:05:04.959233: 
2024-07-06 02:05:04.962324: Epoch 205
2024-07-06 02:05:04.964164: Current learning rate: 0.00813
2024-07-06 02:06:09.866005: Validation loss did not improve from -0.81844. Patience: 3/50
2024-07-06 02:06:09.867739: train_loss -0.7979
2024-07-06 02:06:09.869346: val_loss -0.7905
2024-07-06 02:06:09.870532: Pseudo dice [0.9716, 0.8942]
2024-07-06 02:06:09.871808: Epoch time: 64.91 s
2024-07-06 02:06:11.069929: 
2024-07-06 02:06:11.072621: Epoch 206
2024-07-06 02:06:11.074460: Current learning rate: 0.00813
2024-07-06 02:07:15.976637: Validation loss did not improve from -0.81844. Patience: 4/50
2024-07-06 02:07:15.978413: train_loss -0.7933
2024-07-06 02:07:15.979778: val_loss -0.7947
2024-07-06 02:07:15.981557: Pseudo dice [0.9742, 0.8903]
2024-07-06 02:07:15.983142: Epoch time: 64.91 s
2024-07-06 02:07:17.181118: 
2024-07-06 02:07:17.183203: Epoch 207
2024-07-06 02:07:17.184771: Current learning rate: 0.00812
2024-07-06 02:08:22.108403: Validation loss did not improve from -0.81844. Patience: 5/50
2024-07-06 02:08:22.110232: train_loss -0.7878
2024-07-06 02:08:22.112018: val_loss -0.8113
2024-07-06 02:08:22.114368: Pseudo dice [0.9756, 0.9051]
2024-07-06 02:08:22.115702: Epoch time: 64.93 s
2024-07-06 02:08:22.116979: Yayy! New best EMA pseudo Dice: 0.9349
2024-07-06 02:08:23.644164: 
2024-07-06 02:08:23.646252: Epoch 208
2024-07-06 02:08:23.647472: Current learning rate: 0.00811
2024-07-06 02:09:28.641021: Validation loss improved from -0.81844 to -0.82071! Patience: 5/50
2024-07-06 02:09:28.643532: train_loss -0.7984
2024-07-06 02:09:28.645653: val_loss -0.8207
2024-07-06 02:09:28.647478: Pseudo dice [0.9778, 0.9009]
2024-07-06 02:09:28.649946: Epoch time: 65.0 s
2024-07-06 02:09:28.651602: Yayy! New best EMA pseudo Dice: 0.9354
2024-07-06 02:09:30.509221: 
2024-07-06 02:09:30.511747: Epoch 209
2024-07-06 02:09:30.513564: Current learning rate: 0.0081
2024-07-06 02:10:35.512688: Validation loss did not improve from -0.82071. Patience: 1/50
2024-07-06 02:10:35.515489: train_loss -0.7973
2024-07-06 02:10:35.517329: val_loss -0.8177
2024-07-06 02:10:35.518348: Pseudo dice [0.9746, 0.902]
2024-07-06 02:10:35.519255: Epoch time: 65.01 s
2024-07-06 02:10:35.859093: Yayy! New best EMA pseudo Dice: 0.9356
2024-07-06 02:10:37.376990: 
2024-07-06 02:10:37.378543: Epoch 210
2024-07-06 02:10:37.379875: Current learning rate: 0.00809
2024-07-06 02:11:42.550843: Validation loss did not improve from -0.82071. Patience: 2/50
2024-07-06 02:11:42.552981: train_loss -0.7814
2024-07-06 02:11:42.555324: val_loss -0.8151
2024-07-06 02:11:42.556868: Pseudo dice [0.9752, 0.9002]
2024-07-06 02:11:42.558387: Epoch time: 65.18 s
2024-07-06 02:11:42.559501: Yayy! New best EMA pseudo Dice: 0.9359
2024-07-06 02:11:44.127126: 
2024-07-06 02:11:44.129939: Epoch 211
2024-07-06 02:11:44.131681: Current learning rate: 0.00808
2024-07-06 02:12:49.192606: Validation loss did not improve from -0.82071. Patience: 3/50
2024-07-06 02:12:49.194560: train_loss -0.7768
2024-07-06 02:12:49.196385: val_loss -0.7701
2024-07-06 02:12:49.197860: Pseudo dice [0.9651, 0.8898]
2024-07-06 02:12:49.199155: Epoch time: 65.07 s
2024-07-06 02:12:50.397505: 
2024-07-06 02:12:50.400088: Epoch 212
2024-07-06 02:12:50.401588: Current learning rate: 0.00807
2024-07-06 02:13:55.448915: Validation loss did not improve from -0.82071. Patience: 4/50
2024-07-06 02:13:55.450536: train_loss -0.7691
2024-07-06 02:13:55.452069: val_loss -0.7852
2024-07-06 02:13:55.453220: Pseudo dice [0.9714, 0.894]
2024-07-06 02:13:55.455017: Epoch time: 65.05 s
2024-07-06 02:13:56.659040: 
2024-07-06 02:13:56.662004: Epoch 213
2024-07-06 02:13:56.663769: Current learning rate: 0.00806
2024-07-06 02:15:01.722523: Validation loss did not improve from -0.82071. Patience: 5/50
2024-07-06 02:15:01.724305: train_loss -0.7732
2024-07-06 02:15:01.726602: val_loss -0.8027
2024-07-06 02:15:01.728934: Pseudo dice [0.9747, 0.8958]
2024-07-06 02:15:01.730547: Epoch time: 65.07 s
2024-07-06 02:15:02.935477: 
2024-07-06 02:15:02.937530: Epoch 214
2024-07-06 02:15:02.938601: Current learning rate: 0.00805
2024-07-06 02:16:08.009386: Validation loss did not improve from -0.82071. Patience: 6/50
2024-07-06 02:16:08.011240: train_loss -0.7747
2024-07-06 02:16:08.012616: val_loss -0.7992
2024-07-06 02:16:08.014256: Pseudo dice [0.9719, 0.8909]
2024-07-06 02:16:08.016383: Epoch time: 65.08 s
2024-07-06 02:16:09.535185: 
2024-07-06 02:16:09.537854: Epoch 215
2024-07-06 02:16:09.539227: Current learning rate: 0.00804
2024-07-06 02:17:14.969065: Validation loss did not improve from -0.82071. Patience: 7/50
2024-07-06 02:17:14.975973: train_loss -0.7877
2024-07-06 02:17:14.978193: val_loss -0.8032
2024-07-06 02:17:14.979402: Pseudo dice [0.973, 0.8962]
2024-07-06 02:17:14.980479: Epoch time: 65.44 s
2024-07-06 02:17:16.215072: 
2024-07-06 02:17:16.216988: Epoch 216
2024-07-06 02:17:16.218331: Current learning rate: 0.00803
2024-07-06 02:18:21.445573: Validation loss did not improve from -0.82071. Patience: 8/50
2024-07-06 02:18:21.447780: train_loss -0.7803
2024-07-06 02:18:21.449757: val_loss -0.8061
2024-07-06 02:18:21.450823: Pseudo dice [0.9746, 0.894]
2024-07-06 02:18:21.452034: Epoch time: 65.23 s
2024-07-06 02:18:22.689170: 
2024-07-06 02:18:22.691711: Epoch 217
2024-07-06 02:18:22.693304: Current learning rate: 0.00802
2024-07-06 02:19:27.893611: Validation loss did not improve from -0.82071. Patience: 9/50
2024-07-06 02:19:27.895100: train_loss -0.7968
2024-07-06 02:19:27.896298: val_loss -0.8035
2024-07-06 02:19:27.897308: Pseudo dice [0.972, 0.8985]
2024-07-06 02:19:27.898348: Epoch time: 65.21 s
2024-07-06 02:19:29.099369: 
2024-07-06 02:19:29.101239: Epoch 218
2024-07-06 02:19:29.102464: Current learning rate: 0.00801
2024-07-06 02:20:34.266700: Validation loss did not improve from -0.82071. Patience: 10/50
2024-07-06 02:20:34.268766: train_loss -0.7871
2024-07-06 02:20:34.270717: val_loss -0.817
2024-07-06 02:20:34.272192: Pseudo dice [0.9745, 0.9025]
2024-07-06 02:20:34.273926: Epoch time: 65.17 s
2024-07-06 02:20:35.471023: 
2024-07-06 02:20:35.473877: Epoch 219
2024-07-06 02:20:35.475338: Current learning rate: 0.00801
2024-07-06 02:21:40.654884: Validation loss improved from -0.82071 to -0.82437! Patience: 10/50
2024-07-06 02:21:40.656612: train_loss -0.7945
2024-07-06 02:21:40.658298: val_loss -0.8244
2024-07-06 02:21:40.659535: Pseudo dice [0.9751, 0.9039]
2024-07-06 02:21:40.660516: Epoch time: 65.19 s
2024-07-06 02:21:42.185611: 
2024-07-06 02:21:42.187627: Epoch 220
2024-07-06 02:21:42.188856: Current learning rate: 0.008
2024-07-06 02:22:47.358620: Validation loss did not improve from -0.82437. Patience: 1/50
2024-07-06 02:22:47.360089: train_loss -0.7898
2024-07-06 02:22:47.361484: val_loss -0.8007
2024-07-06 02:22:47.363038: Pseudo dice [0.9744, 0.8934]
2024-07-06 02:22:47.364235: Epoch time: 65.18 s
2024-07-06 02:22:49.345381: 
2024-07-06 02:22:49.348269: Epoch 221
2024-07-06 02:22:49.350247: Current learning rate: 0.00799
2024-07-06 02:23:54.566785: Validation loss did not improve from -0.82437. Patience: 2/50
2024-07-06 02:23:54.568579: train_loss -0.7977
2024-07-06 02:23:54.570121: val_loss -0.8203
2024-07-06 02:23:54.571271: Pseudo dice [0.9752, 0.9012]
2024-07-06 02:23:54.572447: Epoch time: 65.22 s
2024-07-06 02:23:55.759572: 
2024-07-06 02:23:55.761672: Epoch 222
2024-07-06 02:23:55.762953: Current learning rate: 0.00798
2024-07-06 02:25:00.963930: Validation loss did not improve from -0.82437. Patience: 3/50
2024-07-06 02:25:00.965570: train_loss -0.7883
2024-07-06 02:25:00.967093: val_loss -0.7954
2024-07-06 02:25:00.968488: Pseudo dice [0.9702, 0.896]
2024-07-06 02:25:00.969707: Epoch time: 65.21 s
2024-07-06 02:25:02.174905: 
2024-07-06 02:25:02.176720: Epoch 223
2024-07-06 02:25:02.177904: Current learning rate: 0.00797
2024-07-06 02:26:07.434849: Validation loss did not improve from -0.82437. Patience: 4/50
2024-07-06 02:26:07.436536: train_loss -0.7907
2024-07-06 02:26:07.438853: val_loss -0.8018
2024-07-06 02:26:07.440962: Pseudo dice [0.9749, 0.8896]
2024-07-06 02:26:07.442356: Epoch time: 65.26 s
2024-07-06 02:26:08.648969: 
2024-07-06 02:26:08.651615: Epoch 224
2024-07-06 02:26:08.652889: Current learning rate: 0.00796
2024-07-06 02:27:13.858680: Validation loss did not improve from -0.82437. Patience: 5/50
2024-07-06 02:27:13.860612: train_loss -0.7611
2024-07-06 02:27:13.863146: val_loss -0.6794
2024-07-06 02:27:13.865408: Pseudo dice [0.9545, 0.8315]
2024-07-06 02:27:13.866927: Epoch time: 65.21 s
2024-07-06 02:27:15.346554: 
2024-07-06 02:27:15.349288: Epoch 225
2024-07-06 02:27:15.351046: Current learning rate: 0.00795
2024-07-06 02:28:20.395675: Validation loss did not improve from -0.82437. Patience: 6/50
2024-07-06 02:28:20.397902: train_loss -0.6377
2024-07-06 02:28:20.400401: val_loss -0.7299
2024-07-06 02:28:20.401913: Pseudo dice [0.9599, 0.8587]
2024-07-06 02:28:20.403215: Epoch time: 65.05 s
2024-07-06 02:28:21.559652: 
2024-07-06 02:28:21.561668: Epoch 226
2024-07-06 02:28:21.562763: Current learning rate: 0.00794
2024-07-06 02:29:26.522391: Validation loss did not improve from -0.82437. Patience: 7/50
2024-07-06 02:29:26.524071: train_loss -0.7109
2024-07-06 02:29:26.525674: val_loss -0.7626
2024-07-06 02:29:26.526945: Pseudo dice [0.9707, 0.8765]
2024-07-06 02:29:26.528275: Epoch time: 64.97 s
2024-07-06 02:29:27.706413: 
2024-07-06 02:29:27.708702: Epoch 227
2024-07-06 02:29:27.710443: Current learning rate: 0.00793
2024-07-06 02:30:32.548510: Validation loss did not improve from -0.82437. Patience: 8/50
2024-07-06 02:30:32.552201: train_loss -0.7471
2024-07-06 02:30:32.554117: val_loss -0.7673
2024-07-06 02:30:32.555190: Pseudo dice [0.9665, 0.8819]
2024-07-06 02:30:32.556216: Epoch time: 64.85 s
2024-07-06 02:30:33.743520: 
2024-07-06 02:30:33.746283: Epoch 228
2024-07-06 02:30:33.747641: Current learning rate: 0.00792
2024-07-06 02:31:38.675129: Validation loss did not improve from -0.82437. Patience: 9/50
2024-07-06 02:31:38.676647: train_loss -0.7548
2024-07-06 02:31:38.677945: val_loss -0.7689
2024-07-06 02:31:38.678919: Pseudo dice [0.9707, 0.8785]
2024-07-06 02:31:38.679869: Epoch time: 64.93 s
2024-07-06 02:31:39.865162: 
2024-07-06 02:31:39.867648: Epoch 229
2024-07-06 02:31:39.869317: Current learning rate: 0.00791
2024-07-06 02:32:45.357595: Validation loss did not improve from -0.82437. Patience: 10/50
2024-07-06 02:32:45.359729: train_loss -0.764
2024-07-06 02:32:45.361429: val_loss -0.7965
2024-07-06 02:32:45.362478: Pseudo dice [0.972, 0.8941]
2024-07-06 02:32:45.363525: Epoch time: 65.5 s
2024-07-06 02:32:46.887167: 
2024-07-06 02:32:46.889743: Epoch 230
2024-07-06 02:32:46.891140: Current learning rate: 0.0079
2024-07-06 02:33:52.098538: Validation loss did not improve from -0.82437. Patience: 11/50
2024-07-06 02:33:52.100130: train_loss -0.77
2024-07-06 02:33:52.103044: val_loss -0.7927
2024-07-06 02:33:52.104715: Pseudo dice [0.9715, 0.8943]
2024-07-06 02:33:52.106521: Epoch time: 65.21 s
2024-07-06 02:33:53.529216: 
2024-07-06 02:33:53.530935: Epoch 231
2024-07-06 02:33:53.532081: Current learning rate: 0.00789
2024-07-06 02:34:59.358783: Validation loss did not improve from -0.82437. Patience: 12/50
2024-07-06 02:34:59.361363: train_loss -0.7785
2024-07-06 02:34:59.363172: val_loss -0.7944
2024-07-06 02:34:59.364971: Pseudo dice [0.9727, 0.8987]
2024-07-06 02:34:59.366559: Epoch time: 65.83 s
2024-07-06 02:35:00.710077: 
2024-07-06 02:35:00.712023: Epoch 232
2024-07-06 02:35:00.713019: Current learning rate: 0.00789
2024-07-06 02:36:05.940709: Validation loss did not improve from -0.82437. Patience: 13/50
2024-07-06 02:36:05.942977: train_loss -0.7778
2024-07-06 02:36:05.944640: val_loss -0.7757
2024-07-06 02:36:05.945808: Pseudo dice [0.9719, 0.8869]
2024-07-06 02:36:05.946784: Epoch time: 65.23 s
2024-07-06 02:36:07.235590: 
2024-07-06 02:36:07.238118: Epoch 233
2024-07-06 02:36:07.239550: Current learning rate: 0.00788
2024-07-06 02:37:12.289919: Validation loss did not improve from -0.82437. Patience: 14/50
2024-07-06 02:37:12.291476: train_loss -0.76
2024-07-06 02:37:12.293124: val_loss -0.7878
2024-07-06 02:37:12.294696: Pseudo dice [0.9716, 0.8874]
2024-07-06 02:37:12.295954: Epoch time: 65.06 s
2024-07-06 02:37:15.326235: 
2024-07-06 02:37:15.329517: Epoch 234
2024-07-06 02:37:15.331504: Current learning rate: 0.00787
2024-07-06 02:38:22.175743: Validation loss did not improve from -0.82437. Patience: 15/50
2024-07-06 02:38:22.201696: train_loss -0.778
2024-07-06 02:38:22.203893: val_loss -0.7801
2024-07-06 02:38:22.205281: Pseudo dice [0.9717, 0.8928]
2024-07-06 02:38:22.206719: Epoch time: 66.85 s
2024-07-06 02:38:24.239657: 
2024-07-06 02:38:24.242081: Epoch 235
2024-07-06 02:38:24.244207: Current learning rate: 0.00786
2024-07-06 02:39:29.182332: Validation loss did not improve from -0.82437. Patience: 16/50
2024-07-06 02:39:29.184467: train_loss -0.7813
2024-07-06 02:39:29.185783: val_loss -0.8085
2024-07-06 02:39:29.186847: Pseudo dice [0.9727, 0.9044]
2024-07-06 02:39:29.188093: Epoch time: 64.95 s
2024-07-06 02:39:30.465586: 
2024-07-06 02:39:30.467607: Epoch 236
2024-07-06 02:39:30.469187: Current learning rate: 0.00785
2024-07-06 02:40:35.424148: Validation loss did not improve from -0.82437. Patience: 17/50
2024-07-06 02:40:35.425752: train_loss -0.7799
2024-07-06 02:40:35.427209: val_loss -0.8022
2024-07-06 02:40:35.428273: Pseudo dice [0.9736, 0.8975]
2024-07-06 02:40:35.429322: Epoch time: 64.96 s
2024-07-06 02:40:36.627506: 
2024-07-06 02:40:36.629458: Epoch 237
2024-07-06 02:40:36.630595: Current learning rate: 0.00784
2024-07-06 02:41:41.608298: Validation loss did not improve from -0.82437. Patience: 18/50
2024-07-06 02:41:41.610131: train_loss -0.7907
2024-07-06 02:41:41.611697: val_loss -0.8059
2024-07-06 02:41:41.613117: Pseudo dice [0.9756, 0.8946]
2024-07-06 02:41:41.614514: Epoch time: 64.98 s
2024-07-06 02:41:42.802040: 
2024-07-06 02:41:42.804549: Epoch 238
2024-07-06 02:41:42.806436: Current learning rate: 0.00783
2024-07-06 02:42:47.845133: Validation loss did not improve from -0.82437. Patience: 19/50
2024-07-06 02:42:47.846719: train_loss -0.7829
2024-07-06 02:42:47.848004: val_loss -0.7998
2024-07-06 02:42:47.849202: Pseudo dice [0.9735, 0.8917]
2024-07-06 02:42:47.850284: Epoch time: 65.05 s
2024-07-06 02:42:49.051050: 
2024-07-06 02:42:49.053604: Epoch 239
2024-07-06 02:42:49.054924: Current learning rate: 0.00782
2024-07-06 02:43:54.109671: Validation loss did not improve from -0.82437. Patience: 20/50
2024-07-06 02:43:54.111138: train_loss -0.774
2024-07-06 02:43:54.112450: val_loss -0.7937
2024-07-06 02:43:54.113486: Pseudo dice [0.9689, 0.8881]
2024-07-06 02:43:54.114558: Epoch time: 65.06 s
2024-07-06 02:43:55.614276: 
2024-07-06 02:43:55.617122: Epoch 240
2024-07-06 02:43:55.619902: Current learning rate: 0.00781
2024-07-06 02:45:00.679776: Validation loss did not improve from -0.82437. Patience: 21/50
2024-07-06 02:45:00.681226: train_loss -0.782
2024-07-06 02:45:00.682554: val_loss -0.788
2024-07-06 02:45:00.683826: Pseudo dice [0.9732, 0.8956]
2024-07-06 02:45:00.685004: Epoch time: 65.07 s
2024-07-06 02:45:01.894250: 
2024-07-06 02:45:01.896651: Epoch 241
2024-07-06 02:45:01.897960: Current learning rate: 0.0078
2024-07-06 02:46:07.117100: Validation loss did not improve from -0.82437. Patience: 22/50
2024-07-06 02:46:07.118662: train_loss -0.7816
2024-07-06 02:46:07.120012: val_loss -0.7777
2024-07-06 02:46:07.121086: Pseudo dice [0.9742, 0.8719]
2024-07-06 02:46:07.122136: Epoch time: 65.23 s
2024-07-06 02:46:08.324359: 
2024-07-06 02:46:08.327340: Epoch 242
2024-07-06 02:46:08.328937: Current learning rate: 0.00779
2024-07-06 02:47:13.509855: Validation loss did not improve from -0.82437. Patience: 23/50
2024-07-06 02:47:13.511362: train_loss -0.7947
2024-07-06 02:47:13.512701: val_loss -0.8009
2024-07-06 02:47:13.513903: Pseudo dice [0.9729, 0.8903]
2024-07-06 02:47:13.515159: Epoch time: 65.19 s
2024-07-06 02:47:14.725531: 
2024-07-06 02:47:14.728276: Epoch 243
2024-07-06 02:47:14.729871: Current learning rate: 0.00778
2024-07-06 02:48:19.997082: Validation loss did not improve from -0.82437. Patience: 24/50
2024-07-06 02:48:19.998765: train_loss -0.7919
2024-07-06 02:48:19.999933: val_loss -0.8058
2024-07-06 02:48:20.000993: Pseudo dice [0.9751, 0.8963]
2024-07-06 02:48:20.001957: Epoch time: 65.27 s
2024-07-06 02:48:21.228493: 
2024-07-06 02:48:21.230487: Epoch 244
2024-07-06 02:48:21.231452: Current learning rate: 0.00777
2024-07-06 02:49:26.425086: Validation loss did not improve from -0.82437. Patience: 25/50
2024-07-06 02:49:26.426852: train_loss -0.7929
2024-07-06 02:49:26.428847: val_loss -0.7944
2024-07-06 02:49:26.430977: Pseudo dice [0.9695, 0.8895]
2024-07-06 02:49:26.432512: Epoch time: 65.2 s
2024-07-06 02:49:27.915092: 
2024-07-06 02:49:27.918255: Epoch 245
2024-07-06 02:49:27.919771: Current learning rate: 0.00777
2024-07-06 02:50:33.073215: Validation loss did not improve from -0.82437. Patience: 26/50
2024-07-06 02:50:33.075114: train_loss -0.7895
2024-07-06 02:50:33.076379: val_loss -0.812
2024-07-06 02:50:33.077344: Pseudo dice [0.9713, 0.9027]
2024-07-06 02:50:33.078322: Epoch time: 65.16 s
2024-07-06 02:50:34.274501: 
2024-07-06 02:50:34.277362: Epoch 246
2024-07-06 02:50:34.279001: Current learning rate: 0.00776
2024-07-06 02:51:39.422719: Validation loss did not improve from -0.82437. Patience: 27/50
2024-07-06 02:51:39.424476: train_loss -0.7899
2024-07-06 02:51:39.425857: val_loss -0.8082
2024-07-06 02:51:39.427005: Pseudo dice [0.9727, 0.9002]
2024-07-06 02:51:39.428155: Epoch time: 65.15 s
2024-07-06 02:51:41.504531: 
2024-07-06 02:51:41.507208: Epoch 247
2024-07-06 02:51:41.509191: Current learning rate: 0.00775
2024-07-06 02:52:46.631971: Validation loss improved from -0.82437 to -0.82594! Patience: 27/50
2024-07-06 02:52:46.633776: train_loss -0.787
2024-07-06 02:52:46.635356: val_loss -0.8259
2024-07-06 02:52:46.636451: Pseudo dice [0.9751, 0.8994]
2024-07-06 02:52:46.637671: Epoch time: 65.13 s
2024-07-06 02:52:47.846852: 
2024-07-06 02:52:47.849598: Epoch 248
2024-07-06 02:52:47.850691: Current learning rate: 0.00774
2024-07-06 02:53:53.054204: Validation loss did not improve from -0.82594. Patience: 1/50
2024-07-06 02:53:53.056124: train_loss -0.7974
2024-07-06 02:53:53.057499: val_loss -0.8154
2024-07-06 02:53:53.058411: Pseudo dice [0.9741, 0.9019]
2024-07-06 02:53:53.059297: Epoch time: 65.21 s
2024-07-06 02:53:54.263914: 
2024-07-06 02:53:54.265970: Epoch 249
2024-07-06 02:53:54.267419: Current learning rate: 0.00773
2024-07-06 02:54:59.560894: Validation loss did not improve from -0.82594. Patience: 2/50
2024-07-06 02:54:59.562222: train_loss -0.8009
2024-07-06 02:54:59.563974: val_loss -0.8175
2024-07-06 02:54:59.565438: Pseudo dice [0.9759, 0.9018]
2024-07-06 02:54:59.566707: Epoch time: 65.3 s
2024-07-06 02:55:01.161528: 
2024-07-06 02:55:01.163925: Epoch 250
2024-07-06 02:55:01.165695: Current learning rate: 0.00772
2024-07-06 02:56:06.526031: Validation loss did not improve from -0.82594. Patience: 3/50
2024-07-06 02:56:06.527599: train_loss -0.7897
2024-07-06 02:56:06.529041: val_loss -0.8126
2024-07-06 02:56:06.530256: Pseudo dice [0.9739, 0.8938]
2024-07-06 02:56:06.531258: Epoch time: 65.37 s
2024-07-06 02:56:07.761361: 
2024-07-06 02:56:07.763901: Epoch 251
2024-07-06 02:56:07.765282: Current learning rate: 0.00771
2024-07-06 02:57:13.106195: Validation loss did not improve from -0.82594. Patience: 4/50
2024-07-06 02:57:13.107859: train_loss -0.7837
2024-07-06 02:57:13.109895: val_loss -0.8114
2024-07-06 02:57:13.112211: Pseudo dice [0.9736, 0.8984]
2024-07-06 02:57:13.114035: Epoch time: 65.35 s
2024-07-06 02:57:14.342307: 
2024-07-06 02:57:14.344702: Epoch 252
2024-07-06 02:57:14.345782: Current learning rate: 0.0077
2024-07-06 02:58:19.632666: Validation loss did not improve from -0.82594. Patience: 5/50
2024-07-06 02:58:19.634652: train_loss -0.7936
2024-07-06 02:58:19.637163: val_loss -0.8201
2024-07-06 02:58:19.639090: Pseudo dice [0.9784, 0.9064]
2024-07-06 02:58:19.640459: Epoch time: 65.29 s
2024-07-06 02:58:20.868047: 
2024-07-06 02:58:20.870441: Epoch 253
2024-07-06 02:58:20.871955: Current learning rate: 0.00769
2024-07-06 02:59:26.192150: Validation loss did not improve from -0.82594. Patience: 6/50
2024-07-06 02:59:26.193815: train_loss -0.7829
2024-07-06 02:59:26.195065: val_loss -0.8025
2024-07-06 02:59:26.196182: Pseudo dice [0.9711, 0.8841]
2024-07-06 02:59:26.197178: Epoch time: 65.33 s
2024-07-06 02:59:27.410537: 
2024-07-06 02:59:27.412957: Epoch 254
2024-07-06 02:59:27.414400: Current learning rate: 0.00768
2024-07-06 03:00:32.669922: Validation loss did not improve from -0.82594. Patience: 7/50
2024-07-06 03:00:32.672139: train_loss -0.7943
2024-07-06 03:00:32.674982: val_loss -0.8061
2024-07-06 03:00:32.677140: Pseudo dice [0.9756, 0.9055]
2024-07-06 03:00:32.678330: Epoch time: 65.26 s
2024-07-06 03:00:34.207826: 
2024-07-06 03:00:34.210659: Epoch 255
2024-07-06 03:00:34.212593: Current learning rate: 0.00767
2024-07-06 03:01:39.502492: Validation loss did not improve from -0.82594. Patience: 8/50
2024-07-06 03:01:39.504162: train_loss -0.7961
2024-07-06 03:01:39.505691: val_loss -0.8113
2024-07-06 03:01:39.506809: Pseudo dice [0.9741, 0.905]
2024-07-06 03:01:39.508151: Epoch time: 65.3 s
2024-07-06 03:01:40.722031: 
2024-07-06 03:01:40.724864: Epoch 256
2024-07-06 03:01:40.726150: Current learning rate: 0.00766
2024-07-06 03:02:45.969734: Validation loss did not improve from -0.82594. Patience: 9/50
2024-07-06 03:02:45.971132: train_loss -0.8024
2024-07-06 03:02:45.972597: val_loss -0.8247
2024-07-06 03:02:45.973708: Pseudo dice [0.9765, 0.907]
2024-07-06 03:02:45.975211: Epoch time: 65.25 s
2024-07-06 03:02:45.976146: Yayy! New best EMA pseudo Dice: 0.9359
2024-07-06 03:02:47.466495: 
2024-07-06 03:02:47.468926: Epoch 257
2024-07-06 03:02:47.470000: Current learning rate: 0.00765
2024-07-06 03:03:52.735174: Validation loss did not improve from -0.82594. Patience: 10/50
2024-07-06 03:03:52.737196: train_loss -0.8004
2024-07-06 03:03:52.739523: val_loss -0.8223
2024-07-06 03:03:52.740944: Pseudo dice [0.9759, 0.9051]
2024-07-06 03:03:52.742036: Epoch time: 65.27 s
2024-07-06 03:03:52.743014: Yayy! New best EMA pseudo Dice: 0.9363
2024-07-06 03:03:54.296095: 
2024-07-06 03:03:54.298624: Epoch 258
2024-07-06 03:03:54.300028: Current learning rate: 0.00764
2024-07-06 03:04:59.521528: Validation loss did not improve from -0.82594. Patience: 11/50
2024-07-06 03:04:59.523524: train_loss -0.8038
2024-07-06 03:04:59.525469: val_loss -0.795
2024-07-06 03:04:59.526547: Pseudo dice [0.972, 0.898]
2024-07-06 03:04:59.527619: Epoch time: 65.23 s
2024-07-06 03:05:01.126660: 
2024-07-06 03:05:01.128588: Epoch 259
2024-07-06 03:05:01.129778: Current learning rate: 0.00764
2024-07-06 03:06:06.440231: Validation loss did not improve from -0.82594. Patience: 12/50
2024-07-06 03:06:06.442119: train_loss -0.812
2024-07-06 03:06:06.443673: val_loss -0.8112
2024-07-06 03:06:06.444969: Pseudo dice [0.9729, 0.9006]
2024-07-06 03:06:06.446387: Epoch time: 65.32 s
2024-07-06 03:06:07.968811: 
2024-07-06 03:06:07.970622: Epoch 260
2024-07-06 03:06:07.972046: Current learning rate: 0.00763
2024-07-06 03:07:13.188397: Validation loss did not improve from -0.82594. Patience: 13/50
2024-07-06 03:07:13.190041: train_loss -0.7977
2024-07-06 03:07:13.251724: val_loss -0.8075
2024-07-06 03:07:13.253613: Pseudo dice [0.973, 0.9005]
2024-07-06 03:07:13.254973: Epoch time: 65.22 s
2024-07-06 03:07:14.459460: 
2024-07-06 03:07:14.461397: Epoch 261
2024-07-06 03:07:14.463059: Current learning rate: 0.00762
2024-07-06 03:08:19.754200: Validation loss did not improve from -0.82594. Patience: 14/50
2024-07-06 03:08:19.756129: train_loss -0.7576
2024-07-06 03:08:19.758625: val_loss -0.7525
2024-07-06 03:08:19.760229: Pseudo dice [0.9601, 0.8819]
2024-07-06 03:08:19.761425: Epoch time: 65.3 s
2024-07-06 03:08:20.980596: 
2024-07-06 03:08:20.982683: Epoch 262
2024-07-06 03:08:20.983753: Current learning rate: 0.00761
2024-07-06 03:09:26.291886: Validation loss did not improve from -0.82594. Patience: 15/50
2024-07-06 03:09:26.293525: train_loss -0.7187
2024-07-06 03:09:26.294731: val_loss -0.7461
2024-07-06 03:09:26.295812: Pseudo dice [0.9649, 0.8764]
2024-07-06 03:09:26.296999: Epoch time: 65.31 s
2024-07-06 03:09:27.528620: 
2024-07-06 03:09:27.530205: Epoch 263
2024-07-06 03:09:27.531832: Current learning rate: 0.0076
2024-07-06 03:10:32.775378: Validation loss did not improve from -0.82594. Patience: 16/50
2024-07-06 03:10:32.777129: train_loss -0.7403
2024-07-06 03:10:32.778249: val_loss -0.7857
2024-07-06 03:10:32.779354: Pseudo dice [0.9691, 0.8916]
2024-07-06 03:10:32.780353: Epoch time: 65.25 s
2024-07-06 03:10:33.993357: 
2024-07-06 03:10:33.995547: Epoch 264
2024-07-06 03:10:33.996794: Current learning rate: 0.00759
2024-07-06 03:11:39.108400: Validation loss did not improve from -0.82594. Patience: 17/50
2024-07-06 03:11:39.110622: train_loss -0.7581
2024-07-06 03:11:39.112456: val_loss -0.7849
2024-07-06 03:11:39.113610: Pseudo dice [0.9691, 0.8882]
2024-07-06 03:11:39.114870: Epoch time: 65.12 s
2024-07-06 03:11:40.688513: 
2024-07-06 03:11:40.691000: Epoch 265
2024-07-06 03:11:40.692355: Current learning rate: 0.00758
2024-07-06 03:12:45.726230: Validation loss did not improve from -0.82594. Patience: 18/50
2024-07-06 03:12:45.727882: train_loss -0.7832
2024-07-06 03:12:45.729268: val_loss -0.8024
2024-07-06 03:12:45.730273: Pseudo dice [0.973, 0.8965]
2024-07-06 03:12:45.731460: Epoch time: 65.04 s
2024-07-06 03:12:46.954318: 
2024-07-06 03:12:46.956742: Epoch 266
2024-07-06 03:12:46.958217: Current learning rate: 0.00757
2024-07-06 03:13:51.991997: Validation loss did not improve from -0.82594. Patience: 19/50
2024-07-06 03:13:51.993848: train_loss -0.7844
2024-07-06 03:13:51.995597: val_loss -0.8128
2024-07-06 03:13:51.996838: Pseudo dice [0.9754, 0.9015]
2024-07-06 03:13:51.998172: Epoch time: 65.04 s
2024-07-06 03:13:53.229054: 
2024-07-06 03:13:53.231663: Epoch 267
2024-07-06 03:13:53.233528: Current learning rate: 0.00756
2024-07-06 03:14:58.263387: Validation loss did not improve from -0.82594. Patience: 20/50
2024-07-06 03:14:58.265638: train_loss -0.7961
2024-07-06 03:14:58.267815: val_loss -0.8068
2024-07-06 03:14:58.268821: Pseudo dice [0.9717, 0.8998]
2024-07-06 03:14:58.269987: Epoch time: 65.04 s
2024-07-06 03:14:59.489155: 
2024-07-06 03:14:59.491652: Epoch 268
2024-07-06 03:14:59.493214: Current learning rate: 0.00755
2024-07-06 03:16:04.485173: Validation loss did not improve from -0.82594. Patience: 21/50
2024-07-06 03:16:04.487510: train_loss -0.7971
2024-07-06 03:16:04.489013: val_loss -0.8176
2024-07-06 03:16:04.490876: Pseudo dice [0.9749, 0.9029]
2024-07-06 03:16:04.492847: Epoch time: 65.0 s
2024-07-06 03:16:05.717443: 
2024-07-06 03:16:05.719991: Epoch 269
2024-07-06 03:16:05.721016: Current learning rate: 0.00754
2024-07-06 03:17:11.091743: Validation loss did not improve from -0.82594. Patience: 22/50
2024-07-06 03:17:11.093344: train_loss -0.7935
2024-07-06 03:17:11.094831: val_loss -0.8169
2024-07-06 03:17:11.096014: Pseudo dice [0.9757, 0.9003]
2024-07-06 03:17:11.097240: Epoch time: 65.38 s
2024-07-06 03:17:12.645969: 
2024-07-06 03:17:12.649452: Epoch 270
2024-07-06 03:17:12.651098: Current learning rate: 0.00753
2024-07-06 03:18:17.613747: Validation loss did not improve from -0.82594. Patience: 23/50
2024-07-06 03:18:17.615786: train_loss -0.7922
2024-07-06 03:18:17.617436: val_loss -0.8047
2024-07-06 03:18:17.618580: Pseudo dice [0.9768, 0.9008]
2024-07-06 03:18:17.619595: Epoch time: 64.97 s
2024-07-06 03:18:18.877895: 
2024-07-06 03:18:18.880300: Epoch 271
2024-07-06 03:18:18.881759: Current learning rate: 0.00752
2024-07-06 03:19:23.901023: Validation loss did not improve from -0.82594. Patience: 24/50
2024-07-06 03:19:23.902973: train_loss -0.7961
2024-07-06 03:19:23.905614: val_loss -0.8109
2024-07-06 03:19:23.907399: Pseudo dice [0.9733, 0.8962]
2024-07-06 03:19:23.908662: Epoch time: 65.03 s
2024-07-06 03:19:25.646767: 
2024-07-06 03:19:25.649692: Epoch 272
2024-07-06 03:19:25.651351: Current learning rate: 0.00751
2024-07-06 03:20:30.794997: Validation loss did not improve from -0.82594. Patience: 25/50
2024-07-06 03:20:30.796733: train_loss -0.7872
2024-07-06 03:20:30.798257: val_loss -0.7995
2024-07-06 03:20:30.799537: Pseudo dice [0.9703, 0.8975]
2024-07-06 03:20:30.800785: Epoch time: 65.15 s
2024-07-06 03:20:32.019674: 
2024-07-06 03:20:32.022247: Epoch 273
2024-07-06 03:20:32.023498: Current learning rate: 0.00751
2024-07-06 03:21:37.555658: Validation loss did not improve from -0.82594. Patience: 26/50
2024-07-06 03:21:37.585637: train_loss -0.7978
2024-07-06 03:21:37.587727: val_loss -0.813
2024-07-06 03:21:37.588894: Pseudo dice [0.9732, 0.8971]
2024-07-06 03:21:37.590236: Epoch time: 65.56 s
2024-07-06 03:21:38.856745: 
2024-07-06 03:21:38.859356: Epoch 274
2024-07-06 03:21:38.860598: Current learning rate: 0.0075
2024-07-06 03:22:43.965982: Validation loss did not improve from -0.82594. Patience: 27/50
2024-07-06 03:22:43.967937: train_loss -0.8
2024-07-06 03:22:43.969676: val_loss -0.8221
2024-07-06 03:22:43.970994: Pseudo dice [0.9763, 0.9078]
2024-07-06 03:22:43.972114: Epoch time: 65.11 s
2024-07-06 03:22:45.528702: 
2024-07-06 03:22:45.531465: Epoch 275
2024-07-06 03:22:45.533362: Current learning rate: 0.00749
2024-07-06 03:23:50.585137: Validation loss did not improve from -0.82594. Patience: 28/50
2024-07-06 03:23:50.586565: train_loss -0.7966
2024-07-06 03:23:50.587926: val_loss -0.8178
2024-07-06 03:23:50.589050: Pseudo dice [0.9756, 0.9004]
2024-07-06 03:23:50.590368: Epoch time: 65.06 s
2024-07-06 03:23:51.821553: 
2024-07-06 03:23:51.823478: Epoch 276
2024-07-06 03:23:51.824926: Current learning rate: 0.00748
2024-07-06 03:24:57.050898: Validation loss did not improve from -0.82594. Patience: 29/50
2024-07-06 03:24:57.052646: train_loss -0.797
2024-07-06 03:24:57.054644: val_loss -0.8022
2024-07-06 03:24:57.056587: Pseudo dice [0.976, 0.8978]
2024-07-06 03:24:57.057804: Epoch time: 65.23 s
2024-07-06 03:24:58.282318: 
2024-07-06 03:24:58.285204: Epoch 277
2024-07-06 03:24:58.286299: Current learning rate: 0.00747
2024-07-06 03:26:03.373789: Validation loss did not improve from -0.82594. Patience: 30/50
2024-07-06 03:26:03.375599: train_loss -0.8016
2024-07-06 03:26:03.377328: val_loss -0.8066
2024-07-06 03:26:03.378654: Pseudo dice [0.9744, 0.8974]
2024-07-06 03:26:03.379912: Epoch time: 65.09 s
2024-07-06 03:26:04.587213: 
2024-07-06 03:26:04.589462: Epoch 278
2024-07-06 03:26:04.590527: Current learning rate: 0.00746
2024-07-06 03:27:09.724055: Validation loss improved from -0.82594 to -0.82712! Patience: 30/50
2024-07-06 03:27:09.725899: train_loss -0.7963
2024-07-06 03:27:09.727412: val_loss -0.8271
2024-07-06 03:27:09.728642: Pseudo dice [0.9766, 0.902]
2024-07-06 03:27:09.729785: Epoch time: 65.14 s
2024-07-06 03:27:10.956742: 
2024-07-06 03:27:10.959204: Epoch 279
2024-07-06 03:27:10.960705: Current learning rate: 0.00745
2024-07-06 03:28:16.124582: Validation loss did not improve from -0.82712. Patience: 1/50
2024-07-06 03:28:16.126017: train_loss -0.7959
2024-07-06 03:28:16.127510: val_loss -0.8094
2024-07-06 03:28:16.128751: Pseudo dice [0.9772, 0.8989]
2024-07-06 03:28:16.130083: Epoch time: 65.17 s
2024-07-06 03:28:16.479865: Yayy! New best EMA pseudo Dice: 0.9364
2024-07-06 03:28:18.222462: 
2024-07-06 03:28:18.225900: Epoch 280
2024-07-06 03:28:18.227921: Current learning rate: 0.00744
2024-07-06 03:29:24.370829: Validation loss did not improve from -0.82712. Patience: 2/50
2024-07-06 03:29:24.372499: train_loss -0.8057
2024-07-06 03:29:24.373982: val_loss -0.8114
2024-07-06 03:29:24.375075: Pseudo dice [0.9746, 0.9008]
2024-07-06 03:29:24.376458: Epoch time: 66.15 s
2024-07-06 03:29:24.377537: Yayy! New best EMA pseudo Dice: 0.9366
2024-07-06 03:29:25.934142: 
2024-07-06 03:29:25.937654: Epoch 281
2024-07-06 03:29:25.939659: Current learning rate: 0.00743
2024-07-06 03:30:31.627868: Validation loss did not improve from -0.82712. Patience: 3/50
2024-07-06 03:30:31.629355: train_loss -0.7957
2024-07-06 03:30:31.630920: val_loss -0.82
2024-07-06 03:30:31.632325: Pseudo dice [0.978, 0.9046]
2024-07-06 03:30:31.633671: Epoch time: 65.7 s
2024-07-06 03:30:31.635208: Yayy! New best EMA pseudo Dice: 0.937
2024-07-06 03:30:33.236602: 
2024-07-06 03:30:33.240258: Epoch 282
2024-07-06 03:30:33.242022: Current learning rate: 0.00742
2024-07-06 03:31:38.535959: Validation loss did not improve from -0.82712. Patience: 4/50
2024-07-06 03:31:38.537560: train_loss -0.7984
2024-07-06 03:31:38.538986: val_loss -0.8134
2024-07-06 03:31:38.540236: Pseudo dice [0.9745, 0.9012]
2024-07-06 03:31:38.541325: Epoch time: 65.3 s
2024-07-06 03:31:38.542620: Yayy! New best EMA pseudo Dice: 0.9371
2024-07-06 03:31:40.073315: 
2024-07-06 03:31:40.076073: Epoch 283
2024-07-06 03:31:40.078041: Current learning rate: 0.00741
2024-07-06 03:32:45.264274: Validation loss did not improve from -0.82712. Patience: 5/50
2024-07-06 03:32:45.266324: train_loss -0.8031
2024-07-06 03:32:45.268459: val_loss -0.8215
2024-07-06 03:32:45.270355: Pseudo dice [0.976, 0.9014]
2024-07-06 03:32:45.272128: Epoch time: 65.19 s
2024-07-06 03:32:45.273254: Yayy! New best EMA pseudo Dice: 0.9373
2024-07-06 03:32:47.371617: 
2024-07-06 03:32:47.373530: Epoch 284
2024-07-06 03:32:47.375180: Current learning rate: 0.0074
2024-07-06 03:33:53.076930: Validation loss did not improve from -0.82712. Patience: 6/50
2024-07-06 03:33:53.078718: train_loss -0.7987
2024-07-06 03:33:53.080335: val_loss -0.8232
2024-07-06 03:33:53.081645: Pseudo dice [0.9749, 0.9058]
2024-07-06 03:33:53.083053: Epoch time: 65.71 s
2024-07-06 03:33:53.435249: Yayy! New best EMA pseudo Dice: 0.9376
2024-07-06 03:33:54.979025: 
2024-07-06 03:33:54.981019: Epoch 285
2024-07-06 03:33:54.982213: Current learning rate: 0.00739
2024-07-06 03:35:00.261613: Validation loss did not improve from -0.82712. Patience: 7/50
2024-07-06 03:35:00.263174: train_loss -0.7909
2024-07-06 03:35:00.264560: val_loss -0.8056
2024-07-06 03:35:00.266083: Pseudo dice [0.9751, 0.901]
2024-07-06 03:35:00.267260: Epoch time: 65.29 s
2024-07-06 03:35:00.268551: Yayy! New best EMA pseudo Dice: 0.9376
2024-07-06 03:35:01.819726: 
2024-07-06 03:35:01.822436: Epoch 286
2024-07-06 03:35:01.824391: Current learning rate: 0.00738
2024-07-06 03:36:07.077479: Validation loss did not improve from -0.82712. Patience: 8/50
2024-07-06 03:36:07.079112: train_loss -0.8015
2024-07-06 03:36:07.080534: val_loss -0.8147
2024-07-06 03:36:07.082077: Pseudo dice [0.9734, 0.9044]
2024-07-06 03:36:07.083589: Epoch time: 65.26 s
2024-07-06 03:36:07.085094: Yayy! New best EMA pseudo Dice: 0.9378
2024-07-06 03:36:08.624399: 
2024-07-06 03:36:08.626342: Epoch 287
2024-07-06 03:36:08.627458: Current learning rate: 0.00738
2024-07-06 03:37:13.908118: Validation loss did not improve from -0.82712. Patience: 9/50
2024-07-06 03:37:13.910042: train_loss -0.7959
2024-07-06 03:37:13.911839: val_loss -0.8237
2024-07-06 03:37:13.913083: Pseudo dice [0.9792, 0.9071]
2024-07-06 03:37:13.914258: Epoch time: 65.29 s
2024-07-06 03:37:13.915300: Yayy! New best EMA pseudo Dice: 0.9383
2024-07-06 03:37:15.516668: 
2024-07-06 03:37:15.519153: Epoch 288
2024-07-06 03:37:15.520838: Current learning rate: 0.00737
2024-07-06 03:38:21.695678: Validation loss did not improve from -0.82712. Patience: 10/50
2024-07-06 03:38:21.697905: train_loss -0.7991
2024-07-06 03:38:21.770022: val_loss -0.8193
2024-07-06 03:38:21.772054: Pseudo dice [0.9755, 0.9008]
2024-07-06 03:38:21.775904: Epoch time: 66.18 s
2024-07-06 03:38:23.208317: 
2024-07-06 03:38:23.210553: Epoch 289
2024-07-06 03:38:23.212116: Current learning rate: 0.00736
2024-07-06 03:39:29.590482: Validation loss did not improve from -0.82712. Patience: 11/50
2024-07-06 03:39:29.592235: train_loss -0.8002
2024-07-06 03:39:29.593771: val_loss -0.8216
2024-07-06 03:39:29.595141: Pseudo dice [0.9785, 0.9036]
2024-07-06 03:39:29.596179: Epoch time: 66.39 s
2024-07-06 03:39:30.044392: Yayy! New best EMA pseudo Dice: 0.9386
2024-07-06 03:39:31.790671: 
2024-07-06 03:39:31.793733: Epoch 290
2024-07-06 03:39:31.795654: Current learning rate: 0.00735
2024-07-06 03:40:37.707767: Validation loss improved from -0.82712 to -0.83125! Patience: 11/50
2024-07-06 03:40:37.709905: train_loss -0.7835
2024-07-06 03:40:37.711279: val_loss -0.8313
2024-07-06 03:40:37.712608: Pseudo dice [0.9779, 0.9056]
2024-07-06 03:40:37.713843: Epoch time: 65.92 s
2024-07-06 03:40:37.715066: Yayy! New best EMA pseudo Dice: 0.9389
2024-07-06 03:40:39.769629: 
2024-07-06 03:40:39.772160: Epoch 291
2024-07-06 03:40:39.774197: Current learning rate: 0.00734
2024-07-06 03:41:45.556695: Validation loss did not improve from -0.83125. Patience: 1/50
2024-07-06 03:41:45.558673: train_loss -0.7953
2024-07-06 03:41:45.560296: val_loss -0.8064
2024-07-06 03:41:45.561735: Pseudo dice [0.9737, 0.8984]
2024-07-06 03:41:45.562770: Epoch time: 65.79 s
2024-07-06 03:41:46.948132: 
2024-07-06 03:41:46.950595: Epoch 292
2024-07-06 03:41:46.951835: Current learning rate: 0.00733
2024-07-06 03:42:55.402674: Validation loss did not improve from -0.83125. Patience: 2/50
2024-07-06 03:42:55.468471: train_loss -0.79
2024-07-06 03:42:55.471099: val_loss -0.7977
2024-07-06 03:42:55.473109: Pseudo dice [0.9713, 0.896]
2024-07-06 03:42:55.474435: Epoch time: 68.49 s
2024-07-06 03:42:57.572139: 
2024-07-06 03:42:57.575043: Epoch 293
2024-07-06 03:42:57.577280: Current learning rate: 0.00732
2024-07-06 03:44:03.139357: Validation loss did not improve from -0.83125. Patience: 3/50
2024-07-06 03:44:03.141025: train_loss -0.7792
2024-07-06 03:44:03.142933: val_loss -0.7555
2024-07-06 03:44:03.144292: Pseudo dice [0.9552, 0.8824]
2024-07-06 03:44:03.145340: Epoch time: 65.57 s
2024-07-06 03:44:04.431927: 
2024-07-06 03:44:04.434515: Epoch 294
2024-07-06 03:44:04.436466: Current learning rate: 0.00731
2024-07-06 03:45:09.658214: Validation loss did not improve from -0.83125. Patience: 4/50
2024-07-06 03:45:09.660016: train_loss -0.755
2024-07-06 03:45:09.661243: val_loss -0.7776
2024-07-06 03:45:09.662243: Pseudo dice [0.969, 0.887]
2024-07-06 03:45:09.663327: Epoch time: 65.23 s
2024-07-06 03:45:13.351220: 
2024-07-06 03:45:13.353261: Epoch 295
2024-07-06 03:45:13.354770: Current learning rate: 0.0073
2024-07-06 03:46:18.801271: Validation loss did not improve from -0.83125. Patience: 5/50
2024-07-06 03:46:18.803169: train_loss -0.7751
2024-07-06 03:46:18.804230: val_loss -0.7925
2024-07-06 03:46:18.805409: Pseudo dice [0.9701, 0.8947]
2024-07-06 03:46:18.806616: Epoch time: 65.45 s
2024-07-06 03:46:20.033509: 
2024-07-06 03:46:20.035556: Epoch 296
2024-07-06 03:46:20.037067: Current learning rate: 0.00729
2024-07-06 03:47:25.312051: Validation loss did not improve from -0.83125. Patience: 6/50
2024-07-06 03:47:25.313882: train_loss -0.7891
2024-07-06 03:47:25.315063: val_loss -0.8103
2024-07-06 03:47:25.316096: Pseudo dice [0.9731, 0.9005]
2024-07-06 03:47:25.317169: Epoch time: 65.28 s
2024-07-06 03:47:26.549327: 
2024-07-06 03:47:26.551900: Epoch 297
2024-07-06 03:47:26.553486: Current learning rate: 0.00728
2024-07-06 03:48:31.868111: Validation loss improved from -0.83125 to -0.83309! Patience: 6/50
2024-07-06 03:48:31.869759: train_loss -0.7833
2024-07-06 03:48:31.871323: val_loss -0.8331
2024-07-06 03:48:31.872575: Pseudo dice [0.9768, 0.9015]
2024-07-06 03:48:31.873837: Epoch time: 65.32 s
2024-07-06 03:48:33.115683: 
2024-07-06 03:48:33.118542: Epoch 298
2024-07-06 03:48:33.120275: Current learning rate: 0.00727
2024-07-06 03:49:38.587618: Validation loss did not improve from -0.83309. Patience: 1/50
2024-07-06 03:49:38.589440: train_loss -0.7859
2024-07-06 03:49:38.591039: val_loss -0.8046
2024-07-06 03:49:38.592341: Pseudo dice [0.9726, 0.8982]
2024-07-06 03:49:38.593656: Epoch time: 65.47 s
2024-07-06 03:49:39.838004: 
2024-07-06 03:49:39.840421: Epoch 299
2024-07-06 03:49:39.841712: Current learning rate: 0.00726
2024-07-06 03:50:45.370024: Validation loss did not improve from -0.83309. Patience: 2/50
2024-07-06 03:50:45.388409: train_loss -0.7976
2024-07-06 03:50:45.390291: val_loss -0.8087
2024-07-06 03:50:45.391388: Pseudo dice [0.9744, 0.902]
2024-07-06 03:50:45.392353: Epoch time: 65.55 s
2024-07-06 03:50:47.015363: 
2024-07-06 03:50:47.017464: Epoch 300
2024-07-06 03:50:47.019169: Current learning rate: 0.00725
2024-07-06 03:51:52.477788: Validation loss did not improve from -0.83309. Patience: 3/50
2024-07-06 03:51:52.480167: train_loss -0.7989
2024-07-06 03:51:52.482375: val_loss -0.8196
2024-07-06 03:51:52.484176: Pseudo dice [0.9782, 0.9046]
2024-07-06 03:51:52.485329: Epoch time: 65.47 s
2024-07-06 03:51:53.721975: 
2024-07-06 03:51:53.725121: Epoch 301
2024-07-06 03:51:53.726773: Current learning rate: 0.00724
2024-07-06 03:52:59.152883: Validation loss did not improve from -0.83309. Patience: 4/50
2024-07-06 03:52:59.155531: train_loss -0.8074
2024-07-06 03:52:59.157548: val_loss -0.8126
2024-07-06 03:52:59.159071: Pseudo dice [0.9799, 0.9032]
2024-07-06 03:52:59.160905: Epoch time: 65.43 s
2024-07-06 03:53:00.411557: 
2024-07-06 03:53:00.413895: Epoch 302
2024-07-06 03:53:00.415508: Current learning rate: 0.00724
2024-07-06 03:54:05.824950: Validation loss did not improve from -0.83309. Patience: 5/50
2024-07-06 03:54:05.827139: train_loss -0.7996
2024-07-06 03:54:05.828675: val_loss -0.7985
2024-07-06 03:54:05.829950: Pseudo dice [0.973, 0.8958]
2024-07-06 03:54:05.830943: Epoch time: 65.42 s
2024-07-06 03:54:07.081437: 
2024-07-06 03:54:07.084091: Epoch 303
2024-07-06 03:54:07.085494: Current learning rate: 0.00723
2024-07-06 03:55:12.435270: Validation loss did not improve from -0.83309. Patience: 6/50
2024-07-06 03:55:12.437214: train_loss -0.7198
2024-07-06 03:55:12.438438: val_loss -0.7295
2024-07-06 03:55:12.439656: Pseudo dice [0.9533, 0.8773]
2024-07-06 03:55:12.440826: Epoch time: 65.36 s
2024-07-06 03:55:13.686501: 
2024-07-06 03:55:13.689054: Epoch 304
2024-07-06 03:55:13.690504: Current learning rate: 0.00722
2024-07-06 03:56:19.089367: Validation loss did not improve from -0.83309. Patience: 7/50
2024-07-06 03:56:19.090931: train_loss -0.7348
2024-07-06 03:56:19.092154: val_loss -0.7681
2024-07-06 03:56:19.093120: Pseudo dice [0.9683, 0.8845]
2024-07-06 03:56:19.094146: Epoch time: 65.41 s
2024-07-06 03:56:20.616300: 
2024-07-06 03:56:20.619125: Epoch 305
2024-07-06 03:56:20.620794: Current learning rate: 0.00721
2024-07-06 03:57:26.175415: Validation loss did not improve from -0.83309. Patience: 8/50
2024-07-06 03:57:26.177299: train_loss -0.7615
2024-07-06 03:57:26.179096: val_loss -0.7603
2024-07-06 03:57:26.180430: Pseudo dice [0.9606, 0.8895]
2024-07-06 03:57:26.181793: Epoch time: 65.56 s
2024-07-06 03:57:27.423980: 
2024-07-06 03:57:27.426703: Epoch 306
2024-07-06 03:57:27.428520: Current learning rate: 0.0072
2024-07-06 03:58:32.664657: Validation loss did not improve from -0.83309. Patience: 9/50
2024-07-06 03:58:32.666275: train_loss -0.7673
2024-07-06 03:58:32.667464: val_loss -0.807
2024-07-06 03:58:32.668640: Pseudo dice [0.9741, 0.9006]
2024-07-06 03:58:32.669601: Epoch time: 65.24 s
2024-07-06 03:58:34.586042: 
2024-07-06 03:58:34.588804: Epoch 307
2024-07-06 03:58:34.590414: Current learning rate: 0.00719
2024-07-06 03:59:39.678329: Validation loss did not improve from -0.83309. Patience: 10/50
2024-07-06 03:59:39.679910: train_loss -0.7829
2024-07-06 03:59:39.681327: val_loss -0.8003
2024-07-06 03:59:39.682552: Pseudo dice [0.9755, 0.888]
2024-07-06 03:59:39.683852: Epoch time: 65.1 s
2024-07-06 03:59:40.936237: 
2024-07-06 03:59:40.938687: Epoch 308
2024-07-06 03:59:40.940130: Current learning rate: 0.00718
2024-07-06 04:00:46.009316: Validation loss did not improve from -0.83309. Patience: 11/50
2024-07-06 04:00:46.010983: train_loss -0.7938
2024-07-06 04:00:46.012344: val_loss -0.8107
2024-07-06 04:00:46.013572: Pseudo dice [0.9747, 0.8944]
2024-07-06 04:00:46.014934: Epoch time: 65.08 s
2024-07-06 04:00:47.245184: 
2024-07-06 04:00:47.247308: Epoch 309
2024-07-06 04:00:47.248830: Current learning rate: 0.00717
2024-07-06 04:01:52.362221: Validation loss did not improve from -0.83309. Patience: 12/50
2024-07-06 04:01:52.364159: train_loss -0.7869
2024-07-06 04:01:52.365687: val_loss -0.8052
2024-07-06 04:01:52.366832: Pseudo dice [0.9762, 0.9026]
2024-07-06 04:01:52.368241: Epoch time: 65.12 s
2024-07-06 04:01:54.024537: 
2024-07-06 04:01:54.026722: Epoch 310
2024-07-06 04:01:54.028339: Current learning rate: 0.00716
2024-07-06 04:02:59.412253: Validation loss did not improve from -0.83309. Patience: 13/50
2024-07-06 04:02:59.414425: train_loss -0.7967
2024-07-06 04:02:59.416228: val_loss -0.8143
2024-07-06 04:02:59.417255: Pseudo dice [0.9756, 0.9071]
2024-07-06 04:02:59.418505: Epoch time: 65.39 s
2024-07-06 04:03:00.666617: 
2024-07-06 04:03:00.668574: Epoch 311
2024-07-06 04:03:00.669663: Current learning rate: 0.00715
2024-07-06 04:04:06.036567: Validation loss did not improve from -0.83309. Patience: 14/50
2024-07-06 04:04:06.038496: train_loss -0.7982
2024-07-06 04:04:06.040237: val_loss -0.8183
2024-07-06 04:04:06.041209: Pseudo dice [0.9756, 0.9075]
2024-07-06 04:04:06.042307: Epoch time: 65.37 s
2024-07-06 04:04:07.283102: 
2024-07-06 04:04:07.285063: Epoch 312
2024-07-06 04:04:07.286048: Current learning rate: 0.00714
2024-07-06 04:05:12.656933: Validation loss did not improve from -0.83309. Patience: 15/50
2024-07-06 04:05:12.658594: train_loss -0.8023
2024-07-06 04:05:12.659961: val_loss -0.8268
2024-07-06 04:05:12.661224: Pseudo dice [0.9782, 0.9055]
2024-07-06 04:05:12.662548: Epoch time: 65.38 s
2024-07-06 04:05:13.912052: 
2024-07-06 04:05:13.914706: Epoch 313
2024-07-06 04:05:13.916475: Current learning rate: 0.00713
2024-07-06 04:06:19.151131: Validation loss did not improve from -0.83309. Patience: 16/50
2024-07-06 04:06:19.152808: train_loss -0.7956
2024-07-06 04:06:19.154289: val_loss -0.8091
2024-07-06 04:06:19.155276: Pseudo dice [0.972, 0.8981]
2024-07-06 04:06:19.156309: Epoch time: 65.24 s
2024-07-06 04:06:20.412689: 
2024-07-06 04:06:20.415606: Epoch 314
2024-07-06 04:06:20.417236: Current learning rate: 0.00712
2024-07-06 04:07:25.499130: Validation loss did not improve from -0.83309. Patience: 17/50
2024-07-06 04:07:25.501394: train_loss -0.801
2024-07-06 04:07:25.503403: val_loss -0.8249
2024-07-06 04:07:25.504605: Pseudo dice [0.9774, 0.9062]
2024-07-06 04:07:25.506073: Epoch time: 65.09 s
2024-07-06 04:07:27.071244: 
2024-07-06 04:07:27.073994: Epoch 315
2024-07-06 04:07:27.075462: Current learning rate: 0.00711
2024-07-06 04:08:32.402536: Validation loss did not improve from -0.83309. Patience: 18/50
2024-07-06 04:08:32.404288: train_loss -0.8044
2024-07-06 04:08:32.406015: val_loss -0.8022
2024-07-06 04:08:32.407976: Pseudo dice [0.9756, 0.8969]
2024-07-06 04:08:32.409528: Epoch time: 65.33 s
2024-07-06 04:08:33.661316: 
2024-07-06 04:08:33.664286: Epoch 316
2024-07-06 04:08:33.665917: Current learning rate: 0.0071
2024-07-06 04:09:38.902675: Validation loss did not improve from -0.83309. Patience: 19/50
2024-07-06 04:09:38.905003: train_loss -0.8058
2024-07-06 04:09:38.906922: val_loss -0.8209
2024-07-06 04:09:38.908112: Pseudo dice [0.9758, 0.9038]
2024-07-06 04:09:38.909179: Epoch time: 65.24 s
2024-07-06 04:09:40.171175: 
2024-07-06 04:09:40.174207: Epoch 317
2024-07-06 04:09:40.176403: Current learning rate: 0.0071
2024-07-06 04:10:45.461971: Validation loss did not improve from -0.83309. Patience: 20/50
2024-07-06 04:10:45.464255: train_loss -0.8058
2024-07-06 04:10:45.466313: val_loss -0.8058
2024-07-06 04:10:45.467821: Pseudo dice [0.9739, 0.8995]
2024-07-06 04:10:45.469214: Epoch time: 65.29 s
2024-07-06 04:10:46.713695: 
2024-07-06 04:10:46.716739: Epoch 318
2024-07-06 04:10:46.718681: Current learning rate: 0.00709
2024-07-06 04:11:52.262518: Validation loss did not improve from -0.83309. Patience: 21/50
2024-07-06 04:11:52.265089: train_loss -0.7963
2024-07-06 04:11:52.267117: val_loss -0.8172
2024-07-06 04:11:52.268819: Pseudo dice [0.9752, 0.8981]
2024-07-06 04:11:52.270139: Epoch time: 65.55 s
2024-07-06 04:11:54.006518: 
2024-07-06 04:11:54.009073: Epoch 319
2024-07-06 04:11:54.010715: Current learning rate: 0.00708
2024-07-06 04:12:59.471215: Validation loss did not improve from -0.83309. Patience: 22/50
2024-07-06 04:12:59.473166: train_loss -0.7366
2024-07-06 04:12:59.475224: val_loss -0.723
2024-07-06 04:12:59.476992: Pseudo dice [0.9593, 0.873]
2024-07-06 04:12:59.478111: Epoch time: 65.47 s
2024-07-06 04:13:01.078818: 
2024-07-06 04:13:01.080950: Epoch 320
2024-07-06 04:13:01.082427: Current learning rate: 0.00707
2024-07-06 04:14:06.336511: Validation loss did not improve from -0.83309. Patience: 23/50
2024-07-06 04:14:06.338630: train_loss -0.7352
2024-07-06 04:14:06.340552: val_loss -0.7813
2024-07-06 04:14:06.341775: Pseudo dice [0.9745, 0.8843]
2024-07-06 04:14:06.342926: Epoch time: 65.26 s
2024-07-06 04:14:07.610768: 
2024-07-06 04:14:07.613480: Epoch 321
2024-07-06 04:14:07.617852: Current learning rate: 0.00706
2024-07-06 04:15:12.525153: Validation loss did not improve from -0.83309. Patience: 24/50
2024-07-06 04:15:12.526734: train_loss -0.7497
2024-07-06 04:15:12.527967: val_loss -0.7938
2024-07-06 04:15:12.528930: Pseudo dice [0.9737, 0.8929]
2024-07-06 04:15:12.530026: Epoch time: 64.92 s
2024-07-06 04:15:13.760267: 
2024-07-06 04:15:13.762744: Epoch 322
2024-07-06 04:15:13.764064: Current learning rate: 0.00705
2024-07-06 04:16:18.694508: Validation loss did not improve from -0.83309. Patience: 25/50
2024-07-06 04:16:18.696323: train_loss -0.7731
2024-07-06 04:16:18.697699: val_loss -0.7848
2024-07-06 04:16:18.699121: Pseudo dice [0.9684, 0.8875]
2024-07-06 04:16:18.700414: Epoch time: 64.94 s
2024-07-06 04:16:19.989619: 
2024-07-06 04:16:19.992549: Epoch 323
2024-07-06 04:16:19.994346: Current learning rate: 0.00704
2024-07-06 04:17:24.963391: Validation loss did not improve from -0.83309. Patience: 26/50
2024-07-06 04:17:24.965257: train_loss -0.7788
2024-07-06 04:17:24.966757: val_loss -0.8008
2024-07-06 04:17:24.968556: Pseudo dice [0.9729, 0.893]
2024-07-06 04:17:24.970290: Epoch time: 64.98 s
2024-07-06 04:17:26.262830: 
2024-07-06 04:17:26.265473: Epoch 324
2024-07-06 04:17:26.267057: Current learning rate: 0.00703
2024-07-06 04:18:31.221766: Validation loss did not improve from -0.83309. Patience: 27/50
2024-07-06 04:18:31.223173: train_loss -0.7648
2024-07-06 04:18:31.224451: val_loss -0.776
2024-07-06 04:18:31.225423: Pseudo dice [0.9694, 0.8869]
2024-07-06 04:18:31.226460: Epoch time: 64.96 s
2024-07-06 04:18:32.830760: 
2024-07-06 04:18:32.833574: Epoch 325
2024-07-06 04:18:32.835321: Current learning rate: 0.00702
2024-07-06 04:19:37.775561: Validation loss did not improve from -0.83309. Patience: 28/50
2024-07-06 04:19:37.777053: train_loss -0.7687
2024-07-06 04:19:37.778200: val_loss -0.7949
2024-07-06 04:19:37.779121: Pseudo dice [0.9697, 0.8978]
2024-07-06 04:19:37.780247: Epoch time: 64.95 s
2024-07-06 04:19:39.036369: 
2024-07-06 04:19:39.037953: Epoch 326
2024-07-06 04:19:39.039027: Current learning rate: 0.00701
2024-07-06 04:20:43.974303: Validation loss did not improve from -0.83309. Patience: 29/50
2024-07-06 04:20:43.976088: train_loss -0.7829
2024-07-06 04:20:43.977835: val_loss -0.8081
2024-07-06 04:20:43.979191: Pseudo dice [0.9733, 0.8999]
2024-07-06 04:20:43.980505: Epoch time: 64.94 s
2024-07-06 04:20:45.230814: 
2024-07-06 04:20:45.232934: Epoch 327
2024-07-06 04:20:45.234272: Current learning rate: 0.007
2024-07-06 04:21:50.625826: Validation loss did not improve from -0.83309. Patience: 30/50
2024-07-06 04:21:50.628036: train_loss -0.7168
2024-07-06 04:21:50.629624: val_loss -0.7545
2024-07-06 04:21:50.630756: Pseudo dice [0.9643, 0.8665]
2024-07-06 04:21:50.631982: Epoch time: 65.4 s
2024-07-06 04:21:51.888700: 
2024-07-06 04:21:51.891086: Epoch 328
2024-07-06 04:21:51.892222: Current learning rate: 0.00699
2024-07-06 04:22:56.976311: Validation loss did not improve from -0.83309. Patience: 31/50
2024-07-06 04:22:56.978608: train_loss -0.7366
2024-07-06 04:22:56.980385: val_loss -0.7755
2024-07-06 04:22:56.981640: Pseudo dice [0.9693, 0.879]
2024-07-06 04:22:56.982720: Epoch time: 65.09 s
2024-07-06 04:22:58.238594: 
2024-07-06 04:22:58.241041: Epoch 329
2024-07-06 04:22:58.242926: Current learning rate: 0.00698
2024-07-06 04:24:03.369608: Validation loss did not improve from -0.83309. Patience: 32/50
2024-07-06 04:24:03.372002: train_loss -0.7557
2024-07-06 04:24:03.374119: val_loss -0.7863
2024-07-06 04:24:03.375757: Pseudo dice [0.9717, 0.8936]
2024-07-06 04:24:03.377130: Epoch time: 65.13 s
2024-07-06 04:24:05.067329: 
2024-07-06 04:24:05.069950: Epoch 330
2024-07-06 04:24:05.071344: Current learning rate: 0.00697
2024-07-06 04:25:10.249055: Validation loss did not improve from -0.83309. Patience: 33/50
2024-07-06 04:25:10.251012: train_loss -0.777
2024-07-06 04:25:10.252426: val_loss -0.7983
2024-07-06 04:25:10.253682: Pseudo dice [0.9761, 0.8921]
2024-07-06 04:25:10.255304: Epoch time: 65.18 s
2024-07-06 04:25:11.546125: 
2024-07-06 04:25:11.549517: Epoch 331
2024-07-06 04:25:11.551332: Current learning rate: 0.00696
2024-07-06 04:26:16.925154: Validation loss did not improve from -0.83309. Patience: 34/50
2024-07-06 04:26:16.977632: train_loss -0.7875
2024-07-06 04:26:16.979913: val_loss -0.8206
2024-07-06 04:26:16.981338: Pseudo dice [0.9775, 0.9015]
2024-07-06 04:26:16.983033: Epoch time: 65.42 s
2024-07-06 04:26:18.907046: 
2024-07-06 04:26:18.909110: Epoch 332
2024-07-06 04:26:18.911098: Current learning rate: 0.00696
2024-07-06 04:27:24.075283: Validation loss did not improve from -0.83309. Patience: 35/50
2024-07-06 04:27:24.077037: train_loss -0.7814
2024-07-06 04:27:24.078965: val_loss -0.816
2024-07-06 04:27:24.081231: Pseudo dice [0.9789, 0.9012]
2024-07-06 04:27:24.083158: Epoch time: 65.17 s
2024-07-06 04:27:25.358454: 
2024-07-06 04:27:25.360858: Epoch 333
2024-07-06 04:27:25.361992: Current learning rate: 0.00695
2024-07-06 04:28:30.373977: Validation loss did not improve from -0.83309. Patience: 36/50
2024-07-06 04:28:30.375589: train_loss -0.7948
2024-07-06 04:28:30.377353: val_loss -0.8117
2024-07-06 04:28:30.378787: Pseudo dice [0.974, 0.9013]
2024-07-06 04:28:30.380406: Epoch time: 65.02 s
2024-07-06 04:28:31.631444: 
2024-07-06 04:28:31.633824: Epoch 334
2024-07-06 04:28:31.635454: Current learning rate: 0.00694
2024-07-06 04:29:36.603390: Validation loss did not improve from -0.83309. Patience: 37/50
2024-07-06 04:29:36.605250: train_loss -0.8063
2024-07-06 04:29:36.607001: val_loss -0.8117
2024-07-06 04:29:36.608469: Pseudo dice [0.9766, 0.9012]
2024-07-06 04:29:36.609656: Epoch time: 64.97 s
2024-07-06 04:29:38.251764: 
2024-07-06 04:29:38.254279: Epoch 335
2024-07-06 04:29:38.255856: Current learning rate: 0.00693
2024-07-06 04:30:43.317584: Validation loss did not improve from -0.83309. Patience: 38/50
2024-07-06 04:30:43.319569: train_loss -0.7981
2024-07-06 04:30:43.321082: val_loss -0.8099
2024-07-06 04:30:43.322706: Pseudo dice [0.9745, 0.8998]
2024-07-06 04:30:43.323839: Epoch time: 65.07 s
2024-07-06 04:30:44.635636: 
2024-07-06 04:30:44.638567: Epoch 336
2024-07-06 04:30:44.640398: Current learning rate: 0.00692
2024-07-06 04:31:49.872338: Validation loss did not improve from -0.83309. Patience: 39/50
2024-07-06 04:31:49.874079: train_loss -0.7994
2024-07-06 04:31:49.876172: val_loss -0.8127
2024-07-06 04:31:49.878474: Pseudo dice [0.9772, 0.9017]
2024-07-06 04:31:49.880117: Epoch time: 65.24 s
2024-07-06 04:31:51.158761: 
2024-07-06 04:31:51.161524: Epoch 337
2024-07-06 04:31:51.163040: Current learning rate: 0.00691
2024-07-06 04:32:56.400723: Validation loss did not improve from -0.83309. Patience: 40/50
2024-07-06 04:32:56.403321: train_loss -0.7932
2024-07-06 04:32:56.405966: val_loss -0.8001
2024-07-06 04:32:56.407176: Pseudo dice [0.9748, 0.8981]
2024-07-06 04:32:56.408343: Epoch time: 65.25 s
2024-07-06 04:32:57.687478: 
2024-07-06 04:32:57.689767: Epoch 338
2024-07-06 04:32:57.690756: Current learning rate: 0.0069
2024-07-06 04:34:03.018817: Validation loss did not improve from -0.83309. Patience: 41/50
2024-07-06 04:34:03.020389: train_loss -0.7909
2024-07-06 04:34:03.021927: val_loss -0.8163
2024-07-06 04:34:03.023120: Pseudo dice [0.9766, 0.8988]
2024-07-06 04:34:03.024106: Epoch time: 65.33 s
2024-07-06 04:34:04.300719: 
2024-07-06 04:34:04.303214: Epoch 339
2024-07-06 04:34:04.304942: Current learning rate: 0.00689
2024-07-06 04:35:09.627889: Validation loss did not improve from -0.83309. Patience: 42/50
2024-07-06 04:35:09.629701: train_loss -0.7701
2024-07-06 04:35:09.631072: val_loss -0.6591
2024-07-06 04:35:09.632319: Pseudo dice [0.9043, 0.8784]
2024-07-06 04:35:09.633462: Epoch time: 65.33 s
2024-07-06 04:35:11.245837: 
2024-07-06 04:35:11.247923: Epoch 340
2024-07-06 04:35:11.249488: Current learning rate: 0.00688
2024-07-06 04:36:16.597047: Validation loss did not improve from -0.83309. Patience: 43/50
2024-07-06 04:36:16.599927: train_loss -0.7513
2024-07-06 04:36:16.602193: val_loss -0.8001
2024-07-06 04:36:16.604021: Pseudo dice [0.9715, 0.8938]
2024-07-06 04:36:16.605230: Epoch time: 65.36 s
2024-07-06 04:36:17.894067: 
2024-07-06 04:36:17.896615: Epoch 341
2024-07-06 04:36:17.898674: Current learning rate: 0.00687
2024-07-06 04:37:23.118877: Validation loss did not improve from -0.83309. Patience: 44/50
2024-07-06 04:37:23.120499: train_loss -0.7869
2024-07-06 04:37:23.122252: val_loss -0.8072
2024-07-06 04:37:23.123669: Pseudo dice [0.9747, 0.9005]
2024-07-06 04:37:23.124998: Epoch time: 65.23 s
2024-07-06 04:37:24.401291: 
2024-07-06 04:37:24.403958: Epoch 342
2024-07-06 04:37:24.405226: Current learning rate: 0.00686
2024-07-06 04:38:29.573721: Validation loss did not improve from -0.83309. Patience: 45/50
2024-07-06 04:38:29.575388: train_loss -0.7928
2024-07-06 04:38:29.577149: val_loss -0.8199
2024-07-06 04:38:29.578874: Pseudo dice [0.976, 0.9043]
2024-07-06 04:38:29.580580: Epoch time: 65.18 s
2024-07-06 04:38:31.286484: 
2024-07-06 04:38:31.288548: Epoch 343
2024-07-06 04:38:31.289814: Current learning rate: 0.00685
2024-07-06 04:39:36.282748: Validation loss did not improve from -0.83309. Patience: 46/50
2024-07-06 04:39:36.284518: train_loss -0.7923
2024-07-06 04:39:36.285995: val_loss -0.8161
2024-07-06 04:39:36.287150: Pseudo dice [0.9741, 0.8989]
2024-07-06 04:39:36.288065: Epoch time: 65.0 s
2024-07-06 04:39:37.558136: 
2024-07-06 04:39:37.560708: Epoch 344
2024-07-06 04:39:37.562375: Current learning rate: 0.00684
2024-07-06 04:40:42.605397: Validation loss did not improve from -0.83309. Patience: 47/50
2024-07-06 04:40:42.607000: train_loss -0.782
2024-07-06 04:40:42.608455: val_loss -0.808
2024-07-06 04:40:42.609768: Pseudo dice [0.9747, 0.8949]
2024-07-06 04:40:42.610946: Epoch time: 65.05 s
2024-07-06 04:40:44.196131: 
2024-07-06 04:40:44.199320: Epoch 345
2024-07-06 04:40:44.201403: Current learning rate: 0.00683
2024-07-06 04:41:49.661932: Validation loss did not improve from -0.83309. Patience: 48/50
2024-07-06 04:41:49.664493: train_loss -0.7953
2024-07-06 04:41:49.666253: val_loss -0.8222
2024-07-06 04:41:49.667718: Pseudo dice [0.9753, 0.908]
2024-07-06 04:41:49.669058: Epoch time: 65.47 s
2024-07-06 04:41:50.959608: 
2024-07-06 04:41:50.961872: Epoch 346
2024-07-06 04:41:50.963438: Current learning rate: 0.00682
2024-07-06 04:42:57.562822: Validation loss did not improve from -0.83309. Patience: 49/50
2024-07-06 04:42:57.565495: train_loss -0.8018
2024-07-06 04:42:57.567961: val_loss -0.8217
2024-07-06 04:42:57.569256: Pseudo dice [0.975, 0.9056]
2024-07-06 04:42:57.570429: Epoch time: 66.61 s
2024-07-06 04:42:58.850771: 
2024-07-06 04:42:58.852697: Epoch 347
2024-07-06 04:42:58.854256: Current learning rate: 0.00681
2024-07-06 04:44:04.632548: Validation loss did not improve from -0.83309. Patience: 50/50
2024-07-06 04:44:04.634699: train_loss -0.8071
2024-07-06 04:44:04.637531: val_loss -0.8116
2024-07-06 04:44:04.638942: Pseudo dice [0.9744, 0.9016]
2024-07-06 04:44:04.640409: Epoch time: 65.78 s
2024-07-06 04:44:06.062977: Patience reached. Stopping training.
2024-07-06 04:44:06.514722: Training done.
2024-07-06 04:44:07.003322: predicting BE_OLV_00014_Pre_PCI
2024-07-06 04:44:07.081958: BE_OLV_00014_Pre_PCI, shape torch.Size([1, 374, 498, 498]), rank 0
2024-07-06 04:46:02.827826: predicting BE_OLV_00018_Pre_PCI
2024-07-06 04:46:02.912774: BE_OLV_00018_Pre_PCI, shape torch.Size([1, 374, 498, 498]), rank 0
2024-07-06 04:47:17.475124: predicting BE_OLV_00020_Pre_PCI
2024-07-06 04:47:17.503943: BE_OLV_00020_Pre_PCI, shape torch.Size([1, 374, 498, 498]), rank 0
2024-07-06 04:48:32.167515: predicting BE_OLV_00028_Pre_PCI
2024-07-06 04:48:32.261306: BE_OLV_00028_Pre_PCI, shape torch.Size([1, 375, 498, 498]), rank 0
2024-07-06 04:49:46.593903: predicting BE_OLV_00029_Pre_PCI
2024-07-06 04:49:46.708554: BE_OLV_00029_Pre_PCI, shape torch.Size([1, 373, 498, 498]), rank 0
2024-07-06 04:51:01.034968: predicting BE_OLV_00031_Pre_PCI
2024-07-06 04:51:01.181954: BE_OLV_00031_Pre_PCI, shape torch.Size([1, 374, 498, 498]), rank 0
2024-07-06 04:52:15.347190: predicting BE_OLV_00034_Pre_PCI
2024-07-06 04:52:15.495364: BE_OLV_00034_Pre_PCI, shape torch.Size([1, 374, 498, 498]), rank 0
2024-07-06 04:53:31.762694: predicting BE_OLV_00038_Pre_PCI
2024-07-06 04:53:31.866495: BE_OLV_00038_Pre_PCI, shape torch.Size([1, 375, 498, 498]), rank 0
2024-07-06 04:54:46.468904: predicting BE_OLV_00048_Pre_PCI
2024-07-06 04:54:46.646897: BE_OLV_00048_Pre_PCI, shape torch.Size([1, 374, 498, 498]), rank 0
2024-07-06 04:56:02.366927: predicting BE_OLV_00050_Pre_PCI
2024-07-06 04:56:02.393506: BE_OLV_00050_Pre_PCI, shape torch.Size([1, 374, 498, 498]), rank 0
2024-07-06 04:57:17.102674: predicting DK_AHU_00007_Pre_PCI
2024-07-06 04:57:17.266829: DK_AHU_00007_Pre_PCI, shape torch.Size([1, 375, 498, 498]), rank 0
2024-07-06 04:58:32.884502: predicting DK_AHU_00015_Pre_PCI
2024-07-06 04:58:33.114839: DK_AHU_00015_Pre_PCI, shape torch.Size([1, 375, 498, 498]), rank 0
2024-07-06 04:59:49.573395: predicting DK_AHU_00018_Pre_PCI
2024-07-06 04:59:49.691369: DK_AHU_00018_Pre_PCI, shape torch.Size([1, 375, 498, 498]), rank 0
2024-07-06 05:01:04.536011: predicting DK_AHU_00027_Pre_PCI
2024-07-06 05:01:04.703538: DK_AHU_00027_Pre_PCI, shape torch.Size([1, 540, 498, 498]), rank 0
2024-07-06 05:02:58.282632: predicting JP_KOB_00009_Pre_PCI
2024-07-06 05:02:58.311233: JP_KOB_00009_Pre_PCI, shape torch.Size([1, 375, 498, 498]), rank 0
2024-07-06 05:04:12.634390: predicting KR_SNC_00008_Pre_PCI
2024-07-06 05:04:12.911845: KR_SNC_00008_Pre_PCI, shape torch.Size([1, 270, 498, 498]), rank 0
2024-07-06 05:05:04.429196: predicting STENT_0000
2024-07-06 05:05:04.632951: STENT_0000, shape torch.Size([1, 375, 498, 498]), rank 0
2024-07-06 05:06:18.964037: predicting STENT_0001
2024-07-06 05:06:19.120219: STENT_0001, shape torch.Size([1, 375, 498, 498]), rank 0
2024-07-06 05:07:34.072438: predicting STENT_0002
2024-07-06 05:07:34.332222: STENT_0002, shape torch.Size([1, 375, 498, 498]), rank 0
2024-07-06 05:08:55.157370: predicting STENT_0003
2024-07-06 05:08:55.413349: STENT_0003, shape torch.Size([1, 374, 498, 498]), rank 0
2024-07-06 05:10:19.593430: predicting STENT_0004
2024-07-06 05:10:19.674600: STENT_0004, shape torch.Size([1, 374, 498, 498]), rank 0
2024-07-06 05:12:03.439810: Validation complete
2024-07-06 05:12:03.441095: Mean Validation Dice:  0.9330332985070654
wandb: 
wandb: Run history:
wandb:            ema_fg_dice 
wandb:   epoch_end_timestamps 
wandb: epoch_start_timestamps 
wandb:                    lrs 
wandb:           mean_fg_dice 
wandb:           train_losses 
wandb:             val_losses 
wandb: 
wandb: Run summary:
wandb:            ema_fg_dice 0.93495
wandb:   epoch_end_timestamps 1720255444.63454
wandb: epoch_start_timestamps 1720255378.84956
wandb:                    lrs 0.00681
wandb:           mean_fg_dice 0.93797
wandb:           train_losses -0.80706
wandb:             val_losses -0.81158
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset304_Lumen_and_Wall_OCT/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_all/wandb/offline-run-20240705_221238-42hl8a93
wandb: Find logs at: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset304_Lumen_and_Wall_OCT/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_all/wandb/offline-run-20240705_221238-42hl8a93/logs
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fcd809bac10>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fcdf5e98580>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fcdf5d2daf0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fcda410e820>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fcd88038820>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fcd104b8790>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
