/home/gridsan/nchutisilp/.conda/envs/nnunet/bin/python

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2024-11-28 15:46:11.893853: do_dummy_2d_data_aug: False
2024-11-28 15:46:11.895870: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset306_Sohee_Ajay_Calcium_OCT/splits_final.json
2024-11-28 15:46:11.897725: The split file contains 5 splits.
2024-11-28 15:46:11.899093: Desired fold for training: 0
2024-11-28 15:46:11.900418: This split has 10 training and 3 validation cases.

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2024-11-28 15:46:11.892370: do_dummy_2d_data_aug: False
2024-11-28 15:46:11.895838: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset306_Sohee_Ajay_Calcium_OCT/splits_final.json
2024-11-28 15:46:11.897174: The split file contains 5 splits.
2024-11-28 15:46:11.898187: Desired fold for training: 1
2024-11-28 15:46:11.899221: This split has 10 training and 3 validation cases.
using pin_memory on device 0
using pin_memory on device 0
using pin_memory on device 0
2024-11-28 15:46:21.237412: Using torch.compile...
using pin_memory on device 0
2024-11-28 15:46:21.693554: Using torch.compile...
/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': [512, 512], 'median_image_size_in_voxels': [498.0, 498.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset306_Sohee_Ajay_Calcium_OCT', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.49803921580314636, 'mean': 0.14296366274356842, 'median': 0.10980392247438431, 'min': 0.0, 'percentile_00_5': 0.01558823511004448, 'percentile_99_5': 0.49803921580314636, 'std': 0.11562220752239227}}} 

2024-11-28 15:46:22.032385: unpacking dataset...
/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': [512, 512], 'median_image_size_in_voxels': [498.0, 498.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset306_Sohee_Ajay_Calcium_OCT', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.49803921580314636, 'mean': 0.14296366274356842, 'median': 0.10980392247438431, 'min': 0.0, 'percentile_00_5': 0.01558823511004448, 'percentile_99_5': 0.49803921580314636, 'std': 0.11562220752239227}}} 

2024-11-28 15:46:22.520986: unpacking dataset...
2024-11-28 15:46:26.060926: unpacking done...
2024-11-28 15:46:26.111454: Unable to plot network architecture: nnUNet_compile is enabled!
2024-11-28 15:46:26.180676: 
2024-11-28 15:46:26.182126: Epoch 0
2024-11-28 15:46:26.183616: Current learning rate: 0.01
2024-11-28 15:48:48.969611: Validation loss improved from 1000.00000 to -0.34007! Patience: 0/50
2024-11-28 15:48:48.971313: train_loss -0.214
2024-11-28 15:48:48.972964: val_loss -0.3401
2024-11-28 15:48:48.974010: Pseudo dice [0.4714]
2024-11-28 15:48:48.974804: Epoch time: 142.79 s
2024-11-28 15:48:48.975739: Yayy! New best EMA pseudo Dice: 0.4714
2024-11-28 15:48:50.788540: 
2024-11-28 15:48:50.791029: Epoch 1
2024-11-28 15:48:50.792474: Current learning rate: 0.00999
2024-11-28 15:49:37.588115: Validation loss improved from -0.34007 to -0.40369! Patience: 0/50
2024-11-28 15:49:37.590289: train_loss -0.4262
2024-11-28 15:49:37.591049: val_loss -0.4037
2024-11-28 15:49:37.591744: Pseudo dice [0.5252]
2024-11-28 15:49:37.592466: Epoch time: 46.81 s
2024-11-28 15:49:37.593055: Yayy! New best EMA pseudo Dice: 0.4767
2024-11-28 15:49:39.382766: 
2024-11-28 15:49:39.383739: Epoch 2
2024-11-28 15:49:39.384592: Current learning rate: 0.00998
2024-11-28 15:50:26.139800: Validation loss improved from -0.40369 to -0.54797! Patience: 0/50
2024-11-28 15:50:26.143025: train_loss -0.5368
2024-11-28 15:50:26.144063: val_loss -0.548
2024-11-28 15:50:26.144765: Pseudo dice [0.6563]
2024-11-28 15:50:26.145434: Epoch time: 46.76 s
2024-11-28 15:50:26.146342: Yayy! New best EMA pseudo Dice: 0.4947
2024-11-28 15:50:27.947382: 
2024-11-28 15:50:27.949067: Epoch 3
2024-11-28 15:50:27.949958: Current learning rate: 0.00997
2024-11-28 15:51:14.676286: Validation loss improved from -0.54797 to -0.55534! Patience: 0/50
2024-11-28 15:51:14.678235: train_loss -0.5938
2024-11-28 15:51:14.679148: val_loss -0.5553
2024-11-28 15:51:14.680021: Pseudo dice [0.6639]
2024-11-28 15:51:14.680741: Epoch time: 46.73 s
2024-11-28 15:51:14.681446: Yayy! New best EMA pseudo Dice: 0.5116
2024-11-28 15:51:16.439580: 
2024-11-28 15:51:16.441358: Epoch 4
2024-11-28 15:51:16.442416: Current learning rate: 0.00996
2024-11-28 15:52:03.205516: Validation loss improved from -0.55534 to -0.56939! Patience: 0/50
2024-11-28 15:52:03.206988: train_loss -0.6269
2024-11-28 15:52:03.207742: val_loss -0.5694
2024-11-28 15:52:03.208482: Pseudo dice [0.6696]
2024-11-28 15:52:03.209193: Epoch time: 46.77 s
2024-11-28 15:52:03.691307: Yayy! New best EMA pseudo Dice: 0.5274
2024-11-28 15:52:05.533551: 
2024-11-28 15:52:05.535007: Epoch 5
2024-11-28 15:52:05.535740: Current learning rate: 0.00995
2024-11-28 15:52:52.272634: Validation loss did not improve from -0.56939. Patience: 1/50
2024-11-28 15:52:52.275999: train_loss -0.6448
2024-11-28 15:52:52.276977: val_loss -0.5057
2024-11-28 15:52:52.277834: Pseudo dice [0.6194]
2024-11-28 15:52:52.278750: Epoch time: 46.74 s
2024-11-28 15:52:52.279698: Yayy! New best EMA pseudo Dice: 0.5366
2024-11-28 15:52:54.043786: 
2024-11-28 15:52:54.046304: Epoch 6
2024-11-28 15:52:54.047247: Current learning rate: 0.00995
2024-11-28 15:53:40.840994: Validation loss improved from -0.56939 to -0.59557! Patience: 1/50
2024-11-28 15:53:40.844098: train_loss -0.6655
2024-11-28 15:53:40.845127: val_loss -0.5956
2024-11-28 15:53:40.845995: Pseudo dice [0.6936]
2024-11-28 15:53:40.846894: Epoch time: 46.8 s
2024-11-28 15:53:40.847755: Yayy! New best EMA pseudo Dice: 0.5523
2024-11-28 15:53:42.639162: 
2024-11-28 15:53:42.641564: Epoch 7
2024-11-28 15:53:42.642348: Current learning rate: 0.00994
2024-11-28 15:54:29.409591: Validation loss improved from -0.59557 to -0.61180! Patience: 0/50
2024-11-28 15:54:29.413319: train_loss -0.6666
2024-11-28 15:54:29.414538: val_loss -0.6118
2024-11-28 15:54:29.415301: Pseudo dice [0.7035]
2024-11-28 15:54:29.416038: Epoch time: 46.78 s
2024-11-28 15:54:29.416700: Yayy! New best EMA pseudo Dice: 0.5674
2024-11-28 15:54:31.869934: 
2024-11-28 15:54:31.873063: Epoch 8
2024-11-28 15:54:31.874278: Current learning rate: 0.00993
2024-11-28 15:55:18.729393: Validation loss did not improve from -0.61180. Patience: 1/50
2024-11-28 15:55:18.732226: train_loss -0.6767
2024-11-28 15:55:18.733058: val_loss -0.5774
2024-11-28 15:55:18.733810: Pseudo dice [0.6782]
2024-11-28 15:55:18.734511: Epoch time: 46.86 s
2024-11-28 15:55:18.735251: Yayy! New best EMA pseudo Dice: 0.5785
2024-11-28 15:55:20.530876: 
2024-11-28 15:55:20.534549: Epoch 9
2024-11-28 15:55:20.535371: Current learning rate: 0.00992
2024-11-28 15:56:07.394916: Validation loss improved from -0.61180 to -0.61310! Patience: 1/50
2024-11-28 15:56:07.398415: train_loss -0.6874
2024-11-28 15:56:07.399594: val_loss -0.6131
2024-11-28 15:56:07.400282: Pseudo dice [0.7052]
2024-11-28 15:56:07.401078: Epoch time: 46.87 s
2024-11-28 15:56:07.924117: Yayy! New best EMA pseudo Dice: 0.5912
2024-11-28 15:56:09.663897: 
2024-11-28 15:56:09.667280: Epoch 10
2024-11-28 15:56:09.668694: Current learning rate: 0.00991
2024-11-28 15:56:56.509197: Validation loss improved from -0.61310 to -0.63094! Patience: 0/50
2024-11-28 15:56:56.512494: train_loss -0.6947
2024-11-28 15:56:56.513396: val_loss -0.6309
2024-11-28 15:56:56.514030: Pseudo dice [0.7201]
2024-11-28 15:56:56.514823: Epoch time: 46.85 s
2024-11-28 15:56:56.515530: Yayy! New best EMA pseudo Dice: 0.6041
2024-11-28 15:56:58.274854: 
2024-11-28 15:56:58.277731: Epoch 11
2024-11-28 15:56:58.278819: Current learning rate: 0.0099
2024-11-28 15:57:45.116918: Validation loss did not improve from -0.63094. Patience: 1/50
2024-11-28 15:57:45.120453: train_loss -0.7003
2024-11-28 15:57:45.121426: val_loss -0.6067
2024-11-28 15:57:45.122301: Pseudo dice [0.7003]
2024-11-28 15:57:45.123204: Epoch time: 46.85 s
2024-11-28 15:57:45.124082: Yayy! New best EMA pseudo Dice: 0.6137
2024-11-28 15:57:46.869174: 
2024-11-28 15:57:46.871065: Epoch 12
2024-11-28 15:57:46.872096: Current learning rate: 0.00989
2024-11-28 15:58:33.698364: Validation loss did not improve from -0.63094. Patience: 2/50
2024-11-28 15:58:33.700160: train_loss -0.7033
2024-11-28 15:58:33.701083: val_loss -0.5983
2024-11-28 15:58:33.701931: Pseudo dice [0.6929]
2024-11-28 15:58:33.702725: Epoch time: 46.83 s
2024-11-28 15:58:33.703552: Yayy! New best EMA pseudo Dice: 0.6216
2024-11-28 15:58:35.492007: 
2024-11-28 15:58:35.493666: Epoch 13
2024-11-28 15:58:35.494553: Current learning rate: 0.00988
2024-11-28 15:59:22.369363: Validation loss did not improve from -0.63094. Patience: 3/50
2024-11-28 15:59:22.371058: train_loss -0.7119
2024-11-28 15:59:22.371943: val_loss -0.5983
2024-11-28 15:59:22.372648: Pseudo dice [0.6966]
2024-11-28 15:59:22.373522: Epoch time: 46.88 s
2024-11-28 15:59:22.374279: Yayy! New best EMA pseudo Dice: 0.6291
2024-11-28 15:59:24.150242: 
2024-11-28 15:59:24.151656: Epoch 14
2024-11-28 15:59:24.152643: Current learning rate: 0.00987
2024-11-28 16:00:11.009615: Validation loss did not improve from -0.63094. Patience: 4/50
2024-11-28 16:00:11.011511: train_loss -0.7119
2024-11-28 16:00:11.012173: val_loss -0.6229
2024-11-28 16:00:11.013140: Pseudo dice [0.7155]
2024-11-28 16:00:11.013891: Epoch time: 46.86 s
2024-11-28 16:00:11.539220: Yayy! New best EMA pseudo Dice: 0.6378
2024-11-28 16:00:13.331328: 
2024-11-28 16:00:13.332978: Epoch 15
2024-11-28 16:00:13.333850: Current learning rate: 0.00986
2024-11-28 16:01:00.187892: Validation loss improved from -0.63094 to -0.64842! Patience: 4/50
2024-11-28 16:01:00.189733: train_loss -0.7179
2024-11-28 16:01:00.190434: val_loss -0.6484
2024-11-28 16:01:00.191281: Pseudo dice [0.7291]
2024-11-28 16:01:00.192101: Epoch time: 46.86 s
2024-11-28 16:01:00.192974: Yayy! New best EMA pseudo Dice: 0.6469
2024-11-28 16:01:01.991524: 
2024-11-28 16:01:01.992886: Epoch 16
2024-11-28 16:01:01.993671: Current learning rate: 0.00986
2024-11-28 16:01:48.913890: Validation loss did not improve from -0.64842. Patience: 1/50
2024-11-28 16:01:48.915078: train_loss -0.7347
2024-11-28 16:01:48.915781: val_loss -0.619
2024-11-28 16:01:48.916430: Pseudo dice [0.7136]
2024-11-28 16:01:48.917211: Epoch time: 46.92 s
2024-11-28 16:01:48.917795: Yayy! New best EMA pseudo Dice: 0.6536
2024-11-28 16:01:50.789303: 
2024-11-28 16:01:50.791249: Epoch 17
2024-11-28 16:01:50.792273: Current learning rate: 0.00985
2024-11-28 16:02:37.693040: Validation loss did not improve from -0.64842. Patience: 2/50
2024-11-28 16:02:37.694860: train_loss -0.7272
2024-11-28 16:02:37.695678: val_loss -0.6054
2024-11-28 16:02:37.696426: Pseudo dice [0.7031]
2024-11-28 16:02:37.697116: Epoch time: 46.91 s
2024-11-28 16:02:37.697804: Yayy! New best EMA pseudo Dice: 0.6585
2024-11-28 16:02:40.193347: 
2024-11-28 16:02:40.195671: Epoch 18
2024-11-28 16:02:40.196672: Current learning rate: 0.00984
2024-11-28 16:03:27.147545: Validation loss did not improve from -0.64842. Patience: 3/50
2024-11-28 16:03:27.149583: train_loss -0.7276
2024-11-28 16:03:27.150458: val_loss -0.5667
2024-11-28 16:03:27.151340: Pseudo dice [0.6599]
2024-11-28 16:03:27.152184: Epoch time: 46.96 s
2024-11-28 16:03:27.152937: Yayy! New best EMA pseudo Dice: 0.6587
2024-11-28 16:03:28.991865: 
2024-11-28 16:03:28.993728: Epoch 19
2024-11-28 16:03:28.994699: Current learning rate: 0.00983
2024-11-28 16:04:16.010492: Validation loss did not improve from -0.64842. Patience: 4/50
2024-11-28 16:04:16.013297: train_loss -0.7313
2024-11-28 16:04:16.014505: val_loss -0.6314
2024-11-28 16:04:16.015671: Pseudo dice [0.7163]
2024-11-28 16:04:16.016743: Epoch time: 47.02 s
2024-11-28 16:04:16.558953: Yayy! New best EMA pseudo Dice: 0.6644
2024-11-28 16:04:18.469226: 
2024-11-28 16:04:18.470969: Epoch 20
2024-11-28 16:04:18.471784: Current learning rate: 0.00982
2024-11-28 16:05:05.419382: Validation loss did not improve from -0.64842. Patience: 5/50
2024-11-28 16:05:05.421133: train_loss -0.7253
2024-11-28 16:05:05.421866: val_loss -0.626
2024-11-28 16:05:05.422715: Pseudo dice [0.7109]
2024-11-28 16:05:05.423542: Epoch time: 46.95 s
2024-11-28 16:05:05.424273: Yayy! New best EMA pseudo Dice: 0.6691
2024-11-28 16:05:07.290446: 
2024-11-28 16:05:07.291705: Epoch 21
2024-11-28 16:05:07.292546: Current learning rate: 0.00981
2024-11-28 16:05:54.195977: Validation loss did not improve from -0.64842. Patience: 6/50
2024-11-28 16:05:54.197888: train_loss -0.7388
2024-11-28 16:05:54.198797: val_loss -0.6293
2024-11-28 16:05:54.199562: Pseudo dice [0.7196]
2024-11-28 16:05:54.200273: Epoch time: 46.91 s
2024-11-28 16:05:54.200994: Yayy! New best EMA pseudo Dice: 0.6741
2024-11-28 16:05:55.965965: 
2024-11-28 16:05:55.966687: Epoch 22
2024-11-28 16:05:55.967411: Current learning rate: 0.0098
2024-11-28 16:06:42.886500: Validation loss did not improve from -0.64842. Patience: 7/50
2024-11-28 16:06:42.888211: train_loss -0.7446
2024-11-28 16:06:42.889277: val_loss -0.6105
2024-11-28 16:06:42.890249: Pseudo dice [0.6981]
2024-11-28 16:06:42.891355: Epoch time: 46.92 s
2024-11-28 16:06:42.892623: Yayy! New best EMA pseudo Dice: 0.6765
2024-11-28 16:06:44.680549: 
2024-11-28 16:06:44.682211: Epoch 23
2024-11-28 16:06:44.683126: Current learning rate: 0.00979
2024-11-28 16:07:31.685499: Validation loss did not improve from -0.64842. Patience: 8/50
2024-11-28 16:07:31.686732: train_loss -0.7388
2024-11-28 16:07:31.687553: val_loss -0.5975
2024-11-28 16:07:31.688243: Pseudo dice [0.6869]
2024-11-28 16:07:31.689046: Epoch time: 47.01 s
2024-11-28 16:07:31.689692: Yayy! New best EMA pseudo Dice: 0.6776
2024-11-28 16:07:33.455841: 
2024-11-28 16:07:33.456910: Epoch 24
2024-11-28 16:07:33.457677: Current learning rate: 0.00978
2024-11-28 16:08:20.450592: Validation loss did not improve from -0.64842. Patience: 9/50
2024-11-28 16:08:20.452157: train_loss -0.7528
2024-11-28 16:08:20.453109: val_loss -0.6383
2024-11-28 16:08:20.453977: Pseudo dice [0.7251]
2024-11-28 16:08:20.454830: Epoch time: 47.0 s
2024-11-28 16:08:21.002532: Yayy! New best EMA pseudo Dice: 0.6823
2024-11-28 16:08:22.798714: 
2024-11-28 16:08:22.800929: Epoch 25
2024-11-28 16:08:22.801888: Current learning rate: 0.00977
2024-11-28 16:09:09.792108: Validation loss did not improve from -0.64842. Patience: 10/50
2024-11-28 16:09:09.793759: train_loss -0.7568
2024-11-28 16:09:09.794636: val_loss -0.6449
2024-11-28 16:09:09.795506: Pseudo dice [0.7276]
2024-11-28 16:09:09.796329: Epoch time: 47.0 s
2024-11-28 16:09:09.797047: Yayy! New best EMA pseudo Dice: 0.6868
2024-11-28 16:09:11.571864: 
2024-11-28 16:09:11.573461: Epoch 26
2024-11-28 16:09:11.574288: Current learning rate: 0.00977
2024-11-28 16:09:58.592546: Validation loss did not improve from -0.64842. Patience: 11/50
2024-11-28 16:09:58.594184: train_loss -0.7512
2024-11-28 16:09:58.594956: val_loss -0.6435
2024-11-28 16:09:58.595602: Pseudo dice [0.7303]
2024-11-28 16:09:58.596315: Epoch time: 47.02 s
2024-11-28 16:09:58.597034: Yayy! New best EMA pseudo Dice: 0.6912
2024-11-28 16:10:00.390059: 
2024-11-28 16:10:00.392001: Epoch 27
2024-11-28 16:10:00.392750: Current learning rate: 0.00976
2024-11-28 16:10:47.411633: Validation loss improved from -0.64842 to -0.65508! Patience: 11/50
2024-11-28 16:10:47.413307: train_loss -0.7658
2024-11-28 16:10:47.414485: val_loss -0.6551
2024-11-28 16:10:47.415566: Pseudo dice [0.7372]
2024-11-28 16:10:47.416525: Epoch time: 47.02 s
2024-11-28 16:10:47.417537: Yayy! New best EMA pseudo Dice: 0.6958
2024-11-28 16:10:49.221901: 
2024-11-28 16:10:49.223034: Epoch 28
2024-11-28 16:10:49.223889: Current learning rate: 0.00975
2024-11-28 16:11:36.218977: Validation loss improved from -0.65508 to -0.68105! Patience: 0/50
2024-11-28 16:11:36.220212: train_loss -0.7543
2024-11-28 16:11:36.221045: val_loss -0.681
2024-11-28 16:11:36.221971: Pseudo dice [0.7587]
2024-11-28 16:11:36.222782: Epoch time: 47.0 s
2024-11-28 16:11:36.223738: Yayy! New best EMA pseudo Dice: 0.7021
2024-11-28 16:11:38.574099: 
2024-11-28 16:11:38.575968: Epoch 29
2024-11-28 16:11:38.576693: Current learning rate: 0.00974
2024-11-28 16:12:25.581961: Validation loss did not improve from -0.68105. Patience: 1/50
2024-11-28 16:12:25.583351: train_loss -0.756
2024-11-28 16:12:25.584197: val_loss -0.6425
2024-11-28 16:12:25.584855: Pseudo dice [0.7343]
2024-11-28 16:12:25.585589: Epoch time: 47.01 s
2024-11-28 16:12:26.120033: Yayy! New best EMA pseudo Dice: 0.7053
2024-11-28 16:12:27.996421: 
2024-11-28 16:12:27.998138: Epoch 30
2024-11-28 16:12:27.998930: Current learning rate: 0.00973
2024-11-28 16:13:15.040343: Validation loss did not improve from -0.68105. Patience: 2/50
2024-11-28 16:13:15.042143: train_loss -0.7651
2024-11-28 16:13:15.042886: val_loss -0.6289
2024-11-28 16:13:15.043486: Pseudo dice [0.7154]
2024-11-28 16:13:15.044320: Epoch time: 47.05 s
2024-11-28 16:13:15.045058: Yayy! New best EMA pseudo Dice: 0.7063
2024-11-28 16:13:16.898412: 
2024-11-28 16:13:16.899514: Epoch 31
2024-11-28 16:13:16.900268: Current learning rate: 0.00972
2024-11-28 16:14:03.907359: Validation loss did not improve from -0.68105. Patience: 3/50
2024-11-28 16:14:03.909248: train_loss -0.7646
2024-11-28 16:14:03.910040: val_loss -0.6565
2024-11-28 16:14:03.911014: Pseudo dice [0.7371]
2024-11-28 16:14:03.911640: Epoch time: 47.01 s
2024-11-28 16:14:03.912364: Yayy! New best EMA pseudo Dice: 0.7094
2024-11-28 16:14:05.773821: 
2024-11-28 16:14:05.775673: Epoch 32
2024-11-28 16:14:05.776490: Current learning rate: 0.00971
2024-11-28 16:14:52.734816: Validation loss did not improve from -0.68105. Patience: 4/50
2024-11-28 16:14:52.736114: train_loss -0.7747
2024-11-28 16:14:52.736832: val_loss -0.6548
2024-11-28 16:14:52.737443: Pseudo dice [0.7388]
2024-11-28 16:14:52.738534: Epoch time: 46.96 s
2024-11-28 16:14:52.739465: Yayy! New best EMA pseudo Dice: 0.7123
2024-11-28 16:14:54.600129: 
2024-11-28 16:14:54.601646: Epoch 33
2024-11-28 16:14:54.602429: Current learning rate: 0.0097
2024-11-28 16:15:41.586741: Validation loss did not improve from -0.68105. Patience: 5/50
2024-11-28 16:15:41.588540: train_loss -0.7761
2024-11-28 16:15:41.590013: val_loss -0.6697
2024-11-28 16:15:41.591192: Pseudo dice [0.7422]
2024-11-28 16:15:41.592243: Epoch time: 46.99 s
2024-11-28 16:15:41.593350: Yayy! New best EMA pseudo Dice: 0.7153
2024-11-28 16:15:43.423173: 
2024-11-28 16:15:43.424702: Epoch 34
2024-11-28 16:15:43.425662: Current learning rate: 0.00969
2024-11-28 16:16:30.459882: Validation loss did not improve from -0.68105. Patience: 6/50
2024-11-28 16:16:30.461643: train_loss -0.774
2024-11-28 16:16:30.462344: val_loss -0.6302
2024-11-28 16:16:30.462943: Pseudo dice [0.722]
2024-11-28 16:16:30.463519: Epoch time: 47.04 s
2024-11-28 16:16:31.004374: Yayy! New best EMA pseudo Dice: 0.716
2024-11-28 16:16:32.863754: 
2024-11-28 16:16:32.865498: Epoch 35
2024-11-28 16:16:32.866327: Current learning rate: 0.00968
2024-11-28 16:17:19.834679: Validation loss did not improve from -0.68105. Patience: 7/50
2024-11-28 16:17:19.836036: train_loss -0.7655
2024-11-28 16:17:19.836955: val_loss -0.6455
2024-11-28 16:17:19.837749: Pseudo dice [0.7367]
2024-11-28 16:17:19.838413: Epoch time: 46.97 s
2024-11-28 16:17:19.839324: Yayy! New best EMA pseudo Dice: 0.7181
2024-11-28 16:17:21.832081: 
2024-11-28 16:17:21.833530: Epoch 36
2024-11-28 16:17:21.834221: Current learning rate: 0.00968
2024-11-28 16:18:08.802609: Validation loss did not improve from -0.68105. Patience: 8/50
2024-11-28 16:18:08.804579: train_loss -0.773
2024-11-28 16:18:08.805365: val_loss -0.6258
2024-11-28 16:18:08.806113: Pseudo dice [0.7206]
2024-11-28 16:18:08.806789: Epoch time: 46.97 s
2024-11-28 16:18:08.807489: Yayy! New best EMA pseudo Dice: 0.7183
2024-11-28 16:18:10.636739: 
2024-11-28 16:18:10.638357: Epoch 37
2024-11-28 16:18:10.639232: Current learning rate: 0.00967
2024-11-28 16:18:57.670914: Validation loss did not improve from -0.68105. Patience: 9/50
2024-11-28 16:18:57.672592: train_loss -0.7711
2024-11-28 16:18:57.673631: val_loss -0.6568
2024-11-28 16:18:57.674657: Pseudo dice [0.7427]
2024-11-28 16:18:57.675662: Epoch time: 47.04 s
2024-11-28 16:18:57.676458: Yayy! New best EMA pseudo Dice: 0.7207
2024-11-28 16:18:59.575469: 
2024-11-28 16:18:59.576910: Epoch 38
2024-11-28 16:18:59.577693: Current learning rate: 0.00966
2024-11-28 16:19:46.588719: Validation loss did not improve from -0.68105. Patience: 10/50
2024-11-28 16:19:46.590557: train_loss -0.7783
2024-11-28 16:19:46.591278: val_loss -0.6141
2024-11-28 16:19:46.591878: Pseudo dice [0.7102]
2024-11-28 16:19:46.592515: Epoch time: 47.02 s
2024-11-28 16:19:47.916167: 
2024-11-28 16:19:47.917063: Epoch 39
2024-11-28 16:19:47.917866: Current learning rate: 0.00965
2024-11-28 16:20:35.508668: Validation loss did not improve from -0.68105. Patience: 11/50
2024-11-28 16:20:35.510125: train_loss -0.7802
2024-11-28 16:20:35.510756: val_loss -0.6317
2024-11-28 16:20:35.511362: Pseudo dice [0.7193]
2024-11-28 16:20:35.511983: Epoch time: 47.6 s
2024-11-28 16:20:37.425535: 
2024-11-28 16:20:37.426795: Epoch 40
2024-11-28 16:20:37.427490: Current learning rate: 0.00964
2024-11-28 16:21:24.397487: Validation loss did not improve from -0.68105. Patience: 12/50
2024-11-28 16:21:24.399374: train_loss -0.7855
2024-11-28 16:21:24.400095: val_loss -0.6629
2024-11-28 16:21:24.400706: Pseudo dice [0.7456]
2024-11-28 16:21:24.401318: Epoch time: 46.98 s
2024-11-28 16:21:24.401997: Yayy! New best EMA pseudo Dice: 0.7222
2024-11-28 16:21:26.346419: 
2024-11-28 16:21:26.347799: Epoch 41
2024-11-28 16:21:26.348449: Current learning rate: 0.00963
2024-11-28 16:22:13.350262: Validation loss did not improve from -0.68105. Patience: 13/50
2024-11-28 16:22:13.352215: train_loss -0.7758
2024-11-28 16:22:13.353082: val_loss -0.6587
2024-11-28 16:22:13.353766: Pseudo dice [0.744]
2024-11-28 16:22:13.354406: Epoch time: 47.01 s
2024-11-28 16:22:13.355084: Yayy! New best EMA pseudo Dice: 0.7244
2024-11-28 16:22:15.122792: 
2024-11-28 16:22:15.124220: Epoch 42
2024-11-28 16:22:15.125049: Current learning rate: 0.00962
2024-11-28 16:23:02.107806: Validation loss did not improve from -0.68105. Patience: 14/50
2024-11-28 16:23:02.109697: train_loss -0.7822
2024-11-28 16:23:02.110712: val_loss -0.6358
2024-11-28 16:23:02.111490: Pseudo dice [0.724]
2024-11-28 16:23:02.112218: Epoch time: 46.99 s
2024-11-28 16:23:03.349429: 
2024-11-28 16:23:03.351225: Epoch 43
2024-11-28 16:23:03.352226: Current learning rate: 0.00961
2024-11-28 16:23:50.326606: Validation loss did not improve from -0.68105. Patience: 15/50
2024-11-28 16:23:50.328397: train_loss -0.7832
2024-11-28 16:23:50.329267: val_loss -0.6537
2024-11-28 16:23:50.330017: Pseudo dice [0.7367]
2024-11-28 16:23:50.330844: Epoch time: 46.98 s
2024-11-28 16:23:50.331679: Yayy! New best EMA pseudo Dice: 0.7256
2024-11-28 16:23:52.150358: 
2024-11-28 16:23:52.151635: Epoch 44
2024-11-28 16:23:52.152432: Current learning rate: 0.0096
2024-11-28 16:24:39.158746: Validation loss did not improve from -0.68105. Patience: 16/50
2024-11-28 16:24:39.160994: train_loss -0.7876
2024-11-28 16:24:39.161923: val_loss -0.6652
2024-11-28 16:24:39.162581: Pseudo dice [0.7459]
2024-11-28 16:24:39.163421: Epoch time: 47.01 s
2024-11-28 16:24:39.708448: Yayy! New best EMA pseudo Dice: 0.7276
2024-11-28 16:24:41.481836: 
2024-11-28 16:24:41.483760: Epoch 45
2024-11-28 16:24:41.484776: Current learning rate: 0.00959
2024-11-28 16:25:28.455516: Validation loss did not improve from -0.68105. Patience: 17/50
2024-11-28 16:25:28.457264: train_loss -0.7867
2024-11-28 16:25:28.458114: val_loss -0.6587
2024-11-28 16:25:28.458764: Pseudo dice [0.7394]
2024-11-28 16:25:28.459405: Epoch time: 46.98 s
2024-11-28 16:25:28.460088: Yayy! New best EMA pseudo Dice: 0.7288
2024-11-28 16:25:30.216367: 
2024-11-28 16:25:30.217913: Epoch 46
2024-11-28 16:25:30.218809: Current learning rate: 0.00959
2024-11-28 16:26:17.170338: Validation loss did not improve from -0.68105. Patience: 18/50
2024-11-28 16:26:17.172309: train_loss -0.7926
2024-11-28 16:26:17.173128: val_loss -0.623
2024-11-28 16:26:17.173905: Pseudo dice [0.7123]
2024-11-28 16:26:17.174501: Epoch time: 46.96 s
2024-11-28 16:26:18.417770: 
2024-11-28 16:26:18.419307: Epoch 47
2024-11-28 16:26:18.420252: Current learning rate: 0.00958
2024-11-28 16:27:05.374446: Validation loss did not improve from -0.68105. Patience: 19/50
2024-11-28 16:27:05.376009: train_loss -0.7941
2024-11-28 16:27:05.376756: val_loss -0.6683
2024-11-28 16:27:05.377361: Pseudo dice [0.7503]
2024-11-28 16:27:05.378056: Epoch time: 46.96 s
2024-11-28 16:27:05.378595: Yayy! New best EMA pseudo Dice: 0.7295
2024-11-28 16:27:07.147259: 
2024-11-28 16:27:07.148849: Epoch 48
2024-11-28 16:27:07.149800: Current learning rate: 0.00957
2024-11-28 16:27:54.191658: Validation loss did not improve from -0.68105. Patience: 20/50
2024-11-28 16:27:54.193356: train_loss -0.7951
2024-11-28 16:27:54.194326: val_loss -0.6687
2024-11-28 16:27:54.194962: Pseudo dice [0.7528]
2024-11-28 16:27:54.195603: Epoch time: 47.05 s
2024-11-28 16:27:54.196355: Yayy! New best EMA pseudo Dice: 0.7318
2024-11-28 16:27:55.988495: 
2024-11-28 16:27:55.990129: Epoch 49
2024-11-28 16:27:55.991075: Current learning rate: 0.00956
2024-11-28 16:28:42.989466: Validation loss did not improve from -0.68105. Patience: 21/50
2024-11-28 16:28:42.991303: train_loss -0.7922
2024-11-28 16:28:42.992022: val_loss -0.6439
2024-11-28 16:28:42.992799: Pseudo dice [0.734]
2024-11-28 16:28:42.993550: Epoch time: 47.0 s
2024-11-28 16:28:43.533264: Yayy! New best EMA pseudo Dice: 0.732
2024-11-28 16:28:45.746985: 
2024-11-28 16:28:45.748692: Epoch 50
2024-11-28 16:28:45.749702: Current learning rate: 0.00955
2024-11-28 16:29:32.701186: Validation loss did not improve from -0.68105. Patience: 22/50
2024-11-28 16:29:32.703115: train_loss -0.7877
2024-11-28 16:29:32.703884: val_loss -0.6654
2024-11-28 16:29:32.704467: Pseudo dice [0.7424]
2024-11-28 16:29:32.705075: Epoch time: 46.96 s
2024-11-28 16:29:32.705613: Yayy! New best EMA pseudo Dice: 0.7331
2024-11-28 16:29:34.529050: 
2024-11-28 16:29:34.530797: Epoch 51
2024-11-28 16:29:34.531523: Current learning rate: 0.00954
2024-11-28 16:30:21.510551: Validation loss did not improve from -0.68105. Patience: 23/50
2024-11-28 16:30:21.512492: train_loss -0.7921
2024-11-28 16:30:21.513202: val_loss -0.647
2024-11-28 16:30:21.513936: Pseudo dice [0.7326]
2024-11-28 16:30:21.514618: Epoch time: 46.98 s
2024-11-28 16:30:22.770473: 
2024-11-28 16:30:22.772257: Epoch 52
2024-11-28 16:30:22.773243: Current learning rate: 0.00953
2024-11-28 16:31:09.798842: Validation loss did not improve from -0.68105. Patience: 24/50
2024-11-28 16:31:09.801221: train_loss -0.7983
2024-11-28 16:31:09.802396: val_loss -0.6541
2024-11-28 16:31:09.803059: Pseudo dice [0.7405]
2024-11-28 16:31:09.803801: Epoch time: 47.03 s
2024-11-28 16:31:09.804381: Yayy! New best EMA pseudo Dice: 0.7338
2024-11-28 16:31:11.599411: 
2024-11-28 16:31:11.600815: Epoch 53
2024-11-28 16:31:11.601686: Current learning rate: 0.00952
2024-11-28 16:31:58.583588: Validation loss did not improve from -0.68105. Patience: 25/50
2024-11-28 16:31:58.585549: train_loss -0.7931
2024-11-28 16:31:58.586275: val_loss -0.6726
2024-11-28 16:31:58.586872: Pseudo dice [0.7531]
2024-11-28 16:31:58.587613: Epoch time: 46.99 s
2024-11-28 16:31:58.588322: Yayy! New best EMA pseudo Dice: 0.7357
2024-11-28 16:32:00.393762: 
2024-11-28 16:32:00.395286: Epoch 54
2024-11-28 16:32:00.395941: Current learning rate: 0.00951
2024-11-28 16:32:47.339996: Validation loss did not improve from -0.68105. Patience: 26/50
2024-11-28 16:32:47.342244: train_loss -0.7909
2024-11-28 16:32:47.343134: val_loss -0.6358
2024-11-28 16:32:47.343925: Pseudo dice [0.7244]
2024-11-28 16:32:47.344831: Epoch time: 46.95 s
2024-11-28 16:32:49.167254: 
2024-11-28 16:32:49.168665: Epoch 55
2024-11-28 16:32:49.169414: Current learning rate: 0.0095
2024-11-28 16:33:36.163816: Validation loss improved from -0.68105 to -0.68563! Patience: 26/50
2024-11-28 16:33:36.165531: train_loss -0.7969
2024-11-28 16:33:36.166301: val_loss -0.6856
2024-11-28 16:33:36.167034: Pseudo dice [0.7602]
2024-11-28 16:33:36.167878: Epoch time: 47.0 s
2024-11-28 16:33:36.168729: Yayy! New best EMA pseudo Dice: 0.7371
2024-11-28 16:33:37.955485: 
2024-11-28 16:33:37.956858: Epoch 56
2024-11-28 16:33:37.957702: Current learning rate: 0.00949
2024-11-28 16:34:24.918567: Validation loss did not improve from -0.68563. Patience: 1/50
2024-11-28 16:34:24.920189: train_loss -0.7984
2024-11-28 16:34:24.921085: val_loss -0.6288
2024-11-28 16:34:24.921849: Pseudo dice [0.7175]
2024-11-28 16:34:24.922510: Epoch time: 46.97 s
2024-11-28 16:34:26.175422: 
2024-11-28 16:34:26.177071: Epoch 57
2024-11-28 16:34:26.177830: Current learning rate: 0.00949
2024-11-28 16:35:13.140409: Validation loss did not improve from -0.68563. Patience: 2/50
2024-11-28 16:35:13.142196: train_loss -0.7973
2024-11-28 16:35:13.143097: val_loss -0.6625
2024-11-28 16:35:13.143879: Pseudo dice [0.7469]
2024-11-28 16:35:13.144645: Epoch time: 46.97 s
2024-11-28 16:35:14.430289: 
2024-11-28 16:35:14.432015: Epoch 58
2024-11-28 16:35:14.432861: Current learning rate: 0.00948
2024-11-28 16:36:01.426305: Validation loss did not improve from -0.68563. Patience: 3/50
2024-11-28 16:36:01.428190: train_loss -0.8006
2024-11-28 16:36:01.428986: val_loss -0.6562
2024-11-28 16:36:01.429656: Pseudo dice [0.7445]
2024-11-28 16:36:01.430335: Epoch time: 47.0 s
2024-11-28 16:36:01.430887: Yayy! New best EMA pseudo Dice: 0.7372
2024-11-28 16:36:03.264958: 
2024-11-28 16:36:03.266178: Epoch 59
2024-11-28 16:36:03.266956: Current learning rate: 0.00947
2024-11-28 16:36:50.319938: Validation loss did not improve from -0.68563. Patience: 4/50
2024-11-28 16:36:50.321147: train_loss -0.8015
2024-11-28 16:36:50.321841: val_loss -0.6638
2024-11-28 16:36:50.322447: Pseudo dice [0.7476]
2024-11-28 16:36:50.323190: Epoch time: 47.06 s
2024-11-28 16:36:50.873774: Yayy! New best EMA pseudo Dice: 0.7382
2024-11-28 16:36:52.712139: 
2024-11-28 16:36:52.713758: Epoch 60
2024-11-28 16:36:52.714589: Current learning rate: 0.00946
2024-11-28 16:37:39.706911: Validation loss did not improve from -0.68563. Patience: 5/50
2024-11-28 16:37:39.708441: train_loss -0.804
2024-11-28 16:37:39.709155: val_loss -0.6703
2024-11-28 16:37:39.709952: Pseudo dice [0.7524]
2024-11-28 16:37:39.710692: Epoch time: 47.0 s
2024-11-28 16:37:39.711357: Yayy! New best EMA pseudo Dice: 0.7396
2024-11-28 16:37:42.131653: 
2024-11-28 16:37:42.133484: Epoch 61
2024-11-28 16:37:42.134244: Current learning rate: 0.00945
2024-11-28 16:38:29.083692: Validation loss did not improve from -0.68563. Patience: 6/50
2024-11-28 16:38:29.085345: train_loss -0.8023
2024-11-28 16:38:29.086154: val_loss -0.6779
2024-11-28 16:38:29.086901: Pseudo dice [0.7578]
2024-11-28 16:38:29.087549: Epoch time: 46.95 s
2024-11-28 16:38:29.088248: Yayy! New best EMA pseudo Dice: 0.7414
2024-11-28 16:38:30.927659: 
2024-11-28 16:38:30.929380: Epoch 62
2024-11-28 16:38:30.930187: Current learning rate: 0.00944
2024-11-28 16:39:18.454517: Validation loss did not improve from -0.68563. Patience: 7/50
2024-11-28 16:39:18.456148: train_loss -0.8036
2024-11-28 16:39:18.457064: val_loss -0.6722
2024-11-28 16:39:18.457919: Pseudo dice [0.7523]
2024-11-28 16:39:18.458659: Epoch time: 47.53 s
2024-11-28 16:39:18.459267: Yayy! New best EMA pseudo Dice: 0.7425
2024-11-28 16:39:20.303572: 
2024-11-28 16:39:20.305143: Epoch 63
2024-11-28 16:39:20.305997: Current learning rate: 0.00943
2024-11-28 16:40:07.319422: Validation loss did not improve from -0.68563. Patience: 8/50
2024-11-28 16:40:07.321454: train_loss -0.8048
2024-11-28 16:40:07.322280: val_loss -0.6762
2024-11-28 16:40:07.323092: Pseudo dice [0.7562]
2024-11-28 16:40:07.323815: Epoch time: 47.02 s
2024-11-28 16:40:07.324572: Yayy! New best EMA pseudo Dice: 0.7439
2024-11-28 16:40:09.302858: 
2024-11-28 16:40:09.306170: Epoch 64
2024-11-28 16:40:09.307768: Current learning rate: 0.00942
2024-11-28 16:40:56.404689: Validation loss did not improve from -0.68563. Patience: 9/50
2024-11-28 16:40:56.406598: train_loss -0.8078
2024-11-28 16:40:56.407739: val_loss -0.6635
2024-11-28 16:40:56.408836: Pseudo dice [0.7495]
2024-11-28 16:40:56.409855: Epoch time: 47.11 s
2024-11-28 16:40:56.983370: Yayy! New best EMA pseudo Dice: 0.7444
2024-11-28 16:40:58.837568: 
2024-11-28 16:40:58.838816: Epoch 65
2024-11-28 16:40:58.839688: Current learning rate: 0.00941
2024-11-28 16:41:45.792902: Validation loss improved from -0.68563 to -0.69349! Patience: 9/50
2024-11-28 16:41:45.794448: train_loss -0.8072
2024-11-28 16:41:45.795229: val_loss -0.6935
2024-11-28 16:41:45.795962: Pseudo dice [0.7708]
2024-11-28 16:41:45.796664: Epoch time: 46.96 s
2024-11-28 16:41:45.797481: Yayy! New best EMA pseudo Dice: 0.7471
2024-11-28 16:41:47.639464: 
2024-11-28 16:41:47.641632: Epoch 66
2024-11-28 16:41:47.642397: Current learning rate: 0.0094
2024-11-28 16:42:34.694424: Validation loss did not improve from -0.69349. Patience: 1/50
2024-11-28 16:42:34.695752: train_loss -0.8014
2024-11-28 16:42:34.696537: val_loss -0.6443
2024-11-28 16:42:34.697217: Pseudo dice [0.7323]
2024-11-28 16:42:34.697813: Epoch time: 47.06 s
2024-11-28 16:42:35.983039: 
2024-11-28 16:42:35.984380: Epoch 67
2024-11-28 16:42:35.985354: Current learning rate: 0.00939
2024-11-28 16:43:23.018442: Validation loss did not improve from -0.69349. Patience: 2/50
2024-11-28 16:43:23.019736: train_loss -0.8044
2024-11-28 16:43:23.020515: val_loss -0.6634
2024-11-28 16:43:23.021293: Pseudo dice [0.7509]
2024-11-28 16:43:23.022089: Epoch time: 47.04 s
2024-11-28 16:43:24.344394: 
2024-11-28 16:43:24.345915: Epoch 68
2024-11-28 16:43:24.346955: Current learning rate: 0.00939
2024-11-28 16:44:11.382084: Validation loss did not improve from -0.69349. Patience: 3/50
2024-11-28 16:44:11.383203: train_loss -0.8015
2024-11-28 16:44:11.383851: val_loss -0.6764
2024-11-28 16:44:11.384490: Pseudo dice [0.7569]
2024-11-28 16:44:11.385336: Epoch time: 47.04 s
2024-11-28 16:44:11.386023: Yayy! New best EMA pseudo Dice: 0.7472
2024-11-28 16:44:13.293543: 
2024-11-28 16:44:13.294934: Epoch 69
2024-11-28 16:44:13.295604: Current learning rate: 0.00938
2024-11-28 16:45:00.324551: Validation loss did not improve from -0.69349. Patience: 4/50
2024-11-28 16:45:00.325690: train_loss -0.8109
2024-11-28 16:45:00.326372: val_loss -0.6512
2024-11-28 16:45:00.327168: Pseudo dice [0.7376]
2024-11-28 16:45:00.328481: Epoch time: 47.03 s
2024-11-28 16:45:02.219387: 
2024-11-28 16:45:02.220943: Epoch 70
2024-11-28 16:45:02.221856: Current learning rate: 0.00937
2024-11-28 16:45:49.231128: Validation loss did not improve from -0.69349. Patience: 5/50
2024-11-28 16:45:49.232594: train_loss -0.8111
2024-11-28 16:45:49.233665: val_loss -0.6842
2024-11-28 16:45:49.234449: Pseudo dice [0.7596]
2024-11-28 16:45:49.235200: Epoch time: 47.01 s
2024-11-28 16:45:49.235941: Yayy! New best EMA pseudo Dice: 0.7476
2024-11-28 16:45:51.135582: 
2024-11-28 16:45:51.136794: Epoch 71
2024-11-28 16:45:51.137677: Current learning rate: 0.00936
2024-11-28 16:46:38.168746: Validation loss did not improve from -0.69349. Patience: 6/50
2024-11-28 16:46:38.170851: train_loss -0.8074
2024-11-28 16:46:38.171770: val_loss -0.6472
2024-11-28 16:46:38.172467: Pseudo dice [0.735]
2024-11-28 16:46:38.173261: Epoch time: 47.04 s
2024-11-28 16:46:39.476802: 
2024-11-28 16:46:39.478054: Epoch 72
2024-11-28 16:46:39.479237: Current learning rate: 0.00935
2024-11-28 16:47:26.909189: Validation loss did not improve from -0.69349. Patience: 7/50
2024-11-28 16:47:26.910647: train_loss -0.8162
2024-11-28 16:47:26.911574: val_loss -0.6692
2024-11-28 16:47:26.912364: Pseudo dice [0.7485]
2024-11-28 16:47:26.913122: Epoch time: 47.44 s
2024-11-28 16:47:28.230623: 
2024-11-28 16:47:28.232468: Epoch 73
2024-11-28 16:47:28.233485: Current learning rate: 0.00934
2024-11-28 16:48:15.242661: Validation loss did not improve from -0.69349. Patience: 8/50
2024-11-28 16:48:15.243974: train_loss -0.8177
2024-11-28 16:48:15.244762: val_loss -0.6821
2024-11-28 16:48:15.245502: Pseudo dice [0.7588]
2024-11-28 16:48:15.246112: Epoch time: 47.01 s
2024-11-28 16:48:15.246775: Yayy! New best EMA pseudo Dice: 0.7478
2024-11-28 16:48:17.111346: 
2024-11-28 16:48:17.112323: Epoch 74
2024-11-28 16:48:17.113157: Current learning rate: 0.00933
2024-11-28 16:49:04.142278: Validation loss improved from -0.69349 to -0.69844! Patience: 8/50
2024-11-28 16:49:04.144191: train_loss -0.8117
2024-11-28 16:49:04.144862: val_loss -0.6984
2024-11-28 16:49:04.145505: Pseudo dice [0.7726]
2024-11-28 16:49:04.146049: Epoch time: 47.03 s
2024-11-28 16:49:04.712250: Yayy! New best EMA pseudo Dice: 0.7502
2024-11-28 16:49:06.616927: 
2024-11-28 16:49:06.618599: Epoch 75
2024-11-28 16:49:06.619347: Current learning rate: 0.00932
2024-11-28 16:49:53.655246: Validation loss did not improve from -0.69844. Patience: 1/50
2024-11-28 16:49:53.656472: train_loss -0.8094
2024-11-28 16:49:53.657344: val_loss -0.6474
2024-11-28 16:49:53.658186: Pseudo dice [0.739]
2024-11-28 16:49:53.658990: Epoch time: 47.04 s
2024-11-28 16:49:54.986360: 
2024-11-28 16:49:54.988124: Epoch 76
2024-11-28 16:49:54.988986: Current learning rate: 0.00931
2024-11-28 16:50:41.977584: Validation loss did not improve from -0.69844. Patience: 2/50
2024-11-28 16:50:41.979248: train_loss -0.8083
2024-11-28 16:50:41.979996: val_loss -0.6427
2024-11-28 16:50:41.980651: Pseudo dice [0.738]
2024-11-28 16:50:41.981435: Epoch time: 46.99 s
2024-11-28 16:50:43.296583: 
2024-11-28 16:50:43.297638: Epoch 77
2024-11-28 16:50:43.298238: Current learning rate: 0.0093
2024-11-28 16:51:30.397214: Validation loss did not improve from -0.69844. Patience: 3/50
2024-11-28 16:51:30.399179: train_loss -0.8144
2024-11-28 16:51:30.399956: val_loss -0.6608
2024-11-28 16:51:30.400710: Pseudo dice [0.7418]
2024-11-28 16:51:30.401502: Epoch time: 47.1 s
2024-11-28 16:51:31.775429: 
2024-11-28 16:51:31.777156: Epoch 78
2024-11-28 16:51:31.778150: Current learning rate: 0.0093
2024-11-28 16:52:18.989110: Validation loss did not improve from -0.69844. Patience: 4/50
2024-11-28 16:52:18.992862: train_loss -0.8135
2024-11-28 16:52:18.994037: val_loss -0.6663
2024-11-28 16:52:18.995099: Pseudo dice [0.7501]
2024-11-28 16:52:18.995994: Epoch time: 47.22 s
2024-11-28 16:52:20.456377: 
2024-11-28 16:52:20.457871: Epoch 79
2024-11-28 16:52:20.459015: Current learning rate: 0.00929
2024-11-28 16:53:07.501170: Validation loss did not improve from -0.69844. Patience: 5/50
2024-11-28 16:53:07.502766: train_loss -0.8111
2024-11-28 16:53:07.503392: val_loss -0.6533
2024-11-28 16:53:07.503975: Pseudo dice [0.7441]
2024-11-28 16:53:07.504709: Epoch time: 47.05 s
2024-11-28 16:53:09.430372: 
2024-11-28 16:53:09.431578: Epoch 80
2024-11-28 16:53:09.432520: Current learning rate: 0.00928
2024-11-28 16:53:56.511828: Validation loss did not improve from -0.69844. Patience: 6/50
2024-11-28 16:53:56.513327: train_loss -0.8173
2024-11-28 16:53:56.514098: val_loss -0.6606
2024-11-28 16:53:56.514838: Pseudo dice [0.744]
2024-11-28 16:53:56.515486: Epoch time: 47.08 s
2024-11-28 16:53:57.842696: 
2024-11-28 16:53:57.844383: Epoch 81
2024-11-28 16:53:57.845206: Current learning rate: 0.00927
2024-11-28 16:54:44.863483: Validation loss did not improve from -0.69844. Patience: 7/50
2024-11-28 16:54:44.865347: train_loss -0.8139
2024-11-28 16:54:44.866275: val_loss -0.656
2024-11-28 16:54:44.867230: Pseudo dice [0.7402]
2024-11-28 16:54:44.868135: Epoch time: 47.02 s
2024-11-28 16:54:46.195012: 
2024-11-28 16:54:46.196130: Epoch 82
2024-11-28 16:54:46.197215: Current learning rate: 0.00926
2024-11-28 16:55:33.175992: Validation loss did not improve from -0.69844. Patience: 8/50
2024-11-28 16:55:33.177796: train_loss -0.8199
2024-11-28 16:55:33.178615: val_loss -0.6675
2024-11-28 16:55:33.179254: Pseudo dice [0.7505]
2024-11-28 16:55:33.179934: Epoch time: 46.98 s
2024-11-28 16:55:35.036252: 
2024-11-28 16:55:35.038025: Epoch 83
2024-11-28 16:55:35.038779: Current learning rate: 0.00925
2024-11-28 16:56:22.007676: Validation loss did not improve from -0.69844. Patience: 9/50
2024-11-28 16:56:22.009521: train_loss -0.8242
2024-11-28 16:56:22.010356: val_loss -0.6002
2024-11-28 16:56:22.011088: Pseudo dice [0.7057]
2024-11-28 16:56:22.011828: Epoch time: 46.97 s
2024-11-28 16:56:23.254342: 
2024-11-28 16:56:23.255959: Epoch 84
2024-11-28 16:56:23.256855: Current learning rate: 0.00924
2024-11-28 16:57:10.253228: Validation loss did not improve from -0.69844. Patience: 10/50
2024-11-28 16:57:10.255106: train_loss -0.8221
2024-11-28 16:57:10.255992: val_loss -0.6503
2024-11-28 16:57:10.256709: Pseudo dice [0.7415]
2024-11-28 16:57:10.257467: Epoch time: 47.0 s
2024-11-28 16:57:12.086656: 
2024-11-28 16:57:12.088227: Epoch 85
2024-11-28 16:57:12.089025: Current learning rate: 0.00923
2024-11-28 16:57:59.090394: Validation loss did not improve from -0.69844. Patience: 11/50
2024-11-28 16:57:59.092212: train_loss -0.8146
2024-11-28 16:57:59.093059: val_loss -0.6902
2024-11-28 16:57:59.093895: Pseudo dice [0.7635]
2024-11-28 16:57:59.094680: Epoch time: 47.01 s
2024-11-28 16:58:00.410792: 
2024-11-28 16:58:00.412486: Epoch 86
2024-11-28 16:58:00.413382: Current learning rate: 0.00922
2024-11-28 16:58:47.368065: Validation loss did not improve from -0.69844. Patience: 12/50
2024-11-28 16:58:47.369709: train_loss -0.8176
2024-11-28 16:58:47.370425: val_loss -0.6578
2024-11-28 16:58:47.371095: Pseudo dice [0.7406]
2024-11-28 16:58:47.371746: Epoch time: 46.96 s
2024-11-28 16:58:48.640846: 
2024-11-28 16:58:48.642483: Epoch 87
2024-11-28 16:58:48.643488: Current learning rate: 0.00921
2024-11-28 16:59:35.614138: Validation loss did not improve from -0.69844. Patience: 13/50
2024-11-28 16:59:35.616159: train_loss -0.8237
2024-11-28 16:59:35.617257: val_loss -0.6745
2024-11-28 16:59:35.618263: Pseudo dice [0.761]
2024-11-28 16:59:35.619296: Epoch time: 46.98 s
2024-11-28 16:59:36.890166: 
2024-11-28 16:59:36.891725: Epoch 88
2024-11-28 16:59:36.892638: Current learning rate: 0.0092
2024-11-28 17:00:23.940791: Validation loss did not improve from -0.69844. Patience: 14/50
2024-11-28 17:00:23.942566: train_loss -0.8215
2024-11-28 17:00:23.943448: val_loss -0.678
2024-11-28 17:00:23.944272: Pseudo dice [0.7595]
2024-11-28 17:00:23.945125: Epoch time: 47.05 s
2024-11-28 17:00:25.218670: 
2024-11-28 17:00:25.219920: Epoch 89
2024-11-28 17:00:25.220983: Current learning rate: 0.0092
2024-11-28 17:01:12.256084: Validation loss did not improve from -0.69844. Patience: 15/50
2024-11-28 17:01:12.257726: train_loss -0.8213
2024-11-28 17:01:12.258458: val_loss -0.6746
2024-11-28 17:01:12.259265: Pseudo dice [0.7556]
2024-11-28 17:01:12.259910: Epoch time: 47.04 s
2024-11-28 17:01:14.101259: 
2024-11-28 17:01:14.102779: Epoch 90
2024-11-28 17:01:14.103651: Current learning rate: 0.00919
2024-11-28 17:02:01.071366: Validation loss did not improve from -0.69844. Patience: 16/50
2024-11-28 17:02:01.073401: train_loss -0.8247
2024-11-28 17:02:01.074381: val_loss -0.6791
2024-11-28 17:02:01.075222: Pseudo dice [0.7568]
2024-11-28 17:02:01.075983: Epoch time: 46.97 s
2024-11-28 17:02:02.335049: 
2024-11-28 17:02:02.336771: Epoch 91
2024-11-28 17:02:02.337774: Current learning rate: 0.00918
2024-11-28 17:02:49.392897: Validation loss did not improve from -0.69844. Patience: 17/50
2024-11-28 17:02:49.394884: train_loss -0.8253
2024-11-28 17:02:49.395566: val_loss -0.6833
2024-11-28 17:02:49.396297: Pseudo dice [0.7586]
2024-11-28 17:02:49.396908: Epoch time: 47.06 s
2024-11-28 17:02:50.671554: 
2024-11-28 17:02:50.672459: Epoch 92
2024-11-28 17:02:50.673211: Current learning rate: 0.00917
2024-11-28 17:03:37.701298: Validation loss did not improve from -0.69844. Patience: 18/50
2024-11-28 17:03:37.702783: train_loss -0.8221
2024-11-28 17:03:37.703595: val_loss -0.6518
2024-11-28 17:03:37.704374: Pseudo dice [0.741]
2024-11-28 17:03:37.705044: Epoch time: 47.03 s
2024-11-28 17:03:38.934981: 
2024-11-28 17:03:38.936462: Epoch 93
2024-11-28 17:03:38.937235: Current learning rate: 0.00916
2024-11-28 17:04:25.919935: Validation loss did not improve from -0.69844. Patience: 19/50
2024-11-28 17:04:25.921274: train_loss -0.8259
2024-11-28 17:04:25.922261: val_loss -0.6785
2024-11-28 17:04:25.923109: Pseudo dice [0.7579]
2024-11-28 17:04:25.924129: Epoch time: 46.99 s
2024-11-28 17:04:27.139349: 
2024-11-28 17:04:27.141267: Epoch 94
2024-11-28 17:04:27.142304: Current learning rate: 0.00915
2024-11-28 17:05:14.168844: Validation loss did not improve from -0.69844. Patience: 20/50
2024-11-28 17:05:14.169868: train_loss -0.8204
2024-11-28 17:05:14.170527: val_loss -0.6449
2024-11-28 17:05:14.171093: Pseudo dice [0.7273]
2024-11-28 17:05:14.171690: Epoch time: 47.03 s
2024-11-28 17:05:16.513896: 
2024-11-28 17:05:16.515484: Epoch 95
2024-11-28 17:05:16.516348: Current learning rate: 0.00914
2024-11-28 17:06:03.535148: Validation loss did not improve from -0.69844. Patience: 21/50
2024-11-28 17:06:03.536368: train_loss -0.8222
2024-11-28 17:06:03.537380: val_loss -0.6524
2024-11-28 17:06:03.538268: Pseudo dice [0.737]
2024-11-28 17:06:03.539093: Epoch time: 47.02 s
2024-11-28 17:06:04.765259: 
2024-11-28 17:06:04.766451: Epoch 96
2024-11-28 17:06:04.767449: Current learning rate: 0.00913
2024-11-28 17:06:51.746983: Validation loss did not improve from -0.69844. Patience: 22/50
2024-11-28 17:06:51.749029: train_loss -0.8242
2024-11-28 17:06:51.749828: val_loss -0.6529
2024-11-28 17:06:51.750693: Pseudo dice [0.7386]
2024-11-28 17:06:51.751629: Epoch time: 46.99 s
2024-11-28 17:06:52.991984: 
2024-11-28 17:06:52.993928: Epoch 97
2024-11-28 17:06:52.994976: Current learning rate: 0.00912
2024-11-28 17:07:40.001804: Validation loss did not improve from -0.69844. Patience: 23/50
2024-11-28 17:07:40.003052: train_loss -0.8271
2024-11-28 17:07:40.003759: val_loss -0.6534
2024-11-28 17:07:40.004402: Pseudo dice [0.7381]
2024-11-28 17:07:40.005064: Epoch time: 47.01 s
2024-11-28 17:07:41.308301: 
2024-11-28 17:07:41.309940: Epoch 98
2024-11-28 17:07:41.310931: Current learning rate: 0.00911
2024-11-28 17:08:28.365973: Validation loss did not improve from -0.69844. Patience: 24/50
2024-11-28 17:08:28.367691: train_loss -0.8265
2024-11-28 17:08:28.368573: val_loss -0.6965
2024-11-28 17:08:28.369258: Pseudo dice [0.7734]
2024-11-28 17:08:28.370117: Epoch time: 47.06 s
2024-11-28 17:08:29.664119: 
2024-11-28 17:08:29.665683: Epoch 99
2024-11-28 17:08:29.666811: Current learning rate: 0.0091
2024-11-28 17:09:16.729412: Validation loss did not improve from -0.69844. Patience: 25/50
2024-11-28 17:09:16.731412: train_loss -0.8276
2024-11-28 17:09:16.732313: val_loss -0.6527
2024-11-28 17:09:16.733293: Pseudo dice [0.743]
2024-11-28 17:09:16.734257: Epoch time: 47.07 s
2024-11-28 17:09:18.594558: 
2024-11-28 17:09:18.595965: Epoch 100
2024-11-28 17:09:18.597015: Current learning rate: 0.0091
2024-11-28 17:10:05.616401: Validation loss did not improve from -0.69844. Patience: 26/50
2024-11-28 17:10:05.618265: train_loss -0.8345
2024-11-28 17:10:05.619057: val_loss -0.6818
2024-11-28 17:10:05.619793: Pseudo dice [0.7539]
2024-11-28 17:10:05.620565: Epoch time: 47.02 s
2024-11-28 17:10:06.895370: 
2024-11-28 17:10:06.897251: Epoch 101
2024-11-28 17:10:06.898251: Current learning rate: 0.00909
2024-11-28 17:10:53.916281: Validation loss did not improve from -0.69844. Patience: 27/50
2024-11-28 17:10:53.917874: train_loss -0.8325
2024-11-28 17:10:53.918616: val_loss -0.6415
2024-11-28 17:10:53.919315: Pseudo dice [0.7287]
2024-11-28 17:10:53.920099: Epoch time: 47.02 s
2024-11-28 17:10:55.183049: 
2024-11-28 17:10:55.185694: Epoch 102
2024-11-28 17:10:55.186502: Current learning rate: 0.00908
2024-11-28 17:11:42.247342: Validation loss did not improve from -0.69844. Patience: 28/50
2024-11-28 17:11:42.249145: train_loss -0.8285
2024-11-28 17:11:42.249847: val_loss -0.6657
2024-11-28 17:11:42.250662: Pseudo dice [0.7479]
2024-11-28 17:11:42.251487: Epoch time: 47.07 s
2024-11-28 17:11:43.517999: 
2024-11-28 17:11:43.519592: Epoch 103
2024-11-28 17:11:43.520417: Current learning rate: 0.00907
2024-11-28 17:12:30.562096: Validation loss did not improve from -0.69844. Patience: 29/50
2024-11-28 17:12:30.563950: train_loss -0.8348
2024-11-28 17:12:30.564786: val_loss -0.6606
2024-11-28 17:12:30.565522: Pseudo dice [0.7446]
2024-11-28 17:12:30.566257: Epoch time: 47.05 s
2024-11-28 17:12:31.866629: 
2024-11-28 17:12:31.868587: Epoch 104
2024-11-28 17:12:31.869368: Current learning rate: 0.00906
2024-11-28 17:13:18.890026: Validation loss did not improve from -0.69844. Patience: 30/50
2024-11-28 17:13:18.891843: train_loss -0.8339
2024-11-28 17:13:18.892672: val_loss -0.654
2024-11-28 17:13:18.893587: Pseudo dice [0.7391]
2024-11-28 17:13:18.894197: Epoch time: 47.03 s
2024-11-28 17:13:20.788893: 
2024-11-28 17:13:20.790645: Epoch 105
2024-11-28 17:13:20.791401: Current learning rate: 0.00905
2024-11-28 17:14:07.828379: Validation loss did not improve from -0.69844. Patience: 31/50
2024-11-28 17:14:07.830130: train_loss -0.8274
2024-11-28 17:14:07.831090: val_loss -0.6608
2024-11-28 17:14:07.831982: Pseudo dice [0.7478]
2024-11-28 17:14:07.832834: Epoch time: 47.04 s
2024-11-28 17:14:09.571036: 
2024-11-28 17:14:09.572731: Epoch 106
2024-11-28 17:14:09.573558: Current learning rate: 0.00904
2024-11-28 17:14:56.625201: Validation loss did not improve from -0.69844. Patience: 32/50
2024-11-28 17:14:56.626459: train_loss -0.8325
2024-11-28 17:14:56.627261: val_loss -0.684
2024-11-28 17:14:56.627865: Pseudo dice [0.7601]
2024-11-28 17:14:56.628640: Epoch time: 47.06 s
2024-11-28 17:14:57.879508: 
2024-11-28 17:14:57.880388: Epoch 107
2024-11-28 17:14:57.881155: Current learning rate: 0.00903
2024-11-28 17:15:44.872456: Validation loss did not improve from -0.69844. Patience: 33/50
2024-11-28 17:15:44.874503: train_loss -0.8306
2024-11-28 17:15:44.875453: val_loss -0.6507
2024-11-28 17:15:44.876234: Pseudo dice [0.7431]
2024-11-28 17:15:44.876957: Epoch time: 47.0 s
2024-11-28 17:15:46.150991: 
2024-11-28 17:15:46.152426: Epoch 108
2024-11-28 17:15:46.153435: Current learning rate: 0.00902
2024-11-28 17:16:33.207973: Validation loss did not improve from -0.69844. Patience: 34/50
2024-11-28 17:16:33.209350: train_loss -0.8229
2024-11-28 17:16:33.210140: val_loss -0.669
2024-11-28 17:16:33.211042: Pseudo dice [0.7537]
2024-11-28 17:16:33.211969: Epoch time: 47.06 s
2024-11-28 17:16:34.460561: 
2024-11-28 17:16:34.461901: Epoch 109
2024-11-28 17:16:34.462626: Current learning rate: 0.00901
2024-11-28 17:17:21.515340: Validation loss did not improve from -0.69844. Patience: 35/50
2024-11-28 17:17:21.516357: train_loss -0.8336
2024-11-28 17:17:21.517025: val_loss -0.6662
2024-11-28 17:17:21.517704: Pseudo dice [0.7501]
2024-11-28 17:17:21.518360: Epoch time: 47.06 s
2024-11-28 17:17:23.373103: 
2024-11-28 17:17:23.374447: Epoch 110
2024-11-28 17:17:23.375405: Current learning rate: 0.009
2024-11-28 17:18:10.423862: Validation loss did not improve from -0.69844. Patience: 36/50
2024-11-28 17:18:10.425827: train_loss -0.8308
2024-11-28 17:18:10.427001: val_loss -0.6747
2024-11-28 17:18:10.427801: Pseudo dice [0.7556]
2024-11-28 17:18:10.428597: Epoch time: 47.05 s
2024-11-28 17:18:11.698952: 
2024-11-28 17:18:11.700472: Epoch 111
2024-11-28 17:18:11.701433: Current learning rate: 0.009
2024-11-28 17:18:58.757981: Validation loss did not improve from -0.69844. Patience: 37/50
2024-11-28 17:18:58.759639: train_loss -0.8295
2024-11-28 17:18:58.760368: val_loss -0.6837
2024-11-28 17:18:58.761259: Pseudo dice [0.7641]
2024-11-28 17:18:58.762103: Epoch time: 47.06 s
2024-11-28 17:19:00.026656: 
2024-11-28 17:19:00.028366: Epoch 112
2024-11-28 17:19:00.029165: Current learning rate: 0.00899
2024-11-28 17:19:47.067086: Validation loss did not improve from -0.69844. Patience: 38/50
2024-11-28 17:19:47.068649: train_loss -0.8301
2024-11-28 17:19:47.069355: val_loss -0.6516
2024-11-28 17:19:47.070182: Pseudo dice [0.7356]
2024-11-28 17:19:47.070790: Epoch time: 47.04 s
2024-11-28 17:19:48.332289: 
2024-11-28 17:19:48.333705: Epoch 113
2024-11-28 17:19:48.334532: Current learning rate: 0.00898
2024-11-28 17:20:35.359376: Validation loss did not improve from -0.69844. Patience: 39/50
2024-11-28 17:20:35.360959: train_loss -0.8348
2024-11-28 17:20:35.361660: val_loss -0.6555
2024-11-28 17:20:35.362428: Pseudo dice [0.748]
2024-11-28 17:20:35.363153: Epoch time: 47.03 s
2024-11-28 17:20:36.651152: 
2024-11-28 17:20:36.652561: Epoch 114
2024-11-28 17:20:36.653345: Current learning rate: 0.00897
2024-11-28 17:21:23.682570: Validation loss did not improve from -0.69844. Patience: 40/50
2024-11-28 17:21:23.684545: train_loss -0.8287
2024-11-28 17:21:23.685300: val_loss -0.6503
2024-11-28 17:21:23.685908: Pseudo dice [0.7342]
2024-11-28 17:21:23.686592: Epoch time: 47.03 s
2024-11-28 17:21:25.546484: 
2024-11-28 17:21:25.548240: Epoch 115
2024-11-28 17:21:25.549011: Current learning rate: 0.00896
2024-11-28 17:22:12.557146: Validation loss did not improve from -0.69844. Patience: 41/50
2024-11-28 17:22:12.558836: train_loss -0.8274
2024-11-28 17:22:12.559504: val_loss -0.6427
2024-11-28 17:22:12.560229: Pseudo dice [0.7378]
2024-11-28 17:22:12.561060: Epoch time: 47.01 s
2024-11-28 17:22:13.846480: 
2024-11-28 17:22:13.848130: Epoch 116
2024-11-28 17:22:13.849034: Current learning rate: 0.00895
2024-11-28 17:23:00.890141: Validation loss did not improve from -0.69844. Patience: 42/50
2024-11-28 17:23:00.892053: train_loss -0.8254
2024-11-28 17:23:00.893037: val_loss -0.6655
2024-11-28 17:23:00.893759: Pseudo dice [0.7558]
2024-11-28 17:23:00.894433: Epoch time: 47.05 s
2024-11-28 17:23:02.177320: 
2024-11-28 17:23:02.178823: Epoch 117
2024-11-28 17:23:02.179701: Current learning rate: 0.00894
2024-11-28 17:23:49.203865: Validation loss did not improve from -0.69844. Patience: 43/50
2024-11-28 17:23:49.205809: train_loss -0.8331
2024-11-28 17:23:49.206524: val_loss -0.6727
2024-11-28 17:23:49.207284: Pseudo dice [0.7558]
2024-11-28 17:23:49.207995: Epoch time: 47.03 s
2024-11-28 17:23:50.974743: 
2024-11-28 17:23:50.975758: Epoch 118
2024-11-28 17:23:50.976509: Current learning rate: 0.00893
2024-11-28 17:24:37.938650: Validation loss did not improve from -0.69844. Patience: 44/50
2024-11-28 17:24:37.940246: train_loss -0.8341
2024-11-28 17:24:37.941418: val_loss -0.6819
2024-11-28 17:24:37.942504: Pseudo dice [0.7615]
2024-11-28 17:24:37.943729: Epoch time: 46.97 s
2024-11-28 17:24:39.214632: 
2024-11-28 17:24:39.215648: Epoch 119
2024-11-28 17:24:39.216368: Current learning rate: 0.00892
2024-11-28 17:25:26.226108: Validation loss did not improve from -0.69844. Patience: 45/50
2024-11-28 17:25:26.227583: train_loss -0.8306
2024-11-28 17:25:26.228396: val_loss -0.6719
2024-11-28 17:25:26.229139: Pseudo dice [0.7571]
2024-11-28 17:25:26.229908: Epoch time: 47.01 s
2024-11-28 17:25:28.101686: 
2024-11-28 17:25:28.102967: Epoch 120
2024-11-28 17:25:28.103997: Current learning rate: 0.00891
2024-11-28 17:26:15.149391: Validation loss did not improve from -0.69844. Patience: 46/50
2024-11-28 17:26:15.150904: train_loss -0.8434
2024-11-28 17:26:15.151583: val_loss -0.66
2024-11-28 17:26:15.152277: Pseudo dice [0.7473]
2024-11-28 17:26:15.153046: Epoch time: 47.05 s
2024-11-28 17:26:16.436121: 
2024-11-28 17:26:16.437563: Epoch 121
2024-11-28 17:26:16.438222: Current learning rate: 0.0089
2024-11-28 17:27:03.473381: Validation loss did not improve from -0.69844. Patience: 47/50
2024-11-28 17:27:03.475400: train_loss -0.8379
2024-11-28 17:27:03.476282: val_loss -0.668
2024-11-28 17:27:03.477018: Pseudo dice [0.7502]
2024-11-28 17:27:03.477859: Epoch time: 47.04 s
2024-11-28 17:27:04.764287: 
2024-11-28 17:27:04.765700: Epoch 122
2024-11-28 17:27:04.766477: Current learning rate: 0.00889
2024-11-28 17:27:51.776126: Validation loss did not improve from -0.69844. Patience: 48/50
2024-11-28 17:27:51.777964: train_loss -0.8325
2024-11-28 17:27:51.779075: val_loss -0.6449
2024-11-28 17:27:51.780100: Pseudo dice [0.7406]
2024-11-28 17:27:51.781041: Epoch time: 47.02 s
2024-11-28 17:27:53.095020: 
2024-11-28 17:27:53.096348: Epoch 123
2024-11-28 17:27:53.097290: Current learning rate: 0.00889
2024-11-28 17:28:40.121726: Validation loss did not improve from -0.69844. Patience: 49/50
2024-11-28 17:28:40.123424: train_loss -0.8395
2024-11-28 17:28:40.124339: val_loss -0.6351
2024-11-28 17:28:40.125168: Pseudo dice [0.7279]
2024-11-28 17:28:40.125997: Epoch time: 47.03 s
2024-11-28 17:28:41.436934: 
2024-11-28 17:28:41.438193: Epoch 124
2024-11-28 17:28:41.439406: Current learning rate: 0.00888
2024-11-28 17:29:28.496811: Validation loss did not improve from -0.69844. Patience: 50/50
2024-11-28 17:29:28.498717: train_loss -0.8335
2024-11-28 17:29:28.499757: val_loss -0.65
2024-11-28 17:29:28.500757: Pseudo dice [0.7394]
2024-11-28 17:29:28.501692: Epoch time: 47.06 s
2024-11-28 17:29:30.389749: Patience reached. Stopping training.
2024-11-28 17:29:30.952317: Training done.
2024-11-28 17:29:31.301898: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset306_Sohee_Ajay_Calcium_OCT/splits_final.json
2024-11-28 17:29:31.304156: The split file contains 5 splits.
2024-11-28 17:29:31.304840: Desired fold for training: 1
2024-11-28 17:29:31.305564: This split has 10 training and 3 validation cases.
2024-11-28 17:29:31.306394: predicting 101-019
2024-11-28 17:29:31.315557: 101-019, shape torch.Size([1, 375, 498, 498]), rank 0
2024-11-28 17:30:05.053209: predicting 101009Pre
2024-11-28 17:30:05.077067: 101009Pre, shape torch.Size([1, 230, 498, 498]), rank 0
2024-11-28 17:30:11.210770: predicting 704-003
2024-11-28 17:30:11.226135: 704-003, shape torch.Size([1, 375, 498, 498]), rank 0
2024-11-28 17:31:44.670418: Validation complete
2024-11-28 17:31:44.671229: Mean Validation Dice:  0.7319691778176262

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2024-11-28 17:31:54.085895: do_dummy_2d_data_aug: False
2024-11-28 17:31:54.088619: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset306_Sohee_Ajay_Calcium_OCT/splits_final.json
2024-11-28 17:31:54.090193: The split file contains 5 splits.
2024-11-28 17:31:54.090993: Desired fold for training: 2
2024-11-28 17:31:54.091718: This split has 10 training and 3 validation cases.

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2024-11-28 17:31:54.243636: do_dummy_2d_data_aug: False
2024-11-28 17:31:54.245291: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset306_Sohee_Ajay_Calcium_OCT/splits_final.json
2024-11-28 17:31:54.246354: The split file contains 5 splits.
2024-11-28 17:31:54.247121: Desired fold for training: 3
2024-11-28 17:31:54.247748: This split has 11 training and 2 validation cases.
using pin_memory on device 0
using pin_memory on device 0
using pin_memory on device 0
2024-11-28 17:31:56.836607: Using torch.compile...
using pin_memory on device 0
2024-11-28 17:31:57.091351: Using torch.compile...
/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': [512, 512], 'median_image_size_in_voxels': [498.0, 498.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset306_Sohee_Ajay_Calcium_OCT', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.49803921580314636, 'mean': 0.14296366274356842, 'median': 0.10980392247438431, 'min': 0.0, 'percentile_00_5': 0.01558823511004448, 'percentile_99_5': 0.49803921580314636, 'std': 0.11562220752239227}}} 

2024-11-28 17:32:03.832901: unpacking dataset...

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': [512, 512], 'median_image_size_in_voxels': [498.0, 498.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset306_Sohee_Ajay_Calcium_OCT', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.49803921580314636, 'mean': 0.14296366274356842, 'median': 0.10980392247438431, 'min': 0.0, 'percentile_00_5': 0.01558823511004448, 'percentile_99_5': 0.49803921580314636, 'std': 0.11562220752239227}}} 

2024-11-28 17:32:03.833097: unpacking dataset...
2024-11-28 15:46:26.543798: unpacking done...
2024-11-28 15:46:26.560416: Unable to plot network architecture: nnUNet_compile is enabled!
2024-11-28 15:46:26.625726: 
2024-11-28 15:46:26.626971: Epoch 0
2024-11-28 15:46:26.627972: Current learning rate: 0.01
2024-11-28 15:48:49.516666: Validation loss improved from 1000.00000 to -0.44386! Patience: 0/50
2024-11-28 15:48:49.517749: train_loss -0.1838
2024-11-28 15:48:49.518732: val_loss -0.4439
2024-11-28 15:48:49.519635: Pseudo dice [0.5904]
2024-11-28 15:48:49.520635: Epoch time: 142.89 s
2024-11-28 15:48:49.521559: Yayy! New best EMA pseudo Dice: 0.5904
2024-11-28 15:48:51.083428: 
2024-11-28 15:48:51.084863: Epoch 1
2024-11-28 15:48:51.085870: Current learning rate: 0.00999
2024-11-28 15:49:37.405943: Validation loss improved from -0.44386 to -0.46640! Patience: 0/50
2024-11-28 15:49:37.407146: train_loss -0.4462
2024-11-28 15:49:37.407964: val_loss -0.4664
2024-11-28 15:49:37.408798: Pseudo dice [0.6113]
2024-11-28 15:49:37.409575: Epoch time: 46.33 s
2024-11-28 15:49:37.410311: Yayy! New best EMA pseudo Dice: 0.5925
2024-11-28 15:49:39.166066: 
2024-11-28 15:49:39.167998: Epoch 2
2024-11-28 15:49:39.169261: Current learning rate: 0.00998
2024-11-28 15:50:25.452794: Validation loss improved from -0.46640 to -0.49598! Patience: 0/50
2024-11-28 15:50:25.455977: train_loss -0.5486
2024-11-28 15:50:25.457115: val_loss -0.496
2024-11-28 15:50:25.457835: Pseudo dice [0.6281]
2024-11-28 15:50:25.458569: Epoch time: 46.29 s
2024-11-28 15:50:25.459303: Yayy! New best EMA pseudo Dice: 0.5961
2024-11-28 15:50:27.268075: 
2024-11-28 15:50:27.269670: Epoch 3
2024-11-28 15:50:27.271004: Current learning rate: 0.00997
2024-11-28 15:51:13.631211: Validation loss improved from -0.49598 to -0.55963! Patience: 0/50
2024-11-28 15:51:13.634552: train_loss -0.5884
2024-11-28 15:51:13.635699: val_loss -0.5596
2024-11-28 15:51:13.636683: Pseudo dice [0.6971]
2024-11-28 15:51:13.637522: Epoch time: 46.37 s
2024-11-28 15:51:13.638463: Yayy! New best EMA pseudo Dice: 0.6062
2024-11-28 15:51:15.474627: 
2024-11-28 15:51:15.476480: Epoch 4
2024-11-28 15:51:15.477330: Current learning rate: 0.00996
2024-11-28 15:52:01.871457: Validation loss improved from -0.55963 to -0.62120! Patience: 0/50
2024-11-28 15:52:01.872697: train_loss -0.6045
2024-11-28 15:52:01.873455: val_loss -0.6212
2024-11-28 15:52:01.874182: Pseudo dice [0.7242]
2024-11-28 15:52:01.874798: Epoch time: 46.4 s
2024-11-28 15:52:02.365344: Yayy! New best EMA pseudo Dice: 0.618
2024-11-28 15:52:04.241722: 
2024-11-28 15:52:04.243521: Epoch 5
2024-11-28 15:52:04.244318: Current learning rate: 0.00995
2024-11-28 15:52:50.709230: Validation loss improved from -0.62120 to -0.62854! Patience: 0/50
2024-11-28 15:52:50.712443: train_loss -0.6308
2024-11-28 15:52:50.713224: val_loss -0.6285
2024-11-28 15:52:50.713849: Pseudo dice [0.7348]
2024-11-28 15:52:50.714527: Epoch time: 46.47 s
2024-11-28 15:52:50.715203: Yayy! New best EMA pseudo Dice: 0.6297
2024-11-28 15:52:52.455161: 
2024-11-28 15:52:52.460426: Epoch 6
2024-11-28 15:52:52.461480: Current learning rate: 0.00995
2024-11-28 15:53:38.947483: Validation loss improved from -0.62854 to -0.65009! Patience: 0/50
2024-11-28 15:53:38.950809: train_loss -0.6583
2024-11-28 15:53:38.951859: val_loss -0.6501
2024-11-28 15:53:38.952579: Pseudo dice [0.7475]
2024-11-28 15:53:38.953184: Epoch time: 46.5 s
2024-11-28 15:53:38.953931: Yayy! New best EMA pseudo Dice: 0.6414
2024-11-28 15:53:40.721376: 
2024-11-28 15:53:40.724655: Epoch 7
2024-11-28 15:53:40.725640: Current learning rate: 0.00994
2024-11-28 15:54:27.225242: Validation loss improved from -0.65009 to -0.66385! Patience: 0/50
2024-11-28 15:54:27.228278: train_loss -0.6551
2024-11-28 15:54:27.229049: val_loss -0.6638
2024-11-28 15:54:27.229862: Pseudo dice [0.7612]
2024-11-28 15:54:27.230706: Epoch time: 46.51 s
2024-11-28 15:54:27.231347: Yayy! New best EMA pseudo Dice: 0.6534
2024-11-28 15:54:29.588068: 
2024-11-28 15:54:29.590832: Epoch 8
2024-11-28 15:54:29.591789: Current learning rate: 0.00993
2024-11-28 15:55:16.242226: Validation loss did not improve from -0.66385. Patience: 1/50
2024-11-28 15:55:16.245008: train_loss -0.6643
2024-11-28 15:55:16.245885: val_loss -0.636
2024-11-28 15:55:16.246602: Pseudo dice [0.744]
2024-11-28 15:55:16.247509: Epoch time: 46.66 s
2024-11-28 15:55:16.248444: Yayy! New best EMA pseudo Dice: 0.6625
2024-11-28 15:55:18.099715: 
2024-11-28 15:55:18.102900: Epoch 9
2024-11-28 15:55:18.103640: Current learning rate: 0.00992
2024-11-28 15:56:04.688488: Validation loss improved from -0.66385 to -0.66654! Patience: 1/50
2024-11-28 15:56:04.691886: train_loss -0.6848
2024-11-28 15:56:04.692790: val_loss -0.6665
2024-11-28 15:56:04.693638: Pseudo dice [0.7614]
2024-11-28 15:56:04.694482: Epoch time: 46.59 s
2024-11-28 15:56:05.205754: Yayy! New best EMA pseudo Dice: 0.6724
2024-11-28 15:56:06.934544: 
2024-11-28 15:56:06.938048: Epoch 10
2024-11-28 15:56:06.939018: Current learning rate: 0.00991
2024-11-28 15:56:53.495746: Validation loss did not improve from -0.66654. Patience: 1/50
2024-11-28 15:56:53.498814: train_loss -0.6825
2024-11-28 15:56:53.499867: val_loss -0.6552
2024-11-28 15:56:53.500881: Pseudo dice [0.7517]
2024-11-28 15:56:53.501564: Epoch time: 46.57 s
2024-11-28 15:56:53.502292: Yayy! New best EMA pseudo Dice: 0.6803
2024-11-28 15:56:55.367182: 
2024-11-28 15:56:55.369600: Epoch 11
2024-11-28 15:56:55.370690: Current learning rate: 0.0099
2024-11-28 15:57:41.998264: Validation loss did not improve from -0.66654. Patience: 2/50
2024-11-28 15:57:42.001379: train_loss -0.6949
2024-11-28 15:57:42.002336: val_loss -0.6474
2024-11-28 15:57:42.003147: Pseudo dice [0.7517]
2024-11-28 15:57:42.003897: Epoch time: 46.64 s
2024-11-28 15:57:42.004734: Yayy! New best EMA pseudo Dice: 0.6874
2024-11-28 15:57:43.824669: 
2024-11-28 15:57:43.825848: Epoch 12
2024-11-28 15:57:43.826689: Current learning rate: 0.00989
2024-11-28 15:58:30.426109: Validation loss did not improve from -0.66654. Patience: 3/50
2024-11-28 15:58:30.427289: train_loss -0.6914
2024-11-28 15:58:30.428081: val_loss -0.6532
2024-11-28 15:58:30.428798: Pseudo dice [0.7522]
2024-11-28 15:58:30.429540: Epoch time: 46.6 s
2024-11-28 15:58:30.430271: Yayy! New best EMA pseudo Dice: 0.6939
2024-11-28 15:58:32.229971: 
2024-11-28 15:58:32.231374: Epoch 13
2024-11-28 15:58:32.232199: Current learning rate: 0.00988
2024-11-28 15:59:18.850586: Validation loss did not improve from -0.66654. Patience: 4/50
2024-11-28 15:59:18.852386: train_loss -0.7032
2024-11-28 15:59:18.853206: val_loss -0.6492
2024-11-28 15:59:18.854072: Pseudo dice [0.7462]
2024-11-28 15:59:18.854806: Epoch time: 46.62 s
2024-11-28 15:59:18.855461: Yayy! New best EMA pseudo Dice: 0.6991
2024-11-28 15:59:20.695592: 
2024-11-28 15:59:20.696931: Epoch 14
2024-11-28 15:59:20.697781: Current learning rate: 0.00987
2024-11-28 16:00:07.289440: Validation loss did not improve from -0.66654. Patience: 5/50
2024-11-28 16:00:07.291132: train_loss -0.7048
2024-11-28 16:00:07.292215: val_loss -0.624
2024-11-28 16:00:07.293200: Pseudo dice [0.7343]
2024-11-28 16:00:07.294047: Epoch time: 46.6 s
2024-11-28 16:00:07.826948: Yayy! New best EMA pseudo Dice: 0.7027
2024-11-28 16:00:09.689712: 
2024-11-28 16:00:09.691301: Epoch 15
2024-11-28 16:00:09.692092: Current learning rate: 0.00986
2024-11-28 16:00:56.238618: Validation loss did not improve from -0.66654. Patience: 6/50
2024-11-28 16:00:56.240329: train_loss -0.6967
2024-11-28 16:00:56.241384: val_loss -0.6591
2024-11-28 16:00:56.242234: Pseudo dice [0.7597]
2024-11-28 16:00:56.243049: Epoch time: 46.55 s
2024-11-28 16:00:56.243960: Yayy! New best EMA pseudo Dice: 0.7084
2024-11-28 16:00:58.055174: 
2024-11-28 16:00:58.056799: Epoch 16
2024-11-28 16:00:58.057934: Current learning rate: 0.00986
2024-11-28 16:01:44.685759: Validation loss did not improve from -0.66654. Patience: 7/50
2024-11-28 16:01:44.687575: train_loss -0.712
2024-11-28 16:01:44.688608: val_loss -0.6586
2024-11-28 16:01:44.689327: Pseudo dice [0.7602]
2024-11-28 16:01:44.690214: Epoch time: 46.63 s
2024-11-28 16:01:44.690918: Yayy! New best EMA pseudo Dice: 0.7136
2024-11-28 16:01:46.551994: 
2024-11-28 16:01:46.553857: Epoch 17
2024-11-28 16:01:46.554841: Current learning rate: 0.00985
2024-11-28 16:02:33.212879: Validation loss did not improve from -0.66654. Patience: 8/50
2024-11-28 16:02:33.214360: train_loss -0.7186
2024-11-28 16:02:33.215315: val_loss -0.6387
2024-11-28 16:02:33.216288: Pseudo dice [0.7457]
2024-11-28 16:02:33.217267: Epoch time: 46.66 s
2024-11-28 16:02:33.217987: Yayy! New best EMA pseudo Dice: 0.7168
2024-11-28 16:02:35.092505: 
2024-11-28 16:02:35.094191: Epoch 18
2024-11-28 16:02:35.095305: Current learning rate: 0.00984
2024-11-28 16:03:21.825756: Validation loss did not improve from -0.66654. Patience: 9/50
2024-11-28 16:03:21.827022: train_loss -0.7273
2024-11-28 16:03:21.827760: val_loss -0.6487
2024-11-28 16:03:21.828453: Pseudo dice [0.7486]
2024-11-28 16:03:21.829529: Epoch time: 46.74 s
2024-11-28 16:03:21.830163: Yayy! New best EMA pseudo Dice: 0.72
2024-11-28 16:03:24.070641: 
2024-11-28 16:03:24.071940: Epoch 19
2024-11-28 16:03:24.072791: Current learning rate: 0.00983
2024-11-28 16:04:10.769192: Validation loss did not improve from -0.66654. Patience: 10/50
2024-11-28 16:04:10.770557: train_loss -0.7293
2024-11-28 16:04:10.771356: val_loss -0.6385
2024-11-28 16:04:10.772117: Pseudo dice [0.7462]
2024-11-28 16:04:10.772965: Epoch time: 46.7 s
2024-11-28 16:04:11.282306: Yayy! New best EMA pseudo Dice: 0.7226
2024-11-28 16:04:13.075198: 
2024-11-28 16:04:13.076173: Epoch 20
2024-11-28 16:04:13.076962: Current learning rate: 0.00982
2024-11-28 16:04:59.753184: Validation loss did not improve from -0.66654. Patience: 11/50
2024-11-28 16:04:59.755023: train_loss -0.7288
2024-11-28 16:04:59.755871: val_loss -0.6608
2024-11-28 16:04:59.756670: Pseudo dice [0.7544]
2024-11-28 16:04:59.757554: Epoch time: 46.68 s
2024-11-28 16:04:59.758465: Yayy! New best EMA pseudo Dice: 0.7258
2024-11-28 16:05:01.646698: 
2024-11-28 16:05:01.648424: Epoch 21
2024-11-28 16:05:01.649402: Current learning rate: 0.00981
2024-11-28 16:05:48.326097: Validation loss improved from -0.66654 to -0.67451! Patience: 11/50
2024-11-28 16:05:48.328057: train_loss -0.7235
2024-11-28 16:05:48.329004: val_loss -0.6745
2024-11-28 16:05:48.329950: Pseudo dice [0.7662]
2024-11-28 16:05:48.330841: Epoch time: 46.68 s
2024-11-28 16:05:48.331846: Yayy! New best EMA pseudo Dice: 0.7298
2024-11-28 16:05:50.121614: 
2024-11-28 16:05:50.123164: Epoch 22
2024-11-28 16:05:50.123926: Current learning rate: 0.0098
2024-11-28 16:06:36.837600: Validation loss did not improve from -0.67451. Patience: 1/50
2024-11-28 16:06:36.839226: train_loss -0.7342
2024-11-28 16:06:36.840025: val_loss -0.6339
2024-11-28 16:06:36.840799: Pseudo dice [0.7457]
2024-11-28 16:06:36.841496: Epoch time: 46.72 s
2024-11-28 16:06:36.842217: Yayy! New best EMA pseudo Dice: 0.7314
2024-11-28 16:06:38.643860: 
2024-11-28 16:06:38.645824: Epoch 23
2024-11-28 16:06:38.646584: Current learning rate: 0.00979
2024-11-28 16:07:25.327863: Validation loss did not improve from -0.67451. Patience: 2/50
2024-11-28 16:07:25.329663: train_loss -0.7196
2024-11-28 16:07:25.330423: val_loss -0.621
2024-11-28 16:07:25.331221: Pseudo dice [0.7277]
2024-11-28 16:07:25.331995: Epoch time: 46.69 s
2024-11-28 16:07:26.568951: 
2024-11-28 16:07:26.570687: Epoch 24
2024-11-28 16:07:26.571670: Current learning rate: 0.00978
2024-11-28 16:08:13.319659: Validation loss did not improve from -0.67451. Patience: 3/50
2024-11-28 16:08:13.321307: train_loss -0.7259
2024-11-28 16:08:13.322332: val_loss -0.6356
2024-11-28 16:08:13.323334: Pseudo dice [0.7422]
2024-11-28 16:08:13.324134: Epoch time: 46.75 s
2024-11-28 16:08:13.864662: Yayy! New best EMA pseudo Dice: 0.7321
2024-11-28 16:08:15.651236: 
2024-11-28 16:08:15.652918: Epoch 25
2024-11-28 16:08:15.654064: Current learning rate: 0.00977
2024-11-28 16:09:02.411454: Validation loss did not improve from -0.67451. Patience: 4/50
2024-11-28 16:09:02.412777: train_loss -0.736
2024-11-28 16:09:02.413612: val_loss -0.6651
2024-11-28 16:09:02.414498: Pseudo dice [0.7625]
2024-11-28 16:09:02.415220: Epoch time: 46.76 s
2024-11-28 16:09:02.415947: Yayy! New best EMA pseudo Dice: 0.7352
2024-11-28 16:09:04.171843: 
2024-11-28 16:09:04.173221: Epoch 26
2024-11-28 16:09:04.174447: Current learning rate: 0.00977
2024-11-28 16:09:50.961879: Validation loss improved from -0.67451 to -0.67751! Patience: 4/50
2024-11-28 16:09:50.963109: train_loss -0.7441
2024-11-28 16:09:50.964133: val_loss -0.6775
2024-11-28 16:09:50.964976: Pseudo dice [0.7714]
2024-11-28 16:09:50.965861: Epoch time: 46.79 s
2024-11-28 16:09:50.966623: Yayy! New best EMA pseudo Dice: 0.7388
2024-11-28 16:09:52.809483: 
2024-11-28 16:09:52.811432: Epoch 27
2024-11-28 16:09:52.813290: Current learning rate: 0.00976
2024-11-28 16:10:39.701821: Validation loss did not improve from -0.67751. Patience: 1/50
2024-11-28 16:10:39.703568: train_loss -0.7459
2024-11-28 16:10:39.704450: val_loss -0.6306
2024-11-28 16:10:39.705313: Pseudo dice [0.7365]
2024-11-28 16:10:39.706306: Epoch time: 46.9 s
2024-11-28 16:10:40.940420: 
2024-11-28 16:10:40.942421: Epoch 28
2024-11-28 16:10:40.943907: Current learning rate: 0.00975
2024-11-28 16:11:27.753841: Validation loss did not improve from -0.67751. Patience: 2/50
2024-11-28 16:11:27.755476: train_loss -0.746
2024-11-28 16:11:27.756469: val_loss -0.6715
2024-11-28 16:11:27.757490: Pseudo dice [0.7658]
2024-11-28 16:11:27.758334: Epoch time: 46.82 s
2024-11-28 16:11:27.759306: Yayy! New best EMA pseudo Dice: 0.7413
2024-11-28 16:11:29.545457: 
2024-11-28 16:11:29.546807: Epoch 29
2024-11-28 16:11:29.547717: Current learning rate: 0.00974
2024-11-28 16:12:16.323912: Validation loss did not improve from -0.67751. Patience: 3/50
2024-11-28 16:12:16.325670: train_loss -0.7578
2024-11-28 16:12:16.326782: val_loss -0.6533
2024-11-28 16:12:16.327738: Pseudo dice [0.7537]
2024-11-28 16:12:16.328524: Epoch time: 46.78 s
2024-11-28 16:12:16.847011: Yayy! New best EMA pseudo Dice: 0.7425
2024-11-28 16:12:19.008680: 
2024-11-28 16:12:19.010071: Epoch 30
2024-11-28 16:12:19.010901: Current learning rate: 0.00973
2024-11-28 16:13:05.782583: Validation loss did not improve from -0.67751. Patience: 4/50
2024-11-28 16:13:05.784309: train_loss -0.7536
2024-11-28 16:13:05.785310: val_loss -0.6441
2024-11-28 16:13:05.786090: Pseudo dice [0.7472]
2024-11-28 16:13:05.786921: Epoch time: 46.78 s
2024-11-28 16:13:05.787686: Yayy! New best EMA pseudo Dice: 0.743
2024-11-28 16:13:07.584683: 
2024-11-28 16:13:07.586167: Epoch 31
2024-11-28 16:13:07.587060: Current learning rate: 0.00972
2024-11-28 16:13:54.364439: Validation loss did not improve from -0.67751. Patience: 5/50
2024-11-28 16:13:54.366270: train_loss -0.7578
2024-11-28 16:13:54.367167: val_loss -0.6691
2024-11-28 16:13:54.367893: Pseudo dice [0.7624]
2024-11-28 16:13:54.368733: Epoch time: 46.78 s
2024-11-28 16:13:54.369556: Yayy! New best EMA pseudo Dice: 0.7449
2024-11-28 16:13:56.195970: 
2024-11-28 16:13:56.197775: Epoch 32
2024-11-28 16:13:56.199010: Current learning rate: 0.00971
2024-11-28 16:14:42.999624: Validation loss did not improve from -0.67751. Patience: 6/50
2024-11-28 16:14:43.001482: train_loss -0.7592
2024-11-28 16:14:43.002347: val_loss -0.646
2024-11-28 16:14:43.003002: Pseudo dice [0.7523]
2024-11-28 16:14:43.003619: Epoch time: 46.81 s
2024-11-28 16:14:43.004343: Yayy! New best EMA pseudo Dice: 0.7457
2024-11-28 16:14:44.819682: 
2024-11-28 16:14:44.821291: Epoch 33
2024-11-28 16:14:44.822394: Current learning rate: 0.0097
2024-11-28 16:15:31.653862: Validation loss did not improve from -0.67751. Patience: 7/50
2024-11-28 16:15:31.655725: train_loss -0.764
2024-11-28 16:15:31.656560: val_loss -0.6601
2024-11-28 16:15:31.657356: Pseudo dice [0.7586]
2024-11-28 16:15:31.658164: Epoch time: 46.84 s
2024-11-28 16:15:31.658938: Yayy! New best EMA pseudo Dice: 0.747
2024-11-28 16:15:33.464088: 
2024-11-28 16:15:33.465516: Epoch 34
2024-11-28 16:15:33.466233: Current learning rate: 0.00969
2024-11-28 16:16:20.305985: Validation loss did not improve from -0.67751. Patience: 8/50
2024-11-28 16:16:20.307545: train_loss -0.7616
2024-11-28 16:16:20.308436: val_loss -0.6625
2024-11-28 16:16:20.309354: Pseudo dice [0.7602]
2024-11-28 16:16:20.310459: Epoch time: 46.84 s
2024-11-28 16:16:20.859433: Yayy! New best EMA pseudo Dice: 0.7483
2024-11-28 16:16:22.674362: 
2024-11-28 16:16:22.675620: Epoch 35
2024-11-28 16:16:22.676390: Current learning rate: 0.00968
2024-11-28 16:17:09.498961: Validation loss improved from -0.67751 to -0.68075! Patience: 8/50
2024-11-28 16:17:09.500618: train_loss -0.7591
2024-11-28 16:17:09.501526: val_loss -0.6807
2024-11-28 16:17:09.502352: Pseudo dice [0.7732]
2024-11-28 16:17:09.503117: Epoch time: 46.83 s
2024-11-28 16:17:09.503871: Yayy! New best EMA pseudo Dice: 0.7508
2024-11-28 16:17:11.359233: 
2024-11-28 16:17:11.360641: Epoch 36
2024-11-28 16:17:11.361453: Current learning rate: 0.00968
2024-11-28 16:17:58.135011: Validation loss improved from -0.68075 to -0.69077! Patience: 0/50
2024-11-28 16:17:58.136516: train_loss -0.7586
2024-11-28 16:17:58.137507: val_loss -0.6908
2024-11-28 16:17:58.138419: Pseudo dice [0.7808]
2024-11-28 16:17:58.139477: Epoch time: 46.78 s
2024-11-28 16:17:58.140827: Yayy! New best EMA pseudo Dice: 0.7538
2024-11-28 16:17:59.984973: 
2024-11-28 16:17:59.986157: Epoch 37
2024-11-28 16:17:59.987017: Current learning rate: 0.00967
2024-11-28 16:18:46.780829: Validation loss did not improve from -0.69077. Patience: 1/50
2024-11-28 16:18:46.782772: train_loss -0.7722
2024-11-28 16:18:46.783707: val_loss -0.6642
2024-11-28 16:18:46.784558: Pseudo dice [0.7576]
2024-11-28 16:18:46.785272: Epoch time: 46.8 s
2024-11-28 16:18:46.786040: Yayy! New best EMA pseudo Dice: 0.7542
2024-11-28 16:18:48.639643: 
2024-11-28 16:18:48.641377: Epoch 38
2024-11-28 16:18:48.642315: Current learning rate: 0.00966
2024-11-28 16:19:35.403670: Validation loss did not improve from -0.69077. Patience: 2/50
2024-11-28 16:19:35.404871: train_loss -0.7702
2024-11-28 16:19:35.405628: val_loss -0.6718
2024-11-28 16:19:35.406311: Pseudo dice [0.7663]
2024-11-28 16:19:35.407072: Epoch time: 46.77 s
2024-11-28 16:19:35.407731: Yayy! New best EMA pseudo Dice: 0.7554
2024-11-28 16:19:37.236424: 
2024-11-28 16:19:37.237883: Epoch 39
2024-11-28 16:19:37.238634: Current learning rate: 0.00965
2024-11-28 16:20:24.007575: Validation loss did not improve from -0.69077. Patience: 3/50
2024-11-28 16:20:24.008770: train_loss -0.768
2024-11-28 16:20:24.009676: val_loss -0.6491
2024-11-28 16:20:24.010632: Pseudo dice [0.7555]
2024-11-28 16:20:24.011460: Epoch time: 46.77 s
2024-11-28 16:20:24.544061: Yayy! New best EMA pseudo Dice: 0.7554
2024-11-28 16:20:26.448281: 
2024-11-28 16:20:26.450259: Epoch 40
2024-11-28 16:20:26.451448: Current learning rate: 0.00964
2024-11-28 16:21:13.220715: Validation loss did not improve from -0.69077. Patience: 4/50
2024-11-28 16:21:13.222270: train_loss -0.7681
2024-11-28 16:21:13.223279: val_loss -0.6609
2024-11-28 16:21:13.224131: Pseudo dice [0.7624]
2024-11-28 16:21:13.225352: Epoch time: 46.78 s
2024-11-28 16:21:13.226569: Yayy! New best EMA pseudo Dice: 0.7561
2024-11-28 16:21:15.550550: 
2024-11-28 16:21:15.552094: Epoch 41
2024-11-28 16:21:15.553004: Current learning rate: 0.00963
2024-11-28 16:22:02.339587: Validation loss did not improve from -0.69077. Patience: 5/50
2024-11-28 16:22:02.341470: train_loss -0.7727
2024-11-28 16:22:02.342204: val_loss -0.6659
2024-11-28 16:22:02.343001: Pseudo dice [0.7672]
2024-11-28 16:22:02.343755: Epoch time: 46.79 s
2024-11-28 16:22:02.344626: Yayy! New best EMA pseudo Dice: 0.7572
2024-11-28 16:22:04.135827: 
2024-11-28 16:22:04.137613: Epoch 42
2024-11-28 16:22:04.138467: Current learning rate: 0.00962
2024-11-28 16:22:50.913777: Validation loss did not improve from -0.69077. Patience: 6/50
2024-11-28 16:22:50.915541: train_loss -0.7739
2024-11-28 16:22:50.916366: val_loss -0.6484
2024-11-28 16:22:50.917334: Pseudo dice [0.7507]
2024-11-28 16:22:50.918146: Epoch time: 46.78 s
2024-11-28 16:22:52.191944: 
2024-11-28 16:22:52.194172: Epoch 43
2024-11-28 16:22:52.195484: Current learning rate: 0.00961
2024-11-28 16:23:39.047018: Validation loss did not improve from -0.69077. Patience: 7/50
2024-11-28 16:23:39.048662: train_loss -0.7819
2024-11-28 16:23:39.049499: val_loss -0.6713
2024-11-28 16:23:39.050278: Pseudo dice [0.7672]
2024-11-28 16:23:39.051149: Epoch time: 46.86 s
2024-11-28 16:23:39.052099: Yayy! New best EMA pseudo Dice: 0.7576
2024-11-28 16:23:40.840282: 
2024-11-28 16:23:40.841541: Epoch 44
2024-11-28 16:23:40.842383: Current learning rate: 0.0096
2024-11-28 16:24:27.668033: Validation loss did not improve from -0.69077. Patience: 8/50
2024-11-28 16:24:27.669780: train_loss -0.7691
2024-11-28 16:24:27.670597: val_loss -0.6754
2024-11-28 16:24:27.671236: Pseudo dice [0.7702]
2024-11-28 16:24:27.671912: Epoch time: 46.83 s
2024-11-28 16:24:28.199073: Yayy! New best EMA pseudo Dice: 0.7589
2024-11-28 16:24:29.938237: 
2024-11-28 16:24:29.939973: Epoch 45
2024-11-28 16:24:29.940782: Current learning rate: 0.00959
2024-11-28 16:25:16.915522: Validation loss did not improve from -0.69077. Patience: 9/50
2024-11-28 16:25:16.916773: train_loss -0.7765
2024-11-28 16:25:16.917618: val_loss -0.6343
2024-11-28 16:25:16.918366: Pseudo dice [0.7448]
2024-11-28 16:25:16.919349: Epoch time: 46.98 s
2024-11-28 16:25:18.261666: 
2024-11-28 16:25:18.262829: Epoch 46
2024-11-28 16:25:18.263602: Current learning rate: 0.00959
2024-11-28 16:26:05.080602: Validation loss did not improve from -0.69077. Patience: 10/50
2024-11-28 16:26:05.081837: train_loss -0.7805
2024-11-28 16:26:05.082657: val_loss -0.6612
2024-11-28 16:26:05.083464: Pseudo dice [0.7599]
2024-11-28 16:26:05.084268: Epoch time: 46.82 s
2024-11-28 16:26:06.377781: 
2024-11-28 16:26:06.379383: Epoch 47
2024-11-28 16:26:06.380200: Current learning rate: 0.00958
2024-11-28 16:26:53.232000: Validation loss did not improve from -0.69077. Patience: 11/50
2024-11-28 16:26:53.233543: train_loss -0.7796
2024-11-28 16:26:53.234404: val_loss -0.6402
2024-11-28 16:26:53.236859: Pseudo dice [0.7464]
2024-11-28 16:26:53.237860: Epoch time: 46.86 s
2024-11-28 16:26:54.472093: 
2024-11-28 16:26:54.473866: Epoch 48
2024-11-28 16:26:54.474853: Current learning rate: 0.00957
2024-11-28 16:27:41.278089: Validation loss did not improve from -0.69077. Patience: 12/50
2024-11-28 16:27:41.280084: train_loss -0.7801
2024-11-28 16:27:41.280847: val_loss -0.6139
2024-11-28 16:27:41.281620: Pseudo dice [0.726]
2024-11-28 16:27:41.282303: Epoch time: 46.81 s
2024-11-28 16:27:42.535890: 
2024-11-28 16:27:42.537295: Epoch 49
2024-11-28 16:27:42.538054: Current learning rate: 0.00956
2024-11-28 16:28:29.338469: Validation loss did not improve from -0.69077. Patience: 13/50
2024-11-28 16:28:29.339939: train_loss -0.7804
2024-11-28 16:28:29.340746: val_loss -0.6575
2024-11-28 16:28:29.341591: Pseudo dice [0.7541]
2024-11-28 16:28:29.342293: Epoch time: 46.81 s
2024-11-28 16:28:31.134636: 
2024-11-28 16:28:31.136008: Epoch 50
2024-11-28 16:28:31.137127: Current learning rate: 0.00955
2024-11-28 16:29:17.889649: Validation loss did not improve from -0.69077. Patience: 14/50
2024-11-28 16:29:17.891384: train_loss -0.7794
2024-11-28 16:29:17.892318: val_loss -0.6589
2024-11-28 16:29:17.893250: Pseudo dice [0.7595]
2024-11-28 16:29:17.894117: Epoch time: 46.76 s
2024-11-28 16:29:19.144458: 
2024-11-28 16:29:19.145590: Epoch 51
2024-11-28 16:29:19.146547: Current learning rate: 0.00954
2024-11-28 16:30:05.899993: Validation loss did not improve from -0.69077. Patience: 15/50
2024-11-28 16:30:05.901317: train_loss -0.7854
2024-11-28 16:30:05.902214: val_loss -0.6698
2024-11-28 16:30:05.902951: Pseudo dice [0.7652]
2024-11-28 16:30:05.903571: Epoch time: 46.76 s
2024-11-28 16:30:07.539196: 
2024-11-28 16:30:07.541054: Epoch 52
2024-11-28 16:30:07.542040: Current learning rate: 0.00953
2024-11-28 16:30:54.345584: Validation loss did not improve from -0.69077. Patience: 16/50
2024-11-28 16:30:54.346976: train_loss -0.7811
2024-11-28 16:30:54.347786: val_loss -0.6683
2024-11-28 16:30:54.348593: Pseudo dice [0.7718]
2024-11-28 16:30:54.349506: Epoch time: 46.81 s
2024-11-28 16:30:55.592658: 
2024-11-28 16:30:55.594310: Epoch 53
2024-11-28 16:30:55.595016: Current learning rate: 0.00952
2024-11-28 16:31:42.413492: Validation loss did not improve from -0.69077. Patience: 17/50
2024-11-28 16:31:42.415339: train_loss -0.7852
2024-11-28 16:31:42.416255: val_loss -0.6616
2024-11-28 16:31:42.417145: Pseudo dice [0.7597]
2024-11-28 16:31:42.417984: Epoch time: 46.82 s
2024-11-28 16:31:43.728304: 
2024-11-28 16:31:43.729403: Epoch 54
2024-11-28 16:31:43.730365: Current learning rate: 0.00951
2024-11-28 16:32:30.554053: Validation loss did not improve from -0.69077. Patience: 18/50
2024-11-28 16:32:30.555347: train_loss -0.7772
2024-11-28 16:32:30.556060: val_loss -0.6507
2024-11-28 16:32:30.556776: Pseudo dice [0.7518]
2024-11-28 16:32:30.557529: Epoch time: 46.83 s
2024-11-28 16:32:32.365148: 
2024-11-28 16:32:32.366532: Epoch 55
2024-11-28 16:32:32.367810: Current learning rate: 0.0095
2024-11-28 16:33:19.156250: Validation loss did not improve from -0.69077. Patience: 19/50
2024-11-28 16:33:19.157883: train_loss -0.7802
2024-11-28 16:33:19.158627: val_loss -0.6641
2024-11-28 16:33:19.159281: Pseudo dice [0.7598]
2024-11-28 16:33:19.159950: Epoch time: 46.79 s
2024-11-28 16:33:20.448485: 
2024-11-28 16:33:20.449945: Epoch 56
2024-11-28 16:33:20.450609: Current learning rate: 0.00949
2024-11-28 16:34:07.226245: Validation loss did not improve from -0.69077. Patience: 20/50
2024-11-28 16:34:07.227530: train_loss -0.7884
2024-11-28 16:34:07.228592: val_loss -0.6582
2024-11-28 16:34:07.229305: Pseudo dice [0.7607]
2024-11-28 16:34:07.230077: Epoch time: 46.78 s
2024-11-28 16:34:08.532552: 
2024-11-28 16:34:08.534112: Epoch 57
2024-11-28 16:34:08.534869: Current learning rate: 0.00949
2024-11-28 16:34:55.413360: Validation loss did not improve from -0.69077. Patience: 21/50
2024-11-28 16:34:55.415004: train_loss -0.789
2024-11-28 16:34:55.415794: val_loss -0.6733
2024-11-28 16:34:55.416481: Pseudo dice [0.7679]
2024-11-28 16:34:55.417264: Epoch time: 46.88 s
2024-11-28 16:34:56.751440: 
2024-11-28 16:34:56.753170: Epoch 58
2024-11-28 16:34:56.753988: Current learning rate: 0.00948
2024-11-28 16:35:43.598967: Validation loss did not improve from -0.69077. Patience: 22/50
2024-11-28 16:35:43.600187: train_loss -0.7944
2024-11-28 16:35:43.601114: val_loss -0.6668
2024-11-28 16:35:43.601942: Pseudo dice [0.7664]
2024-11-28 16:35:43.602705: Epoch time: 46.85 s
2024-11-28 16:35:43.603607: Yayy! New best EMA pseudo Dice: 0.7592
2024-11-28 16:35:45.454307: 
2024-11-28 16:35:45.456049: Epoch 59
2024-11-28 16:35:45.457102: Current learning rate: 0.00947
2024-11-28 16:36:32.258288: Validation loss did not improve from -0.69077. Patience: 23/50
2024-11-28 16:36:32.259955: train_loss -0.7874
2024-11-28 16:36:32.261015: val_loss -0.6587
2024-11-28 16:36:32.261809: Pseudo dice [0.7576]
2024-11-28 16:36:32.262516: Epoch time: 46.81 s
2024-11-28 16:36:34.053629: 
2024-11-28 16:36:34.055617: Epoch 60
2024-11-28 16:36:34.056681: Current learning rate: 0.00946
2024-11-28 16:37:20.841226: Validation loss did not improve from -0.69077. Patience: 24/50
2024-11-28 16:37:20.843091: train_loss -0.7904
2024-11-28 16:37:20.843940: val_loss -0.6223
2024-11-28 16:37:20.844742: Pseudo dice [0.7353]
2024-11-28 16:37:20.845564: Epoch time: 46.79 s
2024-11-28 16:37:22.125870: 
2024-11-28 16:37:22.127319: Epoch 61
2024-11-28 16:37:22.128066: Current learning rate: 0.00945
2024-11-28 16:38:08.958691: Validation loss did not improve from -0.69077. Patience: 25/50
2024-11-28 16:38:08.960538: train_loss -0.7799
2024-11-28 16:38:08.961338: val_loss -0.6573
2024-11-28 16:38:08.962082: Pseudo dice [0.7638]
2024-11-28 16:38:08.962740: Epoch time: 46.84 s
2024-11-28 16:38:10.237030: 
2024-11-28 16:38:10.238878: Epoch 62
2024-11-28 16:38:10.240022: Current learning rate: 0.00944
2024-11-28 16:38:57.502048: Validation loss did not improve from -0.69077. Patience: 26/50
2024-11-28 16:38:57.520160: train_loss -0.7889
2024-11-28 16:38:57.521289: val_loss -0.6312
2024-11-28 16:38:57.522097: Pseudo dice [0.7403]
2024-11-28 16:38:57.535236: Epoch time: 47.28 s
2024-11-28 16:38:58.873180: 
2024-11-28 16:38:58.874874: Epoch 63
2024-11-28 16:38:58.875930: Current learning rate: 0.00943
2024-11-28 16:39:45.646993: Validation loss did not improve from -0.69077. Patience: 27/50
2024-11-28 16:39:45.648939: train_loss -0.8014
2024-11-28 16:39:45.649652: val_loss -0.6334
2024-11-28 16:39:45.650405: Pseudo dice [0.7425]
2024-11-28 16:39:45.651118: Epoch time: 46.78 s
2024-11-28 16:39:47.336471: 
2024-11-28 16:39:47.337885: Epoch 64
2024-11-28 16:39:47.338748: Current learning rate: 0.00942
2024-11-28 16:40:34.102591: Validation loss did not improve from -0.69077. Patience: 28/50
2024-11-28 16:40:34.104196: train_loss -0.7937
2024-11-28 16:40:34.105064: val_loss -0.6478
2024-11-28 16:40:34.105967: Pseudo dice [0.7553]
2024-11-28 16:40:34.106951: Epoch time: 46.77 s
2024-11-28 16:40:35.966899: 
2024-11-28 16:40:35.968343: Epoch 65
2024-11-28 16:40:35.969101: Current learning rate: 0.00941
2024-11-28 16:41:22.766326: Validation loss did not improve from -0.69077. Patience: 29/50
2024-11-28 16:41:22.768088: train_loss -0.796
2024-11-28 16:41:22.769017: val_loss -0.651
2024-11-28 16:41:22.769770: Pseudo dice [0.7574]
2024-11-28 16:41:22.770593: Epoch time: 46.8 s
2024-11-28 16:41:24.078184: 
2024-11-28 16:41:24.079835: Epoch 66
2024-11-28 16:41:24.080731: Current learning rate: 0.0094
2024-11-28 16:42:10.866271: Validation loss did not improve from -0.69077. Patience: 30/50
2024-11-28 16:42:10.868042: train_loss -0.797
2024-11-28 16:42:10.868909: val_loss -0.6423
2024-11-28 16:42:10.869689: Pseudo dice [0.7561]
2024-11-28 16:42:10.870471: Epoch time: 46.79 s
2024-11-28 16:42:12.211025: 
2024-11-28 16:42:12.212948: Epoch 67
2024-11-28 16:42:12.213740: Current learning rate: 0.00939
2024-11-28 16:42:59.084645: Validation loss did not improve from -0.69077. Patience: 31/50
2024-11-28 16:42:59.086442: train_loss -0.7972
2024-11-28 16:42:59.087750: val_loss -0.6594
2024-11-28 16:42:59.088622: Pseudo dice [0.7606]
2024-11-28 16:42:59.089597: Epoch time: 46.88 s
2024-11-28 16:43:00.391601: 
2024-11-28 16:43:00.393284: Epoch 68
2024-11-28 16:43:00.394222: Current learning rate: 0.00939
2024-11-28 16:43:47.239838: Validation loss did not improve from -0.69077. Patience: 32/50
2024-11-28 16:43:47.241491: train_loss -0.7981
2024-11-28 16:43:47.242493: val_loss -0.6523
2024-11-28 16:43:47.243468: Pseudo dice [0.7598]
2024-11-28 16:43:47.244267: Epoch time: 46.85 s
2024-11-28 16:43:48.556685: 
2024-11-28 16:43:48.558875: Epoch 69
2024-11-28 16:43:48.560076: Current learning rate: 0.00938
2024-11-28 16:44:35.398842: Validation loss did not improve from -0.69077. Patience: 33/50
2024-11-28 16:44:35.400621: train_loss -0.7943
2024-11-28 16:44:35.401574: val_loss -0.6659
2024-11-28 16:44:35.402452: Pseudo dice [0.7654]
2024-11-28 16:44:35.403547: Epoch time: 46.85 s
2024-11-28 16:44:37.316526: 
2024-11-28 16:44:37.318102: Epoch 70
2024-11-28 16:44:37.319256: Current learning rate: 0.00937
2024-11-28 16:45:24.140505: Validation loss did not improve from -0.69077. Patience: 34/50
2024-11-28 16:45:24.142134: train_loss -0.7983
2024-11-28 16:45:24.142914: val_loss -0.6334
2024-11-28 16:45:24.143742: Pseudo dice [0.7469]
2024-11-28 16:45:24.144505: Epoch time: 46.83 s
2024-11-28 16:45:25.503387: 
2024-11-28 16:45:25.504571: Epoch 71
2024-11-28 16:45:25.505405: Current learning rate: 0.00936
2024-11-28 16:46:12.390614: Validation loss did not improve from -0.69077. Patience: 35/50
2024-11-28 16:46:12.392068: train_loss -0.8021
2024-11-28 16:46:12.392919: val_loss -0.6676
2024-11-28 16:46:12.393730: Pseudo dice [0.7706]
2024-11-28 16:46:12.394453: Epoch time: 46.89 s
2024-11-28 16:46:13.681769: 
2024-11-28 16:46:13.682854: Epoch 72
2024-11-28 16:46:13.683797: Current learning rate: 0.00935
2024-11-28 16:47:00.516448: Validation loss did not improve from -0.69077. Patience: 36/50
2024-11-28 16:47:00.518233: train_loss -0.8015
2024-11-28 16:47:00.519104: val_loss -0.6662
2024-11-28 16:47:00.519794: Pseudo dice [0.7688]
2024-11-28 16:47:00.520513: Epoch time: 46.84 s
2024-11-28 16:47:01.865999: 
2024-11-28 16:47:01.867456: Epoch 73
2024-11-28 16:47:01.868146: Current learning rate: 0.00934
2024-11-28 16:47:48.684733: Validation loss did not improve from -0.69077. Patience: 37/50
2024-11-28 16:47:48.686555: train_loss -0.7974
2024-11-28 16:47:48.687388: val_loss -0.6656
2024-11-28 16:47:48.688062: Pseudo dice [0.7639]
2024-11-28 16:47:48.688830: Epoch time: 46.82 s
2024-11-28 16:47:50.057938: 
2024-11-28 16:47:50.059705: Epoch 74
2024-11-28 16:47:50.060614: Current learning rate: 0.00933
2024-11-28 16:48:36.850415: Validation loss did not improve from -0.69077. Patience: 38/50
2024-11-28 16:48:36.852277: train_loss -0.8031
2024-11-28 16:48:36.853040: val_loss -0.6346
2024-11-28 16:48:36.853719: Pseudo dice [0.7457]
2024-11-28 16:48:36.854534: Epoch time: 46.8 s
2024-11-28 16:48:39.120238: 
2024-11-28 16:48:39.122124: Epoch 75
2024-11-28 16:48:39.123090: Current learning rate: 0.00932
2024-11-28 16:49:25.919645: Validation loss did not improve from -0.69077. Patience: 39/50
2024-11-28 16:49:25.920963: train_loss -0.8071
2024-11-28 16:49:25.921842: val_loss -0.6623
2024-11-28 16:49:25.922648: Pseudo dice [0.7612]
2024-11-28 16:49:25.923329: Epoch time: 46.8 s
2024-11-28 16:49:27.265176: 
2024-11-28 16:49:27.266654: Epoch 76
2024-11-28 16:49:27.267560: Current learning rate: 0.00931
2024-11-28 16:50:14.047277: Validation loss did not improve from -0.69077. Patience: 40/50
2024-11-28 16:50:14.049082: train_loss -0.805
2024-11-28 16:50:14.050007: val_loss -0.6288
2024-11-28 16:50:14.050733: Pseudo dice [0.7406]
2024-11-28 16:50:14.051549: Epoch time: 46.79 s
2024-11-28 16:50:15.373747: 
2024-11-28 16:50:15.375211: Epoch 77
2024-11-28 16:50:15.375958: Current learning rate: 0.0093
2024-11-28 16:51:02.190789: Validation loss improved from -0.69077 to -0.69269! Patience: 40/50
2024-11-28 16:51:02.192616: train_loss -0.8023
2024-11-28 16:51:02.193408: val_loss -0.6927
2024-11-28 16:51:02.194124: Pseudo dice [0.785]
2024-11-28 16:51:02.194795: Epoch time: 46.82 s
2024-11-28 16:51:03.499271: 
2024-11-28 16:51:03.500470: Epoch 78
2024-11-28 16:51:03.501275: Current learning rate: 0.0093
2024-11-28 16:51:50.384843: Validation loss did not improve from -0.69269. Patience: 1/50
2024-11-28 16:51:50.386668: train_loss -0.798
2024-11-28 16:51:50.387483: val_loss -0.6783
2024-11-28 16:51:50.388297: Pseudo dice [0.7757]
2024-11-28 16:51:50.389077: Epoch time: 46.89 s
2024-11-28 16:51:50.389712: Yayy! New best EMA pseudo Dice: 0.7608
2024-11-28 16:51:52.318656: 
2024-11-28 16:51:52.320462: Epoch 79
2024-11-28 16:51:52.321370: Current learning rate: 0.00929
2024-11-28 16:52:39.176500: Validation loss did not improve from -0.69269. Patience: 2/50
2024-11-28 16:52:39.178132: train_loss -0.8044
2024-11-28 16:52:39.178928: val_loss -0.6347
2024-11-28 16:52:39.179545: Pseudo dice [0.7433]
2024-11-28 16:52:39.180255: Epoch time: 46.86 s
2024-11-28 16:52:41.115677: 
2024-11-28 16:52:41.117362: Epoch 80
2024-11-28 16:52:41.118325: Current learning rate: 0.00928
2024-11-28 16:53:27.962176: Validation loss did not improve from -0.69269. Patience: 3/50
2024-11-28 16:53:27.964199: train_loss -0.8061
2024-11-28 16:53:27.965370: val_loss -0.6618
2024-11-28 16:53:27.966061: Pseudo dice [0.7633]
2024-11-28 16:53:27.966714: Epoch time: 46.85 s
2024-11-28 16:53:29.370596: 
2024-11-28 16:53:29.372000: Epoch 81
2024-11-28 16:53:29.373280: Current learning rate: 0.00927
2024-11-28 16:54:16.197570: Validation loss did not improve from -0.69269. Patience: 4/50
2024-11-28 16:54:16.199289: train_loss -0.8024
2024-11-28 16:54:16.200084: val_loss -0.686
2024-11-28 16:54:16.200857: Pseudo dice [0.7845]
2024-11-28 16:54:16.201654: Epoch time: 46.83 s
2024-11-28 16:54:16.202431: Yayy! New best EMA pseudo Dice: 0.762
2024-11-28 16:54:18.122072: 
2024-11-28 16:54:18.123816: Epoch 82
2024-11-28 16:54:18.124517: Current learning rate: 0.00926
2024-11-28 16:55:04.899836: Validation loss did not improve from -0.69269. Patience: 5/50
2024-11-28 16:55:04.901730: train_loss -0.7939
2024-11-28 16:55:04.902519: val_loss -0.6446
2024-11-28 16:55:04.903254: Pseudo dice [0.7532]
2024-11-28 16:55:04.904008: Epoch time: 46.78 s
2024-11-28 16:55:06.152738: 
2024-11-28 16:55:06.153595: Epoch 83
2024-11-28 16:55:06.154437: Current learning rate: 0.00925
2024-11-28 16:55:52.982798: Validation loss did not improve from -0.69269. Patience: 6/50
2024-11-28 16:55:52.984855: train_loss -0.8062
2024-11-28 16:55:52.985682: val_loss -0.6697
2024-11-28 16:55:52.986481: Pseudo dice [0.7735]
2024-11-28 16:55:52.987313: Epoch time: 46.83 s
2024-11-28 16:55:52.988001: Yayy! New best EMA pseudo Dice: 0.7623
2024-11-28 16:55:54.834930: 
2024-11-28 16:55:54.836492: Epoch 84
2024-11-28 16:55:54.837306: Current learning rate: 0.00924
2024-11-28 16:56:41.655743: Validation loss did not improve from -0.69269. Patience: 7/50
2024-11-28 16:56:41.657162: train_loss -0.804
2024-11-28 16:56:41.658065: val_loss -0.6381
2024-11-28 16:56:41.658796: Pseudo dice [0.7464]
2024-11-28 16:56:41.659545: Epoch time: 46.82 s
2024-11-28 16:56:43.889690: 
2024-11-28 16:56:43.891823: Epoch 85
2024-11-28 16:56:43.892707: Current learning rate: 0.00923
2024-11-28 16:57:30.682840: Validation loss did not improve from -0.69269. Patience: 8/50
2024-11-28 16:57:30.684757: train_loss -0.806
2024-11-28 16:57:30.685639: val_loss -0.6582
2024-11-28 16:57:30.686550: Pseudo dice [0.7654]
2024-11-28 16:57:30.687443: Epoch time: 46.8 s
2024-11-28 16:57:31.966775: 
2024-11-28 16:57:31.968672: Epoch 86
2024-11-28 16:57:31.969425: Current learning rate: 0.00922
2024-11-28 16:58:18.776180: Validation loss did not improve from -0.69269. Patience: 9/50
2024-11-28 16:58:18.777760: train_loss -0.8035
2024-11-28 16:58:18.778677: val_loss -0.6378
2024-11-28 16:58:18.779485: Pseudo dice [0.7477]
2024-11-28 16:58:18.780187: Epoch time: 46.81 s
2024-11-28 16:58:20.119685: 
2024-11-28 16:58:20.121608: Epoch 87
2024-11-28 16:58:20.122466: Current learning rate: 0.00921
2024-11-28 16:59:06.912434: Validation loss did not improve from -0.69269. Patience: 10/50
2024-11-28 16:59:06.914170: train_loss -0.8117
2024-11-28 16:59:06.915046: val_loss -0.6616
2024-11-28 16:59:06.915810: Pseudo dice [0.7643]
2024-11-28 16:59:06.916549: Epoch time: 46.8 s
2024-11-28 16:59:08.265423: 
2024-11-28 16:59:08.266827: Epoch 88
2024-11-28 16:59:08.267851: Current learning rate: 0.0092
2024-11-28 16:59:55.104501: Validation loss did not improve from -0.69269. Patience: 11/50
2024-11-28 16:59:55.105874: train_loss -0.8189
2024-11-28 16:59:55.106674: val_loss -0.6707
2024-11-28 16:59:55.107410: Pseudo dice [0.7696]
2024-11-28 16:59:55.108098: Epoch time: 46.84 s
2024-11-28 16:59:56.436015: 
2024-11-28 16:59:56.437403: Epoch 89
2024-11-28 16:59:56.438301: Current learning rate: 0.0092
2024-11-28 17:00:43.229430: Validation loss did not improve from -0.69269. Patience: 12/50
2024-11-28 17:00:43.231413: train_loss -0.8096
2024-11-28 17:00:43.232159: val_loss -0.6626
2024-11-28 17:00:43.232987: Pseudo dice [0.7679]
2024-11-28 17:00:43.233799: Epoch time: 46.8 s
2024-11-28 17:00:45.060704: 
2024-11-28 17:00:45.062217: Epoch 90
2024-11-28 17:00:45.062996: Current learning rate: 0.00919
2024-11-28 17:01:31.908843: Validation loss did not improve from -0.69269. Patience: 13/50
2024-11-28 17:01:31.910573: train_loss -0.8128
2024-11-28 17:01:31.911579: val_loss -0.6657
2024-11-28 17:01:31.912554: Pseudo dice [0.7662]
2024-11-28 17:01:31.913527: Epoch time: 46.85 s
2024-11-28 17:01:33.207004: 
2024-11-28 17:01:33.208696: Epoch 91
2024-11-28 17:01:33.209436: Current learning rate: 0.00918
2024-11-28 17:02:20.048120: Validation loss did not improve from -0.69269. Patience: 14/50
2024-11-28 17:02:20.050064: train_loss -0.8142
2024-11-28 17:02:20.051066: val_loss -0.6316
2024-11-28 17:02:20.052052: Pseudo dice [0.738]
2024-11-28 17:02:20.053113: Epoch time: 46.84 s
2024-11-28 17:02:21.305607: 
2024-11-28 17:02:21.307240: Epoch 92
2024-11-28 17:02:21.308122: Current learning rate: 0.00917
2024-11-28 17:03:08.139694: Validation loss did not improve from -0.69269. Patience: 15/50
2024-11-28 17:03:08.141148: train_loss -0.8117
2024-11-28 17:03:08.141998: val_loss -0.6631
2024-11-28 17:03:08.142795: Pseudo dice [0.7646]
2024-11-28 17:03:08.143582: Epoch time: 46.84 s
2024-11-28 17:03:09.377033: 
2024-11-28 17:03:09.379082: Epoch 93
2024-11-28 17:03:09.379910: Current learning rate: 0.00916
2024-11-28 17:03:56.179264: Validation loss did not improve from -0.69269. Patience: 16/50
2024-11-28 17:03:56.181118: train_loss -0.8156
2024-11-28 17:03:56.181970: val_loss -0.6625
2024-11-28 17:03:56.182754: Pseudo dice [0.7687]
2024-11-28 17:03:56.183582: Epoch time: 46.81 s
2024-11-28 17:03:57.446582: 
2024-11-28 17:03:57.448313: Epoch 94
2024-11-28 17:03:57.449427: Current learning rate: 0.00915
2024-11-28 17:04:44.254613: Validation loss did not improve from -0.69269. Patience: 17/50
2024-11-28 17:04:44.255673: train_loss -0.8157
2024-11-28 17:04:44.256358: val_loss -0.6248
2024-11-28 17:04:44.257212: Pseudo dice [0.7376]
2024-11-28 17:04:44.258045: Epoch time: 46.81 s
2024-11-28 17:04:46.049526: 
2024-11-28 17:04:46.050965: Epoch 95
2024-11-28 17:04:46.052013: Current learning rate: 0.00914
2024-11-28 17:05:32.859866: Validation loss did not improve from -0.69269. Patience: 18/50
2024-11-28 17:05:32.861616: train_loss -0.8177
2024-11-28 17:05:32.862655: val_loss -0.6264
2024-11-28 17:05:32.863374: Pseudo dice [0.7405]
2024-11-28 17:05:32.864205: Epoch time: 46.81 s
2024-11-28 17:05:34.167249: 
2024-11-28 17:05:34.168534: Epoch 96
2024-11-28 17:05:34.169284: Current learning rate: 0.00913
2024-11-28 17:06:20.980298: Validation loss did not improve from -0.69269. Patience: 19/50
2024-11-28 17:06:20.981405: train_loss -0.8142
2024-11-28 17:06:20.982157: val_loss -0.6607
2024-11-28 17:06:20.982841: Pseudo dice [0.7631]
2024-11-28 17:06:20.983608: Epoch time: 46.82 s
2024-11-28 17:06:22.682776: 
2024-11-28 17:06:22.684554: Epoch 97
2024-11-28 17:06:22.685431: Current learning rate: 0.00912
2024-11-28 17:07:09.483947: Validation loss did not improve from -0.69269. Patience: 20/50
2024-11-28 17:07:09.485641: train_loss -0.8136
2024-11-28 17:07:09.486373: val_loss -0.6071
2024-11-28 17:07:09.487063: Pseudo dice [0.7261]
2024-11-28 17:07:09.487771: Epoch time: 46.8 s
2024-11-28 17:07:10.755661: 
2024-11-28 17:07:10.757004: Epoch 98
2024-11-28 17:07:10.757800: Current learning rate: 0.00911
2024-11-28 17:07:57.572340: Validation loss did not improve from -0.69269. Patience: 21/50
2024-11-28 17:07:57.574007: train_loss -0.8121
2024-11-28 17:07:57.574816: val_loss -0.6265
2024-11-28 17:07:57.575598: Pseudo dice [0.7399]
2024-11-28 17:07:57.576288: Epoch time: 46.82 s
2024-11-28 17:07:58.836135: 
2024-11-28 17:07:58.837779: Epoch 99
2024-11-28 17:07:58.838888: Current learning rate: 0.0091
2024-11-28 17:08:45.634763: Validation loss did not improve from -0.69269. Patience: 22/50
2024-11-28 17:08:45.636321: train_loss -0.8165
2024-11-28 17:08:45.637329: val_loss -0.6353
2024-11-28 17:08:45.638339: Pseudo dice [0.7429]
2024-11-28 17:08:45.639108: Epoch time: 46.8 s
2024-11-28 17:08:47.502038: 
2024-11-28 17:08:47.503698: Epoch 100
2024-11-28 17:08:47.504475: Current learning rate: 0.0091
2024-11-28 17:09:34.345185: Validation loss did not improve from -0.69269. Patience: 23/50
2024-11-28 17:09:34.346609: train_loss -0.815
2024-11-28 17:09:34.347470: val_loss -0.675
2024-11-28 17:09:34.348438: Pseudo dice [0.7765]
2024-11-28 17:09:34.349502: Epoch time: 46.85 s
2024-11-28 17:09:35.608451: 
2024-11-28 17:09:35.609779: Epoch 101
2024-11-28 17:09:35.610608: Current learning rate: 0.00909
2024-11-28 17:10:22.438417: Validation loss did not improve from -0.69269. Patience: 24/50
2024-11-28 17:10:22.439771: train_loss -0.815
2024-11-28 17:10:22.440830: val_loss -0.6767
2024-11-28 17:10:22.441777: Pseudo dice [0.7775]
2024-11-28 17:10:22.442682: Epoch time: 46.83 s
2024-11-28 17:10:23.681735: 
2024-11-28 17:10:23.682792: Epoch 102
2024-11-28 17:10:23.683752: Current learning rate: 0.00908
2024-11-28 17:11:10.505302: Validation loss did not improve from -0.69269. Patience: 25/50
2024-11-28 17:11:10.506784: train_loss -0.8155
2024-11-28 17:11:10.507646: val_loss -0.6565
2024-11-28 17:11:10.508419: Pseudo dice [0.7618]
2024-11-28 17:11:10.509152: Epoch time: 46.83 s
2024-11-28 17:11:11.826252: 
2024-11-28 17:11:11.827860: Epoch 103
2024-11-28 17:11:11.828687: Current learning rate: 0.00907
2024-11-28 17:11:58.646046: Validation loss did not improve from -0.69269. Patience: 26/50
2024-11-28 17:11:58.647816: train_loss -0.8161
2024-11-28 17:11:58.648746: val_loss -0.6695
2024-11-28 17:11:58.649557: Pseudo dice [0.7727]
2024-11-28 17:11:58.650325: Epoch time: 46.82 s
2024-11-28 17:11:59.903232: 
2024-11-28 17:11:59.904873: Epoch 104
2024-11-28 17:11:59.905801: Current learning rate: 0.00906
2024-11-28 17:12:46.692876: Validation loss did not improve from -0.69269. Patience: 27/50
2024-11-28 17:12:46.694370: train_loss -0.8169
2024-11-28 17:12:46.695188: val_loss -0.6692
2024-11-28 17:12:46.696001: Pseudo dice [0.77]
2024-11-28 17:12:46.696639: Epoch time: 46.79 s
2024-11-28 17:12:48.506485: 
2024-11-28 17:12:48.508261: Epoch 105
2024-11-28 17:12:48.509408: Current learning rate: 0.00905
2024-11-28 17:13:35.272282: Validation loss did not improve from -0.69269. Patience: 28/50
2024-11-28 17:13:35.274001: train_loss -0.8236
2024-11-28 17:13:35.274942: val_loss -0.6521
2024-11-28 17:13:35.275643: Pseudo dice [0.7582]
2024-11-28 17:13:35.276384: Epoch time: 46.77 s
2024-11-28 17:13:36.514744: 
2024-11-28 17:13:36.515883: Epoch 106
2024-11-28 17:13:36.516744: Current learning rate: 0.00904
2024-11-28 17:14:23.309295: Validation loss did not improve from -0.69269. Patience: 29/50
2024-11-28 17:14:23.311028: train_loss -0.8209
2024-11-28 17:14:23.311925: val_loss -0.639
2024-11-28 17:14:23.312654: Pseudo dice [0.7507]
2024-11-28 17:14:23.313489: Epoch time: 46.8 s
2024-11-28 17:14:24.569705: 
2024-11-28 17:14:24.571134: Epoch 107
2024-11-28 17:14:24.571839: Current learning rate: 0.00903
2024-11-28 17:15:11.401531: Validation loss did not improve from -0.69269. Patience: 30/50
2024-11-28 17:15:11.403147: train_loss -0.8252
2024-11-28 17:15:11.403882: val_loss -0.6467
2024-11-28 17:15:11.404513: Pseudo dice [0.7516]
2024-11-28 17:15:11.405181: Epoch time: 46.83 s
2024-11-28 17:15:12.710461: 
2024-11-28 17:15:12.712805: Epoch 108
2024-11-28 17:15:12.713793: Current learning rate: 0.00902
2024-11-28 17:15:59.521396: Validation loss did not improve from -0.69269. Patience: 31/50
2024-11-28 17:15:59.522990: train_loss -0.8239
2024-11-28 17:15:59.523939: val_loss -0.6198
2024-11-28 17:15:59.524637: Pseudo dice [0.7411]
2024-11-28 17:15:59.525311: Epoch time: 46.81 s
2024-11-28 17:16:01.222855: 
2024-11-28 17:16:01.223602: Epoch 109
2024-11-28 17:16:01.224303: Current learning rate: 0.00901
2024-11-28 17:16:48.056377: Validation loss did not improve from -0.69269. Patience: 32/50
2024-11-28 17:16:48.057838: train_loss -0.825
2024-11-28 17:16:48.058820: val_loss -0.6226
2024-11-28 17:16:48.059607: Pseudo dice [0.7427]
2024-11-28 17:16:48.060332: Epoch time: 46.84 s
2024-11-28 17:16:49.923839: 
2024-11-28 17:16:49.925718: Epoch 110
2024-11-28 17:16:49.926574: Current learning rate: 0.009
2024-11-28 17:17:36.771804: Validation loss did not improve from -0.69269. Patience: 33/50
2024-11-28 17:17:36.773522: train_loss -0.8232
2024-11-28 17:17:36.774414: val_loss -0.6419
2024-11-28 17:17:36.775314: Pseudo dice [0.7528]
2024-11-28 17:17:36.776157: Epoch time: 46.85 s
2024-11-28 17:17:38.110905: 
2024-11-28 17:17:38.112874: Epoch 111
2024-11-28 17:17:38.113685: Current learning rate: 0.009
2024-11-28 17:18:24.957187: Validation loss did not improve from -0.69269. Patience: 34/50
2024-11-28 17:18:24.958970: train_loss -0.8275
2024-11-28 17:18:24.960241: val_loss -0.6383
2024-11-28 17:18:24.961230: Pseudo dice [0.7525]
2024-11-28 17:18:24.962260: Epoch time: 46.85 s
2024-11-28 17:18:26.281573: 
2024-11-28 17:18:26.283352: Epoch 112
2024-11-28 17:18:26.284331: Current learning rate: 0.00899
2024-11-28 17:19:13.142006: Validation loss did not improve from -0.69269. Patience: 35/50
2024-11-28 17:19:13.143342: train_loss -0.8216
2024-11-28 17:19:13.144156: val_loss -0.6613
2024-11-28 17:19:13.144795: Pseudo dice [0.7682]
2024-11-28 17:19:13.145533: Epoch time: 46.86 s
2024-11-28 17:19:14.451782: 
2024-11-28 17:19:14.453457: Epoch 113
2024-11-28 17:19:14.454224: Current learning rate: 0.00898
2024-11-28 17:20:01.326533: Validation loss did not improve from -0.69269. Patience: 36/50
2024-11-28 17:20:01.328238: train_loss -0.8187
2024-11-28 17:20:01.329063: val_loss -0.6591
2024-11-28 17:20:01.329837: Pseudo dice [0.7565]
2024-11-28 17:20:01.330492: Epoch time: 46.88 s
2024-11-28 17:20:02.635101: 
2024-11-28 17:20:02.636511: Epoch 114
2024-11-28 17:20:02.637606: Current learning rate: 0.00897
2024-11-28 17:20:49.495692: Validation loss did not improve from -0.69269. Patience: 37/50
2024-11-28 17:20:49.496784: train_loss -0.8221
2024-11-28 17:20:49.497506: val_loss -0.6374
2024-11-28 17:20:49.498139: Pseudo dice [0.7485]
2024-11-28 17:20:49.498798: Epoch time: 46.86 s
2024-11-28 17:20:51.296340: 
2024-11-28 17:20:51.297594: Epoch 115
2024-11-28 17:20:51.298389: Current learning rate: 0.00896
2024-11-28 17:21:38.144763: Validation loss did not improve from -0.69269. Patience: 38/50
2024-11-28 17:21:38.146200: train_loss -0.8272
2024-11-28 17:21:38.147087: val_loss -0.6428
2024-11-28 17:21:38.147917: Pseudo dice [0.7591]
2024-11-28 17:21:38.148959: Epoch time: 46.85 s
2024-11-28 17:21:39.465308: 
2024-11-28 17:21:39.466375: Epoch 116
2024-11-28 17:21:39.467110: Current learning rate: 0.00895
2024-11-28 17:22:26.319776: Validation loss did not improve from -0.69269. Patience: 39/50
2024-11-28 17:22:26.321419: train_loss -0.8291
2024-11-28 17:22:26.322253: val_loss -0.5724
2024-11-28 17:22:26.322962: Pseudo dice [0.7071]
2024-11-28 17:22:26.323793: Epoch time: 46.86 s
2024-11-28 17:22:27.622768: 
2024-11-28 17:22:27.624732: Epoch 117
2024-11-28 17:22:27.625605: Current learning rate: 0.00894
2024-11-28 17:23:14.521367: Validation loss improved from -0.69269 to -0.69358! Patience: 39/50
2024-11-28 17:23:14.523245: train_loss -0.8196
2024-11-28 17:23:14.524096: val_loss -0.6936
2024-11-28 17:23:14.524791: Pseudo dice [0.7827]
2024-11-28 17:23:14.525571: Epoch time: 46.9 s
2024-11-28 17:23:15.895366: 
2024-11-28 17:23:15.896944: Epoch 118
2024-11-28 17:23:15.897704: Current learning rate: 0.00893
2024-11-28 17:24:02.716106: Validation loss did not improve from -0.69358. Patience: 1/50
2024-11-28 17:24:02.717401: train_loss -0.8264
2024-11-28 17:24:02.718453: val_loss -0.6494
2024-11-28 17:24:02.719388: Pseudo dice [0.7505]
2024-11-28 17:24:02.720187: Epoch time: 46.82 s
2024-11-28 17:24:04.040613: 
2024-11-28 17:24:04.042419: Epoch 119
2024-11-28 17:24:04.043322: Current learning rate: 0.00892
2024-11-28 17:24:50.856196: Validation loss did not improve from -0.69358. Patience: 2/50
2024-11-28 17:24:50.858080: train_loss -0.8291
2024-11-28 17:24:50.859098: val_loss -0.683
2024-11-28 17:24:50.859888: Pseudo dice [0.783]
2024-11-28 17:24:50.860552: Epoch time: 46.82 s
2024-11-28 17:24:53.049746: 
2024-11-28 17:24:53.051335: Epoch 120
2024-11-28 17:24:53.052313: Current learning rate: 0.00891
2024-11-28 17:25:39.786668: Validation loss did not improve from -0.69358. Patience: 3/50
2024-11-28 17:25:39.788210: train_loss -0.8299
2024-11-28 17:25:39.788996: val_loss -0.6459
2024-11-28 17:25:39.789853: Pseudo dice [0.7575]
2024-11-28 17:25:39.790580: Epoch time: 46.74 s
2024-11-28 17:25:41.089454: 
2024-11-28 17:25:41.090623: Epoch 121
2024-11-28 17:25:41.091609: Current learning rate: 0.0089
2024-11-28 17:26:27.851439: Validation loss did not improve from -0.69358. Patience: 4/50
2024-11-28 17:26:27.853211: train_loss -0.828
2024-11-28 17:26:27.854023: val_loss -0.6471
2024-11-28 17:26:27.854856: Pseudo dice [0.7597]
2024-11-28 17:26:27.855704: Epoch time: 46.76 s
2024-11-28 17:26:29.108129: 
2024-11-28 17:26:29.109668: Epoch 122
2024-11-28 17:26:29.110566: Current learning rate: 0.00889
2024-11-28 17:27:15.916300: Validation loss did not improve from -0.69358. Patience: 5/50
2024-11-28 17:27:15.917404: train_loss -0.8286
2024-11-28 17:27:15.918222: val_loss -0.6589
2024-11-28 17:27:15.919100: Pseudo dice [0.7655]
2024-11-28 17:27:15.919984: Epoch time: 46.81 s
2024-11-28 17:27:17.235591: 
2024-11-28 17:27:17.236967: Epoch 123
2024-11-28 17:27:17.237775: Current learning rate: 0.00889
2024-11-28 17:28:04.080048: Validation loss did not improve from -0.69358. Patience: 6/50
2024-11-28 17:28:04.081803: train_loss -0.8314
2024-11-28 17:28:04.082609: val_loss -0.6529
2024-11-28 17:28:04.083460: Pseudo dice [0.758]
2024-11-28 17:28:04.084393: Epoch time: 46.85 s
2024-11-28 17:28:05.401956: 
2024-11-28 17:28:05.403678: Epoch 124
2024-11-28 17:28:05.404503: Current learning rate: 0.00888
2024-11-28 17:28:52.249589: Validation loss did not improve from -0.69358. Patience: 7/50
2024-11-28 17:28:52.251233: train_loss -0.8253
2024-11-28 17:28:52.252001: val_loss -0.6529
2024-11-28 17:28:52.252674: Pseudo dice [0.7576]
2024-11-28 17:28:52.253443: Epoch time: 46.85 s
2024-11-28 17:28:54.118784: 
2024-11-28 17:28:54.120438: Epoch 125
2024-11-28 17:28:54.121318: Current learning rate: 0.00887
2024-11-28 17:29:40.890381: Validation loss did not improve from -0.69358. Patience: 8/50
2024-11-28 17:29:40.892233: train_loss -0.8311
2024-11-28 17:29:40.893221: val_loss -0.6481
2024-11-28 17:29:40.894281: Pseudo dice [0.759]
2024-11-28 17:29:40.895215: Epoch time: 46.77 s
2024-11-28 17:29:42.179385: 
2024-11-28 17:29:42.180823: Epoch 126
2024-11-28 17:29:42.181533: Current learning rate: 0.00886
2024-11-28 17:30:28.852197: Validation loss did not improve from -0.69358. Patience: 9/50
2024-11-28 17:30:28.853882: train_loss -0.8262
2024-11-28 17:30:28.854851: val_loss -0.6427
2024-11-28 17:30:28.855629: Pseudo dice [0.7538]
2024-11-28 17:30:28.856322: Epoch time: 46.68 s
2024-11-28 17:30:30.096649: 
2024-11-28 17:30:30.097726: Epoch 127
2024-11-28 17:30:30.098611: Current learning rate: 0.00885
2024-11-28 17:31:16.588426: Validation loss did not improve from -0.69358. Patience: 10/50
2024-11-28 17:31:16.590024: train_loss -0.8202
2024-11-28 17:31:16.591017: val_loss -0.6295
2024-11-28 17:31:16.592111: Pseudo dice [0.7358]
2024-11-28 17:31:16.593187: Epoch time: 46.5 s
2024-11-28 17:31:17.852974: 
2024-11-28 17:31:17.854778: Epoch 128
2024-11-28 17:31:17.856158: Current learning rate: 0.00884
2024-11-28 17:32:04.283719: Validation loss did not improve from -0.69358. Patience: 11/50
2024-11-28 17:32:04.285453: train_loss -0.8283
2024-11-28 17:32:04.286192: val_loss -0.6627
2024-11-28 17:32:04.286997: Pseudo dice [0.7662]
2024-11-28 17:32:04.287725: Epoch time: 46.43 s
2024-11-28 17:32:05.679112: 
2024-11-28 17:32:05.680829: Epoch 129
2024-11-28 17:32:05.681702: Current learning rate: 0.00883
2024-11-28 17:32:53.148270: Validation loss did not improve from -0.69358. Patience: 12/50
2024-11-28 17:32:53.149751: train_loss -0.8251
2024-11-28 17:32:53.150632: val_loss -0.6292
2024-11-28 17:32:53.151315: Pseudo dice [0.7415]
2024-11-28 17:32:53.152098: Epoch time: 47.47 s
2024-11-28 17:32:54.997295: 
2024-11-28 17:32:54.999467: Epoch 130
2024-11-28 17:32:55.000558: Current learning rate: 0.00882
2024-11-28 17:34:24.384080: Validation loss did not improve from -0.69358. Patience: 13/50
2024-11-28 17:34:24.384957: train_loss -0.827
2024-11-28 17:34:24.385796: val_loss -0.6087
2024-11-28 17:34:24.386552: Pseudo dice [0.7263]
2024-11-28 17:34:24.387320: Epoch time: 89.39 s
2024-11-28 17:34:25.809288: 
2024-11-28 17:34:25.810928: Epoch 131
2024-11-28 17:34:25.811866: Current learning rate: 0.00881
2024-11-28 17:35:49.025739: Validation loss did not improve from -0.69358. Patience: 14/50
2024-11-28 17:35:49.026808: train_loss -0.8293
2024-11-28 17:35:49.027784: val_loss -0.6426
2024-11-28 17:35:49.028620: Pseudo dice [0.7565]
2024-11-28 17:35:49.029546: Epoch time: 83.22 s
2024-11-28 17:35:50.428226: 
2024-11-28 17:35:50.429698: Epoch 132
2024-11-28 17:35:50.430591: Current learning rate: 0.0088
2024-11-28 17:37:27.530002: Validation loss did not improve from -0.69358. Patience: 15/50
2024-11-28 17:37:27.531109: train_loss -0.8261
2024-11-28 17:37:27.532064: val_loss -0.6421
2024-11-28 17:37:27.532854: Pseudo dice [0.7538]
2024-11-28 17:37:27.533629: Epoch time: 97.1 s
2024-11-28 17:37:28.918736: 
2024-11-28 17:37:28.920269: Epoch 133
2024-11-28 17:37:28.921044: Current learning rate: 0.00879
2024-11-28 17:39:06.108031: Validation loss did not improve from -0.69358. Patience: 16/50
2024-11-28 17:39:06.109358: train_loss -0.8325
2024-11-28 17:39:06.110404: val_loss -0.6134
2024-11-28 17:39:06.111303: Pseudo dice [0.7357]
2024-11-28 17:39:06.112059: Epoch time: 97.19 s
2024-11-28 17:39:07.498319: 
2024-11-28 17:39:07.499969: Epoch 134
2024-11-28 17:39:07.500741: Current learning rate: 0.00879
2024-11-28 17:40:44.837328: Validation loss did not improve from -0.69358. Patience: 17/50
2024-11-28 17:40:44.838417: train_loss -0.8334
2024-11-28 17:40:44.839295: val_loss -0.6631
2024-11-28 17:40:44.840042: Pseudo dice [0.7665]
2024-11-28 17:40:44.840756: Epoch time: 97.34 s
2024-11-28 17:40:46.810477: 
2024-11-28 17:40:46.811624: Epoch 135
2024-11-28 17:40:46.812350: Current learning rate: 0.00878
2024-11-28 17:42:23.589510: Validation loss did not improve from -0.69358. Patience: 18/50
2024-11-28 17:42:23.590914: train_loss -0.8325
2024-11-28 17:42:23.592199: val_loss -0.6727
2024-11-28 17:42:23.593250: Pseudo dice [0.7725]
2024-11-28 17:42:23.594369: Epoch time: 96.78 s
2024-11-28 17:42:25.055756: 
2024-11-28 17:42:25.056809: Epoch 136
2024-11-28 17:42:25.057587: Current learning rate: 0.00877
2024-11-28 17:44:02.489557: Validation loss did not improve from -0.69358. Patience: 19/50
2024-11-28 17:44:02.490663: train_loss -0.8306
2024-11-28 17:44:02.491578: val_loss -0.6463
2024-11-28 17:44:02.492238: Pseudo dice [0.7501]
2024-11-28 17:44:02.493090: Epoch time: 97.44 s
2024-11-28 17:44:03.904675: 
2024-11-28 17:44:03.905821: Epoch 137
2024-11-28 17:44:03.906659: Current learning rate: 0.00876
2024-11-28 17:45:41.197577: Validation loss did not improve from -0.69358. Patience: 20/50
2024-11-28 17:45:41.198508: train_loss -0.8336
2024-11-28 17:45:41.199456: val_loss -0.6765
2024-11-28 17:45:41.200426: Pseudo dice [0.7762]
2024-11-28 17:45:41.201318: Epoch time: 97.3 s
2024-11-28 17:45:42.601672: 
2024-11-28 17:45:42.602589: Epoch 138
2024-11-28 17:45:42.603440: Current learning rate: 0.00875
2024-11-28 17:47:19.074121: Validation loss did not improve from -0.69358. Patience: 21/50
2024-11-28 17:47:19.074913: train_loss -0.8342
2024-11-28 17:47:19.075664: val_loss -0.6198
2024-11-28 17:47:19.076425: Pseudo dice [0.7375]
2024-11-28 17:47:19.077184: Epoch time: 96.47 s
2024-11-28 17:47:20.479183: 
2024-11-28 17:47:20.480766: Epoch 139
2024-11-28 17:47:20.481586: Current learning rate: 0.00874
2024-11-28 17:48:57.760200: Validation loss did not improve from -0.69358. Patience: 22/50
2024-11-28 17:48:57.761330: train_loss -0.8322
2024-11-28 17:48:57.762380: val_loss -0.6656
2024-11-28 17:48:57.763159: Pseudo dice [0.766]
2024-11-28 17:48:57.763930: Epoch time: 97.28 s
2024-11-28 17:48:59.713762: 
2024-11-28 17:48:59.715207: Epoch 140
2024-11-28 17:48:59.715937: Current learning rate: 0.00873
2024-11-28 17:50:36.492236: Validation loss did not improve from -0.69358. Patience: 23/50
2024-11-28 17:50:36.493065: train_loss -0.8334
2024-11-28 17:50:36.493969: val_loss -0.6559
2024-11-28 17:50:36.494605: Pseudo dice [0.7633]
2024-11-28 17:50:36.495277: Epoch time: 96.78 s
2024-11-28 17:50:37.871840: 
2024-11-28 17:50:37.873412: Epoch 141
2024-11-28 17:50:37.874245: Current learning rate: 0.00872
2024-11-28 17:52:15.791883: Validation loss did not improve from -0.69358. Patience: 24/50
2024-11-28 17:52:15.793470: train_loss -0.8342
2024-11-28 17:52:15.794416: val_loss -0.6746
2024-11-28 17:52:15.795186: Pseudo dice [0.7753]
2024-11-28 17:52:15.795879: Epoch time: 97.92 s
2024-11-28 17:52:17.586544: 
2024-11-28 17:52:17.588053: Epoch 142
2024-11-28 17:52:17.588802: Current learning rate: 0.00871
2024-11-28 17:53:57.124386: Validation loss did not improve from -0.69358. Patience: 25/50
2024-11-28 17:53:57.125294: train_loss -0.8343
2024-11-28 17:53:57.126018: val_loss -0.6704
2024-11-28 17:53:57.126776: Pseudo dice [0.7771]
2024-11-28 17:53:57.127573: Epoch time: 99.54 s
2024-11-28 17:53:58.512323: 
2024-11-28 17:53:58.513795: Epoch 143
2024-11-28 17:53:58.514689: Current learning rate: 0.0087
2024-11-28 17:55:37.486197: Validation loss did not improve from -0.69358. Patience: 26/50
2024-11-28 17:55:37.487156: train_loss -0.8412
2024-11-28 17:55:37.487846: val_loss -0.6488
2024-11-28 17:55:37.488569: Pseudo dice [0.7548]
2024-11-28 17:55:37.489275: Epoch time: 98.98 s
2024-11-28 17:55:38.902387: 
2024-11-28 17:55:38.904108: Epoch 144
2024-11-28 17:55:38.904980: Current learning rate: 0.00869
2024-11-28 17:57:16.573935: Validation loss did not improve from -0.69358. Patience: 27/50
2024-11-28 17:57:16.575406: train_loss -0.8393
2024-11-28 17:57:16.576274: val_loss -0.6399
2024-11-28 17:57:16.577059: Pseudo dice [0.7522]
2024-11-28 17:57:16.577808: Epoch time: 97.67 s
2024-11-28 17:57:18.612131: 
2024-11-28 17:57:18.613469: Epoch 145
2024-11-28 17:57:18.614381: Current learning rate: 0.00868
2024-11-28 17:58:56.231141: Validation loss did not improve from -0.69358. Patience: 28/50
2024-11-28 17:58:56.232345: train_loss -0.8374
2024-11-28 17:58:56.233429: val_loss -0.6255
2024-11-28 17:58:56.234253: Pseudo dice [0.7403]
2024-11-28 17:58:56.235143: Epoch time: 97.62 s
2024-11-28 17:58:57.691122: 
2024-11-28 17:58:57.692362: Epoch 146
2024-11-28 17:58:57.693165: Current learning rate: 0.00868
2024-11-28 18:00:34.586203: Validation loss did not improve from -0.69358. Patience: 29/50
2024-11-28 18:00:34.587192: train_loss -0.8356
2024-11-28 18:00:34.588067: val_loss -0.6375
2024-11-28 18:00:34.588812: Pseudo dice [0.7522]
2024-11-28 18:00:34.589630: Epoch time: 96.9 s
2024-11-28 18:00:35.979134: 
2024-11-28 18:00:35.980200: Epoch 147
2024-11-28 18:00:35.980850: Current learning rate: 0.00867
2024-11-28 18:02:13.502315: Validation loss did not improve from -0.69358. Patience: 30/50
2024-11-28 18:02:13.503617: train_loss -0.8394
2024-11-28 18:02:13.504434: val_loss -0.6637
2024-11-28 18:02:13.505161: Pseudo dice [0.7675]
2024-11-28 18:02:13.505864: Epoch time: 97.53 s
2024-11-28 18:02:14.888942: 
2024-11-28 18:02:14.890772: Epoch 148
2024-11-28 18:02:14.891654: Current learning rate: 0.00866
2024-11-28 18:03:52.308299: Validation loss did not improve from -0.69358. Patience: 31/50
2024-11-28 18:03:52.309456: train_loss -0.8386
2024-11-28 18:03:52.310738: val_loss -0.6326
2024-11-28 18:03:52.311569: Pseudo dice [0.7437]
2024-11-28 18:03:52.312399: Epoch time: 97.42 s
2024-11-28 18:03:53.716307: 
2024-11-28 18:03:53.717604: Epoch 149
2024-11-28 18:03:53.718506: Current learning rate: 0.00865
2024-11-28 18:05:30.359237: Validation loss did not improve from -0.69358. Patience: 32/50
2024-11-28 18:05:30.360191: train_loss -0.8356
2024-11-28 18:05:30.361225: val_loss -0.6277
2024-11-28 18:05:30.361914: Pseudo dice [0.7495]
2024-11-28 18:05:30.362578: Epoch time: 96.65 s
2024-11-28 18:05:32.354272: 
2024-11-28 18:05:32.355666: Epoch 150
2024-11-28 18:05:32.356492: Current learning rate: 0.00864
2024-11-28 18:07:09.745271: Validation loss did not improve from -0.69358. Patience: 33/50
2024-11-28 18:07:09.746445: train_loss -0.8391
2024-11-28 18:07:09.747357: val_loss -0.6557
2024-11-28 18:07:09.748061: Pseudo dice [0.7624]
2024-11-28 18:07:09.748820: Epoch time: 97.39 s
2024-11-28 18:07:11.150941: 
2024-11-28 18:07:11.152260: Epoch 151
2024-11-28 18:07:11.153030: Current learning rate: 0.00863
2024-11-28 18:08:47.938889: Validation loss did not improve from -0.69358. Patience: 34/50
2024-11-28 18:08:47.939938: train_loss -0.8326
2024-11-28 18:08:47.940992: val_loss -0.6577
2024-11-28 18:08:47.942032: Pseudo dice [0.7686]
2024-11-28 18:08:47.943022: Epoch time: 96.79 s
2024-11-28 18:08:49.325121: 
2024-11-28 18:08:49.326238: Epoch 152
2024-11-28 18:08:49.327001: Current learning rate: 0.00862
2024-11-28 18:10:26.615055: Validation loss did not improve from -0.69358. Patience: 35/50
2024-11-28 18:10:26.615992: train_loss -0.8405
2024-11-28 18:10:26.616813: val_loss -0.6408
2024-11-28 18:10:26.617647: Pseudo dice [0.7487]
2024-11-28 18:10:26.618481: Epoch time: 97.29 s
2024-11-28 18:10:27.999609: 
2024-11-28 18:10:28.000689: Epoch 153
2024-11-28 18:10:28.001409: Current learning rate: 0.00861
2024-11-28 18:12:05.472588: Validation loss did not improve from -0.69358. Patience: 36/50
2024-11-28 18:12:05.473383: train_loss -0.8401
2024-11-28 18:12:05.474248: val_loss -0.6651
2024-11-28 18:12:05.475248: Pseudo dice [0.7729]
2024-11-28 18:12:05.476037: Epoch time: 97.47 s
2024-11-28 18:12:07.315203: 
2024-11-28 18:12:07.316497: Epoch 154
2024-11-28 18:12:07.317452: Current learning rate: 0.0086
2024-11-28 18:13:44.709425: Validation loss did not improve from -0.69358. Patience: 37/50
2024-11-28 18:13:44.710579: train_loss -0.834
2024-11-28 18:13:44.711629: val_loss -0.6463
2024-11-28 18:13:44.712413: Pseudo dice [0.7567]
2024-11-28 18:13:44.713185: Epoch time: 97.4 s
2024-11-28 18:13:46.723628: 
2024-11-28 18:13:46.725050: Epoch 155
2024-11-28 18:13:46.725820: Current learning rate: 0.00859
2024-11-28 18:15:24.077695: Validation loss did not improve from -0.69358. Patience: 38/50
2024-11-28 18:15:24.078767: train_loss -0.8307
2024-11-28 18:15:24.079740: val_loss -0.6067
2024-11-28 18:15:24.080623: Pseudo dice [0.7242]
2024-11-28 18:15:24.081530: Epoch time: 97.36 s
2024-11-28 18:15:25.545586: 
2024-11-28 18:15:25.546978: Epoch 156
2024-11-28 18:15:25.547820: Current learning rate: 0.00858
2024-11-28 18:17:02.188141: Validation loss did not improve from -0.69358. Patience: 39/50
2024-11-28 18:17:02.189015: train_loss -0.8367
2024-11-28 18:17:02.189928: val_loss -0.6268
2024-11-28 18:17:02.190655: Pseudo dice [0.7453]
2024-11-28 18:17:02.191425: Epoch time: 96.64 s
2024-11-28 18:17:03.598586: 
2024-11-28 18:17:03.599835: Epoch 157
2024-11-28 18:17:03.600662: Current learning rate: 0.00858
2024-11-28 18:18:40.944170: Validation loss did not improve from -0.69358. Patience: 40/50
2024-11-28 18:18:40.944993: train_loss -0.8373
2024-11-28 18:18:40.945729: val_loss -0.547
2024-11-28 18:18:40.946407: Pseudo dice [0.686]
2024-11-28 18:18:40.947190: Epoch time: 97.35 s
2024-11-28 18:18:42.383548: 
2024-11-28 18:18:42.384867: Epoch 158
2024-11-28 18:18:42.385741: Current learning rate: 0.00857
2024-11-28 18:20:19.809240: Validation loss did not improve from -0.69358. Patience: 41/50
2024-11-28 18:20:19.810133: train_loss -0.8291
2024-11-28 18:20:19.811268: val_loss -0.6658
2024-11-28 18:20:19.812234: Pseudo dice [0.7725]
2024-11-28 18:20:19.813149: Epoch time: 97.43 s
2024-11-28 18:20:21.234171: 
2024-11-28 18:20:21.235867: Epoch 159
2024-11-28 18:20:21.236889: Current learning rate: 0.00856
2024-11-28 18:21:58.576940: Validation loss did not improve from -0.69358. Patience: 42/50
2024-11-28 18:21:58.578260: train_loss -0.8356
2024-11-28 18:21:58.579285: val_loss -0.6557
2024-11-28 18:21:58.580119: Pseudo dice [0.7628]
2024-11-28 18:21:58.581194: Epoch time: 97.35 s
2024-11-28 18:22:00.585470: 
2024-11-28 18:22:00.586773: Epoch 160
2024-11-28 18:22:00.587604: Current learning rate: 0.00855
2024-11-28 18:23:38.072137: Validation loss did not improve from -0.69358. Patience: 43/50
2024-11-28 18:23:38.073376: train_loss -0.8327
2024-11-28 18:23:38.074317: val_loss -0.6471
2024-11-28 18:23:38.075079: Pseudo dice [0.7586]
2024-11-28 18:23:38.075881: Epoch time: 97.49 s
2024-11-28 18:23:39.482359: 
2024-11-28 18:23:39.483964: Epoch 161
2024-11-28 18:23:39.484880: Current learning rate: 0.00854
2024-11-28 18:25:16.184103: Validation loss did not improve from -0.69358. Patience: 44/50
2024-11-28 18:25:16.185213: train_loss -0.8339
2024-11-28 18:25:16.186084: val_loss -0.6404
2024-11-28 18:25:16.186895: Pseudo dice [0.7513]
2024-11-28 18:25:16.187886: Epoch time: 96.7 s
2024-11-28 18:25:17.591847: 
2024-11-28 18:25:17.593544: Epoch 162
2024-11-28 18:25:17.594352: Current learning rate: 0.00853
2024-11-28 18:26:55.003070: Validation loss did not improve from -0.69358. Patience: 45/50
2024-11-28 18:26:55.003934: train_loss -0.8284
2024-11-28 18:26:55.004833: val_loss -0.5861
2024-11-28 18:26:55.005565: Pseudo dice [0.7154]
2024-11-28 18:26:55.006265: Epoch time: 97.41 s
2024-11-28 18:26:56.414989: 
2024-11-28 18:26:56.416524: Epoch 163
2024-11-28 18:26:56.417428: Current learning rate: 0.00852
2024-11-28 18:28:33.785449: Validation loss did not improve from -0.69358. Patience: 46/50
2024-11-28 18:28:33.786799: train_loss -0.8332
2024-11-28 18:28:33.787679: val_loss -0.6598
2024-11-28 18:28:33.788448: Pseudo dice [0.7657]
2024-11-28 18:28:33.789153: Epoch time: 97.37 s
2024-11-28 18:28:35.637195: 
2024-11-28 18:28:35.638818: Epoch 164
2024-11-28 18:28:35.639692: Current learning rate: 0.00851
2024-11-28 18:30:13.043493: Validation loss did not improve from -0.69358. Patience: 47/50
2024-11-28 18:30:13.044681: train_loss -0.836
2024-11-28 18:30:13.045640: val_loss -0.6693
2024-11-28 18:30:13.046394: Pseudo dice [0.7745]
2024-11-28 18:30:13.047200: Epoch time: 97.41 s
2024-11-28 18:30:15.016074: 
2024-11-28 18:30:15.017209: Epoch 165
2024-11-28 18:30:15.018027: Current learning rate: 0.0085
2024-11-28 18:31:52.427030: Validation loss did not improve from -0.69358. Patience: 48/50
2024-11-28 18:31:52.428361: train_loss -0.8373
2024-11-28 18:31:52.429237: val_loss -0.6464
2024-11-28 18:31:52.430037: Pseudo dice [0.7618]
2024-11-28 18:31:52.430820: Epoch time: 97.41 s
2024-11-28 18:31:53.809076: 
2024-11-28 18:31:53.810038: Epoch 166
2024-11-28 18:31:53.810716: Current learning rate: 0.00849
2024-11-28 18:33:32.723013: Validation loss did not improve from -0.69358. Patience: 49/50
2024-11-28 18:33:32.723903: train_loss -0.8329
2024-11-28 18:33:32.724844: val_loss -0.6691
2024-11-28 18:33:32.725533: Pseudo dice [0.7748]
2024-11-28 18:33:32.726285: Epoch time: 98.92 s
2024-11-28 18:33:34.084446: 
2024-11-28 18:33:34.085753: Epoch 167
2024-11-28 18:33:34.086543: Current learning rate: 0.00848
2024-11-28 18:35:13.700807: Validation loss did not improve from -0.69358. Patience: 50/50
2024-11-28 18:35:13.701998: train_loss -0.8333
2024-11-28 18:35:13.703101: val_loss -0.6396
2024-11-28 18:35:13.703956: Pseudo dice [0.7516]
2024-11-28 18:35:13.704724: Epoch time: 99.62 s
2024-11-28 18:35:15.185517: Patience reached. Stopping training.
2024-11-28 18:35:16.166950: Training done.
2024-11-28 18:35:16.313092: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset306_Sohee_Ajay_Calcium_OCT/splits_final.json
2024-11-28 18:35:16.317111: The split file contains 5 splits.
2024-11-28 18:35:16.317946: Desired fold for training: 0
2024-11-28 18:35:16.318757: This split has 10 training and 3 validation cases.
2024-11-28 18:35:16.319630: predicting 02008Pre
2024-11-28 18:35:16.330199: 02008Pre, shape torch.Size([1, 171, 498, 498]), rank 0
2024-11-28 18:35:38.585370: predicting 106-002
2024-11-28 18:35:38.601668: 106-002, shape torch.Size([1, 539, 498, 498]), rank 0
2024-11-28 18:36:10.795653: predicting 701-013
2024-11-28 18:36:10.823212: 701-013, shape torch.Size([1, 375, 498, 498]), rank 0
2024-11-28 18:36:58.386020: Validation complete
2024-11-28 18:36:58.387103: Mean Validation Dice:  0.7347039971114655
2024-11-28 17:32:07.971734: unpacking done...
2024-11-28 17:32:08.160383: Unable to plot network architecture: nnUNet_compile is enabled!
2024-11-28 17:32:08.298273: 
2024-11-28 17:32:08.299799: Epoch 0
2024-11-28 17:32:08.300695: Current learning rate: 0.01
2024-11-28 17:34:04.858608: Validation loss improved from 1000.00000 to -0.33852! Patience: 0/50
2024-11-28 17:34:04.859483: train_loss -0.2066
2024-11-28 17:34:04.860775: val_loss -0.3385
2024-11-28 17:34:04.861821: Pseudo dice [0.4775]
2024-11-28 17:34:04.862888: Epoch time: 116.56 s
2024-11-28 17:34:04.864410: Yayy! New best EMA pseudo Dice: 0.4775
2024-11-28 17:34:06.944531: 
2024-11-28 17:34:06.945990: Epoch 1
2024-11-28 17:34:06.946872: Current learning rate: 0.00999
2024-11-28 17:34:53.572992: Validation loss improved from -0.33852 to -0.52177! Patience: 0/50
2024-11-28 17:34:53.574788: train_loss -0.4358
2024-11-28 17:34:53.575452: val_loss -0.5218
2024-11-28 17:34:53.576077: Pseudo dice [0.6514]
2024-11-28 17:34:53.576739: Epoch time: 46.63 s
2024-11-28 17:34:53.577311: Yayy! New best EMA pseudo Dice: 0.4949
2024-11-28 17:34:55.461245: 
2024-11-28 17:34:55.462626: Epoch 2
2024-11-28 17:34:55.463538: Current learning rate: 0.00998
2024-11-28 17:35:42.122982: Validation loss improved from -0.52177 to -0.53535! Patience: 0/50
2024-11-28 17:35:42.124592: train_loss -0.5463
2024-11-28 17:35:42.125304: val_loss -0.5353
2024-11-28 17:35:42.125933: Pseudo dice [0.627]
2024-11-28 17:35:42.126706: Epoch time: 46.66 s
2024-11-28 17:35:42.127412: Yayy! New best EMA pseudo Dice: 0.5081
2024-11-28 17:35:44.060423: 
2024-11-28 17:35:44.061659: Epoch 3
2024-11-28 17:35:44.062533: Current learning rate: 0.00997
2024-11-28 17:36:30.650941: Validation loss improved from -0.53535 to -0.56186! Patience: 0/50
2024-11-28 17:36:30.652718: train_loss -0.5831
2024-11-28 17:36:30.653440: val_loss -0.5619
2024-11-28 17:36:30.654064: Pseudo dice [0.6488]
2024-11-28 17:36:30.654779: Epoch time: 46.59 s
2024-11-28 17:36:30.655496: Yayy! New best EMA pseudo Dice: 0.5222
2024-11-28 17:36:32.496392: 
2024-11-28 17:36:32.497193: Epoch 4
2024-11-28 17:36:32.497848: Current learning rate: 0.00996
2024-11-28 17:37:19.109442: Validation loss improved from -0.56186 to -0.57564! Patience: 0/50
2024-11-28 17:37:19.110935: train_loss -0.6183
2024-11-28 17:37:19.111853: val_loss -0.5756
2024-11-28 17:37:19.112583: Pseudo dice [0.6553]
2024-11-28 17:37:19.113353: Epoch time: 46.62 s
2024-11-28 17:37:19.571826: Yayy! New best EMA pseudo Dice: 0.5355
2024-11-28 17:37:21.486692: 
2024-11-28 17:37:21.489082: Epoch 5
2024-11-28 17:37:21.490057: Current learning rate: 0.00995
2024-11-28 17:38:08.131317: Validation loss improved from -0.57564 to -0.66025! Patience: 0/50
2024-11-28 17:38:08.133119: train_loss -0.6391
2024-11-28 17:38:08.134029: val_loss -0.6602
2024-11-28 17:38:08.134740: Pseudo dice [0.7268]
2024-11-28 17:38:08.135494: Epoch time: 46.65 s
2024-11-28 17:38:08.136182: Yayy! New best EMA pseudo Dice: 0.5546
2024-11-28 17:38:09.883669: 
2024-11-28 17:38:09.884586: Epoch 6
2024-11-28 17:38:09.885292: Current learning rate: 0.00995
2024-11-28 17:38:56.557247: Validation loss did not improve from -0.66025. Patience: 1/50
2024-11-28 17:38:56.558844: train_loss -0.6499
2024-11-28 17:38:56.559735: val_loss -0.649
2024-11-28 17:38:56.560668: Pseudo dice [0.7227]
2024-11-28 17:38:56.561986: Epoch time: 46.68 s
2024-11-28 17:38:56.562900: Yayy! New best EMA pseudo Dice: 0.5714
2024-11-28 17:38:58.317014: 
2024-11-28 17:38:58.318458: Epoch 7
2024-11-28 17:38:58.319269: Current learning rate: 0.00994
2024-11-28 17:39:44.995310: Validation loss did not improve from -0.66025. Patience: 2/50
2024-11-28 17:39:44.996622: train_loss -0.6649
2024-11-28 17:39:44.997380: val_loss -0.6251
2024-11-28 17:39:44.998080: Pseudo dice [0.6999]
2024-11-28 17:39:44.998698: Epoch time: 46.68 s
2024-11-28 17:39:44.999302: Yayy! New best EMA pseudo Dice: 0.5843
2024-11-28 17:39:47.355078: 
2024-11-28 17:39:47.356333: Epoch 8
2024-11-28 17:39:47.357087: Current learning rate: 0.00993
2024-11-28 17:40:34.077777: Validation loss did not improve from -0.66025. Patience: 3/50
2024-11-28 17:40:34.079301: train_loss -0.6724
2024-11-28 17:40:34.080187: val_loss -0.5799
2024-11-28 17:40:34.080966: Pseudo dice [0.6776]
2024-11-28 17:40:34.081621: Epoch time: 46.73 s
2024-11-28 17:40:34.082193: Yayy! New best EMA pseudo Dice: 0.5936
2024-11-28 17:40:35.956877: 
2024-11-28 17:40:35.958571: Epoch 9
2024-11-28 17:40:35.959299: Current learning rate: 0.00992
2024-11-28 17:41:22.676283: Validation loss improved from -0.66025 to -0.67127! Patience: 3/50
2024-11-28 17:41:22.677525: train_loss -0.6788
2024-11-28 17:41:22.678701: val_loss -0.6713
2024-11-28 17:41:22.679636: Pseudo dice [0.7426]
2024-11-28 17:41:22.680517: Epoch time: 46.72 s
2024-11-28 17:41:23.199219: Yayy! New best EMA pseudo Dice: 0.6085
2024-11-28 17:41:24.959279: 
2024-11-28 17:41:24.960672: Epoch 10
2024-11-28 17:41:24.961612: Current learning rate: 0.00991
2024-11-28 17:42:11.682869: Validation loss did not improve from -0.67127. Patience: 1/50
2024-11-28 17:42:11.684602: train_loss -0.6818
2024-11-28 17:42:11.685493: val_loss -0.6564
2024-11-28 17:42:11.686248: Pseudo dice [0.7309]
2024-11-28 17:42:11.686971: Epoch time: 46.73 s
2024-11-28 17:42:11.687595: Yayy! New best EMA pseudo Dice: 0.6207
2024-11-28 17:42:13.415055: 
2024-11-28 17:42:13.416090: Epoch 11
2024-11-28 17:42:13.416897: Current learning rate: 0.0099
2024-11-28 17:43:00.126637: Validation loss improved from -0.67127 to -0.70803! Patience: 1/50
2024-11-28 17:43:00.128351: train_loss -0.6902
2024-11-28 17:43:00.129533: val_loss -0.708
2024-11-28 17:43:00.130389: Pseudo dice [0.7626]
2024-11-28 17:43:00.131308: Epoch time: 46.71 s
2024-11-28 17:43:00.132297: Yayy! New best EMA pseudo Dice: 0.6349
2024-11-28 17:43:01.928707: 
2024-11-28 17:43:01.930688: Epoch 12
2024-11-28 17:43:01.931631: Current learning rate: 0.00989
2024-11-28 17:43:48.644466: Validation loss did not improve from -0.70803. Patience: 1/50
2024-11-28 17:43:48.645528: train_loss -0.6973
2024-11-28 17:43:48.646217: val_loss -0.6752
2024-11-28 17:43:48.646999: Pseudo dice [0.7384]
2024-11-28 17:43:48.647867: Epoch time: 46.72 s
2024-11-28 17:43:48.648666: Yayy! New best EMA pseudo Dice: 0.6453
2024-11-28 17:43:50.516872: 
2024-11-28 17:43:50.518190: Epoch 13
2024-11-28 17:43:50.518879: Current learning rate: 0.00988
2024-11-28 17:44:37.201099: Validation loss did not improve from -0.70803. Patience: 2/50
2024-11-28 17:44:37.202185: train_loss -0.7098
2024-11-28 17:44:37.202918: val_loss -0.634
2024-11-28 17:44:37.203592: Pseudo dice [0.7012]
2024-11-28 17:44:37.204308: Epoch time: 46.69 s
2024-11-28 17:44:37.204905: Yayy! New best EMA pseudo Dice: 0.6509
2024-11-28 17:44:39.007036: 
2024-11-28 17:44:39.008610: Epoch 14
2024-11-28 17:44:39.009405: Current learning rate: 0.00987
2024-11-28 17:45:25.681629: Validation loss did not improve from -0.70803. Patience: 3/50
2024-11-28 17:45:25.683146: train_loss -0.7058
2024-11-28 17:45:25.683843: val_loss -0.6873
2024-11-28 17:45:25.684563: Pseudo dice [0.7477]
2024-11-28 17:45:25.685219: Epoch time: 46.68 s
2024-11-28 17:45:26.212668: Yayy! New best EMA pseudo Dice: 0.6606
2024-11-28 17:45:28.020087: 
2024-11-28 17:45:28.021038: Epoch 15
2024-11-28 17:45:28.021975: Current learning rate: 0.00986
2024-11-28 17:46:14.692147: Validation loss did not improve from -0.70803. Patience: 4/50
2024-11-28 17:46:14.693857: train_loss -0.7164
2024-11-28 17:46:14.694683: val_loss -0.6573
2024-11-28 17:46:14.695252: Pseudo dice [0.7232]
2024-11-28 17:46:14.695881: Epoch time: 46.68 s
2024-11-28 17:46:14.696497: Yayy! New best EMA pseudo Dice: 0.6668
2024-11-28 17:46:16.527169: 
2024-11-28 17:46:16.528843: Epoch 16
2024-11-28 17:46:16.529974: Current learning rate: 0.00986
2024-11-28 17:47:03.238982: Validation loss improved from -0.70803 to -0.70943! Patience: 4/50
2024-11-28 17:47:03.240635: train_loss -0.7153
2024-11-28 17:47:03.241506: val_loss -0.7094
2024-11-28 17:47:03.242178: Pseudo dice [0.7648]
2024-11-28 17:47:03.242927: Epoch time: 46.71 s
2024-11-28 17:47:03.243846: Yayy! New best EMA pseudo Dice: 0.6766
2024-11-28 17:47:05.106372: 
2024-11-28 17:47:05.108230: Epoch 17
2024-11-28 17:47:05.109024: Current learning rate: 0.00985
2024-11-28 17:47:51.841633: Validation loss did not improve from -0.70943. Patience: 1/50
2024-11-28 17:47:51.843106: train_loss -0.7197
2024-11-28 17:47:51.843970: val_loss -0.698
2024-11-28 17:47:51.844814: Pseudo dice [0.7559]
2024-11-28 17:47:51.845701: Epoch time: 46.74 s
2024-11-28 17:47:51.846715: Yayy! New best EMA pseudo Dice: 0.6845
2024-11-28 17:47:53.722492: 
2024-11-28 17:47:53.724424: Epoch 18
2024-11-28 17:47:53.725785: Current learning rate: 0.00984
2024-11-28 17:48:40.464077: Validation loss did not improve from -0.70943. Patience: 2/50
2024-11-28 17:48:40.465712: train_loss -0.7265
2024-11-28 17:48:40.466468: val_loss -0.6872
2024-11-28 17:48:40.467261: Pseudo dice [0.7472]
2024-11-28 17:48:40.468006: Epoch time: 46.74 s
2024-11-28 17:48:40.468735: Yayy! New best EMA pseudo Dice: 0.6908
2024-11-28 17:48:42.843332: 
2024-11-28 17:48:42.845072: Epoch 19
2024-11-28 17:48:42.846234: Current learning rate: 0.00983
2024-11-28 17:49:29.612416: Validation loss did not improve from -0.70943. Patience: 3/50
2024-11-28 17:49:29.613961: train_loss -0.7292
2024-11-28 17:49:29.614819: val_loss -0.7047
2024-11-28 17:49:29.615652: Pseudo dice [0.7653]
2024-11-28 17:49:29.616427: Epoch time: 46.77 s
2024-11-28 17:49:30.148440: Yayy! New best EMA pseudo Dice: 0.6983
2024-11-28 17:49:32.049593: 
2024-11-28 17:49:32.051288: Epoch 20
2024-11-28 17:49:32.052529: Current learning rate: 0.00982
2024-11-28 17:50:18.777493: Validation loss did not improve from -0.70943. Patience: 4/50
2024-11-28 17:50:18.779085: train_loss -0.73
2024-11-28 17:50:18.779839: val_loss -0.6449
2024-11-28 17:50:18.780500: Pseudo dice [0.72]
2024-11-28 17:50:18.781198: Epoch time: 46.73 s
2024-11-28 17:50:18.781988: Yayy! New best EMA pseudo Dice: 0.7004
2024-11-28 17:50:20.619948: 
2024-11-28 17:50:20.621284: Epoch 21
2024-11-28 17:50:20.622369: Current learning rate: 0.00981
2024-11-28 17:51:07.355628: Validation loss did not improve from -0.70943. Patience: 5/50
2024-11-28 17:51:07.357246: train_loss -0.7335
2024-11-28 17:51:07.358175: val_loss -0.651
2024-11-28 17:51:07.359025: Pseudo dice [0.7171]
2024-11-28 17:51:07.360291: Epoch time: 46.74 s
2024-11-28 17:51:07.361109: Yayy! New best EMA pseudo Dice: 0.7021
2024-11-28 17:51:09.178489: 
2024-11-28 17:51:09.180159: Epoch 22
2024-11-28 17:51:09.180903: Current learning rate: 0.0098
2024-11-28 17:51:55.937915: Validation loss did not improve from -0.70943. Patience: 6/50
2024-11-28 17:51:55.939506: train_loss -0.7327
2024-11-28 17:51:55.940564: val_loss -0.6636
2024-11-28 17:51:55.941667: Pseudo dice [0.7242]
2024-11-28 17:51:55.943028: Epoch time: 46.76 s
2024-11-28 17:51:55.943925: Yayy! New best EMA pseudo Dice: 0.7043
2024-11-28 17:51:57.717049: 
2024-11-28 17:51:57.718631: Epoch 23
2024-11-28 17:51:57.719557: Current learning rate: 0.00979
2024-11-28 17:52:44.444569: Validation loss did not improve from -0.70943. Patience: 7/50
2024-11-28 17:52:44.446245: train_loss -0.7369
2024-11-28 17:52:44.447121: val_loss -0.6769
2024-11-28 17:52:44.447943: Pseudo dice [0.7394]
2024-11-28 17:52:44.448669: Epoch time: 46.73 s
2024-11-28 17:52:44.449459: Yayy! New best EMA pseudo Dice: 0.7078
2024-11-28 17:52:46.195718: 
2024-11-28 17:52:46.197511: Epoch 24
2024-11-28 17:52:46.198393: Current learning rate: 0.00978
2024-11-28 17:53:32.983053: Validation loss did not improve from -0.70943. Patience: 8/50
2024-11-28 17:53:32.984543: train_loss -0.7437
2024-11-28 17:53:32.985412: val_loss -0.6047
2024-11-28 17:53:32.986267: Pseudo dice [0.6839]
2024-11-28 17:53:32.987202: Epoch time: 46.79 s
2024-11-28 17:53:34.772061: 
2024-11-28 17:53:34.773015: Epoch 25
2024-11-28 17:53:34.773796: Current learning rate: 0.00977
2024-11-28 17:54:21.551719: Validation loss did not improve from -0.70943. Patience: 9/50
2024-11-28 17:54:21.553115: train_loss -0.74
2024-11-28 17:54:21.553924: val_loss -0.6709
2024-11-28 17:54:21.554620: Pseudo dice [0.738]
2024-11-28 17:54:21.555362: Epoch time: 46.78 s
2024-11-28 17:54:21.555997: Yayy! New best EMA pseudo Dice: 0.7087
2024-11-28 17:54:23.376293: 
2024-11-28 17:54:23.377914: Epoch 26
2024-11-28 17:54:23.378808: Current learning rate: 0.00977
2024-11-28 17:55:10.170847: Validation loss did not improve from -0.70943. Patience: 10/50
2024-11-28 17:55:10.172441: train_loss -0.7533
2024-11-28 17:55:10.173456: val_loss -0.653
2024-11-28 17:55:10.174400: Pseudo dice [0.7159]
2024-11-28 17:55:10.175164: Epoch time: 46.8 s
2024-11-28 17:55:10.175936: Yayy! New best EMA pseudo Dice: 0.7094
2024-11-28 17:55:11.948409: 
2024-11-28 17:55:11.949975: Epoch 27
2024-11-28 17:55:11.950788: Current learning rate: 0.00976
2024-11-28 17:55:58.727551: Validation loss did not improve from -0.70943. Patience: 11/50
2024-11-28 17:55:58.729238: train_loss -0.7541
2024-11-28 17:55:58.729941: val_loss -0.6503
2024-11-28 17:55:58.730672: Pseudo dice [0.7156]
2024-11-28 17:55:58.731278: Epoch time: 46.78 s
2024-11-28 17:55:58.731893: Yayy! New best EMA pseudo Dice: 0.71
2024-11-28 17:56:00.509620: 
2024-11-28 17:56:00.511199: Epoch 28
2024-11-28 17:56:00.511948: Current learning rate: 0.00975
2024-11-28 17:56:47.281146: Validation loss did not improve from -0.70943. Patience: 12/50
2024-11-28 17:56:47.282335: train_loss -0.7474
2024-11-28 17:56:47.283018: val_loss -0.6962
2024-11-28 17:56:47.283742: Pseudo dice [0.7511]
2024-11-28 17:56:47.284589: Epoch time: 46.77 s
2024-11-28 17:56:47.285324: Yayy! New best EMA pseudo Dice: 0.7141
2024-11-28 17:56:49.090504: 
2024-11-28 17:56:49.091906: Epoch 29
2024-11-28 17:56:49.092699: Current learning rate: 0.00974
2024-11-28 17:57:35.874777: Validation loss did not improve from -0.70943. Patience: 13/50
2024-11-28 17:57:35.876193: train_loss -0.7511
2024-11-28 17:57:35.876934: val_loss -0.698
2024-11-28 17:57:35.877545: Pseudo dice [0.7613]
2024-11-28 17:57:35.878266: Epoch time: 46.79 s
2024-11-28 17:57:36.403989: Yayy! New best EMA pseudo Dice: 0.7188
2024-11-28 17:57:38.236761: 
2024-11-28 17:57:38.238335: Epoch 30
2024-11-28 17:57:38.239096: Current learning rate: 0.00973
2024-11-28 17:58:25.034304: Validation loss did not improve from -0.70943. Patience: 14/50
2024-11-28 17:58:25.036183: train_loss -0.7536
2024-11-28 17:58:25.037211: val_loss -0.6971
2024-11-28 17:58:25.038091: Pseudo dice [0.7566]
2024-11-28 17:58:25.038890: Epoch time: 46.8 s
2024-11-28 17:58:25.039554: Yayy! New best EMA pseudo Dice: 0.7226
2024-11-28 17:58:27.382087: 
2024-11-28 17:58:27.383085: Epoch 31
2024-11-28 17:58:27.383969: Current learning rate: 0.00972
2024-11-28 17:59:14.173581: Validation loss did not improve from -0.70943. Patience: 15/50
2024-11-28 17:59:14.175437: train_loss -0.7519
2024-11-28 17:59:14.176269: val_loss -0.6539
2024-11-28 17:59:14.177204: Pseudo dice [0.7253]
2024-11-28 17:59:14.178184: Epoch time: 46.79 s
2024-11-28 17:59:14.178912: Yayy! New best EMA pseudo Dice: 0.7229
2024-11-28 17:59:16.129708: 
2024-11-28 17:59:16.131215: Epoch 32
2024-11-28 17:59:16.131927: Current learning rate: 0.00971
2024-11-28 18:00:02.964792: Validation loss did not improve from -0.70943. Patience: 16/50
2024-11-28 18:00:02.966478: train_loss -0.7651
2024-11-28 18:00:02.967358: val_loss -0.6366
2024-11-28 18:00:02.968228: Pseudo dice [0.7091]
2024-11-28 18:00:02.969147: Epoch time: 46.84 s
2024-11-28 18:00:04.243022: 
2024-11-28 18:00:04.244580: Epoch 33
2024-11-28 18:00:04.245256: Current learning rate: 0.0097
2024-11-28 18:00:51.102324: Validation loss did not improve from -0.70943. Patience: 17/50
2024-11-28 18:00:51.103776: train_loss -0.759
2024-11-28 18:00:51.104595: val_loss -0.7009
2024-11-28 18:00:51.105304: Pseudo dice [0.7558]
2024-11-28 18:00:51.105937: Epoch time: 46.86 s
2024-11-28 18:00:51.106534: Yayy! New best EMA pseudo Dice: 0.7249
2024-11-28 18:00:52.969260: 
2024-11-28 18:00:52.971255: Epoch 34
2024-11-28 18:00:52.972120: Current learning rate: 0.00969
2024-11-28 18:01:39.796714: Validation loss did not improve from -0.70943. Patience: 18/50
2024-11-28 18:01:39.797910: train_loss -0.7627
2024-11-28 18:01:39.798806: val_loss -0.702
2024-11-28 18:01:39.799504: Pseudo dice [0.7591]
2024-11-28 18:01:39.800287: Epoch time: 46.83 s
2024-11-28 18:01:40.345932: Yayy! New best EMA pseudo Dice: 0.7284
2024-11-28 18:01:42.241482: 
2024-11-28 18:01:42.243136: Epoch 35
2024-11-28 18:01:42.244037: Current learning rate: 0.00968
2024-11-28 18:02:29.054648: Validation loss did not improve from -0.70943. Patience: 19/50
2024-11-28 18:02:29.055996: train_loss -0.7637
2024-11-28 18:02:29.056763: val_loss -0.6893
2024-11-28 18:02:29.057479: Pseudo dice [0.7497]
2024-11-28 18:02:29.058794: Epoch time: 46.82 s
2024-11-28 18:02:29.060000: Yayy! New best EMA pseudo Dice: 0.7305
2024-11-28 18:02:31.009218: 
2024-11-28 18:02:31.010665: Epoch 36
2024-11-28 18:02:31.011472: Current learning rate: 0.00968
2024-11-28 18:03:17.807886: Validation loss improved from -0.70943 to -0.73861! Patience: 19/50
2024-11-28 18:03:17.809467: train_loss -0.7605
2024-11-28 18:03:17.810273: val_loss -0.7386
2024-11-28 18:03:17.810915: Pseudo dice [0.7859]
2024-11-28 18:03:17.811753: Epoch time: 46.8 s
2024-11-28 18:03:17.812372: Yayy! New best EMA pseudo Dice: 0.736
2024-11-28 18:03:19.687824: 
2024-11-28 18:03:19.689479: Epoch 37
2024-11-28 18:03:19.690763: Current learning rate: 0.00967
2024-11-28 18:04:06.497229: Validation loss did not improve from -0.73861. Patience: 1/50
2024-11-28 18:04:06.498929: train_loss -0.7619
2024-11-28 18:04:06.499610: val_loss -0.6528
2024-11-28 18:04:06.500366: Pseudo dice [0.7211]
2024-11-28 18:04:06.501081: Epoch time: 46.81 s
2024-11-28 18:04:07.806441: 
2024-11-28 18:04:07.807641: Epoch 38
2024-11-28 18:04:07.808355: Current learning rate: 0.00966
2024-11-28 18:04:54.589786: Validation loss did not improve from -0.73861. Patience: 2/50
2024-11-28 18:04:54.591452: train_loss -0.7703
2024-11-28 18:04:54.592265: val_loss -0.6866
2024-11-28 18:04:54.592927: Pseudo dice [0.7504]
2024-11-28 18:04:54.593613: Epoch time: 46.79 s
2024-11-28 18:04:54.594207: Yayy! New best EMA pseudo Dice: 0.7361
2024-11-28 18:04:56.513331: 
2024-11-28 18:04:56.514705: Epoch 39
2024-11-28 18:04:56.515642: Current learning rate: 0.00965
2024-11-28 18:05:43.303978: Validation loss did not improve from -0.73861. Patience: 3/50
2024-11-28 18:05:43.305551: train_loss -0.7681
2024-11-28 18:05:43.306304: val_loss -0.6718
2024-11-28 18:05:43.307062: Pseudo dice [0.737]
2024-11-28 18:05:43.307647: Epoch time: 46.79 s
2024-11-28 18:05:43.872378: Yayy! New best EMA pseudo Dice: 0.7362
2024-11-28 18:05:45.836933: 
2024-11-28 18:05:45.838182: Epoch 40
2024-11-28 18:05:45.838933: Current learning rate: 0.00964
2024-11-28 18:06:32.639043: Validation loss did not improve from -0.73861. Patience: 4/50
2024-11-28 18:06:32.640827: train_loss -0.7783
2024-11-28 18:06:32.641534: val_loss -0.6813
2024-11-28 18:06:32.642191: Pseudo dice [0.7429]
2024-11-28 18:06:32.642834: Epoch time: 46.81 s
2024-11-28 18:06:32.643507: Yayy! New best EMA pseudo Dice: 0.7369
2024-11-28 18:06:34.555835: 
2024-11-28 18:06:34.557478: Epoch 41
2024-11-28 18:06:34.558187: Current learning rate: 0.00963
2024-11-28 18:07:21.320733: Validation loss did not improve from -0.73861. Patience: 5/50
2024-11-28 18:07:21.322634: train_loss -0.7673
2024-11-28 18:07:21.323472: val_loss -0.6675
2024-11-28 18:07:21.324252: Pseudo dice [0.7251]
2024-11-28 18:07:21.325057: Epoch time: 46.77 s
2024-11-28 18:07:23.019622: 
2024-11-28 18:07:23.021490: Epoch 42
2024-11-28 18:07:23.022617: Current learning rate: 0.00962
2024-11-28 18:08:09.830473: Validation loss did not improve from -0.73861. Patience: 6/50
2024-11-28 18:08:09.832340: train_loss -0.7759
2024-11-28 18:08:09.833304: val_loss -0.659
2024-11-28 18:08:09.834118: Pseudo dice [0.721]
2024-11-28 18:08:09.835019: Epoch time: 46.81 s
2024-11-28 18:08:11.105905: 
2024-11-28 18:08:11.108212: Epoch 43
2024-11-28 18:08:11.109109: Current learning rate: 0.00961
2024-11-28 18:08:57.944355: Validation loss did not improve from -0.73861. Patience: 7/50
2024-11-28 18:08:57.945723: train_loss -0.7702
2024-11-28 18:08:57.946508: val_loss -0.6862
2024-11-28 18:08:57.947347: Pseudo dice [0.745]
2024-11-28 18:08:57.948074: Epoch time: 46.84 s
2024-11-28 18:08:59.214422: 
2024-11-28 18:08:59.215842: Epoch 44
2024-11-28 18:08:59.216869: Current learning rate: 0.0096
2024-11-28 18:09:46.054159: Validation loss did not improve from -0.73861. Patience: 8/50
2024-11-28 18:09:46.055242: train_loss -0.7752
2024-11-28 18:09:46.055903: val_loss -0.7095
2024-11-28 18:09:46.056613: Pseudo dice [0.7678]
2024-11-28 18:09:46.057425: Epoch time: 46.84 s
2024-11-28 18:09:46.617574: Yayy! New best EMA pseudo Dice: 0.7386
2024-11-28 18:09:48.423011: 
2024-11-28 18:09:48.424697: Epoch 45
2024-11-28 18:09:48.425462: Current learning rate: 0.00959
2024-11-28 18:10:35.235518: Validation loss did not improve from -0.73861. Patience: 9/50
2024-11-28 18:10:35.236834: train_loss -0.7767
2024-11-28 18:10:35.237756: val_loss -0.6898
2024-11-28 18:10:35.238497: Pseudo dice [0.7414]
2024-11-28 18:10:35.239221: Epoch time: 46.82 s
2024-11-28 18:10:35.240028: Yayy! New best EMA pseudo Dice: 0.7388
2024-11-28 18:10:37.087528: 
2024-11-28 18:10:37.089284: Epoch 46
2024-11-28 18:10:37.090470: Current learning rate: 0.00959
2024-11-28 18:11:23.885395: Validation loss did not improve from -0.73861. Patience: 10/50
2024-11-28 18:11:23.886989: train_loss -0.7825
2024-11-28 18:11:23.887666: val_loss -0.6587
2024-11-28 18:11:23.888479: Pseudo dice [0.7295]
2024-11-28 18:11:23.889096: Epoch time: 46.8 s
2024-11-28 18:11:25.171325: 
2024-11-28 18:11:25.172885: Epoch 47
2024-11-28 18:11:25.173830: Current learning rate: 0.00958
2024-11-28 18:12:11.980849: Validation loss did not improve from -0.73861. Patience: 11/50
2024-11-28 18:12:11.982432: train_loss -0.7736
2024-11-28 18:12:11.983327: val_loss -0.6633
2024-11-28 18:12:11.984136: Pseudo dice [0.724]
2024-11-28 18:12:11.984957: Epoch time: 46.81 s
2024-11-28 18:12:13.256084: 
2024-11-28 18:12:13.257402: Epoch 48
2024-11-28 18:12:13.258236: Current learning rate: 0.00957
2024-11-28 18:13:00.053410: Validation loss did not improve from -0.73861. Patience: 12/50
2024-11-28 18:13:00.055033: train_loss -0.7885
2024-11-28 18:13:00.055945: val_loss -0.6521
2024-11-28 18:13:00.056583: Pseudo dice [0.7145]
2024-11-28 18:13:00.057323: Epoch time: 46.8 s
2024-11-28 18:13:01.306933: 
2024-11-28 18:13:01.308778: Epoch 49
2024-11-28 18:13:01.309729: Current learning rate: 0.00956
2024-11-28 18:13:48.069439: Validation loss did not improve from -0.73861. Patience: 13/50
2024-11-28 18:13:48.071274: train_loss -0.7742
2024-11-28 18:13:48.072268: val_loss -0.6194
2024-11-28 18:13:48.073170: Pseudo dice [0.7033]
2024-11-28 18:13:48.074234: Epoch time: 46.77 s
2024-11-28 18:13:49.908543: 
2024-11-28 18:13:49.910559: Epoch 50
2024-11-28 18:13:49.911351: Current learning rate: 0.00955
2024-11-28 18:14:36.726135: Validation loss did not improve from -0.73861. Patience: 14/50
2024-11-28 18:14:36.727844: train_loss -0.7857
2024-11-28 18:14:36.728679: val_loss -0.6485
2024-11-28 18:14:36.729444: Pseudo dice [0.7137]
2024-11-28 18:14:36.730246: Epoch time: 46.82 s
2024-11-28 18:14:38.011591: 
2024-11-28 18:14:38.012875: Epoch 51
2024-11-28 18:14:38.013621: Current learning rate: 0.00954
2024-11-28 18:15:24.824311: Validation loss did not improve from -0.73861. Patience: 15/50
2024-11-28 18:15:24.825953: train_loss -0.788
2024-11-28 18:15:24.826844: val_loss -0.6401
2024-11-28 18:15:24.827788: Pseudo dice [0.7154]
2024-11-28 18:15:24.828815: Epoch time: 46.82 s
2024-11-28 18:15:26.109964: 
2024-11-28 18:15:26.111562: Epoch 52
2024-11-28 18:15:26.112402: Current learning rate: 0.00953
2024-11-28 18:16:12.898826: Validation loss did not improve from -0.73861. Patience: 16/50
2024-11-28 18:16:12.900495: train_loss -0.7869
2024-11-28 18:16:12.901273: val_loss -0.7204
2024-11-28 18:16:12.901892: Pseudo dice [0.7774]
2024-11-28 18:16:12.902852: Epoch time: 46.79 s
2024-11-28 18:16:14.649568: 
2024-11-28 18:16:14.651299: Epoch 53
2024-11-28 18:16:14.651934: Current learning rate: 0.00952
2024-11-28 18:17:01.460313: Validation loss did not improve from -0.73861. Patience: 17/50
2024-11-28 18:17:01.461786: train_loss -0.7851
2024-11-28 18:17:01.462676: val_loss -0.6795
2024-11-28 18:17:01.463961: Pseudo dice [0.7482]
2024-11-28 18:17:01.465217: Epoch time: 46.81 s
2024-11-28 18:17:02.776515: 
2024-11-28 18:17:02.777814: Epoch 54
2024-11-28 18:17:02.779048: Current learning rate: 0.00951
2024-11-28 18:17:49.576679: Validation loss did not improve from -0.73861. Patience: 18/50
2024-11-28 18:17:49.578368: train_loss -0.7841
2024-11-28 18:17:49.579257: val_loss -0.6907
2024-11-28 18:17:49.579945: Pseudo dice [0.7507]
2024-11-28 18:17:49.580694: Epoch time: 46.8 s
2024-11-28 18:17:51.500436: 
2024-11-28 18:17:51.502370: Epoch 55
2024-11-28 18:17:51.503167: Current learning rate: 0.0095
2024-11-28 18:18:38.313394: Validation loss did not improve from -0.73861. Patience: 19/50
2024-11-28 18:18:38.314795: train_loss -0.7852
2024-11-28 18:18:38.315531: val_loss -0.7139
2024-11-28 18:18:38.316285: Pseudo dice [0.7713]
2024-11-28 18:18:38.317232: Epoch time: 46.82 s
2024-11-28 18:18:38.318180: Yayy! New best EMA pseudo Dice: 0.7396
2024-11-28 18:18:40.211769: 
2024-11-28 18:18:40.213090: Epoch 56
2024-11-28 18:18:40.213940: Current learning rate: 0.00949
2024-11-28 18:19:27.077289: Validation loss did not improve from -0.73861. Patience: 20/50
2024-11-28 18:19:27.078796: train_loss -0.7822
2024-11-28 18:19:27.079532: val_loss -0.7224
2024-11-28 18:19:27.080321: Pseudo dice [0.7772]
2024-11-28 18:19:27.081218: Epoch time: 46.87 s
2024-11-28 18:19:27.081980: Yayy! New best EMA pseudo Dice: 0.7434
2024-11-28 18:19:28.925624: 
2024-11-28 18:19:28.926852: Epoch 57
2024-11-28 18:19:28.927668: Current learning rate: 0.00949
2024-11-28 18:20:15.729358: Validation loss did not improve from -0.73861. Patience: 21/50
2024-11-28 18:20:15.730993: train_loss -0.7914
2024-11-28 18:20:15.731783: val_loss -0.6653
2024-11-28 18:20:15.732497: Pseudo dice [0.7256]
2024-11-28 18:20:15.733263: Epoch time: 46.81 s
2024-11-28 18:20:16.998428: 
2024-11-28 18:20:16.999535: Epoch 58
2024-11-28 18:20:17.000431: Current learning rate: 0.00948
2024-11-28 18:21:03.839675: Validation loss did not improve from -0.73861. Patience: 22/50
2024-11-28 18:21:03.841787: train_loss -0.7937
2024-11-28 18:21:03.843002: val_loss -0.6689
2024-11-28 18:21:03.843923: Pseudo dice [0.732]
2024-11-28 18:21:03.844879: Epoch time: 46.84 s
2024-11-28 18:21:05.169153: 
2024-11-28 18:21:05.170836: Epoch 59
2024-11-28 18:21:05.171776: Current learning rate: 0.00947
2024-11-28 18:21:51.959399: Validation loss did not improve from -0.73861. Patience: 23/50
2024-11-28 18:21:51.960978: train_loss -0.7938
2024-11-28 18:21:51.961722: val_loss -0.7175
2024-11-28 18:21:51.962492: Pseudo dice [0.7685]
2024-11-28 18:21:51.963295: Epoch time: 46.79 s
2024-11-28 18:21:52.554196: Yayy! New best EMA pseudo Dice: 0.7434
2024-11-28 18:21:54.461723: 
2024-11-28 18:21:54.463373: Epoch 60
2024-11-28 18:21:54.464048: Current learning rate: 0.00946
2024-11-28 18:22:41.216372: Validation loss did not improve from -0.73861. Patience: 24/50
2024-11-28 18:22:41.217311: train_loss -0.7988
2024-11-28 18:22:41.218000: val_loss -0.701
2024-11-28 18:22:41.218626: Pseudo dice [0.7553]
2024-11-28 18:22:41.219262: Epoch time: 46.76 s
2024-11-28 18:22:41.220127: Yayy! New best EMA pseudo Dice: 0.7446
2024-11-28 18:22:43.115349: 
2024-11-28 18:22:43.116271: Epoch 61
2024-11-28 18:22:43.116924: Current learning rate: 0.00945
2024-11-28 18:23:29.908657: Validation loss did not improve from -0.73861. Patience: 25/50
2024-11-28 18:23:29.910438: train_loss -0.7965
2024-11-28 18:23:29.911292: val_loss -0.6628
2024-11-28 18:23:29.912012: Pseudo dice [0.7298]
2024-11-28 18:23:29.912693: Epoch time: 46.8 s
2024-11-28 18:23:31.269622: 
2024-11-28 18:23:31.271875: Epoch 62
2024-11-28 18:23:31.273001: Current learning rate: 0.00944
2024-11-28 18:24:18.099523: Validation loss did not improve from -0.73861. Patience: 26/50
2024-11-28 18:24:18.101200: train_loss -0.7933
2024-11-28 18:24:18.102013: val_loss -0.6703
2024-11-28 18:24:18.102750: Pseudo dice [0.7318]
2024-11-28 18:24:18.103392: Epoch time: 46.83 s
2024-11-28 18:24:19.440140: 
2024-11-28 18:24:19.441550: Epoch 63
2024-11-28 18:24:19.442517: Current learning rate: 0.00943
2024-11-28 18:25:06.257015: Validation loss did not improve from -0.73861. Patience: 27/50
2024-11-28 18:25:06.258743: train_loss -0.7958
2024-11-28 18:25:06.259674: val_loss -0.6661
2024-11-28 18:25:06.260469: Pseudo dice [0.7345]
2024-11-28 18:25:06.261307: Epoch time: 46.82 s
2024-11-28 18:25:07.958252: 
2024-11-28 18:25:07.959949: Epoch 64
2024-11-28 18:25:07.960997: Current learning rate: 0.00942
2024-11-28 18:25:54.775558: Validation loss did not improve from -0.73861. Patience: 28/50
2024-11-28 18:25:54.777252: train_loss -0.8017
2024-11-28 18:25:54.778175: val_loss -0.6646
2024-11-28 18:25:54.778913: Pseudo dice [0.7234]
2024-11-28 18:25:54.779710: Epoch time: 46.82 s
2024-11-28 18:25:56.617283: 
2024-11-28 18:25:56.619036: Epoch 65
2024-11-28 18:25:56.619936: Current learning rate: 0.00941
2024-11-28 18:26:43.421053: Validation loss did not improve from -0.73861. Patience: 29/50
2024-11-28 18:26:43.422582: train_loss -0.7944
2024-11-28 18:26:43.423325: val_loss -0.6809
2024-11-28 18:26:43.423949: Pseudo dice [0.7392]
2024-11-28 18:26:43.424628: Epoch time: 46.81 s
2024-11-28 18:26:44.725253: 
2024-11-28 18:26:44.726593: Epoch 66
2024-11-28 18:26:44.727367: Current learning rate: 0.0094
2024-11-28 18:27:31.528537: Validation loss did not improve from -0.73861. Patience: 30/50
2024-11-28 18:27:31.530235: train_loss -0.8055
2024-11-28 18:27:31.531268: val_loss -0.722
2024-11-28 18:27:31.532272: Pseudo dice [0.7736]
2024-11-28 18:27:31.533305: Epoch time: 46.81 s
2024-11-28 18:27:32.833176: 
2024-11-28 18:27:32.835117: Epoch 67
2024-11-28 18:27:32.836081: Current learning rate: 0.00939
2024-11-28 18:28:19.648119: Validation loss did not improve from -0.73861. Patience: 31/50
2024-11-28 18:28:19.650148: train_loss -0.8022
2024-11-28 18:28:19.651209: val_loss -0.6806
2024-11-28 18:28:19.651958: Pseudo dice [0.7433]
2024-11-28 18:28:19.652714: Epoch time: 46.82 s
2024-11-28 18:28:20.992796: 
2024-11-28 18:28:20.994408: Epoch 68
2024-11-28 18:28:20.995426: Current learning rate: 0.00939
2024-11-28 18:29:07.811077: Validation loss did not improve from -0.73861. Patience: 32/50
2024-11-28 18:29:07.812821: train_loss -0.8055
2024-11-28 18:29:07.813810: val_loss -0.7006
2024-11-28 18:29:07.814653: Pseudo dice [0.7641]
2024-11-28 18:29:07.815596: Epoch time: 46.82 s
2024-11-28 18:29:07.816400: Yayy! New best EMA pseudo Dice: 0.745
2024-11-28 18:29:09.695008: 
2024-11-28 18:29:09.697067: Epoch 69
2024-11-28 18:29:09.698196: Current learning rate: 0.00938
2024-11-28 18:29:56.522815: Validation loss did not improve from -0.73861. Patience: 33/50
2024-11-28 18:29:56.524399: train_loss -0.7959
2024-11-28 18:29:56.525501: val_loss -0.7149
2024-11-28 18:29:56.526417: Pseudo dice [0.7674]
2024-11-28 18:29:56.527343: Epoch time: 46.83 s
2024-11-28 18:29:57.077974: Yayy! New best EMA pseudo Dice: 0.7473
2024-11-28 18:29:58.891174: 
2024-11-28 18:29:58.892487: Epoch 70
2024-11-28 18:29:58.893236: Current learning rate: 0.00937
2024-11-28 18:30:45.675222: Validation loss did not improve from -0.73861. Patience: 34/50
2024-11-28 18:30:45.676612: train_loss -0.8006
2024-11-28 18:30:45.677527: val_loss -0.7084
2024-11-28 18:30:45.678411: Pseudo dice [0.7632]
2024-11-28 18:30:45.679198: Epoch time: 46.79 s
2024-11-28 18:30:45.680262: Yayy! New best EMA pseudo Dice: 0.7489
2024-11-28 18:30:47.615400: 
2024-11-28 18:30:47.616707: Epoch 71
2024-11-28 18:30:47.617350: Current learning rate: 0.00936
2024-11-28 18:31:34.405769: Validation loss did not improve from -0.73861. Patience: 35/50
2024-11-28 18:31:34.407516: train_loss -0.8027
2024-11-28 18:31:34.408185: val_loss -0.7041
2024-11-28 18:31:34.408849: Pseudo dice [0.7576]
2024-11-28 18:31:34.409608: Epoch time: 46.79 s
2024-11-28 18:31:34.410228: Yayy! New best EMA pseudo Dice: 0.7497
2024-11-28 18:31:36.325064: 
2024-11-28 18:31:36.326096: Epoch 72
2024-11-28 18:31:36.326863: Current learning rate: 0.00935
2024-11-28 18:32:23.141102: Validation loss did not improve from -0.73861. Patience: 36/50
2024-11-28 18:32:23.142717: train_loss -0.8001
2024-11-28 18:32:23.143644: val_loss -0.6301
2024-11-28 18:32:23.144440: Pseudo dice [0.703]
2024-11-28 18:32:23.145188: Epoch time: 46.82 s
2024-11-28 18:32:24.502587: 
2024-11-28 18:32:24.503798: Epoch 73
2024-11-28 18:32:24.504462: Current learning rate: 0.00934
2024-11-28 18:33:11.354607: Validation loss did not improve from -0.73861. Patience: 37/50
2024-11-28 18:33:11.356167: train_loss -0.8047
2024-11-28 18:33:11.357102: val_loss -0.6752
2024-11-28 18:33:11.357847: Pseudo dice [0.739]
2024-11-28 18:33:11.358729: Epoch time: 46.85 s
2024-11-28 18:33:12.733863: 
2024-11-28 18:33:12.735384: Epoch 74
2024-11-28 18:33:12.736380: Current learning rate: 0.00933
2024-11-28 18:33:59.540346: Validation loss did not improve from -0.73861. Patience: 38/50
2024-11-28 18:33:59.542332: train_loss -0.8013
2024-11-28 18:33:59.543005: val_loss -0.6895
2024-11-28 18:33:59.543692: Pseudo dice [0.752]
2024-11-28 18:33:59.544334: Epoch time: 46.81 s
2024-11-28 18:34:01.955306: 
2024-11-28 18:34:01.956663: Epoch 75
2024-11-28 18:34:01.957513: Current learning rate: 0.00932
2024-11-28 18:34:48.778006: Validation loss did not improve from -0.73861. Patience: 39/50
2024-11-28 18:34:48.779391: train_loss -0.8074
2024-11-28 18:34:48.781073: val_loss -0.7191
2024-11-28 18:34:48.781886: Pseudo dice [0.7757]
2024-11-28 18:34:48.782891: Epoch time: 46.83 s
2024-11-28 18:34:50.289894: 
2024-11-28 18:34:50.291935: Epoch 76
2024-11-28 18:34:50.292679: Current learning rate: 0.00931
2024-11-28 18:35:37.162513: Validation loss did not improve from -0.73861. Patience: 40/50
2024-11-28 18:35:37.165030: train_loss -0.8063
2024-11-28 18:35:37.166483: val_loss -0.7171
2024-11-28 18:35:37.167556: Pseudo dice [0.7708]
2024-11-28 18:35:37.168447: Epoch time: 46.88 s
2024-11-28 18:35:37.169526: Yayy! New best EMA pseudo Dice: 0.7505
2024-11-28 18:35:39.059453: 
2024-11-28 18:35:39.061170: Epoch 77
2024-11-28 18:35:39.062061: Current learning rate: 0.0093
2024-11-28 18:36:25.850419: Validation loss did not improve from -0.73861. Patience: 41/50
2024-11-28 18:36:25.851862: train_loss -0.8118
2024-11-28 18:36:25.852731: val_loss -0.7008
2024-11-28 18:36:25.853578: Pseudo dice [0.7608]
2024-11-28 18:36:25.854549: Epoch time: 46.79 s
2024-11-28 18:36:25.855372: Yayy! New best EMA pseudo Dice: 0.7515
2024-11-28 18:36:27.802946: 
2024-11-28 18:36:27.804705: Epoch 78
2024-11-28 18:36:27.805488: Current learning rate: 0.0093
2024-11-28 18:37:14.652613: Validation loss did not improve from -0.73861. Patience: 42/50
2024-11-28 18:37:14.654590: train_loss -0.8089
2024-11-28 18:37:14.655373: val_loss -0.7054
2024-11-28 18:37:14.656397: Pseudo dice [0.7634]
2024-11-28 18:37:14.657179: Epoch time: 46.85 s
2024-11-28 18:37:14.657867: Yayy! New best EMA pseudo Dice: 0.7527
2024-11-28 18:37:16.532314: 
2024-11-28 18:37:16.533706: Epoch 79
2024-11-28 18:37:16.534452: Current learning rate: 0.00929
2024-11-28 18:38:03.766163: Validation loss did not improve from -0.73861. Patience: 43/50
2024-11-28 18:38:03.768410: train_loss -0.8074
2024-11-28 18:38:03.769630: val_loss -0.6861
2024-11-28 18:38:03.770717: Pseudo dice [0.7437]
2024-11-28 18:38:03.771717: Epoch time: 47.24 s
2024-11-28 18:38:05.655750: 
2024-11-28 18:38:05.656869: Epoch 80
2024-11-28 18:38:05.657815: Current learning rate: 0.00928
2024-11-28 18:38:52.435580: Validation loss did not improve from -0.73861. Patience: 44/50
2024-11-28 18:38:52.437428: train_loss -0.8108
2024-11-28 18:38:52.438210: val_loss -0.7313
2024-11-28 18:38:52.439031: Pseudo dice [0.7853]
2024-11-28 18:38:52.439746: Epoch time: 46.78 s
2024-11-28 18:38:52.440387: Yayy! New best EMA pseudo Dice: 0.7552
2024-11-28 18:38:54.315263: 
2024-11-28 18:38:54.316747: Epoch 81
2024-11-28 18:38:54.318212: Current learning rate: 0.00927
2024-11-28 18:39:41.076917: Validation loss did not improve from -0.73861. Patience: 45/50
2024-11-28 18:39:41.078733: train_loss -0.8056
2024-11-28 18:39:41.079464: val_loss -0.6731
2024-11-28 18:39:41.080183: Pseudo dice [0.7388]
2024-11-28 18:39:41.081178: Epoch time: 46.76 s
2024-11-28 18:39:42.427688: 
2024-11-28 18:39:42.429354: Epoch 82
2024-11-28 18:39:42.430311: Current learning rate: 0.00926
2024-11-28 18:40:29.312546: Validation loss did not improve from -0.73861. Patience: 46/50
2024-11-28 18:40:29.313777: train_loss -0.8149
2024-11-28 18:40:29.314518: val_loss -0.7062
2024-11-28 18:40:29.315337: Pseudo dice [0.7588]
2024-11-28 18:40:29.315956: Epoch time: 46.89 s
2024-11-28 18:40:30.564074: 
2024-11-28 18:40:30.565857: Epoch 83
2024-11-28 18:40:30.567136: Current learning rate: 0.00925
2024-11-28 18:41:17.385496: Validation loss did not improve from -0.73861. Patience: 47/50
2024-11-28 18:41:17.386861: train_loss -0.8111
2024-11-28 18:41:17.387668: val_loss -0.681
2024-11-28 18:41:17.388512: Pseudo dice [0.7457]
2024-11-28 18:41:17.389622: Epoch time: 46.82 s
2024-11-28 18:41:18.628417: 
2024-11-28 18:41:18.629905: Epoch 84
2024-11-28 18:41:18.630689: Current learning rate: 0.00924
2024-11-28 18:42:05.417985: Validation loss did not improve from -0.73861. Patience: 48/50
2024-11-28 18:42:05.419048: train_loss -0.808
2024-11-28 18:42:05.419976: val_loss -0.7344
2024-11-28 18:42:05.420595: Pseudo dice [0.7866]
2024-11-28 18:42:05.421389: Epoch time: 46.79 s
2024-11-28 18:42:05.955741: Yayy! New best EMA pseudo Dice: 0.7566
2024-11-28 18:42:07.703546: 
2024-11-28 18:42:07.705737: Epoch 85
2024-11-28 18:42:07.706804: Current learning rate: 0.00923
2024-11-28 18:42:54.472779: Validation loss did not improve from -0.73861. Patience: 49/50
2024-11-28 18:42:54.474570: train_loss -0.8099
2024-11-28 18:42:54.475449: val_loss -0.6288
2024-11-28 18:42:54.476108: Pseudo dice [0.7065]
2024-11-28 18:42:54.477151: Epoch time: 46.77 s
2024-11-28 18:42:56.203280: 
2024-11-28 18:42:56.205237: Epoch 86
2024-11-28 18:42:56.205912: Current learning rate: 0.00922
2024-11-28 18:43:42.980559: Validation loss did not improve from -0.73861. Patience: 50/50
2024-11-28 18:43:42.981729: train_loss -0.8131
2024-11-28 18:43:42.982613: val_loss -0.7146
2024-11-28 18:43:42.983420: Pseudo dice [0.7647]
2024-11-28 18:43:42.984186: Epoch time: 46.78 s
2024-11-28 18:43:44.229935: Patience reached. Stopping training.
2024-11-28 18:43:44.792317: Training done.
2024-11-28 18:43:44.961524: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset306_Sohee_Ajay_Calcium_OCT/splits_final.json
2024-11-28 18:43:44.963649: The split file contains 5 splits.
2024-11-28 18:43:44.964434: Desired fold for training: 3
2024-11-28 18:43:44.965242: This split has 11 training and 2 validation cases.
2024-11-28 18:43:44.966124: predicting 03009Pre
2024-11-28 18:43:44.972775: 03009Pre, shape torch.Size([1, 400, 498, 498]), rank 0
2024-11-28 18:44:15.113360: predicting 101-044
2024-11-28 18:44:15.138676: 101-044, shape torch.Size([1, 404, 498, 498]), rank 0
2024-11-28 18:44:49.802988: Validation complete
2024-11-28 18:44:49.805295: Mean Validation Dice:  0.7545031935075228

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2024-11-28 18:44:56.395911: do_dummy_2d_data_aug: False
2024-11-28 18:44:56.397294: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset306_Sohee_Ajay_Calcium_OCT/splits_final.json
2024-11-28 18:44:56.398511: The split file contains 5 splits.
2024-11-28 18:44:56.399212: Desired fold for training: 4
2024-11-28 18:44:56.399890: This split has 11 training and 2 validation cases.
using pin_memory on device 0
using pin_memory on device 0
2024-11-28 18:44:58.954729: Using torch.compile...
/home/gridsan/nchutisilp/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': [512, 512], 'median_image_size_in_voxels': [498.0, 498.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset306_Sohee_Ajay_Calcium_OCT', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [375, 498, 498], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 0.49803921580314636, 'mean': 0.14296366274356842, 'median': 0.10980392247438431, 'min': 0.0, 'percentile_00_5': 0.01558823511004448, 'percentile_99_5': 0.49803921580314636, 'std': 0.11562220752239227}}} 

2024-11-28 18:45:04.497593: unpacking dataset...
2024-11-28 17:32:08.073232: unpacking done...
2024-11-28 17:32:08.159869: Unable to plot network architecture: nnUNet_compile is enabled!
2024-11-28 17:32:08.287139: 
2024-11-28 17:32:08.288403: Epoch 0
2024-11-28 17:32:08.289479: Current learning rate: 0.01
2024-11-28 17:35:02.837375: Validation loss improved from 1000.00000 to -0.35680! Patience: 0/50
2024-11-28 17:35:02.838706: train_loss -0.2348
2024-11-28 17:35:02.840120: val_loss -0.3568
2024-11-28 17:35:02.841137: Pseudo dice [0.5067]
2024-11-28 17:35:02.842334: Epoch time: 174.55 s
2024-11-28 17:35:02.843246: Yayy! New best EMA pseudo Dice: 0.5067
2024-11-28 17:35:04.437671: 
2024-11-28 17:35:04.439173: Epoch 1
2024-11-28 17:35:04.440192: Current learning rate: 0.00999
2024-11-28 17:36:45.593010: Validation loss improved from -0.35680 to -0.46178! Patience: 0/50
2024-11-28 17:36:45.594569: train_loss -0.4888
2024-11-28 17:36:45.595618: val_loss -0.4618
2024-11-28 17:36:45.596324: Pseudo dice [0.5969]
2024-11-28 17:36:45.597035: Epoch time: 101.16 s
2024-11-28 17:36:45.597796: Yayy! New best EMA pseudo Dice: 0.5157
2024-11-28 17:36:47.486853: 
2024-11-28 17:36:47.488564: Epoch 2
2024-11-28 17:36:47.489258: Current learning rate: 0.00998
2024-11-28 17:38:28.888006: Validation loss improved from -0.46178 to -0.48510! Patience: 0/50
2024-11-28 17:38:28.889073: train_loss -0.5659
2024-11-28 17:38:28.889969: val_loss -0.4851
2024-11-28 17:38:28.890687: Pseudo dice [0.619]
2024-11-28 17:38:28.891453: Epoch time: 101.4 s
2024-11-28 17:38:28.892065: Yayy! New best EMA pseudo Dice: 0.526
2024-11-28 17:38:30.904855: 
2024-11-28 17:38:30.906248: Epoch 3
2024-11-28 17:38:30.907189: Current learning rate: 0.00997
2024-11-28 17:40:12.043903: Validation loss improved from -0.48510 to -0.50864! Patience: 0/50
2024-11-28 17:40:12.045654: train_loss -0.6095
2024-11-28 17:40:12.046919: val_loss -0.5086
2024-11-28 17:40:12.047795: Pseudo dice [0.6264]
2024-11-28 17:40:12.048838: Epoch time: 101.14 s
2024-11-28 17:40:12.049821: Yayy! New best EMA pseudo Dice: 0.5361
2024-11-28 17:40:14.010799: 
2024-11-28 17:40:14.012606: Epoch 4
2024-11-28 17:40:14.013330: Current learning rate: 0.00996
2024-11-28 17:41:54.580989: Validation loss improved from -0.50864 to -0.51204! Patience: 0/50
2024-11-28 17:41:54.582270: train_loss -0.6382
2024-11-28 17:41:54.583022: val_loss -0.512
2024-11-28 17:41:54.583719: Pseudo dice [0.6309]
2024-11-28 17:41:54.584415: Epoch time: 100.57 s
2024-11-28 17:41:55.084743: Yayy! New best EMA pseudo Dice: 0.5456
2024-11-28 17:41:57.032080: 
2024-11-28 17:41:57.033648: Epoch 5
2024-11-28 17:41:57.034526: Current learning rate: 0.00995
2024-11-28 17:43:38.062032: Validation loss improved from -0.51204 to -0.51736! Patience: 0/50
2024-11-28 17:43:38.063409: train_loss -0.6472
2024-11-28 17:43:38.064203: val_loss -0.5174
2024-11-28 17:43:38.064999: Pseudo dice [0.6335]
2024-11-28 17:43:38.065688: Epoch time: 101.03 s
2024-11-28 17:43:38.066508: Yayy! New best EMA pseudo Dice: 0.5543
2024-11-28 17:43:39.927036: 
2024-11-28 17:43:39.928236: Epoch 6
2024-11-28 17:43:39.928982: Current learning rate: 0.00995
2024-11-28 17:45:21.069929: Validation loss improved from -0.51736 to -0.53460! Patience: 0/50
2024-11-28 17:45:21.070881: train_loss -0.6655
2024-11-28 17:45:21.071770: val_loss -0.5346
2024-11-28 17:45:21.072515: Pseudo dice [0.6461]
2024-11-28 17:45:21.073229: Epoch time: 101.15 s
2024-11-28 17:45:21.073977: Yayy! New best EMA pseudo Dice: 0.5635
2024-11-28 17:45:23.013094: 
2024-11-28 17:45:23.014432: Epoch 7
2024-11-28 17:45:23.015384: Current learning rate: 0.00994
2024-11-28 17:47:04.157257: Validation loss improved from -0.53460 to -0.54660! Patience: 0/50
2024-11-28 17:47:04.158508: train_loss -0.6711
2024-11-28 17:47:04.159498: val_loss -0.5466
2024-11-28 17:47:04.160344: Pseudo dice [0.6579]
2024-11-28 17:47:04.161247: Epoch time: 101.15 s
2024-11-28 17:47:04.162035: Yayy! New best EMA pseudo Dice: 0.573
2024-11-28 17:47:06.810402: 
2024-11-28 17:47:06.811639: Epoch 8
2024-11-28 17:47:06.812392: Current learning rate: 0.00993
2024-11-28 17:48:48.055869: Validation loss improved from -0.54660 to -0.59089! Patience: 0/50
2024-11-28 17:48:48.056983: train_loss -0.6855
2024-11-28 17:48:48.057873: val_loss -0.5909
2024-11-28 17:48:48.058600: Pseudo dice [0.6915]
2024-11-28 17:48:48.059529: Epoch time: 101.25 s
2024-11-28 17:48:48.060206: Yayy! New best EMA pseudo Dice: 0.5848
2024-11-28 17:48:49.994546: 
2024-11-28 17:48:49.996216: Epoch 9
2024-11-28 17:48:49.997167: Current learning rate: 0.00992
2024-11-28 17:50:30.590973: Validation loss did not improve from -0.59089. Patience: 1/50
2024-11-28 17:50:30.591792: train_loss -0.7051
2024-11-28 17:50:30.592999: val_loss -0.5764
2024-11-28 17:50:30.593938: Pseudo dice [0.6823]
2024-11-28 17:50:30.594682: Epoch time: 100.6 s
2024-11-28 17:50:31.152677: Yayy! New best EMA pseudo Dice: 0.5946
2024-11-28 17:50:33.074700: 
2024-11-28 17:50:33.075594: Epoch 10
2024-11-28 17:50:33.076305: Current learning rate: 0.00991
2024-11-28 17:52:14.322567: Validation loss did not improve from -0.59089. Patience: 2/50
2024-11-28 17:52:14.323243: train_loss -0.7079
2024-11-28 17:52:14.324176: val_loss -0.5662
2024-11-28 17:52:14.324965: Pseudo dice [0.6714]
2024-11-28 17:52:14.325799: Epoch time: 101.25 s
2024-11-28 17:52:14.326546: Yayy! New best EMA pseudo Dice: 0.6022
2024-11-28 17:52:16.197255: 
2024-11-28 17:52:16.198576: Epoch 11
2024-11-28 17:52:16.199313: Current learning rate: 0.0099
2024-11-28 17:53:57.249386: Validation loss did not improve from -0.59089. Patience: 3/50
2024-11-28 17:53:57.250174: train_loss -0.7214
2024-11-28 17:53:57.250881: val_loss -0.5297
2024-11-28 17:53:57.251567: Pseudo dice [0.6456]
2024-11-28 17:53:57.252202: Epoch time: 101.05 s
2024-11-28 17:53:57.252883: Yayy! New best EMA pseudo Dice: 0.6066
2024-11-28 17:53:59.160203: 
2024-11-28 17:53:59.161805: Epoch 12
2024-11-28 17:53:59.162610: Current learning rate: 0.00989
2024-11-28 17:55:40.383948: Validation loss did not improve from -0.59089. Patience: 4/50
2024-11-28 17:55:40.384972: train_loss -0.7212
2024-11-28 17:55:40.385892: val_loss -0.5682
2024-11-28 17:55:40.386605: Pseudo dice [0.6691]
2024-11-28 17:55:40.387422: Epoch time: 101.23 s
2024-11-28 17:55:40.388322: Yayy! New best EMA pseudo Dice: 0.6128
2024-11-28 17:55:42.360074: 
2024-11-28 17:55:42.361944: Epoch 13
2024-11-28 17:55:42.362995: Current learning rate: 0.00988
2024-11-28 17:57:22.964884: Validation loss did not improve from -0.59089. Patience: 5/50
2024-11-28 17:57:22.965584: train_loss -0.7364
2024-11-28 17:57:22.966375: val_loss -0.5595
2024-11-28 17:57:22.967103: Pseudo dice [0.6653]
2024-11-28 17:57:22.967810: Epoch time: 100.61 s
2024-11-28 17:57:22.968510: Yayy! New best EMA pseudo Dice: 0.6181
2024-11-28 17:57:24.890032: 
2024-11-28 17:57:24.891074: Epoch 14
2024-11-28 17:57:24.891887: Current learning rate: 0.00987
2024-11-28 17:59:06.193787: Validation loss did not improve from -0.59089. Patience: 6/50
2024-11-28 17:59:06.195105: train_loss -0.7367
2024-11-28 17:59:06.196075: val_loss -0.565
2024-11-28 17:59:06.197074: Pseudo dice [0.6681]
2024-11-28 17:59:06.197981: Epoch time: 101.31 s
2024-11-28 17:59:06.714200: Yayy! New best EMA pseudo Dice: 0.6231
2024-11-28 17:59:08.630916: 
2024-11-28 17:59:08.632379: Epoch 15
2024-11-28 17:59:08.633076: Current learning rate: 0.00986
2024-11-28 18:00:49.974294: Validation loss improved from -0.59089 to -0.59821! Patience: 6/50
2024-11-28 18:00:49.975417: train_loss -0.7379
2024-11-28 18:00:49.976473: val_loss -0.5982
2024-11-28 18:00:49.977354: Pseudo dice [0.6987]
2024-11-28 18:00:49.978286: Epoch time: 101.35 s
2024-11-28 18:00:49.979247: Yayy! New best EMA pseudo Dice: 0.6306
2024-11-28 18:00:51.979831: 
2024-11-28 18:00:51.981142: Epoch 16
2024-11-28 18:00:51.981822: Current learning rate: 0.00986
2024-11-28 18:02:33.310586: Validation loss did not improve from -0.59821. Patience: 1/50
2024-11-28 18:02:33.311574: train_loss -0.7351
2024-11-28 18:02:33.312467: val_loss -0.5528
2024-11-28 18:02:33.313265: Pseudo dice [0.656]
2024-11-28 18:02:33.314032: Epoch time: 101.33 s
2024-11-28 18:02:33.314762: Yayy! New best EMA pseudo Dice: 0.6332
2024-11-28 18:02:35.310861: 
2024-11-28 18:02:35.311832: Epoch 17
2024-11-28 18:02:35.312572: Current learning rate: 0.00985
2024-11-28 18:04:16.636532: Validation loss did not improve from -0.59821. Patience: 2/50
2024-11-28 18:04:16.637310: train_loss -0.7386
2024-11-28 18:04:16.638291: val_loss -0.5387
2024-11-28 18:04:16.639057: Pseudo dice [0.6483]
2024-11-28 18:04:16.639909: Epoch time: 101.33 s
2024-11-28 18:04:16.640766: Yayy! New best EMA pseudo Dice: 0.6347
2024-11-28 18:04:19.308316: 
2024-11-28 18:04:19.309865: Epoch 18
2024-11-28 18:04:19.310675: Current learning rate: 0.00984
2024-11-28 18:06:00.011659: Validation loss did not improve from -0.59821. Patience: 3/50
2024-11-28 18:06:00.012609: train_loss -0.7468
2024-11-28 18:06:00.013587: val_loss -0.5569
2024-11-28 18:06:00.014369: Pseudo dice [0.6661]
2024-11-28 18:06:00.015185: Epoch time: 100.71 s
2024-11-28 18:06:00.015827: Yayy! New best EMA pseudo Dice: 0.6378
2024-11-28 18:06:01.996095: 
2024-11-28 18:06:01.997446: Epoch 19
2024-11-28 18:06:01.998363: Current learning rate: 0.00983
2024-11-28 18:07:43.297506: Validation loss did not improve from -0.59821. Patience: 4/50
2024-11-28 18:07:43.298434: train_loss -0.7619
2024-11-28 18:07:43.299646: val_loss -0.5788
2024-11-28 18:07:43.300583: Pseudo dice [0.687]
2024-11-28 18:07:43.301549: Epoch time: 101.3 s
2024-11-28 18:07:43.861013: Yayy! New best EMA pseudo Dice: 0.6428
2024-11-28 18:07:45.842004: 
2024-11-28 18:07:45.843261: Epoch 20
2024-11-28 18:07:45.844113: Current learning rate: 0.00982
2024-11-28 18:09:27.163700: Validation loss did not improve from -0.59821. Patience: 5/50
2024-11-28 18:09:27.164668: train_loss -0.7625
2024-11-28 18:09:27.165500: val_loss -0.5691
2024-11-28 18:09:27.166286: Pseudo dice [0.6766]
2024-11-28 18:09:27.167089: Epoch time: 101.32 s
2024-11-28 18:09:27.167886: Yayy! New best EMA pseudo Dice: 0.6461
2024-11-28 18:09:29.186857: 
2024-11-28 18:09:29.188182: Epoch 21
2024-11-28 18:09:29.189185: Current learning rate: 0.00981
2024-11-28 18:11:10.580945: Validation loss did not improve from -0.59821. Patience: 6/50
2024-11-28 18:11:10.582127: train_loss -0.7594
2024-11-28 18:11:10.582954: val_loss -0.5626
2024-11-28 18:11:10.583630: Pseudo dice [0.6647]
2024-11-28 18:11:10.584485: Epoch time: 101.4 s
2024-11-28 18:11:10.585268: Yayy! New best EMA pseudo Dice: 0.648
2024-11-28 18:11:12.484381: 
2024-11-28 18:11:12.485865: Epoch 22
2024-11-28 18:11:12.486608: Current learning rate: 0.0098
2024-11-28 18:12:53.292323: Validation loss did not improve from -0.59821. Patience: 7/50
2024-11-28 18:12:53.293287: train_loss -0.7591
2024-11-28 18:12:53.294306: val_loss -0.5816
2024-11-28 18:12:53.295335: Pseudo dice [0.6816]
2024-11-28 18:12:53.296129: Epoch time: 100.81 s
2024-11-28 18:12:53.296993: Yayy! New best EMA pseudo Dice: 0.6514
2024-11-28 18:12:55.297399: 
2024-11-28 18:12:55.298953: Epoch 23
2024-11-28 18:12:55.299736: Current learning rate: 0.00979
2024-11-28 18:14:35.935409: Validation loss did not improve from -0.59821. Patience: 8/50
2024-11-28 18:14:35.936358: train_loss -0.7717
2024-11-28 18:14:35.937230: val_loss -0.5687
2024-11-28 18:14:35.937966: Pseudo dice [0.6743]
2024-11-28 18:14:35.938763: Epoch time: 100.64 s
2024-11-28 18:14:35.939507: Yayy! New best EMA pseudo Dice: 0.6536
2024-11-28 18:14:37.876620: 
2024-11-28 18:14:37.877923: Epoch 24
2024-11-28 18:14:37.878884: Current learning rate: 0.00978
2024-11-28 18:16:19.243257: Validation loss did not improve from -0.59821. Patience: 9/50
2024-11-28 18:16:19.244858: train_loss -0.7665
2024-11-28 18:16:19.245853: val_loss -0.5832
2024-11-28 18:16:19.246582: Pseudo dice [0.6846]
2024-11-28 18:16:19.247227: Epoch time: 101.37 s
2024-11-28 18:16:19.846202: Yayy! New best EMA pseudo Dice: 0.6567
2024-11-28 18:16:21.776216: 
2024-11-28 18:16:21.777739: Epoch 25
2024-11-28 18:16:21.778425: Current learning rate: 0.00977
2024-11-28 18:18:03.181292: Validation loss did not improve from -0.59821. Patience: 10/50
2024-11-28 18:18:03.182065: train_loss -0.759
2024-11-28 18:18:03.182844: val_loss -0.5835
2024-11-28 18:18:03.183707: Pseudo dice [0.6791]
2024-11-28 18:18:03.184453: Epoch time: 101.41 s
2024-11-28 18:18:03.185226: Yayy! New best EMA pseudo Dice: 0.659
2024-11-28 18:18:05.121680: 
2024-11-28 18:18:05.123023: Epoch 26
2024-11-28 18:18:05.123867: Current learning rate: 0.00977
2024-11-28 18:19:46.409481: Validation loss did not improve from -0.59821. Patience: 11/50
2024-11-28 18:19:46.410836: train_loss -0.7715
2024-11-28 18:19:46.411963: val_loss -0.5556
2024-11-28 18:19:46.412696: Pseudo dice [0.6631]
2024-11-28 18:19:46.413568: Epoch time: 101.29 s
2024-11-28 18:19:46.414402: Yayy! New best EMA pseudo Dice: 0.6594
2024-11-28 18:19:48.365371: 
2024-11-28 18:19:48.366329: Epoch 27
2024-11-28 18:19:48.367157: Current learning rate: 0.00976
2024-11-28 18:21:29.668542: Validation loss did not improve from -0.59821. Patience: 12/50
2024-11-28 18:21:29.669689: train_loss -0.7719
2024-11-28 18:21:29.670505: val_loss -0.5697
2024-11-28 18:21:29.671362: Pseudo dice [0.6799]
2024-11-28 18:21:29.672091: Epoch time: 101.31 s
2024-11-28 18:21:29.672831: Yayy! New best EMA pseudo Dice: 0.6614
2024-11-28 18:21:31.608638: 
2024-11-28 18:21:31.610219: Epoch 28
2024-11-28 18:21:31.611092: Current learning rate: 0.00975
2024-11-28 18:23:12.183180: Validation loss did not improve from -0.59821. Patience: 13/50
2024-11-28 18:23:12.184582: train_loss -0.7792
2024-11-28 18:23:12.185515: val_loss -0.541
2024-11-28 18:23:12.186197: Pseudo dice [0.6529]
2024-11-28 18:23:12.186894: Epoch time: 100.58 s
2024-11-28 18:23:14.091048: 
2024-11-28 18:23:14.092086: Epoch 29
2024-11-28 18:23:14.092895: Current learning rate: 0.00974
2024-11-28 18:24:55.463007: Validation loss did not improve from -0.59821. Patience: 14/50
2024-11-28 18:24:55.464372: train_loss -0.7789
2024-11-28 18:24:55.465617: val_loss -0.5824
2024-11-28 18:24:55.466358: Pseudo dice [0.6858]
2024-11-28 18:24:55.467030: Epoch time: 101.37 s
2024-11-28 18:24:56.042434: Yayy! New best EMA pseudo Dice: 0.6631
2024-11-28 18:24:57.968899: 
2024-11-28 18:24:57.970263: Epoch 30
2024-11-28 18:24:57.971015: Current learning rate: 0.00973
2024-11-28 18:26:39.367439: Validation loss did not improve from -0.59821. Patience: 15/50
2024-11-28 18:26:39.368369: train_loss -0.7814
2024-11-28 18:26:39.369243: val_loss -0.5812
2024-11-28 18:26:39.370158: Pseudo dice [0.6909]
2024-11-28 18:26:39.370980: Epoch time: 101.4 s
2024-11-28 18:26:39.371669: Yayy! New best EMA pseudo Dice: 0.6659
2024-11-28 18:26:41.331568: 
2024-11-28 18:26:41.332837: Epoch 31
2024-11-28 18:26:41.333839: Current learning rate: 0.00972
2024-11-28 18:28:22.697925: Validation loss did not improve from -0.59821. Patience: 16/50
2024-11-28 18:28:22.699147: train_loss -0.7889
2024-11-28 18:28:22.700046: val_loss -0.5956
2024-11-28 18:28:22.700851: Pseudo dice [0.6886]
2024-11-28 18:28:22.701544: Epoch time: 101.37 s
2024-11-28 18:28:22.702229: Yayy! New best EMA pseudo Dice: 0.6682
2024-11-28 18:28:24.671593: 
2024-11-28 18:28:24.673092: Epoch 32
2024-11-28 18:28:24.673799: Current learning rate: 0.00971
2024-11-28 18:30:05.640643: Validation loss did not improve from -0.59821. Patience: 17/50
2024-11-28 18:30:05.641876: train_loss -0.7788
2024-11-28 18:30:05.643130: val_loss -0.5674
2024-11-28 18:30:05.644157: Pseudo dice [0.6685]
2024-11-28 18:30:05.645177: Epoch time: 100.97 s
2024-11-28 18:30:05.646187: Yayy! New best EMA pseudo Dice: 0.6682
2024-11-28 18:30:07.621743: 
2024-11-28 18:30:07.623049: Epoch 33
2024-11-28 18:30:07.623976: Current learning rate: 0.0097
2024-11-28 18:31:48.450640: Validation loss did not improve from -0.59821. Patience: 18/50
2024-11-28 18:31:48.451832: train_loss -0.7848
2024-11-28 18:31:48.452988: val_loss -0.5668
2024-11-28 18:31:48.453849: Pseudo dice [0.6787]
2024-11-28 18:31:48.454652: Epoch time: 100.83 s
2024-11-28 18:31:48.455474: Yayy! New best EMA pseudo Dice: 0.6692
2024-11-28 18:31:50.440782: 
2024-11-28 18:31:50.442330: Epoch 34
2024-11-28 18:31:50.443204: Current learning rate: 0.00969
2024-11-28 18:33:31.969643: Validation loss did not improve from -0.59821. Patience: 19/50
2024-11-28 18:33:31.970351: train_loss -0.7845
2024-11-28 18:33:31.971500: val_loss -0.5794
2024-11-28 18:33:31.972233: Pseudo dice [0.6841]
2024-11-28 18:33:31.973012: Epoch time: 101.53 s
2024-11-28 18:33:32.526398: Yayy! New best EMA pseudo Dice: 0.6707
2024-11-28 18:33:34.463334: 
2024-11-28 18:33:34.464837: Epoch 35
2024-11-28 18:33:34.465528: Current learning rate: 0.00968
2024-11-28 18:35:15.430544: Validation loss did not improve from -0.59821. Patience: 20/50
2024-11-28 18:35:15.431789: train_loss -0.7931
2024-11-28 18:35:15.432647: val_loss -0.5967
2024-11-28 18:35:15.433443: Pseudo dice [0.7032]
2024-11-28 18:35:15.434235: Epoch time: 100.97 s
2024-11-28 18:35:15.435373: Yayy! New best EMA pseudo Dice: 0.674
2024-11-28 18:35:17.418460: 
2024-11-28 18:35:17.419709: Epoch 36
2024-11-28 18:35:17.420393: Current learning rate: 0.00968
2024-11-28 18:36:38.187789: Validation loss did not improve from -0.59821. Patience: 21/50
2024-11-28 18:36:38.188977: train_loss -0.7895
2024-11-28 18:36:38.189873: val_loss -0.5932
2024-11-28 18:36:38.190616: Pseudo dice [0.6923]
2024-11-28 18:36:38.191426: Epoch time: 80.77 s
2024-11-28 18:36:38.192318: Yayy! New best EMA pseudo Dice: 0.6758
2024-11-28 18:36:40.085013: 
2024-11-28 18:36:40.086484: Epoch 37
2024-11-28 18:36:40.087201: Current learning rate: 0.00967
2024-11-28 18:37:28.248954: Validation loss did not improve from -0.59821. Patience: 22/50
2024-11-28 18:37:28.250950: train_loss -0.7916
2024-11-28 18:37:28.251969: val_loss -0.5695
2024-11-28 18:37:28.252822: Pseudo dice [0.6759]
2024-11-28 18:37:28.253838: Epoch time: 48.17 s
2024-11-28 18:37:28.255030: Yayy! New best EMA pseudo Dice: 0.6758
2024-11-28 18:37:30.082684: 
2024-11-28 18:37:30.084001: Epoch 38
2024-11-28 18:37:30.084846: Current learning rate: 0.00966
2024-11-28 18:38:18.561908: Validation loss did not improve from -0.59821. Patience: 23/50
2024-11-28 18:38:18.563685: train_loss -0.7922
2024-11-28 18:38:18.564675: val_loss -0.5961
2024-11-28 18:38:18.565644: Pseudo dice [0.6865]
2024-11-28 18:38:18.566596: Epoch time: 48.48 s
2024-11-28 18:38:18.567424: Yayy! New best EMA pseudo Dice: 0.6769
2024-11-28 18:38:21.297304: 
2024-11-28 18:38:21.298904: Epoch 39
2024-11-28 18:38:21.300145: Current learning rate: 0.00965
2024-11-28 18:39:09.341533: Validation loss did not improve from -0.59821. Patience: 24/50
2024-11-28 18:39:09.342896: train_loss -0.7922
2024-11-28 18:39:09.343659: val_loss -0.5332
2024-11-28 18:39:09.344345: Pseudo dice [0.6414]
2024-11-28 18:39:09.345095: Epoch time: 48.05 s
2024-11-28 18:39:11.219696: 
2024-11-28 18:39:11.222013: Epoch 40
2024-11-28 18:39:11.222832: Current learning rate: 0.00964
2024-11-28 18:39:59.366796: Validation loss did not improve from -0.59821. Patience: 25/50
2024-11-28 18:39:59.368434: train_loss -0.7989
2024-11-28 18:39:59.369564: val_loss -0.5668
2024-11-28 18:39:59.370416: Pseudo dice [0.6719]
2024-11-28 18:39:59.371148: Epoch time: 48.15 s
2024-11-28 18:40:00.710251: 
2024-11-28 18:40:00.711931: Epoch 41
2024-11-28 18:40:00.712720: Current learning rate: 0.00963
2024-11-28 18:40:48.745626: Validation loss did not improve from -0.59821. Patience: 26/50
2024-11-28 18:40:48.747059: train_loss -0.7942
2024-11-28 18:40:48.747807: val_loss -0.5876
2024-11-28 18:40:48.748520: Pseudo dice [0.6977]
2024-11-28 18:40:48.749266: Epoch time: 48.04 s
2024-11-28 18:40:49.994362: 
2024-11-28 18:40:49.996048: Epoch 42
2024-11-28 18:40:49.997238: Current learning rate: 0.00962
2024-11-28 18:41:38.032207: Validation loss did not improve from -0.59821. Patience: 27/50
2024-11-28 18:41:38.033401: train_loss -0.7981
2024-11-28 18:41:38.034277: val_loss -0.5768
2024-11-28 18:41:38.035052: Pseudo dice [0.6819]
2024-11-28 18:41:38.035849: Epoch time: 48.04 s
2024-11-28 18:41:39.294993: 
2024-11-28 18:41:39.296325: Epoch 43
2024-11-28 18:41:39.297293: Current learning rate: 0.00961
2024-11-28 18:42:27.294025: Validation loss did not improve from -0.59821. Patience: 28/50
2024-11-28 18:42:27.295715: train_loss -0.7994
2024-11-28 18:42:27.296459: val_loss -0.5712
2024-11-28 18:42:27.297139: Pseudo dice [0.6826]
2024-11-28 18:42:27.297859: Epoch time: 48.0 s
2024-11-28 18:42:27.298717: Yayy! New best EMA pseudo Dice: 0.6769
2024-11-28 18:42:29.102930: 
2024-11-28 18:42:29.104054: Epoch 44
2024-11-28 18:42:29.104981: Current learning rate: 0.0096
2024-11-28 18:43:17.100916: Validation loss did not improve from -0.59821. Patience: 29/50
2024-11-28 18:43:17.102773: train_loss -0.7956
2024-11-28 18:43:17.103632: val_loss -0.5473
2024-11-28 18:43:17.104402: Pseudo dice [0.6672]
2024-11-28 18:43:17.105126: Epoch time: 48.0 s
2024-11-28 18:43:18.858627: 
2024-11-28 18:43:18.860194: Epoch 45
2024-11-28 18:43:18.861090: Current learning rate: 0.00959
2024-11-28 18:44:06.820173: Validation loss improved from -0.59821 to -0.62755! Patience: 29/50
2024-11-28 18:44:06.821996: train_loss -0.8038
2024-11-28 18:44:06.822782: val_loss -0.6275
2024-11-28 18:44:06.823755: Pseudo dice [0.7169]
2024-11-28 18:44:06.824551: Epoch time: 47.96 s
2024-11-28 18:44:06.825517: Yayy! New best EMA pseudo Dice: 0.68
2024-11-28 18:44:08.532492: 
2024-11-28 18:44:08.534253: Epoch 46
2024-11-28 18:44:08.535351: Current learning rate: 0.00959
2024-11-28 18:44:56.460584: Validation loss did not improve from -0.62755. Patience: 1/50
2024-11-28 18:44:56.462938: train_loss -0.7982
2024-11-28 18:44:56.464237: val_loss -0.5631
2024-11-28 18:44:56.465120: Pseudo dice [0.6699]
2024-11-28 18:44:56.465806: Epoch time: 47.93 s
2024-11-28 18:44:57.879200: 
2024-11-28 18:44:57.881513: Epoch 47
2024-11-28 18:44:57.882404: Current learning rate: 0.00958
2024-11-28 18:45:46.844733: Validation loss did not improve from -0.62755. Patience: 2/50
2024-11-28 18:45:46.846083: train_loss -0.7999
2024-11-28 18:45:46.846801: val_loss -0.5774
2024-11-28 18:45:46.847543: Pseudo dice [0.6802]
2024-11-28 18:45:46.848444: Epoch time: 48.97 s
2024-11-28 18:45:48.099372: 
2024-11-28 18:45:48.101207: Epoch 48
2024-11-28 18:45:48.102029: Current learning rate: 0.00957
2024-11-28 18:47:21.378905: Validation loss did not improve from -0.62755. Patience: 3/50
2024-11-28 18:47:21.380418: train_loss -0.7993
2024-11-28 18:47:21.381834: val_loss -0.5853
2024-11-28 18:47:21.382650: Pseudo dice [0.6874]
2024-11-28 18:47:21.383384: Epoch time: 93.28 s
2024-11-28 18:47:22.622239: 
2024-11-28 18:47:22.623899: Epoch 49
2024-11-28 18:47:22.625048: Current learning rate: 0.00956
2024-11-28 18:48:48.268283: Validation loss did not improve from -0.62755. Patience: 4/50
2024-11-28 18:48:48.270035: train_loss -0.8008
2024-11-28 18:48:48.271887: val_loss -0.569
2024-11-28 18:48:48.272830: Pseudo dice [0.6745]
2024-11-28 18:48:48.273881: Epoch time: 85.65 s
2024-11-28 18:48:50.499829: 
2024-11-28 18:48:50.502179: Epoch 50
2024-11-28 18:48:50.503757: Current learning rate: 0.00955
2024-11-28 18:50:30.366886: Validation loss did not improve from -0.62755. Patience: 5/50
2024-11-28 18:50:30.367948: train_loss -0.804
2024-11-28 18:50:30.368846: val_loss -0.6021
2024-11-28 18:50:30.369899: Pseudo dice [0.7016]
2024-11-28 18:50:30.371073: Epoch time: 99.87 s
2024-11-28 18:50:30.371819: Yayy! New best EMA pseudo Dice: 0.6816
2024-11-28 18:50:32.090503: 
2024-11-28 18:50:32.091626: Epoch 51
2024-11-28 18:50:32.092718: Current learning rate: 0.00954
2024-11-28 18:52:11.604396: Validation loss did not improve from -0.62755. Patience: 6/50
2024-11-28 18:52:11.605346: train_loss -0.8038
2024-11-28 18:52:11.606448: val_loss -0.5647
2024-11-28 18:52:11.607300: Pseudo dice [0.6739]
2024-11-28 18:52:11.608285: Epoch time: 99.52 s
2024-11-28 18:52:12.857794: 
2024-11-28 18:52:12.859385: Epoch 52
2024-11-28 18:52:12.860192: Current learning rate: 0.00953
2024-11-28 18:53:52.472597: Validation loss did not improve from -0.62755. Patience: 7/50
2024-11-28 18:53:52.473793: train_loss -0.8042
2024-11-28 18:53:52.475523: val_loss -0.5879
2024-11-28 18:53:52.476944: Pseudo dice [0.6911]
2024-11-28 18:53:52.478401: Epoch time: 99.62 s
2024-11-28 18:53:52.479624: Yayy! New best EMA pseudo Dice: 0.6819
2024-11-28 18:53:54.198405: 
2024-11-28 18:53:54.200149: Epoch 53
2024-11-28 18:53:54.201444: Current learning rate: 0.00952
2024-11-28 18:55:33.306326: Validation loss did not improve from -0.62755. Patience: 8/50
2024-11-28 18:55:33.307603: train_loss -0.8079
2024-11-28 18:55:33.308559: val_loss -0.5915
2024-11-28 18:55:33.309249: Pseudo dice [0.6974]
2024-11-28 18:55:33.310148: Epoch time: 99.11 s
2024-11-28 18:55:33.310842: Yayy! New best EMA pseudo Dice: 0.6834
2024-11-28 18:55:35.066560: 
2024-11-28 18:55:35.068098: Epoch 54
2024-11-28 18:55:35.069044: Current learning rate: 0.00951
2024-11-28 18:57:14.754059: Validation loss did not improve from -0.62755. Patience: 9/50
2024-11-28 18:57:14.755265: train_loss -0.8089
2024-11-28 18:57:14.756413: val_loss -0.5468
2024-11-28 18:57:14.757668: Pseudo dice [0.663]
2024-11-28 18:57:14.758609: Epoch time: 99.69 s
2024-11-28 18:57:16.525844: 
2024-11-28 18:57:16.527423: Epoch 55
2024-11-28 18:57:16.528288: Current learning rate: 0.0095
2024-11-28 18:58:56.253905: Validation loss did not improve from -0.62755. Patience: 10/50
2024-11-28 18:58:56.254583: train_loss -0.8059
2024-11-28 18:58:56.255368: val_loss -0.519
2024-11-28 18:58:56.256442: Pseudo dice [0.6466]
2024-11-28 18:58:56.257658: Epoch time: 99.73 s
2024-11-28 18:58:57.472884: 
2024-11-28 18:58:57.473787: Epoch 56
2024-11-28 18:58:57.474555: Current learning rate: 0.00949
2024-11-28 19:00:37.201706: Validation loss did not improve from -0.62755. Patience: 11/50
2024-11-28 19:00:37.203331: train_loss -0.7998
2024-11-28 19:00:37.204263: val_loss -0.5845
2024-11-28 19:00:37.205025: Pseudo dice [0.6949]
2024-11-28 19:00:37.205930: Epoch time: 99.73 s
2024-11-28 19:00:38.423192: 
2024-11-28 19:00:38.425007: Epoch 57
2024-11-28 19:00:38.426268: Current learning rate: 0.00949
2024-11-28 19:02:17.549978: Validation loss did not improve from -0.62755. Patience: 12/50
2024-11-28 19:02:17.550856: train_loss -0.8068
2024-11-28 19:02:17.551728: val_loss -0.5512
2024-11-28 19:02:17.552470: Pseudo dice [0.6649]
2024-11-28 19:02:17.553348: Epoch time: 99.13 s
2024-11-28 19:02:18.753350: 
2024-11-28 19:02:18.754861: Epoch 58
2024-11-28 19:02:18.755595: Current learning rate: 0.00948
2024-11-28 19:03:57.931688: Validation loss did not improve from -0.62755. Patience: 13/50
2024-11-28 19:03:57.932898: train_loss -0.8069
2024-11-28 19:03:57.933907: val_loss -0.5884
2024-11-28 19:03:57.934786: Pseudo dice [0.6867]
2024-11-28 19:03:57.935814: Epoch time: 99.18 s
2024-11-28 19:03:59.171946: 
2024-11-28 19:03:59.174036: Epoch 59
2024-11-28 19:03:59.174926: Current learning rate: 0.00947
2024-11-28 19:05:38.979363: Validation loss did not improve from -0.62755. Patience: 14/50
2024-11-28 19:05:38.980306: train_loss -0.8087
2024-11-28 19:05:38.981503: val_loss -0.5782
2024-11-28 19:05:38.982683: Pseudo dice [0.688]
2024-11-28 19:05:38.983911: Epoch time: 99.81 s
2024-11-28 19:05:40.759899: 
2024-11-28 19:05:40.761401: Epoch 60
2024-11-28 19:05:40.762187: Current learning rate: 0.00946
2024-11-28 19:07:20.419177: Validation loss did not improve from -0.62755. Patience: 15/50
2024-11-28 19:07:20.419973: train_loss -0.8107
2024-11-28 19:07:20.421163: val_loss -0.5713
2024-11-28 19:07:20.422078: Pseudo dice [0.681]
2024-11-28 19:07:20.423041: Epoch time: 99.66 s
2024-11-28 19:07:21.679551: 
2024-11-28 19:07:21.680887: Epoch 61
2024-11-28 19:07:21.681873: Current learning rate: 0.00945
2024-11-28 19:09:01.393607: Validation loss did not improve from -0.62755. Patience: 16/50
2024-11-28 19:09:01.394993: train_loss -0.814
2024-11-28 19:09:01.395957: val_loss -0.5713
2024-11-28 19:09:01.396862: Pseudo dice [0.6647]
2024-11-28 19:09:01.398011: Epoch time: 99.72 s
2024-11-28 19:09:02.992362: 
2024-11-28 19:09:02.993948: Epoch 62
2024-11-28 19:09:02.994695: Current learning rate: 0.00944
2024-11-28 19:10:42.795816: Validation loss did not improve from -0.62755. Patience: 17/50
2024-11-28 19:10:42.797337: train_loss -0.8117
2024-11-28 19:10:42.798025: val_loss -0.5711
2024-11-28 19:10:42.798758: Pseudo dice [0.6807]
2024-11-28 19:10:42.799442: Epoch time: 99.81 s
2024-11-28 19:10:44.043269: 
2024-11-28 19:10:44.044742: Epoch 63
2024-11-28 19:10:44.045533: Current learning rate: 0.00943
2024-11-28 19:12:23.173555: Validation loss did not improve from -0.62755. Patience: 18/50
2024-11-28 19:12:23.174953: train_loss -0.8104
2024-11-28 19:12:23.176508: val_loss -0.5729
2024-11-28 19:12:23.177522: Pseudo dice [0.6797]
2024-11-28 19:12:23.178207: Epoch time: 99.13 s
2024-11-28 19:12:24.409061: 
2024-11-28 19:12:24.411038: Epoch 64
2024-11-28 19:12:24.411866: Current learning rate: 0.00942
2024-11-28 19:14:04.243559: Validation loss did not improve from -0.62755. Patience: 19/50
2024-11-28 19:14:04.244448: train_loss -0.8164
2024-11-28 19:14:04.245617: val_loss -0.5933
2024-11-28 19:14:04.246868: Pseudo dice [0.702]
2024-11-28 19:14:04.247798: Epoch time: 99.84 s
2024-11-28 19:14:06.029779: 
2024-11-28 19:14:06.031436: Epoch 65
2024-11-28 19:14:06.032502: Current learning rate: 0.00941
2024-11-28 19:15:45.751273: Validation loss did not improve from -0.62755. Patience: 20/50
2024-11-28 19:15:45.752658: train_loss -0.8229
2024-11-28 19:15:45.753859: val_loss -0.5763
2024-11-28 19:15:45.755008: Pseudo dice [0.6856]
2024-11-28 19:15:45.756033: Epoch time: 99.72 s
2024-11-28 19:15:46.985885: 
2024-11-28 19:15:46.987741: Epoch 66
2024-11-28 19:15:46.989085: Current learning rate: 0.0094
2024-11-28 19:17:26.770864: Validation loss did not improve from -0.62755. Patience: 21/50
2024-11-28 19:17:26.772097: train_loss -0.8189
2024-11-28 19:17:26.773275: val_loss -0.5901
2024-11-28 19:17:26.774487: Pseudo dice [0.6927]
2024-11-28 19:17:26.775494: Epoch time: 99.79 s
2024-11-28 19:17:28.061457: 
2024-11-28 19:17:28.063222: Epoch 67
2024-11-28 19:17:28.064358: Current learning rate: 0.00939
2024-11-28 19:19:07.404045: Validation loss did not improve from -0.62755. Patience: 22/50
2024-11-28 19:19:07.405414: train_loss -0.8137
2024-11-28 19:19:07.406778: val_loss -0.602
2024-11-28 19:19:07.407866: Pseudo dice [0.7081]
2024-11-28 19:19:07.409092: Epoch time: 99.35 s
2024-11-28 19:19:07.410153: Yayy! New best EMA pseudo Dice: 0.6852
2024-11-28 19:19:09.204583: 
2024-11-28 19:19:09.206075: Epoch 68
2024-11-28 19:19:09.207305: Current learning rate: 0.00939
2024-11-28 19:20:48.153674: Validation loss did not improve from -0.62755. Patience: 23/50
2024-11-28 19:20:48.155052: train_loss -0.8137
2024-11-28 19:20:48.156212: val_loss -0.6179
2024-11-28 19:20:48.157134: Pseudo dice [0.7171]
2024-11-28 19:20:48.158186: Epoch time: 98.95 s
2024-11-28 19:20:48.158996: Yayy! New best EMA pseudo Dice: 0.6884
2024-11-28 19:20:49.925659: 
2024-11-28 19:20:49.926992: Epoch 69
2024-11-28 19:20:49.927836: Current learning rate: 0.00938
2024-11-28 19:22:29.429509: Validation loss did not improve from -0.62755. Patience: 24/50
2024-11-28 19:22:29.430650: train_loss -0.818
2024-11-28 19:22:29.431392: val_loss -0.5825
2024-11-28 19:22:29.432369: Pseudo dice [0.6861]
2024-11-28 19:22:29.433055: Epoch time: 99.51 s
2024-11-28 19:22:31.249238: 
2024-11-28 19:22:31.251040: Epoch 70
2024-11-28 19:22:31.251844: Current learning rate: 0.00937
2024-11-28 19:24:11.020612: Validation loss did not improve from -0.62755. Patience: 25/50
2024-11-28 19:24:11.021806: train_loss -0.8189
2024-11-28 19:24:11.022959: val_loss -0.5991
2024-11-28 19:24:11.023978: Pseudo dice [0.6998]
2024-11-28 19:24:11.025145: Epoch time: 99.77 s
2024-11-28 19:24:11.026192: Yayy! New best EMA pseudo Dice: 0.6893
2024-11-28 19:24:12.872925: 
2024-11-28 19:24:12.874743: Epoch 71
2024-11-28 19:24:12.875835: Current learning rate: 0.00936
2024-11-28 19:25:52.834103: Validation loss did not improve from -0.62755. Patience: 26/50
2024-11-28 19:25:52.835801: train_loss -0.8229
2024-11-28 19:25:52.836814: val_loss -0.572
2024-11-28 19:25:52.837587: Pseudo dice [0.6802]
2024-11-28 19:25:52.838329: Epoch time: 99.96 s
2024-11-28 19:25:54.170121: 
2024-11-28 19:25:54.171677: Epoch 72
2024-11-28 19:25:54.172935: Current learning rate: 0.00935
2024-11-28 19:27:34.076396: Validation loss did not improve from -0.62755. Patience: 27/50
2024-11-28 19:27:34.077631: train_loss -0.8237
2024-11-28 19:27:34.078948: val_loss -0.5754
2024-11-28 19:27:34.079649: Pseudo dice [0.6871]
2024-11-28 19:27:34.080496: Epoch time: 99.91 s
2024-11-28 19:27:35.782656: 
2024-11-28 19:27:35.784374: Epoch 73
2024-11-28 19:27:35.785268: Current learning rate: 0.00934
2024-11-28 19:29:15.175647: Validation loss did not improve from -0.62755. Patience: 28/50
2024-11-28 19:29:15.176963: train_loss -0.8204
2024-11-28 19:29:15.177806: val_loss -0.578
2024-11-28 19:29:15.178612: Pseudo dice [0.6798]
2024-11-28 19:29:15.179388: Epoch time: 99.4 s
2024-11-28 19:29:16.429393: 
2024-11-28 19:29:16.431212: Epoch 74
2024-11-28 19:29:16.432021: Current learning rate: 0.00933
2024-11-28 19:30:56.175130: Validation loss did not improve from -0.62755. Patience: 29/50
2024-11-28 19:30:56.176335: train_loss -0.8208
2024-11-28 19:30:56.177551: val_loss -0.6154
2024-11-28 19:30:56.178558: Pseudo dice [0.7114]
2024-11-28 19:30:56.179452: Epoch time: 99.75 s
2024-11-28 19:30:56.738661: Yayy! New best EMA pseudo Dice: 0.6898
2024-11-28 19:30:58.590183: 
2024-11-28 19:30:58.591916: Epoch 75
2024-11-28 19:30:58.592915: Current learning rate: 0.00932
2024-11-28 19:32:38.392405: Validation loss did not improve from -0.62755. Patience: 30/50
2024-11-28 19:32:38.393505: train_loss -0.8241
2024-11-28 19:32:38.394624: val_loss -0.5799
2024-11-28 19:32:38.395628: Pseudo dice [0.6902]
2024-11-28 19:32:38.396431: Epoch time: 99.8 s
2024-11-28 19:32:38.397250: Yayy! New best EMA pseudo Dice: 0.6899
2024-11-28 19:32:40.262516: 
2024-11-28 19:32:40.264575: Epoch 76
2024-11-28 19:32:40.265537: Current learning rate: 0.00931
2024-11-28 19:34:20.262028: Validation loss did not improve from -0.62755. Patience: 31/50
2024-11-28 19:34:20.263068: train_loss -0.8224
2024-11-28 19:34:20.263980: val_loss -0.5584
2024-11-28 19:34:20.264626: Pseudo dice [0.6734]
2024-11-28 19:34:20.265290: Epoch time: 100.0 s
2024-11-28 19:34:21.575884: 
2024-11-28 19:34:21.577775: Epoch 77
2024-11-28 19:34:21.578753: Current learning rate: 0.0093
2024-11-28 19:36:01.335018: Validation loss did not improve from -0.62755. Patience: 32/50
2024-11-28 19:36:01.336227: train_loss -0.8246
2024-11-28 19:36:01.337111: val_loss -0.5114
2024-11-28 19:36:01.337910: Pseudo dice [0.6457]
2024-11-28 19:36:01.338536: Epoch time: 99.76 s
2024-11-28 19:36:02.624226: 
2024-11-28 19:36:02.625474: Epoch 78
2024-11-28 19:36:02.626170: Current learning rate: 0.0093
2024-11-28 19:37:41.195912: Validation loss did not improve from -0.62755. Patience: 33/50
2024-11-28 19:37:41.197239: train_loss -0.8197
2024-11-28 19:37:41.198371: val_loss -0.5869
2024-11-28 19:37:41.199223: Pseudo dice [0.6915]
2024-11-28 19:37:41.199986: Epoch time: 98.57 s
2024-11-28 19:37:42.519340: 
2024-11-28 19:37:42.520707: Epoch 79
2024-11-28 19:37:42.521607: Current learning rate: 0.00929
2024-11-28 19:39:22.186160: Validation loss did not improve from -0.62755. Patience: 34/50
2024-11-28 19:39:22.187668: train_loss -0.8191
2024-11-28 19:39:22.188930: val_loss -0.539
2024-11-28 19:39:22.189618: Pseudo dice [0.6629]
2024-11-28 19:39:22.190377: Epoch time: 99.67 s
2024-11-28 19:39:24.017063: 
2024-11-28 19:39:24.018219: Epoch 80
2024-11-28 19:39:24.019171: Current learning rate: 0.00928
2024-11-28 19:41:04.308092: Validation loss did not improve from -0.62755. Patience: 35/50
2024-11-28 19:41:04.309120: train_loss -0.8202
2024-11-28 19:41:04.309955: val_loss -0.5757
2024-11-28 19:41:04.310682: Pseudo dice [0.6851]
2024-11-28 19:41:04.311538: Epoch time: 100.29 s
2024-11-28 19:41:05.632889: 
2024-11-28 19:41:05.634509: Epoch 81
2024-11-28 19:41:05.635347: Current learning rate: 0.00927
2024-11-28 19:42:46.151733: Validation loss did not improve from -0.62755. Patience: 36/50
2024-11-28 19:42:46.153429: train_loss -0.8206
2024-11-28 19:42:46.154785: val_loss -0.5953
2024-11-28 19:42:46.155538: Pseudo dice [0.6998]
2024-11-28 19:42:46.156360: Epoch time: 100.52 s
2024-11-28 19:42:47.483995: 
2024-11-28 19:42:47.485330: Epoch 82
2024-11-28 19:42:47.486356: Current learning rate: 0.00926
2024-11-28 19:44:27.932573: Validation loss did not improve from -0.62755. Patience: 37/50
2024-11-28 19:44:27.933495: train_loss -0.8276
2024-11-28 19:44:27.934581: val_loss -0.598
2024-11-28 19:44:27.935304: Pseudo dice [0.703]
2024-11-28 19:44:27.936031: Epoch time: 100.45 s
2024-11-28 19:44:29.162210: 
2024-11-28 19:44:29.163631: Epoch 83
2024-11-28 19:44:29.164357: Current learning rate: 0.00925
2024-11-28 19:46:08.794681: Validation loss did not improve from -0.62755. Patience: 38/50
2024-11-28 19:46:08.795641: train_loss -0.8262
2024-11-28 19:46:08.796660: val_loss -0.5854
2024-11-28 19:46:08.797759: Pseudo dice [0.6928]
2024-11-28 19:46:08.798570: Epoch time: 99.63 s
2024-11-28 19:46:10.437815: 
2024-11-28 19:46:10.439234: Epoch 84
2024-11-28 19:46:10.440073: Current learning rate: 0.00924
2024-11-28 19:47:50.787709: Validation loss did not improve from -0.62755. Patience: 39/50
2024-11-28 19:47:50.788398: train_loss -0.8225
2024-11-28 19:47:50.789383: val_loss -0.6138
2024-11-28 19:47:50.790317: Pseudo dice [0.7168]
2024-11-28 19:47:50.791230: Epoch time: 100.35 s
2024-11-28 19:47:51.359955: Yayy! New best EMA pseudo Dice: 0.69
2024-11-28 19:47:53.146888: 
2024-11-28 19:47:53.148420: Epoch 85
2024-11-28 19:47:53.149104: Current learning rate: 0.00923
2024-11-28 19:49:33.397530: Validation loss did not improve from -0.62755. Patience: 40/50
2024-11-28 19:49:33.398722: train_loss -0.8347
2024-11-28 19:49:33.399530: val_loss -0.5738
2024-11-28 19:49:33.400313: Pseudo dice [0.6876]
2024-11-28 19:49:33.400906: Epoch time: 100.25 s
2024-11-28 19:49:34.654458: 
2024-11-28 19:49:34.656124: Epoch 86
2024-11-28 19:49:34.656812: Current learning rate: 0.00922
2024-11-28 19:51:14.906788: Validation loss did not improve from -0.62755. Patience: 41/50
2024-11-28 19:51:14.908662: train_loss -0.8291
2024-11-28 19:51:14.910011: val_loss -0.5913
2024-11-28 19:51:14.910784: Pseudo dice [0.695]
2024-11-28 19:51:14.911499: Epoch time: 100.25 s
2024-11-28 19:51:14.912275: Yayy! New best EMA pseudo Dice: 0.6903
2024-11-28 19:51:16.819084: 
2024-11-28 19:51:16.820344: Epoch 87
2024-11-28 19:51:16.821009: Current learning rate: 0.00921
2024-11-28 19:52:56.643447: Validation loss did not improve from -0.62755. Patience: 42/50
2024-11-28 19:52:56.646749: train_loss -0.8328
2024-11-28 19:52:56.649096: val_loss -0.5666
2024-11-28 19:52:56.650090: Pseudo dice [0.6738]
2024-11-28 19:52:56.651259: Epoch time: 99.83 s
2024-11-28 19:52:58.084691: 
2024-11-28 19:52:58.087116: Epoch 88
2024-11-28 19:52:58.088110: Current learning rate: 0.0092
2024-11-28 19:54:37.388528: Validation loss did not improve from -0.62755. Patience: 43/50
2024-11-28 19:54:37.389354: train_loss -0.8284
2024-11-28 19:54:37.390205: val_loss -0.5556
2024-11-28 19:54:37.391097: Pseudo dice [0.6807]
2024-11-28 19:54:37.391905: Epoch time: 99.31 s
2024-11-28 19:54:38.657973: 
2024-11-28 19:54:38.659585: Epoch 89
2024-11-28 19:54:38.660577: Current learning rate: 0.0092
2024-11-28 19:56:17.650891: Validation loss did not improve from -0.62755. Patience: 44/50
2024-11-28 19:56:17.652337: train_loss -0.8359
2024-11-28 19:56:17.653572: val_loss -0.5708
2024-11-28 19:56:17.654241: Pseudo dice [0.68]
2024-11-28 19:56:17.654905: Epoch time: 99.0 s
2024-11-28 19:56:19.401609: 
2024-11-28 19:56:19.403295: Epoch 90
2024-11-28 19:56:19.404493: Current learning rate: 0.00919
2024-11-28 19:57:59.158287: Validation loss did not improve from -0.62755. Patience: 45/50
2024-11-28 19:57:59.159455: train_loss -0.8308
2024-11-28 19:57:59.160836: val_loss -0.6111
2024-11-28 19:57:59.161818: Pseudo dice [0.7091]
2024-11-28 19:57:59.162840: Epoch time: 99.76 s
2024-11-28 19:58:00.446395: 
2024-11-28 19:58:00.447669: Epoch 91
2024-11-28 19:58:00.448421: Current learning rate: 0.00918
2024-11-28 19:59:41.150633: Validation loss did not improve from -0.62755. Patience: 46/50
2024-11-28 19:59:41.151988: train_loss -0.8341
2024-11-28 19:59:41.153154: val_loss -0.5803
2024-11-28 19:59:41.154018: Pseudo dice [0.6895]
2024-11-28 19:59:41.154870: Epoch time: 100.71 s
2024-11-28 19:59:42.420307: 
2024-11-28 19:59:42.421458: Epoch 92
2024-11-28 19:59:42.422444: Current learning rate: 0.00917
2024-11-28 20:01:22.864310: Validation loss did not improve from -0.62755. Patience: 47/50
2024-11-28 20:01:22.865413: train_loss -0.8339
2024-11-28 20:01:22.866346: val_loss -0.5661
2024-11-28 20:01:22.867118: Pseudo dice [0.6818]
2024-11-28 20:01:22.867950: Epoch time: 100.45 s
2024-11-28 20:01:24.105909: 
2024-11-28 20:01:24.107370: Epoch 93
2024-11-28 20:01:24.108242: Current learning rate: 0.00916
2024-11-28 20:03:03.257137: Validation loss did not improve from -0.62755. Patience: 48/50
2024-11-28 20:03:03.258686: train_loss -0.8329
2024-11-28 20:03:03.259826: val_loss -0.5707
2024-11-28 20:03:03.260565: Pseudo dice [0.686]
2024-11-28 20:03:03.261509: Epoch time: 99.15 s
2024-11-28 20:03:04.502668: 
2024-11-28 20:03:04.504714: Epoch 94
2024-11-28 20:03:04.505477: Current learning rate: 0.00915
2024-11-28 20:04:44.365792: Validation loss did not improve from -0.62755. Patience: 49/50
2024-11-28 20:04:44.367208: train_loss -0.8373
2024-11-28 20:04:44.368598: val_loss -0.5552
2024-11-28 20:04:44.369735: Pseudo dice [0.6723]
2024-11-28 20:04:44.370970: Epoch time: 99.87 s
2024-11-28 20:04:46.096246: 
2024-11-28 20:04:46.098189: Epoch 95
2024-11-28 20:04:46.099017: Current learning rate: 0.00914
2024-11-28 20:06:25.966277: Validation loss did not improve from -0.62755. Patience: 50/50
2024-11-28 20:06:25.967309: train_loss -0.8308
2024-11-28 20:06:25.968340: val_loss -0.6172
2024-11-28 20:06:25.969140: Pseudo dice [0.7111]
2024-11-28 20:06:25.969811: Epoch time: 99.87 s
2024-11-28 20:06:27.526486: Patience reached. Stopping training.
2024-11-28 20:06:28.103763: Training done.
2024-11-28 20:06:28.223783: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset306_Sohee_Ajay_Calcium_OCT/splits_final.json
2024-11-28 20:06:28.227065: The split file contains 5 splits.
2024-11-28 20:06:28.227946: Desired fold for training: 2
2024-11-28 20:06:28.228836: This split has 10 training and 3 validation cases.
2024-11-28 20:06:28.229676: predicting 401-004
2024-11-28 20:06:28.239334: 401-004, shape torch.Size([1, 375, 498, 498]), rank 0
2024-11-28 20:07:00.966296: predicting 706-005
2024-11-28 20:07:00.987621: 706-005, shape torch.Size([1, 375, 498, 498]), rank 0
2024-11-28 20:07:20.513514: predicting 708006Pre
2024-11-28 20:07:20.534872: 708006Pre, shape torch.Size([1, 253, 498, 498]), rank 0
2024-11-28 20:07:54.419643: Validation complete
2024-11-28 20:07:54.421317: Mean Validation Dice:  0.6211384345637144
2024-11-28 18:45:08.389906: unpacking done...
2024-11-28 18:45:08.423501: Unable to plot network architecture: nnUNet_compile is enabled!
2024-11-28 18:45:08.473049: 
2024-11-28 18:45:08.474739: Epoch 0
2024-11-28 18:45:08.476007: Current learning rate: 0.01
2024-11-28 18:47:54.732620: Validation loss improved from 1000.00000 to -0.28449! Patience: 0/50
2024-11-28 18:47:54.733729: train_loss -0.2103
2024-11-28 18:47:54.734804: val_loss -0.2845
2024-11-28 18:47:54.735532: Pseudo dice [0.4448]
2024-11-28 18:47:54.736486: Epoch time: 166.26 s
2024-11-28 18:47:54.737406: Yayy! New best EMA pseudo Dice: 0.4448
2024-11-28 18:47:56.326271: 
2024-11-28 18:47:56.328144: Epoch 1
2024-11-28 18:47:56.329193: Current learning rate: 0.00999
2024-11-28 18:49:35.303826: Validation loss improved from -0.28449 to -0.42902! Patience: 0/50
2024-11-28 18:49:35.304863: train_loss -0.4864
2024-11-28 18:49:35.305573: val_loss -0.429
2024-11-28 18:49:35.306367: Pseudo dice [0.563]
2024-11-28 18:49:35.307227: Epoch time: 98.98 s
2024-11-28 18:49:35.308205: Yayy! New best EMA pseudo Dice: 0.4566
2024-11-28 18:49:37.056822: 
2024-11-28 18:49:37.058473: Epoch 2
2024-11-28 18:49:37.059315: Current learning rate: 0.00998
2024-11-28 18:51:16.551885: Validation loss improved from -0.42902 to -0.47653! Patience: 0/50
2024-11-28 18:51:16.553388: train_loss -0.5789
2024-11-28 18:51:16.554312: val_loss -0.4765
2024-11-28 18:51:16.555170: Pseudo dice [0.6088]
2024-11-28 18:51:16.555827: Epoch time: 99.5 s
2024-11-28 18:51:16.556397: Yayy! New best EMA pseudo Dice: 0.4718
2024-11-28 18:51:18.456480: 
2024-11-28 18:51:18.458068: Epoch 3
2024-11-28 18:51:18.459100: Current learning rate: 0.00997
2024-11-28 18:52:58.361665: Validation loss improved from -0.47653 to -0.53330! Patience: 0/50
2024-11-28 18:52:58.362867: train_loss -0.6106
2024-11-28 18:52:58.363903: val_loss -0.5333
2024-11-28 18:52:58.364618: Pseudo dice [0.6528]
2024-11-28 18:52:58.365278: Epoch time: 99.91 s
2024-11-28 18:52:58.366007: Yayy! New best EMA pseudo Dice: 0.4899
2024-11-28 18:53:00.164462: 
2024-11-28 18:53:00.165878: Epoch 4
2024-11-28 18:53:00.166552: Current learning rate: 0.00996
2024-11-28 18:54:39.462568: Validation loss did not improve from -0.53330. Patience: 1/50
2024-11-28 18:54:39.463840: train_loss -0.6339
2024-11-28 18:54:39.464978: val_loss -0.4762
2024-11-28 18:54:39.465649: Pseudo dice [0.6254]
2024-11-28 18:54:39.466459: Epoch time: 99.3 s
2024-11-28 18:54:39.937659: Yayy! New best EMA pseudo Dice: 0.5035
2024-11-28 18:54:41.777751: 
2024-11-28 18:54:41.779808: Epoch 5
2024-11-28 18:54:41.781280: Current learning rate: 0.00995
2024-11-28 18:56:21.044608: Validation loss did not improve from -0.53330. Patience: 2/50
2024-11-28 18:56:21.046319: train_loss -0.6466
2024-11-28 18:56:21.048003: val_loss -0.5112
2024-11-28 18:56:21.048862: Pseudo dice [0.6346]
2024-11-28 18:56:21.049615: Epoch time: 99.27 s
2024-11-28 18:56:21.050477: Yayy! New best EMA pseudo Dice: 0.5166
2024-11-28 18:56:22.811516: 
2024-11-28 18:56:22.812843: Epoch 6
2024-11-28 18:56:22.813651: Current learning rate: 0.00995
2024-11-28 18:58:02.157152: Validation loss improved from -0.53330 to -0.54155! Patience: 2/50
2024-11-28 18:58:02.158499: train_loss -0.6744
2024-11-28 18:58:02.159719: val_loss -0.5415
2024-11-28 18:58:02.160611: Pseudo dice [0.6539]
2024-11-28 18:58:02.161367: Epoch time: 99.35 s
2024-11-28 18:58:02.162078: Yayy! New best EMA pseudo Dice: 0.5303
2024-11-28 18:58:03.904020: 
2024-11-28 18:58:03.905286: Epoch 7
2024-11-28 18:58:03.906010: Current learning rate: 0.00994
2024-11-28 18:59:43.836141: Validation loss did not improve from -0.54155. Patience: 1/50
2024-11-28 18:59:43.837396: train_loss -0.6773
2024-11-28 18:59:43.838263: val_loss -0.4965
2024-11-28 18:59:43.839208: Pseudo dice [0.6197]
2024-11-28 18:59:43.840173: Epoch time: 99.93 s
2024-11-28 18:59:43.841142: Yayy! New best EMA pseudo Dice: 0.5392
2024-11-28 18:59:45.640783: 
2024-11-28 18:59:45.642015: Epoch 8
2024-11-28 18:59:45.642957: Current learning rate: 0.00993
2024-11-28 19:01:25.748398: Validation loss improved from -0.54155 to -0.55986! Patience: 1/50
2024-11-28 19:01:25.749645: train_loss -0.6835
2024-11-28 19:01:25.750843: val_loss -0.5599
2024-11-28 19:01:25.751490: Pseudo dice [0.6649]
2024-11-28 19:01:25.752462: Epoch time: 100.11 s
2024-11-28 19:01:25.753476: Yayy! New best EMA pseudo Dice: 0.5518
2024-11-28 19:01:28.075169: 
2024-11-28 19:01:28.076697: Epoch 9
2024-11-28 19:01:28.077614: Current learning rate: 0.00992
2024-11-28 19:03:08.137290: Validation loss did not improve from -0.55986. Patience: 1/50
2024-11-28 19:03:08.138484: train_loss -0.7022
2024-11-28 19:03:08.139357: val_loss -0.5484
2024-11-28 19:03:08.140050: Pseudo dice [0.6751]
2024-11-28 19:03:08.140651: Epoch time: 100.06 s
2024-11-28 19:03:08.668719: Yayy! New best EMA pseudo Dice: 0.5641
2024-11-28 19:03:10.432810: 
2024-11-28 19:03:10.434053: Epoch 10
2024-11-28 19:03:10.434766: Current learning rate: 0.00991
2024-11-28 19:04:50.456712: Validation loss did not improve from -0.55986. Patience: 2/50
2024-11-28 19:04:50.458332: train_loss -0.7107
2024-11-28 19:04:50.459821: val_loss -0.5561
2024-11-28 19:04:50.460858: Pseudo dice [0.6689]
2024-11-28 19:04:50.461748: Epoch time: 100.03 s
2024-11-28 19:04:50.462886: Yayy! New best EMA pseudo Dice: 0.5746
2024-11-28 19:04:52.190261: 
2024-11-28 19:04:52.192094: Epoch 11
2024-11-28 19:04:52.192790: Current learning rate: 0.0099
2024-11-28 19:06:31.519578: Validation loss did not improve from -0.55986. Patience: 3/50
2024-11-28 19:06:31.521047: train_loss -0.7125
2024-11-28 19:06:31.522022: val_loss -0.5385
2024-11-28 19:06:31.522669: Pseudo dice [0.6575]
2024-11-28 19:06:31.523274: Epoch time: 99.33 s
2024-11-28 19:06:31.523976: Yayy! New best EMA pseudo Dice: 0.5829
2024-11-28 19:06:33.288087: 
2024-11-28 19:06:33.289789: Epoch 12
2024-11-28 19:06:33.290929: Current learning rate: 0.00989
2024-11-28 19:08:13.197946: Validation loss did not improve from -0.55986. Patience: 4/50
2024-11-28 19:08:13.198862: train_loss -0.7155
2024-11-28 19:08:13.199988: val_loss -0.5538
2024-11-28 19:08:13.200999: Pseudo dice [0.6715]
2024-11-28 19:08:13.201825: Epoch time: 99.91 s
2024-11-28 19:08:13.202599: Yayy! New best EMA pseudo Dice: 0.5918
2024-11-28 19:08:15.048137: 
2024-11-28 19:08:15.049582: Epoch 13
2024-11-28 19:08:15.050294: Current learning rate: 0.00988
2024-11-28 19:09:54.624552: Validation loss improved from -0.55986 to -0.58632! Patience: 4/50
2024-11-28 19:09:54.625892: train_loss -0.7158
2024-11-28 19:09:54.626847: val_loss -0.5863
2024-11-28 19:09:54.627888: Pseudo dice [0.6899]
2024-11-28 19:09:54.628715: Epoch time: 99.58 s
2024-11-28 19:09:54.629785: Yayy! New best EMA pseudo Dice: 0.6016
2024-11-28 19:09:56.439877: 
2024-11-28 19:09:56.441311: Epoch 14
2024-11-28 19:09:56.442012: Current learning rate: 0.00987
2024-11-28 19:11:36.426024: Validation loss did not improve from -0.58632. Patience: 1/50
2024-11-28 19:11:36.427486: train_loss -0.7233
2024-11-28 19:11:36.428725: val_loss -0.4844
2024-11-28 19:11:36.429528: Pseudo dice [0.637]
2024-11-28 19:11:36.430537: Epoch time: 99.99 s
2024-11-28 19:11:36.951953: Yayy! New best EMA pseudo Dice: 0.6051
2024-11-28 19:11:38.766210: 
2024-11-28 19:11:38.767839: Epoch 15
2024-11-28 19:11:38.768753: Current learning rate: 0.00986
2024-11-28 19:13:18.966680: Validation loss did not improve from -0.58632. Patience: 2/50
2024-11-28 19:13:18.967766: train_loss -0.7296
2024-11-28 19:13:18.969459: val_loss -0.5523
2024-11-28 19:13:18.970393: Pseudo dice [0.6702]
2024-11-28 19:13:18.971022: Epoch time: 100.2 s
2024-11-28 19:13:18.971725: Yayy! New best EMA pseudo Dice: 0.6116
2024-11-28 19:13:20.791069: 
2024-11-28 19:13:20.792762: Epoch 16
2024-11-28 19:13:20.793767: Current learning rate: 0.00986
2024-11-28 19:15:00.183383: Validation loss did not improve from -0.58632. Patience: 3/50
2024-11-28 19:15:00.184420: train_loss -0.7439
2024-11-28 19:15:00.185210: val_loss -0.5398
2024-11-28 19:15:00.186118: Pseudo dice [0.6607]
2024-11-28 19:15:00.187143: Epoch time: 99.39 s
2024-11-28 19:15:00.188241: Yayy! New best EMA pseudo Dice: 0.6165
2024-11-28 19:15:02.029408: 
2024-11-28 19:15:02.031136: Epoch 17
2024-11-28 19:15:02.031856: Current learning rate: 0.00985
2024-11-28 19:16:42.128407: Validation loss did not improve from -0.58632. Patience: 4/50
2024-11-28 19:16:42.129940: train_loss -0.7481
2024-11-28 19:16:42.132017: val_loss -0.5357
2024-11-28 19:16:42.133054: Pseudo dice [0.6562]
2024-11-28 19:16:42.133813: Epoch time: 100.1 s
2024-11-28 19:16:42.135076: Yayy! New best EMA pseudo Dice: 0.6205
2024-11-28 19:16:43.948323: 
2024-11-28 19:16:43.949767: Epoch 18
2024-11-28 19:16:43.950429: Current learning rate: 0.00984
2024-11-28 19:18:24.159078: Validation loss did not improve from -0.58632. Patience: 5/50
2024-11-28 19:18:24.160292: train_loss -0.7413
2024-11-28 19:18:24.161115: val_loss -0.5485
2024-11-28 19:18:24.162167: Pseudo dice [0.6641]
2024-11-28 19:18:24.162884: Epoch time: 100.21 s
2024-11-28 19:18:24.163648: Yayy! New best EMA pseudo Dice: 0.6249
2024-11-28 19:18:26.445462: 
2024-11-28 19:18:26.446935: Epoch 19
2024-11-28 19:18:26.448092: Current learning rate: 0.00983
2024-11-28 19:20:05.949598: Validation loss did not improve from -0.58632. Patience: 6/50
2024-11-28 19:20:05.950696: train_loss -0.7484
2024-11-28 19:20:05.951569: val_loss -0.5212
2024-11-28 19:20:05.952219: Pseudo dice [0.6466]
2024-11-28 19:20:05.952897: Epoch time: 99.51 s
2024-11-28 19:20:06.508974: Yayy! New best EMA pseudo Dice: 0.627
2024-11-28 19:20:08.369543: 
2024-11-28 19:20:08.371121: Epoch 20
2024-11-28 19:20:08.371917: Current learning rate: 0.00982
2024-11-28 19:21:47.772592: Validation loss did not improve from -0.58632. Patience: 7/50
2024-11-28 19:21:47.773667: train_loss -0.7554
2024-11-28 19:21:47.774643: val_loss -0.564
2024-11-28 19:21:47.775481: Pseudo dice [0.6675]
2024-11-28 19:21:47.776339: Epoch time: 99.41 s
2024-11-28 19:21:47.777083: Yayy! New best EMA pseudo Dice: 0.6311
2024-11-28 19:21:49.659731: 
2024-11-28 19:21:49.660745: Epoch 21
2024-11-28 19:21:49.661550: Current learning rate: 0.00981
2024-11-28 19:23:29.172901: Validation loss did not improve from -0.58632. Patience: 8/50
2024-11-28 19:23:29.173946: train_loss -0.7547
2024-11-28 19:23:29.175115: val_loss -0.5695
2024-11-28 19:23:29.176332: Pseudo dice [0.6696]
2024-11-28 19:23:29.177399: Epoch time: 99.52 s
2024-11-28 19:23:29.178477: Yayy! New best EMA pseudo Dice: 0.6349
2024-11-28 19:23:30.976620: 
2024-11-28 19:23:30.978165: Epoch 22
2024-11-28 19:23:30.979015: Current learning rate: 0.0098
2024-11-28 19:25:10.427670: Validation loss did not improve from -0.58632. Patience: 9/50
2024-11-28 19:25:10.428836: train_loss -0.7625
2024-11-28 19:25:10.430365: val_loss -0.5639
2024-11-28 19:25:10.431508: Pseudo dice [0.6674]
2024-11-28 19:25:10.432709: Epoch time: 99.45 s
2024-11-28 19:25:10.433740: Yayy! New best EMA pseudo Dice: 0.6382
2024-11-28 19:25:12.149192: 
2024-11-28 19:25:12.151451: Epoch 23
2024-11-28 19:25:12.152505: Current learning rate: 0.00979
2024-11-28 19:26:51.975183: Validation loss did not improve from -0.58632. Patience: 10/50
2024-11-28 19:26:51.975850: train_loss -0.7605
2024-11-28 19:26:51.976874: val_loss -0.5408
2024-11-28 19:26:51.978095: Pseudo dice [0.6631]
2024-11-28 19:26:51.979491: Epoch time: 99.83 s
2024-11-28 19:26:51.980291: Yayy! New best EMA pseudo Dice: 0.6407
2024-11-28 19:26:53.703903: 
2024-11-28 19:26:53.705467: Epoch 24
2024-11-28 19:26:53.706163: Current learning rate: 0.00978
2024-11-28 19:28:33.342745: Validation loss did not improve from -0.58632. Patience: 11/50
2024-11-28 19:28:33.344351: train_loss -0.7653
2024-11-28 19:28:33.345713: val_loss -0.5304
2024-11-28 19:28:33.346806: Pseudo dice [0.6553]
2024-11-28 19:28:33.348012: Epoch time: 99.64 s
2024-11-28 19:28:33.868437: Yayy! New best EMA pseudo Dice: 0.6421
2024-11-28 19:28:35.622165: 
2024-11-28 19:28:35.624136: Epoch 25
2024-11-28 19:28:35.624916: Current learning rate: 0.00977
2024-11-28 19:30:15.789817: Validation loss did not improve from -0.58632. Patience: 12/50
2024-11-28 19:30:15.791138: train_loss -0.7651
2024-11-28 19:30:15.792008: val_loss -0.5637
2024-11-28 19:30:15.792811: Pseudo dice [0.6772]
2024-11-28 19:30:15.793706: Epoch time: 100.17 s
2024-11-28 19:30:15.794464: Yayy! New best EMA pseudo Dice: 0.6456
2024-11-28 19:30:17.576102: 
2024-11-28 19:30:17.577501: Epoch 26
2024-11-28 19:30:17.578170: Current learning rate: 0.00977
2024-11-28 19:31:56.183492: Validation loss did not improve from -0.58632. Patience: 13/50
2024-11-28 19:31:56.184514: train_loss -0.7626
2024-11-28 19:31:56.185348: val_loss -0.5461
2024-11-28 19:31:56.186044: Pseudo dice [0.6477]
2024-11-28 19:31:56.186760: Epoch time: 98.61 s
2024-11-28 19:31:56.187553: Yayy! New best EMA pseudo Dice: 0.6458
2024-11-28 19:31:57.959183: 
2024-11-28 19:31:57.960644: Epoch 27
2024-11-28 19:31:57.961458: Current learning rate: 0.00976
2024-11-28 19:33:37.261052: Validation loss did not improve from -0.58632. Patience: 14/50
2024-11-28 19:33:37.262407: train_loss -0.7708
2024-11-28 19:33:37.263984: val_loss -0.5588
2024-11-28 19:33:37.264919: Pseudo dice [0.6735]
2024-11-28 19:33:37.265761: Epoch time: 99.3 s
2024-11-28 19:33:37.266571: Yayy! New best EMA pseudo Dice: 0.6486
2024-11-28 19:33:39.004842: 
2024-11-28 19:33:39.006103: Epoch 28
2024-11-28 19:33:39.006772: Current learning rate: 0.00975
2024-11-28 19:35:18.842866: Validation loss improved from -0.58632 to -0.60115! Patience: 14/50
2024-11-28 19:35:18.844293: train_loss -0.7752
2024-11-28 19:35:18.845687: val_loss -0.6011
2024-11-28 19:35:18.846842: Pseudo dice [0.7024]
2024-11-28 19:35:18.847961: Epoch time: 99.84 s
2024-11-28 19:35:18.848934: Yayy! New best EMA pseudo Dice: 0.654
2024-11-28 19:35:20.640569: 
2024-11-28 19:35:20.642655: Epoch 29
2024-11-28 19:35:20.643686: Current learning rate: 0.00974
2024-11-28 19:37:00.628477: Validation loss did not improve from -0.60115. Patience: 1/50
2024-11-28 19:37:00.630466: train_loss -0.7752
2024-11-28 19:37:00.631995: val_loss -0.5641
2024-11-28 19:37:00.633006: Pseudo dice [0.6772]
2024-11-28 19:37:00.634006: Epoch time: 99.99 s
2024-11-28 19:37:01.175972: Yayy! New best EMA pseudo Dice: 0.6563
2024-11-28 19:37:03.432983: 
2024-11-28 19:37:03.434471: Epoch 30
2024-11-28 19:37:03.435359: Current learning rate: 0.00973
2024-11-28 19:38:43.346603: Validation loss improved from -0.60115 to -0.60628! Patience: 1/50
2024-11-28 19:38:43.347654: train_loss -0.7785
2024-11-28 19:38:43.349118: val_loss -0.6063
2024-11-28 19:38:43.350351: Pseudo dice [0.7111]
2024-11-28 19:38:43.351279: Epoch time: 99.92 s
2024-11-28 19:38:43.352467: Yayy! New best EMA pseudo Dice: 0.6618
2024-11-28 19:38:45.145749: 
2024-11-28 19:38:45.146760: Epoch 31
2024-11-28 19:38:45.147648: Current learning rate: 0.00972
2024-11-28 19:40:24.503366: Validation loss did not improve from -0.60628. Patience: 1/50
2024-11-28 19:40:24.504760: train_loss -0.7716
2024-11-28 19:40:24.505660: val_loss -0.5333
2024-11-28 19:40:24.506414: Pseudo dice [0.6516]
2024-11-28 19:40:24.507193: Epoch time: 99.36 s
2024-11-28 19:40:25.779331: 
2024-11-28 19:40:25.781156: Epoch 32
2024-11-28 19:40:25.781998: Current learning rate: 0.00971
2024-11-28 19:42:05.892538: Validation loss did not improve from -0.60628. Patience: 2/50
2024-11-28 19:42:05.893381: train_loss -0.7803
2024-11-28 19:42:05.894738: val_loss -0.4969
2024-11-28 19:42:05.895530: Pseudo dice [0.644]
2024-11-28 19:42:05.896349: Epoch time: 100.12 s
2024-11-28 19:42:07.158123: 
2024-11-28 19:42:07.159877: Epoch 33
2024-11-28 19:42:07.160772: Current learning rate: 0.0097
2024-11-28 19:43:47.326507: Validation loss did not improve from -0.60628. Patience: 3/50
2024-11-28 19:43:47.327676: train_loss -0.7796
2024-11-28 19:43:47.329060: val_loss -0.5676
2024-11-28 19:43:47.330134: Pseudo dice [0.6746]
2024-11-28 19:43:47.331141: Epoch time: 100.17 s
2024-11-28 19:43:48.585792: 
2024-11-28 19:43:48.587556: Epoch 34
2024-11-28 19:43:48.588379: Current learning rate: 0.00969
2024-11-28 19:45:28.601007: Validation loss did not improve from -0.60628. Patience: 4/50
2024-11-28 19:45:28.602293: train_loss -0.7822
2024-11-28 19:45:28.603252: val_loss -0.5398
2024-11-28 19:45:28.603949: Pseudo dice [0.6481]
2024-11-28 19:45:28.604717: Epoch time: 100.02 s
2024-11-28 19:45:30.443316: 
2024-11-28 19:45:30.444857: Epoch 35
2024-11-28 19:45:30.445592: Current learning rate: 0.00968
2024-11-28 19:47:10.156241: Validation loss did not improve from -0.60628. Patience: 5/50
2024-11-28 19:47:10.157441: train_loss -0.7787
2024-11-28 19:47:10.158380: val_loss -0.5392
2024-11-28 19:47:10.159350: Pseudo dice [0.6598]
2024-11-28 19:47:10.160320: Epoch time: 99.72 s
2024-11-28 19:47:11.475446: 
2024-11-28 19:47:11.476479: Epoch 36
2024-11-28 19:47:11.477272: Current learning rate: 0.00968
2024-11-28 19:48:50.282199: Validation loss did not improve from -0.60628. Patience: 6/50
2024-11-28 19:48:50.283395: train_loss -0.786
2024-11-28 19:48:50.284421: val_loss -0.5233
2024-11-28 19:48:50.285137: Pseudo dice [0.6413]
2024-11-28 19:48:50.285768: Epoch time: 98.81 s
2024-11-28 19:48:51.655639: 
2024-11-28 19:48:51.656905: Epoch 37
2024-11-28 19:48:51.657781: Current learning rate: 0.00967
2024-11-28 19:50:31.829331: Validation loss did not improve from -0.60628. Patience: 7/50
2024-11-28 19:50:31.855162: train_loss -0.7896
2024-11-28 19:50:31.858170: val_loss -0.5733
2024-11-28 19:50:31.859168: Pseudo dice [0.6828]
2024-11-28 19:50:31.860844: Epoch time: 100.2 s
2024-11-28 19:50:33.184330: 
2024-11-28 19:50:33.185405: Epoch 38
2024-11-28 19:50:33.186201: Current learning rate: 0.00966
2024-11-28 19:52:12.515929: Validation loss did not improve from -0.60628. Patience: 8/50
2024-11-28 19:52:12.517598: train_loss -0.7847
2024-11-28 19:52:12.519448: val_loss -0.5944
2024-11-28 19:52:12.520603: Pseudo dice [0.6943]
2024-11-28 19:52:12.521426: Epoch time: 99.33 s
2024-11-28 19:52:12.522418: Yayy! New best EMA pseudo Dice: 0.6635
2024-11-28 19:52:14.381559: 
2024-11-28 19:52:14.383413: Epoch 39
2024-11-28 19:52:14.384061: Current learning rate: 0.00965
2024-11-28 19:53:54.211090: Validation loss did not improve from -0.60628. Patience: 9/50
2024-11-28 19:53:54.214025: train_loss -0.7915
2024-11-28 19:53:54.215242: val_loss -0.5771
2024-11-28 19:53:54.215927: Pseudo dice [0.6874]
2024-11-28 19:53:54.216749: Epoch time: 99.83 s
2024-11-28 19:53:54.720201: Yayy! New best EMA pseudo Dice: 0.6659
2024-11-28 19:53:56.553578: 
2024-11-28 19:53:56.555249: Epoch 40
2024-11-28 19:53:56.555976: Current learning rate: 0.00964
2024-11-28 19:55:36.564505: Validation loss did not improve from -0.60628. Patience: 10/50
2024-11-28 19:55:36.565794: train_loss -0.7986
2024-11-28 19:55:36.567120: val_loss -0.5764
2024-11-28 19:55:36.567888: Pseudo dice [0.6862]
2024-11-28 19:55:36.568618: Epoch time: 100.01 s
2024-11-28 19:55:36.569245: Yayy! New best EMA pseudo Dice: 0.668
2024-11-28 19:55:39.040527: 
2024-11-28 19:55:39.042146: Epoch 41
2024-11-28 19:55:39.042877: Current learning rate: 0.00963
2024-11-28 19:57:18.450883: Validation loss did not improve from -0.60628. Patience: 11/50
2024-11-28 19:57:18.452018: train_loss -0.7974
2024-11-28 19:57:18.452932: val_loss -0.5491
2024-11-28 19:57:18.453623: Pseudo dice [0.6733]
2024-11-28 19:57:18.454450: Epoch time: 99.41 s
2024-11-28 19:57:18.455162: Yayy! New best EMA pseudo Dice: 0.6685
2024-11-28 19:57:20.239340: 
2024-11-28 19:57:20.240636: Epoch 42
2024-11-28 19:57:20.241443: Current learning rate: 0.00962
2024-11-28 19:59:00.308189: Validation loss did not improve from -0.60628. Patience: 12/50
2024-11-28 19:59:00.309106: train_loss -0.7927
2024-11-28 19:59:00.310285: val_loss -0.508
2024-11-28 19:59:00.310977: Pseudo dice [0.6353]
2024-11-28 19:59:00.312168: Epoch time: 100.07 s
2024-11-28 19:59:01.507109: 
2024-11-28 19:59:01.508957: Epoch 43
2024-11-28 19:59:01.509779: Current learning rate: 0.00961
2024-11-28 20:00:41.528359: Validation loss did not improve from -0.60628. Patience: 13/50
2024-11-28 20:00:41.529315: train_loss -0.7961
2024-11-28 20:00:41.530255: val_loss -0.5756
2024-11-28 20:00:41.531008: Pseudo dice [0.6901]
2024-11-28 20:00:41.531626: Epoch time: 100.02 s
2024-11-28 20:00:42.781894: 
2024-11-28 20:00:42.783183: Epoch 44
2024-11-28 20:00:42.783820: Current learning rate: 0.0096
2024-11-28 20:02:22.779072: Validation loss did not improve from -0.60628. Patience: 14/50
2024-11-28 20:02:22.780363: train_loss -0.799
2024-11-28 20:02:22.781488: val_loss -0.5882
2024-11-28 20:02:22.782592: Pseudo dice [0.6979]
2024-11-28 20:02:22.783284: Epoch time: 100.0 s
2024-11-28 20:02:23.349030: Yayy! New best EMA pseudo Dice: 0.6707
2024-11-28 20:02:25.148233: 
2024-11-28 20:02:25.150790: Epoch 45
2024-11-28 20:02:25.152461: Current learning rate: 0.00959
2024-11-28 20:04:05.145577: Validation loss did not improve from -0.60628. Patience: 15/50
2024-11-28 20:04:05.146806: train_loss -0.7977
2024-11-28 20:04:05.147588: val_loss -0.5486
2024-11-28 20:04:05.148360: Pseudo dice [0.6726]
2024-11-28 20:04:05.149004: Epoch time: 100.0 s
2024-11-28 20:04:05.149818: Yayy! New best EMA pseudo Dice: 0.6709
2024-11-28 20:04:06.945213: 
2024-11-28 20:04:06.946574: Epoch 46
2024-11-28 20:04:06.947580: Current learning rate: 0.00959
2024-11-28 20:05:46.397129: Validation loss improved from -0.60628 to -0.61028! Patience: 15/50
2024-11-28 20:05:46.398620: train_loss -0.8015
2024-11-28 20:05:46.399835: val_loss -0.6103
2024-11-28 20:05:46.400809: Pseudo dice [0.7129]
2024-11-28 20:05:46.402174: Epoch time: 99.45 s
2024-11-28 20:05:46.403003: Yayy! New best EMA pseudo Dice: 0.6751
2024-11-28 20:05:48.181224: 
2024-11-28 20:05:48.183005: Epoch 47
2024-11-28 20:05:48.183928: Current learning rate: 0.00958
2024-11-28 20:07:13.415312: Validation loss did not improve from -0.61028. Patience: 1/50
2024-11-28 20:07:13.416610: train_loss -0.7979
2024-11-28 20:07:13.417436: val_loss -0.6064
2024-11-28 20:07:13.418221: Pseudo dice [0.711]
2024-11-28 20:07:13.418970: Epoch time: 85.24 s
2024-11-28 20:07:13.419555: Yayy! New best EMA pseudo Dice: 0.6787
2024-11-28 20:07:15.197521: 
2024-11-28 20:07:15.199253: Epoch 48
2024-11-28 20:07:15.199969: Current learning rate: 0.00957
2024-11-28 20:08:12.807504: Validation loss did not improve from -0.61028. Patience: 2/50
2024-11-28 20:08:12.809699: train_loss -0.7982
2024-11-28 20:08:12.810639: val_loss -0.5827
2024-11-28 20:08:12.811711: Pseudo dice [0.6834]
2024-11-28 20:08:12.812780: Epoch time: 57.61 s
2024-11-28 20:08:12.813674: Yayy! New best EMA pseudo Dice: 0.6792
2024-11-28 20:08:14.485645: 
2024-11-28 20:08:14.487993: Epoch 49
2024-11-28 20:08:14.489170: Current learning rate: 0.00956
2024-11-28 20:09:02.263848: Validation loss did not improve from -0.61028. Patience: 3/50
2024-11-28 20:09:02.265030: train_loss -0.7948
2024-11-28 20:09:02.265729: val_loss -0.5396
2024-11-28 20:09:02.266524: Pseudo dice [0.6808]
2024-11-28 20:09:02.267401: Epoch time: 47.78 s
2024-11-28 20:09:02.796139: Yayy! New best EMA pseudo Dice: 0.6793
2024-11-28 20:09:04.495023: 
2024-11-28 20:09:04.496733: Epoch 50
2024-11-28 20:09:04.497887: Current learning rate: 0.00955
2024-11-28 20:09:52.202493: Validation loss did not improve from -0.61028. Patience: 4/50
2024-11-28 20:09:52.204221: train_loss -0.8021
2024-11-28 20:09:52.205249: val_loss -0.6003
2024-11-28 20:09:52.206260: Pseudo dice [0.7122]
2024-11-28 20:09:52.207062: Epoch time: 47.71 s
2024-11-28 20:09:52.208055: Yayy! New best EMA pseudo Dice: 0.6826
2024-11-28 20:09:53.914235: 
2024-11-28 20:09:53.915630: Epoch 51
2024-11-28 20:09:53.917161: Current learning rate: 0.00954
2024-11-28 20:10:41.638431: Validation loss did not improve from -0.61028. Patience: 5/50
2024-11-28 20:10:41.640290: train_loss -0.8035
2024-11-28 20:10:41.641419: val_loss -0.5756
2024-11-28 20:10:41.642406: Pseudo dice [0.6794]
2024-11-28 20:10:41.643805: Epoch time: 47.73 s
2024-11-28 20:10:43.198421: 
2024-11-28 20:10:43.200657: Epoch 52
2024-11-28 20:10:43.202084: Current learning rate: 0.00953
2024-11-28 20:11:30.939793: Validation loss did not improve from -0.61028. Patience: 6/50
2024-11-28 20:11:30.941641: train_loss -0.798
2024-11-28 20:11:30.942384: val_loss -0.6058
2024-11-28 20:11:30.943425: Pseudo dice [0.7056]
2024-11-28 20:11:30.944260: Epoch time: 47.74 s
2024-11-28 20:11:30.945009: Yayy! New best EMA pseudo Dice: 0.6846
2024-11-28 20:11:32.999105: 
2024-11-28 20:11:33.001649: Epoch 53
2024-11-28 20:11:33.002781: Current learning rate: 0.00952
2024-11-28 20:12:20.725818: Validation loss did not improve from -0.61028. Patience: 7/50
2024-11-28 20:12:20.727776: train_loss -0.8005
2024-11-28 20:12:20.728710: val_loss -0.5314
2024-11-28 20:12:20.729795: Pseudo dice [0.6698]
2024-11-28 20:12:20.730840: Epoch time: 47.73 s
2024-11-28 20:12:21.940971: 
2024-11-28 20:12:21.943027: Epoch 54
2024-11-28 20:12:21.944236: Current learning rate: 0.00951
2024-11-28 20:13:09.661663: Validation loss did not improve from -0.61028. Patience: 8/50
2024-11-28 20:13:09.663632: train_loss -0.8022
2024-11-28 20:13:09.664359: val_loss -0.5947
2024-11-28 20:13:09.665008: Pseudo dice [0.7065]
2024-11-28 20:13:09.665725: Epoch time: 47.72 s
2024-11-28 20:13:10.200757: Yayy! New best EMA pseudo Dice: 0.6855
2024-11-28 20:13:11.921643: 
2024-11-28 20:13:11.923921: Epoch 55
2024-11-28 20:13:11.925226: Current learning rate: 0.0095
2024-11-28 20:13:59.639311: Validation loss did not improve from -0.61028. Patience: 9/50
2024-11-28 20:13:59.641315: train_loss -0.7994
2024-11-28 20:13:59.642695: val_loss -0.5712
2024-11-28 20:13:59.643803: Pseudo dice [0.6799]
2024-11-28 20:13:59.645275: Epoch time: 47.72 s
2024-11-28 20:14:00.874613: 
2024-11-28 20:14:00.876571: Epoch 56
2024-11-28 20:14:00.877646: Current learning rate: 0.00949
2024-11-28 20:14:48.623790: Validation loss did not improve from -0.61028. Patience: 10/50
2024-11-28 20:14:48.625706: train_loss -0.8109
2024-11-28 20:14:48.626563: val_loss -0.5751
2024-11-28 20:14:48.627414: Pseudo dice [0.6905]
2024-11-28 20:14:48.628512: Epoch time: 47.75 s
2024-11-28 20:14:48.629351: Yayy! New best EMA pseudo Dice: 0.6855
2024-11-28 20:14:50.259370: 
2024-11-28 20:14:50.261817: Epoch 57
2024-11-28 20:14:50.262928: Current learning rate: 0.00949
2024-11-28 20:15:37.959575: Validation loss did not improve from -0.61028. Patience: 11/50
2024-11-28 20:15:37.961540: train_loss -0.8049
2024-11-28 20:15:37.962566: val_loss -0.5604
2024-11-28 20:15:37.963803: Pseudo dice [0.6701]
2024-11-28 20:15:37.964911: Epoch time: 47.7 s
2024-11-28 20:15:39.172453: 
2024-11-28 20:15:39.174912: Epoch 58
2024-11-28 20:15:39.176409: Current learning rate: 0.00948
2024-11-28 20:16:26.916224: Validation loss did not improve from -0.61028. Patience: 12/50
2024-11-28 20:16:26.918188: train_loss -0.8089
2024-11-28 20:16:26.919345: val_loss -0.5729
2024-11-28 20:16:26.920491: Pseudo dice [0.692]
2024-11-28 20:16:26.921701: Epoch time: 47.75 s
2024-11-28 20:16:28.151989: 
2024-11-28 20:16:28.154178: Epoch 59
2024-11-28 20:16:28.155430: Current learning rate: 0.00947
2024-11-28 20:17:15.965537: Validation loss did not improve from -0.61028. Patience: 13/50
2024-11-28 20:17:15.967396: train_loss -0.8103
2024-11-28 20:17:15.968397: val_loss -0.6025
2024-11-28 20:17:15.969826: Pseudo dice [0.7084]
2024-11-28 20:17:15.970950: Epoch time: 47.82 s
2024-11-28 20:17:16.511211: Yayy! New best EMA pseudo Dice: 0.6871
2024-11-28 20:17:18.203171: 
2024-11-28 20:17:18.205454: Epoch 60
2024-11-28 20:17:18.206593: Current learning rate: 0.00946
2024-11-28 20:18:05.929249: Validation loss did not improve from -0.61028. Patience: 14/50
2024-11-28 20:18:05.930593: train_loss -0.8102
2024-11-28 20:18:05.931494: val_loss -0.5945
2024-11-28 20:18:05.932359: Pseudo dice [0.6966]
2024-11-28 20:18:05.933274: Epoch time: 47.73 s
2024-11-28 20:18:05.934399: Yayy! New best EMA pseudo Dice: 0.6881
2024-11-28 20:18:07.775832: 
2024-11-28 20:18:07.778069: Epoch 61
2024-11-28 20:18:07.779366: Current learning rate: 0.00945
2024-11-28 20:18:55.444690: Validation loss did not improve from -0.61028. Patience: 15/50
2024-11-28 20:18:55.446402: train_loss -0.8114
2024-11-28 20:18:55.447158: val_loss -0.5818
2024-11-28 20:18:55.448097: Pseudo dice [0.692]
2024-11-28 20:18:55.449085: Epoch time: 47.67 s
2024-11-28 20:18:55.449939: Yayy! New best EMA pseudo Dice: 0.6884
2024-11-28 20:18:57.203393: 
2024-11-28 20:18:57.205631: Epoch 62
2024-11-28 20:18:57.207077: Current learning rate: 0.00944
2024-11-28 20:19:44.907874: Validation loss improved from -0.61028 to -0.61094! Patience: 15/50
2024-11-28 20:19:44.909430: train_loss -0.8115
2024-11-28 20:19:44.910170: val_loss -0.6109
2024-11-28 20:19:44.911041: Pseudo dice [0.704]
2024-11-28 20:19:44.912216: Epoch time: 47.71 s
2024-11-28 20:19:44.912967: Yayy! New best EMA pseudo Dice: 0.69
2024-11-28 20:19:46.624127: 
2024-11-28 20:19:46.626631: Epoch 63
2024-11-28 20:19:46.627692: Current learning rate: 0.00943
2024-11-28 20:20:34.328936: Validation loss did not improve from -0.61094. Patience: 1/50
2024-11-28 20:20:34.330575: train_loss -0.8087
2024-11-28 20:20:34.331486: val_loss -0.5948
2024-11-28 20:20:34.332252: Pseudo dice [0.6933]
2024-11-28 20:20:34.333337: Epoch time: 47.71 s
2024-11-28 20:20:34.334392: Yayy! New best EMA pseudo Dice: 0.6903
2024-11-28 20:20:36.468695: 
2024-11-28 20:20:36.470978: Epoch 64
2024-11-28 20:20:36.471695: Current learning rate: 0.00942
2024-11-28 20:21:24.175236: Validation loss did not improve from -0.61094. Patience: 2/50
2024-11-28 20:21:24.177049: train_loss -0.8071
2024-11-28 20:21:24.178498: val_loss -0.5916
2024-11-28 20:21:24.179887: Pseudo dice [0.6951]
2024-11-28 20:21:24.181214: Epoch time: 47.71 s
2024-11-28 20:21:24.714436: Yayy! New best EMA pseudo Dice: 0.6908
2024-11-28 20:21:26.510987: 
2024-11-28 20:21:26.513364: Epoch 65
2024-11-28 20:21:26.514712: Current learning rate: 0.00941
2024-11-28 20:22:14.195822: Validation loss did not improve from -0.61094. Patience: 3/50
2024-11-28 20:22:14.197867: train_loss -0.8133
2024-11-28 20:22:14.198817: val_loss -0.5645
2024-11-28 20:22:14.199825: Pseudo dice [0.6782]
2024-11-28 20:22:14.201056: Epoch time: 47.69 s
2024-11-28 20:22:15.412871: 
2024-11-28 20:22:15.414988: Epoch 66
2024-11-28 20:22:15.415978: Current learning rate: 0.0094
2024-11-28 20:23:03.118476: Validation loss did not improve from -0.61094. Patience: 4/50
2024-11-28 20:23:03.119921: train_loss -0.8113
2024-11-28 20:23:03.120925: val_loss -0.5863
2024-11-28 20:23:03.121873: Pseudo dice [0.6986]
2024-11-28 20:23:03.122922: Epoch time: 47.71 s
2024-11-28 20:23:04.345078: 
2024-11-28 20:23:04.347050: Epoch 67
2024-11-28 20:23:04.347835: Current learning rate: 0.00939
2024-11-28 20:23:52.039313: Validation loss did not improve from -0.61094. Patience: 5/50
2024-11-28 20:23:52.041898: train_loss -0.813
2024-11-28 20:23:52.043149: val_loss -0.5998
2024-11-28 20:23:52.044630: Pseudo dice [0.7097]
2024-11-28 20:23:52.045684: Epoch time: 47.7 s
2024-11-28 20:23:52.046720: Yayy! New best EMA pseudo Dice: 0.6924
2024-11-28 20:23:53.801209: 
2024-11-28 20:23:53.802999: Epoch 68
2024-11-28 20:23:53.804011: Current learning rate: 0.00939
2024-11-28 20:24:41.579618: Validation loss did not improve from -0.61094. Patience: 6/50
2024-11-28 20:24:41.581816: train_loss -0.819
2024-11-28 20:24:41.582758: val_loss -0.5637
2024-11-28 20:24:41.583621: Pseudo dice [0.6845]
2024-11-28 20:24:41.584486: Epoch time: 47.78 s
2024-11-28 20:24:42.820524: 
2024-11-28 20:24:42.822381: Epoch 69
2024-11-28 20:24:42.823309: Current learning rate: 0.00938
2024-11-28 20:25:30.611716: Validation loss did not improve from -0.61094. Patience: 7/50
2024-11-28 20:25:30.613054: train_loss -0.8249
2024-11-28 20:25:30.614021: val_loss -0.6033
2024-11-28 20:25:30.614727: Pseudo dice [0.7076]
2024-11-28 20:25:30.615867: Epoch time: 47.79 s
2024-11-28 20:25:31.167871: Yayy! New best EMA pseudo Dice: 0.6932
2024-11-28 20:25:32.868180: 
2024-11-28 20:25:32.870499: Epoch 70
2024-11-28 20:25:32.871891: Current learning rate: 0.00937
2024-11-28 20:26:20.635546: Validation loss did not improve from -0.61094. Patience: 8/50
2024-11-28 20:26:20.638089: train_loss -0.8206
2024-11-28 20:26:20.639055: val_loss -0.5676
2024-11-28 20:26:20.640016: Pseudo dice [0.6874]
2024-11-28 20:26:20.640851: Epoch time: 47.77 s
2024-11-28 20:26:21.877149: 
2024-11-28 20:26:21.879507: Epoch 71
2024-11-28 20:26:21.880737: Current learning rate: 0.00936
2024-11-28 20:27:09.604676: Validation loss did not improve from -0.61094. Patience: 9/50
2024-11-28 20:27:09.606435: train_loss -0.8191
2024-11-28 20:27:09.607384: val_loss -0.5331
2024-11-28 20:27:09.608745: Pseudo dice [0.6656]
2024-11-28 20:27:09.609598: Epoch time: 47.73 s
2024-11-28 20:27:10.861704: 
2024-11-28 20:27:10.863469: Epoch 72
2024-11-28 20:27:10.865061: Current learning rate: 0.00935
2024-11-28 20:27:58.607727: Validation loss did not improve from -0.61094. Patience: 10/50
2024-11-28 20:27:58.609526: train_loss -0.8222
2024-11-28 20:27:58.610348: val_loss -0.5822
2024-11-28 20:27:58.610941: Pseudo dice [0.6882]
2024-11-28 20:27:58.611681: Epoch time: 47.75 s
2024-11-28 20:27:59.871294: 
2024-11-28 20:27:59.873434: Epoch 73
2024-11-28 20:27:59.874552: Current learning rate: 0.00934
2024-11-28 20:28:47.616425: Validation loss did not improve from -0.61094. Patience: 11/50
2024-11-28 20:28:47.618568: train_loss -0.8172
2024-11-28 20:28:47.619761: val_loss -0.5726
2024-11-28 20:28:47.620381: Pseudo dice [0.6825]
2024-11-28 20:28:47.621172: Epoch time: 47.75 s
2024-11-28 20:28:48.850227: 
2024-11-28 20:28:48.852626: Epoch 74
2024-11-28 20:28:48.853623: Current learning rate: 0.00933
2024-11-28 20:29:36.645511: Validation loss did not improve from -0.61094. Patience: 12/50
2024-11-28 20:29:36.646770: train_loss -0.823
2024-11-28 20:29:36.647952: val_loss -0.6061
2024-11-28 20:29:36.648629: Pseudo dice [0.7127]
2024-11-28 20:29:36.649393: Epoch time: 47.8 s
2024-11-28 20:29:38.759669: 
2024-11-28 20:29:38.761470: Epoch 75
2024-11-28 20:29:38.762371: Current learning rate: 0.00932
2024-11-28 20:30:26.435451: Validation loss did not improve from -0.61094. Patience: 13/50
2024-11-28 20:30:26.437662: train_loss -0.8174
2024-11-28 20:30:26.439179: val_loss -0.573
2024-11-28 20:30:26.440197: Pseudo dice [0.6852]
2024-11-28 20:30:26.441324: Epoch time: 47.68 s
2024-11-28 20:30:27.706766: 
2024-11-28 20:30:27.709448: Epoch 76
2024-11-28 20:30:27.710372: Current learning rate: 0.00931
2024-11-28 20:31:15.399988: Validation loss did not improve from -0.61094. Patience: 14/50
2024-11-28 20:31:15.402842: train_loss -0.8187
2024-11-28 20:31:15.403796: val_loss -0.551
2024-11-28 20:31:15.404909: Pseudo dice [0.6764]
2024-11-28 20:31:15.405688: Epoch time: 47.7 s
2024-11-28 20:31:16.560488: 
2024-11-28 20:31:16.562884: Epoch 77
2024-11-28 20:31:16.563881: Current learning rate: 0.0093
2024-11-28 20:32:04.243567: Validation loss did not improve from -0.61094. Patience: 15/50
2024-11-28 20:32:04.245632: train_loss -0.8224
2024-11-28 20:32:04.246964: val_loss -0.5566
2024-11-28 20:32:04.248152: Pseudo dice [0.6734]
2024-11-28 20:32:04.249531: Epoch time: 47.69 s
2024-11-28 20:32:05.504650: 
2024-11-28 20:32:05.506534: Epoch 78
2024-11-28 20:32:05.507413: Current learning rate: 0.0093
2024-11-28 20:32:53.196043: Validation loss did not improve from -0.61094. Patience: 16/50
2024-11-28 20:32:53.197757: train_loss -0.8222
2024-11-28 20:32:53.198798: val_loss -0.5662
2024-11-28 20:32:53.199567: Pseudo dice [0.6793]
2024-11-28 20:32:53.200363: Epoch time: 47.69 s
2024-11-28 20:32:54.474855: 
2024-11-28 20:32:54.477064: Epoch 79
2024-11-28 20:32:54.478073: Current learning rate: 0.00929
2024-11-28 20:33:42.183413: Validation loss did not improve from -0.61094. Patience: 17/50
2024-11-28 20:33:42.185378: train_loss -0.8228
2024-11-28 20:33:42.186628: val_loss -0.5719
2024-11-28 20:33:42.187701: Pseudo dice [0.68]
2024-11-28 20:33:42.188848: Epoch time: 47.71 s
2024-11-28 20:33:43.965182: 
2024-11-28 20:33:43.967047: Epoch 80
2024-11-28 20:33:43.968505: Current learning rate: 0.00928
2024-11-28 20:34:31.669002: Validation loss did not improve from -0.61094. Patience: 18/50
2024-11-28 20:34:31.670722: train_loss -0.8205
2024-11-28 20:34:31.671867: val_loss -0.5902
2024-11-28 20:34:31.672685: Pseudo dice [0.6861]
2024-11-28 20:34:31.673367: Epoch time: 47.71 s
2024-11-28 20:34:32.939761: 
2024-11-28 20:34:32.941772: Epoch 81
2024-11-28 20:34:32.942805: Current learning rate: 0.00927
2024-11-28 20:35:20.656932: Validation loss did not improve from -0.61094. Patience: 19/50
2024-11-28 20:35:20.659387: train_loss -0.823
2024-11-28 20:35:20.660017: val_loss -0.6054
2024-11-28 20:35:20.660617: Pseudo dice [0.7122]
2024-11-28 20:35:20.661499: Epoch time: 47.72 s
2024-11-28 20:35:21.925447: 
2024-11-28 20:35:21.927320: Epoch 82
2024-11-28 20:35:21.928303: Current learning rate: 0.00926
2024-11-28 20:36:09.627598: Validation loss did not improve from -0.61094. Patience: 20/50
2024-11-28 20:36:09.629036: train_loss -0.8319
2024-11-28 20:36:09.630032: val_loss -0.5784
2024-11-28 20:36:09.631100: Pseudo dice [0.6881]
2024-11-28 20:36:09.632208: Epoch time: 47.71 s
2024-11-28 20:36:10.825488: 
2024-11-28 20:36:10.827464: Epoch 83
2024-11-28 20:36:10.828910: Current learning rate: 0.00925
2024-11-28 20:36:58.519025: Validation loss did not improve from -0.61094. Patience: 21/50
2024-11-28 20:36:58.521104: train_loss -0.826
2024-11-28 20:36:58.522160: val_loss -0.5964
2024-11-28 20:36:58.523230: Pseudo dice [0.6988]
2024-11-28 20:36:58.524343: Epoch time: 47.7 s
2024-11-28 20:36:59.714311: 
2024-11-28 20:36:59.716153: Epoch 84
2024-11-28 20:36:59.717115: Current learning rate: 0.00924
2024-11-28 20:37:47.412290: Validation loss did not improve from -0.61094. Patience: 22/50
2024-11-28 20:37:47.413391: train_loss -0.8249
2024-11-28 20:37:47.414217: val_loss -0.5723
2024-11-28 20:37:47.415035: Pseudo dice [0.6847]
2024-11-28 20:37:47.415875: Epoch time: 47.7 s
2024-11-28 20:37:49.179409: 
2024-11-28 20:37:49.181383: Epoch 85
2024-11-28 20:37:49.182553: Current learning rate: 0.00923
2024-11-28 20:38:37.160043: Validation loss did not improve from -0.61094. Patience: 23/50
2024-11-28 20:38:37.161897: train_loss -0.8263
2024-11-28 20:38:37.162856: val_loss -0.5899
2024-11-28 20:38:37.163768: Pseudo dice [0.7128]
2024-11-28 20:38:37.164794: Epoch time: 47.98 s
2024-11-28 20:38:38.350392: 
2024-11-28 20:38:38.352386: Epoch 86
2024-11-28 20:38:38.353055: Current learning rate: 0.00922
2024-11-28 20:39:26.043136: Validation loss did not improve from -0.61094. Patience: 24/50
2024-11-28 20:39:26.045265: train_loss -0.826
2024-11-28 20:39:26.046190: val_loss -0.5921
2024-11-28 20:39:26.046977: Pseudo dice [0.7024]
2024-11-28 20:39:26.047856: Epoch time: 47.7 s
2024-11-28 20:39:27.267850: 
2024-11-28 20:39:27.270919: Epoch 87
2024-11-28 20:39:27.272382: Current learning rate: 0.00921
2024-11-28 20:40:14.968441: Validation loss did not improve from -0.61094. Patience: 25/50
2024-11-28 20:40:14.970270: train_loss -0.827
2024-11-28 20:40:14.971181: val_loss -0.5617
2024-11-28 20:40:14.972222: Pseudo dice [0.6781]
2024-11-28 20:40:14.973518: Epoch time: 47.7 s
2024-11-28 20:40:16.171856: 
2024-11-28 20:40:16.174241: Epoch 88
2024-11-28 20:40:16.175168: Current learning rate: 0.0092
2024-11-28 20:41:03.868966: Validation loss did not improve from -0.61094. Patience: 26/50
2024-11-28 20:41:03.870571: train_loss -0.8333
2024-11-28 20:41:03.871901: val_loss -0.5897
2024-11-28 20:41:03.872740: Pseudo dice [0.7012]
2024-11-28 20:41:03.873489: Epoch time: 47.7 s
2024-11-28 20:41:05.073863: 
2024-11-28 20:41:05.075726: Epoch 89
2024-11-28 20:41:05.077081: Current learning rate: 0.0092
2024-11-28 20:41:52.757266: Validation loss did not improve from -0.61094. Patience: 27/50
2024-11-28 20:41:52.758763: train_loss -0.8268
2024-11-28 20:41:52.759378: val_loss -0.5985
2024-11-28 20:41:52.760065: Pseudo dice [0.7114]
2024-11-28 20:41:52.760721: Epoch time: 47.69 s
2024-11-28 20:41:53.301129: Yayy! New best EMA pseudo Dice: 0.6941
2024-11-28 20:41:55.026332: 
2024-11-28 20:41:55.028954: Epoch 90
2024-11-28 20:41:55.029669: Current learning rate: 0.00919
2024-11-28 20:42:42.676906: Validation loss improved from -0.61094 to -0.61138! Patience: 27/50
2024-11-28 20:42:42.678787: train_loss -0.8338
2024-11-28 20:42:42.680320: val_loss -0.6114
2024-11-28 20:42:42.681675: Pseudo dice [0.71]
2024-11-28 20:42:42.682764: Epoch time: 47.65 s
2024-11-28 20:42:42.683624: Yayy! New best EMA pseudo Dice: 0.6957
2024-11-28 20:42:44.368173: 
2024-11-28 20:42:44.370613: Epoch 91
2024-11-28 20:42:44.371546: Current learning rate: 0.00918
2024-11-28 20:43:32.006704: Validation loss did not improve from -0.61138. Patience: 1/50
2024-11-28 20:43:32.008624: train_loss -0.8248
2024-11-28 20:43:32.009894: val_loss -0.5684
2024-11-28 20:43:32.011348: Pseudo dice [0.6827]
2024-11-28 20:43:32.012550: Epoch time: 47.64 s
2024-11-28 20:43:33.173638: 
2024-11-28 20:43:33.175379: Epoch 92
2024-11-28 20:43:33.176658: Current learning rate: 0.00917
2024-11-28 20:44:20.864984: Validation loss improved from -0.61138 to -0.61665! Patience: 1/50
2024-11-28 20:44:20.866417: train_loss -0.8319
2024-11-28 20:44:20.867369: val_loss -0.6167
2024-11-28 20:44:20.868227: Pseudo dice [0.7141]
2024-11-28 20:44:20.869035: Epoch time: 47.69 s
2024-11-28 20:44:20.869782: Yayy! New best EMA pseudo Dice: 0.6964
2024-11-28 20:44:22.543878: 
2024-11-28 20:44:22.546133: Epoch 93
2024-11-28 20:44:22.547483: Current learning rate: 0.00916
2024-11-28 20:45:10.270821: Validation loss did not improve from -0.61665. Patience: 1/50
2024-11-28 20:45:10.272869: train_loss -0.8266
2024-11-28 20:45:10.273757: val_loss -0.5971
2024-11-28 20:45:10.274562: Pseudo dice [0.6938]
2024-11-28 20:45:10.275311: Epoch time: 47.73 s
2024-11-28 20:45:11.436951: 
2024-11-28 20:45:11.439133: Epoch 94
2024-11-28 20:45:11.440070: Current learning rate: 0.00915
2024-11-28 20:45:59.199534: Validation loss did not improve from -0.61665. Patience: 2/50
2024-11-28 20:45:59.202597: train_loss -0.8333
2024-11-28 20:45:59.204523: val_loss -0.5838
2024-11-28 20:45:59.205656: Pseudo dice [0.6963]
2024-11-28 20:45:59.206775: Epoch time: 47.77 s
2024-11-28 20:46:00.885000: 
2024-11-28 20:46:00.887840: Epoch 95
2024-11-28 20:46:00.889183: Current learning rate: 0.00914
2024-11-28 20:46:48.601658: Validation loss did not improve from -0.61665. Patience: 3/50
2024-11-28 20:46:48.603981: train_loss -0.8332
2024-11-28 20:46:48.605139: val_loss -0.5352
2024-11-28 20:46:48.605866: Pseudo dice [0.6633]
2024-11-28 20:46:48.606531: Epoch time: 47.72 s
2024-11-28 20:46:49.773292: 
2024-11-28 20:46:49.775663: Epoch 96
2024-11-28 20:46:49.776705: Current learning rate: 0.00913
2024-11-28 20:47:37.516597: Validation loss did not improve from -0.61665. Patience: 4/50
2024-11-28 20:47:37.518569: train_loss -0.8296
2024-11-28 20:47:37.519215: val_loss -0.5935
2024-11-28 20:47:37.520197: Pseudo dice [0.7049]
2024-11-28 20:47:37.521149: Epoch time: 47.75 s
2024-11-28 20:47:39.054820: 
2024-11-28 20:47:39.056779: Epoch 97
2024-11-28 20:47:39.057549: Current learning rate: 0.00912
2024-11-28 20:48:26.792316: Validation loss did not improve from -0.61665. Patience: 5/50
2024-11-28 20:48:26.793440: train_loss -0.8333
2024-11-28 20:48:26.794340: val_loss -0.5572
2024-11-28 20:48:26.795210: Pseudo dice [0.676]
2024-11-28 20:48:26.796048: Epoch time: 47.74 s
2024-11-28 20:48:27.970878: 
2024-11-28 20:48:27.973304: Epoch 98
2024-11-28 20:48:27.974278: Current learning rate: 0.00911
2024-11-28 20:49:15.684510: Validation loss did not improve from -0.61665. Patience: 6/50
2024-11-28 20:49:15.686508: train_loss -0.8303
2024-11-28 20:49:15.687736: val_loss -0.5602
2024-11-28 20:49:15.688665: Pseudo dice [0.671]
2024-11-28 20:49:15.689675: Epoch time: 47.72 s
2024-11-28 20:49:16.893831: 
2024-11-28 20:49:16.895910: Epoch 99
2024-11-28 20:49:16.897098: Current learning rate: 0.0091
2024-11-28 20:50:04.664358: Validation loss did not improve from -0.61665. Patience: 7/50
2024-11-28 20:50:04.666221: train_loss -0.828
2024-11-28 20:50:04.667154: val_loss -0.5937
2024-11-28 20:50:04.668393: Pseudo dice [0.6996]
2024-11-28 20:50:04.669579: Epoch time: 47.77 s
2024-11-28 20:50:06.376636: 
2024-11-28 20:50:06.379481: Epoch 100
2024-11-28 20:50:06.381097: Current learning rate: 0.0091
2024-11-28 20:50:54.111753: Validation loss improved from -0.61665 to -0.62353! Patience: 7/50
2024-11-28 20:50:54.113655: train_loss -0.8318
2024-11-28 20:50:54.114488: val_loss -0.6235
2024-11-28 20:50:54.115361: Pseudo dice [0.7261]
2024-11-28 20:50:54.116155: Epoch time: 47.74 s
2024-11-28 20:50:55.309162: 
2024-11-28 20:50:55.311259: Epoch 101
2024-11-28 20:50:55.312222: Current learning rate: 0.00909
2024-11-28 20:51:43.074792: Validation loss did not improve from -0.62353. Patience: 1/50
2024-11-28 20:51:43.076163: train_loss -0.8325
2024-11-28 20:51:43.076957: val_loss -0.5948
2024-11-28 20:51:43.077688: Pseudo dice [0.7051]
2024-11-28 20:51:43.078308: Epoch time: 47.77 s
2024-11-28 20:51:44.268144: 
2024-11-28 20:51:44.270276: Epoch 102
2024-11-28 20:51:44.271226: Current learning rate: 0.00908
2024-11-28 20:52:32.028160: Validation loss did not improve from -0.62353. Patience: 2/50
2024-11-28 20:52:32.029930: train_loss -0.8412
2024-11-28 20:52:32.030706: val_loss -0.5903
2024-11-28 20:52:32.031444: Pseudo dice [0.6985]
2024-11-28 20:52:32.032065: Epoch time: 47.76 s
2024-11-28 20:52:33.242180: 
2024-11-28 20:52:33.243943: Epoch 103
2024-11-28 20:52:33.244803: Current learning rate: 0.00907
2024-11-28 20:53:20.971948: Validation loss did not improve from -0.62353. Patience: 3/50
2024-11-28 20:53:20.973349: train_loss -0.836
2024-11-28 20:53:20.974066: val_loss -0.5379
2024-11-28 20:53:20.975091: Pseudo dice [0.6626]
2024-11-28 20:53:20.976230: Epoch time: 47.73 s
2024-11-28 20:53:22.168056: 
2024-11-28 20:53:22.169824: Epoch 104
2024-11-28 20:53:22.170743: Current learning rate: 0.00906
2024-11-28 20:54:09.903252: Validation loss did not improve from -0.62353. Patience: 4/50
2024-11-28 20:54:09.905360: train_loss -0.8384
2024-11-28 20:54:09.906361: val_loss -0.5876
2024-11-28 20:54:09.907174: Pseudo dice [0.7005]
2024-11-28 20:54:09.908377: Epoch time: 47.74 s
2024-11-28 20:54:11.640257: 
2024-11-28 20:54:11.641861: Epoch 105
2024-11-28 20:54:11.642821: Current learning rate: 0.00905
2024-11-28 20:54:59.325035: Validation loss did not improve from -0.62353. Patience: 5/50
2024-11-28 20:54:59.327163: train_loss -0.832
2024-11-28 20:54:59.328858: val_loss -0.5519
2024-11-28 20:54:59.329882: Pseudo dice [0.6799]
2024-11-28 20:54:59.331132: Epoch time: 47.69 s
2024-11-28 20:55:00.533183: 
2024-11-28 20:55:00.535355: Epoch 106
2024-11-28 20:55:00.536532: Current learning rate: 0.00904
2024-11-28 20:55:48.243482: Validation loss did not improve from -0.62353. Patience: 6/50
2024-11-28 20:55:48.245442: train_loss -0.8347
2024-11-28 20:55:48.246229: val_loss -0.5583
2024-11-28 20:55:48.247075: Pseudo dice [0.674]
2024-11-28 20:55:48.247880: Epoch time: 47.71 s
2024-11-28 20:55:49.483688: 
2024-11-28 20:55:49.485590: Epoch 107
2024-11-28 20:55:49.486290: Current learning rate: 0.00903
2024-11-28 20:56:37.167867: Validation loss did not improve from -0.62353. Patience: 7/50
2024-11-28 20:56:37.169898: train_loss -0.8352
2024-11-28 20:56:37.171300: val_loss -0.567
2024-11-28 20:56:37.172218: Pseudo dice [0.6943]
2024-11-28 20:56:37.173484: Epoch time: 47.69 s
2024-11-28 20:56:38.363319: 
2024-11-28 20:56:38.366149: Epoch 108
2024-11-28 20:56:38.367621: Current learning rate: 0.00902
2024-11-28 20:57:26.076131: Validation loss did not improve from -0.62353. Patience: 8/50
2024-11-28 20:57:26.077795: train_loss -0.8382
2024-11-28 20:57:26.078892: val_loss -0.573
2024-11-28 20:57:26.080078: Pseudo dice [0.6905]
2024-11-28 20:57:26.081259: Epoch time: 47.72 s
2024-11-28 20:57:27.664166: 
2024-11-28 20:57:27.666258: Epoch 109
2024-11-28 20:57:27.667171: Current learning rate: 0.00901
2024-11-28 20:58:15.555261: Validation loss did not improve from -0.62353. Patience: 9/50
2024-11-28 20:58:15.557673: train_loss -0.834
2024-11-28 20:58:15.559163: val_loss -0.615
2024-11-28 20:58:15.560506: Pseudo dice [0.723]
2024-11-28 20:58:15.561601: Epoch time: 47.89 s
2024-11-28 20:58:17.301953: 
2024-11-28 20:58:17.303963: Epoch 110
2024-11-28 20:58:17.305205: Current learning rate: 0.009
2024-11-28 20:59:05.030938: Validation loss did not improve from -0.62353. Patience: 10/50
2024-11-28 20:59:05.032901: train_loss -0.8333
2024-11-28 20:59:05.033976: val_loss -0.5813
2024-11-28 20:59:05.035285: Pseudo dice [0.688]
2024-11-28 20:59:05.036406: Epoch time: 47.73 s
2024-11-28 20:59:06.233509: 
2024-11-28 20:59:06.235522: Epoch 111
2024-11-28 20:59:06.236710: Current learning rate: 0.009
2024-11-28 20:59:53.937084: Validation loss did not improve from -0.62353. Patience: 11/50
2024-11-28 20:59:53.938446: train_loss -0.8384
2024-11-28 20:59:53.939137: val_loss -0.6052
2024-11-28 20:59:53.940588: Pseudo dice [0.7113]
2024-11-28 20:59:53.941522: Epoch time: 47.71 s
2024-11-28 20:59:55.137401: 
2024-11-28 20:59:55.139596: Epoch 112
2024-11-28 20:59:55.140727: Current learning rate: 0.00899
2024-11-28 21:00:42.854837: Validation loss did not improve from -0.62353. Patience: 12/50
2024-11-28 21:00:42.856307: train_loss -0.8429
2024-11-28 21:00:42.857457: val_loss -0.6173
2024-11-28 21:00:42.858650: Pseudo dice [0.7223]
2024-11-28 21:00:42.860006: Epoch time: 47.72 s
2024-11-28 21:00:42.861287: Yayy! New best EMA pseudo Dice: 0.6978
2024-11-28 21:00:44.608701: 
2024-11-28 21:00:44.611276: Epoch 113
2024-11-28 21:00:44.612648: Current learning rate: 0.00898
2024-11-28 21:01:32.313058: Validation loss did not improve from -0.62353. Patience: 13/50
2024-11-28 21:01:32.314627: train_loss -0.842
2024-11-28 21:01:32.315587: val_loss -0.5903
2024-11-28 21:01:32.316474: Pseudo dice [0.7051]
2024-11-28 21:01:32.317212: Epoch time: 47.71 s
2024-11-28 21:01:32.317911: Yayy! New best EMA pseudo Dice: 0.6985
2024-11-28 21:01:34.042764: 
2024-11-28 21:01:34.045058: Epoch 114
2024-11-28 21:01:34.045995: Current learning rate: 0.00897
2024-11-28 21:02:21.776045: Validation loss did not improve from -0.62353. Patience: 14/50
2024-11-28 21:02:21.778100: train_loss -0.8413
2024-11-28 21:02:21.778806: val_loss -0.5604
2024-11-28 21:02:21.779966: Pseudo dice [0.6765]
2024-11-28 21:02:21.780852: Epoch time: 47.74 s
2024-11-28 21:02:23.508030: 
2024-11-28 21:02:23.510421: Epoch 115
2024-11-28 21:02:23.511447: Current learning rate: 0.00896
2024-11-28 21:03:11.255077: Validation loss did not improve from -0.62353. Patience: 15/50
2024-11-28 21:03:11.256416: train_loss -0.8379
2024-11-28 21:03:11.257184: val_loss -0.5473
2024-11-28 21:03:11.258197: Pseudo dice [0.6652]
2024-11-28 21:03:11.259388: Epoch time: 47.75 s
2024-11-28 21:03:12.462199: 
2024-11-28 21:03:12.464359: Epoch 116
2024-11-28 21:03:12.465452: Current learning rate: 0.00895
2024-11-28 21:04:00.215136: Validation loss did not improve from -0.62353. Patience: 16/50
2024-11-28 21:04:00.216902: train_loss -0.8416
2024-11-28 21:04:00.218345: val_loss -0.5916
2024-11-28 21:04:00.219632: Pseudo dice [0.687]
2024-11-28 21:04:00.220640: Epoch time: 47.76 s
2024-11-28 21:04:01.455575: 
2024-11-28 21:04:01.457631: Epoch 117
2024-11-28 21:04:01.458601: Current learning rate: 0.00894
2024-11-28 21:04:49.201122: Validation loss did not improve from -0.62353. Patience: 17/50
2024-11-28 21:04:49.203663: train_loss -0.8447
2024-11-28 21:04:49.205352: val_loss -0.5771
2024-11-28 21:04:49.206336: Pseudo dice [0.6951]
2024-11-28 21:04:49.207376: Epoch time: 47.75 s
2024-11-28 21:04:50.373264: 
2024-11-28 21:04:50.376363: Epoch 118
2024-11-28 21:04:50.378023: Current learning rate: 0.00893
2024-11-28 21:05:38.146789: Validation loss did not improve from -0.62353. Patience: 18/50
2024-11-28 21:05:38.148795: train_loss -0.8437
2024-11-28 21:05:38.149683: val_loss -0.5904
2024-11-28 21:05:38.150594: Pseudo dice [0.7068]
2024-11-28 21:05:38.151709: Epoch time: 47.78 s
2024-11-28 21:05:39.382663: 
2024-11-28 21:05:39.384580: Epoch 119
2024-11-28 21:05:39.385756: Current learning rate: 0.00892
2024-11-28 21:06:27.139205: Validation loss did not improve from -0.62353. Patience: 19/50
2024-11-28 21:06:27.140818: train_loss -0.8444
2024-11-28 21:06:27.141877: val_loss -0.5885
2024-11-28 21:06:27.143004: Pseudo dice [0.7016]
2024-11-28 21:06:27.144283: Epoch time: 47.76 s
2024-11-28 21:06:28.946767: 
2024-11-28 21:06:28.949142: Epoch 120
2024-11-28 21:06:28.950471: Current learning rate: 0.00891
2024-11-28 21:07:16.675822: Validation loss improved from -0.62353 to -0.62412! Patience: 19/50
2024-11-28 21:07:16.678767: train_loss -0.8406
2024-11-28 21:07:16.679806: val_loss -0.6241
2024-11-28 21:07:16.680751: Pseudo dice [0.7239]
2024-11-28 21:07:16.681767: Epoch time: 47.73 s
2024-11-28 21:07:18.255567: 
2024-11-28 21:07:18.258388: Epoch 121
2024-11-28 21:07:18.259324: Current learning rate: 0.0089
2024-11-28 21:08:05.994019: Validation loss did not improve from -0.62412. Patience: 1/50
2024-11-28 21:08:05.996141: train_loss -0.8449
2024-11-28 21:08:05.997444: val_loss -0.5637
2024-11-28 21:08:05.998638: Pseudo dice [0.6915]
2024-11-28 21:08:05.999372: Epoch time: 47.74 s
2024-11-28 21:08:07.222193: 
2024-11-28 21:08:07.224812: Epoch 122
2024-11-28 21:08:07.225898: Current learning rate: 0.00889
2024-11-28 21:08:54.986230: Validation loss did not improve from -0.62412. Patience: 2/50
2024-11-28 21:08:54.987768: train_loss -0.8439
2024-11-28 21:08:54.988674: val_loss -0.5646
2024-11-28 21:08:54.989742: Pseudo dice [0.6855]
2024-11-28 21:08:54.990517: Epoch time: 47.77 s
2024-11-28 21:08:56.203070: 
2024-11-28 21:08:56.204720: Epoch 123
2024-11-28 21:08:56.205619: Current learning rate: 0.00889
2024-11-28 21:09:43.978923: Validation loss did not improve from -0.62412. Patience: 3/50
2024-11-28 21:09:43.981378: train_loss -0.8393
2024-11-28 21:09:43.982344: val_loss -0.5733
2024-11-28 21:09:43.983107: Pseudo dice [0.6785]
2024-11-28 21:09:43.983861: Epoch time: 47.78 s
2024-11-28 21:09:45.191113: 
2024-11-28 21:09:45.193221: Epoch 124
2024-11-28 21:09:45.194626: Current learning rate: 0.00888
2024-11-28 21:10:32.921042: Validation loss did not improve from -0.62412. Patience: 4/50
2024-11-28 21:10:32.922741: train_loss -0.8418
2024-11-28 21:10:32.924059: val_loss -0.5603
2024-11-28 21:10:32.925364: Pseudo dice [0.6735]
2024-11-28 21:10:32.926463: Epoch time: 47.73 s
2024-11-28 21:10:34.693597: 
2024-11-28 21:10:34.696572: Epoch 125
2024-11-28 21:10:34.698200: Current learning rate: 0.00887
2024-11-28 21:11:22.426418: Validation loss did not improve from -0.62412. Patience: 5/50
2024-11-28 21:11:22.428335: train_loss -0.8479
2024-11-28 21:11:22.429594: val_loss -0.544
2024-11-28 21:11:22.430267: Pseudo dice [0.6614]
2024-11-28 21:11:22.430945: Epoch time: 47.74 s
2024-11-28 21:11:23.639406: 
2024-11-28 21:11:23.642677: Epoch 126
2024-11-28 21:11:23.644162: Current learning rate: 0.00886
2024-11-28 21:12:11.883358: Validation loss did not improve from -0.62412. Patience: 6/50
2024-11-28 21:12:11.886838: train_loss -0.8383
2024-11-28 21:12:11.888249: val_loss -0.5485
2024-11-28 21:12:11.888915: Pseudo dice [0.6697]
2024-11-28 21:12:11.900113: Epoch time: 48.25 s
2024-11-28 21:12:13.516186: 
2024-11-28 21:12:13.518870: Epoch 127
2024-11-28 21:12:13.520169: Current learning rate: 0.00885
2024-11-28 21:13:02.684813: Validation loss did not improve from -0.62412. Patience: 7/50
2024-11-28 21:13:02.707941: train_loss -0.8487
2024-11-28 21:13:02.759650: val_loss -0.5979
2024-11-28 21:13:02.761907: Pseudo dice [0.7047]
2024-11-28 21:13:02.763924: Epoch time: 49.19 s
2024-11-28 21:13:04.167971: 
2024-11-28 21:13:04.169863: Epoch 128
2024-11-28 21:13:04.170653: Current learning rate: 0.00884
2024-11-28 21:13:52.130035: Validation loss did not improve from -0.62412. Patience: 8/50
2024-11-28 21:13:52.131829: train_loss -0.8462
2024-11-28 21:13:52.132764: val_loss -0.5369
2024-11-28 21:13:52.133488: Pseudo dice [0.6588]
2024-11-28 21:13:52.134156: Epoch time: 47.97 s
2024-11-28 21:13:53.350690: 
2024-11-28 21:13:53.353746: Epoch 129
2024-11-28 21:13:53.355666: Current learning rate: 0.00883
2024-11-28 21:14:41.059879: Validation loss did not improve from -0.62412. Patience: 9/50
2024-11-28 21:14:41.060890: train_loss -0.8439
2024-11-28 21:14:41.061642: val_loss -0.547
2024-11-28 21:14:41.062603: Pseudo dice [0.6792]
2024-11-28 21:14:41.063793: Epoch time: 47.71 s
2024-11-28 21:14:42.775496: 
2024-11-28 21:14:42.777655: Epoch 130
2024-11-28 21:14:42.778399: Current learning rate: 0.00882
2024-11-28 21:15:30.499083: Validation loss did not improve from -0.62412. Patience: 10/50
2024-11-28 21:15:30.501131: train_loss -0.8475
2024-11-28 21:15:30.502042: val_loss -0.5615
2024-11-28 21:15:30.502858: Pseudo dice [0.6686]
2024-11-28 21:15:30.503662: Epoch time: 47.73 s
2024-11-28 21:15:31.729717: 
2024-11-28 21:15:31.731404: Epoch 131
2024-11-28 21:15:31.732414: Current learning rate: 0.00881
2024-11-28 21:16:19.460346: Validation loss did not improve from -0.62412. Patience: 11/50
2024-11-28 21:16:19.462070: train_loss -0.8468
2024-11-28 21:16:19.462963: val_loss -0.5902
2024-11-28 21:16:19.464135: Pseudo dice [0.7058]
2024-11-28 21:16:19.464885: Epoch time: 47.73 s
2024-11-28 21:16:21.089065: 
2024-11-28 21:16:21.090747: Epoch 132
2024-11-28 21:16:21.091598: Current learning rate: 0.0088
2024-11-28 21:17:08.791478: Validation loss did not improve from -0.62412. Patience: 12/50
2024-11-28 21:17:08.793208: train_loss -0.8479
2024-11-28 21:17:08.793919: val_loss -0.584
2024-11-28 21:17:08.794567: Pseudo dice [0.6906]
2024-11-28 21:17:08.795246: Epoch time: 47.71 s
2024-11-28 21:17:10.022421: 
2024-11-28 21:17:10.024154: Epoch 133
2024-11-28 21:17:10.025016: Current learning rate: 0.00879
2024-11-28 21:17:57.738680: Validation loss did not improve from -0.62412. Patience: 13/50
2024-11-28 21:17:57.740914: train_loss -0.8482
2024-11-28 21:17:57.742018: val_loss -0.5819
2024-11-28 21:17:57.743364: Pseudo dice [0.6925]
2024-11-28 21:17:57.744411: Epoch time: 47.72 s
2024-11-28 21:17:58.965626: 
2024-11-28 21:17:58.967628: Epoch 134
2024-11-28 21:17:58.969115: Current learning rate: 0.00879
2024-11-28 21:18:46.750321: Validation loss did not improve from -0.62412. Patience: 14/50
2024-11-28 21:18:46.751900: train_loss -0.8423
2024-11-28 21:18:46.753388: val_loss -0.5442
2024-11-28 21:18:46.754601: Pseudo dice [0.6615]
2024-11-28 21:18:46.755655: Epoch time: 47.79 s
2024-11-28 21:18:48.576028: 
2024-11-28 21:18:48.578357: Epoch 135
2024-11-28 21:18:48.579791: Current learning rate: 0.00878
2024-11-28 21:19:36.319651: Validation loss did not improve from -0.62412. Patience: 15/50
2024-11-28 21:19:36.321541: train_loss -0.846
2024-11-28 21:19:36.322802: val_loss -0.5513
2024-11-28 21:19:36.324023: Pseudo dice [0.6756]
2024-11-28 21:19:36.325346: Epoch time: 47.75 s
2024-11-28 21:19:37.569195: 
2024-11-28 21:19:37.571343: Epoch 136
2024-11-28 21:19:37.572720: Current learning rate: 0.00877
2024-11-28 21:20:25.286238: Validation loss did not improve from -0.62412. Patience: 16/50
2024-11-28 21:20:25.287984: train_loss -0.8475
2024-11-28 21:20:25.289014: val_loss -0.5825
2024-11-28 21:20:25.290175: Pseudo dice [0.6926]
2024-11-28 21:20:25.291037: Epoch time: 47.72 s
2024-11-28 21:20:26.499069: 
2024-11-28 21:20:26.501226: Epoch 137
2024-11-28 21:20:26.502308: Current learning rate: 0.00876
2024-11-28 21:21:14.218536: Validation loss did not improve from -0.62412. Patience: 17/50
2024-11-28 21:21:14.220238: train_loss -0.8513
2024-11-28 21:21:14.220963: val_loss -0.5698
2024-11-28 21:21:14.221775: Pseudo dice [0.6875]
2024-11-28 21:21:14.222635: Epoch time: 47.72 s
2024-11-28 21:21:15.492158: 
2024-11-28 21:21:15.494673: Epoch 138
2024-11-28 21:21:15.495729: Current learning rate: 0.00875
2024-11-28 21:22:03.176539: Validation loss did not improve from -0.62412. Patience: 18/50
2024-11-28 21:22:03.178328: train_loss -0.8543
2024-11-28 21:22:03.179502: val_loss -0.5872
2024-11-28 21:22:03.180427: Pseudo dice [0.6944]
2024-11-28 21:22:03.181281: Epoch time: 47.69 s
2024-11-28 21:22:04.415290: 
2024-11-28 21:22:04.417341: Epoch 139
2024-11-28 21:22:04.418103: Current learning rate: 0.00874
2024-11-28 21:22:52.143785: Validation loss did not improve from -0.62412. Patience: 19/50
2024-11-28 21:22:52.145975: train_loss -0.8514
2024-11-28 21:22:52.147151: val_loss -0.5596
2024-11-28 21:22:52.148478: Pseudo dice [0.6788]
2024-11-28 21:22:52.149366: Epoch time: 47.73 s
2024-11-28 21:22:53.963684: 
2024-11-28 21:22:53.966007: Epoch 140
2024-11-28 21:22:53.967406: Current learning rate: 0.00873
2024-11-28 21:23:41.662414: Validation loss did not improve from -0.62412. Patience: 20/50
2024-11-28 21:23:41.664383: train_loss -0.8497
2024-11-28 21:23:41.665419: val_loss -0.5959
2024-11-28 21:23:41.666469: Pseudo dice [0.6996]
2024-11-28 21:23:41.667413: Epoch time: 47.7 s
2024-11-28 21:23:42.921364: 
2024-11-28 21:23:42.923283: Epoch 141
2024-11-28 21:23:42.924166: Current learning rate: 0.00872
2024-11-28 21:24:30.615931: Validation loss did not improve from -0.62412. Patience: 21/50
2024-11-28 21:24:30.617929: train_loss -0.847
2024-11-28 21:24:30.618616: val_loss -0.5512
2024-11-28 21:24:30.619367: Pseudo dice [0.6786]
2024-11-28 21:24:30.620240: Epoch time: 47.7 s
2024-11-28 21:24:31.853933: 
2024-11-28 21:24:31.855916: Epoch 142
2024-11-28 21:24:31.856952: Current learning rate: 0.00871
2024-11-28 21:25:19.527945: Validation loss did not improve from -0.62412. Patience: 22/50
2024-11-28 21:25:19.529709: train_loss -0.8506
2024-11-28 21:25:19.530546: val_loss -0.5826
2024-11-28 21:25:19.531290: Pseudo dice [0.6913]
2024-11-28 21:25:19.532139: Epoch time: 47.68 s
2024-11-28 21:25:21.141751: 
2024-11-28 21:25:21.143620: Epoch 143
2024-11-28 21:25:21.144328: Current learning rate: 0.0087
2024-11-28 21:26:08.821586: Validation loss did not improve from -0.62412. Patience: 23/50
2024-11-28 21:26:08.822954: train_loss -0.8503
2024-11-28 21:26:08.824447: val_loss -0.5106
2024-11-28 21:26:08.825512: Pseudo dice [0.6385]
2024-11-28 21:26:08.826631: Epoch time: 47.68 s
2024-11-28 21:26:10.058086: 
2024-11-28 21:26:10.060947: Epoch 144
2024-11-28 21:26:10.062499: Current learning rate: 0.00869
2024-11-28 21:26:57.763582: Validation loss did not improve from -0.62412. Patience: 24/50
2024-11-28 21:26:57.765398: train_loss -0.8502
2024-11-28 21:26:57.766092: val_loss -0.568
2024-11-28 21:26:57.766812: Pseudo dice [0.6851]
2024-11-28 21:26:57.767508: Epoch time: 47.71 s
2024-11-28 21:26:59.563924: 
2024-11-28 21:26:59.566001: Epoch 145
2024-11-28 21:26:59.567110: Current learning rate: 0.00868
2024-11-28 21:27:47.264297: Validation loss did not improve from -0.62412. Patience: 25/50
2024-11-28 21:27:47.266982: train_loss -0.8398
2024-11-28 21:27:47.268575: val_loss -0.5537
2024-11-28 21:27:47.269637: Pseudo dice [0.6723]
2024-11-28 21:27:47.270627: Epoch time: 47.7 s
2024-11-28 21:27:48.510899: 
2024-11-28 21:27:48.513273: Epoch 146
2024-11-28 21:27:48.514308: Current learning rate: 0.00868
2024-11-28 21:28:36.197276: Validation loss did not improve from -0.62412. Patience: 26/50
2024-11-28 21:28:36.199471: train_loss -0.8483
2024-11-28 21:28:36.200137: val_loss -0.5826
2024-11-28 21:28:36.200810: Pseudo dice [0.6972]
2024-11-28 21:28:36.201558: Epoch time: 47.69 s
2024-11-28 21:28:37.444648: 
2024-11-28 21:28:37.446354: Epoch 147
2024-11-28 21:28:37.447515: Current learning rate: 0.00867
2024-11-28 21:29:25.167473: Validation loss did not improve from -0.62412. Patience: 27/50
2024-11-28 21:29:25.169298: train_loss -0.849
2024-11-28 21:29:25.170297: val_loss -0.5733
2024-11-28 21:29:25.171164: Pseudo dice [0.6888]
2024-11-28 21:29:25.172110: Epoch time: 47.73 s
2024-11-28 21:29:26.439665: 
2024-11-28 21:29:26.441266: Epoch 148
2024-11-28 21:29:26.442157: Current learning rate: 0.00866
2024-11-28 21:30:14.131385: Validation loss did not improve from -0.62412. Patience: 28/50
2024-11-28 21:30:14.132835: train_loss -0.8521
2024-11-28 21:30:14.133864: val_loss -0.5613
2024-11-28 21:30:14.134749: Pseudo dice [0.6731]
2024-11-28 21:30:14.135955: Epoch time: 47.69 s
2024-11-28 21:30:15.407131: 
2024-11-28 21:30:15.409305: Epoch 149
2024-11-28 21:30:15.410396: Current learning rate: 0.00865
2024-11-28 21:31:03.121787: Validation loss did not improve from -0.62412. Patience: 29/50
2024-11-28 21:31:03.123437: train_loss -0.8429
2024-11-28 21:31:03.124783: val_loss -0.5439
2024-11-28 21:31:03.125838: Pseudo dice [0.6676]
2024-11-28 21:31:03.127075: Epoch time: 47.72 s
2024-11-28 21:31:04.918158: 
2024-11-28 21:31:04.920790: Epoch 150
2024-11-28 21:31:04.921942: Current learning rate: 0.00864
2024-11-28 21:31:52.569609: Validation loss did not improve from -0.62412. Patience: 30/50
2024-11-28 21:31:52.570878: train_loss -0.8488
2024-11-28 21:31:52.571725: val_loss -0.5697
2024-11-28 21:31:52.572650: Pseudo dice [0.6797]
2024-11-28 21:31:52.573304: Epoch time: 47.65 s
2024-11-28 21:31:53.815202: 
2024-11-28 21:31:53.817145: Epoch 151
2024-11-28 21:31:53.817997: Current learning rate: 0.00863
2024-11-28 21:32:41.483561: Validation loss did not improve from -0.62412. Patience: 31/50
2024-11-28 21:32:41.485630: train_loss -0.8414
2024-11-28 21:32:41.486838: val_loss -0.5474
2024-11-28 21:32:41.488075: Pseudo dice [0.6673]
2024-11-28 21:32:41.489414: Epoch time: 47.67 s
2024-11-28 21:32:42.741207: 
2024-11-28 21:32:42.744051: Epoch 152
2024-11-28 21:32:42.745492: Current learning rate: 0.00862
2024-11-28 21:33:30.428917: Validation loss did not improve from -0.62412. Patience: 32/50
2024-11-28 21:33:30.430943: train_loss -0.8433
2024-11-28 21:33:30.432600: val_loss -0.5962
2024-11-28 21:33:30.433872: Pseudo dice [0.7049]
2024-11-28 21:33:30.435201: Epoch time: 47.69 s
2024-11-28 21:33:31.689946: 
2024-11-28 21:33:31.692266: Epoch 153
2024-11-28 21:33:31.693405: Current learning rate: 0.00861
2024-11-28 21:34:19.378478: Validation loss did not improve from -0.62412. Patience: 33/50
2024-11-28 21:34:19.380737: train_loss -0.8464
2024-11-28 21:34:19.382249: val_loss -0.5907
2024-11-28 21:34:19.383373: Pseudo dice [0.6924]
2024-11-28 21:34:19.384024: Epoch time: 47.69 s
2024-11-28 21:34:21.023220: 
2024-11-28 21:34:21.025276: Epoch 154
2024-11-28 21:34:21.026459: Current learning rate: 0.0086
2024-11-28 21:35:08.702753: Validation loss did not improve from -0.62412. Patience: 34/50
2024-11-28 21:35:08.704327: train_loss -0.8499
2024-11-28 21:35:08.705146: val_loss -0.6051
2024-11-28 21:35:08.706095: Pseudo dice [0.7075]
2024-11-28 21:35:08.707202: Epoch time: 47.68 s
2024-11-28 21:35:10.493840: 
2024-11-28 21:35:10.495914: Epoch 155
2024-11-28 21:35:10.496816: Current learning rate: 0.00859
2024-11-28 21:35:58.180734: Validation loss did not improve from -0.62412. Patience: 35/50
2024-11-28 21:35:58.182527: train_loss -0.8478
2024-11-28 21:35:58.184485: val_loss -0.6099
2024-11-28 21:35:58.185587: Pseudo dice [0.7172]
2024-11-28 21:35:58.186377: Epoch time: 47.69 s
2024-11-28 21:35:59.459199: 
2024-11-28 21:35:59.461119: Epoch 156
2024-11-28 21:35:59.462191: Current learning rate: 0.00858
2024-11-28 21:36:47.158409: Validation loss did not improve from -0.62412. Patience: 36/50
2024-11-28 21:36:47.159646: train_loss -0.8507
2024-11-28 21:36:47.160586: val_loss -0.5876
2024-11-28 21:36:47.161598: Pseudo dice [0.6989]
2024-11-28 21:36:47.162447: Epoch time: 47.7 s
2024-11-28 21:36:48.438849: 
2024-11-28 21:36:48.441542: Epoch 157
2024-11-28 21:36:48.442942: Current learning rate: 0.00858
2024-11-28 21:37:36.143616: Validation loss did not improve from -0.62412. Patience: 37/50
2024-11-28 21:37:36.145039: train_loss -0.8553
2024-11-28 21:37:36.145771: val_loss -0.5989
2024-11-28 21:37:36.146653: Pseudo dice [0.7034]
2024-11-28 21:37:36.147886: Epoch time: 47.71 s
2024-11-28 21:37:37.430781: 
2024-11-28 21:37:37.432956: Epoch 158
2024-11-28 21:37:37.434173: Current learning rate: 0.00857
2024-11-28 21:38:25.259084: Validation loss did not improve from -0.62412. Patience: 38/50
2024-11-28 21:38:25.261037: train_loss -0.8488
2024-11-28 21:38:25.261974: val_loss -0.5618
2024-11-28 21:38:25.262982: Pseudo dice [0.6709]
2024-11-28 21:38:25.263663: Epoch time: 47.83 s
2024-11-28 21:38:26.537978: 
2024-11-28 21:38:26.540015: Epoch 159
2024-11-28 21:38:26.540757: Current learning rate: 0.00856
2024-11-28 21:39:14.240739: Validation loss did not improve from -0.62412. Patience: 39/50
2024-11-28 21:39:14.242745: train_loss -0.8537
2024-11-28 21:39:14.243534: val_loss -0.5526
2024-11-28 21:39:14.244135: Pseudo dice [0.6758]
2024-11-28 21:39:14.244762: Epoch time: 47.71 s
2024-11-28 21:39:16.007608: 
2024-11-28 21:39:16.009653: Epoch 160
2024-11-28 21:39:16.010787: Current learning rate: 0.00855
2024-11-28 21:40:03.707996: Validation loss did not improve from -0.62412. Patience: 40/50
2024-11-28 21:40:03.710339: train_loss -0.8531
2024-11-28 21:40:03.711443: val_loss -0.5343
2024-11-28 21:40:03.712330: Pseudo dice [0.6631]
2024-11-28 21:40:03.713794: Epoch time: 47.7 s
2024-11-28 21:40:04.982103: 
2024-11-28 21:40:04.984847: Epoch 161
2024-11-28 21:40:04.986429: Current learning rate: 0.00854
2024-11-28 21:40:52.698054: Validation loss did not improve from -0.62412. Patience: 41/50
2024-11-28 21:40:52.700066: train_loss -0.8561
2024-11-28 21:40:52.701367: val_loss -0.5563
2024-11-28 21:40:52.702518: Pseudo dice [0.6781]
2024-11-28 21:40:52.703681: Epoch time: 47.72 s
2024-11-28 21:40:53.957460: 
2024-11-28 21:40:53.959341: Epoch 162
2024-11-28 21:40:53.960114: Current learning rate: 0.00853
2024-11-28 21:41:41.670176: Validation loss did not improve from -0.62412. Patience: 42/50
2024-11-28 21:41:41.672274: train_loss -0.8558
2024-11-28 21:41:41.673263: val_loss -0.6029
2024-11-28 21:41:41.673984: Pseudo dice [0.7107]
2024-11-28 21:41:41.674813: Epoch time: 47.72 s
2024-11-28 21:41:42.948062: 
2024-11-28 21:41:42.950474: Epoch 163
2024-11-28 21:41:42.951707: Current learning rate: 0.00852
2024-11-28 21:42:30.667984: Validation loss did not improve from -0.62412. Patience: 43/50
2024-11-28 21:42:30.669579: train_loss -0.8494
2024-11-28 21:42:30.670769: val_loss -0.5387
2024-11-28 21:42:30.671915: Pseudo dice [0.6471]
2024-11-28 21:42:30.673000: Epoch time: 47.72 s
2024-11-28 21:42:31.966030: 
2024-11-28 21:42:31.968295: Epoch 164
2024-11-28 21:42:31.969347: Current learning rate: 0.00851
2024-11-28 21:43:19.742075: Validation loss did not improve from -0.62412. Patience: 44/50
2024-11-28 21:43:19.743855: train_loss -0.8494
2024-11-28 21:43:19.744705: val_loss -0.5775
2024-11-28 21:43:19.745764: Pseudo dice [0.6858]
2024-11-28 21:43:19.746787: Epoch time: 47.78 s
2024-11-28 21:43:21.906418: 
2024-11-28 21:43:21.908703: Epoch 165
2024-11-28 21:43:21.909829: Current learning rate: 0.0085
2024-11-28 21:44:09.642539: Validation loss did not improve from -0.62412. Patience: 45/50
2024-11-28 21:44:09.644452: train_loss -0.8527
2024-11-28 21:44:09.645317: val_loss -0.5805
2024-11-28 21:44:09.646033: Pseudo dice [0.701]
2024-11-28 21:44:09.646683: Epoch time: 47.74 s
2024-11-28 21:44:10.936903: 
2024-11-28 21:44:10.939189: Epoch 166
2024-11-28 21:44:10.940335: Current learning rate: 0.00849
2024-11-28 21:44:58.654863: Validation loss did not improve from -0.62412. Patience: 46/50
2024-11-28 21:44:58.656854: train_loss -0.8529
2024-11-28 21:44:58.657864: val_loss -0.5802
2024-11-28 21:44:58.658649: Pseudo dice [0.6928]
2024-11-28 21:44:58.659971: Epoch time: 47.72 s
2024-11-28 21:44:59.921619: 
2024-11-28 21:44:59.923347: Epoch 167
2024-11-28 21:44:59.924614: Current learning rate: 0.00848
2024-11-28 21:45:47.566851: Validation loss did not improve from -0.62412. Patience: 47/50
2024-11-28 21:45:47.569009: train_loss -0.8508
2024-11-28 21:45:47.569734: val_loss -0.5722
2024-11-28 21:45:47.570542: Pseudo dice [0.6896]
2024-11-28 21:45:47.571555: Epoch time: 47.65 s
2024-11-28 21:45:48.807548: 
2024-11-28 21:45:48.809683: Epoch 168
2024-11-28 21:45:48.810808: Current learning rate: 0.00847
2024-11-28 21:46:36.461554: Validation loss did not improve from -0.62412. Patience: 48/50
2024-11-28 21:46:36.463176: train_loss -0.8482
2024-11-28 21:46:36.464100: val_loss -0.5285
2024-11-28 21:46:36.464750: Pseudo dice [0.6521]
2024-11-28 21:46:36.465416: Epoch time: 47.66 s
2024-11-28 21:46:37.703162: 
2024-11-28 21:46:37.705437: Epoch 169
2024-11-28 21:46:37.706398: Current learning rate: 0.00847
2024-11-28 21:47:25.357911: Validation loss did not improve from -0.62412. Patience: 49/50
2024-11-28 21:47:25.360037: train_loss -0.8553
2024-11-28 21:47:25.361077: val_loss -0.5463
2024-11-28 21:47:25.362300: Pseudo dice [0.672]
2024-11-28 21:47:25.363349: Epoch time: 47.66 s
2024-11-28 21:47:27.163051: 
2024-11-28 21:47:27.165901: Epoch 170
2024-11-28 21:47:27.167209: Current learning rate: 0.00846
2024-11-28 21:48:14.825562: Validation loss did not improve from -0.62412. Patience: 50/50
2024-11-28 21:48:14.826756: train_loss -0.8485
2024-11-28 21:48:14.827561: val_loss -0.5491
2024-11-28 21:48:14.828487: Pseudo dice [0.6679]
2024-11-28 21:48:14.829531: Epoch time: 47.66 s
2024-11-28 21:48:16.092698: Patience reached. Stopping training.
2024-11-28 21:48:16.627867: Training done.
2024-11-28 21:48:16.910643: Using splits from existing split file: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_preprocessed/Dataset306_Sohee_Ajay_Calcium_OCT/splits_final.json
2024-11-28 21:48:16.924964: The split file contains 5 splits.
2024-11-28 21:48:16.925950: Desired fold for training: 4
2024-11-28 21:48:16.926825: This split has 11 training and 2 validation cases.
2024-11-28 21:48:16.927772: predicting 04010Pre
2024-11-28 21:48:16.939494: 04010Pre, shape torch.Size([1, 248, 498, 498]), rank 0
2024-11-28 21:48:35.655353: predicting 101-045
2024-11-28 21:48:35.676710: 101-045, shape torch.Size([1, 375, 498, 498]), rank 0
2024-11-28 21:50:57.772204: Validation complete
2024-11-28 21:50:57.772681: Mean Validation Dice:  0.5489400256952239
