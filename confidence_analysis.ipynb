{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e32cb4f-9335-4cd9-9755-637e2ff64d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffe6ff96-7e23-4dbf-a583-43d49f54f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ts = Path('/home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_raw/Dataset302_Calcium_OCTv2/labelsTs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff7e51d6-56ca-4373-87db-c6e7107445f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretraining_suffixes = [\n",
    "    # 'finetuned_from_scratch_test', 'finetuned_with_CLIP_test',\n",
    "                        'finetuned_with_Genesis_test', \n",
    "                        # 'finetuned_with_LaW_test'\n",
    "                       ]\n",
    "presentation_names = [\n",
    "    # 'nnUNet 3D/160x128x32', 'nnUNet 3D/160x128x32 (CLIP Pre-&Post-IVL)', \n",
    "                      'nnUNet 3D/160x128x32 (Genesis Unannotated OCT)', \n",
    "                      # 'nnUNet 3D/160x128x32 (LaW OCT)'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "998d7226-87b6-48fe-951e-373a8dc6114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = list(label_path.name for label_path in label_ts.glob(\"*.nii.gz\"))\n",
    "\n",
    "batched_labels = []\n",
    "for label_path in label_ts.glob(\"*.nii.gz\"):\n",
    "    # Read label to a numpy array\n",
    "    label = sitk.ReadImage(label_path)\n",
    "    label = sitk.GetArrayFromImage(label)\n",
    "    \n",
    "    # Convert a numpy array label to a Tensor\n",
    "    label = torch.Tensor(label)\n",
    "    label = label.long()\n",
    "    label = label.unsqueeze(0)\n",
    "\n",
    "    batched_labels.append(label)\n",
    "\n",
    "# BxDxHxW\n",
    "batched_labels = torch.vstack(batched_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c03ad5a-4b81-4a67-b092-865b5027aafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnUNet 3D/160x128x32 (Genesis Unannotated OCT) 0, 1, 2, Done!\n"
     ]
    }
   ],
   "source": [
    "root_path = Path('/home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset302_Calcium_OCTv2/nnUNetTrainer__nnUNetPlans__3d_32x160x128_b10/')\n",
    "losses = dict()\n",
    "for presentation_name, pretraining_suffix in zip(presentation_names, pretraining_suffixes):\n",
    "    losses[presentation_name] = []\n",
    "    print(presentation_name, end=\" \")\n",
    "    for fold in range(3):\n",
    "        print(fold , end=\", \")\n",
    "\n",
    "        prediction_folder = root_path / f'fold_{fold}_{pretraining_suffix}'\n",
    "\n",
    "        batched_log_probabilities = []\n",
    "        for label_name in label_names:\n",
    "            # Read prediction to a numpy array\n",
    "            prediction = np.load(prediction_folder / label_name.replace(\".nii.gz\", \".npz\"))\n",
    "            prediction = prediction['probabilities']\n",
    "\n",
    "            # Convert a numpy array probabilities into a log probability Tensor\n",
    "            prediction = torch.Tensor(prediction)\n",
    "            prediction = torch.log(prediction)\n",
    "            prediction = prediction.unsqueeze(0)\n",
    "\n",
    "            batched_log_probabilities.append(prediction)\n",
    "\n",
    "        # BxCxDxHxW\n",
    "        batched_log_probabilities = torch.vstack(batched_log_probabilities)\n",
    "\n",
    "        ce_loss = F.nll_loss(batched_log_probabilities, batched_labels)\n",
    "        losses[presentation_name].append(ce_loss.item())\n",
    "    print(\"Done!\")\n",
    "torch.save(losses, 'nnUNetTrainer_CELosses_Genesis.pt')    \n",
    "# torch.save(losses, 'nnUNetTrainer_CELosses_woPre_CLIP_LAW.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69eb69d0-53db-483d-b06c-70478d67eb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale 2\n",
      "nnUNet 3D/160x128x32 (Genesis Unannotated OCT) 0, 1, 2, Done!\n",
      "Scale 3\n",
      "nnUNet 3D/160x128x32 (Genesis Unannotated OCT) 0, 1, 2, Done!\n",
      "Scale 4\n",
      "nnUNet 3D/160x128x32 (Genesis Unannotated OCT) 0, 1, 2, Done!\n",
      "Scale 5\n",
      "nnUNet 3D/160x128x32 (Genesis Unannotated OCT) 0, 1, 2, Done!\n"
     ]
    }
   ],
   "source": [
    "for scale in range(2,6):\n",
    "    print(\"Scale\", scale)\n",
    "    root_path = Path(f'/home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_results/Dataset302_Calcium_OCTv2/nnUNetTrainerScaleAnalysis{scale}__nnUNetPlans__3d_32x160x128_b10/')\n",
    "\n",
    "    losses = dict()\n",
    "    for presentation_name, pretraining_suffix in zip(presentation_names, pretraining_suffixes):\n",
    "        losses[presentation_name] = []\n",
    "        print(presentation_name, end=\" \")\n",
    "        for fold in range(3):\n",
    "            print(fold , end=\", \")\n",
    "\n",
    "            prediction_folder = root_path / f'fold_{fold}_{pretraining_suffix}'\n",
    "\n",
    "            batched_log_probabilities = []\n",
    "            for label_name in label_names:\n",
    "                # Read prediction to a numpy array\n",
    "                prediction = np.load(prediction_folder / label_name.replace(\".nii.gz\", \".npz\"))\n",
    "                prediction = prediction['probabilities']\n",
    "\n",
    "                # Convert a numpy array probabilities into a log probability Tensor\n",
    "                prediction = torch.Tensor(prediction)\n",
    "                prediction = torch.log(prediction)\n",
    "                prediction = prediction.unsqueeze(0)\n",
    "\n",
    "                batched_log_probabilities.append(prediction)\n",
    "\n",
    "            # BxCxDxHxW\n",
    "            batched_log_probabilities = torch.vstack(batched_log_probabilities)\n",
    "\n",
    "            ce_loss = F.nll_loss(batched_log_probabilities, batched_labels)\n",
    "            losses[presentation_name].append(ce_loss.item())\n",
    "        print(\"Done!\")\n",
    "    torch.save(losses, f'nnUNetTrainerScaleAnalysis{scale}_CELosses_Genesis.pt')\n",
    "    # torch.save(losses, f'nnUNetTrainerScaleAnalysis{scale}_CELosses_woPre_CLIP_LAW.pt')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d82af45a-6736-46dd-bdb0-ba3d8d8c5336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nnUNet 3D/160x128x32 (Genesis Unannotated OCT)': [0.04950612410902977,\n",
       "  0.053184833377599716,\n",
       "  0.046510886400938034]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = torch.load('nnUNetTrainer_CELosses_Genesis.pt')\n",
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c412d5ab-c9a9-42c9-8318-aee9e9367668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nnUNet 3D/160x128x32': [0.05369274690747261,\n",
       "  0.0596805214881897,\n",
       "  0.05074412375688553],\n",
       " 'nnUNet 3D/160x128x32 (CLIP Pre-&Post-IVL)': [0.0556299164891243,\n",
       "  0.056006330996751785,\n",
       "  0.04590117186307907],\n",
       " 'nnUNet 3D/160x128x32 (LaW OCT)': [0.04940780624747276,\n",
       "  0.04896751418709755,\n",
       "  0.0490996427834034]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = torch.load('nnUNetTrainer_CELosses_woPre_CLIP_LAW.pt')\n",
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb1a1cd9-1474-4b3e-bd92-4ff29ff4d194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{'nnUNet 3D/160x128x32 (Genesis Unannotated OCT)': [0.0996871143579483, 0.0918693095445633, 0.10200122743844986]}\n",
      "\n",
      "3\n",
      "{'nnUNet 3D/160x128x32 (Genesis Unannotated OCT)': [0.06646720319986343, 0.07186301797628403, 0.08549285680055618]}\n",
      "\n",
      "4\n",
      "{'nnUNet 3D/160x128x32 (Genesis Unannotated OCT)': [0.06043776497244835, 0.06393242627382278, 0.055108971893787384]}\n",
      "\n",
      "5\n",
      "{'nnUNet 3D/160x128x32 (Genesis Unannotated OCT)': [0.07767369598150253, 0.06849031150341034, 0.12025713920593262]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for scale in range(2,6):\n",
    "    print(scale)\n",
    "    losses = torch.load(f'nnUNetTrainerScaleAnalysis{scale}_CELosses_Genesis.pt')\n",
    "    print(losses)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "817750ae-e8ad-4eee-a726-c1d29e9204ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{'nnUNet 3D/160x128x32': [0.10112794488668442, 0.0981173887848854, 0.12073627859354019], 'nnUNet 3D/160x128x32 (CLIP Pre-&Post-IVL)': [0.10181018710136414, 0.09586725383996964, 0.12667453289031982], 'nnUNet 3D/160x128x32 (LaW OCT)': [0.07728803902864456, 0.07829064130783081, 0.090856172144413]}\n",
      "\n",
      "3\n",
      "{'nnUNet 3D/160x128x32': [0.15814074873924255, 0.0674314796924591, 0.09355108439922333], 'nnUNet 3D/160x128x32 (CLIP Pre-&Post-IVL)': [0.055596042424440384, 0.0710187628865242, 0.0884246826171875], 'nnUNet 3D/160x128x32 (LaW OCT)': [0.061689358204603195, 0.063583143055439, 0.0835082158446312]}\n",
      "\n",
      "4\n",
      "{'nnUNet 3D/160x128x32': [0.07198143005371094, 0.055013902485370636, 0.05309624597430229], 'nnUNet 3D/160x128x32 (CLIP Pre-&Post-IVL)': [0.060034286230802536, 0.05875031650066376, 0.049891747534275055], 'nnUNet 3D/160x128x32 (LaW OCT)': [0.06659381836652756, 0.05495190992951393, 0.05585246533155441]}\n",
      "\n",
      "5\n",
      "{'nnUNet 3D/160x128x32': [0.08301436901092529, 0.06917698681354523, 0.11636274307966232], 'nnUNet 3D/160x128x32 (CLIP Pre-&Post-IVL)': [0.08754587918519974, 0.0631466954946518, 0.11517512798309326], 'nnUNet 3D/160x128x32 (LaW OCT)': [0.06787256896495819, 0.05537740886211395, 0.10037226974964142]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for scale in range(2,6):\n",
    "    print(scale)\n",
    "    losses = torch.load(f'nnUNetTrainerScaleAnalysis{scale}_CELosses_woPre_CLIP_LAW.pt')\n",
    "    print(losses)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2003e092-d067-4e38-b83f-1bcc133a9fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9c4461-4092-4701-b632-16c4f6ab35a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c22e7da-f091-4628-ae88-212e8d8a1179",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
